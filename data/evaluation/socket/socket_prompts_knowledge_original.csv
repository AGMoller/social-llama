type,task,question,options,knowledge
PAIR,talkdown-pairs,"For the quote ""{text_a}"" and its context ""{text_b}"", is the quote condescending?","['No', 'Yes']"
REG,hahackathon#humor_rating,"Determine the degree of humor of the given sentence: ""{text}"". The score should be ranging from 0.0 to 5.0, and can be a decimal. 0 is not humorous at all, and 5 is very humorous.",
CLS,hahackathon#is_humor,"For the sentence: ""{text}"", is it humorous?","['No', 'Yes']","'No': This label is used if the sentence lacks humor, meaning it does not intend to amuse or invoke laughter. 'Yes': This label applies if the sentence is humorous, indicating it is meant to be funny, witty, or amusing."
PAIR,humor-pairs,"The first sentence is ""{text_a}"". The second sentence is ""{text_b}"". Is the first sentence funnier than the second sentence?","['Yes', 'No']"
CLS,sarc,"For the sentence: ""{text}"", is it sarcastic?","['Yes', 'No']","'Yes': This label indicates the sentence is sarcastic, meaning it conveys irony or mocks with a tone of detachment or insincerity. 'No': This label is used if the sentence is not sarcastic, implying a straightforward or sincere expression without irony."
CLS,tweet_irony,"For the sentence: ""{text}"", is it ironic?","['No', 'Yes']","Definition of irony in a text: The text expresses an evaluation whose literal polarity is the opposite of the intended polarity. "
CLS,contextual-abuse#IdentityDirectedAbuse,"For the sentence: ""{text}"", is it identity directed abuse?","['No', 'Yes']","Definition of ‚Äúidentity directed abuse‚Äù: Content which contains a negative statement made against an identity. An ‚Äòidentity‚Äô is a social category that relates to a fundamental aspect of individuals‚Äô community, socio-demographics, position or self-representation. It includes but is not limited to Religion, Race, Ethnicity, Gender, Sexuality, Nationality, Disability/Ableness and Class."
CLS,contextual-abuse#PersonDirectedAbuse,"For the sentence: ""{text}"", is it person directed abuse?","['No', 'Yes']","Definition of ‚Äúperson directed abuse‚Äù: Content which directs negativity against an identifiable person, who is either part of the conversation thread or is named. Person-directed abuse includes serious character based attacks, such as accusing the person of lying, as well as aggression, insults and menacing language."
REG,hahackathon#offense_rating,"Determine the degree of offense of the given sentence: ""{text}"". The score should be ranging from 0.0 to 5.0, and can be a decimal.",
CLS,hasbiasedimplication,"For the sentence: ""{text}"", does it imply some biases?","['No', 'Yes']"
CLS,hateoffensive,"For the sentence: ""{text}"", is it hate or offensive?","['Hate', 'Offensive', 'Neither']","'Hate': we define hate speech as language that is used to expresses hatred towards a targeted group or is intended to be derogatory, to humiliate, or to insult the members of the group"
CLS,implicit-hate#explicit_hate,"For the sentence: ""{text}"", is it explicit hate?","['No', 'Yes']","Explicit hate: explicit hate speech contains explicit keywords directed towards a protected entity."
CLS,implicit-hate#implicit_hate,"For the sentence: ""{text}"", is it implicitly hateful?","['No', 'Yes']","Implicit hate: coded or indirect language that disparages a person or group on the basis of protected characteristics like race, gender, and cultural identity."
CLS,implicit-hate#incitement_hate,"For the sentence: ""{text}"", is it a hateful incitement to act?","['No', 'Yes']"
CLS,implicit-hate#inferiority_hate,"For the sentence: ""{text}"", is it inferiority hate?","['No', 'Yes']"
CLS,implicit-hate#stereotypical_hate,"For the sentence: ""{text}"", is it a hateful message involving stereotypes?","['No', 'Yes']"
CLS,implicit-hate#threatening_hate,"For the sentence: ""{text}"", is it hateful in a threatening way?","['No', 'Yes']"
CLS,implicit-hate#white_grievance_hate,"For the sentence: ""{text}"", is it white grievance hate?","['No', 'Yes']"
CLS,intentyn,"For the sentence: ""{text}"", is it intentional?","['No', 'Yes']"
CLS,jigsaw#identity_hate,"For the sentence: ""{text}"", is it identity hate?","['No', 'Yes']"
CLS,jigsaw#insult,"For the sentence: ""{text}"", is it an insult?","['No', 'Yes']"
CLS,jigsaw#obscene,"For the sentence: ""{text}"", is it obscene?","['No', 'Yes']"
CLS,jigsaw#severe_toxic,"For the sentence: ""{text}"", is it severely toxic?","['No', 'Yes']"
CLS,jigsaw#threat,"For the sentence: ""{text}"", is it a threat?","['No', 'Yes']"
CLS,jigsaw#toxic,"For the sentence: ""{text}"", is it toxic?","['No', 'Yes']"
CLS,offensiveyn,"For the sentence: ""{text}"", is it offensive?","['No', 'Yes']"
CLS,sexyn,"For the sentence: ""{text}"", is it sexist?","['No', 'Yes']"
SPAN,toxic-span,"In the sentence: ""{text}"", which part of it can be identified as toxic?",
CLS,tweet_offensive,"For the sentence: ""{text}"", is it offensive?","['No', 'Yes']"
CLS,crowdflower,"For the sentence: ""{text}"", what is its emotion?","['empty', 'sadness', 'enthusiasm', 'neutral', 'worry', 'love', 'fun', 'hate', 'happiness', 'relief', 'boredom', 'surprise', 'anger']","'empty': This label is used if the sentence conveys a sense of emptiness or lack of emotion. 'sadness': This label applies to sentences that express feelings of sorrow or melancholy. 'enthusiasm': This label is chosen for sentences expressing excitement or energetic interest. 'neutral': This label signifies a sentence with a neutral tone, lacking strong emotional content. 'worry': This label is for sentences that express anxiety or concern. 'love': This label applies to sentences expressing affection, love, or deep liking. 'fun': This label is used for sentences that convey a sense of enjoyment or amusement. 'hate': This label indicates sentences expressing intense dislike or hostility. 'happiness': This label is for sentences that express joy or contentment. 'relief': This label applies to sentences expressing a sense of alleviation or ease of concern or distress. 'boredom': This label is used for sentences that convey a sense of tedium or uninterest. 'surprise': This label is for sentences that express astonishment or unexpectedness. 'anger': This label applies to sentences that convey feelings of rage or intense displeasure."
CLS,dailydialog,"For the given conversation, ""{text}"", what is its emotion?","['no emotion', 'anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise']","'no emotion': This label is chosen if the conversation lacks any discernible emotional content, indicating a neutral or emotionless tone. 'anger': This label applies to conversations expressing feelings of anger, such as rage, frustration, or irritation. 'disgust': This label is used for conversations that convey a sense of disgust, revulsion, or strong disapproval. 'fear': This label indicates conversations expressing fear, anxiety, or apprehension. 'happiness': This label is chosen for conversations that express joy, contentment, or positivity. 'sadness': This label applies to conversations that convey sadness, sorrow, or melancholy. 'surprise': This label is used for conversations that express surprise, shock, or astonishment."
REG,emobank#arousal,"Given the VAD model of emotion, determine the degree of arousal of the given sentence: ""{text}"". The score should be ranging from 0.0 to 5.0, and can be a decimal.",
REG,emobank#dominance,"Given the VAD model of emotion, determine the degree of dominance of the given sentence: ""{text}"". The score should be ranging from 0.0 to 5.0, and can be a decimal.",
REG,emobank#valence,"Given the VAD model of emotion, determine the degree of valence of the given sentence: ""{text}"". The score should be ranging from 0.0 to 5.0, and can be a decimal.",
SPAN,emotion-span,"In the sentence: ""{text}"", which part of it expresses strong emotion?",
REG,empathy#distress,"Determine the degree of distress of the given sentence: ""{text}"". The score should be ranging from 0.0 to 7.0, and can be a decimal.",
CLS,empathy#distress_bin,"For the sentence: ""{text}"", is it showing distress?","['No', 'Yes']"
PAIR,same-side-pairs,"For the sentences: ""{text_a}"" and ""{text_b}"", are they on the same side?","['No', 'Yes']"
CLS,sentitreebank,"For the sentence: ""{text}"", is it positive?","['Yes', 'No']"
CLS,tweet_emoji,"For the sentence: ""{text}"", what is the emoji that can be added to it?","['‚ù§', 'üòç', 'üòÇ', 'üíï', 'üî•', 'üòä', 'üòé', '‚ú®', 'üíô', 'üòò', 'üì∑', 'üá∫üá∏', '‚òÄ', 'üíú', 'üòâ', 'üíØ', 'üòÅ', 'üéÑ', 'üì∏', 'üòú']"
CLS,tweet_emotion,"For the sentence: ""{text}"", what is its emotion?","['anger', 'joy', 'optimism', 'sadness']","anger (also includes annoyance, rage), anticipation (also includes interest, vigilance), disgust (also includes disinterest, dislike, loathing), fear (also includes apprehension, anxiety, terror), joy (also includes serenity, ecstasy), love (also includes affection), optimism (also includes hopefulness, confidence), pessimism (also includes cynicism, no confidence), sadness (also includes pensiveness, grief), surprise (also includes distraction, amazement), trust (also includes acceptance, liking, admiration), neutral or no emotion"
CLS,tweet_sentiment,"For the sentence: ""{text}"", what is its sentiment?","['negative', 'neutral', 'positive']"
CLS,complaints,"For the sentence: ""{text}"", is it a complaint?","['No', 'Yes']"
REG,empathy#empathy,"Determine the degree of empathy of the given sentence: ""{text}"". The score should be ranging from 0.0 to 7.0, and can be a decimal.",
CLS,empathy#empathy_bin,"For the sentence: ""{text}"", is it expressing empathy?","['No', 'Yes']"
CLS,hayati_politeness,"For the sentence: ""{text}"", is it polite?","['No', 'Yes']"
CLS,questionintimacy,"For the sentence: ""{text}"", how intimate do you think it is?","['Very intimate', 'Intimate', 'Somewhat intimate', 'Not very intimate', 'Not intimate', 'Not intimate at all']","'Very intimate': This label is used for sentences that express a very high degree of personal or private emotional closeness or familiarity. 'Intimate': This label applies to sentences that show a significant, but not the highest, level of personal or emotional closeness. 'Somewhat intimate': This label is chosen for sentences that indicate a moderate level of personal or emotional closeness. 'Not very intimate': This label is used for sentences that display a low level of personal or emotional closeness. 'Not intimate': This label applies to sentences that lack a sense of personal or emotional closeness. 'Not intimate at all': This label is chosen for sentences that are completely devoid of any intimacy, indicating no personal or emotional closeness."
CLS,stanfordpoliteness,"For the sentence: ""{text}"", is it polite?","['Yes', 'No']"
CLS,bragging#brag_achievement,"For the sentence: ""{text}"", is it bragging about an achievement?","['No', 'Yes']"
CLS,bragging#brag_action,"For the sentence: ""{text}"", is it bragging about an action?","['No', 'Yes']"
CLS,bragging#brag_possession,"For the sentence: ""{text}"", is it bragging about a possession?","['No', 'Yes']"
CLS,bragging#brag_trait,"For the sentence: ""{text}"", is it bragging about a trait?","['No', 'Yes']"
CLS,hypo-l,"For the sentence: ""{text}"", is it a hyperbole?","['No', 'Yes']"
PAIR,neutralizing-bias-pairs,"For the sentences: ""{text_a}"" and ""{text_b}"", which one is biased?","['the first sentence is biased', 'the second sentence is biased']"
SPAN,propaganda-span,"In the sentence: ""{text}"", which part of it can be identified as the propaganda?",
CLS,rumor#rumor_bool,"For the sentence: ""{text}"", is it a rumor?","['No', 'Yes']"
CLS,two-to-lie#receiver_truth,"For the sentence :""{text}"", will it be perceived as a lie by the receiver?","['Yes', 'No']"
CLS,two-to-lie#sender_truth,"For the sentence :""{text}"", is the sender intending to tell a lie?","['Yes', 'No']"