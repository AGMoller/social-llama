[
    {
        "text": "Auto-Encoding Total Correlation Explanation.   Advances in unsupervised learning enable reconstruction and generation of\nsamples from complex distributions, but this success is marred by the\ninscrutability of the representations learned. We propose an\ninformation-theoretic approach to characterizing disentanglement and dependence\nin representation learning using multivariate mutual information, also called\ntotal correlation. The principle of total Cor-relation Ex-planation (CorEx) has\nmotivated successful unsupervised learning applications across a variety of\ndomains, but under some restrictive assumptions. Here we relax those\nrestrictions by introducing a flexible variational lower bound to CorEx.\nSurprisingly, we find that this lower bound is equivalent to the one in\nvariational autoencoders (VAE) under certain conditions. This\ninformation-theoretic view of VAE deepens our understanding of hierarchical VAE\nand motivates a new algorithm, AnchorVAE, that makes latent codes more\ninterpretable through information maximization and enables generation of richer\nand more realistic samples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Zhu reduction for Jacobi $n$-point functions and applications.   We establish precise Zhu reduction formulas for Jacobi $n$-point functions\nwhich show the absence of any possible poles arising in these formulas. We then\nexploit this to produce results concerning the structure of strongly regular\nvertex operator algebras, and also to motivate new differential operators\nacting on Jacobi forms. Finally, we apply the reduction formulas to the Fermion\nmodel in order to create polynomials of quasi-Jacobi forms which are Jacobi\nforms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Large-Scale CNN Ensemble for Medication Safety Analysis.   Revealing Adverse Drug Reactions (ADR) is an essential part of post-marketing\ndrug surveillance, and data from health-related forums and medical communities\ncan be of a great significance for estimating such effects. In this paper, we\npropose an end-to-end CNN-based method for predicting drug safety on user\ncomments from healthcare discussion forums. We present an architecture that is\nbased on a vast ensemble of CNNs with varied structural parameters, where the\nprediction is determined by the majority vote. To evaluate the performance of\nthe proposed solution, we present a large-scale dataset collected from a\nmedical website that consists of over 50 thousand reviews for more than 4000\ndrugs. The results demonstrate that our model significantly outperforms\nconventional approaches and predicts medicine safety with an accuracy of 87.17%\nfor binary and 62.88% for multi-classification tasks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Concentration of Multilinear Functions of the Ising Model with Applications to Network Data.   We prove near-tight concentration of measure for polynomial functions of the\nIsing model under high temperature. For any degree $d$, we show that a\ndegree-$d$ polynomial of a $n$-spin Ising model exhibits exponential tails that\nscale as $\\exp(-r^{2/d})$ at radius $r=\\tilde{\\Omega}_d(n^{d/2})$. Our\nconcentration radius is optimal up to logarithmic factors for constant $d$,\nimproving known results by polynomial factors in the number of spins. We\ndemonstrate the efficacy of polynomial functions as statistics for testing the\nstrength of interactions in social networks in both synthetic and real world\ndata.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evidence Logics with Relational Evidence.   Dynamic evidence logics are logics for reasoning about the evidence and\nevidence-based beliefs of agents in a dynamic environment. In this paper, we\nintroduce a family of logics for reasoning about relational evidence: evidence\nthat involves an orderings of states in terms of their relative plausibility.\nWe provide sound and complete axiomatizations for the logics. We also present\nseveral evidential actions and prove soundness and completeness for the\nassociated dynamic logics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Right Amenability And Growth Of Finitely Right Generated Left Group Sets.   We introduce right generating sets, Cayley graphs, growth functions, types\nand rates, and isoperimetric constants for left homogeneous spaces equipped\nwith coordinate systems; characterise right amenable finitely right generated\nleft homogeneous spaces with finite stabilisers as those whose isoperimetric\nconstant is $0$; and prove that finitely right generated left homogeneous\nspaces with finite stabilisers of sub-exponential growth are right amenable, in\nparticular, quotient sets of groups of sub-exponential growth by finite\nsubgroups are right amenable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Performance of Range Separated Hybrids: Study within BECKE88 family and Semilocal Exchange Hole based Range Separated Hybrid.   A long range corrected range separated hybrid functional is developed based\non the density matrix expansion (DME) based semilocal exchange hole with\nLee-Yang-Parr (LYP) correlation. An extensive study involving the proposed\nrange separated hybrid for thermodynamic as well as properties related to the\nfractional occupation number is compared with different BECKE88 family\nsemilocal, hybrid and range separated hybrids. It has been observed that using\nKohn-Sham kinetic energy dependent exchange hole several properties related to\nthe fractional occupation number can be improved without hindering the\nthermochemical accuracy. The newly constructed range separated hybrid\naccurately describe the hydrogen and non-hydrogen reaction barrier heights. The\npresent range separated functional has been constructed using full semilocal\nmeta-GGA type exchange hole having exact properties related to exchange hole\ntherefore, it has a strong physical basis.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Graphons: A Nonparametric Method to Model, Estimate, and Design Algorithms for Massive Networks.   Many social and economic systems are naturally represented as networks, from\noff-line and on-line social networks, to bipartite networks, like Netflix and\nAmazon, between consumers and products. Graphons, developed as limits of\ngraphs, form a natural, nonparametric method to describe and estimate large\nnetworks like Facebook and LinkedIn. Here we describe the development of the\ntheory of graphons, for both dense and sparse networks, over the last decade.\nWe also review theorems showing that we can consistently estimate graphons from\nmassive networks in a wide variety of models. Finally, we show how to use\ngraphons to estimate missing links in a sparse network, which has applications\nfrom estimating social and information networks in development economics, to\nrigorously and efficiently doing collaborative filtering with applications to\nmovie recommendations in Netflix and product suggestions in Amazon.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Prospects of detecting HI using redshifted 21 cm radiation at z ~ 3.   Distribution of cold gas in the post-reionization era provides an important\nlink between distribution of galaxies and the process of star formation.\nRedshifted 21 cm radiation from the Hyperfine transition of neutral Hydrogen\nallows us to probe the neutral component of cold gas, most of which is to be\nfound in the interstellar medium of galaxies. Existing and upcoming radio\ntelescopes can probe the large scale distribution of neutral Hydrogen via HI\nintensity mapping. In this paper we use an estimate of the HI power spectrum\nderived using an ansatz to compute the expected signal from the large scale HI\ndistribution at z ~ 3. We find that the scale dependence of bias at small\nscales makes a significant difference to the expected signal even at large\nangular scales. We compare the predicted signal strength with the sensitivity\nof radio telescopes that can observe such radiation and calculate the\nobservation time required for detecting neutral Hydrogen at these redshifts. We\nfind that OWFA (Ooty Wide Field Array) offers the best possibility to detect\nneutral Hydrogen at z ~ 3 before the SKA (Square Kilometer Array) becomes\noperational. We find that the OWFA should be able to make a 3 sigma or a more\nsignificant detection in 2000 hours of observations at several angular scales.\nCalculations done using the Fisher matrix approach indicate that a 5 sigma\ndetection of the binned HI power spectrum via measurement of the amplitude of\nthe HI power spectrum is possible in 1000 hours (Sarkar, Bharadwaj and Ali,\n2017).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Local-Search Algorithm for Steiner Forest.   In the Steiner Forest problem, we are given a graph and a collection of\nsource-sink pairs, and the goal is to find a subgraph of minimum total length\nsuch that all pairs are connected. The problem is APX-Hard and can be\n2-approximated by, e.g., the elegant primal-dual algorithm of Agrawal, Klein,\nand Ravi from 1995.\nWe give a local-search-based constant-factor approximation for the problem.\nLocal search brings in new techniques to an area that has for long not seen any\nimprovements and might be a step towards a combinatorial algorithm for the more\ngeneral survivable network design problem. Moreover, local search was an\nessential tool to tackle the dynamic MST/Steiner Tree problem, whereas dynamic\nSteiner Forest is still wide open.\nIt is easy to see that any constant factor local search algorithm requires\nsteps that add/drop many edges together. We propose natural local moves which,\nat each step, either (a) add a shortest path in the current graph and then drop\na bunch of inessential edges, or (b) add a set of edges to the current\nsolution. This second type of moves is motivated by the potential function we\nuse to measure progress, combining the cost of the solution with a penalty for\neach connected component. Our carefully-chosen local moves and potential\nfunction work in tandem to eliminate bad local minima that arise when using\nmore traditional local moves.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A unified view of entropy-regularized Markov decision processes.   We propose a general framework for entropy-regularized average-reward\nreinforcement learning in Markov decision processes (MDPs). Our approach is\nbased on extending the linear-programming formulation of policy optimization in\nMDPs to accommodate convex regularization functions. Our key result is showing\nthat using the conditional entropy of the joint state-action distributions as\nregularization yields a dual optimization problem closely resembling the\nBellman optimality equations. This result enables us to formalize a number of\nstate-of-the-art entropy-regularized reinforcement learning algorithms as\napproximate variants of Mirror Descent or Dual Averaging, and thus to argue\nabout the convergence properties of these methods. In particular, we show that\nthe exact version of the TRPO algorithm of Schulman et al. (2015) actually\nconverges to the optimal policy, while the entropy-regularized policy gradient\nmethods of Mnih et al. (2016) may fail to converge to a fixed point. Finally,\nwe illustrate empirically the effects of using various regularization\ntechniques on learning performance in a simple reinforcement learning setup.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interpretable Feature Recommendation for Signal Analytics.   This paper presents an automated approach for interpretable feature\nrecommendation for solving signal data analytics problems. The method has been\ntested by performing experiments on datasets in the domain of prognostics where\ninterpretation of features is considered very important. The proposed approach\nis based on Wide Learning architecture and provides means for interpretation of\nthe recommended features. It is to be noted that such an interpretation is not\navailable with feature learning approaches like Deep Learning (such as\nConvolutional Neural Network) or feature transformation approaches like\nPrincipal Component Analysis. Results show that the feature recommendation and\ninterpretation techniques are quite effective for the problems at hand in terms\nof performance and drastic reduction in time to develop a solution. It is\nfurther shown by an example, how this human-in-loop interpretation system can\nbe used as a prescriptive system.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Edge states in non-Fermi liquids.   We devise an approach to the calculation of scaling dimensions of generic\noperators describing scattering within multi-channel Luttinger liquid. The\nlocal impurity scattering in an arbitrary configuration of conducting and\ninsulating channels is investigated and the problem is reduced to a single\nalgebraic matrix equation. In particular, the solution to this equation is\nfound for a finite array of chains described by Luttinger liquid models. It is\nfound that for a weak inter-chain hybridisation and intra-channel\nelectron-electron attraction the edge wires are robust against disorder whereas\nbulk wires, on contrary, become insulating. Thus, the edge state may exist in a\nfinite sliding Luttinger liquid without time-reversal symmetry breaking\n(quantum Hall systems) or spin-orbit interaction (topological insulators).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stable absorbing boundary conditions for molecular dynamics in general domains.   A new type of absorbing boundary conditions for molecular dynamics\nsimulations are presented. The exact boundary conditions for crystalline solids\nwith harmonic approximation are expressed as a dynamic Dirichlet- to-Neumann\n(DtN) map. It connects the displacement of the atoms at the boundary to the\ntraction on these atoms. The DtN map is valid for a domain with general\ngeometry. To avoid evaluating the time convo- lution of the dynamic DtN map, we\napproximate the associated kernel function by rational functions in the Laplace\ndomain. The parameters in the approximations are determined by interpolations.\nThe explicit forms of the zeroth, first, and second order approximations will\nbe presented. The stability of the molecular dynamics model, supplemented with\nthese absorbing boundary conditions is established. Two numerical simulations\nare performed to demonstrate the effectiveness of the methods.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A criterion related to the Riemann Hypothesis.   A crucial role in the Nyman-Beurling-Báez-Duarte approach to the Riemann\nHypothesis is played by the distance \\[\nd_N^2:=\\inf_{A_N}\\frac{1}{2\\pi}\\int_{-\\infty}^\\infty\\left|1-\\zeta\nA_N\\left(\\frac{1}{2}+it\\right)\\right|^2\\frac{dt}{\\frac{1}{4}+t^2}\\:, \\] where\nthe infimum is over all Dirichlet polynomials\n$$A_N(s)=\\sum_{n=1}^{N}\\frac{a_n}{n^s}$$ of length $N$. In this paper we\ninvestigate $d_N^2$ under the assumption that the Riemann zeta function has\nfour non-trivial zeros off the critical line. Thus we obtain a criterion for\nthe non validity of the Riemann Hypothesis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Designing Coalition-Proof Reverse Auctions over Continuous Goods.   This paper investigates reverse auctions that involve continuous values of\ndifferent types of goods, general nonconvex constraints, and second stage\ncosts. We seek to design the payment rules and conditions under which\ncoalitions of participants cannot influence the auction outcome in order to\nobtain higher collective utility. Under the incentive-compatible\nVickrey-Clarke-Groves mechanism, we show that coalition-proof outcomes are\nachieved if the submitted bids are convex and the constraint sets are of a\npolymatroid-type. These conditions, however, do not capture the complexity of\nthe general class of reverse auctions under consideration. By relaxing the\nproperty of incentive-compatibility, we investigate further payment rules that\nare coalition-proof without any extra conditions on the submitted bids and the\nconstraint sets. Since calculating the payments directly for these mechanisms\nis computationally difficult for auctions involving many participants, we\npresent two computationally efficient methods. Our results are verified with\nseveral case studies based on electricity market data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uncertainty quantification of coal seam gas production prediction using Polynomial Chaos.   A surrogate model approximates a computationally expensive solver. Polynomial\nChaos is a method to construct surrogate models by summing combinations of\ncarefully chosen polynomials. The polynomials are chosen to respect the\nprobability distributions of the uncertain input variables (parameters); this\nallows for both uncertainty quantification and global sensitivity analysis.\nIn this paper we apply these techniques to a commercial solver for the\nestimation of peak gas rate and cumulative gas extraction from a coal seam gas\nwell. The polynomial expansion is shown to honour the underlying geophysics\nwith low error when compared to a much more complex and computationally slower\ncommercial solver. We make use of advanced numerical integration techniques to\nachieve this accuracy using relatively small amounts of training data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On noncommutative geometry of the Standard Model: fermion multiplet as internal forms.   We unveil the geometric nature of the multiplet of fundamental fermions in\nthe Standard Model of fundamental particles as a noncommutative analogue of de\nRham forms on the internal finite quantum space.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Verifying Patterns of Dynamic Architectures using Model Checking.   Architecture patterns capture architectural design experience and provide\nabstract solutions to recurring architectural design problems. They consist of\na description of component types and restrict component connection and\nactivation. Therefore, they guarantee some desired properties for architectures\nemploying the pattern. Unfortunately, most documented patterns do not provide a\nformal guarantee of whether their specification indeed leads to the desired\nguarantee. Failure in doing so, however, might lead to wrong architectures,\ni.e., architectures wrongly supposed to show certain desired properties. Since\narchitectures, in general, have a high impact on the quality of the resulting\nsystem and architectural flaws are only difficult, if not to say impossible, to\nrepair, this may lead to badly reparable quality issues in the resulting\nsystem. To address this problem, we propose an approach based on model checking\nto verify pattern specifications w.r.t. their guarantees. In the following we\napply the approach to three well-known patterns for dynamic architectures: the\nSingleton, the Model-View-Controller, and the Broker pattern. Thereby, we\ndiscovered ambiguities and missing constraints for all three specifications.\nThus, we conclude that verifying patterns of dynamic architectures using model\nchecking is feasible and useful to discover ambiguities and flaws in pattern\nspecifications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Transition to turbulence when the Tollmien-Schlichting and bypass routes coexist.   Plane Poiseuille flow, the pressure driven flow between parallel plates,\nshows a route to turbulence connected with a linear instability to\nTollmien-Schlichting (TS) waves, and another one, the bypass transition, that\nis triggered with finite amplitude perturbation. We use direct numerical\nsimulations to explore the arrangement of the different routes to turbulence\namong the set of initial conditions. For plates that are a distance $2H$ apart\nand in a domain of width $2\\pi H$ and length $2\\pi H$ the subcritical\ninstability to TS waves sets in at $Re_{c}=5815$ that extends down to\n$Re_{TS}\\approx4884$. The bypass route becomes available above $Re_E=459$ with\nthe appearance of three-dimensional finite-amplitude traveling waves. The\nbypass transition covers a large set of finite amplitude perturbations. Below\n$Re_c$, TS appear for a tiny set of initial conditions that grows with\nincreasing Reynolds number. Above $Re_c$ the previously stable region becomes\nunstable via TS waves, but a sharp transition to the bypass route can still be\nidentified. Both routes lead to the same turbulent in the final stage of the\ntransition, but on different time scales. Similar phenomena can be expected in\nother flows where two or more routes to turbulence compete.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Solving Non-parametric Inverse Problem in Continuous Markov Random Field using Loopy Belief Propagation.   In this paper, we address the inverse problem, or the statistical machine\nlearning problem, in Markov random fields with a non-parametric pair-wise\nenergy function with continuous variables. The inverse problem is formulated by\nmaximum likelihood estimation. The exact treatment of maximum likelihood\nestimation is intractable because of two problems: (1) it includes the\nevaluation of the partition function and (2) it is formulated in the form of\nfunctional optimization. We avoid Problem (1) by using Bethe approximation.\nBethe approximation is an approximation technique equivalent to the loopy\nbelief propagation. Problem (2) can be solved by using orthonormal function\nexpansion. Orthonormal function expansion can reduce a functional optimization\nproblem to a function optimization problem. Our method can provide an analytic\nform of the solution of the inverse problem within the framework of Bethe\napproximation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Extension complexities of Cartesian products involving a pyramid.   It is an open question whether the linear extension complexity of the\nCartesian product of two polytopes P, Q is the sum of the extension\ncomplexities of P and Q. We give an affirmative answer to this question for the\ncase that one of the two polytopes is a pyramid.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards Neural Co-Processors for the Brain: Combining Decoding and Encoding in Brain-Computer Interfaces.   The field of brain-computer interfaces is poised to advance from the\ntraditional goal of controlling prosthetic devices using brain signals to\ncombining neural decoding and encoding within a single neuroprosthetic device.\nSuch a device acts as a \"co-processor\" for the brain, with applications ranging\nfrom inducing Hebbian plasticity for rehabilitation after brain injury to\nreanimating paralyzed limbs and enhancing memory. We review recent progress in\nsimultaneous decoding and encoding for closed-loop control and plasticity\ninduction. To address the challenge of multi-channel decoding and encoding, we\nintroduce a unifying framework for developing brain co-processors based on\nartificial neural networks and deep learning. These \"neural co-processors\" can\nbe used to jointly optimize cost functions with the nervous system to achieve\ndesired behaviors ranging from targeted neuro-rehabilitation to augmentation of\nbrain function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Graphical Models Using Multiplicative Weights.   We give a simple, multiplicative-weight update algorithm for learning\nundirected graphical models or Markov random fields (MRFs). The approach is\nnew, and for the well-studied case of Ising models or Boltzmann machines, we\nobtain an algorithm that uses a nearly optimal number of samples and has\nquadratic running time (up to logarithmic factors), subsuming and improving on\nall prior work. Additionally, we give the first efficient algorithm for\nlearning Ising models over general alphabets.\nOur main application is an algorithm for learning the structure of t-wise\nMRFs with nearly-optimal sample complexity (up to polynomial losses in\nnecessary terms that depend on the weights) and running time that is\n$n^{O(t)}$. In addition, given $n^{O(t)}$ samples, we can also learn the\nparameters of the model and generate a hypothesis that is close in statistical\ndistance to the true MRF. All prior work runs in time $n^{\\Omega(d)}$ for\ngraphs of bounded degree d and does not generate a hypothesis close in\nstatistical distance even for t=3. We observe that our runtime has the correct\ndependence on n and t assuming the hardness of learning sparse parities with\nnoise.\nOur algorithm--the Sparsitron-- is easy to implement (has only one parameter)\nand holds in the on-line setting. Its analysis applies a regret bound from\nFreund and Schapire's classic Hedge algorithm. It also gives the first solution\nto the problem of learning sparse Generalized Linear Models (GLMs).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Angpow: a software for the fast computation of accurate tomographic power spectra.   The statistical distribution of galaxies is a powerful probe to constrain\ncosmological models and gravity. In particular the matter power spectrum $P(k)$\nbrings information about the cosmological distance evolution and the galaxy\nclustering together. However the building of $P(k)$ from galaxy catalogues\nneeds a cosmological model to convert angles on the sky and redshifts into\ndistances, which leads to difficulties when comparing data with predicted\n$P(k)$ from other cosmological models, and for photometric surveys like LSST.\nThe angular power spectrum $C_\\ell(z_1,z_2)$ between two bins located at\nredshift $z_1$ and $z_2$ contains the same information than the matter power\nspectrum, is free from any cosmological assumption, but the prediction of\n$C_\\ell(z_1,z_2)$ from $P(k)$ is a costly computation when performed exactly.\nThe Angpow software aims at computing quickly and accurately the auto\n($z_1=z_2$) and cross ($z_1 \\neq z_2$) angular power spectra between redshift\nbins. We describe the developed algorithm, based on developments on the\nChebyshev polynomial basis and on the Clenshaw-Curtis quadrature method. We\nvalidate the results with other codes, and benchmark the performance. Angpow is\nflexible and can handle any user defined power spectra, transfer functions, and\nredshift selection windows. The code is fast enough to be embedded inside\nprograms exploring large cosmological parameter spaces through the\n$C_\\ell(z_1,z_2)$ comparison with data. We emphasize that the Limber's\napproximation, often used to fasten the computation, gives wrong $C_\\ell$\nvalues for cross-correlations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Efficient SMC$^2$ schemes for stochastic kinetic models.   Fitting stochastic kinetic models represented by Markov jump processes within\nthe Bayesian paradigm is complicated by the intractability of the observed data\nlikelihood. There has therefore been considerable attention given to the design\nof pseudo-marginal Markov chain Monte Carlo algorithms for such models.\nHowever, these methods are typically computationally intensive, often require\ncareful tuning and must be restarted from scratch upon receipt of new\nobservations. Sequential Monte Carlo (SMC) methods on the other hand aim to\nefficiently reuse posterior samples at each time point. Despite their appeal,\napplying SMC schemes in scenarios with both dynamic states and static\nparameters is made difficult by the problem of particle degeneracy. A\nprincipled approach for overcoming this problem is to move each parameter\nparticle through a Metropolis-Hastings kernel that leaves the target invariant.\nThis rejuvenation step is key to a recently proposed SMC$^2$ algorithm, which\ncan be seen as the pseudo-marginal analogue of an idealised scheme known as\niterated batch importance sampling. Computing the parameter weights in SMC$^2$\nrequires running a particle filter over dynamic states to unbiasedly estimate\nthe intractable observed data likelihood contributions at each time point. In\nthis paper, we propose to use an auxiliary particle filter inside the SMC$^2$\nscheme. Our method uses two recently proposed constructs for sampling\nconditioned jump processes and we find that the resulting inference schemes\ntypically require fewer state particles than when using a simple bootstrap\nfilter. Using two applications, we compare the performance of the proposed\napproach with various competing methods, including two global MCMC schemes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Self-injective commutative rings have no nontrivial rigid ideals.   We establish a link between trace modules and rigidity in modules over\nNoetherian rings. Using the theory of trace ideals we make partial progress on\na question of Dao, and on the Auslander-Reiten conjecture over Artinian\nGorenstein rings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient and principled score estimation with Nyström kernel exponential families.   We propose a fast method with statistical guarantees for learning an\nexponential family density model where the natural parameter is in a\nreproducing kernel Hilbert space, and may be infinite-dimensional. The model is\nlearned by fitting the derivative of the log density, the score, thus avoiding\nthe need to compute a normalization constant. Our approach improves the\ncomputational efficiency of an earlier solution by using a low-rank,\nNyström-like solution. The new solution retains the consistency and\nconvergence rates of the full-rank solution (exactly in Fisher distance, and\nnearly in other distances), with guarantees on the degree of cost and storage\nreduction. We evaluate the method in experiments on density estimation and in\nthe construction of an adaptive Hamiltonian Monte Carlo sampler. Compared to an\nexisting score learning approach using a denoising autoencoder, our estimator\nis empirically more data-efficient when estimating the score, runs faster, and\nhas fewer parameters (which can be tuned in a principled and interpretable\nway), in addition to providing statistical guarantees.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "QCD-Aware Recursive Neural Networks for Jet Physics.   Recent progress in applying machine learning for jet physics has been built\nupon an analogy between calorimeters and images. In this work, we present a\nnovel class of recursive neural networks built instead upon an analogy between\nQCD and natural languages. In the analogy, four-momenta are like words and the\nclustering history of sequential recombination jet algorithms is like the\nparsing of a sentence. Our approach works directly with the four-momenta of a\nvariable-length set of particles, and the jet-based tree structure varies on an\nevent-by-event basis. Our experiments highlight the flexibility of our method\nfor building task-specific jet embeddings and show that recursive architectures\nare significantly more accurate and data efficient than previous image-based\nnetworks. We extend the analogy from individual jets (sentences) to full events\n(paragraphs), and show for the first time an event-level classifier operating\non all the stable particles produced in an LHC event.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "A multiplier inclusion theorem on product domains.   In this note it is shown that the class of all multipliers from the\n$d$-parameter Hardy space $H^1_{\\mathrm{prod}} (\\mathbb{T}^d)$ to $L^2\n(\\mathbb{T}^d)$ is properly contained in the class of all multipliers from $L\n\\log^{d/2} L (\\mathbb{T}^d)$ to $L^2(\\mathbb{T}^d)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Resonating Valence Bond Theory of Superconductivity: Beyond Cuprates.   Resonating valence bond (RVB) theory of high Tc superconductivity, an\nelectron correlation based mechanism, began as an insightful response by\nAnderson, to Bednorz and Muller's discovery of high Tc superconductivity in\ncuprates in late 1986. Shortly a theoretical framework for quantum spin liquids\nand superconductivity was developed. This theory adresses a formidable strong\ncoupling quantum manybody problem, in modern times. It is built on certain key\nexperimental facts: i) survival of a dynamical Mott localization in a metallic\nstate, ii) proliferation of bond singlets and iii) absence of fermi liquid\nquasi particles. After summarising RVB theory I will provide an aerial view of,\nmostly, new superconductors where I believe that, to a large degree RVB\nmechanism is at work and indicate prospects for even higher Tc's.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Accretion of Planetary Material onto Host Stars.   Accretion of planetary material onto host stars may occur throughout a star's\nlife. Especially prone to accretion, extrasolar planets in short-period orbits,\nwhile relatively rare, constitute a significant fraction of the known\npopulation, and these planets are subject to dynamical and atmospheric\ninfluences that can drive significant mass loss. Theoretical models frame\nexpectations regarding the rates and extent of this planetary accretion. For\ninstance, tidal interactions between planets and stars may drive complete\norbital decay during the main sequence. Many planets that survive their stars'\nmain sequence lifetime will still be engulfed when the host stars become red\ngiant stars. There is some observational evidence supporting these predictions,\nsuch as a dearth of close-in planets around fast stellar rotators, which is\nconsistent with tidal spin-up and planet accretion. There remains no clear\nchemical evidence for pollution of the atmospheres of main sequence or red\ngiant stars by planetary materials, but a wealth of evidence points to active\naccretion by white dwarfs. In this article, we review the current understanding\nof accretion of planetary material, from the pre- to the post-main sequence and\nbeyond. The review begins with the astrophysical framework for that process and\nthen considers accretion during various phases of a host star's life, during\nwhich the details of accretion vary, and the observational evidence for\naccretion during these phases.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hausdorff dimension, projections, intersections, and Besicovitch sets.   This is a survey on recent developments on the Hausdorff dimension of\nprojections and intersections for general subsets of Euclidean spaces, with an\nemphasis on estimates of the Hausdorff dimension of exceptional sets and on\nrestricted projection families. We shall also discuss relations between\nprojections and Hausdorff dimension of Besicovitch sets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pattern-forming fronts in a Swift-Hohenberg equation with directional quenching - parallel and oblique stripes.   We study the effect of domain growth on the orientation of striped phases in\na Swift-Hohenberg equation. Domain growth is encoded in a step-like parameter\ndependence that allows stripe formation in a half plane, and suppresses\npatterns in the complement, while the boundary of the pattern-forming region is\npropagating with fixed normal velocity. We construct front solutions that leave\nbehind stripes in the pattern-forming region that are parallel to or at a small\noblique angle to the boundary.\nTechnically, the construction of stripe formation parallel to the boundary\nrelies on ill-posed, infinite-dimensional spatial dynamics. Stripes forming at\na small oblique angle are constructed using a functional-analytic, perturbative\napproach. Here, the main difficulties are the presence of continuous spectrum\nand the fact that small oblique angles appear as a singular perturbation in a\ntraveling-wave problem. We resolve the former difficulty using a farfield-core\ndecomposition and Fredholm theory in weighted spaces. The singular perturbation\nproblem is resolved using preconditioners and boot-strapping.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Morgan type uncertainty principle and unique continuation properties for abstract Schrödinger equations.   In this paper, Morgan type uncertainty principle and unique continuation\nproperties of abstract Schrödinger equations with time dependent potentials\nin vector-valued classes are obtained. The equation involves a possible linear\noperators considered in the Hilbert spaces. So, by choosing the corresponding\nspaces H and operators we derived unique continuation properties for numerous\nclasses of Schrödinger type equations and its systems which occur in a wide\nvariety of physical systems",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Faster Bounding Box Annotation for Object Detection in Indoor Scenes.   This paper proposes an approach for rapid bounding box annotation for object\ndetection datasets. The procedure consists of two stages: The first step is to\nannotate a part of the dataset manually, and the second step proposes\nannotations for the remaining samples using a model trained with the first\nstage annotations. We experimentally study which first/second stage split\nminimizes to total workload. In addition, we introduce a new fully labeled\nobject detection dataset collected from indoor scenes. Compared to other indoor\ndatasets, our collection has more class categories, different backgrounds,\nlighting conditions, occlusion and high intra-class differences. We train deep\nlearning based object detectors with a number of state-of-the-art models and\ncompare them in terms of speed and accuracy. The fully annotated dataset is\nreleased freely available for the research community.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A/D Converter Architectures for Energy-Efficient Vision Processor.   AI applications have emerged in current world. Among AI applications,\ncomputer-vision (CV) related applications have attracted high interest.\nHardware implementation of CV processors necessitates a high performance but\nlow-power image detector. The key to energy-efficiency work lies in\nanalog-digital converting, where output of imaging detectors is transferred to\ndigital domain and CV algorithms can be performed on data. In this paper,\nanalog-digital converter architectures are compared, and an example ADC design\nis proposed which achieves both good performance and low power consumption.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A novel distribution-free hybrid regression model for manufacturing process efficiency improvement.   This work is motivated by a particular problem of a modern paper\nmanufacturing industry, in which maximum efficiency of the fiber-filler\nrecovery process is desired. A lot of unwanted materials along with valuable\nfibers and fillers come out as a by-product of the paper manufacturing process\nand mostly goes as waste. The job of an efficient Krofta supracell is to\nseparate the unwanted materials from the valuable ones so that fibers and\nfillers can be collected from the waste materials and reused in the\nmanufacturing process. The efficiency of Krofta depends on several crucial\nprocess parameters and monitoring them is a difficult proposition. To solve\nthis problem, we propose a novel hybridization of regression trees (RT) and\nartificial neural networks (ANN), hybrid RT-ANN model, to solve the problem of\nlow recovery percentage of the supracell. This model is used to achieve the\ngoal of improving supracell efficiency, viz., gain in percentage recovery. In\naddition, theoretical results for the universal consistency of the proposed\nmodel are given with the optimal value of a vital model parameter. Experimental\nfindings show that the proposed hybrid RT-ANN model achieves higher accuracy in\npredicting Krofta recovery percentage than other conventional regression models\nfor solving the Krofta efficiency problem. This work will help the paper\nmanufacturing company to become environmentally friendly with minimal\necological damage and improved waste recovery.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Assessing Excited State Energy Gaps with Time-Dependent Density Functional Theory on Ru(II) Complexes.   A set of density functionals coming from different rungs on Jacob's ladder\nare employed to evaluate the electronic excited states of three Ru(II)\ncomplexes. While most studies on the performance of density functionals compare\nthe vertical excitation energies, in this work we focus on the energy gaps\nbetween the electronic excited states, of the same and different multiplicity.\nExcited state energy gaps are important for example to determine radiationless\ntransition probabilities. Besides energies, a functional should deliver the\ncorrect state character and state ordering. Therefore, wavefunction overlaps\nare introduced to systematically evaluate the effect of different functionals\non the character of the excited states. As a reference, the energies and state\ncharacters from multi-state second-order perturbation theory complete active\nspace (MS-CASPT2) are used. In comparison to MS-CASPT2, it is found that while\nhybrid functionals provide better vertical excitation energies, pure\nfunctionals typically give more accurate excited state energy gaps. Pure\nfunctionals are also found to reproduce the state character and ordering in\ncloser agreement to MS-CASPT2 than the hybrid functionals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Approximation of Bandwidth for the Interactive Operation in Video on Demand System.   An interactive session of video-on-demand (VOD) streaming procedure deserves\nsmooth data transportation for the viewer, irrespective of their geographic\nlocation. To access the required video, bandwidth management during the video\nobjects transportation at any interactive session is a mandatory prerequisite.\nIt has been observed in the domain likes movie on demand, electronic\nencyclopedia, interactive games, and educational resources. The required data\nis imported from the distributed storage servers through the high speed\nbackbone network. This paper presents the viewer driven session based\nmulti-user model with respect to the overlay mesh network. In virtue of\nreality, the direct implication of this work elaborately shows the required\nbandwidth is a causal part in the video on demand system. The analytic model of\nsession based single viewer bandwidth requirement model presents the bandwidth\nrequirement for any interactive session like, pause, move slow, rewind, skip\nsome number of frames, or move fast with some constant number of frames. This\nwork presents the bandwidth requirement model for any interactive session that\nbrings the trade-off in data-transportation and storage costs for different\nsystem resources and also for the various system configurations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "GOLDRUSH. II. Clustering of Galaxies at $z\\sim 4-6$ Revealed with the Half-Million Dropouts Over the 100 deg$^2$ Area Corresponding to 1 Gpc$^3$.   We present clustering properties from 579,492 Lyman break galaxies (LBGs) at\nz~4-6 over the 100 deg^2 sky (corresponding to a 1.4 Gpc^3 volume) identified\nin early data of the Hyper Suprime-Cam (HSC) Subaru strategic program survey.\nWe derive angular correlation functions (ACFs) of the HSC LBGs with\nunprecedentedly high statistical accuracies at z~4-6, and compare them with the\nhalo occupation distribution (HOD) models. We clearly identify significant ACF\nexcesses in 10\"<$\\theta$<90\", the transition scale between 1- and 2-halo terms,\nsuggestive of the existence of the non-linear halo bias effect. Combining the\nHOD models and previous clustering measurements of faint LBGs at z~4-7, we\ninvestigate dark-matter halo mass (Mh) of the z~4-7 LBGs and its correlation\nwith various physical properties including the star-formation rate (SFR), the\nstellar-to-halo mass ratio (SHMR), and the dark matter accretion rate (dotMh)\nover a wide-mass range of Mh/M$_\\odot$=4x10^10-4x10^12. We find that the SHMR\nincreases from z~4 to 7 by a factor of ~4 at Mh~1x10^11 M$_\\odot$, while the\nSHMR shows no strong evolution in the similar redshift range at Mh~1x10^12\nM$_\\odot$. Interestingly, we identify a tight relation of SFR/dotMh-Mh showing\nno significant evolution beyond 0.15 dex in this wide-mass range over z~4-7.\nThis weak evolution suggests that the SFR/dotMh-Mh relation is a fundamental\nrelation in high-redshift galaxy formation whose star formation activities are\nregulated by the dark matter mass assembly. Assuming this fundamental relation,\nwe calculate the cosmic SFR densities (SFRDs) over z=0-10 (a.k.a. Madau-Lilly\nplot). The cosmic SFRD evolution based on the fundamental relation agrees with\nthe one obtained by observations, suggesting that the cosmic SFRD increase from\nz~10 to 4-2 (decrease from z~4-2 to 0) is mainly driven by the increase of the\nhalo abundance (the decrease of the accretion rate).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lipschitz continuity of quasiconformal mappings and of the solutions to second order elliptic PDE with respect to the distance ratio metric.   The main aim of this paper is to study the Lipschitz continuity of certain\n$(K, K')$-quasiconformal mappings with respect to the distance ratio metric,\nand the Lipschitz continuity of the solution of a quasilinear differential\nequation with respect to the distance ratio metric.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Holistic Clustering on Linked Data.   Link discovery is an active field of research to support data integration in\nthe Web of Data. Due to the huge size and number of available data sources,\nefficient and effective link discovery is a very challenging task. Common\npairwise link discovery approaches do not scale to many sources with very large\nentity sets. We here propose a distributed holistic approach to link many data\nsources based on a clustering of entities that represent the same real-world\nobject. Our clustering approach provides a compact and fused representation of\nentities, and can identify errors in existing links as well as many new links.\nWe support a distributed execution of the clustering approach to achieve faster\nexecution times and scalability for large real-world data sets. We provide a\nnovel gold standard for multi-source clustering, and evaluate our methods with\nrespect to effectiveness and efficiency for large data sets from the geographic\nand music domains.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fine-grained Event Learning of Human-Object Interaction with LSTM-CRF.   Event learning is one of the most important problems in AI. However,\nnotwithstanding significant research efforts, it is still a very complex task,\nespecially when the events involve the interaction of humans or agents with\nother objects, as it requires modeling human kinematics and object movements.\nThis study proposes a methodology for learning complex human-object interaction\n(HOI) events, involving the recording, annotation and classification of event\ninteractions. For annotation, we allow multiple interpretations of a motion\ncapture by slicing over its temporal span, for classification, we use\nLong-Short Term Memory (LSTM) sequential models with Conditional Randon Field\n(CRF) for constraints of outputs. Using a setup involving captures of\nhuman-object interaction as three dimensional inputs, we argue that this\napproach could be used for event types involving complex spatio-temporal\ndynamics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-Scale Continuous CRFs as Sequential Deep Networks for Monocular Depth Estimation.   This paper addresses the problem of depth estimation from a single still\nimage. Inspired by recent works on multi- scale convolutional neural networks\n(CNN), we propose a deep model which fuses complementary information derived\nfrom multiple CNN side outputs. Different from previous methods, the\nintegration is obtained by means of continuous Conditional Random Fields\n(CRFs). In particular, we propose two different variations, one based on a\ncascade of multiple CRFs, the other on a unified graphical model. By designing\na novel CNN implementation of mean-field updates for continuous CRFs, we show\nthat both proposed models can be regarded as sequential deep networks and that\ntraining can be performed end-to-end. Through extensive experimental evaluation\nwe demonstrate the effective- ness of the proposed approach and establish new\nstate of the art results on publicly available datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological Sieving of Rings According to their Rigidity.   We present a novel mechanism for resolving the mechanical rigidity of\nnanoscopic circular polymers that flow in a complex environment. The emergence\nof a regime of negative differential mobility induced by topological\ninteractions between the rings and the substrate is the key mechanism for\nselective sieving of circular polymers with distinct flexibilities. A simple\nmodel accurately describes the sieving process observed in molecular dynamics\nsimulations and yields experimentally verifiable analytical predictions, which\ncan be used as a reference guide for improving filtration procedures of\ncircular filaments. The topological sieving mechanism we propose ought to be\nrelevant also in probing the microscopic details of complex substrates.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Locally Repairable Codes with Multiple $(r_{i}, δ_{i})$-Localities.   In distributed storage systems, locally repairable codes (LRCs) are\nintroduced to realize low disk I/O and repair cost. In order to tolerate\nmultiple node failures, the LRCs with \\emph{$(r, \\delta)$-locality} are further\nproposed. Since hot data is not uncommon in a distributed storage system, both\nZeh \\emph{et al.} and Kadhe \\emph{et al.} focus on the LRCs with \\emph{multiple\nlocalities or unequal localities} (ML-LRCs) recently, which said that the\nlocalities among the code symbols can be different. ML-LRCs are attractive and\nuseful in reducing repair cost for hot data. In this paper, we generalize the\nML-LRCs to the $(r,\\delta)$-locality case of multiple node failures, and define\nan LRC with multiple $(r_{i}, \\delta_{i})_{i\\in [s]}$ localities ($s\\ge 2$),\nwhere $r_{1}\\leq r_{2}\\leq\\dots\\leq r_{s}$ and\n$\\delta_{1}\\geq\\delta_{2}\\geq\\dots\\geq\\delta_{s}\\geq2$. Such codes ensure that\nsome hot data could be repaired more quickly and have better failure-tolerance\nin certain cases because of relatively smaller $r_{i}$ and larger $\\delta_{i}$.\nThen, we derive a Singleton-like upper bound on the minimum distance for the\nproposed LRCs by employing the regenerating-set technique. Finally, we obtain a\nclass of explicit and structured constructions of optimal ML-LRCs, and further\nextend them to the cases of multiple $(r_{i}, \\delta)_{i\\in [s]}$ localities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Self-bound quantum droplets in atomic mixtures.   Self-bound quantum droplets are a newly discovered phase in the context of\nultracold atoms. In this work we report their experimental realization\nfollowing the original proposal by Petrov [Phys. Rev. Lett. 115, 155302\n(2015)], using an attractive bosonic mixture. In this system spherical droplets\nform due to the balance of competing attractive and repulsive forces, provided\nby the mean-field energy close to the collapse threshold and the first-order\ncorrection due to quantum fluctuations. Thanks to an optical levitating\npotential with negligible residual confinement we observe self-bound droplets\nin free space and we characterize the conditions for their formation as well as\ntheir equilibrium properties. This work sets the stage for future studies on\nquantum droplets, from the measurement of their peculiar excitation spectrum,\nto the exploration of their superfluid nature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Spreading of correlations in the Falicov-Kimball model.   We study dynamical properties of the one- and two-dimensional Falicov-Kimball\nmodel using lattice Monte Carlo simulations. In particular, we calculate the\nspreading of charge correlations in the equilibrium model and after an\ninteraction quench. The results show a reduction of the light-cone velocity\nwith interaction strength at low temperature, while the phase velocity\nincreases. At higher temperature, the initial spreading is determined by the\nFermi velocity of the noninteracting system and the maximum range of the\ncorrelations decreases with increasing interaction strength. Charge order\ncorrelations in the disorder potential enhance the range of the correlations.\nWe also use the numerically exact lattice Monte Carlo results to benchmark the\naccuracy of equilibrium and nonequilibrium dynamical cluster approximation\ncalculations. It is shown that the bias introduced by the mapping to a\nperiodized cluster is substantial, and that from a numerical point of view, it\nis more efficient to simulate the lattice model directly.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An open-source platform to study uniaxial stress effects on nanoscale devices.   We present an automatic measurement platform that enables the\ncharacterization of nanodevices by electrical transport and optical\nspectroscopy as a function of uniaxial stress. We provide insights into and\ndetailed descriptions of the mechanical device, the substrate design and\nfabrication, and the instrument control software, which is provided under\nopen-source license. The capability of the platform is demonstrated by\ncharacterizing the piezo-resistance of an InAs nanowire device using a\ncombination of electrical transport and Raman spectroscopy. The advantages of\nthis measurement platform are highlighted by comparison with state-of-the-art\npiezo-resistance measurements in InAs nanowires. We envision that the\nsystematic application of this methodology will provide new insights into the\nphysics of nanoscale devices and novel materials for electronics, and thus\ncontribute to the assessment of the potential of strain as a technology booster\nfor nanoscale electronics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Distributive Aronszajn trees.   Ben-David and Shelah proved that if $\\lambda$ is a singular strong-limit\ncardinal and $2^\\lambda=\\lambda^+$, then $\\square^*_\\lambda$ entails the\nexistence of a normal $\\lambda$-distributive $\\lambda^+$-Aronszajn tree. Here,\nit is proved that the same conclusion remains valid after replacing the\nhypothesis $\\square^*_\\lambda$ by $\\square(\\lambda^+,{<}\\lambda)$.\nAs $\\square(\\lambda^+,{<}\\lambda)$ does not impose a bound on the order-type\nof the witnessing clubs, our construction is necessarily different from that of\nBen-David and Shelah, and instead uses walks on ordinals augmented with club\nguessing.\nA major component of this work is the study of postprocessing functions and\ntheir effect on square sequences. A byproduct of this study is the finding that\nfor $\\kappa$ regular uncountable, $\\square(\\kappa)$ entails the existence of a\npartition of $\\kappa$ into $\\kappa$ many fat sets. When contrasted with a\nclassic model of Magidor, this shows that it is equiconsistent with the\nexistence of a weakly compact cardinal that $\\omega_2$ cannot be split into two\nfat sets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Continuous Learning in Single-Incremental-Task Scenarios.   It was recently shown that architectural, regularization and rehearsal\nstrategies can be used to train deep models sequentially on a number of\ndisjoint tasks without forgetting previously acquired knowledge. However, these\nstrategies are still unsatisfactory if the tasks are not disjoint but\nconstitute a single incremental task (e.g., class-incremental learning). In\nthis paper we point out the differences between multi-task and\nsingle-incremental-task scenarios and show that well-known approaches such as\nLWF, EWC and SI are not ideal for incremental task scenarios. A new approach,\ndenoted as AR1, combining architectural and regularization strategies is then\nspecifically proposed. AR1 overhead (in term of memory and computation) is very\nsmall thus making it suitable for online learning. When tested on CORe50 and\niCIFAR-100, AR1 outperformed existing regularization strategies by a good\nmargin.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On certain geometric properties in Banach spaces of vector-valued functions.   We consider a certain type of geometric properties of Banach spaces, which\nincludes for instance octahedrality, almost squareness, lushness and the\nDaugavet property. For this type of properties, we obtain a general reduction\ntheorem, which, roughly speaking, states the following: if the property in\nquestion is stable under certain finite absolute sums (for example finite\n$\\ell^p$-sums), then it is also stable under the formation of corresponding\nKöthe-Bochner spaces (for example $L^p$-Bochner spaces). From this general\ntheorem, we obtain as corollaries a number of new results as well as some\nalternative proofs of already known results concerning octahedral and almost\nsquare spaces and their relatives, diameter-two-properties, lush spaces and\nother classes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Maximum likelihood estimation of determinantal point processes.   Determinantal point processes (DPPs) have wide-ranging applications in\nmachine learning, where they are used to enforce the notion of diversity in\nsubset selection problems. Many estimators have been proposed, but surprisingly\nthe basic properties of the maximum likelihood estimator (MLE) have received\nlittle attention. The difficulty is that it is a non-concave maximization\nproblem, and such functions are notoriously difficult to understand in high\ndimensions, despite their importance in modern machine learning. Here we study\nboth the local and global geometry of the expected log-likelihood function. We\nprove several rates of convergence for the MLE and give a complete\ncharacterization of the case where these are parametric. We also exhibit a\npotential curse of dimensionality where the asymptotic variance of the MLE\nscales exponentially with the dimension of the problem. Moreover, we exhibit an\nexponential number of saddle points, and give evidence that these may be the\nonly critical points.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a Bootstrap approach to higher orders of epsilon expansion.   We employ a hybrid approach in determining the anomalous dimension and OPE\ncoefficient of higher spin operators in the Wilson-Fisher theory. First we do a\nlarge spin analysis for CFT data where we use results obtained from the usual\nand the Mellin Bootstrap and also from Feynman diagram literature. This gives\nnew predictions at $O(\\epsilon^4)$ and $O(\\epsilon^5)$ for anomalous dimensions\nand OPE coefficients, and also provides a cross-check for the results from\nMellin Bootstrap. These higher orders get contributions from all higher spin\noperators in the crossed channel. We also use the Bootstrap in Mellin space\nmethod for $\\phi^3$ in $d=6-\\epsilon$ CFT where we calculate general higher\nspin OPE data. We demonstrate a higher loop order calculation in this approach\nby summing over contributions from higher spin operators of the crossed channel\nin the same spirit as before.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Magnetic domains in thin ferromagnetic films with strong perpendicular anisotropy.   We investigate the scaling of the ground state energy and optimal domain\npatterns in thin ferromagnetic films with strong uniaxial anisotropy and the\neasy axis perpendicular to the film plane. Starting from the full\nthree-dimensional micromagnetic model, we identify the critical scaling where\nthe transition from single domain to multidomain ground states such as bubble\nor maze patterns occurs. Furthermore, we analyze the asymptotic behavior of the\nenergy in two regimes separated by a transition. In the single domain regime,\nthe energy $\\Gamma$-converges towards a much simpler two-dimensional and local\nmodel. In the second regime, we derive the scaling of the minimal energy and\ndeduce a scaling law for the typical domain size.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "New ADS Functionality for the Curator.   In this paper we provide an update concerning the operations of the NASA\nAstrophysics Data System (ADS), its services and user interface, and the\ncontent currently indexed in its database. As the primary information system\nused by researchers in Astronomy, the ADS aims to provide a comprehensive index\nof all scholarly resources appearing in the literature. With the current effort\nin our community to support data and software citations, we discuss what steps\nthe ADS is taking to provide the needed infrastructure in collaboration with\npublishers and data providers. A new API provides access to the ADS search\ninterface, metrics, and libraries allowing users to programmatically automate\ndiscovery and curation tasks. The new ADS interface supports a greater\nintegration of content and services with a variety of partners, including ORCID\nclaiming, indexing of SIMBAD objects, and article graphics from a variety of\npublishers. Finally, we highlight how librarians can facilitate the ingest of\ngray literature that they curate into our system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Active Bias: Training More Accurate Neural Networks by Emphasizing High Variance Samples.   Self-paced learning and hard example mining re-weight training instances to\nimprove learning accuracy. This paper presents two improved alternatives based\non lightweight estimates of sample uncertainty in stochastic gradient descent\n(SGD): the variance in predicted probability of the correct class across\niterations of mini-batch SGD, and the proximity of the correct class\nprobability to the decision threshold. Extensive experimental results on six\ndatasets show that our methods reliably improve accuracy in various network\narchitectures, including additional gains on top of other popular training\ntechniques, such as residual learning, momentum, ADAM, batch normalization,\ndropout, and distillation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Partial Knowledge In Embeddings.   Representing domain knowledge is crucial for any task. There has been a wide\nrange of techniques developed to represent this knowledge, from older logic\nbased approaches to the more recent deep learning based techniques (i.e.\nembeddings). In this paper, we discuss some of these methods, focusing on the\nrepresentational expressiveness tradeoffs that are often made. In particular,\nwe focus on the the ability of various techniques to encode `partial knowledge'\n- a key component of successful knowledge systems. We introduce and describe\nthe concepts of `ensembles of embeddings' and `aggregate embeddings' and\ndemonstrate how they allow for partial knowledge.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Off-diagonal asymptotic properties of Bergman kernels associated to analytic Kähler potentials.   We prove a new off-diagonal asymptotic of the Bergman kernels associated to\ntensor powers of a positive line bundle on a compact Kähler manifold. We show\nthat if the Kähler potential is real analytic, then the Bergman kernel\naccepts a complete asymptotic expansion in a neighborhood of the diagonal of\nshrinking size $k^{-\\frac14}$. These improve the earlier results in the subject\nfor smooth potentials, where an expansion exists in a $k^{-\\frac12}$\nneighborhood of the diagonal. We obtain our results by finding upper bounds of\nthe form $C^m m!^{2}$ for the Bergman coefficients $b_m(x, \\bar y)$, which is\nan interesting problem on its own. We find such upper bounds using the method\nof Berman-Berndtsson-Sjöstrand. We also show that sharpening these upper\nbounds would improve the rate of shrinking neighborhoods of the diagonal $x=y$\nin our results. In the special case of metrics with local constant holomorphic\nsectional curvatures, we obtain off-diagonal asymptotic in a fixed (as $k \\to\n\\infty$) neighborhood of the diagonal, which recovers a result of Berman [Ber]\n(see Remark 3.5 of [Ber] for higher dimensions). In this case, we also find an\nexplicit formula for the Bergman kernel mod $O(e^{-k \\delta} )$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Empirical Analysis of Vulnerabilities in Python Packages for Web Applications.   This paper examines software vulnerabilities in common Python packages used\nparticularly for web development. The empirical dataset is based on the PyPI\npackage repository and the so-called Safety DB used to track vulnerabilities in\nselected packages within the repository. The methodological approach builds on\na release-based time series analysis of the conditional probabilities for the\nreleases of the packages to be vulnerable. According to the results, many of\nthe Python vulnerabilities observed seem to be only modestly severe; input\nvalidation and cross-site scripting have been the most typical vulnerabilities.\nIn terms of the time series analysis based on the release histories, only the\nrecent past is observed to be relevant for statistical predictions; the\nclassical Markov property holds.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predictive Independence Testing, Predictive Conditional Independence Testing, and Predictive Graphical Modelling.   Testing (conditional) independence of multivariate random variables is a task\ncentral to statistical inference and modelling in general - though\nunfortunately one for which to date there does not exist a practicable\nworkflow. State-of-art workflows suffer from the need for heuristic or\nsubjective manual choices, high computational complexity, or strong parametric\nassumptions.\nWe address these problems by establishing a theoretical link between\nmultivariate/conditional independence testing, and model comparison in the\nmultivariate predictive modelling aka supervised learning task. This link\nallows advances in the extensively studied supervised learning workflow to be\ndirectly transferred to independence testing workflows - including automated\ntuning of machine learning type which addresses the need for a heuristic\nchoice, the ability to quantitatively trade-off computational demand with\naccuracy, and the modern black-box philosophy for checking and interfacing.\nAs a practical implementation of this link between the two workflows, we\npresent a python package 'pcit', which implements our novel multivariate and\nconditional independence tests, interfacing the supervised learning API of the\nscikit-learn package. Theory and package also allow for straightforward\nindependence test based learning of graphical model structure.\nWe empirically show that our proposed predictive independence test outperform\nor are on par to current practice, and the derived graphical model structure\nlearning algorithms asymptotically recover the 'true' graph. This paper, and\nthe 'pcit' package accompanying it, thus provide powerful, scalable,\ngeneralizable, and easy-to-use methods for multivariate and conditional\nindependence testing, as well as for graphical model structure learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Face centered cubic and hexagonal close packed skyrmion crystals in centro-symmetric magnets.   Skyrmions are disk-like objects that typically form triangular crystals in\ntwo dimensional systems. This situation is analogous to the so-called \"pancake\nvortices\" of quasi-two dimensional superconductors. The way in which skyrmion\ndisks or pancake skyrmions pile up in layered centro-symmetric materials is\ndictated by the inter-layer exchange. Unbiased Monte Carlo simulations and\nsimple stabilization arguments reveal face centered cubic and hexagonal close\npacked skyrmion crystals for different choices of the inter-layer exchange, in\naddition to the conventional triangular crystal of skyrmion lines. Moreover, an\ninhomogeneous current induces sliding motion of pancake skyrmions, indicating\nthat they behave as effective mesoscale particles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Distinct evolutions of Weyl fermion quasiparticles and Fermi arcs with bulk band topology in Weyl semimetals.   The Weyl semimetal phase is a recently discovered topological quantum state\nof matter characterized by the presence of topologically protected degeneracies\nnear the Fermi level. These degeneracies are the source of exotic phenomena,\nincluding the realization of chiral Weyl fermions as quasiparticles in the bulk\nand the formation of Fermi arc states on the surfaces. Here, we demonstrate\nthat these two key signatures show distinct evolutions with the bulk band\ntopology by performing angle-resolved photoemission spectroscopy, supported by\nfirst-principle calculations, on transition-metal monophosphides. While Weyl\nfermion quasiparticles exist only when the chemical potential is located\nbetween two saddle points of the Weyl cone features, the Fermi arc states\nextend in a larger energy scale and are robust across the bulk Lifshitz\ntransitions associated with the recombination of two non-trivial Fermi surfaces\nenclosing one Weyl point into a single trivial Fermi surface enclosing two Weyl\npoints of opposite chirality. Therefore, in some systems (e.g. NbP),\ntopological Fermi arc states are preserved even if Weyl fermion quasiparticles\nare absent in the bulk. Our findings not only provide insight into the\nrelationship between the exotic physical phenomena and the intrinsic bulk band\ntopology in Weyl semimetals, but also resolve the apparent puzzle of the\ndifferent magneto-transport properties observed in TaAs, TaP and NbP, where the\nFermi arc states are similar.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An improved high order finite difference method for non-conforming grid interfaces for the wave equation.   This paper presents an extension of a recently developed high order finite\ndifference method for the wave equation on a grid with non-conforming\ninterfaces. The stability proof of the existing methods relies on the\ninterpolation operators being norm-contracting, which is satisfied by the\nsecond and fourth order operators, but not by the sixth order operator. We\nconstruct new penalty terms to impose interface conditions such that the\nstability proof does not require the norm-contracting condition. As a\nconsequence, the sixth order accurate scheme is also provably stable. Numerical\nexperiments demonstrate the improved stability and accuracy property.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Incomplete Gauss sums modulo primes.   We obtain a new bound for incomplete Gauss sums modulo primes. Our argument\nfalls under the framework of Vinogradov's method which we use to reduce the\nproblem under consideration to bounding the number of solutions to two distinct\nsystems of congruences. The first is related to Vinogradov's mean value\ntheorem, although the second does not appear to have been considered before.\nOur bound improves on current results in the range $N\\ge\nq^{2k^{-1/2}+O(k^{-3/2})}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Mismeasure of Mergers: Revised Limits on Self-interacting Dark Matter in Merging Galaxy Clusters.   In an influential recent paper, Harvey et al (2015) derive an upper limit to\nthe self-interaction cross section of dark matter ($\\sigma_{\\rm DM} < 0.47$\ncm$^2$/g at 95\\% confidence) by averaging the dark matter-galaxy offsets in a\nsample of merging galaxy clusters. Using much more comprehensive data on the\nsame clusters, we identify several substantial errors in their offset\nmeasurements. Correcting these errors relaxes the upper limit on $\\sigma_{\\rm\nDM}$ to $\\lesssim 2$ cm$^2$/g, following the Harvey et al prescription for\nrelating offsets to cross sections in a simple solid body scattering model.\nFurthermore, many clusters in the sample violate the assumptions behind this\nprescription, so even this revised upper limit should be used with caution.\nAlthough this particular sample does not tightly constrain self-interacting\ndark matter models when analyzed this way, we discuss how merger ensembles may\nbe used more effectively in the future. We conclude that errors inherent in\nusing single-band imaging to identify mass and light peaks do not necessarily\naverage out in a sample of this size, particularly when a handful of\nsubstructures constitute a majority of the weight in the ensemble.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Quantum groups, Yang-Baxter maps and quasi-determinants.   For any quasi-triangular Hopf algebra, there exists the universal R-matrix,\nwhich satisfies the Yang-Baxter equation. It is known that the adjoint action\nof the universal R-matrix on the elements of the tensor square of the algebra\nconstitutes a quantum Yang-Baxter map, which satisfies the set-theoretic\nYang-Baxter equation. The map has a zero curvature representation among\nL-operators defined as images of the universal R-matrix. We find that the zero\ncurvature representation can be solved by the Gauss decomposition of a product\nof L-operators. Thereby obtained a quasi-determinant expression of the quantum\nYang-Baxter map associated with the quantum algebra $U_{q}(gl(n))$. Moreover,\nthe map is identified with products of quasi-Plücker coordinates over a\nmatrix composed of the L-operators. We also consider the quasi-classical limit,\nwhere the underlying quantum algebra reduces to a Poisson algebra. The\nquasi-determinant expression of the quantum Yang-Baxter map reduces to ratios\nof determinants, which give a new expression of a classical Yang-Baxter map.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Ultra-Fast Reactive Transport Simulations When Chemical Reactions Meet Machine Learning: Chemical Equilibrium.   During reactive transport modeling, the computational cost associated with\nchemical reaction calculations is often 10-100 times higher than that of\ntransport calculations. Most of these costs results from chemical equilibrium\ncalculations that are performed at least once in every mesh cell and at every\ntime step of the simulation. Calculating chemical equilibrium is an iterative\nprocess, where each iteration is in general so computationally expensive that\neven if every calculation converged in a single iteration, the resulting\nspeedup would not be significant. Thus, rather than proposing a fast-converging\nnumerical method for solving chemical equilibrium equations, we present a\nmachine learning method that enables new equilibrium states to be quickly and\naccurately estimated, whenever a previous equilibrium calculation with similar\ninput conditions has been performed. We demonstrate the use of this smart\nchemical equilibrium method in a reactive transport modeling example and show\nthat, even at early simulation times, the majority of all equilibrium\ncalculations are quickly predicted and, after some time steps, the\nmachine-learning-accelerated chemical solver has been fully trained to rapidly\nperform all subsequent equilibrium calculations, resulting in speedups of\nalmost two orders of magnitude. We remark that our new on-demand machine\nlearning method can be applied to any case in which a massive number of\nsequential/parallel evaluations of a computationally expensive function $f$\nneeds to be done, $y=f(x)$. We remark, that, in contrast to traditional machine\nlearning algorithms, our on-demand training approach does not require a\nstatistics-based training phase before the actual simulation of interest\ncommences. The introduced on-demand training scheme requires, however, the\nfirst-order derivatives $\\partial f/\\partial x$ for later smart predictions.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Discrete CMC surfaces in R^3 and discrete minimal surfaces in S^3. A discrete Lawson correspondence.   The main result of this paper is a discrete Lawson correspondence between\ndiscrete CMC surfaces in R^3 and discrete minimal surfaces in S^3. This is a\ncorrespondence between two discrete isothermic surfaces. We show that this\ncorrespondence is an isometry in the following sense: it preserves the metric\ncoefficients introduced previously by Bobenko and Suris for isothermic nets.\nExactly as in the smooth case, this is a correspondence between nets with the\nsame Lax matrices, and the immersion formulas also coincide with the smooth\ncase.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Merging fragments of classical logic.   We investigate the possibility of extending the non-functionally complete\nlogic of a collection of Boolean connectives by the addition of further Boolean\nconnectives that make the resulting set of connectives functionally complete.\nMore precisely, we will be interested in checking whether an axiomatization for\nClassical Propositional Logic may be produced by merging Hilbert-style calculi\nfor two disjoint incomplete fragments of it. We will prove that the answer to\nthat problem is a negative one, unless one of the components includes only\ntop-like connectives.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum gauge symmetry of reducible gauge theory.   We derive the gaugeon formalism of the Kalb-Ramond field theory, a reducible\ngauge theory, which discusses the quantum gauge freedom. In gaugeon formalism,\ntheory admits quantum gauge symmetry which leaves the action form-invariant.\nThe BRST symmetric gaugeon formalism is also studied which introduces the\ngaugeon ghost fields and gaugeon ghosts of ghosts fields. To replace the\nYokoyama subsidiary conditions by a single Kugo-Ojima type condition the virtue\nof BRST symmetry is utilized. Under generalized BRST transformations, we show\nthat the gaugeon fields appear naturally in the reducible gauge theory.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Gradient descent GAN optimization is locally stable.   Despite the growing prominence of generative adversarial networks (GANs),\noptimization in GANs is still a poorly understood topic. In this paper, we\nanalyze the \"gradient descent\" form of GAN optimization i.e., the natural\nsetting where we simultaneously take small gradient steps in both generator and\ndiscriminator parameters. We show that even though GAN optimization does not\ncorrespond to a convex-concave game (even for simple parameterizations), under\nproper conditions, equilibrium points of this optimization procedure are still\n\\emph{locally asymptotically stable} for the traditional GAN formulation. On\nthe other hand, we show that the recently proposed Wasserstein GAN can have\nnon-convergent limit cycles near equilibrium. Motivated by this stability\nanalysis, we propose an additional regularization term for gradient descent GAN\nupdates, which \\emph{is} able to guarantee local stability for both the WGAN\nand the traditional GAN, and also shows practical promise in speeding up\nconvergence and addressing mode collapse.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "JointGAN: Multi-Domain Joint Distribution Learning with Generative Adversarial Nets.   A new generative adversarial network is developed for joint distribution\nmatching. Distinct from most existing approaches, that only learn conditional\ndistributions, the proposed model aims to learn a joint distribution of\nmultiple random variables (domains). This is achieved by learning to sample\nfrom conditional distributions between the domains, while simultaneously\nlearning to sample from the marginals of each individual domain. The proposed\nframework consists of multiple generators and a single softmax-based critic,\nall jointly trained via adversarial learning. From a simple noise source, the\nproposed framework allows synthesis of draws from the marginals, conditional\ndraws given observations from a subset of random variables, or complete draws\nfrom the full joint distribution. Most examples considered are for joint\nanalysis of two domains, with examples for three domains also presented.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Applied Knowledge Framework to Study Complex Systems.   The complexity of knowledge production on complex systems is well-known, but\nthere still lacks knowledge framework that would both account for a certain\nstructure of knowledge production at an epistemological level and be directly\napplicable to the study and management of complex systems. We set a basis for\nsuch a framework, by first analyzing in detail a case study of the construction\nof a geographical theory of complex territorial systems, through mixed methods,\nnamely qualitative interview analysis and quantitative citation network\nanalysis. We can therethrough inductively build a framework that considers\nknowledge entreprises as perspectives, with co-evolving components within\ncomplementary knowledge domains. We finally discuss potential applications and\ndevelopments.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Electronic structure of transferred graphene/h-BN van der Waals heterostructures with nonzero stacking angles by nano-ARPES.   In van der Waals heterostructures, the periodic potential from the Moiré\nsuperlattice can be used as a control knob to modulate the electronic structure\nof the constituent materials. Here we present a nanoscale angle-resolved\nphotoemission spectroscopy (Nano-ARPES) study of transferred graphene/h-BN\nheterostructures with two different stacking angles of 2.4° and 4.3°\nrespectively. Our measurements reveal six replicas of graphene Dirac cones at\nthe superlattice Brillouin zone (SBZ) centers. The size of the SBZ and its\nrelative rotation angle to the graphene BZ are in good agreement with Moiré\nsuperlattice period extracted from atomic force microscopy (AFM) measurements.\nComparison to epitaxial graphene/h-BN with 0° stacking angles suggests\nthat the interaction between graphene and h-BN decreases with increasing\nstacking angle.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Axiomatizing Epistemic Logic of Friendship via Tree Sequent Calculus.   This paper positively solves an open problem if it is possible to provide a\nHilbert system to Epistemic Logic of Friendship (EFL) by Seligman, Girard and\nLiu. To find a Hilbert system, we first introduce a sound, complete and\ncut-free tree (or nested) sequent calculus for EFL, which is an integrated\ncombination of Seligman's sequent calculus for basic hybrid logic and a tree\nsequent calculus for modal logic. Then we translate a tree sequent into an\nordinary formula to specify a Hilbert system of EFL and finally show that our\nHilbert system is sound and complete for the intended two-dimensional\nsemantics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fan-type spin structure in uni-axial chiral magnets.   We investigate the spin structure of a uni-axial chiral magnet near the\ntransition temperatures in low fields perpendicular to the helical axis. We\nfind a fan-type modulation structure where the clockwise and counterclockwise\nwindings appear alternatively along the propagation direction of the modulation\nstructure. This structure is often realized in a Yoshimori-type (non-chiral)\nhelimagnet but it is rarely realized in a chiral helimagnet. To discuss\nunderlying physics of this structure, we reconsider the phase diagram (phase\nboundary and crossover lines) through the free energy and asymptotic behaviors\nof isolated solitons. The fan structure appears slightly below the phase\nboundary of the continuous transition of instability-type. In this region,\nthere are no solutions containing any types of isolated solitons to the mean\nfield equations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Biocompatible Writing of Data into DNA.   A simple DNA-based data storage scheme is demonstrated in which information\nis written using \"addressing\" oligonucleotides. In contrast to other methods\nthat allow arbitrary code to be stored, the resulting DNA is suitable for\ndownstream enzymatic and biological processing. This capability is crucial for\nDNA computers, and may allow for a diverse array of computational operations to\nbe carried out using this DNA. Although here we use gel-based methods for\ninformation readout, we also propose more advanced methods involving\nprotein/DNA complexes and atomic force microscopy/nano-pore schemes for data\nreadout.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Community structure detection and evaluation during the pre- and post-ictal hippocampal depth recordings.   Detecting and evaluating regions of brain under various circumstances is one\nof the most interesting topics in computational neuroscience. However, the\nmajority of the studies on detecting communities of a functional connectivity\nnetwork of the brain is done on networks obtained from coherency attributes,\nand not from correlation. This lack of studies, in part, is due to the fact\nthat many common methods for clustering graphs require the nodes of the network\nto be `positively' linked together, a property that is guaranteed by a\ncoherency matrix, by definition. However, correlation matrices reveal more\ninformation regarding how each pair of nodes are linked together. In this\nstudy, for the first time we simultaneously examine four inherently different\nnetwork clustering methods (spectral, heuristic, and optimization methods)\napplied to the functional connectivity networks of the CA1 region of the\nhippocampus of an anaesthetized rat during pre-ictal and post-ictal states. The\nnetworks are obtained from correlation matrices, and its results are compared\nwith the ones obtained by applying the same methods to coherency matrices. The\ncorrelation matrices show a much finer community structure compared to the\ncoherency matrices. Furthermore, we examine the potential smoothing effect of\nchoosing various window sizes for computing the correlation/coherency matrices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accurate, Efficient and Scalable Graph Embedding.   The Graph Convolutional Network (GCN) model and its variants are powerful\ngraph embedding tools for facilitating classification and clustering on graphs.\nHowever, a major challenge is to reduce the complexity of layered GCNs and make\nthem parallelizable and scalable on very large graphs --- state-of the art\ntechniques are unable to achieve scalability without losing accuracy and\nefficiency. In this paper, we propose novel parallelization techniques for\ngraph sampling-based GCNs that achieve superior scalable performance on very\nlarge graphs without compromising accuracy. Specifically, our GCN guarantees\nwork-efficient training and produces order of magnitude savings in computation\nand communication. To scale GCN training on tightly-coupled shared memory\nsystems, we develop parallelization strategies for the key steps in training:\nFor the graph sampling step, we exploit parallelism within and across multiple\nsampling instances, and devise an efficient data structure for concurrent\naccesses that provides theoretical guarantee of near-linear speedup with number\nof processing units. For the feature propagation step within the sampled graph,\nwe improve cache utilization and reduce DRAM communication by data\npartitioning. We prove that our partitioning strategy is a 2-approximation for\nminimizing the communication time compared to the optimal strategy. We\ndemonstrate that our parallel graph embedding outperforms state-of-the-art\nmethods in scalability (with respect to number of processors, graph size and\nGCN model size), efficiency and accuracy on several large datasets. On a\n40-core Xeon platform, our parallel training achieves 64$\\times$ speedup (with\nAVX) in the sampling step and 25$\\times$ speedup in the feature propagation\nstep, compared to the serial implementation, resulting in a net speedup of\n21$\\times$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "New constraints on the millimetre emission of six debris disks.   The presence of dusty debris around main sequence stars denotes the existence\nof planetary systems. Such debris disks are often identified by the presence of\nexcess continuum emission at infrared and (sub-)millimetre wavelengths, with\nmeasurements at longer wavelengths tracing larger and cooler dust grains. The\nexponent of the slope of the disk emission at sub-millimetre wavelengths, `q',\ndefines the size distribution of dust grains in the disk. This size\ndistribution is a function of the rigid strength of the dust producing parent\nplanetesimals. As part of the survey `PLAnetesimals around TYpical Pre-main\nseqUence Stars' (PLATYPUS) we observed six debris disks at 9-mm using the\nAustralian Telescope Compact Array. We obtain marginal (~3-\\sigma) detections\nof three targets: HD 105, HD 61005, and HD 131835. Upper limits for the three\nremaining disks, HD20807, HD109573, and HD109085, provide further constraint of\nthe (sub-)millimetre slope of their spectral energy distributions. The values\nof q (or their limits) derived from our observations are all smaller than the\noft-assumed steady state collisional cascade model (q = 3.5), but lie well\nwithin the theoretically expected range for debris disks q ~ 3 to 4. The\nmeasured q values for our targets are all < 3.3, consistent with both\ncollisional modelling results and theoretical predictions for parent\nplanetesimal bodies being `rubble piles' held together loosely by their\nself-gravity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Elliptic operators on refined Sobolev scales on vector bundles.   We introduce a refined Sobolev scale on a vector bundle over a closed\ninfinitely smooth manifold. This scale consists of inner product Hörmander\nspaces parametrized with a real number and a function varying slowly at\ninfinity in the sense of Karamata. We prove that these spaces are obtained by\nthe interpolation with a function parameter between inner product Sobolev\nspaces. An arbitrary classical elliptic pseudodifferential operator acting\nbetween vector bundles of the same rank is investigated on this scale. We prove\nthat this operator is bounded and Fredholm on pairs of appropriate Hörmander\nspaces. We also prove that the solutions to the corresponding elliptic equation\nsatisfy a certain a priori estimate on these spaces. The local regularity of\nthese solutions is investigated on the refined Sobolev scale. We find new\nsufficient conditions for the solutions to have continuous derivatives of a\ngiven order.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Selected topics on Toric Varieties.   This article is based on a series of lectures on toric varieties given at\nRIMS, Kyoto. We start by introducing toric varieties, their basic properties\nand later pass to more advanced topics relating mostly to combinatorics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "New descriptions of the weighted Reed-Muller codes and the homogeneous Reed-Muller codes.   We give a description of the weighted Reed-Muller codes over a prime field in\na modular algebra. A description of the homogeneous Reed-Muller codes in the\nsame ambient space is presented for the binary case. A decoding procedure using\nthe Landrock-Manz method is developed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analysing the Potential of BLE to Support Dynamic Broadcasting Scenarios.   In this paper, we present a novel approach for broadcasting information based\non a Bluetooth Low Energy (BLE) ibeacon technology. We propose a dynamic method\nthat uses a combination of Wi-Fi and BLE technology where every technology\nplays a part in a user discovery and broadcasting process. In such system, a\nspecific ibeacon device broadcasts the information when a user is in proximity.\nUsing experiments, we conduct a scenario where the system discovers users,\ndisseminates information, and later we use collected data to examine the system\nperformance and capability. The results show that our proposed approach has a\npromising potential to become a powerful tool in the discovery and broadcasting\nconcept that can be easily implemented and used in business environments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Journal of Open Source Software (JOSS): design and first-year review.   This article describes the motivation, design, and progress of the Journal of\nOpen Source Software (JOSS). JOSS is a free and open-access journal that\npublishes articles describing research software. It has the dual goals of\nimproving the quality of the software submitted and providing a mechanism for\nresearch software developers to receive credit. While designed to work within\nthe current merit system of science, JOSS addresses the dearth of rewards for\nkey contributions to science made in the form of software. JOSS publishes\narticles that encapsulate scholarship contained in the software itself, and its\nrigorous peer review targets the software components: functionality,\ndocumentation, tests, continuous integration, and the license. A JOSS article\ncontains an abstract describing the purpose and functionality of the software,\nreferences, and a link to the software archive. The article is the entry point\nof a JOSS submission, which encompasses the full set of software artifacts.\nSubmission and review proceed in the open, on GitHub. Editors, reviewers, and\nauthors work collaboratively and openly. Unlike other journals, JOSS does not\nreject articles requiring major revision; while not yet accepted, articles\nremain visible and under review until the authors make adequate changes (or\nwithdraw, if unable to meet requirements). Once an article is accepted, JOSS\ngives it a DOI, deposits its metadata in Crossref, and the article can begin\ncollecting citations on indexers like Google Scholar and other services.\nAuthors retain copyright of their JOSS article, releasing it under a Creative\nCommons Attribution 4.0 International License. In its first year, starting in\nMay 2016, JOSS published 111 articles, with more than 40 additional articles\nunder review. JOSS is a sponsored project of the nonprofit organization\nNumFOCUS and is an affiliate of the Open Source Initiative.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Visualizing Time-Varying Particle Flows with Diffusion Geometry.   The tasks of identifying separation structures and clusters in flow data are\nfundamental to flow visualization. Significant work has been devoted to these\ntasks in flow represented by vector fields, but there are unique challenges in\naddressing these tasks for time-varying particle data. The unstructured nature\nof particle data, nonuniform and sparse sampling, and the inability to access\narbitrary particles in space-time make it difficult to define separation and\nclustering for particle data. We observe that weaker notions of separation and\nclustering through continuous measures of these structures are meaningful when\ncoupled with user exploration. We achieve this goal by defining a measure of\nparticle similarity between pairs of particles. More specifically, separation\noccurs when spatially-localized particles are dissimilar, while clustering is\ncharacterized by sets of particles that are similar to one another. To be\nrobust to imperfections in sampling we use diffusion geometry to compute\nparticle similarity. Diffusion geometry is parameterized by a scale that allows\na user to explore separation and clustering in a continuous manner. We\nillustrate the benefits of our technique on a variety of 2D and 3D flow\ndatasets, from particles integrated in fluid simulations based on time-varying\nvector fields, to particle-based simulations in astrophysics.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Are theoretical results 'Results'?.   Yes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "High-transmissivity Silicon Visible-wavelength Metasurface Designs based on Truncated-cone Nanoantennae.   High-transmissivity all-dielectric metasurfaces have recently attracted\nattention towards the realization of ultra-compact optical devices and systems.\nSilicon based metasurfaces, in particular, are highly promising considering the\npossibility of monolithic integration with VLSI circuits. Realization of\nsilicon based metasurfaces operational in the visible wavelengths remains a\nchallenge. A numerical study of silicon metasurfaces based on stepped truncated\ncone shaped nanoantenna elements is presented. Metasurfaces based on the\nstepped conical geometry can be designed for operation in the 700nm to 800nm\nwavelength window and achieve full cycle phase response (0 to pi with an\nimproved transmittance in comparison with previously reported cylindrical\ngeometry [1]. A systematic parameter study of the influence of various\ngeometrical parameters on the achievable amplitude and phase coverage is\nreported.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On topological cyclic homology.   Topological cyclic homology is a refinement of Connes--Tsygan's cyclic\nhomology which was introduced by Bökstedt--Hsiang--Madsen in 1993 as an\napproximation to algebraic $K$-theory. There is a trace map from algebraic\n$K$-theory to topological cyclic homology, and a theorem of\nDundas--Goodwillie--McCarthy asserts that this induces an equivalence of\nrelative theories for nilpotent immersions, which gives a way for computing\n$K$-theory in various situations. The construction of topological cyclic\nhomology is based on genuine equivariant homotopy theory, the use of explicit\npoint-set models, and the elaborate notion of a cyclotomic spectrum.\nThe goal of this paper is to revisit this theory using only\nhomotopy-invariant notions. In particular, we give a new construction of\ntopological cyclic homology. This is based on a new definition of the\n$\\infty$-category of cyclotomic spectra: We define a cyclotomic spectrum to be\na spectrum $X$ with $S^1$-action (in the most naive sense) together with\n$S^1$-equivariant maps $\\varphi_p: X\\to X^{tC_p}$ for all primes $p$. Here\n$X^{tC_p}=\\mathrm{cofib}(\\mathrm{Nm}: X_{hC_p}\\to X^{hC_p})$ is the Tate\nconstruction. On bounded below spectra, we prove that this agrees with previous\ndefinitions. As a consequence, we obtain a new and simple formula for\ntopological cyclic homology.\nIn order to construct the maps $\\varphi_p: X\\to X^{tC_p}$ in the example of\ntopological Hochschild homology we introduce and study Tate diagonals for\nspectra and Frobenius homomorphisms of commutative ring spectra. In particular\nwe prove a version of the Segal conjecture for the Tate diagonals and relate\nthese Frobenius homomorphisms to power operations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast Snapshottable Concurrent Braun Heaps.   This paper proposes a new concurrent heap algorithm, based on a stateless\nshape property, which efficiently maintains balance during insert and removeMin\noperations implemented with hand-over-hand locking. It also provides a O(1)\nlinearizable snapshot operation based on lazy copy-on-write semantics. Such\nsnapshots can be used to provide consistent views of the heap during iteration,\nas well as to make speculative updates (which can later be dropped).\nThe simplicity of the algorithm allows it to be easily proven correct, and\nthe choice of shape property provides priority queue performance which is\ncompetitive with highly optimized skiplist implementations (and has stronger\nbounds on worst-case time complexity).\nA Scala reference implementation is provided.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Trading the Twitter Sentiment with Reinforcement Learning.   This paper is to explore the possibility to use alternative data and\nartificial intelligence techniques to trade stocks. The efficacy of the daily\nTwitter sentiment on predicting the stock return is examined using machine\nlearning methods. Reinforcement learning(Q-learning) is applied to generate the\noptimal trading policy based on the sentiment signal. The predicting power of\nthe sentiment signal is more significant if the stock price is driven by the\nexpectation of the company growth and when the company has a major event that\ndraws the public attention. The optimal trading strategy based on reinforcement\nlearning outperforms the trading strategy based on the machine learning\nprediction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Liouville theorem for the Euler equations in the plane.   This paper is concerned with qualitative properties of bounded steady flows\nof an ideal incompressible fluid with no stagnation point in the\ntwo-dimensional plane R^2. We show that any such flow is a shear flow, that is,\nit is parallel to some constant vector. The proof of this Liouville-type result\nis firstly based on the study of the geometric properties of the level curves\nof the stream function and secondly on the derivation of some estimates on the\nat most logarithmic growth of the argument of the flow. These estimates lead to\nthe conclusion that the streamlines of the flow are all parallel lines.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "An Empirical Bayes Approach to Regularization Using Previously Published Models.   This manuscript proposes a novel empirical Bayes technique for regularizing\nregression coefficients in predictive models. When predictions from a\npreviously published model are available, this empirical Bayes method provides\na natural mathematical framework for shrinking coefficients toward the\nestimates implied by the body of existing research rather than the shrinkage\ntoward zero provided by traditional L1 and L2 penalization schemes. The method\nis applied to two different prediction problems. The first involves the\nconstruction of a model for predicting whether a single nucleotide polymorphism\n(SNP) of the KCNQ1 gene will result in dysfunction of the corresponding voltage\ngated ion channel. The second involves the prediction of preoperative serum\ncreatinine change in patients undergoing cardiac surgery.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Differentially Private ANOVA Testing.   Modern society generates an incredible amount of data about individuals, and\nreleasing summary statistics about this data in a manner that provably protects\nindividual privacy would offer a valuable resource for researchers in many\nfields. We present the first algorithm for analysis of variance (ANOVA) that\npreserves differential privacy, allowing this important statistical test to be\nconducted (and the results released) on databases of sensitive information. In\naddition to our private algorithm for the F test statistic, we show a rigorous\nway to compute p-values that accounts for the added noise needed to preserve\nprivacy. Finally, we present experimental results quantifying the statistical\npower of this differentially private version of the test, finding that a sample\nof several thousand observations is frequently enough to detect variation\nbetween groups. The differentially private ANOVA algorithm is a promising\napproach for releasing a common test statistic that is valuable in fields in\nthe sciences and social sciences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The application of Monte Carlo methods for learning generalized linear model.   Monte Carlo method is a broad class of computational algorithms that rely on\nrepeated random sampling to obtain numerical results. They are often used in\nphysical and mathematical problems and are most useful when it is difficult or\nimpossible to use other mathematical methods. Basically, many statisticians\nhave been increasingly drawn to Monte Carlo method in three distinct problem\nclasses: optimization, numerical integration, and generating draws from a\nprobability distribution. In this paper, we will introduce the Monte Carlo\nmethod for calculating coefficients in Generalized Linear Model(GLM),\nespecially for Logistic Regression. Our main methods are Metropolis\nHastings(MH) Algorithms and Stochastic Approximation in Monte Carlo\nComputation(SAMC). For comparison, we also get results automatically using MLE\nmethod in R software.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detecting laws in power subgroups.   A group law is said to be detectable in power subgroups if, for all coprime\n$m$ and $n$, a group $G$ satisfies the law if and only if the power subgroups\n$G^m$ and $G^n$ both satisfy the law. We prove that for all positive integers\n$c$, nilpotency of class at most $c$ is detectable in power subgroups, as is\nthe $k$-Engel law for $k$ at most 4. In contrast, detectability in power\nsubgroups fails for solvability of given derived length: we construct a finite\ngroup $W$ such that $W^2$ and $W^3$ are metabelian but $W$ has derived length\n$3$. We analyse the complexity of the detectability of commutativity in power\nsubgroups, in terms of finite presentations that encode a proof of the result.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mitigating Confirmation Bias on Twitter by Recommending Opposing Views.   In this work, we propose a content-based recommendation approach to increase\nexposure to opposing beliefs and opinions. Our aim is to help provide users\nwith more diverse viewpoints on issues, which are discussed in partisan groups\nfrom different perspectives. Since due to the backfire effect, people's\noriginal beliefs tend to strengthen when challenged with counter evidence, we\nneed to expose them to opposing viewpoints at the right time. The preliminary\nwork presented here describes our first step into this direction. As\nillustrative showcase, we take the political debate on Twitter around the\npresidency of Donald Trump.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Distance Between Filtered Spaces Via Tripods.   We present a simplified treatment of stability of filtrations on finite\nspaces. Interestingly, we can lift the stability result for combinatorial\nfiltrations from [CSEM06] to the case when two filtrations live on different\nspaces without directly invoking the concept of interleaving. We then prove\nthat this distance is intrinsic by constructing explicit geodesics between any\npair of filtered spaces. Finally we use this construction to obtain a\nstrengthening of the stability result.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fitch-Style Modal Lambda Calculi.   Fitch-style modal deduction, in which modalities are eliminated by opening a\nsubordinate proof, and introduced by shutting one, were investigated in the\n1990s as a basis for lambda calculi. We show that such calculi have good\ncomputational properties for a variety of intuitionistic modal logics.\nSemantics are given in cartesian closed categories equipped with an adjunction\nof endofunctors, with the necessity modality interpreted by the right adjoint.\nWhere this functor is an idempotent comonad, a coherence result on the\nsemantics allows us to present a calculus for intuitionistic S4 that is simpler\nthan others in the literature. We show the calculi can be extended à la\ntense logic with the left adjoint of necessity, and are then complete for the\ncategorical semantics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "CoAP over ICN.   The Constrained Application Protocol (CoAP) is a specialized Web transfer\nprotocol for resource-oriented applications intended to run on constrained\ndevices, typically part of the Internet of Things. In this paper we leverage\nInformation-Centric Networking (ICN), deployed within the domain of a network\nprovider that interconnects, in addition to other terminals, CoAP endpoints in\norder to provide enhanced CoAP services. We present various CoAP-specific\ncommunication scenarios and discuss how ICN can provide benefits to both\nnetwork providers and CoAP applications, even though the latter are not aware\nof the existence of ICN. In particular, the use of ICN results in smaller state\nmanagement complexity at CoAP endpoints, simpler implementation at CoAP\nendpoints, and less communication overhead in the network.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gaussian Processes for HRF estimation for BOLD fMRI.   We present a non-parametric joint estimation method for fMRI task activation\nvalues and the hemodynamic response function (HRF). The HRF is modeled as a\nGaussian process, making continuous evaluation possible for jittered paradigms\nand providing a variance estimate at each point.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pinned, locked, pushed, and pulled traveling waves in structured environments.   Traveling fronts describe the transition between two alternative states in a\ngreat number of physical and biological systems. Examples include the spread of\nbeneficial mutations, chemical reactions, and the invasions by foreign species.\nIn homogeneous environments, the alternative states are separated by a smooth\nfront moving at a constant velocity. This simple picture can break down in\nstructured environments such as tissues, patchy landscapes, and microfluidic\ndevices. Habitat fragmentation can pin the front at a particular location or\nlock invasion velocities into specific values. Locked velocities are not\nsensitive to moderate changes in dispersal or growth and are determined by the\nspatial and temporal periodicity of the environment. The synchronization with\nthe environment results in discontinuous fronts that propagate as periodic\npulses. We characterize the transition from continuous to locked invasions and\nshow that it is controlled by positive density-dependence in dispersal or\ngrowth. We also demonstrate that velocity locking is robust to demographic and\nenvironmental fluctuations and examine stochastic dynamics and evolution in\nlocked invasions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Practical Integer-to-Binary Mapping for Quantum Annealers.   Recent advancements in quantum annealing hardware and numerous studies in\nthis area suggests that quantum annealers have the potential to be effective in\nsolving unconstrained binary quadratic programming problems. Naturally, one may\ndesire to expand the application domain of these machines to problems with\ngeneral discrete variables. In this paper, we explore the possibility of\nemploying quantum annealers to solve unconstrained quadratic programming\nproblems over a bounded integer domain. We present an approach for encoding\ninteger variables into binary ones, thereby representing unconstrained integer\nquadratic programming problems as unconstrained binary quadratic programming\nproblems. To respect some of the limitations of the currently developed quantum\nannealers, we propose an integer encoding, named bounded- coefficient encoding,\nin which we limit the size of the coefficients that appear in the encoding.\nFurthermore, we propose an algorithm for finding the upper bound on the\ncoefficients of the encoding using the precision of the machine and the\ncoefficients of the original integer problem. Finally, we experimentally show\nthat this approach is far more resilient to the noise of the quantum annealers\ncompared to traditional approaches for the encoding of integers in base two.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pluricanonical Periods over Compact Riemann Surfaces of Genus at least 2.   This article is an attempt to generalize Riemann's bilinear relations on\ncompact Riemann surface of genus at least 2, which may lead to new structures\nin the theory of hyperbolic Riemann surfaces. No significant result is\nobtained, the article serves to bring the readers' attention to the observation\nmade by [Bol-1949], and some easy consequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The splashback radius of halos from particle dynamics. II. Dependence on mass, accretion rate, redshift, and cosmology.   The splashback radius $R_{\\rm sp}$, the apocentric radius of particles on\ntheir first orbit after falling into a dark matter halo, has recently been\nsuggested as a physically motivated halo boundary that separates accreting from\norbiting material. Using the SPARTA code presented in Paper I, we analyze the\norbits of billions of particles in cosmological simulations of structure\nformation and measure $R_{\\rm sp}$ for a large sample of halos that span a mass\nrange from dwarf galaxy to massive cluster halos, reach redshift 8, and include\nWMAP, Planck, and self-similar cosmologies. We analyze the dependence of\n$R_{\\rm sp}/R_{\\rm 200m}$ and $M_{\\rm sp}/M_{\\rm 200m}$ on the mass accretion\nrate $\\Gamma$, halo mass, redshift, and cosmology. The scatter in these\nrelations varies between 0.02 and 0.1 dex. While we confirm the known trend\nthat $R_{\\rm sp}/R_{\\rm 200m}$ decreases with $\\Gamma$, the relationships turn\nout to be more complex than previously thought, demonstrating that $R_{\\rm sp}$\nis an independent definition of the halo boundary that cannot trivially be\nreconstructed from spherical overdensity definitions. We present fitting\nfunctions for $R_{\\rm sp}/R_{\\rm 200m}$ and $M_{\\rm sp}/M_{\\rm 200m}$ as a\nfunction of accretion rate, peak height, and redshift, achieving an accuracy of\n5% or better everywhere in the parameter space explored. We discuss the\nphysical meaning of the distribution of particle apocenters and show that the\npreviously proposed definition of $R_{\\rm sp}$ as the radius of the steepest\nlogarithmic density slope encloses roughly three-quarters of the apocenters.\nFinally, we conclude that no analytical model presented thus far can fully\nexplain our results.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ensemble Classifier for Eye State Classification using EEG Signals.   The growing importance and utilization of measuring brain waves (e.g. EEG\nsignals of eye state) in brain-computer interface (BCI) applications\nhighlighted the need for suitable classification methods. In this paper, a\ncomparison between three of well-known classification methods (i.e. support\nvector machine (SVM), hidden Markov map (HMM), and radial basis function (RBF))\nfor EEG based eye state classification was achieved. Furthermore, a suggested\nmethod that is based on ensemble model was tested. The suggested (ensemble\nsystem) method based on a voting algorithm with two kernels: random forest (RF)\nand Kstar classification methods. The performance was tested using three\nmeasurement parameters: accuracy, mean absolute error (MAE), and confusion\nmatrix. Results showed that the proposed method outperforms the other tested\nmethods. For instance, the suggested method's performance was 97.27% accuracy\nand 0.13 MAE.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Conjugates and Adjoint Descent.   In this note we present an $\\infty$-categorical framework for descent along\nadjunctions and a general formula for counting conjugates up to equivalence\nwhich unifies several known formulae from different fields.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Linear Convergence of An Iterative Phase Retrieval Algorithm with Data Reuse.   Phase retrieval has been an attractive but difficult problem rising from\nphysical science, and there has been a gap between state-of-the-art theoretical\nconvergence analyses and the corresponding efficient retrieval methods.\nFirstly, these analyses all assume that the sensing vectors and the iterative\nupdates are independent, which only fits the ideal model with infinite\nmeasurements but not the reality, where data are limited and have to be reused.\nSecondly, the empirical results of some efficient methods, such as the\nrandomized Kaczmarz method, show linear convergence, which is beyond existing\ntheoretical explanations considering its randomness and reuse of data. In this\nwork, we study for the first time, without the independence assumption, the\nconvergence behavior of the randomized Kaczmarz method for phase retrieval.\nSpecifically, beginning from taking expectation of the squared estimation error\nwith respect to the index of measurement by fixing the sensing vector and the\nerror in the previous step, we discard the independence assumption, rigorously\nderive the upper and lower bounds of the reduction of the mean squared error,\nand prove the linear convergence. This work fills the gap between a fast\nconverging algorithm and its theoretical understanding. The proposed\nmethodology may contribute to the study of other iterative algorithms for phase\nretrieval and other problems in the broad area of signal processing and machine\nlearning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "LD-SDS: Towards an Expressive Spoken Dialogue System based on Linked-Data.   In this work we discuss the related challenges and describe an approach\ntowards the fusion of state-of-the-art technologies from the Spoken Dialogue\nSystems (SDS) and the Semantic Web and Information Retrieval domains. We\nenvision a dialogue system named LD-SDS that will support advanced, expressive,\nand engaging user requests, over multiple, complex, rich, and open-domain data\nsources that will leverage the wealth of the available Linked Data.\nSpecifically, we focus on: a) improving the identification, disambiguation and\nlinking of entities occurring in data sources and user input; b) offering\nadvanced query services for exploiting the semantics of the data, with\nreasoning and exploratory capabilities; and c) expanding the typical\ninformation seeking dialogue model (slot filling) to better reflect real-world\nconversational search scenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convolution Aware Initialization.   Initialization of parameters in deep neural networks has been shown to have a\nbig impact on the performance of the networks (Mishkin & Matas, 2015). The\ninitialization scheme devised by He et al, allowed convolution activations to\ncarry a constrained mean which allowed deep networks to be trained effectively\n(He et al., 2015a). Orthogonal initializations and more generally orthogonal\nmatrices in standard recurrent networks have been proved to eradicate the\nvanishing and exploding gradient problem (Pascanu et al., 2012). Majority of\ncurrent initialization schemes do not take fully into account the intrinsic\nstructure of the convolution operator. Using the duality of the Fourier\ntransform and the convolution operator, Convolution Aware Initialization builds\northogonal filters in the Fourier space, and using the inverse Fourier\ntransform represents them in the standard space. With Convolution Aware\nInitialization we noticed not only higher accuracy and lower loss, but faster\nconvergence. We achieve new state of the art on the CIFAR10 dataset, and\nachieve close to state of the art on various other tasks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Acyclic cluster algebras, reflection groups, and curves on a punctured disc.   We establish a bijective correspondence between certain non-self-intersecting\ncurves in an $n$-punctured disc and positive ${\\mathbf c}$-vectors of acyclic\ncluster algebras whose quivers have multiple arrows between every pair of\nvertices. As a corollary, we obtain a proof of a conjecture by K.-H. Lee and K.\nLee (arXiv:1703.09113) on the combinatorial description of real Schur roots for\nacyclic quivers with multiple arrows, and give a combinatorial characterization\nof seeds in terms of curves in an $n$-punctured disc.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Affiliation networks with an increasing degree sequence.   Affiliation network is one kind of two-mode social network with two different\nsets of nodes (namely, a set of actors and a set of social events) and edges\nrepresenting the affiliation of the actors with the social events. Although a\nnumber of statistical models are proposed to analyze affiliation networks, the\nasymptotic behaviors of the estimator are still unknown or have not been\nproperly explored. In this paper, we study an affiliation model with the degree\nsequence as the exclusively natural sufficient statistic in the exponential\nfamily distributions. We establish the uniform consistency and asymptotic\nnormality of the maximum likelihood estimator when the numbers of actors and\nevents both go to infinity. Simulation studies and a real data example\ndemonstrate our theoretical results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fraunhofer diffraction at the two-dimensional quadratically distorted (QD) Grating.   A two-dimensional (2D) mathematical model of quadratically distorted (QD)\ngrating is established with the principles of Fraunhofer diffraction and\nFourier optics. Discrete sampling and bisection algorithm are applied for\nfinding numerical solution of the diffraction pattern of QD grating. This 2D\nmathematical model allows the precise design of QD grating and improves the\noptical performance of simultaneous multiplane imaging system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the status of the Born-Oppenheimer expansion in molecular systems theory.   It is shown that the adiabatic Born-Oppenheimer expansion does not satisfy\nthe necessary condition for the applicability of perturbation theory. A simple\nexample of an exact solution of a problem that can not be obtained from the\nBorn-Oppenheimer expansion is given. A new version of perturbation theory for\nmolecular systems is proposed.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Randomized Load Balancing on Networks with Stochastic Inputs.   Iterative load balancing algorithms for indivisible tokens have been studied\nintensively in the past. Complementing previous worst-case analyses, we study\nan average-case scenario where the load inputs are drawn from a fixed\nprobability distribution. For cycles, tori, hypercubes and expanders, we obtain\nalmost matching upper and lower bounds on the discrepancy, the difference\nbetween the maximum and the minimum load. Our bounds hold for a variety of\nprobability distributions including the uniform and binomial distribution but\nalso distributions with unbounded range such as the Poisson and geometric\ndistribution. For graphs with slow convergence like cycles and tori, our\nresults demonstrate a substantial difference between the convergence in the\nworst- and average-case. An important ingredient in our analysis is new upper\nbound on the t-step transition probability of a general Markov chain, which is\nderived by invoking the evolving set process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emergence of Leadership in Communication.   We study a neuro-inspired model that mimics a discussion (or information\ndissemination) process in a network of agents. During their interaction, agents\nredistribute activity and network weights, resulting in emergence of leader(s).\nThe model is able to reproduce the basic scenarios of leadership known in\nnature and society: laissez-faire (irregular activity, weak leadership, sizable\ninter-follower interaction, autonomous sub-leaders); participative or\ndemocratic (strong leadership, but with feedback from followers); and\nautocratic (no feedback, one-way influence). Several pertinent aspects of these\nscenarios are found as well---e.g., hidden leadership (a hidden clique of\nagents driving the official autocratic leader), and successive leadership (two\nleaders influence followers by turns). We study how these scenarios emerge from\ninter-agent dynamics and how they depend on behavior rules of agents---in\nparticular, on their inertia against state changes.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "The border support rank of two-by-two matrix multiplication is seven.   We show that the border support rank of the tensor corresponding to\ntwo-by-two matrix multiplication is seven over the complex numbers. We do this\nby constructing two polynomials that vanish on all complex tensors with format\nfour-by-four-by-four and border rank at most six, but that do not vanish\nsimultaneously on any tensor with the same support as the two-by-two matrix\nmultiplication tensor. This extends the work of Hauenstein, Ikenmeyer, and\nLandsberg. We also give two proofs that the support rank of the two-by-two\nmatrix multiplication tensor is seven over any field: one proof using a result\nof De Groote saying that the decomposition of this tensor is unique up to\nsandwiching, and another proof via the substitution method. These results\nanswer a question asked by Cohn and Umans. Studying the border support rank of\nthe matrix multiplication tensor is relevant for the design of matrix\nmultiplication algorithms, because upper bounds on the border support rank of\nthe matrix multiplication tensor lead to upper bounds on the computational\ncomplexity of matrix multiplication, via a construction of Cohn and Umans.\nMoreover, support rank has applications in quantum communication complexity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nanostructured complex oxides as a route towards thermal behavior in artificial spin ice systems.   We have used soft x-ray photoemission electron microscopy to image the\nmagnetization of single domain La$_{0.7}$Sr$_{0.3}$MnO$_{3}$ nano-islands\narranged in geometrically frustrated configurations such as square ice and\nkagome ice geometries. Upon thermal randomization, ensembles of nano-islands\nwith strong inter-island magnetic coupling relax towards low-energy\nconfigurations. Statistical analysis shows that the likelihood of ensembles\nfalling into low-energy configurations depends strongly on the annealing\ntemperature. Annealing to just below the Curie temperature of the ferromagnetic\nfilm (T$_{C}$ = 338 K) allows for a much greater probability of achieving low\nenergy configurations as compared to annealing above the Curie temperature. At\nthis thermally active temperature of 325 K, the ensemble of ferromagnetic\nnano-islands explore their energy landscape over time and eventually transition\nto lower energy states as compared to the frozen-in configurations obtained\nupon cooling from above the Curie temperature. Thus, this materials system\nallows for a facile method to systematically study thermal evolution of\nartificial spin ice arrays of nano-islands at temperatures modestly above room\ntemperature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Dining Philosophers, Leader Election and Ring Size problems, in the quantum setting.   We provide the first quantum (exact) protocol for the Dining Philosophers\nproblem (DP), a central problem in distributed algorithms. It is well known\nthat the problem cannot be solved exactly in the classical setting. We then use\nour DP protocol to provide a new quantum protocol for the tightly related\nproblem of exact leader election (LE) on a ring, improving significantly in\nboth time and memory complexity over the known LE protocol by Tani et. al. To\ndo this, we show that in some sense the exact DP and exact LE problems are\nequivalent; interestingly, in the classical non-exact setting they are not.\nHopefully, the results will lead to exact quantum protocols for other important\ndistributed algorithmic questions; in particular, we discuss interesting\nconnections to the ring size problem, as well as to a physically motivated\nquestion of breaking symmetry in 1D translationally invariant systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Infinite-Dimensionality in Quantum Foundations: W*-algebras as Presheaves over Matrix Algebras.   In this paper, W*-algebras are presented as canonical colimits of diagrams of\nmatrix algebras and completely positive maps. In other words, matrix algebras\nare dense in W*-algebras.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Gaia-ESO Survey: low-alpha element stars in the Galactic Bulge.   We take advantage of the Gaia-ESO Survey iDR4 bulge data to search for\nabundance anomalies that could shed light on the composite nature of the Milky\nWay bulge. The alpha-elements (Mg, Si, and whenever available, Ca) abundances,\nand their trends with Fe abundances have been analysed for a total of 776 bulge\nstars. In addition, the aluminum abundances and their ratio to Fe and Mg have\nalso been examined. Our analysis reveals the existence of low-alpha element\nabundance stars with respect to the standard bulge sequence in the [alpha/Fe]\nvs. [Fe/H] plane. 18 objects present deviations in [alpha/Fe] ranging from 2.1\nto 5.3 sigma with respect to the median standard value. Those stars do not show\nMg-Al anti-correlation patterns. Incidentally, this sign of the existence of\nmultiple stellar populations is reported firmly for the first time for the\nbulge globular cluster NGC 6522. The identified low-alpha abundance stars have\nchemical patterns compatible with those of the thin disc. Their link with\nmassive dwarf galaxies accretion seems unlikely, as larger deviations in alpha\nabundance and Al would be expected. The vision of a bulge composite nature and\na complex formation process is reinforced by our results. The used approach, a\nmulti-method and model-driven analysis of high resolution data seems crucial to\nreveal this complexity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Versatile Approach to Evaluating and Testing Automated Vehicles based on Kernel Methods.   Evaluation and validation of complicated control systems are crucial to\nguarantee usability and safety. Usually, failure happens in some very rarely\nencountered situations, but once triggered, the consequence is disastrous.\nAccelerated Evaluation is a methodology that efficiently tests those\nrarely-occurring yet critical failures via smartly-sampled test cases. The\ndistribution used in sampling is pivotal to the performance of the method, but\nbuilding a suitable distribution requires case-by-case analysis. This paper\nproposes a versatile approach for constructing sampling distribution using\nkernel method. The approach uses statistical learning tools to approximate the\ncritical event sets and constructs distributions based on the unique properties\nof Gaussian distributions. We applied the method to evaluate the automated\nvehicles. Numerical experiments show proposed approach can robustly identify\nthe rare failures and significantly reduce the evaluation time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multimodal Clustering for Community Detection.   Multimodal clustering is an unsupervised technique for mining interesting\npatterns in $n$-adic binary relations or $n$-mode networks. Among different\ntypes of such generalized patterns one can find biclusters and formal concepts\n(maximal bicliques) for 2-mode case, triclusters and triconcepts for 3-mode\ncase, closed $n$-sets for $n$-mode case, etc. Object-attribute biclustering\n(OA-biclustering) for mining large binary datatables (formal contexts or 2-mode\nnetworks) arose by the end of the last decade due to intractability of\ncomputation problems related to formal concepts; this type of patterns was\nproposed as a meaningful and scalable approximation of formal concepts. In this\npaper, our aim is to present recent advance in OA-biclustering and its\nextensions to mining multi-mode communities in SNA setting. We also discuss\nconnection between clustering coefficients known in SNA community for 1-mode\nand 2-mode networks and OA-bicluster density, the main quality measure of an\nOA-bicluster. Our experiments with 2-, 3-, and 4-mode large real-world networks\nshow that this type of patterns is suitable for community detection in\nmulti-mode cases within reasonable time even though the number of corresponding\n$n$-cliques is still unknown due to computation difficulties. An interpretation\nof OA-biclusters for 1-mode networks is provided as well.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Multimodal Subspace Clustering Networks.   We present convolutional neural network (CNN) based approaches for\nunsupervised multimodal subspace clustering. The proposed framework consists of\nthree main stages - multimodal encoder, self-expressive layer, and multimodal\ndecoder. The encoder takes multimodal data as input and fuses them to a latent\nspace representation. The self-expressive layer is responsible for enforcing\nthe self-expressiveness property and acquiring an affinity matrix corresponding\nto the data points. The decoder reconstructs the original input data. The\nnetwork uses the distance between the decoder's reconstruction and the original\ninput in its training. We investigate early, late and intermediate fusion\ntechniques and propose three different encoders corresponding to them for\nspatial fusion. The self-expressive layers and multimodal decoders are\nessentially the same for different spatial fusion-based approaches. In addition\nto various spatial fusion-based methods, an affinity fusion-based network is\nalso proposed in which the self-expressive layer corresponding to different\nmodalities is enforced to be the same. Extensive experiments on three datasets\nshow that the proposed methods significantly outperform the state-of-the-art\nmultimodal subspace clustering methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Filter Functions in Regularisers by Minimising Quotients.   Learning approaches have recently become very popular in the field of inverse\nproblems. A large variety of methods has been established in recent years,\nranging from bi-level learning to high-dimensional machine learning techniques.\nMost learning approaches, however, only aim at fitting parametrised models to\nfavourable training data whilst ignoring misfit training data completely. In\nthis paper, we follow up on the idea of learning parametrised regularisation\nfunctions by quotient minimisation as established in [3]. We extend the model\ntherein to include higher-dimensional filter functions to be learned and allow\nfor fit- and misfit-training data consisting of multiple functions. We first\npresent results resembling behaviour of well-established derivative-based\nsparse regularisers like total variation or higher-order total variation in\none-dimension. Our second and main contribution is the introduction of novel\nfamilies of non-derivative-based regularisers. This is accomplished by learning\nfavourable scales and geometric properties while at the same time avoiding\nunfavourable ones.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust Task Clustering for Deep Many-Task Learning.   We investigate task clustering for deep-learning based multi-task and\nfew-shot learning in a many-task setting. We propose a new method to measure\ntask similarities with cross-task transfer performance matrix for the deep\nlearning scenario. Although this matrix provides us critical information\nregarding similarity between tasks, its asymmetric property and unreliable\nperformance scores can affect conventional clustering methods adversely.\nAdditionally, the uncertain task-pairs, i.e., the ones with extremely\nasymmetric transfer scores, may collectively mislead clustering algorithms to\noutput an inaccurate task-partition. To overcome these limitations, we propose\na novel task-clustering algorithm by using the matrix completion technique. The\nproposed algorithm constructs a partially-observed similarity matrix based on\nthe certainty of cluster membership of the task-pairs. We then use a matrix\ncompletion algorithm to complete the similarity matrix. Our theoretical\nanalysis shows that under mild constraints, the proposed algorithm will\nperfectly recover the underlying \"true\" similarity matrix with a high\nprobability. Our results show that the new task clustering method can discover\ntask clusters for training flexible and superior neural network models in a\nmulti-task learning setup for sentiment classification and dialog intent\nclassification tasks. Our task clustering approach also extends metric-based\nfew-shot learning methods to adapt multiple metrics, which demonstrates\nempirical advantages when the tasks are diverse.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotically preserving particle-in-cell methods for inhomogenous strongly magnetized plasmas.   We propose a class of Particle-In-Cell (PIC) methods for the Vlasov-Poisson\nsystem with a strong and inhomogeneous external magnetic field with fixed\ndirection, where we focus on the motion of particles in the plane orthogonal to\nthe magnetic field (so-called poloidal directions). In this regime, the time\nstep can be subject to stability constraints related to the smallness of Larmor\nradius and plasma frequency. To avoid this limitation, our approach is based on\nfirst and higher-order semi-implicit numerical schemes already validated on\ndissipative systems [3] and for homogeneous magnetic fields [10]. Thus, when\nthe magnitude of the external magnetic field becomes large, this method\nprovides a consistent PIC discretization of the guiding-center system taking\ninto account variations of the magnetic field. We carry out some theoretical\nproofs and perform several numerical experiments that establish a solid\nvalidation of the method and its underlying concepts.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Optimal Timing to Trade Along a Randomized Brownian Bridge.   This paper studies an optimal trading problem that incorporates the trader's\nmarket view on the terminal asset price distribution and uninformative noise\nembedded in the asset price dynamics. We model the underlying asset price\nevolution by an exponential randomized Brownian bridge (rBb) and consider\nvarious prior distributions for the random endpoint. We solve for the optimal\nstrategies to sell a stock, call, or put, and analyze the associated delayed\nliquidation premia. We solve for the optimal trading strategies numerically and\ncompare them across different prior beliefs. Among our results, we find that\ndisconnected continuation/exercise regions arise when the trader prescribe a\ntwo-point discrete distribution and double exponential distribution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "General $(α, β)$ metrics with relatively isotroic mean Landsberg curvature.   In this paper, we study a new class of Finsler metrics, F=\\alpha\\phi(b^2,s),\ns:=\\beta/\\alpha, defined by a Riemannian metric \\alpha and 1-form \\beta. It is\ncalled general (\\alpha, \\beta) metric. In this paper, we assume \\phi be\ncoefficient by s and \\beta be closed and conformal. We find a nessecary and\nsufficient condition for the metric of relatively isotropic mean Landsberg\ncurvature to be Berwald.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Estimating the unseen from multiple populations.   Given samples from a distribution, how many new elements should we expect to\nfind if we continue sampling this distribution? This is an important and\nactively studied problem, with many applications ranging from unseen species\nestimation to genomics. We generalize this extrapolation and related unseen\nestimation problems to the multiple population setting, where population $j$\nhas an unknown distribution $D_j$ from which we observe $n_j$ samples. We\nderive an optimal estimator for the total number of elements we expect to find\namong new samples across the populations. Surprisingly, we prove that our\nestimator's accuracy is independent of the number of populations. We also\ndevelop an efficient optimization algorithm to solve the more general problem\nof estimating multi-population frequency distributions. We validate our methods\nand theory through extensive experiments. Finally, on a real dataset of human\ngenomes across multiple ancestries, we demonstrate how our approach for unseen\nestimation can enable cohort designs that can discover interesting mutations\nwith greater efficiency.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Incidence systems on Cartesian powers of algebraic curves.   We show that a reduct of the Zariski structure of an algebraic curve which is\nnot locally modular interprets a field, answering a question of Zilber's.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Grid-forming Control for Power Converters based on Matching of Synchronous Machines.   We consider the problem of grid-forming control of power converters in\nlow-inertia power systems. Starting from an average-switch three-phase inverter\nmodel, we draw parallels to a synchronous machine (SM) model and propose a\nnovel grid-forming converter control strategy which dwells upon the main\ncharacteristic of a SM: the presence of an internal rotating magnetic field. In\nparticular, we augment the converter system with a virtual oscillator whose\nfrequency is driven by the DC-side voltage measurement and which sets the\nconverter pulse-width-modulation signal, thereby achieving exact matching\nbetween the converter in closed-loop and the SM dynamics. We then provide a\nsufficient condition assuring existence, uniqueness, and global asymptotic\nstability of equilibria in a coordinate frame attached to the virtual\noscillator angle. By actuating the DC-side input of the converter we are able\nto enforce this sufficient condition. In the same setting, we highlight strict\nincremental passivity, droop, and power-sharing properties of the proposed\nframework, which are compatible with conventional requirements of power system\noperation. We subsequently adopt disturbance decoupling techniques to design\nadditional control loops that regulate the DC-side voltage, as well as AC-side\nfrequency and amplitude, while in the end validating them with numerical\nexperiments.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Two forms of minimality in ASPIC+.   Many systems of structured argumentation explicitly require that the facts\nand rules that make up the argument for a conclusion be the minimal set\nrequired to derive the conclusion. ASPIC+ does not place such a requirement on\narguments, instead requiring that every rule and fact that are part of an\nargument be used in its construction. Thus ASPIC+ arguments are minimal in the\nsense that removing any element of the argument would lead to a structure that\nis not an argument. In this brief note we discuss these two types of minimality\nand show how the first kind of minimality can, if desired, be recovered in\nASPIC+.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Study of deteriorating semiopaque turquoise lead-potassium glass beads at different stages of corrosion using micro-FTIR spectroscopy.   Nowadays, a problem of historical beadworks conservation in museum\ncollections is actual more than ever because of fatal corrosion of the 19th\ncentury glass beads. Vibrational spectroscopy is a powerful method for\ninvestigation of glass, namely, of correlation of the structure-chemical\ncomposition. Therefore, Fourier-transform infrared spectroscopy was used for\nexamination of degradation processes in cloudy turquoise glass beads, which in\ncontrast to other color ones deteriorate especially strongly. Micro-X-ray\nfluorescence spectrometry of samples has shown that lead-potassium glass\nPbO-K$_2$O-SiO$_2$ with small amount of Cu and Sb was used for manufacture of\ncloudy turquoise beads. Fourier-transform infrared spectroscopy study of the\nbeads at different stages of glass corrosion was carried out in the range from\n200 to 4000 cm$^{-1}$ in the attenuated total reflection mode. In all the\nspectra, we have observed shifts of two major absorption bands to low-frequency\nrange (~1000 and ~775 cm$^{-1}$) compared to ones typical for amorphous SiO2\n(~1100 and 800 cm$^{-1}$, respectively). Such an effect is connected with\nPb$^{2+}$ and K$^+$ appending to the glass network. The presence of a weak band\nat ~1630 cm$^{-1}$ in all the spectra is attributed to the adsorption of\nH$_2$O. After annealing of the beads, the band disappeared completely in less\ndeteriorated samples and became significantly weaker in more destroyed ones.\nBased on that we conclude that there is adsorbed molecular water on the beads.\nHowever, products of corrosion (e.g., alkali in the form of white crystals or\ndroplets of liquid alkali) were not observed on the glass surface. We have also\nobserved glass depolymerisation in the strongly degraded beads, which is\nexhibited in domination of the band peaked at ~1000 cm$^{-1}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Methods for Interpreting and Understanding Deep Neural Networks.   This paper provides an entry point to the problem of interpreting a deep\nneural network model and explaining its predictions. It is based on a tutorial\ngiven at ICASSP 2017. It introduces some recently proposed techniques of\ninterpretation, along with theory, tricks and recommendations, to make most\nefficient use of these techniques on real data. It also discusses a number of\npractical applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Solving $\\ell^p\\!$-norm regularization with tensor kernels.   In this paper, we discuss how a suitable family of tensor kernels can be used\nto efficiently solve nonparametric extensions of $\\ell^p$ regularized learning\nmethods. Our main contribution is proposing a fast dual algorithm, and showing\nthat it allows to solve the problem efficiently. Our results contrast recent\nfindings suggesting kernel methods cannot be extended beyond Hilbert setting.\nNumerical experiments confirm the effectiveness of the method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Conservative Exploration using Interleaving.   In many practical problems, a learning agent may want to learn the best\naction in hindsight without ever taking a bad action, which is significantly\nworse than the default production action. In general, this is impossible\nbecause the agent has to explore unknown actions, some of which can be bad, to\nlearn better actions. However, when the actions are combinatorial, this may be\npossible if the unknown action can be evaluated by interleaving it with the\nproduction action. We formalize this concept as learning in stochastic\ncombinatorial semi-bandits with exchangeable actions. We design efficient\nlearning algorithms for this problem, bound their n-step regret, and evaluate\nthem on both synthetic and real-world problems. Our real-world experiments show\nthat our algorithms can learn to recommend K most attractive movies without\never violating a strict production constraint, both overall and subject to a\ndiversity constraint.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structured Differential Learning for Automatic Threshold Setting.   We introduce a technique that can automatically tune the parameters of a\nrule-based computer vision system comprised of thresholds, combinational logic,\nand time constants. This lets us retain the flexibility and perspicacity of a\nconventionally structured system while allowing us to perform approximate\ngradient descent using labeled data. While this is only a heuristic procedure,\nas far as we are aware there is no other efficient technique for tuning such\nsystems. We describe the components of the system and the associated supervised\nlearning mechanism. We also demonstrate the utility of the algorithm by\ncomparing its performance versus hand tuning for an automotive headlight\ncontroller. Despite having over 100 parameters, the method is able to\nprofitably adjust the system values given just the desired output for a number\nof videos.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Abelian Tensor Models on the Lattice.   We consider a chain of Abelian Klebanov-Tarnopolsky fermionic tensor models\ncoupled through quartic nearest-neighbor interactions. We characterize the\ngauge-singlet spectrum for small chains ($L=2,3,4,5$) and observe that the\nspectral statistics exhibits strong evidences in favor of quasi-many body\nlocalization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Change of grading, injective dimension and dualizing complexes.   Let $G,H$ be groups, $\\phi: G \\rightarrow H$ a group morphism, and $A$ a\n$G$-graded algebra. The morphism $\\phi$ induces an $H$-grading on $A$, and on\nany $G$-graded $A$-module, which thus becomes an $H$-graded $A$-module. Given\nan injective $G$-graded $A$-module, we give bounds for its injective dimension\nwhen seen as $H$-graded $A$-module. Following ideas by Van den Bergh, we give\nan application of our results to the stability of dualizing complexes through\nchange of grading.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Homogeneous Kobayashi-hyperbolic manifolds with high-dimensional group of holomorphic automorphisms.   We determine all connected homogeneous Kobayashi-hyperbolic manifolds of\ndimension $n\\ge 2$ whose holomorphic automorphism group has dimension $n^2-2$.\nThis result complements an existing classification for automorphism group\ndimension $n^2-1$ and greater obtained without the homogeneity assumption.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ALMA Observations of the Gravitational Lens SDP.9.   We present long-baseline ALMA observations of the strong gravitational lens\nH-ATLAS J090740.0-004200 (SDP.9), which consists of an elliptical galaxy at\n$z_{\\mathrm{L}}=0.6129$ lensing a background submillimeter galaxy into two\nextended arcs. The data include Band 6 continuum observations, as well as CO\n$J$=6$-$5 molecular line observations, from which we measure an updated source\nredshift of $z_{\\mathrm{S}}=1.5747$. The image morphology in the ALMA data is\ndifferent from that of the HST data, indicating a spatial offset between the\nstellar, gas, and dust component of the source galaxy. We model the lens as an\nelliptical power law density profile with external shear using a combination of\narchival HST data and conjugate points identified in the ALMA data. Our best\nmodel has an Einstein radius of $\\theta_{\\mathrm{E}}=0.66\\pm0.01$ and a\nslightly steeper than isothermal mass profile slope. We search for the central\nimage of the lens, which can be used constrain the inner mass distribution of\nthe lens galaxy including the central supermassive black hole, but do not\ndetect it in the integrated CO image at a 3$\\sigma$ rms level of 0.0471 Jy km\ns$^{-1}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Estimates for $π(x)$ for large values of $x$ and Ramanujan's prime counting inequality.   In this paper we use refined approximations for Chebyshev's\n$\\vartheta$-function to establish new explicit estimates for the prime counting\nfunction $\\pi(x)$, which improve the current best estimates for large values of\n$x$. As an application we find an upper bound for the number $H_0$ which is\ndefined to be the smallest positive integer so that Ramanujan's prime counting\ninequality holds for every $x \\geq H_0$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Estimating the rate of defects under imperfect sampling inspection - a new approach.   We consider the problem of estimating the the rate of defects (mean number of\ndefects per item), given counts of defects detected by two independent\nimperfect inspectors on a sample of items. In contrast with the well-known\nmethod of Capture-Recapture, here we {\\it{do not}} have information regarding\nthe number of defects jointly detected by {\\it{both}} inspectors. We solve this\nproblem by constructing two types of estimators - a simple moment-type\nestimator, and a more complicated maximum-likelihood estimator. The performance\nof these estimators is studied analytically and by means of simulations. It is\nshown that the maximum-likelihood estimator is superior to the moment-type\nestimator. A systematic comparison with the Capture-Recapture method is also\nmade.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "TED Talk Recommender Using Speech Transcripts.   Nowadays, online video platforms mostly recommend related videos by analyzing\nuser-driven data such as viewing patterns, rather than the content of the\nvideos. However, content is more important than any other element when videos\naim to deliver knowledge. Therefore, we have developed a web application which\nrecommends related TED lecture videos to the users, considering the content of\nthe videos from the transcripts. TED Talk Recommender constructs a network for\nrecommending videos that are similar content-wise and providing a user\ninterface.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Estimation of the discontinuous leverage effect: Evidence from the NASDAQ order book.   An extensive empirical literature documents a generally negative correlation,\nnamed the \"leverage effect,\" between asset returns and changes of volatility.\nIt is more challenging to establish such a return-volatility relationship for\njumps in high-frequency data. We propose new nonparametric methods to assess\nand test for a discontinuous leverage effect --- i.e. a relation between\ncontemporaneous jumps in prices and volatility. The methods are robust to\nmarket microstructure noise and build on a newly developed price-jump\nlocalization and estimation procedure. Our empirical investigation of six years\nof transaction data from 320 NASDAQ firms displays no unconditional negative\ncorrelation between price and volatility cojumps. We show, however, that there\nis a strong relation between price-volatility cojumps if one conditions on the\nsign of price jumps and whether the price jumps are market-wide or\nidiosyncratic. Firms' volatility levels strongly explain the cross-section of\ndiscontinuous leverage while debt-to-equity ratios have no significant\nexplanatory power.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Maximum principles for the fractional p-Laplacian and symmetry of solutions.   In this paper, we consider nonlinear equations involving the fractional\np-Laplacian $$ (-\\lap)_p^s u(x)) \\equiv C_{n,s,p} PV \\int_{\\mathbb{R}^n}\n\\frac{|u(x)-u(y)|^{p-2}[u(x)-u(y)]}{|x-z|^{n+ps}} dz= f(x,u).$$\nWe prove a {\\em maximum principle for anti-symmetric functions} and obtain\nother key ingredients for carrying on the method of moving planes, such as {\\em\na key boundary estimate lemma}. Then we establish radial symmetry and\nmonotonicity for positive solutions to semilinear equations involving the\nfractional p-Laplacian in a unit ball and in the whole space. We believe that\nthe methods developed here can be applied to a variety of problems involving\nnonlinear nonlocal operators.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning causal Bayes networks using interventional path queries in polynomial time and sample complexity.   Causal discovery from empirical data is a fundamental problem in many\nscientific domains. Observational data allows for identifiability only up to\nMarkov equivalence class. In this paper we first propose a polynomial time\nalgorithm for learning the exact correctly-oriented structure of the transitive\nreduction of any causal Bayesian networks with high probability, by using\ninterventional path queries. Each path query takes as input an origin node and\na target node, and answers whether there is a directed path from the origin to\nthe target. This is done by intervening the origin node and observing samples\nfrom the target node. We theoretically show the logarithmic sample complexity\nfor the size of interventional data per path query, for continuous and discrete\nnetworks. We further extend our work to learn the transitive edges using\nlogarithmic sample complexity (albeit in time exponential in the maximum number\nof parents for discrete networks). This allows us to learn the full network. We\nalso provide an analysis of imperfect interventions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A practical guide to the simultaneous determination of protein structure and dynamics using metainference.   Accurate protein structural ensembles can be determined with metainference, a\nBayesian inference method that integrates experimental information with prior\nknowledge of the system and deals with all sources of uncertainty and errors as\nwell as with system heterogeneity. Furthermore, metainference can be\nimplemented using the metadynamics approach, which enables the computational\nstudy of complex biological systems requiring extensive conformational\nsampling. In this chapter, we provide a step-by-step guide to perform and\nanalyse metadynamic metainference simulations using the ISDB module of the\nopen-source PLUMED library, as well as a series of practical tips to avoid\ncommon mistakes. Specifically, we will guide the reader in the process of\nlearning how to model the structural ensemble of a small disordered peptide by\ncombining state-of-the-art molecular mechanics force fields with nuclear\nmagnetic resonance data, including chemical shifts, scalar couplings and\nresidual dipolar couplings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On indirect noise in multicomponent nozzle flows.   A one-dimensional, unsteady nozzle flow is modelled to identify the sources\nof indirect noise in multicomponent gases. First, from non-equilibrium\nthermodynamics relations, it is shown that a compositional inhomogeneity\nadvected in an accelerating flow is a source of sound induced by\ninhomogeneities in the mixture (i) chemical potentials and (ii) specific heat\ncapacities. Second, it is shown that the acoustic, entropy and compositional\nlinear perturbations evolve independently from each other and they become\ncoupled through mean-flow gradients and/or at the boundaries. Third, the\nequations are cast in invariant formulation and a mathematical solution is\nfound by asymptotic expansion of path-ordered integrals with an infinite radius\nof convergence. Finally, the transfer functions are calculated for a supersonic\nnozzle with finite spatial extent perturbed by a methane-air compositional\ninhomogeneity. The proposed framework will help identify and quantify the\nsources of sound in nozzles with relevance, for example, to aeronautical gas\nturbines.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A parity-breaking electronic nematic phase transition in the spin-orbit coupled metal Cd$_2$Re$_2$O$_7$.   Strong electron interactions can drive metallic systems toward a variety of\nwell-known symmetry-broken phases, but the instabilities of correlated metals\nwith strong spin-orbit coupling have only recently begun to be explored. We\nuncovered a multipolar nematic phase of matter in the metallic pyrochlore\nCd$_2$Re$_2$O$_7$ using spatially resolved second-harmonic optical anisotropy\nmeasurements. Like previously discovered electronic nematic phases, this\nmultipolar phase spontaneously breaks rotational symmetry while preserving\ntranslational invariance. However, it has the distinguishing property of being\nodd under spatial inversion, which is allowed only in the presence of\nspin-orbit coupling. By examining the critical behavior of the multipolar\nnematic order parameter, we show that it drives the thermal phase transition\nnear 200 kelvin in Cd$_2$Re$_2$O$_7$ and induces a parity-breaking lattice\ndistortion as a secondary order.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Complete Classification of Generalized Santha-Vazirani Sources.   Let $\\mathcal{F}$ be a finite alphabet and $\\mathcal{D}$ be a finite set of\ndistributions over $\\mathcal{F}$. A Generalized Santha-Vazirani (GSV) source of\ntype $(\\mathcal{F}, \\mathcal{D})$, introduced by Beigi, Etesami and Gohari\n(ICALP 2015, SICOMP 2017), is a random sequence $(F_1, \\dots, F_n)$ in\n$\\mathcal{F}^n$, where $F_i$ is a sample from some distribution $d \\in\n\\mathcal{D}$ whose choice may depend on $F_1, \\dots, F_{i-1}$.\nWe show that all GSV source types $(\\mathcal{F}, \\mathcal{D})$ fall into one\nof three categories: (1) non-extractable; (2) extractable with error\n$n^{-\\Theta(1)}$; (3) extractable with error $2^{-\\Omega(n)}$. This rules out\nother error rates like $1/\\log n$ or $2^{-\\sqrt{n}}$.\nWe provide essentially randomness-optimal extraction algorithms for\nextractable sources. Our algorithm for category (2) sources extracts with error\n$\\varepsilon$ from $n = \\mathrm{poly}(1/\\varepsilon)$ samples in time linear in\n$n$. Our algorithm for category (3) sources extracts $m$ bits with error\n$\\varepsilon$ from $n = O(m + \\log 1/\\varepsilon)$ samples in time\n$\\min\\{O(nm2^m),n^{O(\\lvert\\mathcal{F}\\rvert)}\\}$.\nWe also give algorithms for classifying a GSV source type $(\\mathcal{F},\n\\mathcal{D})$: Membership in category (1) can be decided in $\\mathrm{NP}$,\nwhile membership in category (3) is polynomial-time decidable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Personal Food Computer: A new device for controlled-environment agriculture.   Due to their interdisciplinary nature, devices for controlled-environment\nagriculture have the possibility to turn into ideal tools not only to conduct\nresearch on plant phenology but also to create curricula in a wide range of\ndisciplines. Controlled-environment devices are increasing their\nfunctionalities as well as improving their accessibility. Traditionally,\nbuilding one of these devices from scratch implies knowledge in fields such as\nmechanical engineering, digital electronics, programming, and energy\nmanagement. However, the requirements of an effective controlled environment\ndevice for personal use brings new constraints and challenges. This paper\npresents the OpenAg Personal Food Computer (PFC); a low cost desktop size\nplatform, which not only targets plant phenology researchers but also\nhobbyists, makers, and teachers from elementary to high-school levels (K-12).\nThe PFC is completely open-source and it is intended to become a tool that can\nbe used for collective data sharing and plant growth analysis. Thanks to its\nmodular design, the PFC can be used in a large spectrum of activities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An aptamer-biosensor for azole class antifungal drugs.   This report describes the development of an aptamer for sensing azole\nantifungal drugs for therapeutic drug monitoring. Modified Synthetic Evolution\nof Ligands through Exponential Enrichment (SELEX) was used to discover a DNA\naptamer recognizing azole class antifungal drugs. This aptamer undergoes a\nsecondary structural change upon binding to its target molecule as shown\nthrough fluorescence anisotropy-based binding measurements. Experiments using\ncircular dichroism spectroscopy, revealed a unique double G-quadruplex\nstructure that was essential and specific for binding to the azole antifungal\ntarget. Aptamer-functionalized Graphene Field Effect Transistor (GFET) devices\nwere created and used to measure the binding of strength of azole antifungals\nto this surface. In total this aptamer and the supporting sensing platform\ncould provide a valuable tool for improving the treatment of patients with\ninvasive fungal infections.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Counting Multiplicities in a Hypersurface over a Number Field.   We fix a counting function of multiplicities of algebraic points in a\nprojective hypersurface over a number field, and take the sum over all\nalgebraic points of bounded height and fixed degree. An upper bound for the sum\nwith respect to this counting function will be given in terms of the degree of\nthe hypersurface, the dimension of the singular locus, the upper bounds of\nheight, and the degree of the field of definition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "CosmoGAN: creating high-fidelity weak lensing convergence maps using Generative Adversarial Networks.   Inferring model parameters from experimental data is a grand challenge in\nmany sciences, including cosmology. This often relies critically on high\nfidelity numerical simulations, which are prohibitively computationally\nexpensive. The application of deep learning techniques to generative modeling\nis renewing interest in using high dimensional density estimators as\ncomputationally inexpensive emulators of fully-fledged simulations. These\ngenerative models have the potential to make a dramatic shift in the field of\nscientific simulations, but for that shift to happen we need to study the\nperformance of such generators in the precision regime needed for science\napplications. To this end, in this work we apply Generative Adversarial\nNetworks to the problem of generating weak lensing convergence maps. We show\nthat our generator network produces maps that are described by, with high\nstatistical confidence, the same summary statistics as the fully simulated\nmaps.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Structural Analysis and Optimal Design of Distributed System Throttlers.   In this paper, we investigate the performance analysis and synthesis of\ndistributed system throttlers (DST). A throttler is a mechanism that limits the\nflow rate of incoming metrics, e.g., byte per second, network bandwidth usage,\ncapacity, traffic, etc. This can be used to protect a service's backend/clients\nfrom getting overloaded, or to reduce the effects of uncertainties in demand\nfor shared services. We study performance deterioration of DSTs subject to\ndemand uncertainty. We then consider network synthesis problems that aim to\nimprove the performance of noisy DSTs via communication link modifications as\nwell as server update cycle modifications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dependence and dependence structures: estimation and visualization using distance multivariance.   Distance multivariance is a multivariate dependence measure, which can detect\ndependencies between an arbitrary number of random vectors each of which can\nhave a distinct dimension. Here we discuss several new aspects and present a\nconcise overview. We relax the required moment conditions considerably and show\nthat distance multivariance unifies (and extends) distance covariance and the\nHilbert-Schmidt independence criterion HSIC, moreover also the classical linear\ndependence measures: covariance, Pearson's correlation and the RV coefficient\nappear as limiting cases. For measures based on distance multivariance the\ncorresponding resampling tests are introduced, and several related measures are\ndefined: a new multicorrelation which satisfies a natural set of multivariate\ndependence measure axioms and $m$-multivariance which is a new dependence\nmeasure yielding tests for pairwise independence and independence of higher\norder. These tests are computationally feasible and under very mild moment\nconditions they are consistent against all alternatives. Moreover, a general\nvisualization scheme for higher order dependencies is proposed.\nMany illustrative examples are included. All functions for the use of\ndistance multivariance in applications are published in the R-package\n'multivariance'.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "High-speed X-ray imaging spectroscopy system with Zynq SoC for solar observations.   We have developed a system combining a back-illuminated\nComplementary-Metal-Oxide-Semiconductor (CMOS) imaging sensor and Xilinx Zynq\nSystem-on-Chip (SoC) device for a soft X-ray (0.5-10 keV) imaging spectroscopy\nobservation of the Sun to investigate the dynamics of the solar corona. Because\ntypical timescales of energy release phenomena in the corona span a few minutes\nat most, we aim to obtain the corresponding energy spectra and derive the\nphysical parameters, i.e., temperature and emission measure, every few tens of\nseconds or less for future solar X-ray observations. An X-ray photon-counting\ntechnique, with a frame rate of a few hundred frames per second or more, can\nachieve such results. We used the Zynq SoC device to achieve the requirements.\nZynq contains an ARM processor core, which is also known as the Processing\nSystem (PS) part, and a Programmable Logic (PL) part in a single chip. We use\nthe PL and PS to control the sensor and seamless recording of data to a storage\nsystem, respectively. We aim to use the system for the third flight of the\nFocusing Optics Solar X-ray Imager (FOXSI-3) sounding rocket experiment for the\nfirst photon-counting X-ray imaging and spectroscopy of the Sun.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Concave losses for robust dictionary learning.   Traditional dictionary learning methods are based on quadratic convex loss\nfunction and thus are sensitive to outliers. In this paper, we propose a\ngeneric framework for robust dictionary learning based on concave losses. We\nprovide results on composition of concave functions, notably regarding\nsuper-gradient computations, that are key for developing generic dictionary\nlearning algorithms applicable to smooth and non-smooth losses. In order to\nimprove identification of outliers, we introduce an initialization heuristic\nbased on undercomplete dictionary learning. Experimental results using\nsynthetic and real data demonstrate that our method is able to better detect\noutliers, is capable of generating better dictionaries, outperforming\nstate-of-the-art methods such as K-SVD and LC-KSVD.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using deterministic approximations to accelerate SMC for posterior sampling.   Sequential Monte Carlo has become a standard tool for Bayesian Inference of\ncomplex models. This approach can be computationally demanding, especially when\ninitialized from the prior distribution. On the other hand, deter-ministic\napproximations of the posterior distribution are often available with no\ntheoretical guaranties. We propose a bridge sampling scheme starting from such\na deterministic approximation of the posterior distribution and targeting the\ntrue one. The resulting Shortened Bridge Sampler (SBS) relies on a sequence of\ndistributions that is determined in an adaptive way. We illustrate the\nrobustness and the efficiency of the methodology on a large simulation study.\nWhen applied to network datasets, SBS inference leads to different statistical\nconclusions from the one supplied by the standard variational Bayes\napproximation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "EPTL - A temporal logic for weakly consistent systems.   The high availability and scalability of weakly-consistent systems attracts\nsystem designers. Yet, writing correct application code for this type of\nsystems is difficult; even how to specify the intended behavior of such systems\nis still an open question. There has not been established any standard method\nto specify the intended dynamic behavior of a weakly consistent system. There\nexist specifications of various consistency models for distributed and\nconcurrent systems; and the semantics of replicated datatypes like CRDTs have\nbeen specified in axiomatic and operational models based on visibility\nrelations.\nIn this paper, we present a temporal logic, EPTL, that is tailored to specify\nproperties of weakly consistent systems. In contrast to LTL and CTL, EPTL takes\ninto account that operations of weakly consistent systems are in many cases not\nserializable and have to be treated respectively to capture the behavior. We\nembed our temporal logic in Isabelle/HOL and can thereby leverage strong\nsemi-automatic proving capabilities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Is Epicurus the father of Reinforcement Learning?.   The Epicurean Philosophy is commonly thought as simplistic and hedonistic.\nHere I discuss how this is a misconception and explore its link to\nReinforcement Learning. Based on the letters of Epicurus, I construct an\nobjective function for hedonism which turns out to be equivalent of the\nReinforcement Learning objective function when omitting the discount factor. I\nthen discuss how Plato and Aristotle 's views that can be also loosely linked\nto Reinforcement Learning, as well as their weaknesses in relationship to it.\nFinally, I emphasise the close affinity of the Epicurean views and the Bellman\nequation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hidden order and symmetry protected topological states in quantum link ladders.   We show that whereas spin-1/2 one-dimensional U(1) quantum-link models (QLMs)\nare topologically trivial, when implemented in ladder-like lattices these\nmodels may present an intriguing ground-state phase diagram, which includes a\nsymmetry protected topological (SPT) phase that may be readily revealed by\nanalyzing long-range string spin correlations along the ladder legs. We propose\na simple scheme for the realization of spin-1/2 U(1) QLMs based on\nsingle-component fermions loaded in an optical lattice with s- and p-bands,\nshowing that the SPT phase may be experimentally realized by adiabatic\npreparation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Electronic characteristics of ultrathin SrRuO$_3$ films and their relationship with the metal$-$insulator transition.   SrRuO$_3$ (SRO) films are known to exhibit insulating behavior as their\nthickness approaches four unit cells. We employ electron energy$-$loss (EEL)\nspectroscopy to probe the spatially resolved electronic structures of both\ninsulating and conducting SRO to correlate them with the metal$-$insulator\ntransition (MIT). Importantly, the central layer of the ultrathin insulating\nfilm exhibits distinct features from the metallic SRO. Moreover, EEL near edge\nspectra adjacent to the SrTiO$_3$ (STO) substrate or to the capping layer are\nremarkably similar to those of STO. The site$-$projected density of states\nbased on density functional theory (DFT) partially reflects the characteristics\nof the spectra of these layers. These results may provide important information\non the possible influence of STO on the electronic states of ultrathin SRO.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Endpoint Sobolev and BV continuity for maximal operators.   In this paper we investigate some questions related to the continuity of\nmaximal operators in $W^{1,1}$ and $BV$ spaces, complementing some well-known\nboundedness results. Letting $\\widetilde M$ be the one-dimensional uncentered\nHardy-Littlewood maximal operator, we prove that the map $f \\mapsto\n\\big(\\widetilde Mf\\big)'$ is continuous from $W^{1,1}(\\mathbb{R})$ to\n$L^1(\\mathbb{R})$. In the discrete setting, we prove that $\\widetilde M:\nBV(\\mathbb{Z}) \\to BV(\\mathbb{Z})$ is also continuous. For the one-dimensional\nfractional Hardy-Littlewood maximal operator, we prove by means of\ncounterexamples that the corresponding continuity statements do not hold, both\nin the continuous and discrete settings, and for the centered and uncentered\nversions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Calculation of thallium hyperfine anomaly.   We suggest a method to calculate hyperfine anomaly for many-electron atoms\nand ions. At first, we tested this method by calculating hyperfine anomaly for\nhydrogen-like thallium ion and obtained fairly good agreement with analytical\nexpressions. Then we did calculations for the neutral thallium and tested an\nassumption, that the the ratio between the anomalies for $s$ and $p_{1/2}$\nstates is the same for these two systems. Finally, we come up with\nrecommendations about preferable atomic states for the precision measurements\nof the nuclear $g$ factors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lectures on the mean values of functionals -- An elementary introduction to infinite-dimensional probability.   This is an elementary introduction to infinite-dimensional probability. In\nthe lectures, we compute the exact mean values of some functionals on C[0,1]\nand L[0,1] by considering these functionals as infinite-dimensional random\nvariables. The results show that there exist the complete concentration of\nmeasure phenomenon for these mean values since the variances are all zeroes.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Bias Correction For Paid Search In Media Mix Modeling.   Evaluating the return on ad spend (ROAS), the causal effect of advertising on\nsales, is critical to advertisers for understanding the performance of their\nexisting marketing strategy as well as how to improve and optimize it. Media\nMix Modeling (MMM) has been used as a convenient analytical tool to address the\nproblem using observational data. However it is well recognized that MMM\nsuffers from various fundamental challenges: data collection, model\nspecification and selection bias due to ad targeting, among others\n\\citep{chan2017,wolfe2016}.\nIn this paper, we study the challenge associated with measuring the impact of\nsearch ads in MMM, namely the selection bias due to ad targeting. Using causal\ndiagrams of the search ad environment, we derive a statistically principled\nmethod for bias correction based on the \\textit{back-door} criterion\n\\citep{pearl2013causality}. We use case studies to show that the method\nprovides promising results by comparison with results from randomized\nexperiments. We also report a more complex case study where the advertiser had\nspent on more than a dozen media channels but results from a randomized\nexperiment are not available. Both our theory and empirical studies suggest\nthat in some common, practical scenarios, one may be able to obtain an\napproximately unbiased estimate of search ad ROAS.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling of nonlinear audio effects with end-to-end deep neural networks.   In the context of music production, distortion effects are mainly used for\naesthetic reasons and are usually applied to electric musical instruments. Most\nexisting methods for nonlinear modeling are often either simplified or\noptimized to a very specific circuit. In this work, we investigate deep\nlearning architectures for audio processing and we aim to find a general\npurpose end-to-end deep neural network to perform modeling of nonlinear audio\neffects. We show the network modeling various nonlinearities and we discuss the\ngeneralization capabilities among different instruments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Application of $h$-principle to Manifold Calculus.   Manifold calculus is a form of functor calculus that analyzes contravariant\nfunctors from some categories of manifolds to topological spaces by providing\nanalytic approximations to them. In this paper we apply the theory of\nh-principle to construct several examples of analytic functors in this sense.\nWe prove that the analytic approximation of the Lagrangian embeddings functor\n$\\mathrm{emb}_{\\mathrm{Lag}}(-,N)$ is the totally real embeddings functor\n$\\mathrm{emb}_{\\mathrm{TR}}(-,N)$. Under certain conditions we provide a\ngeometric construction for the homotopy fiber of $ \\mathrm{emb}(M,N)\n\\rightarrow \\mathrm{imm}(M,N)$. This construction also provides an example of a\nfunctor which is itself empty when evaluated on most manifolds but it's\nanalytic approximation is almost always non-empty.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "GraphCombEx: A Software Tool for Exploration of Combinatorial Optimisation Properties of Large Graphs.   We present a prototype of a software tool for exploration of multiple\ncombinatorial optimisation problems in large real-world and synthetic complex\nnetworks. Our tool, called GraphCombEx (an acronym of Graph Combinatorial\nExplorer), provides a unified framework for scalable computation and\npresentation of high-quality suboptimal solutions and bounds for a number of\nwidely studied combinatorial optimisation problems. Efficient representation\nand applicability to large-scale graphs and complex networks are particularly\nconsidered in its design. The problems currently supported include maximum\nclique, graph colouring, maximum independent set, minimum vertex clique\ncovering, minimum dominating set, as well as the longest simple cycle problem.\nSuboptimal solutions and intervals for optimal objective values are estimated\nusing scalable heuristics. The tool is designed with extensibility in mind,\nwith the view of further problems and both new fast and high-performance\nheuristics to be added in the future. GraphCombEx has already been successfully\nused as a support tool in a number of recent research studies using\ncombinatorial optimisation to analyse complex networks, indicating its promise\nas a research software tool.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Performance study of SKIROC2 and SKIROC2A with BGA testboard.   SKIROC2 is an ASIC to readout the silicon pad detectors for the\nelectromagnetic calorimeter in the International Linear Collider.\nCharacteristics of SKIROC2 and the new version of SKIROC2A, packaged with BGA,\nare measured with testboards and charge injection. The results on the\nsignal-to-noise ratio of both trigger and ADC output, threshold tuning\ncapability and timing resolution are presented.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Modularity Matters: Learning Invariant Relational Reasoning Tasks.   We focus on two supervised visual reasoning tasks whose labels encode a\nsemantic relational rule between two or more objects in an image: the MNIST\nParity task and the colorized Pentomino task. The objects in the images undergo\nrandom translation, scaling, rotation and coloring transformations. Thus these\ntasks involve invariant relational reasoning. We report uneven performance of\nvarious deep CNN models on these two tasks. For the MNIST Parity task, we\nreport that the VGG19 model soundly outperforms a family of ResNet models.\nMoreover, the family of ResNet models exhibits a general sensitivity to random\ninitialization for the MNIST Parity task. For the colorized Pentomino task, now\nboth the VGG19 and ResNet models exhibit sluggish optimization and very poor\ntest generalization, hovering around 30% test error. The CNN we tested all\nlearn hierarchies of fully distributed features and thus encode the distributed\nrepresentation prior. We are motivated by a hypothesis from cognitive\nneuroscience which posits that the human visual cortex is modularized, and this\nallows the visual cortex to learn higher order invariances. To this end, we\nconsider a modularized variant of the ResNet model, referred to as a Residual\nMixture Network (ResMixNet) which employs a mixture-of-experts architecture to\ninterleave distributed representations with more specialized, modular\nrepresentations. We show that very shallow ResMixNets are capable of learning\neach of the two tasks well, attaining less than 2% and 1% test error on the\nMNIST Parity and the colorized Pentomino tasks respectively. Most importantly,\nthe ResMixNet models are extremely parameter efficient: generalizing better\nthan various non-modular CNNs that have over 10x the number of parameters.\nThese experimental results support the hypothesis that modularity is a robust\nprior for learning invariant relational reasoning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Search Intelligence: Deep Learning For Dominant Category Prediction.   Deep Neural Networks, and specifically fully-connected convolutional neural\nnetworks are achieving remarkable results across a wide variety of domains.\nThey have been trained to achieve state-of-the-art performance when applied to\nproblems such as speech recognition, image classification, natural language\nprocessing and bioinformatics. Most of these deep learning models when applied\nto classification employ the softmax activation function for prediction and aim\nto minimize cross-entropy loss. In this paper, we have proposed a supervised\nmodel for dominant category prediction to improve search recall across all eBay\nclassifieds platforms. The dominant category label for each query in the last\n90 days is first calculated by summing the total number of collaborative clicks\namong all categories. The category having the highest number of collaborative\nclicks for the given query will be considered its dominant category. Second,\neach query is transformed to a numeric vector by mapping each unique word in\nthe query document to a unique integer value; all padded to equal length based\non the maximum document length within the pre-defined vocabulary size. A\nfully-connected deep convolutional neural network (CNN) is then applied for\nclassification. The proposed model achieves very high classification accuracy\ncompared to other state-of-the-art machine learning techniques.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Semantic Cross-Species Derived Data Management Application.   Managing dynamic information in large multi-site, multi-species, and\nmulti-discipline consortia is a challenging task for data management\napplications. Often in academic research studies the goals for informatics\nteams are to build applications that provide extract-transform-load (ETL)\nfunctionality to archive and catalog source data that has been collected by the\nresearch teams. In consortia that cross species and methodological or\nscientific domains, building interfaces that supply data in a usable fashion\nand make intuitive sense to scientists from dramatically different backgrounds\nincreases the complexity for developers. Further, reusing source data from\noutside one's scientific domain is fraught with ambiguities in understanding\nthe data types, analysis methodologies, and how to combine the data with those\nfrom other research teams. We report on the design, implementation, and\nperformance of a semantic data management application to support the NIMH\nfunded Conte Center at the University of California, Irvine. The Center is\ntesting a theory of the consequences of \"fragmented\" (unpredictable, high\nentropy) early-life experiences on adolescent cognitive and emotional outcomes\nin both humans and rodents. It employs cross-species neuroimaging, epigenomic,\nmolecular, and neuroanatomical approaches in humans and rodents to assess the\npotential consequences of fragmented unpredictable experience on brain\nstructure and circuitry. To address this multi-technology, multi-species\napproach, the system uses semantic web techniques based on the Neuroimaging\nData Model (NIDM) to facilitate data ETL functionality. We find this approach\nenables a low-cost, easy to maintain, and semantically meaningful information\nmanagement system, enabling the diverse research teams to access and use the\ndata.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "FAST Adaptive Smoothing and Thresholding for Improved Activation Detection in Low-Signal fMRI.   Functional Magnetic Resonance Imaging is a noninvasive tool used to study\nbrain function. Detecting activation is challenged by many factors, and even\nmore so in low-signal scenarios that arise in the performance of high-level\ncognitive tasks. We provide a fully automated and fast adaptive smoothing and\nthresholding (FAST) algorithm that uses smoothing and extreme value theory on\ncorrelated statistical parametric maps for thresholding. Performance on\nexperiments spanning a range of low-signal settings is very encouraging. The\nmethodology also performs well in a study to identify the cerebral regions that\nperceive only-auditory-reliable and only-visual-reliable speech stimuli as well\nas those that perceive one but not the other.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improving Sharir and Welzl's bound on crossing-free matchings through solving a stronger recurrence.   Sharir and Welzl [1] derived a bound on crossing-free matchings primarily\nbased on solving a recurrence based on the size of the matchings. We show that\nthe recurrence given in Lemma 2.3 in Sharir and Welzl can be improve to\n$(2n-6s)\\textbf{Ma}_{m}(P)\\leq\\frac{68}{3}(s+2)\\textbf{Ma}_{m-1}(P)$ and\n$(3n-7s)\\textbf{Ma}_{m}(P)\\leq44.5(s+2)\\textbf{Ma}_{m-1}(P)$, thereby improving\nthe upper bound for crossing-free matchings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Revealing patterns in HIV viral load data and classifying patients via a novel machine learning cluster summarization method.   HIV RNA viral load (VL) is an important outcome variable in studies of HIV\ninfected persons. There exists only a handful of methods which classify\npatients by viral load patterns. Most methods place limits on the use of viral\nload measurements, are often specific to a particular study design, and do not\naccount for complex, temporal variation. To address this issue, we propose a\nset of four unambiguous computable characteristics (features) of time-varying\nHIV viral load patterns, along with a novel centroid-based classification\nalgorithm, which we use to classify a population of 1,576 HIV positive clinic\npatients into one of five different viral load patterns (clusters) often found\nin the literature: durably suppressed viral load (DSVL), sustained low viral\nload (SLVL), sustained high viral load (SHVL), high viral load suppression\n(HVLS), and rebounding viral load (RVL). The centroid algorithm summarizes\nthese clusters in terms of their centroids and radii. We show that this allows\nnew viral load patterns to be assigned pattern membership based on the distance\nfrom the centroid relative to its radius, which we term radial normalization\nclassification. This method has the benefit of providing an objective and\nquantitative method to assign viral load pattern membership with a concise and\ninterpretable model that aids clinical decision making. This method also\nfacilitates meta-analyses by providing computably distinct HIV categories.\nFinally we propose that this novel centroid algorithm could also be useful in\nthe areas of cluster comparison for outcomes research and data reduction in\nmachine learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal Regulation Response of Batteries Under Cycle Aging Mechanisms.   When providing frequency regulation in a pay-for-performance market,\nbatteries need to carefully balance the trade-off between following regulation\nsignals and their degradation costs in real-time. Existing battery control\nstrategies either do not consider mismatch penalties in pay-for-performance\nmarkets, or cannot accurately account for battery cycle aging mechanism during\noperation. This paper derives an online control policy that minimizes a battery\nowner's operating cost for providing frequency regulation in a\npay-for-performance market. The proposed policy considers an accurate\nelectrochemical battery cycle aging model, and is applicable to most types of\nbattery cells. It has a threshold structure, and achieves near-optimal\nperformance with respect to an offline controller that has complete future\ninformation. We explicitly characterize this gap and show it is independent of\nthe duration of operation. Simulation results with both synthetic and real\nregulation traces are conducted to illustrate the theoretical results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Local Feature Descriptor Learning with Adaptive Siamese Network.   Although the recent progress in the deep neural network has led to the\ndevelopment of learnable local feature descriptors, there is no explicit answer\nfor estimation of the necessary size of a neural network. Specifically, the\nlocal feature is represented in a low dimensional space, so the neural network\nshould have more compact structure. The small networks required for local\nfeature descriptor learning may be sensitive to initial conditions and learning\nparameters and more likely to become trapped in local minima. In order to\naddress the above problem, we introduce an adaptive pruning Siamese\nArchitecture based on neuron activation to learn local feature descriptors,\nmaking the network more computationally efficient with an improved recognition\nrate over more complex networks. Our experiments demonstrate that our learned\nlocal feature descriptors outperform the state-of-art methods in patch\nmatching.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Vandermonde Matrices with Nodes in the Unit Disk and the Large Sieve.   We derive bounds on the extremal singular values and the condition number of\nNxK, with N>=K, Vandermonde matrices with nodes in the unit disk. The\nmathematical techniques we develop to prove our main results are inspired by a\nlink---first established by by Selberg [1] and later extended by Moitra\n[2]---between the extremal singular values of Vandermonde matrices with nodes\non the unit circle and large sieve inequalities. Our main conceptual\ncontribution lies in establishing a connection between the extremal singular\nvalues of Vandermonde matrices with nodes in the unit disk and a novel large\nsieve inequality involving polynomials in z \\in C with |z|<=1. Compared to\nBazán's upper bound on the condition number [3], which, to the best of our\nknowledge, constitutes the only analytical result---available in the\nliterature---on the condition number of Vandermonde matrices with nodes in the\nunit disk, our bound not only takes a much simpler form, but is also sharper\nfor certain node configurations. Moreover, the bound we obtain can be evaluated\nconsistently in a numerically stable fashion, whereas the evaluation of\nBazán's bound requires the solution of a linear system of equations which has\nthe same condition number as the Vandermonde matrix under consideration and can\ntherefore lead to numerical instability in practice. As a byproduct, our\nresult---when particularized to the case of nodes on the unit circle---slightly\nimproves upon the Selberg-Moitra bound.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Separation of the charge density wave and superconducting states by an intermediate semimetal phase in pressurized TaTe2.   In layered transition metal dichalcogenides (LTMDCs) that display both charge\ndensity waves (CDWs) and superconductivity, the superconducting state generally\nemerges directly on suppression of the CDW state. Here, however, we report a\ndifferent observation for pressurized TaTe2, a non-superconducting CDW-bearing\nLTMDC at ambient pressure. We find that a superconducting state does not occur\nin TaTe2 after the full suppression of its CDW state, which we observe at about\n3 GPa, but, rather, a non-superconducting semimetal state is observed. At a\nhigher pressure, ~21 GPa, where both the semimetal state and the corresponding\npositive magnetoresistance effect are destroyed, superconductivity finally\nemerges and remains present up to ~50 GPa, the high pressure limit of our\nmeasurements. Our pressure-temperature phase diagram for TaTe2 demonstrates\nthat the CDW and the superconducting phases in TaTe2 do not directly transform\none to the other, but rather are separated by a semimetal state, - the first\nexperimental case where the CDW and superconducting states are separated by an\nintermediate phase in LTMDC systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Measuring High-Energy Spectra with HAWC.   The High-Altitude Water-Cherenkov (HAWC) experiment is a TeV $\\gamma$-ray\nobservatory located \\unit[4100]{m} above sea level on the Sierra Negra mountain\nin Puebla, Mexico. The detector consists of 300 water-filled tanks, each\ninstrumented with 4 photomultiplier tubes that utilize the water-Cherenkov\ntechnique to detect atmospheric air showers produced by cosmic $\\gamma$ rays.\nConstruction of HAWC was completed in March of 2015. The experiment's wide\ninstantaneous field of view (\\unit[2]{sr}) and high duty cycle (> 95\\%) make it\na powerful survey instrument sensitive to pulsars, supernova remnants, and\nother $\\gamma$-ray sources. The mechanisms of particle acceleration at these\nsources can be studied by analyzing their high-energy spectra. To this end, we\nhave developed an event-by-event energy-reconstruction algorithm using an\nartificial neural network to estimate energies of primary $\\gamma$ rays at\nHAWC. We will present the details of this technique and its performance as well\nas the current progress toward using it to measure energy spectra of\n$\\gamma$-ray sources.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks.   New types of machine learning hardware in development and entering the market\nhold the promise of revolutionizing deep learning in a manner as profound as\nGPUs. However, existing software frameworks and training algorithms for deep\nlearning have yet to evolve to fully leverage the capability of the new wave of\nsilicon. We already see the limitations of existing algorithms for models that\nexploit structured input via complex and instance-dependent control flow, which\nprohibits minibatching. We present an asynchronous model-parallel (AMP)\ntraining algorithm that is specifically motivated by training on networks of\ninterconnected devices. Through an implementation on multi-core CPUs, we show\nthat AMP training converges to the same accuracy as conventional synchronous\ntraining algorithms in a similar number of epochs, but utilizes the available\nhardware more efficiently even for small minibatch sizes, resulting in\nsignificantly shorter overall training times. Our framework opens the door for\nscaling up a new class of deep learning models that cannot be efficiently\ntrained today.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ELDAR, a new method to identify AGN in multi-filter surveys: the ALHAMBRA test-case.   We present ELDAR, a new method that exploits the potential of medium- and\nnarrow-band filter surveys to securely identify active galactic nuclei (AGN)\nand determine their redshifts. Our methodology improves on traditional\napproaches by looking for AGN emission lines expected to be identified against\nthe continuum, thanks to the width of the filters. To assess its performance,\nwe apply ELDAR to the data of the ALHAMBRA survey, which covered an effective\narea of $2.38\\,{\\rm deg}^2$ with 20 contiguous medium-band optical filters down\nto F814W$\\simeq 24.5$. Using two different configurations of ELDAR in which we\nrequire the detection of at least 2 and 3 emission lines, respectively, we\nextract two catalogues of type-I AGN. The first is composed of 585 sources\n($79\\,\\%$ of them spectroscopically-unknown) down to F814W$=22.5$ at $z_{\\rm\nphot}>1$, which corresponds to a surface density of $209\\,{\\rm deg}^{-2}$. In\nthe second, the 494 selected sources ($83\\,\\%$ of them\nspectroscopically-unknown) reach F814W$=23$ at $z_{\\rm phot}>1.5$, for a\ncorresponding number density of $176\\,{\\rm deg}^{-2}$. Then, using samples of\nspectroscopically-known AGN in the ALHAMBRA fields, for the two catalogues we\nestimate a completeness of $73\\,\\%$ and $67\\,\\%$, and a redshift precision of\n$1.01\\,\\%$ and $0.86\\,\\%$ (with outliers fractions of $8.1\\,\\%$ and $5.8\\,\\%$).\nAt $z>2$, where our selection performs best, we reach $85\\,\\%$ and $77\\,\\%$\ncompleteness and we find no contamination from galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Non-cocompact Group Actions and $π_1$-Semistability at Infinity.   A finitely presented 1-ended group $G$ has {\\it semistable fundamental group\nat infinity} if $G$ acts geometrically on a simply connected and locally\ncompact ANR $Y$ having the property that any two proper rays in $Y$ are\nproperly homotopic. This property of $Y$ captures a notion of connectivity at\ninfinity stronger than \"1-ended\", and is in fact a feature of $G$, being\nindependent of choices. It is a fundamental property in the homotopical study\nof finitely presented groups. While many important classes of groups have been\nshown to have semistable fundamental group at infinity, the question of whether\nevery $G$ has this property has been a recognized open question for nearly\nforty years. In this paper we attack the problem by considering a proper {\\it\nbut non-cocompact} action of a group $J$ on such an $Y$. This $J$ would\ntypically be a subgroup of infinite index in the geometrically acting\nover-group $G$; for example $J$ might be infinite cyclic or some other subgroup\nwhose semistability properties are known. We divide the semistability property\nof $G$ into a $J$-part and a \"perpendicular to $J$\" part, and we analyze how\nthese two parts fit together. Among other things, this analysis leads to a\nproof (in a companion paper) that a class of groups previously considered to be\nlikely counter examples do in fact have the semistability property.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Non-Ergodic Delocalization in the Rosenzweig-Porter Model.   We consider the Rosenzweig-Porter model $H = V + \\sqrt{T}\\, \\Phi$, where $V$\nis a $N \\times N$ diagonal matrix, $\\Phi$ is drawn from the $N \\times N$\nGaussian Orthogonal Ensemble, and $N^{-1} \\ll T \\ll 1$. We prove that the\neigenfunctions of $H$ are typically supported in a set of approximately $NT$\nsites, thereby confirming the existence of a previously conjectured non-ergodic\ndelocalized phase. Our proof is based on martingale estimates along the\ncharacteristic curves of the stochastic advection equation satisfied by the\nlocal resolvent of the Brownian motion representation of $H$.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "A Grouping Genetic Algorithm for Joint Stratification and Sample Allocation Designs.   Predicting the cheapest sample size for the optimal stratification in\nmultivariate survey design is a problem in cases where the population frame is\nlarge. A solution exists that iteratively searches for the minimum sample size\nnecessary to meet accuracy constraints in partitions of atomic strata created\nby the Cartesian product of auxiliary variables into larger strata. The optimal\nstratification can be found by testing all possible partitions. However the\nnumber of possible partitions grows exponentially with the number of initial\nstrata. There are alternative ways of modelling this problem, one of the most\nnatural is using Genetic Algorithms (GA). These evolutionary algorithms use\nrecombination, mutation and selection to search for optimal solutions. They\noften converge on optimal or near-optimal solution more quickly than exact\nmethods. We propose a new GA approach to this problem using grouping genetic\noperators instead of traditional operators. The results show a significant\nimprovement in solution quality for similar computational effort, corresponding\nto large monetary savings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Axion detection via Topological Casimir Effect.   We propose a new table-top experimental configuration for the direct\ndetection of dark matter axions with mass in the $(10^{-6} \\rm eV - 10^{-2} \\rm\neV)$ range using non-perturbative effects in a system with non-trivial spatial\ntopology. Different from most experimental setups found in literature on direct\ndark matter axion detection, which relies on $\\dot{\\theta}$ or\n$\\vec{\\nabla}\\theta$, we found that our system is in principle sensitive to a\nstatic $\\theta\\geq 10^{-14}$ and can also be used to set limit on the\nfundamental constant $\\theta_{\\rm QED}$ which becomes the fundamental\nobservable parameter of the Maxwell system if some conditions are met.\nConnection with Witten effect when the induced electric charge $e'$ is\nproportional to $\\theta$ and the magnetic monopole becomes the dyon with\nnon-vanishing $e'=-e \\frac{\\theta}{2\\pi}$ is also discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Convergence of ground state solutions for nonlinear Schrödinger equations on graphs.   We consider the nonlinear Schrödinger equation $-\\Delta u+(\\lambda\na(x)+1)u=|u|^{p-1}u$ on a locally finite graph $G=(V,E)$. We prove via the\nNehari method that if $a(x)$ satisfies certain assumptions, for any\n$\\lambda>1$, the equation admits a ground state solution $u_\\lambda$. Moreover,\nas $\\lambda\\rightarrow \\infty$, the solution $u_\\lambda$ converges to a\nsolution of the Dirichlet problem $-\\Delta u+u=|u|^{p-1}u$ which is defined on\nthe potential well $\\Omega$. We also provide a numerical experiment which\nsolves the equation on a finite graph to illustrate our results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Noncommutative Knörrer type equivalences via noncommutative resolutions of singularities.   We construct Knörrer type equivalences outside of the hypersurface case,\nnamely, between singularity categories of cyclic quotient surface singularities\nand certain finite dimensional local algebras. This generalises Knörrer's\nequivalence for singularities of Dynkin type A (between Krull dimensions $2$\nand $0$) and yields many new equivalences between singularity categories of\nfinite dimensional algebras.\nOur construction uses noncommutative resolutions of singularities, relative\nsingularity categories, and an idea of Hille & Ploog yielding strongly\nquasi-hereditary algebras which we describe explicitly by building on Wemyss's\nwork on reconstruction algebras. Moreover, K-theory gives obstructions to\ngeneralisations of our main result.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Real-Time Adaptive Image Compression.   We present a machine learning-based approach to lossy image compression which\noutperforms all existing codecs, while running in real-time.\nOur algorithm typically produces files 2.5 times smaller than JPEG and JPEG\n2000, 2 times smaller than WebP, and 1.7 times smaller than BPG on datasets of\ngeneric images across all quality levels. At the same time, our codec is\ndesigned to be lightweight and deployable: for example, it can encode or decode\nthe Kodak dataset in around 10ms per image on GPU.\nOur architecture is an autoencoder featuring pyramidal analysis, an adaptive\ncoding module, and regularization of the expected codelength. We also\nsupplement our approach with adversarial training specialized towards use in a\ncompression setting: this enables us to produce visually pleasing\nreconstructions for very low bitrates.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparison of the h-index for Different Fields of Research Using Bootstrap Methodology.   An important disadvantage of the h-index is that typically it cannot take\ninto account the specific field of research of a researcher. Usually sample\npoint estimates of the average and median h-index values for the various fields\nare reported that are highly variable and dependent of the specific samples and\nit would be useful to provide confidence intervals of prediction accuracy. In\nthis paper we apply the non-parametric bootstrap technique for constructing\nconfidence intervals for the h-index for different fields of research. In this\nway no specific assumptions about the distribution of the empirical hindex are\nrequired as well as no large samples since that the methodology is based on\nresampling from the initial sample. The results of the analysis showed\nimportant differences between the various fields. The performance of the\nbootstrap intervals for the mean and median h-index for most fields seems to be\nrather satisfactory as revealed by the performed simulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ultracold atoms in multiple-radiofrequency dressed adiabatic potentials.   We present the first experimental demonstration of a multiple-radiofrequency\ndressed potential for the configurable magnetic confinement of ultracold atoms.\nWe load cold $^{87}$Rb atoms into a double well potential with an adjustable\nbarrier height, formed by three radiofrequencies applied to atoms in a static\nquadrupole magnetic field. Our multiple-radiofrequency approach gives precise\ncontrol over the double well characteristics, including the depth of individual\nwells and the height of the barrier, and enables reliable transfer of atoms\nbetween the available trapping geometries. We have characterised the\nmultiple-radiofrequency dressed system using radiofrequency spectroscopy,\nfinding good agreement with the eigenvalues numerically calculated using\nFloquet theory. This method creates trapping potentials that can be\nreconfigured by changing the amplitudes, polarizations and frequencies of the\napplied dressing fields, and easily extended with additional dressing\nfrequencies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Phase locking the spin precession in a storage ring.   This letter reports the successful use of feedback from a spin polarization\nmeasurement to the revolution frequency of a 0.97 GeV/$c$ bunched and polarized\ndeuteron beam in the Cooler Synchrotron (COSY) storage ring in order to control\nboth the precession rate ($\\approx 121$ kHz) and the phase of the horizontal\npolarization component. Real time synchronization with a radio frequency (rf)\nsolenoid made possible the rotation of the polarization out of the horizontal\nplane, yielding a demonstration of the feedback method to manipulate the\npolarization. In particular, the rotation rate shows a sinusoidal function of\nthe horizontal polarization phase (relative to the rf solenoid), which was\ncontrolled to within a one standard deviation range of $\\sigma = 0.21$ rad. The\nminimum possible adjustment was 3.7 mHz out of a revolution frequency of 753\nkHz, which changes the precession rate by 26 mrad/s. Such a capability meets a\nrequirement for the use of storage rings to look for an intrinsic electric\ndipole moment of charged particles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Measuring scientific buzz.   Keywords are important for information retrieval. They are used to classify\nand sort papers. However, these terms can also be used to study trends within\nand across fields. We want to explore the lifecycle of new keywords. How often\ndo new terms come into existence and how long till they fade out? In this\npaper, we present our preliminary analysis where we measure the burstiness of\nkeywords within the field of AI. We examine 150k keywords in approximately 100k\njournal and conference papers. We find that nearly 80\\% of the keywords die off\nbefore year one for both journals and conferences but that terms last longer in\njournals versus conferences. We also observe time periods of thematic bursts in\nAI -- one where the terms are more neuroscience inspired and one more oriented\nto computational optimization. This work shows promise of using author keywords\nto better understand dynamics of buzz within science.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Subspace Tracking Algorithms for Millimeter Wave MIMO Channel Estimation with Hybrid Beamforming.   This paper proposes the use of subspace tracking algorithms for performing\nMIMO channel estimation at millimeter wave (mmWave) frequencies. Using a\nsubspace approach, we develop a protocol enabling the estimation of the right\n(resp. left) singular vectors at the transmitter (resp. receiver) side; then,\nwe adapt the projection approximation subspace tracking with deflation (PASTd)\nand the orthogonal Oja (OOJA) algorithms to our framework and obtain two\nchannel estimation algorithms. The hybrid analog/digital nature of the\nbeamformer is also explicitly taken into account at the algorithm design stage.\nNumerical results show that the proposed estimation algorithms are effective,\nand that they perform better than two relevant competing alternatives available\nin the open literature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effects of geometrical frustration on ferromagnetism in the Hubbard model on the Shastry-Sutherland lattice.   The small-cluster exact-diagonalization calculations and the projector\nquantum Monte Carlo method are used to examine the competing effects of\ngeometrical frustration and interaction on ferromagnetism in the Hubbard model\non the Shastry-Sutherland lattice. It is shown that the geometrical frustration\nstabilizes the ferromagnetic state at high electron concentrations ($n \\gtrsim\n7/4$), where strong correlations between ferromagnetism and the shape of the\nnoninteracting density of states are observed. In particular, it is found that\nferromagnetism is stabilized only for these values of frustration parameters,\nwhich lead to the single peaked noninterating density of states at the band\nedge. Once, two or more peaks appear in the noninteracting density of states at\nthe band egde the ferromagnetic state is suppressed. This opens a new route\ntowards the understanding of ferromagnetism in strongly correlated systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Semiparametrical Gaussian Processes Learning of Forward Dynamical Models for Navigating in a Circular Maze.   This paper presents a problem of model learning for the purpose of learning\nhow to navigate a ball to a goal state in a circular maze environment with two\ndegrees of freedom. The motion of the ball in the maze environment is\ninfluenced by several non-linear effects such as dry friction and contacts,\nwhich are difficult to model physically. We propose a semiparametric model to\nestimate the motion dynamics of the ball based on Gaussian Process Regression\nequipped with basis functions obtained from physics first principles. The\naccuracy of this semiparametric model is shown not only in estimation but also\nin prediction at n-steps ahead and its compared with standard algorithms for\nmodel learning. The learned model is then used in a trajectory optimization\nalgorithm to compute ball trajectories. We propose the system presented in the\npaper as a benchmark problem for reinforcement and robot learning, for its\ninteresting and challenging dynamics and its relative ease of reproducibility.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A prismatic classifying space.   A qualgebra $G$ is a set having two binary operations that satisfy\ncompatibility conditions which are modeled upon a group under conjugation and\nmultiplication. We develop a homology theory for qualgebras and describe a\nclassifying space for it. This space is constructed from $G$-colored prisms\n(products of simplices) and simultaneously generalizes (and includes)\nsimplicial classifying spaces for groups and cubical classifying spaces for\nquandles. Degenerate cells of several types are added to the regular prismatic\ncells; by duality, these correspond to \"non-rigid\" Reidemeister moves and their\nhigher dimensional analogues. Coupled with $G$-coloring techniques, our\nhomology theory yields invariants of knotted trivalent graphs in $\\mathbb{R}^3$\nand knotted foams in $\\mathbb{R}^4$. We re-interpret these invariants as\nhomotopy classes of maps from $S^2$ or $S^3$ to the classifying space of $G$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Local Algorithms for Hierarchical Dense Subgraph Discovery.   Finding the dense regions of a graph and relations among them is a\nfundamental problem in network analysis. Core and truss decompositions reveal\ndense subgraphs with hierarchical relations. The incremental nature of\nalgorithms for computing these decompositions and the need for global\ninformation at each step of the algorithm hinders scalable parallelization and\napproximations since the densest regions are not revealed until the end. In a\nprevious work, Lu et al. proposed to iteratively compute the $h$-indices of\nneighbor vertex degrees to obtain the core numbers and prove that the\nconvergence is obtained after a finite number of iterations. This work\ngeneralizes the iterative $h$-index computation for truss decomposition as well\nas nucleus decomposition which leverages higher-order structures to generalize\ncore and truss decompositions. In addition, we prove convergence bounds on the\nnumber of iterations. We present a framework of local algorithms to obtain the\ncore, truss, and nucleus decompositions. Our algorithms are local, parallel,\noffer high scalability, and enable approximations to explore time and quality\ntrade-offs. Our shared-memory implementation verifies the efficiency,\nscalability, and effectiveness of our local algorithms on real-world networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unsupervised Body Part Regression via Spatially Self-ordering Convolutional Neural Networks.   Automatic body part recognition for CT slices can benefit various medical\nimage applications. Recent deep learning methods demonstrate promising\nperformance, with the requirement of large amounts of labeled images for\ntraining. The intrinsic structural or superior-inferior slice ordering\ninformation in CT volumes is not fully exploited. In this paper, we propose a\nconvolutional neural network (CNN) based Unsupervised Body part Regression\n(UBR) algorithm to address this problem. A novel unsupervised learning method\nand two inter-sample CNN loss functions are presented. Distinct from previous\nwork, UBR builds a coordinate system for the human body and outputs a\ncontinuous score for each axial slice, representing the normalized position of\nthe body part in the slice. The training process of UBR resembles a\nself-organization process: slice scores are learned from inter-slice\nrelationships. The training samples are unlabeled CT volumes that are abundant,\nthus no extra annotation effort is needed. UBR is simple, fast, and accurate.\nQuantitative and qualitative experiments validate its effectiveness. In\naddition, we show two applications of UBR in network initialization and anomaly\ndetection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Inversion-Based Learning Approach for Improving Impromptu Trajectory Tracking of Robots with Non-Minimum Phase Dynamics.   This paper presents a learning-based approach for impromptu trajectory\ntracking for non-minimum phase systems, i.e., systems with unstable inverse\ndynamics. Inversion-based feedforward approaches are commonly used for\nimproving tracking performance; however, these approaches are not directly\napplicable to non-minimum phase systems due to their inherent instability. In\norder to resolve the instability issue, existing methods have assumed that the\nsystem model is known and used pre-actuation or inverse approximation\ntechniques. In this work, we propose an approach for learning a stable,\napproximate inverse of a non-minimum phase baseline system directly from its\ninput-output data. Through theoretical discussions, simulations, and\nexperiments on two different platforms, we show the stability of our proposed\napproach and its effectiveness for high-accuracy, impromptu tracking. Our\napproach also shows that including more information in the training, as is\ncommonly assumed to be useful, does not lead to better performance but may\ntrigger instability and impact the effectiveness of the overall approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parallel mining of time-faded heavy hitters.   We present PFDCMSS, a novel message-passing based parallel algorithm for\nmining time-faded heavy hitters. The algorithm is a parallel version of the\nrecently published FDCMSS sequential algorithm. We formally prove its\ncorrectness by showing that the underlying data structure, a sketch augmented\nwith a Space Saving stream summary holding exactly two counters, is mergeable.\nWhilst mergeability of traditional sketches derives immediately from theory, we\nshow that merging our augmented sketch is non trivial. Nonetheless, the\nresulting parallel algorithm is fast and simple to implement. To the best of\nour knowledge, PFDCMSS is the first parallel algorithm solving the problem of\nmining time-faded heavy hitters on message-passing parallel architectures.\nExtensive experimental results confirm that PFDCMSS retains the extreme\naccuracy and error bound provided by FDCMSS whilst providing excellent parallel\nscalability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological conjugacy of topological Markov shifts and Ruelle algebras.   We will characterize topologically conjugate two-sided topological Markov\nshifts $(\\bar{X}_A,\\bar{\\sigma}_A)$ in terms of the associated asymptotic\nRuelle $C^*$-algebras ${\\mathcal{R}}_A$ with its commutative $C^*$-subalgebras\n$C(\\bar{X}_A)$ and the canonical circle actions. We will also show that\nextended Ruelle algebras ${\\widetilde{\\mathcal{R}}}_A$, which are purely\ninfinite version of the asymptotic Ruelle algebras, with its commutative\n$C^*$-subalgebras $C(\\bar{X}_A)$ and the canonical torus actions $\\gamma^A$ are\ncomplete invariants for topological conjugacy of two-sided topological Markov\nshifts. We then have a computable topological conjugacy invariant, written in\nterms of the underlying matrix, of a two-sided topological Markov shift by\nusing K-theory of the extended Ruelle algebra. The diagonal action of\n$\\gamma^A$ has a unique KMS-state on ${\\widetilde{\\mathcal{R}}}_A$, which is an\nextension of the Parry measure on $\\bar{X}_A$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "3D Human Pose Estimation on a Configurable Bed from a Pressure Image.   Robots have the potential to assist people in bed, such as in healthcare\nsettings, yet bedding materials like sheets and blankets can make observation\nof the human body difficult for robots. A pressure-sensing mat on a bed can\nprovide pressure images that are relatively insensitive to bedding materials.\nHowever, prior work on estimating human pose from pressure images has been\nrestricted to 2D pose estimates and flat beds. In this work, we present two\nconvolutional neural networks to estimate the 3D joint positions of a person in\na configurable bed from a single pressure image. The first network directly\noutputs 3D joint positions, while the second outputs a kinematic model that\nincludes estimated joint angles and limb lengths. We evaluated our networks on\ndata from 17 human participants with two bed configurations: supine and seated.\nOur networks achieved a mean joint position error of 77 mm when tested with\ndata from people outside the training set, outperforming several baselines. We\nalso present a simple mechanical model that provides insight into ambiguity\nassociated with limbs raised off of the pressure mat, and demonstrate that\nMonte Carlo dropout can be used to estimate pose confidence in these\nsituations. Finally, we provide a demonstration in which a mobile manipulator\nuses our network's estimated kinematic model to reach a location on a person's\nbody in spite of the person being seated in a bed and covered by a blanket.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Safer Classification by Synthesis.   The discriminative approach to classification using deep neural networks has\nbecome the de-facto standard in various fields. Complementing recent\nreservations about safety against adversarial examples, we show that\nconventional discriminative methods can easily be fooled to provide incorrect\nlabels with very high confidence to out of distribution examples. We posit that\na generative approach is the natural remedy for this problem, and propose a\nmethod for classification using generative models. At training time, we learn a\ngenerative model for each class, while at test time, given an example to\nclassify, we query each generator for its most similar generation, and select\nthe class corresponding to the most similar one. Our approach is general and\ncan be used with expressive models such as GANs and VAEs. At test time, our\nmethod accurately \"knows when it does not know,\" and provides resilience to out\nof distribution examples while maintaining competitive performance for standard\nexamples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Perovskite Substrates Boost the Thermopower of Cobaltate Thin Films at High Temperatures.   Transition metal oxides are promising candidates for thermoelectric\napplications, because they are stable at high temperature and because strong\nelectronic correlations can generate large Seebeck coefficients, but their\nthermoelectric power factors are limited by the low electrical conductivity. We\nreport transport measurements on Ca3Co4O9 films on various perovskite\nsubstrates and show that reversible incorporation of oxygen into SrTiO3 and\nLaAlO3 substrates activates a parallel conduction channel for p-type carriers,\ngreatly enhancing the thermoelectric performance of the film-substrate system\nat temperatures above 450 °C. Thin-film structures that take advantage of\nboth electronic correlations and the high oxygen mobility of transition metal\noxides thus open up new perspectives for thermopower generation at high\ntemperature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An Exploration of Approaches to Integrating Neural Reranking Models in Multi-Stage Ranking Architectures.   We explore different approaches to integrating a simple convolutional neural\nnetwork (CNN) with the Lucene search engine in a multi-stage ranking\narchitecture. Our models are trained using the PyTorch deep learning toolkit,\nwhich is implemented in C/C++ with a Python frontend. One obvious integration\nstrategy is to expose the neural network directly as a service. For this, we\nuse Apache Thrift, a software framework for building scalable cross-language\nservices. In exploring alternative architectures, we observe that once trained,\nthe feedforward evaluation of neural networks is quite straightforward.\nTherefore, we can extract the parameters of a trained CNN from PyTorch and\nimport the model into Java, taking advantage of the Java Deeplearning4J library\nfor feedforward evaluation. This has the advantage that the entire end-to-end\nsystem can be implemented in Java. As a third approach, we can extract the\nneural network from PyTorch and \"compile\" it into a C++ program that exposes a\nThrift service. We evaluate these alternatives in terms of performance (latency\nand throughput) as well as ease of integration. Experiments show that\nfeedforward evaluation of the convolutional neural network is significantly\nslower in Java, while the performance of the compiled C++ network does not\nconsistently beat the PyTorch implementation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "BMO estimate of lacunary Fourier series on nonabelian discrete groups.   We show that the classical equivalence between the BMO norm and the $L^2$\nnorm of a lacunary Fourier series has an analogue on any discrete group $G$\nequipped with a conditionally negative function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological Perspectives on Statistical Quantities I.   In statistics cumulants are defined to be functions that measure the linear\nindependence of random variables. In the non-communicative case the Boolean\ncumulants can be described as functions that measure deviation of a map between\nalgebras from being an algebra morphism. In Algebraic topology maps that are\nhomotopic to being algebra morphisms are studied using the theory of $A_\\infty$\nalgebras. In this paper we will explore the link between these two points of\nviews on maps between algebras that are not algebra maps.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Planning with Multiple Biases.   Recent work has considered theoretical models for the behavior of agents with\nspecific behavioral biases: rather than making decisions that optimize a given\npayoff function, the agent behaves inefficiently because its decisions suffer\nfrom an underlying bias. These approaches have generally considered an agent\nwho experiences a single behavioral bias, studying the effect of this bias on\nthe outcome.\nIn general, however, decision-making can and will be affected by multiple\nbiases operating at the same time. How do multiple biases interact to produce\nthe overall outcome? Here we consider decisions in the presence of a pair of\nbiases exhibiting an intuitively natural interaction: present bias -- the\ntendency to value costs incurred in the present too highly -- and sunk-cost\nbias -- the tendency to incorporate costs experienced in the past into one's\nplans for the future.\nWe propose a theoretical model for planning with this pair of biases, and we\nshow how certain natural behavioral phenomena can arise in our model only when\nagents exhibit both biases. As part of our model we differentiate between\nagents that are aware of their biases (sophisticated) and agents that are\nunaware of them (naive). Interestingly, we show that the interaction between\nthe two biases is quite complex: in some cases, they mitigate each other's\neffects while in other cases they might amplify each other. We obtain a number\nof further results as well, including the fact that the planning problem in our\nmodel for an agent experiencing and aware of both biases is computationally\nhard in general, though tractable under more relaxed assumptions.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Mean field limits for nonlinear spatially extended hawkes processes with exponential memory kernels.   We consider spatially extended systems of interacting nonlinear Hawkes\nprocesses modeling large systems of neurons placed in Rd and study the\nassociated mean field limits. As the total number of neurons tends to infinity,\nwe prove that the evolution of a typical neuron, attached to a given spatial\nposition, can be described by a nonlinear limit differential equation driven by\na Poisson random measure. The limit process is described by a neural field\nequation. As a consequence, we provide a rigorous derivation of the neural\nfield equation based on a thorough mean field analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Well-posedness and dispersive decay of small data solutions for the Benjamin-Ono equation.   This article represents a first step toward understanding the long time\ndynamics of solutions for the Benjamin-Ono equation. While this problem is\nknown to be both completely integrable and globally well-posed in $L^2$, much\nless seems to be known concerning its long time dynamics. Here, we prove that\nfor small localized data the solutions have (nearly) dispersive dynamics almost\nglobally in time. An additional objective is to revisit the $L^2$ theory for\nthe Benjamin-Ono equation and provide a simpler, self-contained approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effective holographic theory of charge density waves.   We use Gauge/Gravity duality to write down an effective low energy\nholographic theory of charge density waves. We consider a simple gravity model\nwhich breaks translations spontaneously in the dual field theory in a\nhomogeneous manner, capturing the low energy dynamics of phonons coupled to\nconserved currents. We first focus on the leading two-derivative action, which\nleads to excited states with non-zero strain. We show that including subleading\nquartic derivative terms leads to dynamical instabilities of AdS$_2$\ntranslation invariant states and to stable phases breaking translations\nspontaneously. We compute analytically the real part of the electric\nconductivity. The model allows to construct Lifshitz-like hyperscaling\nviolating quantum critical ground states breaking translations spontaneously.\nAt these critical points, the real part of the dc conductivity can be metallic\nor insulating.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Conformer-selection by matter-wave interference.   We establish that matter-wave interference at near-resonant ultraviolet\noptical gratings can be used to spatially separate individual conformers of\ncomplex molecules. Our calculations show that the conformational purity of the\nprepared beam can be close to 100% and that all molecules remain in their\nelectronic ground state. The proposed technique is independent of the dipole\nmoment and the spin of the molecule and thus paves the way for\nstructure-sensitive experiments with hydrocarbons and biomolecules, such as\nneurotransmitters and hormones, which evaded conformer-pure isolation so far",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An Architecture for Embedded Systems Supporting Assisted Living.   The rise in life expectancy is one of the great achievements of the twentieth\ncentury. This phenomenon originates a still increasing interest in Ambient\nAssisted Living (AAL) technological solutions that may support people in their\ndaily routines allowing an independent and safe lifestyle as long as possible.\nAAL systems generally acquire data from the field and reason on them and the\ncontext to accomplish their tasks. Very often, AAL systems are vertical\nsolutions, thus making hard their reuse and adaptation to different domains\nwith respect to the ones for which they have been developed. In this paper we\npropose an architectural solution that allows the acquisition level of an ALL\nsystem to be easily built, configured, and extended without affecting the\nreasoning level of the system. We experienced our proposal in a fall detection\nsystem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Visual Entailment: A Novel Task for Fine-Grained Image Understanding.   Existing visual reasoning datasets such as Visual Question Answering (VQA),\noften suffer from biases conditioned on the question, image or answer\ndistributions. The recently proposed CLEVR dataset addresses these limitations\nand requires fine-grained reasoning but the dataset is synthetic and consists\nof similar objects and sentence structures across the dataset.\nIn this paper, we introduce a new inference task, Visual Entailment (VE) -\nconsisting of image-sentence pairs whereby a premise is defined by an image,\nrather than a natural language sentence as in traditional Textual Entailment\ntasks. The goal of a trained VE model is to predict whether the image\nsemantically entails the text. To realize this task, we build a dataset SNLI-VE\nbased on the Stanford Natural Language Inference corpus and Flickr30k dataset.\nWe evaluate various existing VQA baselines and build a model called Explainable\nVisual Entailment (EVE) system to address the VE task. EVE achieves up to 71%\naccuracy and outperforms several other state-of-the-art VQA based models.\nFinally, we demonstrate the explainability of EVE through cross-modal attention\nvisualizations. The SNLI-VE dataset is publicly available at\nthis https URL necla-ml/SNLI-VE.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Social Media Analysis For Organizations: Us Northeastern Public And State Libraries Case Study.   Social networking sites such as Twitter have provided a great opportunity for\norganizations such as public libraries to disseminate information for public\nrelations purposes. However, there is a need to analyze vast amounts of social\nmedia data. This study presents a computational approach to explore the content\nof tweets posted by nine public libraries in the northeastern United States of\nAmerica. In December 2017, this study extracted more than 19,000 tweets from\nthe Twitter accounts of seven state libraries and two urban public libraries.\nComputational methods were applied to collect the tweets and discover\nmeaningful themes. This paper shows how the libraries have used Twitter to\nrepresent their services and provides a starting point for different\norganizations to evaluate the themes of their public tweets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Symmetries and regularity for holomorphic maps between balls.   Let $f:{\\mathbb B}^n \\to {\\mathbb B}^N$ be a holomorphic map. We study\nsubgroups $\\Gamma_f \\subseteq {\\rm Aut}({\\mathbb B}^n)$ and $T_f \\subseteq {\\rm\nAut}({\\mathbb B}^N)$. When $f$ is proper, we show both these groups are Lie\nsubgroups. When $\\Gamma_f$ contains the center of ${\\bf U}(n)$, we show that\n$f$ is spherically equivalent to a polynomial. When $f$ is minimal we show that\nthere is a homomorphism $\\Phi:\\Gamma_f \\to T_f$ such that $f$ is equivariant\nwith respect to $\\Phi$. To do so, we characterize minimality via the triviality\nof a third group $H_f$. We relate properties of ${\\rm Ker}(\\Phi)$ to older\nresults on invariant proper maps between balls. When $f$ is proper but\ncompletely non-rational, we show that either both $\\Gamma_f$ and $T_f$ are\nfinite or both are noncompact.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Question Answering through Transfer Learning from Large Fine-grained Supervision Data.   We show that the task of question answering (QA) can significantly benefit\nfrom the transfer learning of models trained on a different large, fine-grained\nQA dataset. We achieve the state of the art in two well-studied QA datasets,\nWikiQA and SemEval-2016 (Task 3A), through a basic transfer learning technique\nfrom SQuAD. For WikiQA, our model outperforms the previous best model by more\nthan 8%. We demonstrate that finer supervision provides better guidance for\nlearning lexical and syntactic information than coarser supervision, through\nquantitative results and visual analysis. We also show that a similar transfer\nlearning procedure achieves the state of the art on an entailment task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Virtual-to-Real: Learning to Control in Visual Semantic Segmentation.   Collecting training data from the physical world is usually time-consuming\nand even dangerous for fragile robots, and thus, recent advances in robot\nlearning advocate the use of simulators as the training platform.\nUnfortunately, the reality gap between synthetic and real visual data prohibits\ndirect migration of the models trained in virtual worlds to the real world.\nThis paper proposes a modular architecture for tackling the virtual-to-real\nproblem. The proposed architecture separates the learning model into a\nperception module and a control policy module, and uses semantic image\nsegmentation as the meta representation for relating these two modules. The\nperception module translates the perceived RGB image to semantic image\nsegmentation. The control policy module is implemented as a deep reinforcement\nlearning agent, which performs actions based on the translated image\nsegmentation. Our architecture is evaluated in an obstacle avoidance task and a\ntarget following task. Experimental results show that our architecture\nsignificantly outperforms all of the baseline methods in both virtual and real\nenvironments, and demonstrates a faster learning curve than them. We also\npresent a detailed analysis for a variety of variant configurations, and\nvalidate the transferability of our modular architecture.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Fast and Slow: PROPEDEUTICA for Real-time Malware Detection.   In this paper, we introduce and evaluate PROPEDEUTICA, a novel methodology\nand framework for efficient and effective real-time malware detection,\nleveraging the best of conventional machine learning (ML) and deep learning\n(DL) algorithms. In PROPEDEUTICA, all software processes in the system start\nexecution subjected to a conventional ML detector for fast classification. If a\npiece of software receives a borderline classification, it is subjected to\nfurther analysis via more performance expensive and more accurate DL methods,\nvia our newly proposed DL algorithm DEEPMALWARE. Further, we introduce delays\nto the execution of software subjected to deep learning analysis as a way to\n\"buy time\" for DL analysis and to rate-limit the impact of possible malware in\nthe system. We evaluated PROPEDEUTICA with a set of 9,115 malware samples and\n877 commonly used benign software samples from various categories for the\nWindows OS. Our results show that the false positive rate for conventional ML\nmethods can reach 20%, and for modern DL methods it is usually below 6%.\nHowever, the classification time for DL can be 100X longer than conventional ML\nmethods. PROPEDEUTICA improved the detection F1-score from 77.54% (conventional\nML method) to 90.25%, and reduced the detection time by 54.86%. Further, the\npercentage of software subjected to DL analysis was approximately 40% on\naverage. Further, the application of delays in software subjected to ML reduced\nthe detection time by approximately 10%. Finally, we found and discussed a\ndiscrepancy between the detection accuracy offline (analysis after all traces\nare collected) and on-the-fly (analysis in tandem with trace collection). Our\ninsights show that conventional ML and modern DL-based malware detectors in\nisolation cannot meet the needs of efficient and effective malware detection:\nhigh accuracy, low false positive rate, and short classification time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accelerated Primal-Dual Proximal Block Coordinate Updating Methods for Constrained Convex Optimization.   Block Coordinate Update (BCU) methods enjoy low per-update computational\ncomplexity because every time only one or a few block variables would need to\nbe updated among possibly a large number of blocks. They are also easily\nparallelized and thus have been particularly popular for solving problems\ninvolving large-scale dataset and/or variables. In this paper, we propose a\nprimal-dual BCU method for solving linearly constrained convex program in\nmulti-block variables. The method is an accelerated version of a primal-dual\nalgorithm proposed by the authors, which applies randomization in selecting\nblock variables to update and establishes an $O(1/t)$ convergence rate under\nweak convexity assumption. We show that the rate can be accelerated to\n$O(1/t^2)$ if the objective is strongly convex. In addition, if one block\nvariable is independent of the others in the objective, we then show that the\nalgorithm can be modified to achieve a linear rate of convergence. The\nnumerical experiments show that the accelerated method performs stably with a\nsingle set of parameters while the original method needs to tune the parameters\nfor different datasets in order to achieve a comparable level of performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evidence accumulation in a Laplace domain decision space.   Evidence accumulation models of simple decision-making have long assumed that\nthe brain estimates a scalar decision variable corresponding to the\nlog-likelihood ratio of the two alternatives. Typical neural implementations of\nthis algorithmic cognitive model assume that large numbers of neurons are each\nnoisy exemplars of the scalar decision variable. Here we propose a neural\nimplementation of the diffusion model in which many neurons construct and\nmaintain the Laplace transform of the distance to each of the decision bounds.\nAs in classic findings from brain regions including LIP, the firing rate of\nneurons coding for the Laplace transform of net accumulated evidence grows to a\nbound during random dot motion tasks. However, rather than noisy exemplars of a\nsingle mean value, this approach makes the novel prediction that firing rates\ngrow to the bound exponentially, across neurons there should be a distribution\nof different rates. A second set of neurons records an approximate inversion of\nthe Laplace transform, these neurons directly estimate net accumulated\nevidence. In analogy to time cells and place cells observed in the hippocampus\nand other brain regions, the neurons in this second set have receptive fields\nalong a \"decision axis.\" This finding is consistent with recent findings from\nrodent recordings. This theoretical approach places simple evidence\naccumulation models in the same mathematical language as recent proposals for\nrepresenting time and space in cognitive models for memory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Imaginary time, shredded propagator method for large-scale GW calculations.   The GW method is a many-body approach capable of providing quasiparticle\nbands for realistic systems spanning physics, chemistry, and materials science.\nDespite its power, GW is not routinely applied to large complex materials due\nto its computational expense. We perform an exact recasting of the GW\npolarizability and the self-energy as Laplace integrals over imaginary time\npropagators. We then \"shred\" the propagators (via energy windowing) and\napproximate them in a controlled manner by using Gauss-Laguerre quadrature and\ndiscrete variable methods to treat the imaginary time propagators in real\nspace. The resulting cubic scaling GW method has a sufficiently small prefactor\nto outperform standard quartic scaling methods on small systems (>=10 atoms)\nand also represents a substantial improvement over several other cubic methods\ntested. This approach is useful for evaluating quantum mechanical response\nfunction involving large sums containing energy (difference) denominators.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Optical properties of a four-layer waveguiding nanocomposite structure in near-IR regime.   The theoretical study of the optical properties of TE- and TM- modes in a\nfour-layer structure composed of the magneto-optical yttrium iron garnet\nguiding layer on a dielectric substrate covered by planar nanocomposite guiding\nmultilayer is presented. The dispersion equation is obtained taking into\naccount the bigyrotropic properties of yttrium-iron garnet, and an original\nalgorithm for the guided modes identification is proposed. The dispersion\nspectra are analyzed and the energy flux distributions across the structure are\ncalculated. The fourfold difference between the partial power fluxes within the\nwaveguide layers is achieved in the wavelength range of 200 nm.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Precision of Evaluation Methods in White Light Interferometry: Correlogram Correlation Method.   In this paper we promote a method for the evaluation of a surface topography\nwhich we call the correlogram correlation method. Employing a theoretical\nanalysis as well as numerical simulations the method is proven to be the most\naccurate among available evaluation algorithms in the common case of\nuncorrelated noise. Examples illustrate the superiority of the correlogram\ncorrelation method over the common envelope and phase methods.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "The Global Optimization Geometry of Low-Rank Matrix Optimization.   This paper considers general rank-constrained optimization problems that\nminimize a general objective function $f(X)$ over the set of rectangular\n$n\\times m$ matrices that have rank at most $r$. To tackle the rank constraint\nand also to reduce the computational burden, we factorize $X$ into $UV^T$ where\n$U$ and $V$ are $n\\times r$ and $m\\times r$ matrices, respectively, and then\noptimize over the small matrices $U$ and $V$. We characterize the global\noptimization geometry of the nonconvex factored problem and show that the\ncorresponding objective function satisfies the robust strict saddle property as\nlong as the original objective function $f$ satisfies restricted strong\nconvexity and smoothness properties, ensuring global convergence of many local\nsearch algorithms (such as noisy gradient descent) in polynomial time for\nsolving the factored problem. We also provide a comprehensive analysis for the\noptimization geometry of a matrix factorization problem where we aim to find\n$n\\times r$ and $m\\times r$ matrices $U$ and $V$ such that $UV^T$ approximates\na given matrix $X^\\star$. Aside from the robust strict saddle property, we show\nthat the objective function of the matrix factorization problem has no spurious\nlocal minima and obeys the strict saddle property not only for the\nexact-parameterization case where $rank(X^\\star) = r$, but also for the\nover-parameterization case where $rank(X^\\star) < r$ and the\nunder-parameterization case where $rank(X^\\star) > r$. These geometric\nproperties imply that a number of iterative optimization algorithms (such as\ngradient descent) converge to a global solution with random initialization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Flux-flow and vortex-glass phase in iron pnictide BaFe$_{2-x}$Ni$_x$As$_2$ single crystals with $T_c$ $\\sim$ 20 K.   We analysed the flux-flow region of isofield magneto resistivity data\nobtained on three crystals of BaFe$_{2-x}$Ni$_x$As$_2$ with $T_c$$\\sim$20 K for\nthree different geometries relative to the angle formed between the applied\nmagnetic field and the c-axis of the crystals. The field dependent activation\nenergy, $U_0$, was obtained from the TAFF and modified vortex-glass models,\nwhich were compared with the values of $U_0$ obtained from flux-creep available\nin the literature. We observed that the $U_0$ obtained from the TAFF model show\ndeviations among the different crystals, while the correspondent glass lines\nobtained from the vortex glass model are virtually coincident. It is shown that\nthe data is well explained by the modified vortex glass model, allowing to\nextract values of $T_g$, the glass transition temperature, and $T^*$, a\ntemperature which scales with the mean field critical temperature $T_c(H)$. The\nresulting glass lines obey the anisotropic Ginzburg-Landau theory and are well\nfitted by a theory developed in the literature by considering the effect of\ndisorder.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Exponential growth of homotopy groups of suspended finite complexes.   We study the asymptotic behavior of the homotopy groups of simply connected\nfinite $p$-local complexes, and define a space to be locally hyperbolic if its\nhomotopy groups have exponential growth. Under some certain conditions related\nto the functorial decomposition of loop suspension, we prove that the suspended\nfinite complexes are locally hyperbolic if suitable but accessible information\nof the homotopy groups is known. In particular, we prove that Moore spaces are\nlocally hyperbolic, and other candidates are also given.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Enhancing TCP End-to-End Performance in Millimeter-Wave Communications.   Recently, millimeter-wave (mmWave) communications have received great\nattention due to the availability of large spectrum resources. Nevertheless,\ntheir impact on TCP performance has been overlooked, which is observed that the\nsaid TCP performance collapse occurs owing to the significant difference in\nsignal quality between LOS and NLOS links. We propose a novel TCP design for\nmmWave communications, a mmWave performance enhancing proxy (mmPEP), enabling\nnot only to overcome TCP performance collapse but also exploit the properties\nof mmWave channels. The base station installs the TCP proxy to operate the two\nfunctionalities called Ack management and batch retransmission. Specifically,\nthe proxy sends the said early-Ack to the server not to decrease its sending\nrate even in the NLOS status. In addition, when a packet-loss is detected, the\nproxy retransmits not only lost packets but also the certain number of the\nfollowing packets expected to be lost too. It is verified by ns-3 simulation\nthat compared with benchmark, mmPEP enhances the end-to-end rate and packet\ndelivery ratio by maintaining high sending rate with decreasing the loss\nrecovery time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Power of Symmetric Linear Programs.   We consider families of symmetric linear programs (LPs) that decide a\nproperty of graphs (or other relational structures) in the sense that, for each\nsize of graph, there is an LP defining a polyhedral lift that separates the\ninteger points corresponding to graphs with the property from those\ncorresponding to graphs without the property. We show that this is equivalent,\nwith at most polynomial blow-up in size, to families of symmetric Boolean\ncircuits with threshold gates. In particular, when we consider polynomial-size\nLPs, the model is equivalent to definability in a non-uniform version of\nfixed-point logic with counting (FPC). Known upper and lower bounds for FPC\napply to the non-uniform version. In particular, this implies that the class of\ngraphs with perfect matchings has polynomial-size symmetric LPs while we obtain\nan exponential lower bound for symmetric LPs for the class of Hamiltonian\ngraphs. We compare and contrast this with previous results (Yannakakis 1991)\nshowing that any symmetric LPs for the matching and TSP polytopes have\nexponential size. As an application, we establish that for random, uniformly\ndistributed graphs, polynomial-size symmetric LPs are as powerful as general\nBoolean circuits. We illustrate the effect of this on the well-studied\nplanted-clique problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The GENIUS Approach to Robust Mendelian Randomization Inference.   Mendelian randomization (MR) is a popular instrumental variable (IV)\napproach. A key IV identification condition known as the exclusion restriction\nrequires no direct effect of an IV on the outcome not through the exposure\nwhich is unrealistic in most MR analyses. As a result, possible violation of\nthe exclusion restriction can seldom be ruled out in such studies. To address\nthis concern, we introduce a new class of IV estimators which are robust to\nviolation of the exclusion restriction under a large collection of data\ngenerating mechanisms consistent with parametric models commonly assumed in the\nMR literature. Our approach named \"MR G-Estimation under No Interaction with\nUnmeasured Selection\" (MR GENIUS) may be viewed as a modification to Robins'\nG-estimation approach that is robust to both additive unmeasured confounding\nand violation of the exclusion restriction assumption. We also establish that\nestimation with MR GENIUS may also be viewed as a robust generalization of the\nwell-known Lewbel estimator for a triangular system of structural equations\nwith endogeneity. Specifically, we show that unlike Lewbel estimation, MR\nGENIUS is under fairly weak conditions also robust to unmeasured confounding of\nthe effects of the genetic IVs, another possible violation of a key IV\nIdentification condition. Furthermore, while Lewbel estimation involves\nspecification of linear models both for the outcome and the exposure, MR GENIUS\ngenerally does not require specification of a structural model for the direct\neffect of invalid IVs on the outcome, therefore allowing the latter model to be\nunrestricted. Finally, unlike Lewbel estimation, MR GENIUS is shown to equally\napply for binary, discrete or continuous exposure and outcome variables and can\nbe used under prospective sampling, or retrospective sampling such as in a\ncase-control study.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal Frequency Ranges for Sub-Microsecond Precision Pulsar Timing.   Precision pulsar timing requires optimization against measurement errors and\nastrophysical variance from the neutron stars themselves and the interstellar\nmedium. We investigate optimization of arrival time precision as a function of\nradio frequency and bandwidth. We find that increases in bandwidth that reduce\nthe contribution from receiver noise are countered by the strong chromatic\ndependence of interstellar effects and intrinsic pulse-profile evolution. The\nresulting optimal frequency range is therefore telescope and pulsar dependent.\nWe demonstrate the results for five pulsars included in current pulsar timing\narrays and determine that they are not optimally observed at current center\nfrequencies. For those objects, we find that better choices of total bandwidth\nas well as center frequency can improve the arrival-time precision. Wideband\nreceivers centered at somewhat higher frequencies with respect to the currently\nadopted receivers can reduce required overall integration times and provide\nsignificant improvements in arrival time uncertainty by a factor of ~sqrt(2) in\nmost cases, assuming a fixed integration time. We also discuss how timing\nprograms can be extended to pulsars with larger dispersion measures through the\nuse of higher-frequency observations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Chern classes and Gromov--Witten theory of projective bundles.   We prove that the Gromov--Witten theory (GWT) of a projective bundle can be\ndetermined by the Chern classes and the GWT of the base. It completely answers\na question raised in a previous paper (arXiv:1607.00740). Its consequences\ninclude that the GWT of the blow-up of X at a smooth subvariety Z is uniquely\ndetermined by GWT of X, Z plus some topological data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Photonic topological pumping through the edges of a dynamical four-dimensional quantum Hall system.   When a two-dimensional electron gas is exposed to a perpendicular magnetic\nfield and an in-plane electric field, its conductance becomes quantized in the\ntransverse in-plane direction: this is known as the quantum Hall (QH) effect.\nThis effect is a result of the nontrivial topology of the system's electronic\nband structure, where an integer topological invariant known as the first Chern\nnumber leads to the quantization of the Hall conductance. Interestingly, it was\nshown that the QH effect can be generalized mathematically to four spatial\ndimensions (4D), but this effect has never been realized for the obvious reason\nthat experimental systems are bound to three spatial dimensions. In this work,\nwe harness the high tunability and control offered by photonic waveguide arrays\nto experimentally realize a dynamically-generated 4D QH system using a 2D array\nof coupled optical waveguides. The inter-waveguide separation is constructed\nsuch that the propagation of light along the device samples over\nhigher-dimensional momenta in the directions orthogonal to the two physical\ndimensions, thus realizing a 2D topological pump. As a result, the device's\nband structure is associated with 4D topological invariants known as second\nChern numbers which support a quantized bulk Hall response with a 4D symmetry.\nIn a finite-sized system, the 4D topological bulk response is carried by\nlocalized edges modes that cross the sample as a function of of the modulated\nauxiliary momenta. We directly observe this crossing through photon pumping\nfrom edge-to-edge and corner-to-corner of our system. These are equivalent to\nthe pumping of charge across a 4D system from one 3D hypersurface to the\nopposite one and from one 2D hyperedge to another, and serve as first\nexperimental realization of higher-dimensional topological physics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reynolds number dependence of the structure functions in homogeneous turbulence.   We compare the predictions of stochastic closure theory (SCT) with\nexperimental measurements of homogeneous turbulence made in the Variable\nDensity Turbulence Tunnel (VDTT) at the Max Planck Institute for Dynamics and\nSelf-Organization in Gottingen. While the general form of SCT contains\ninfinitely many free parameters, the data permit us to reduce the number to\nseven, only three of which are active over the entire inertial range. Of these\nthree, one parameter characterizes the variance of the mean field noise in SCT\nand another characterizes the rate in the large deviations of the mean. The\nthird parameter is the decay exponent of the Fourier variables in the Fourier\nexpansion of the noise, which characterizes the smoothness of the turbulent\nvelocity. SCT compares favorably with velocity structure functions measured in\nthe experiment. We considered even-order structure functions ranging in order\nfrom two to eight as well as the third-order structure functions at five\nTaylor-Reynolds numbers (Rl) between 110 and 1450. The comparisons highlight\nseveral advantages of the SCT, which include explicit predictions for the\nstructure functions at any scale and for any Reynolds number. We observed that\nfinite-Rl corrections, for instance, are important even at the highest Reynolds\nnumbers produced in the experiments. SCT gives us the correct basis function to\nexpress all the moments of the velocity differences in turbulence in Fourier\nspace. The SCT produces the coefficients of the series and so determines the\nstatistical quantities that characterize the small scales in turbulence. It\nalso characterizes the random force acting on the fluid in the stochastic\nNavier-Stokes equation, as described in the paper.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The modularity of action and perception revisited using control theory and active inference.   The assumption that action and perception can be investigated independently\nis entrenched in theories, models and experimental approaches across the brain\nand mind sciences. In cognitive science, this has been a central point of\ncontention between computationalist and 4Es (enactive, embodied, extended and\nembedded) theories of cognition, with the former embracing the \"classical\nsandwich\", modular, architecture of the mind and the latter actively denying\nthis separation can be made. In this work we suggest that the modular\nindependence of action and perception strongly resonates with the separation\nprinciple of control theory and furthermore that this principle provides formal\ncriteria within which to evaluate the implications of the modularity of action\nand perception. We will also see that real-time feedback with the environment,\noften considered necessary for the definition of 4Es ideas, is not however a\nsufficient condition to avoid the \"classical sandwich\". Finally, we argue that\nan emerging framework in the cognitive and brain sciences, active inference,\nextends ideas derived from control theory to the study of biological systems\nwhile disposing of the separation principle, describing non-modular models of\nbehaviour strongly aligned with 4Es theories of cognition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Numerical assessment of the percolation threshold using complement networks.   Models of percolation processes on networks currently assume locally\ntree-like structures at low densities, and are derived exactly only in the\nthermodynamic limit. Finite size effects and the presence of short loops in\nreal systems however cause a deviation between the empirical percolation\nthreshold $p_c$ and its model-predicted value $\\pi_c$. Here we show the\nexistence of an empirical linear relation between $p_c$ and $\\pi_c$ across a\nlarge number of real and model networks. Such a putatively universal relation\ncan then be used to correct the estimated value of $\\pi_c$. We further show how\nto obtain a more precise relation using the concept of the complement graph, by\ninvestigating on the connection between the percolation threshold of a network,\n$p_c$, and that of its complement, $\\bar{p}_c$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Network topology of neural systems supporting avalanche dynamics predicts stimulus propagation and recovery.   Many neural systems display avalanche behavior characterized by uninterrupted\nsequences of neuronal firing whose distributions of size and durations are\nheavy-tailed. Theoretical models of such systems suggest that these dynamics\nsupport optimal information transmission and storage. However, the unknown role\nof network structure precludes an understanding of how variations in network\ntopology manifest in neural dynamics and either support or impinge upon\ninformation processing. Here, using a generalized spiking model, we develop a\nmechanistic understanding of how network topology supports information\nprocessing through network dynamics. First, we show how network topology\ndetermines network dynamics by analytically and numerically demonstrating that\nnetwork topology can be designed to propagate stimulus patterns for long\ndurations. We then identify strongly connected cycles as empirically observable\nnetwork motifs that are prevalent in such networks. Next, we show that within a\nnetwork, mathematical intuitions from network control theory are tightly linked\nwith dynamics initiated by node-specific stimulation and can identify stimuli\nthat promote long-lasting cascades. Finally, we use these network-based metrics\nand control-based stimuli to demonstrate that long-lasting cascade dynamics\nfacilitate delayed recovery of stimulus patterns from network activity, as\nmeasured by mutual information. Collectively, our results provide evidence that\ncortical networks are structured with architectural motifs that support\nlong-lasting propagation and recovery of a few crucial patterns of stimulation,\nespecially those consisting of activity in highly controllable neurons.\nBroadly, our results imply that avalanching neural networks could contribute to\ncognitive faculties that require persistent activation of neuronal patterns,\nsuch as working memory or attention.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Mixing of odd- and even-frequency pairings in strongly correlated electron systems under magnetic field.   Even- and odd-frequency superconductivity coexist due to broken time-reversal\nsymmetry under magnetic field. In order to describe this mixing, we extend the\nlinearized Eliashberg equation for the spin and charge fluctuation mechanism in\nstrongly correlated electron systems. We apply this extended Eliashberg\nequation to the odd-frequency superconductivity on a quasi-one-dimensional\nisosceles triangular lattice under in-plane magnetic field and examine the\neffect of the even-frequency component.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Asymptotic Properties of the Maximum Likelihood Estimator in Regime Switching Econometric Models.   Markov regime switching models have been widely used in numerous empirical\napplications in economics and finance. However, the asymptotic distribution of\nthe maximum likelihood estimator (MLE) has not been proven for some empirically\npopular Markov regime switching models. In particular, the asymptotic\ndistribution of the MLE has been unknown for models in which some elements of\nthe transition probability matrix have the value of zero, as is commonly\nassumed in empirical applications with models with more than two regimes. This\nalso includes models in which the regime-specific density depends on both the\ncurrent and the lagged regimes such as the seminal model of Hamilton (1989) and\nswitching ARCH model of Hamilton and Susmel (1994). This paper shows the\nasymptotic normality of the MLE and consistency of the asymptotic covariance\nmatrix estimate of these models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Differences Among Noninformative Stopping Rules Are Often Relevant to Bayesian Decisions.   L.J. Savage once hoped to show that \"the superficially incompatible systems\nof ideas associated on the one hand with [subjective Bayesianism] and on the\nother hand with [classical statistics]...lend each other mutual support and\nclarification.\" By 1972, however, he had largely \"lost faith in the devices\" of\nclassical statistics. One aspect of those \"devices\" that he found objectionable\nis that differences among the \"stopping rules\" that are used to decide when to\nend an experiment which are \"noninformative\" from a Bayesian perspective can\naffect decisions made using a classical approach. Two experiments that produce\nthe same data using different stopping rules seem to differ only in the\nintentions of the experimenters regarding whether or not they would have\ncarried on if the data had been different, which seem irrelevant to the\nevidential import of the data and thus to facts about what actions the data\nwarrant.\nI argue that classical and Bayesian ideas about stopping rules do in fact\n\"lend each other\" the kind of \"mutual support and clarification\" that Savage\nhad originally hoped to find. They do so in a kind of case that is common in\nscientific practice, in which those who design an experiment have different\ninterests from those who will make decisions in light of its results. I show\nthat, in cases of this kind, Bayesian principles provide qualified support for\nthe classical statistical practice of \"penalizing\" \"biased\" stopping rules.\nHowever, they require this practice in a narrower range of circumstances than\nclassical principles do, and for different reasons. I argue that classical\narguments for this practice are compelling in precisely the class of cases in\nwhich Bayesian principles also require it, and thus that we should regard\nBayesian principles as clarifying classical statistical ideas about stopping\nrules rather than the reverse.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SySeVR: A Framework for Using Deep Learning to Detect Software Vulnerabilities.   The detection of software vulnerabilities (or vulnerabilities for short) is\nan important problem that has yet to be tackled, as manifested by many\nvulnerabilities reported on a daily basis. This calls for machine learning\nmethods to automate vulnerability detection. Deep learning is attractive for\nthis purpose because it does not require human experts to manually define\nfeatures. Despite the tremendous success of deep learning in other domains, its\napplicability to vulnerability detection is not systematically understood. In\norder to fill this void, we propose the first systematic framework for using\ndeep learning to detect vulnerabilities. The framework, dubbed Syntax-based,\nSemantics-based, and Vector Representations (SySeVR), focuses on obtaining\nprogram representations that can accommodate syntax and semantic information\npertinent to vulnerabilities. Our experiments with 4 software products\ndemonstrate the usefulness of the framework: we detect 15 vulnerabilities that\nare not reported in the National Vulnerability Database. Among these 15\nvulnerabilities, 7 are unknown and have been reported to the vendors, and the\nother 8 have been \"silently\" patched by the vendors when releasing newer\nversions of the products.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Data-Dependent Random Features for Improved Generalization in Supervised Learning.   The randomized-feature approach has been successfully employed in large-scale\nkernel approximation and supervised learning. The distribution from which the\nrandom features are drawn impacts the number of features required to\nefficiently perform a learning task. Recently, it has been shown that employing\ndata-dependent randomization improves the performance in terms of the required\nnumber of random features. In this paper, we are concerned with the\nrandomized-feature approach in supervised learning for good generalizability.\nWe propose the Energy-based Exploration of Random Features (EERF) algorithm\nbased on a data-dependent score function that explores the set of possible\nfeatures and exploits the promising regions. We prove that the proposed score\nfunction with high probability recovers the spectrum of the best fit within the\nmodel class. Our empirical results on several benchmark datasets further verify\nthat our method requires smaller number of random features to achieve a certain\ngeneralization error compared to the state-of-the-art while introducing\nnegligible pre-processing overhead. EERF can be implemented in a few lines of\ncode and requires no additional tuning parameters.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the commutative center of Moufang loops.   We construct two infinite series of Moufang loops of exponent $3$ whose\ncommutative center (i.e. the set of elements that commute with all elements of\nthe loop) is not a normal subloop. In particular, we obtain examples of such\nloops of orders $3^8$ and $3^{11}$ one of which can be defined as the Moufang\ntriplication of the free Burnside group $B(3,3)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian analysis of 210Pb dating.   In many studies of environmental change of the past few centuries, 210Pb\ndating is used to obtain chronologies for sedimentary sequences. One of the\nmost commonly used approaches to estimate the ages of depths in a sequence is\nto assume a constant rate of supply (CRS) or influx of `unsupported' 210Pb from\nthe atmosphere, together with a constant or varying amount of `supported'\n210Pb. Current 210Pb dating models do not use a proper statistical framework\nand thus provide poor estimates of errors. Here we develop a new model for\n210Pb dating, where both ages and values of supported and unsupported 210Pb\nform part of the parameters. We apply our model to a case study from Canada as\nwell as to some simulated examples. Our model can extend beyond the current CRS\napproach, deal with asymmetric errors and mix 210Pb with other types of dating,\nthus obtaining more robust, realistic and statistically better defined\nestimates.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "k*-Nearest Neighbors: From Global to Local.   The weighted k-nearest neighbors algorithm is one of the most fundamental\nnon-parametric methods in pattern recognition and machine learning. The\nquestion of setting the optimal number of neighbors as well as the optimal\nweights has received much attention throughout the years, nevertheless this\nproblem seems to have remained unsettled. In this paper we offer a simple\napproach to locally weighted regression/classification, where we make the\nbias-variance tradeoff explicit. Our formulation enables us to phrase a notion\nof optimal weights, and to efficiently find these weights as well as the\noptimal number of neighbors efficiently and adaptively, for each data point\nwhose value we wish to estimate. The applicability of our approach is\ndemonstrated on several datasets, showing superior performance over standard\nlocally weighted methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On a registration-based approach to sensor network localization.   We consider a registration-based approach for localizing sensor networks from\nrange measurements. This is based on the assumption that one can find\noverlapping cliques spanning the network. That is, for each sensor, one can\nidentify geometric neighbors for which all inter-sensor ranges are known. Such\ncliques can be efficiently localized using multidimensional scaling. However,\nsince each clique is localized in some local coordinate system, we are required\nto register them in a global coordinate system. In other words, our approach is\nbased on transforming the localization problem into a problem of registration.\nIn this context, the main contributions are as follows. First, we describe an\nefficient method for partitioning the network into overlapping cliques. Second,\nwe study the problem of registering the localized cliques, and formulate a\nnecessary rigidity condition for uniquely recovering the global sensor\ncoordinates. In particular, we present a method for efficiently testing\nrigidity, and a proposal for augmenting the partitioned network to enforce\nrigidity. A recently proposed semidefinite relaxation of global registration is\nused for registering the cliques. We present simulation results on random and\nstructured sensor networks to demonstrate that the proposed method compares\nfavourably with state-of-the-art methods in terms of run-time, accuracy, and\nscalability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Regularization, sparse recovery, and median-of-means tournaments.   A regularized risk minimization procedure for regression function estimation\nis introduced that achieves near optimal accuracy and confidence under general\nconditions, including heavy-tailed predictor and response variables. The\nprocedure is based on median-of-means tournaments, introduced by the authors in\n[8]. It is shown that the new procedure outperforms standard regularized\nempirical risk minimization procedures such as lasso or slope in heavy-tailed\nproblems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Isomorphism between Differential and Moment Invariants under Affine Transform.   The invariant is one of central topics in science, technology and\nengineering. The differential invariant is essential in understanding or\ndescribing some important phenomena or procedures in mathematics, physics,\nchemistry, biology or computer science etc. The derivation of differential\ninvariants is usually difficult or complicated. This paper reports a discovery\nthat under the affine transform, differential invariants have similar\nstructures with moment invariants up to a scalar function of transform\nparameters. If moment invariants are known, relative differential invariants\ncan be obtained by the substitution of moments by derivatives with the same\norder. Whereas moment invariants can be calculated by multiple integrals, this\nmethod provides a simple way to derive differential invariants without the need\nto resolve any equation system. Since the definition of moments on different\nmanifolds or in different dimension of spaces is well established, differential\ninvariants on or in them will also be well defined. Considering that moments\nhave a strong background in mathematics and physics, this technique offers a\nnew view angle to the inner structure of invariants. Projective differential\ninvariants can also be found in this way with a screening process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Taming Non-stationary Bandits: A Bayesian Approach.   We consider the multi armed bandit problem in non-stationary environments.\nBased on the Bayesian method, we propose a variant of Thompson Sampling which\ncan be used in both rested and restless bandit scenarios. Applying discounting\nto the parameters of prior distribution, we describe a way to systematically\nreduce the effect of past observations. Further, we derive the exact expression\nfor the probability of picking sub-optimal arms. By increasing the exploitative\nvalue of Bayes' samples, we also provide an optimistic version of the\nalgorithm. Extensive empirical analysis is conducted under various scenarios to\nvalidate the utility of proposed algorithms. A comparison study with various\nstate-of-the-arm algorithms is also included.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-resonant secular dynamics of trans-Neptunian objects perturbed by a distant super-Earth.   We use a secular model to describe the non-resonant dynamics of\ntrans-Neptunian objects in the presence of an external ten-earth-mass\nperturber. The secular dynamics is analogous to an \"eccentric Kozai mechanism\"\nbut with both an inner component (the four giant planets) and an outer one (the\neccentric distant perturber). By the means of Poincaré sections, the cases of\na non-inclined or inclined outer planet are successively studied, making the\nconnection with previous works. In the inclined case, the problem is reduced to\ntwo degrees of freedom by assuming a non-precessing argument of perihelion for\nthe perturbing body.\nThe size of the perturbation is typically ruled by the semi-major axis of the\nsmall body: we show that the classic integrable picture is still valid below\nabout 70 AU, but it is progressively destroyed when we get closer to the\nexternal perturber. In particular, for a>150 AU, large-amplitude orbital flips\nbecome possible, and for a>200 AU, the Kozai libration islands are totally\nsubmerged by the chaotic sea. Numerous resonance relations are highlighted. The\nmost large and persistent ones are associated to apsidal alignments or\nanti-alignments with the orbit of the distant perturber.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Quantum sensors for the generating functional of interacting quantum field theories.   Difficult problems described in terms of interacting quantum fields evolving\nin real time or out of equilibrium are abound in condensed-matter and\nhigh-energy physics. Addressing such problems via controlled experiments in\natomic, molecular, and optical physics would be a breakthrough in the field of\nquantum simulations. In this work, we present a quantum-sensing protocol to\nmeasure the generating functional of an interacting quantum field theory and,\nwith it, all the relevant information about its in or out of equilibrium\nphenomena. Our protocol can be understood as a collective interferometric\nscheme based on a generalization of the notion of Schwinger sources in quantum\nfield theories, which make it possible to probe the generating functional. We\nshow that our scheme can be realized in crystals of trapped ions acting as\nanalog quantum simulators of self-interacting scalar quantum field theories.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Unifying Map and Landmark Based Representations for Visual Navigation.   This works presents a formulation for visual navigation that unifies map\nbased spatial reasoning and path planning, with landmark based robust plan\nexecution in noisy environments. Our proposed formulation is learned from data\nand is thus able to leverage statistical regularities of the world. This allows\nit to efficiently navigate in novel environments given only a sparse set of\nregistered images as input for building representations for space. Our\nformulation is based on three key ideas: a learned path planner that outputs\npath plans to reach the goal, a feature synthesis engine that predicts features\nfor locations along the planned path, and a learned goal-driven closed loop\ncontroller that can follow plans given these synthesized features. We test our\napproach for goal-driven navigation in simulated real world environments and\nreport performance gains over competitive baseline approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Role of Text Preprocessing in Neural Network Architectures: An Evaluation Study on Text Categorization and Sentiment Analysis.   Text preprocessing is often the first step in the pipeline of a Natural\nLanguage Processing (NLP) system, with potential impact in its final\nperformance. Despite its importance, text preprocessing has not received much\nattention in the deep learning literature. In this paper we investigate the\nimpact of simple text preprocessing decisions (particularly tokenizing,\nlemmatizing, lowercasing and multiword grouping) on the performance of a\nstandard neural text classifier. We perform an extensive evaluation on standard\nbenchmarks from text categorization and sentiment analysis. While our\nexperiments show that a simple tokenization of input text is generally\nadequate, they also highlight significant degrees of variability across\npreprocessing techniques. This reveals the importance of paying attention to\nthis usually-overlooked step in the pipeline, particularly when comparing\ndifferent models. Finally, our evaluation provides insights into the best\npreprocessing practices for training word embeddings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Principle of Similitude in Biology: From Allometry to the Formulation of Dimensionally Homogenous `Laws'.   Meaningful laws of nature must be independent of the units employed to\nmeasure the variables. The principle of similitude (Rayleigh 1915) or\ndimensional homogeneity, states that only commensurable quantities (ones having\nthe same dimension) may be compared, therefore, meaningful laws of nature must\nbe homogeneous equations in their various units of measurement, a result which\nwas formalized in the $\\rm \\Pi$ theorem (Vaschy 1892; Buckingham 1914).\nHowever, most relations in allometry do not satisfy this basic requirement,\nincluding the `3/4 Law' (Kleiber 1932) that relates the basal metabolic rate\nand body mass, which it is sometimes claimed to be the most fundamental\nbiological rate (Brown et al. 2004) and the closest to a law in life sciences\n(West \\& Brown 2004). Using the $\\rm \\Pi$ theorem, here we show that it is\npossible to construct a unique homogeneous equation for the metabolic rates, in\nagreement with data in the literature. We find that the variations in the\ndependence of the metabolic rates on body mass are secondary, coming from\nvariations in the allometric dependence of the heart frequencies. This includes\nnot only different classes of animals (mammals, birds, invertebrates) but also\ndifferent exercise conditions (basal and maximal). Our results demonstrate that\nmost of the differences found in the allometric exponents (White et al. 2007)\nare due to compare incommensurable quantities and that our dimensionally\nhomogenous formula, unify these differences into a single formulation. We\ndiscuss the ecological implications of this new formulation in the context of\nthe Malthusian's, Fenchel's and the total energy consumed in a lifespan\nrelations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Facial Recognition Enabled Smart Door Using Microsoft Face API.   Privacy and Security are two universal rights and, to ensure that in our\ndaily life we are secure, a lot of research is going on in the field of home\nsecurity, and IoT is the turning point for the industry, where we connect\neveryday objects to share data for our betterment. Facial recognition is a\nwell-established process in which the face is detected and identified out of\nthe image. We aim to create a smart door, which secures the gateway on the\nbasis of who we are. In our proof of concept of a smart door we have used a\nlive HD camera on the front side of setup attached to a display monitor\nconnected to the camera to show who is standing in front of the door, also the\nwhole system will be able to give voice outputs by processing text them on the\nRaspberry Pi ARM processor used and show the answers as output on the screen.\nWe are using a set of electromagnets controlled by the microcontroller, which\nwill act as a lock. So a person can open the smart door with the help of facial\nrecognition and at the same time also be able to interact with it. The facial\nrecognition is done by Microsoft face API but our state of the art desktop\napplication operating over Microsoft Visual Studio IDE reduces the\ncomputational time by detecting the face out of the photo and giving that as\nthe output to Microsoft Face API, which is hosted over Microsoft Azure cloud\nsupport.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Exploratory Study on the Implementation and Adoption of ERP Solutions for Businesses.   Enterprise Resource Planning (ERP) systems have been covered in both\nmainstream Information Technology (IT) periodicals, and in academic literature,\nas a result of extensive adoption by organisations in the last two decades.\nSome of the past studies have reported operational efficiency and other gains,\nwhile other studies have pointed out the challenges. ERP systems continue to\nevolve, moving into the cloud hosted sphere, and being implemented by\nrelatively smaller and regional companies. This project has carried out an\nexploratory study into the use of ERP systems, within Hawke's Bay New Zealand.\nERP systems make up a major investment and undertaking by those companies.\nTherefore, research and lessons learned in this area are very important. In\naddition to a significant initial literature review, this project has conducted\na survey on the local users' experience with Microsoft Dynamics NAV (a popular\nERP brand). As a result, this study will contribute new and relevant\ninformation to the literature on business information systems and to ERP\nsystems, in particular.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Aggregation and Resource Scheduling in Machine-type Communication Networks: A Stochastic Geometry Approach.   Data aggregation is a promising approach to enable massive machine-type\ncommunication (mMTC). This paper focuses on the aggregation phase where a\nmassive number of machine-type devices (MTDs) transmit to aggregators. By using\nnon-orthogonal multiple access (NOMA) principles, we allow several MTDs to\nshare the same orthogonal channel in our proposed hybrid access scheme. We\ndevelop an analytical framework based on stochastic geometry to investigate the\nsystem performance in terms of average success probability and average number\nof simultaneously served MTDs, under imperfect successive interference\ncancellation (SIC) at the aggregators, for two scheduling schemes: random\nresource scheduling (RRS) and channel-aware resource scheduling (CRS). We\nidentify the power constraints on the MTDs sharing the same channel to attain a\nfair coexistence with purely orthogonal multiple access (OMA) setups, then\npower control coefficients are found so that these MTDs perform with similar\nreliability. We show that under high access demand, the hybrid scheme with CRS\noutperforms the OMA setup by simultaneously serving more MTDs with reduced\npower consumption.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Electrostatic gyrokinetic simulation of global tokamak boundary plasma and the generation of nonlinear intermittent turbulence.   Boundary plasma physics plays an important role in tokamak confinement, but\nis difficult to simulate in a gyrokinetic code due to the scale-inseparable\nnonlocal multi-physics in magnetic separatrix and open magnetic field geometry.\nNeutral particles are also an important part of the boundary plasma physics. In\nthe present paper, noble electrostatic gyrokinetic techniques to simulate the\nflux-driven, low-beta electrostatic boundary plasma is reported. Gyrokinetic\nions and drift-kinetic electrons are utilized without scale-separation between\nthe neoclassical and turbulence dynamics. It is found that the nonlinear\nintermittent turbulence is a natural gyrokinetic phenomenon in the boundary\nplasma in the vicinity of the magnetic separatrix surface and in the scrape-off\nlayer.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Deep Learning Interior Tomography for Region-of-Interest Reconstruction.   Interior tomography for the region-of-interest (ROI) imaging has advantages\nof using a small detector and reducing X-ray radiation dose. However, standard\nanalytic reconstruction suffers from severe cupping artifacts due to existence\nof null space in the truncated Radon transform. Existing penalized\nreconstruction methods may address this problem but they require extensive\ncomputations due to the iterative reconstruction. Inspired by the recent deep\nlearning approaches to low-dose and sparse view CT, here we propose a deep\nlearning architecture that removes null space signals from the FBP\nreconstruction. Experimental results have shown that the proposed method\nprovides near-perfect reconstruction with about 7-10 dB improvement in PSNR\nover existing methods in spite of significantly reduced run-time complexity.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Constraint Programming as Reinforcement Learning.   Stochastic Constraint Programming (SCP) is an extension of Constraint\nProgramming (CP) used for modelling and solving problems involving constraints\nand uncertainty. SCP inherits excellent modelling abilities and filtering\nalgorithms from CP, but so far it has not been applied to large problems.\nReinforcement Learning (RL) extends Dynamic Programming to large stochastic\nproblems, but is problem-specific and has no generic solvers. We propose a\nhybrid combining the scalability of RL with the modelling and constraint\nfiltering methods of CP. We implement a prototype in a CP system and\ndemonstrate its usefulness on SCP problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fractional Topological Elasticity and Fracton Order.   We analyze the \"higher rank\" gauge theories, that capture some of the\nphenomenology of the Fracton order. It is shown that these theories loose gauge\ninvariance when arbitrarily weak and smooth curvature is introduced. We propose\na resolution to this problem by introducing a theory invariant under\narea-preserving diffeomorphisms, which reduce to the \"higher rank\" gauge\ntransformations upon linearization around a flat background. The proposed\ntheory is \\emph{geometric} in nature and is interpreted as a theory of\n\\emph{fractional topological elasticity}. This theory exhibits the Fracton\nphenomenology. We explore the conservation laws, topological excitations,\nlinear response, various kinematical constraints, and canonical structure of\nthe theory. Finally, we emphasize that the very structure of Riemann-Cartan\ngeometry, which we use to formulate the theory, encodes the Fracton\nphenomenology, suggesting that the Fracton order itself is \\emph{geometric} in\nnature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Evidence for OH or H2O on the surface of 433 Eros and 1036 Ganymed.   Water and hydroxyl, once thought to be found only in the primitive airless\nbodies that formed beyond roughly 2.5-3 AU, have recently been detected on the\nMoon and Vesta, which both have surfaces dominated by evolved, non-primitive\ncompositions. In both these cases, the water/OH is thought to be exogenic,\neither brought in via impacts with comets or hydrated asteroids or created via\nsolar wind interactions with silicates in the regolith or both. Such exogenic\nprocesses should also be occurring on other airless body surfaces. To test this\nhypothesis, we used the NASA Infrared Telescope Facility (IRTF) to measure\nreflectance spectra (2.0 to 4.1 {\\mu}m) of two large near-Earth asteroids\n(NEAs) with compositions generally interpreted as anhydrous: 433 Eros and 1036\nGanymed. OH is detected on both of these bodies in the form of absorption\nfeatures near 3 {\\mu}m. The spectra contain a component of thermal emission at\nlonger wavelengths, from which we estimate thermal of 167+/- 98 J m-2s-1/2K-1\nfor Eros (consistent with previous estimates) and 214+/- 80 J m-2s-1/2K-1 for\nGanymed, the first reported measurement of thermal inertia for this object.\nThese observations demonstrate that processes responsible for water/OH creation\non large airless bodies also act on much smaller bodies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lattice Boltzmann simulation of viscous fingering of immiscible displacement in a channel using an improved wetting scheme.   An improved wetting boundary implementation strategy is proposed based on\nlattice Boltzmann color-gradient model in this paper. In this strategy, an\nextra interface force condition is demonstrated based on the diffuse interface\nassumption and is employed in contact line region. It has been validated by\nthree benchmark problems: static droplet wetting on a flat surface and a curved\nsurface, and dynamic capillary filling. Good performances are shown in all\nthree cases. Relied on the strict validation to our scheme, the viscous\nfingering phenomenon of immiscible fluids displacement in a two-dimensional\nchannel has been restudied in this paper. High viscosity ratio, wide range\ncontact angle, accurate moving contact line and mutual independence between\nsurface tension and viscosity are the obvious advantages of our model. We find\nthe linear relationship between the contact angle and displacement velocity or\nvariation of finger length. When the viscosity ratio is smaller than 20, the\ndisplacement velocity is increasing with increasing viscosity ratio and\nreducing capillary number, and when the viscosity ratio is larger than 20, the\ndisplacement velocity tends to a specific constant. A similar conclusion is\nobtained on the variation of finger length.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Automated Problem Identification: Regression vs Classification via Evolutionary Deep Networks.   Regression or classification? This is perhaps the most basic question faced\nwhen tackling a new supervised learning problem. We present an Evolutionary\nDeep Learning (EDL) algorithm that automatically solves this by identifying the\nquestion type with high accuracy, along with a proposed deep architecture.\nTypically, a significant amount of human insight and preparation is required\nprior to executing machine learning algorithms. For example, when creating deep\nneural networks, the number of parameters must be selected in advance and\nfurthermore, a lot of these choices are made based upon pre-existing knowledge\nof the data such as the use of a categorical cross entropy loss function.\nHumans are able to study a dataset and decide whether it represents a\nclassification or a regression problem, and consequently make decisions which\nwill be applied to the execution of the neural network. We propose the\nAutomated Problem Identification (API) algorithm, which uses an evolutionary\nalgorithm interface to TensorFlow to manipulate a deep neural network to decide\nif a dataset represents a classification or a regression problem. We test API\non 16 different classification, regression and sentiment analysis datasets with\nup to 10,000 features and up to 17,000 unique target values. API achieves an\naverage accuracy of $96.3\\%$ in identifying the problem type without hardcoding\nany insights about the general characteristics of regression or classification\nproblems. For example, API successfully identifies classification problems even\nwith 1000 target values. Furthermore, the algorithm recommends which loss\nfunction to use and also recommends a neural network architecture. Our work is\ntherefore a step towards fully automated machine learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Astronomy of Cholanaikkan tribe of Kerala.   Cholanaikkans are a diminishing tribe of India. With a population of less\nthan 200 members, this tribe living in the reserved forests about 80 km from\nKozhikode, it is one of the most isolated tribes. A programme of the Government\nof Kerala brings some of them to Kozhikode once a year. We studied various\naspects of the tribe during such a visit in 2016. We report their science and\ntechnology.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Efficient Estimation for Dimension Reduction with Censored Data.   We propose a general index model for survival data, which generalizes many\ncommonly used semiparametric survival models and belongs to the framework of\ndimension reduction. Using a combination of geometric approach in\nsemiparametrics and martingale treatment in survival data analysis, we devise\nestimation procedures that are feasible and do not require\ncovariate-independent censoring as assumed in many dimension reduction methods\nfor censored survival data. We establish the root-$n$ consistency and\nasymptotic normality of the proposed estimators and derive the most efficient\nestimator in this class for the general index model. Numerical experiments are\ncarried out to demonstrate the empirical performance of the proposed estimators\nand an application to an AIDS data further illustrates the usefulness of the\nwork.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Note on Kaldi's PLDA Implementation.   Some explanations to Kaldi's PLDA implementation to make formula derivation\neasier to catch.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entanglement entropy and computational complexity of the Anderson impurity model out of equilibrium I: quench dynamics.   We study the growth of entanglement entropy in density matrix renormalization\ngroup calculations of the real-time quench dynamics of the Anderson impurity\nmodel. We find that with appropriate choice of basis, the entropy growth is\nlogarithmic in both the interacting and noninteracting single-impurity models.\nThe logarithmic entropy growth is understood from a noninteracting chain model\nas a critical behavior separating regimes of linear growth and saturation of\nentropy, corresponding respectively to an overlapping and gapped energy spectra\nof the set of bath states. We find that with an appropriate choices of basis\n(energy-ordered bath orbitals), logarithmic entropy growth is the generic\nbehavior of quenched impurity models. A noninteracting calculation of a\ndouble-impurity Anderson model supports the conclusion in the multi-impurity\ncase. The logarithmic growth of entanglement entropy enables studies of quench\ndynamics to very long times.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multi-objective optimization to explicitly account for model complexity when learning Bayesian Networks.   Bayesian Networks have been widely used in the last decades in many fields,\nto describe statistical dependencies among random variables. In general,\nlearning the structure of such models is a problem with considerable\ntheoretical interest that still poses many challenges. On the one hand, this is\na well-known NP-complete problem, which is practically hardened by the huge\nsearch space of possible solutions. On the other hand, the phenomenon of\nI-equivalence, i.e., different graphical structures underpinning the same set\nof statistical dependencies, may lead to multimodal fitness landscapes further\nhindering maximum likelihood approaches to solve the task. Despite all these\ndifficulties, greedy search methods based on a likelihood score coupled with a\nregularization term to account for model complexity, have been shown to be\nsurprisingly effective in practice. In this paper, we consider the formulation\nof the task of learning the structure of Bayesian Networks as an optimization\nproblem based on a likelihood score. Nevertheless, our approach do not adjust\nthis score by means of any of the complexity terms proposed in the literature;\ninstead, it accounts directly for the complexity of the discovered solutions by\nexploiting a multi-objective optimization procedure. To this extent, we adopt\nNSGA-II and define the first objective function to be the likelihood of a\nsolution and the second to be the number of selected arcs. We thoroughly\nanalyze the behavior of our method on a wide set of simulated data, and we\ndiscuss the performance considering the goodness of the inferred solutions both\nin terms of their objective functions and with respect to the retrieved\nstructure. Our results show that NSGA-II can converge to solutions\ncharacterized by better likelihood and less arcs than classic approaches,\nalthough paradoxically frequently characterized by a lower similarity to the\ntarget network.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Theoretical Accuracy in Cosmological Growth Estimation.   We elucidate the importance of the consistent treatment of gravity-model\nspecific non-linearities when estimating the growth of cosmological structures\nfrom redshift space distortions (RSD). Within the context of standard\nperturbation theory (SPT), we compare the predictions of two theoretical\ntemplates with redshift space data from COLA (COmoving Lagrangian Acceleration)\nsimulations in the normal branch of DGP gravity (nDGP) and General Relativity\n(GR). Using COLA for these comparisons is validated using a suite of full\nN-body simulations for the same theories. The two theoretical templates\ncorrespond to the standard general relativistic perturbation equations and\nthose same equations modelled within nDGP. Gravitational clustering non-linear\neffects are accounted for by modelling the power spectrum up to one loop order\nand redshift space clustering anisotropy is modelled using the Taruya,\nNishimichi and Saito (TNS) RSD model. Using this approach, we attempt to\nrecover the simulation's fiducial logarithmic growth parameter $f$. By\nassigning the simulation data with errors representing an idealised survey with\na volume of $10\\mbox{Gpc}^3/h^3$, we find the GR template is unable to recover\nfiducial $f$ to within 1$\\sigma$ at $z=1$ when we match the data up to $k_{\\rm\nmax}=0.195h$/Mpc. On the other hand, the DGP template recovers the fiducial\nvalue within $1\\sigma$. Further, we conduct the same analysis for sets of mock\ndata generated for generalised models of modified gravity using SPT, where\nagain we analyse the GR template's ability to recover the fiducial value. We\nfind that for models with enhanced gravitational non-linearity, the theoretical\nbias of the GR template becomes significant for stage IV surveys. Thus, we show\nthat for the future large data volume galaxy surveys, the self-consistent\nmodelling of non-GR gravity scenarios will be crucial in constraining theory\nparameters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An Ensemble Boosting Model for Predicting Transfer to the Pediatric Intensive Care Unit.   Our work focuses on the problem of predicting the transfer of pediatric\npatients from the general ward of a hospital to the pediatric intensive care\nunit. Using data collected over 5.5 years from the electronic health records of\ntwo medical facilities, we develop classifiers based on adaptive boosting and\ngradient tree boosting. We further combine these learned classifiers into an\nensemble model and compare its performance to a modified pediatric early\nwarning score (PEWS) baseline that relies on expert defined guidelines. To\ngauge model generalizability, we perform an inter-facility evaluation where we\ntrain our algorithm on data from one facility and perform evaluation on a\nhidden test dataset from a separate facility. We show that improvements are\nwitnessed over the PEWS baseline in accuracy (0.77 vs. 0.69), sensitivity (0.80\nvs. 0.68), specificity (0.74 vs. 0.70) and AUROC (0.85 vs. 0.73).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pronunciation recognition of English phonemes /\\textipa{@}/, /æ/, /\\textipa{A}:/ and /\\textipa{2}/ using Formants and Mel Frequency Cepstral Coefficients.   The Vocal Joystick Vowel Corpus, by Washington University, was used to study\nmonophthongs pronounced by native English speakers. The objective of this study\nwas to quantitatively measure the extent at which speech recognition methods\ncan distinguish between similar sounding vowels. In particular, the phonemes\n/\\textipa{@}/, /{\\ae}/, /\\textipa{A}:/ and /\\textipa{2}/ were analysed. 748\nsound files from the corpus were used and subjected to Linear Predictive Coding\n(LPC) to compute their formants, and to Mel Frequency Cepstral Coefficients\n(MFCC) algorithm, to compute the cepstral coefficients. A Decision Tree\nClassifier was used to build a predictive model that learnt the patterns of the\ntwo first formants measured in the data set, as well as the patterns of the 13\ncepstral coefficients. An accuracy of 70\\% was achieved using formants for the\nmentioned phonemes. For the MFCC analysis an accuracy of 52 \\% was achieved and\nan accuracy of 71\\% when /\\textipa{@}/ was ignored. The results obtained show\nthat the studied algorithms are far from mimicking the ability of\ndistinguishing subtle differences in sounds like human hearing does.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ubiquitous quasi-Fuchsian surfaces in cusped hyperbolic 3-manifolds.   This paper proves that every finite volume hyperbolic 3-manifold M contains a\nubiquitous collection of closed, immersed, quasi-Fuchsian surfaces. These\nsurfaces are ubiquitous in the sense that their preimages in the universal\ncover separate any pair of disjoint, non-asymptotic geodesic planes. The proof\nrelies in a crucial way on the corresponding theorem of Kahn and Markovic for\nclosed 3-manifolds. As a corollary of this result and a companion statement\nabout surfaces with cusps, we recover Wise's theorem that the fundamental group\nof M acts freely and cocompactly on a CAT(0) cube complex.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Verifiable Light-Weight Monitoring for Certificate Transparency Logs.   Trust in publicly verifiable Certificate Transparency (CT) logs is reduced\nthrough cryptography, gossip, auditing, and monitoring. The role of a monitor\nis to observe each and every log entry, looking for suspicious certificates\nthat interest the entity running the monitor. While anyone can run a monitor,\nit requires continuous operation and copies of the logs to be inspected. This\nhas lead to the emergence of monitoring-as-a-service: a trusted party runs the\nmonitor and provides registered subjects with selective certificate\nnotifications, e.g., \"notify me of all foo.com certificates\". We present a\nCT/bis extension for verifiable light-weight monitoring that enables subjects\nto verify the correctness of such notifications, reducing the trust that is\nplaced in these monitors. Our extension supports verifiable monitoring of\nwild-card domains and piggybacks on CT's existing gossip-audit security model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fixed-Parameter Tractable Sampling for RNA Design with Multiple Target Structures.   The design of multi-stable RNA molecules has important applications in\nbiology, medicine, and biotechnology. Synthetic design approaches profit\nstrongly from effective in-silico methods, which can tremendously impact their\ncost and feasibility. We revisit a central ingredient of most in-silico design\nmethods: the sampling of sequences for the design of multi-target structures,\npossibly including pseudoknots. For this task, we present the efficient, tree\ndecomposition-based algorithm. Our fixed parameter tractable approach is\nunderpinned by establishing the P-hardness of uniform sampling. Modeling the\nproblem as a constraint network, our program supports generic\nBoltzmann-weighted sampling for arbitrary additive RNA energy models; this\nenables the generation of RNA sequences meeting specific goals like expected\nfree energies or \\GCb-content. Finally, we empirically study general properties\nof the approach and generate biologically relevant multi-target\nBoltzmann-weighted designs for a common design benchmark. Generating seed\nsequences with our program, we demonstrate significant improvements over the\npreviously best multi-target sampling strategy (uniform sampling).Our software\nis freely available at: this https URL .",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "K-means Algorithm over Compressed Binary Data.   We consider a network of binary-valued sensors with a fusion center. The\nfusion center has to perform K-means clustering on the binary data transmitted\nby the sensors. In order to reduce the amount of data transmitted within the\nnetwork, the sensors compress their data with a source coding scheme based on\nbinary sparse matrices. We propose to apply the K-means algorithm directly over\nthe compressed data without reconstructing the original sensors measurements,\nin order to avoid potentially complex decoding operations. We provide\napproximated expressions of the error probabilities of the K-means steps in the\ncompressed domain. From these expressions, we show that applying the K-means\nalgorithm in the compressed domain enables to recover the clusters of the\noriginal domain. Monte Carlo simulations illustrate the accuracy of the\nobtained approximated error probabilities, and show that the coding rate needed\nto perform K-means clustering in the compressed domain is lower than the rate\nneeded to reconstruct all the measurements.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Motif and Hypergraph Correlation Clustering.   Motivated by applications in social and biological network analysis, we\nintroduce a new form of agnostic clustering termed~\\emph{motif correlation\nclustering}, which aims to minimize the cost of clustering errors associated\nwith both edges and higher-order network structures. The problem may be\nsuccinctly described as follows: Given a complete graph $G$, partition the\nvertices of the graph so that certain predetermined `important' subgraphs\nmostly lie within the same cluster, while `less relevant' subgraphs are allowed\nto lie across clusters. Our contributions are as follows: We first introduce\nseveral variants of motif correlation clustering and then show that these\nclustering problems are NP-hard. We then proceed to describe polynomial-time\nclustering algorithms that provide constant approximation guarantees for the\nproblems at hand. Despite following the frequently used LP relaxation and\nrounding procedure, the algorithms involve a sophisticated and carefully\ndesigned neighborhood growing step that combines information about both edge\nand motif structures. We conclude with several examples illustrating the\nperformance of the developed algorithms on synthetic and real networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Surface Normals in the Wild.   We study the problem of single-image depth estimation for images in the wild.\nWe collect human annotated surface normals and use them to train a neural\nnetwork that directly predicts pixel-wise depth. We propose two novel loss\nfunctions for training with surface normal annotations. Experiments on NYU\nDepth and our own dataset demonstrate that our approach can significantly\nimprove the quality of depth estimation in the wild.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Extensions of Operators, Liftings of Monads and Distributive Laws.   In a previous study, the algebraic formulation of the First Fundamental\nTheorem of Calculus (FFTC) is shown to allow extensions of differential and\nRota-Baxter operators on the one hand, and to give rise to liftings of monads\nand comonads, and mixed distributive laws on the other. Generalizing the FFTC,\nwe consider in this paper a class of constraints between a differential\noperator and a Rota-Baxter operator. For a given constraint, we show that the\nexistences of extensions of differential and Rota-Baxter operators, of liftings\nof monads and comonads, and of mixed distributive laws are equivalent. We\nfurther give a classification of the constraints satisfying these equivalent\nconditions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Realisability of Pomsets via Communicating Automata.   Pomsets are a model of concurrent computations introduced by Pratt. They can\nprovide a syntax-oblivious description of semantics of coordination models\nbased on asynchronous message-passing, such as Message Sequence Charts (MSCs).\nIn this paper, we study conditions that ensure a specification expressed as a\nset of pomsets can be faithfully realised via communicating automata. Our main\ncontributions are (i) the definition of a realisability condition accounting\nfor termination soundness, (ii) conditions for global specifications with\n\"multi-threaded\" participants, and (iii) the definition of realisability\nconditions that can be decided directly over pomsets. A positive by-product of\nour approach is the efficiency gain in the verification of the realisability\nconditions obtained when restricting to specific classes of choreographies\ncharacterisable in term of behavioural types.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "FO model checking of geometric graphs.   Over the past two decades the main focus of research into first-order (FO)\nmodel checking algorithms has been on sparse relational structures -\nculminating in the FPT algorithm by Grohe, Kreutzer and Siebertz for FO model\nchecking of nowhere dense classes of graphs. On contrary to that, except the\ncase of locally bounded clique-width only little is currently known about FO\nmodel checking of dense classes of graphs or other structures. We study the FO\nmodel checking problem for dense graph classes definable by geometric means\n(intersection and visibility graphs). We obtain new nontrivial FPT results,\ne.g., for restricted subclasses of circular-arc, circle, box, disk, and\npolygon-visibility graphs. These results use the FPT algorithm by Gajarský et\nal. for FO model checking of posets of bounded width. We also complement the\ntractability results by related hardness reductions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Matter-wave solutions in the Bose-Einstein condensates with the harmonic and Gaussian potentials.   We study exact solutions of the quasi-one-dimensional Gross-Pitaevskii (GP)\nequation with the (space, time)-modulated potential and nonlinearity and the\ntime-dependent gain or loss term in Bose-Einstein condensates. In particular,\nbased on the similarity transformation, we report several families of exact\nsolutions of the GP equation in the combination of the harmonic and Gaussian\npotentials, in which some physically relevant solutions are described. The\nstability of the obtained matter-wave solutions is addressed numerically such\nthat some stable solutions are found. Moreover, we also analyze the parameter\nregimes for the stable solutions. These results may raise the possibility of\nrelative experiments and potential applications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the area of constrained polygonal linkages.   We study configuration spaces of linkages whose underlying graph are polygons\nwith diagonal constrains, or more general, partial two-trees. We show that\n(with an appropriate definition) the oriented area is a Bott-Morse function on\nthe configuration space. Its critical points are described and Bott-Morse\nindices are computed. This paper is a generalization of analogous results for\npolygonal linkages (obtained earlier by G. Khimshiashvili, G. Panina, and A.\nZhukova).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evolution of the Kondo lattice electronic structure above the transport coherence temperature.   The temperature-dependent evolution of the Kondo lattice is a long-standing\ntopic of theoretical and experimental investigation and yet it lacks a truly\nmicroscopic description of the relation of the basic $f$-$d$ hybridization\nprocesses to the fundamental temperature scales of Kondo screening and\nFermi-liquid lattice coherence. Here, the temperature-dependence of $f$-$d$\nhybridized band dispersions and Fermi-energy $f$ spectral weight in the Kondo\nlattice system CeCoIn$_5$ is investigated using $f$-resonant angle-resolved\nphotoemission (ARPES) with sufficient detail to allow direct comparison to\nfirst principles dynamical mean field theory (DMFT) calculations containing\nfull realism of crystalline electric field states. The ARPES results, for two\northogonal (001) and (100) cleaved surfaces and three different $f$-$d$\nhybridization scenarios, with additional microscopic insight provided by DMFT,\nreveal $f$ participation in the Fermi surface at temperatures much higher than\nthe lattice coherence temperature, $T^*\\approx$ 45 K, commonly believed to be\nthe onset for such behavior. The identification of a $T$-dependent crystalline\nelectric field degeneracy crossover in the DMFT theory $below$ $T^*$ is\nspecifically highlighted.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Possible heights of graph transformation groups.   In the following text we prove that for all finite $p\\geq0$ there exists a\ntopological graph $X$ such that $\\{p,p+1,p+2,\\ldots\\}\\cup\\{+\\infty\\}$ is the\ncollection of all possible heights for transformation groups with phase space\n$X$. Moreover for all topological graph $X$ with $p$ as height of\ntransformation group $(Homeo(X),X)$, $\\{p,p+1,p+2,\\ldots\\}\\cup\\{+\\infty\\}$\nagain is the collection of all possible heights for transformation groups with\nphase space $X$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Supernova -- Supernova Remnant Connection.   Many aspects of the progenitor systems, environments, and explosion dynamics\nof the various subtypes of supernovae are difficult to investigate at\nextragalactic distances where they are observed as unresolved sources.\nAlternatively, young supernova remnants in our own galaxy and in the Large and\nSmall Magellanic Clouds offer opportunities to resolve, measure, and track\nexpanding stellar ejecta in fine detail, but the handful that are known exhibit\nwidely different properties that reflect the diversity of their parent\nexplosions and local circumstellar and interstellar environments. A way of\ncomplementing both supernova and supernova remnant research is to establish\nstrong empirical links between the two separate stages of stellar explosions.\nHere we briefly review recent progress in the development of\nsupernova---supernova remnant connections, paying special attention to\nconnections made through the study of \"middle-aged\" (10-100 yr) supernovae and\nyoung (< 1000 yr) supernova remnants. We highlight how this approach can\nuniquely inform several key areas of supernova research, including the origins\nof explosive mixing, high-velocity jets, and the formation of dust in the\nejecta.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "UV Detector based on InAlN/GaN-on-Si HEMT Stack with Photo-to-Dark Current Ratio > 107.   We demonstrate an InAlN/GaN-on-Si HEMT based UV detector with photo to dark\ncurrent ratio > 107. Ti/Al/Ni/Au metal stack was evaporated and rapid thermal\nannealed for Ohmic contacts to the 2D electron gas (2DEG) at the InAlN/GaN\ninterface while the channel + barrier was recess etched to a depth of 20 nm to\npinch-off the 2DEG between Source-Drain pads. Spectral responsivity (SR) of 34\nA/W at 367 nm was measured at 5 V in conjunction with very high photo to dark\ncurrent ratio of > 10^7. The photo to dark current ratio at a fixed bias was\nfound to be decreasing with increase in recess length of the PD. The fabricated\ndevices were found to exhibit a UV-to-visible rejection ratio of >103 with a\nlow dark current < 32 pA at 5 V. Transient measurements showed rise and fall\ntimes in the range of 3-4 ms. The gain mechanism was investigated and carrier\nlifetimes were estimated which matched well with those reported elsewhere.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Double-sided probing by map of Asplund's distances using Logarithmic Image Processing in the framework of Mathematical Morphology.   We establish the link between Mathematical Morphology and the map of\nAsplund's distances between a probe and a grey scale function, using the\nLogarithmic Image Processing scalar multiplication. We demonstrate that the map\nis the logarithm of the ratio between a dilation and an erosion of the function\nby a structuring function: the probe. The dilations and erosions are mappings\nfrom the lattice of the images into the lattice of the positive functions.\nUsing a flat structuring element, the expression of the map of Asplund's\ndistances can be simplified with a dilation and an erosion of the image; these\nmappings stays in the lattice of the images. We illustrate our approach by an\nexample of pattern matching with a non-flat structuring function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparison of Flow Scheduling Policies for Mix of Regular and Deadline Traffic in Datacenter Environments.   Datacenters are the main infrastructure on top of which cloud computing\nservices are offered. Such infrastructure may be shared by a large number of\ntenants and applications generating a spectrum of datacenter traffic. Delay\nsensitive applications and applications with specific Service Level Agreements\n(SLAs), generate deadline constrained flows, while other applications initiate\nflows that are desired to be delivered as early as possible. As a result,\ndatacenter traffic is a mix of two types of flows: deadline and regular. There\nare several scheduling policies for either traffic type with focus on\nminimizing completion times or deadline miss rate. In this report, we apply\nseveral scheduling policies to mix traffic scenario while varying the ratio of\nregular to deadline traffic. We consider FCFS (First Come First Serve), SRPT\n(Shortest Remaining Processing Time) and Fair Sharing as deadline agnostic\napproaches and a combination of Earliest Deadline First (EDF) with either FCFS\nor SRPT as deadline-aware schemes. In addition, for the latter, we consider\nboth cases of prioritizing deadline traffic (Deadline First) and prioritizing\nregular traffic (Deadline Last). We study both light-tailed and heavy-tailed\nflow size distributions and measure mean, median and tail flow completion times\n(FCT) for regular flows along with Deadline Miss Rate (DMR) and average\nlateness for deadline flows. We also consider two operation regimes of\nlightly-loaded (low utilization) and heavily-loaded (high utilization). We find\nthat performance of deadline-aware schemes is highly dependent on fraction of\ndeadline traffic. With light-tailed flow sizes, we find that FCFS performs\nbetter in terms of tail times and average lateness while SRPT performs better\nin average times and deadline miss rate. For heavy-tailed flow sizes, except\nfor tail times, SRPT performs better in all other metrics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Magnetic behavior of new compounds, Gd3RuSn6 and Tb3RuSn6.   We report temperature (T) dependence of dc magnetization, electrical\nresistivity (rho(T)), and heat-capacity of rare-earth (R) compounds, Gd3RuSn6\nand Tb3RuSn6, which are found to crystallize in the Yb3CoSn6-type orthorhombic\nstructure (space group: Cmcm). The results establish that there is an onset of\nantiferromagnetic order near (T_N) 19 and 25 K respectively. In addition, we\nfind that there is another magnetic transition for both the cases around 14 and\n17 K respectively. In the case of the Gd compound, the spin-scattering\ncontribution to rho is found to increase below 75 K as the material is cooled\ntowards T_N, thereby resulting in a minimum in the plot of rho(T) unexpected\nfor Gd based systems. Isothermal magnetization at 1.8 K reveals an upward\ncurvature around 50 kOe. Isothermal magnetoresistance plots show interesting\nanomalies in the magnetically ordered state. There are sign reversals in the\nplot of isothermal entropy change versus T in the magnetically ordered state,\nindicating subtle changes in the spin reorientation with T. The results reveal\nthat these compounds exhibit interesting magnetic properties.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stage 4 validation of the Satellite Image Automatic Mapper lightweight computer program for Earth observation Level 2 product generation, Part 1 Theory.   The European Space Agency (ESA) defines an Earth Observation (EO) Level 2\nproduct as a multispectral (MS) image corrected for geometric, atmospheric,\nadjacency and topographic effects, stacked with its scene classification map\n(SCM), whose legend includes quality layers such as cloud and cloud-shadow. No\nESA EO Level 2 product has ever been systematically generated at the ground\nsegment. To contribute toward filling an information gap from EO big data to\nthe ESA EO Level 2 product, an original Stage 4 validation (Val) of the\nSatellite Image Automatic Mapper (SIAM) lightweight computer program was\nconducted by independent means on an annual Web-Enabled Landsat Data (WELD)\nimage composite time-series of the conterminous U.S. The core of SIAM is a one\npass prior knowledge based decision tree for MS reflectance space\nhyperpolyhedralization into static color names presented in literature in\nrecent years. For the sake of readability this paper is split into two. The\npresent Part 1 Theory provides the multidisciplinary background of a priori\ncolor naming in cognitive science, from linguistics to computer vision. To cope\nwith dictionaries of MS color names and land cover class names that do not\ncoincide and must be harmonized, an original hybrid guideline is proposed to\nidentify a categorical variable pair relationship. An original quantitative\nmeasure of categorical variable pair association is also proposed. The\nsubsequent Part 2 Validation discusses Stage 4 Val results collected by an\noriginal protocol for wall-to-wall thematic map quality assessment without\nsampling where the test and reference map legends can differ. Conclusions are\nthat the SIAM-WELD maps instantiate a Level 2 SCM product whose legend is the 4\nclass taxonomy of the FAO Land Cover Classification System at the Dichotomous\nPhase Level 1 vegetation/nonvegetation and Level 2 terrestrial/aquatic.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A Dynamic Programming Principle for Distribution-Constrained Optimal Stopping.   We consider an optimal stopping problem where a constraint is placed on the\ndistribution of the stopping time. Reformulating the problem in terms of\nso-called measure-valued martingales allows us to transform the marginal\nconstraint into an initial condition and view the problem as a stochastic\ncontrol problem; we establish the corresponding dynamic programming principle.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Precision Prediction for the Cosmological Density Distribution.   The distribution of matter in the universe is, to first order, lognormal.\nImproving this approximation requires characterization of the third moment\n(skewness) of the log density field. Thus, using Millennium Simulation\nphenomenology and building on previous work, we present analytic fits for the\nmean, variance, and skewness of the log density field $A$. We further show that\na Generalized Extreme Value (GEV) distribution accurately models $A$; we submit\nthat this GEV behavior is the result of strong intrapixel correlations, without\nwhich the smoothed distribution would tend (by the Central Limit Theorem)\ntoward a Gaussian. Our GEV model yields cumulative distribution functions\naccurate to within 1.7 per cent for near-concordance cosmologies, over a range\nof redshifts and smoothing scales.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An Optics-Based Approach to Thermal Management of Photovoltaics: Selective-Spectral and Radiative Cooling.   For commercial one-sun solar modules, up to 80% of the incoming sunlight may\nbe dissipated as heat, potentially raising the temperature 20 C - 30 C higher\nthan the ambient. In the long term, extreme self-heating erodes efficiency and\nshortens lifetime, thereby dramatically reducing the total energy output.\nTherefore, it is critically important to develop effective and practical (and\npreferably passive) cooling methods to reduce operating temperature of PV\nmodules. In this paper, we explore two fundamental (but often overlooked)\norigins of PV self-heating, namely, sub-bandgap absorption and imperfect\nthermal radiation. The analysis suggests that we redesign the optical\nproperties of the solar module to eliminate parasitic absorption\n(selective-spectral cooling) and enhance thermal emission (radiative cooling).\nOur Comprehensive opto-electro-thermal simulation shows that the proposed\ntechniques would cool the one-sun and low-concentrated terrestrial solar\nmodules up to 10 C and 20 C, respectively. This self-cooling would\nsubstantially extend the lifetime for solar modules, with The corresponding\nincrease in energy yields and reduced LCOE.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Functional geometry of protein-protein interaction networks.   Motivation: Protein-protein interactions (PPIs) are usually modelled as\nnetworks. These networks have extensively been studied using graphlets, small\ninduced subgraphs capturing the local wiring patterns around nodes in networks.\nThey revealed that proteins involved in similar functions tend to be similarly\nwired. However, such simple models can only represent pairwise relationships\nand cannot fully capture the higher-order organization of protein interactions,\nincluding protein complexes. Results: To model the multi-sale organization of\nthese complex biological systems, we utilize simplicial complexes from\ncomputational geometry. The question is how to mine these new representations\nof PPI networks to reveal additional biological information. To address this,\nwe define simplets, a generalization of graphlets to simplicial complexes. By\nusing simplets, we define a sensitive measure of similarity between simplicial\ncomplex network representations that allows for clustering them according to\ntheir data types better than clustering them by using other state-of-the-art\nmeasures, e.g., spectral distance, or facet distribution distance. We model\nhuman and baker's yeast PPI networks as simplicial complexes that capture PPIs\nand protein complexes as simplices. On these models, we show that our newly\nintroduced simplet-based methods cluster proteins by function better than the\nclustering methods that use the standard PPI networks, uncovering the new\nunderlying functional organization of the cell. We demonstrate the existence of\nthe functional geometry in the PPI data and the superiority of our\nsimplet-based methods to effectively mine for new biological information hidden\nin the complexity of the higher order organization of PPI networks.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A new algorithm for fast generalized DFTs.   We give an new arithmetic algorithm to compute the generalized Discrete\nFourier Transform (DFT) over finite groups $G$. The new algorithm uses\n$O(|G|^{\\omega/2 + o(1)})$ operations to compute the generalized DFT over\nfinite groups of Lie type, including the linear, orthogonal, and symplectic\nfamilies and their variants, as well as all finite simple groups of Lie type.\nHere $\\omega$ is the exponent of matrix multiplication, so the exponent\n$\\omega/2$ is optimal if $\\omega = 2$. Previously, \"exponent one\" algorithms\nwere known for supersolvable groups and the symmetric and alternating groups.\nNo exponent one algorithms were known (even under the assumption $\\omega = 2$)\nfor families of linear groups of fixed dimension, and indeed the previous\nbest-known algorithm for $SL_2(F_q)$ had exponent $4/3$ despite being the focus\nof significant effort. We unconditionally achieve exponent at most $1.19$ for\nthis group, and exponent one if $\\omega = 2$. Our algorithm also yields an\nimproved exponent for computing the generalized DFT over general finite groups\n$G$, which beats the longstanding previous best upper bound, for any $\\omega$.\nIn particular, assuming $\\omega = 2$, we achieve exponent $\\sqrt{2}$, while the\nprevious best was $3/2$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectral up- and downshifting of Akhmediev breathers under wind forcing.   We experimentally and numerically investigate the effect of wind forcing on\nthe spectral dynamics of Akhmediev breathers, a wave-type known to model the\nmodulation instability. We develop the wind model to the same order in\nsteepness as the higher order modifcation of the nonlinear Schroedinger\nequation, also referred to as the Dysthe equation. This results in an\nasymmetric wind term in the higher order, in addition to the leading order wind\nforcing term. The derived model is in good agreement with laboratory\nexperiments within the range of the facility's length. We show that the leading\norder forcing term amplifies all frequencies equally and therefore induces only\na broadening of the spectrum while the asymmetric higher order term in the\nmodel enhances higher frequencies more than lower ones. Thus, the latter term\ninduces a permanent upshift of the spectral mean. On the other hand, in\ncontrast to the direct effect of wind forcing, wind can indirectly lead to\nfrequency downshifts, due to dissipative effects such as wave breaking, or\nthrough amplification of the intrinsic spectral asymmetry of the Dysthe\nequation. Furthermore, the definitions of the up- and downshift in terms of\npeak- and mean frequencies, that are critical to relate our work to previous\nresults, are highlighted and discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Uncharted Forest a Technique for Exploratory Data Analysis.   Exploratory data analysis is crucial for developing and understanding\nclassification models from high-dimensional datasets. We explore the utility of\na new unsupervised tree ensemble called uncharted forest for visualizing class\nassociations, sample-sample associations, class heterogeneity, and\nuninformative classes for provenance studies. The uncharted forest algorithm\ncan be used to partition data using random selections of variables and metrics\nbased on statistical spread. After each tree is grown, a tally of the samples\nthat arrive at every terminal node is maintained. Those tallies are stored in\nsingle sample association matrix and a likelihood measure for each sample being\npartitioned with one another can be made. That matrix may be readily viewed as\na heat map, and the probabilities can be quantified via new metrics that\naccount for class or cluster membership. We display the advantages and\nlimitations of using this technique by applying it to two classification\ndatasets and three provenance study datasets. Two of the metrics presented in\nthis paper are also compared with widely used metrics from two algorithms that\nhave variance-based clustering mechanisms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Solvable Hydrodynamics of Quantum Integrable Systems.   The conventional theory of hydrodynamics describes the evolution in time of\nchaotic many-particle systems from local to global equilibrium. In a quantum\nintegrable system, local equilibrium is characterized by a local generalized\nGibbs ensemble or equivalently a local distribution of pseudo-momenta. We study\ntime evolution from local equilibria in such models by solving a certain\nkinetic equation, the \"Bethe-Boltzmann\" equation satisfied by the local\npseudo-momentum density. Explicit comparison with density matrix\nrenormalization group time evolution of a thermal expansion in the XXZ model\nshows that hydrodynamical predictions from smooth initial conditions can be\nremarkably accurate, even for small system sizes. Solutions are also obtained\nin the Lieb-Liniger model for free expansion into vacuum and collisions between\nclouds of particles, which model experiments on ultracold one-dimensional Bose\ngases.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Differentially Private Learning of Undirected Graphical Models using Collective Graphical Models.   We investigate the problem of learning discrete, undirected graphical models\nin a differentially private way. We show that the approach of releasing noisy\nsufficient statistics using the Laplace mechanism achieves a good trade-off\nbetween privacy, utility, and practicality. A naive learning algorithm that\nuses the noisy sufficient statistics \"as is\" outperforms general-purpose\ndifferentially private learning algorithms. However, it has three limitations:\nit ignores knowledge about the data generating process, rests on uncertain\ntheoretical foundations, and exhibits certain pathologies. We develop a more\nprincipled approach that applies the formalism of collective graphical models\nto perform inference over the true sufficient statistics within an\nexpectation-maximization framework. We show that this learns better models than\ncompeting approaches on both synthetic data and on real human mobility data\nused as a case study.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ChaLearn Looking at People: A Review of Events and Resources.   This paper reviews the historic of ChaLearn Looking at People (LAP) events.\nWe started in 2011 (with the release of the first Kinect device) to run\nchallenges related to human action/activity and gesture recognition. Since then\nwe have regularly organized events in a series of competitions covering all\naspects of visual analysis of humans. So far we have organized more than 10\ninternational challenges and events in this field. This paper reviews\nassociated events, and introduces the ChaLearn LAP platform where public\nresources (including code, data and preprints of papers) related to the\norganized events are available. We also provide a discussion on perspectives of\nChaLearn LAP activities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Minimal surfaces near short geodesics in hyperbolic $3$-manifolds.   If $M$ is a finite volume complete hyperbolic $3$-manifold, the quantity\n$\\mathcal A_1(M)$ is defined as the infimum of the areas of closed minimal\nsurfaces in $M$. In this paper we study the continuity property of the\nfunctional $\\mathcal A_1$ with respect to the geometric convergence of\nhyperbolic manifolds. We prove that it is lower semi-continuous and even\ncontinuous if $\\mathcal A_1(M)$ is realized by a minimal surface satisfying\nsome hypotheses. Understanding the interaction between minimal surfaces and\nshort geodesics in $M$ is the main theme of this paper",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Two-fold Role of Observables in Classical and Quantum Kinematics.   Observables have a dual nature in both classical and quantum kinematics: they\nare at the same time \\emph{quantities}, allowing to separate states by means of\ntheir numerical values, and \\emph{generators of transformations}, establishing\nrelations between different states. In this work, we show how this two-fold\nrole of observables constitutes a key feature in the conceptual analysis of\nclassical and quantum kinematics, shedding a new light on the distinguishing\nfeature of the quantum at the kinematical level. We first take a look at the\nalgebraic description of both classical and quantum observables in terms of\nJordan-Lie algebras and show how the two algebraic structures are the precise\nmathematical manifestation of the two-fold role of observables. Then, we turn\nto the geometric reformulation of quantum kinematics in terms of Kähler\nmanifolds. A key achievement of this reformulation is to show that the two-fold\nrole of observables is the constitutive ingredient defining what an observable\nis. Moreover, it points to the fact that, from the restricted point of view of\nthe transformational role of observables, classical and quantum kinematics\nbehave in exactly the same way. Finally, we present Landsman's general\nframework of Poisson spaces with transition probability, which highlights with\nunmatched clarity that the crucial difference between the two kinematics lies\nin the way the two roles of observables are related to each other.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning Aided Optimization for Energy Harvesting Devices with Outdated State Information.   This paper considers utility optimal power control for energy harvesting\nwireless devices with a finite capacity battery. The distribution information\nof the underlying wireless environment and harvestable energy is unknown and\nonly outdated system state information is known at the device controller. This\nscenario shares similarity with Lyapunov opportunistic optimization and online\nlearning but is different from both. By a novel combination of Zinkevich's\nonline gradient learning technique and the drift-plus-penalty technique from\nLyapunov opportunistic optimization, this paper proposes a learning-aided\nalgorithm that achieves utility within $O(\\epsilon)$ of the optimal, for any\ndesired $\\epsilon>0$, by using a battery with an $O(1/\\epsilon)$ capacity. The\nproposed algorithm has low complexity and makes power investment decisions\nbased on system history, without requiring knowledge of the system state or its\nprobability distribution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evidence for universality in the initial planetesimal mass function.   Planetesimals may form from the gravitational collapse of dense particle\nclumps initiated by the streaming instability. We use simulations of\naerodynamically coupled gas-particle mixtures to investigate whether the\nproperties of planetesimals formed in this way depend upon the sizes of the\nparticles that participate in the instability. Based on three high resolution\nsimulations that span a range of dimensionless stopping time $6 \\times 10^{-3}\n\\leq \\tau \\leq 2$ no statistically significant differences in the initial\nplanetesimal mass function are found. The mass functions are fit by a\npower-law, ${\\rm d}N / {\\rm d}M_p \\propto M_p^{-p}$, with $p=1.5-1.7$ and\nerrors of $\\Delta p \\approx 0.1$. Comparing the particle density fields prior\nto collapse, we find that the high wavenumber power spectra are similarly\nindistinguishable, though the large-scale geometry of structures induced via\nthe streaming instability is significantly different between all three cases.\nWe interpret the results as evidence for a near-universal slope to the mass\nfunction, arising from the small-scale structure of streaming-induced\nturbulence.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Parity-Forbidden Transitions and Their Impacts on the Optical Absorption Properties of Lead-Free Metal Halide Perovskites and Double Perovskites.   Using density-functional theory calculations, we analyze the optical\nabsorption properties of lead (Pb)-free metal halide perovskites\n(AB$^{2+}$X$_3$) and double perovskites (AB$^+$B$^{3+}$X$_6$) (A = Cs or\nmonovalent organic ion, B$^{2+}$ = non-Pb divalent metal, B$^+$ = monovalent\nmetal, B$^{3+}$ = trivalent metal, X = halogen). We show that, if B$^{2+}$ is\nnot Sn or Ge, Pb-free metal halide perovskites exhibit poor optical absorptions\nbecause of their indirect bandgap nature. Among the nine possible types of\nPb-free metal halide double perovskites, six have direct bandgaps. Of these six\ntypes, four show inversion symmetry-induced parity-forbidden or weak\ntransitions between band edges, making them not ideal for thin-film solar cell\napplication. Only one type of Pb-free double perovskite shows optical\nabsorption and electronic properties suitable for solar cell applications,\nnamely those with B$^+$ = In, Tl and B$^{3+}$ = Sb, Bi. Our results provide\nimportant insights for designing new metal halide perovskites and double\nperovskites for optoelectronic applications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bootstrap confidence sets for spectral projectors of sample covariance.   Let $X_{1},\\ldots,X_{n}$ be i.i.d. sample in $\\mathbb{R}^{p}$ with zero mean\nand the covariance matrix $\\mathbf{\\Sigma}$. The problem of recovering the\nprojector onto an eigenspace of $\\mathbf{\\Sigma}$ from these observations\nnaturally arises in many applications. Recent technique from [Koltchinskii,\nLounici, 2015] helps to study the asymptotic distribution of the distance in\nthe Frobenius norm $\\| \\mathbf{P}_r - \\widehat{\\mathbf{P}}_r \\|_{2}$ between\nthe true projector $\\mathbf{P}_r$ on the subspace of the $r$-th eigenvalue and\nits empirical counterpart $\\widehat{\\mathbf{P}}_r$ in terms of the effective\nrank of $\\mathbf{\\Sigma}$. This paper offers a bootstrap procedure for building\nsharp confidence sets for the true projector $\\mathbf{P}_r$ from the given\ndata. This procedure does not rely on the asymptotic distribution of $\\|\n\\mathbf{P}_r - \\widehat{\\mathbf{P}}_r \\|_{2}$ and its moments. It could be\napplied for small or moderate sample size $n$ and large dimension $p$. The main\nresult states the validity of the proposed procedure for finite samples with an\nexplicit error bound for the error of bootstrap approximation. This bound\ninvolves some new sharp results on Gaussian comparison and Gaussian\nanti-concentration in high-dimensional spaces. Numeric results confirm a good\nperformance of the method in realistic examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Six operations formalism for generalized operads.   This paper shows that generalizations of operads equipped with their\nrespective bar/cobar dualities are related by a six operations formalism\nanalogous to that of classical contexts in algebraic geometry. As a consequence\nof our constructions, we prove intertwining theorems which govern derived\nKoszul duality of push-forwards and pull-backs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Beyond black-boxes in Bayesian inverse problems and model validation: applications in solid mechanics of elastography.   The present paper is motivated by one of the most fundamental challenges in\ninverse problems, that of quantifying model discrepancies and errors. While\nsignificant strides have been made in calibrating model parameters, the\noverwhelming majority of pertinent methods is based on the assumption of a\nperfect model. Motivated by problems in solid mechanics which, as all problems\nin continuum thermodynamics, are described by conservation laws and\nphenomenological constitutive closures, we argue that in order to quantify\nmodel uncertainty in a physically meaningful manner, one should break open the\nblack-box forward model. In particular we propose formulating an undirected\nprobabilistic model that explicitly accounts for the governing equations and\ntheir validity. This recasts the solution of both forward and inverse problems\nas probabilistic inference tasks where the problem's state variables should not\nonly be compatible with the data but also with the governing equations as well.\nEven though the probability densities involved do not contain any black-box\nterms, they live in much higher-dimensional spaces. In combination with the\nintractability of the normalization constant of the undirected model employed,\nthis poses significant challenges which we propose to address with a\nlinearly-scaling, double-layer of Stochastic Variational Inference. We\ndemonstrate the capabilities and efficacy of the proposed model in synthetic\nforward and inverse problems (with and without model error) in elastography.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Characterization of Thermal Neutron Beam Monitors.   Neutron beam monitors with high efficiency, low gamma sensitivity, high time\nand space resolution are required in neutron beam experiments to continuously\ndiagnose the delivered beam. In this work, commercially available neutron beam\nmonitors have been characterized using the R2D2 beamline at IFE (Norway) and\nusing a Be-based neutron source. For the gamma sensitivity measurements\ndifferent gamma sources have been used. The evaluation of the monitors\nincludes, the study of their efficiency, attenuation, scattering and\nsensitivity to gamma. In this work we report the results of this\ncharacterization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bayesian inference in Y-linked two-sex branching processes with mutations: ABC approach.   A Y-linked two-sex branching process with mutations and blind choice of males\nis a suitable model for analyzing the evolution of the number of carriers of an\nallele and its mutations of a Y-linked gene. Considering a two-sex monogamous\npopulation, in this model each female chooses her partner from among the male\npopulation without caring about his type (i.e., the allele he carries). In this\nwork, we deal with the problem of estimating the main parameters of such model\ndeveloping the Bayesian inference in a parametric framework. Firstly, we\nconsider, as sample scheme, the observation of the total number of females and\nmales up to some generation as well as the number of males of each genotype at\nlast generation. Later, we introduce the information of the mutated males only\nin the last generation obtaining in this way a second sample scheme. For both\nsamples, we apply the Approximate Bayesian Computation (ABC) methodology to\napproximate the posterior distributions of the main parameters of this model.\nThe accuracy of the procedure based on these samples is illustrated and\ndiscussed by way of simulated examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Waldschmidt constants for Stanley-Reisner ideals of a class of graphs.   In the present note we study Waldschmidt constants of Stanley-Reisner ideals\nof a hypergraph and a graph with vertices forming a bipyramid over a planar\nn-gon. The case of the hypergraph has been studied by Bocci and Franci. We\nreprove their main result. The case of the graph is new. Interestingly, both\ncases provide series of ideals with Waldschmidt constants descending to 1. It\nwould be interesting to known if there are bounded ascending sequences of\nWaldschmidt constants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "$L^p$ estimates for the Bergman projection on some Reinhardt domains.   We obtain $L^p$ regularity for the Bergman projection on some Reinhardt\ndomains. We start with a bounded initial domain $\\Omega$ with some symmetry\nproperties and generate successor domains in higher {dimensions}. We prove: If\nthe Bergman kernel on $\\Omega$ satisfies appropriate estimates, then the\nBergman projection on the successor is $L^p$ bounded. For example, the Bergman\nprojection on successors of strictly pseudoconvex initial domains is bounded on\n$L^p$ for $1<p<\\infty$. The successor domains need not have smooth boundary nor\nbe strictly pseudoconvex.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Randomizing growing networks with a time-respecting null model.   Complex networks are often used to represent systems that are not static but\ngrow with time: people make new friendships, new papers are published and refer\nto the existing ones, and so forth. To assess the statistical significance of\nmeasurements made on such networks, we propose a randomization methodology---a\ntime-respecting null model---that preserves both the network's degree sequence\nand the time evolution of individual nodes' degree values. By preserving the\ntemporal linking patterns of the analyzed system, the proposed model is able to\nfactor out the effect of the system's temporal patterns on its structure. We\napply the model to the citation network of Physical Review scholarly papers and\nthe citation network of US movies. The model reveals that the two datasets are\nstrikingly different with respect to their degree-degree correlations, and we\ndiscuss the important implications of this finding on the information provided\nby paradigmatic node centrality metrics such as indegree and Google's PageRank.\nThe randomization methodology proposed here can be used to assess the\nsignificance of any structural property in growing networks, which could bring\nnew insights into the problems where null models play a critical role, such as\nthe detection of communities and network motifs.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Self-Taught Support Vector Machine.   In this paper, a new approach for classification of target task using limited\nlabeled target data as well as enormous unlabeled source data is proposed which\nis called self-taught learning. The target and source data can be drawn from\ndifferent distributions. In the previous approaches, covariate shift assumption\nis considered where the marginal distributions p(x) change over domains and the\nconditional distributions p(y|x) remain the same. In our approach, we propose a\nnew objective function which simultaneously learns a common space T(.) where\nthe conditional distributions over domains p(T(x)|y) remain the same and learns\nrobust SVM classifiers for target task using both source and target data in the\nnew representation. Hence, in the proposed objective function, the hidden label\nof the source data is also incorporated. We applied the proposed approach on\nCaltech-256, MSRC+LMO datasets and compared the performance of our algorithm to\nthe available competing methods. Our method has a superior performance to the\nsuccessful existing algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Block Mean Approximation for Efficient Second Order Optimization.   Advanced optimization algorithms such as Newton method and AdaGrad benefit\nfrom second order derivative or second order statistics to achieve better\ndescent directions and faster convergence rates. At their heart, such\nalgorithms need to compute the inverse or inverse square root of a matrix whose\nsize is quadratic of the dimensionality of the search space. For high\ndimensional search spaces, the matrix inversion or inversion of square root\nbecomes overwhelming which in turn demands for approximate methods. In this\nwork, we propose a new matrix approximation method which divides a matrix into\nblocks and represents each block by one or two numbers. The method allows\nefficient computation of matrix inverse and inverse square root. We apply our\nmethod to AdaGrad in training deep neural networks. Experiments show\nencouraging results compared to the diagonal approximation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantitative analysis of the influence of keV He ion bombardment on exchange bias layer systems.   The mechanism of ion bombardment induced magnetic patterning of exchange bias\nlayer systems for creating engineered magnetic stray field landscapes is still\nunclear. We compare results from vectorial magneto-optic Kerr effect\nmeasurements to a recently proposed model with time dependent rotatable\nmagnetic anisotropy. Results show massive reduction of rotational magnetic\nanisotropy compared to all other magnetic anisotropies. We disprove the\nassumption of comparable weakening of all magnetic anisotropies and show that\nion bombardment mainly influences smaller grains in the antiferromagnet.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Regularization for Deep Learning: A Taxonomy.   Regularization is one of the crucial ingredients of deep learning, yet the\nterm regularization has various definitions, and regularization methods are\noften studied separately from each other. In our work we present a systematic,\nunifying taxonomy to categorize existing methods. We distinguish methods that\naffect data, network architectures, error terms, regularization terms, and\noptimization procedures. We do not provide all details about the listed\nmethods; instead, we present an overview of how the methods can be sorted into\nmeaningful categories and sub-categories. This helps revealing links and\nfundamental similarities between them. Finally, we include practical\nrecommendations both for users and for developers of new regularization\nmethods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gaschütz Lemma for Compact Groups.   We prove the Gaschütz Lemma holds for all metrisable compact groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dual SVM Training on a Budget.   We present a dual subspace ascent algorithm for support vector machine\ntraining that respects a budget constraint limiting the number of support\nvectors. Budget methods are effective for reducing the training time of kernel\nSVM while retaining high accuracy. To date, budget training is available only\nfor primal (SGD-based) solvers. Dual subspace ascent methods like sequential\nminimal optimization are attractive for their good adaptation to the problem\nstructure, their fast convergence rate, and their practical speed. By\nincorporating a budget constraint into a dual algorithm, our method enjoys the\nbest of both worlds. We demonstrate considerable speed-ups over primal budget\ntraining methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Evolutionary Game for User Access Mode Selection in Fog Radio Access Networks.   The fog radio access network (F-RAN) is a promising paradigm for the fifth\ngeneration wireless communication systems to provide high spectral efficiency\nand energy efficiency. Characterizing users to select an appropriate\ncommunication mode among fog access point (F-AP), and device-to-device (D2D) in\nF-RANs is critical for performance optimization. Using evolutionary game\ntheory, we investigate the dynamics of user access mode selection in F-RANs.\nSpecifically, the competition among groups of potential users space is\nformulated as a dynamic evolutionary game, and the evolutionary equilibrium is\nthe solution to this game. Stochastic geometry tool is used to derive the\nproposals' payoff expressions for both F-AP and D2D users by taking into\naccount the different nodes locations, cache sizes as well as the delay cost.\nThe analytical results obtained from the game model are evaluated via\nsimulations, which show that the evolutionary game based access mode selection\nalgorithm can reach a much higher payoff than the max rate based algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Two-component domain decomposition scheme with overlapping subdomains for parabolic equations.   An iteration-free method of domain decomposition is considered for\napproximate solving a boundary value problem for a second-order parabolic\nequation. A standard approach to constructing domain decomposition schemes is\nbased on a partition of unity for the domain under the consideration. Here a\nnew general approach is proposed for constructing domain decomposition schemes\nwith overlapping subdomains based on indicator functions of subdomains. The\nbasic peculiarity of this method is connected with a representation of the\nproblem operator as the sum of two operators, which are constructed for two\nseparate subdomains with the subtraction of the operator that is associated\nwith the intersection of the subdomains. There is developed a two-component\nfactorized scheme, which can be treated as a generalization of the standard\nAlternating Direction Implicit (ADI) schemes to the case of a special\nthree-component splitting. There are obtained conditions for the unconditional\nstability of regionally additive schemes constructed using indicator functions\nof subdomains. Numerical results are presented for a model two-dimensional\nproblem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nondestructive testing of grating imperfections using grating-based X-ray phase-contrast imaging.   We reported the usage of grating-based X-ray phase-contrast imaging in\nnondestructive testing of grating imperfections. It was found that\nelectroplating flaws could be easily detected by conventional absorption\nsignal, and in particular, we observed that the grating defects resulting from\nuneven ultraviolet exposure could be clearly discriminated with phase-contrast\nsignal. The experimental results demonstrate that grating-based X-ray\nphase-contrast imaging, with a conventional low-brilliance X-ray source, a\nlarge field of view and a reasonable compact setup, which simultaneously yields\nphase- and attenuation-contrast signal of the sample, can be ready-to-use in\nfast nondestructive testing of various imperfections in gratings and other\nsimilar photoetching products.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Heterogeneous elastic plates with in-plane modulation of the target curvature and applications to thin gel sheets.   We rigorously derive a Kirchhoff plate theory, via $\\Gamma$-convergence, from\na three-di\\-men\\-sio\\-nal model that describes the finite elasticity of an\nelastically heterogeneous, thin sheet. The heterogeneity in the elastic\nproperties of the material results in a spontaneous strain that depends on both\nthe thickness and the plane variables $x'$. At the same time, the spontaneous\nstrain is $h$-close to the identity, where $h$ is the small parameter\nquantifying the thickness. The 2D Kirchhoff limiting model is constrained to\nthe set of isometric immersions of the mid-plane of the plate into\n$\\mathbb{R}^3$, with a corresponding energy that penalizes deviations of the\ncurvature tensor associated with a deformation from a $x'$-dependent target\ncurvature tensor. A discussion on the 2D minimizers is provided in the case\nwhere the target curvature tensor is piecewise constant. Finally, we apply the\nderived plate theory to the modeling of swelling-induced shape changes in\nheterogeneous thin gel sheets.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Machine Learning for Structured Clinical Data.   Research is a tertiary priority in the EHR, where the priorities are patient\ncare and billing. Because of this, the data is not standardized or formatted in\na manner easily adapted to machine learning approaches. Data may be missing for\na large variety of reasons ranging from individual input styles to differences\nin clinical decision making, for example, which lab tests to issue. Few\npatients are annotated at a research quality, limiting sample size and\npresenting a moving gold standard. Patient progression over time is key to\nunderstanding many diseases but many machine learning algorithms require a\nsnapshot, at a single time point, to create a usable vector form. Furthermore,\nalgorithms that produce black box results do not provide the interpretability\nrequired for clinical adoption. This chapter discusses these challenges and\nothers in applying machine learning techniques to the structured EHR (i.e.\nPatient Demographics, Family History, Medication Information, Vital Signs,\nLaboratory Tests, Genetic Testing). It does not cover feature extraction from\nadditional sources such as imaging data or free text patient notes but the\napproaches discussed can include features extracted from these sources.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The growth of carbon chains in IRC+10216 mapped with ALMA.   Linear carbon chains are common in various types of astronomical molecular\nsources. Possible formation mechanisms involve both bottom-up and top-down\nroutes. We have carried out a combined observational and modeling study of the\nformation of carbon chains in the C-star envelope IRC+10216, where the\npolymerization of acetylene and hydrogen cyanide induced by ultraviolet photons\ncan drive the formation of linear carbon chains of increasing length. We have\nused ALMA to map the emission of 3 mm rotational lines of the hydrocarbon\nradicals C2H, C4H, and C6H, and the CN-containing species CN, C3N, HC3N, and\nHC5N with an angular resolution of 1\". The spatial distribution of all these\nspecies is a hollow, 5-10\" wide, spherical shell located at a radius of 10-20\"\nfrom the star, with no appreciable emission close to the star. Our observations\nresolve the broad shell of carbon chains into thinner sub-shells which are 1-2\"\nwide and not fully concentric, indicating that the mass loss process has been\ndiscontinuous and not fully isotropic. The radial distributions of the species\nmapped reveal subtle differences: while the hydrocarbon radicals have very\nsimilar radial distributions, the CN-containing species show more diverse\ndistributions, with HC3N appearing earlier in the expansion and the radical CN\nextending later than the rest of the species. The observed morphology can be\nrationalized by a chemical model in which the growth of polyynes is mainly\nproduced by rapid gas-phase chemical reactions of C2H and C4H radicals with\nunsaturated hydrocarbons, while cyanopolyynes are mainly formed from polyynes\nin gas-phase reactions with CN and C3N radicals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "V-cycle multigrid algorithms for discontinuous Galerkin methods on non-nested polytopic meshes.   In this paper we analyse the convergence properties of V-cycle multigrid\nalgorithms for the numerical solution of the linear system of equations arising\nfrom discontinuous Galerkin discretization of second-order elliptic partial\ndifferential equations on polytopal meshes. Here, the sequence of spaces that\nstands at the basis of the multigrid scheme is possibly non nested and is\nobtained based on employing agglomeration with possible edge/face coarsening.\nWe prove that the method converges uniformly with respect to the granularity of\nthe grid and the polynomial approximation degree p, provided that the number of\nsmoothing steps, which depends on p, is chosen sufficiently large.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "MC$^2$: Multi-wavelength and dynamical analysis of the merging galaxy cluster ZwCl 0008.8+5215: An older and less massive Bullet Cluster.   We analyze a rich dataset including Subaru/SuprimeCam, HST/ACS and WFC3,\nKeck/DEIMOS, Chandra/ACIS-I, and JVLA/C and D array for the merging galaxy\ncluster ZwCl 0008.8+5215. With a joint Subaru/HST weak gravitational lensing\nanalysis, we identify two dominant subclusters and estimate the masses to be\nM$_{200}=\\text{5.7}^{+\\text{2.8}}_{-\\text{1.8}}\\times\\text{10}^{\\text{14}}\\,\\text{M}_{\\odot}$\nand 1.2$^{+\\text{1.4}}_{-\\text{0.6}}\\times10^{14}$ M$_{\\odot}$. We estimate the\nprojected separation between the two subclusters to be\n924$^{+\\text{243}}_{-\\text{206}}$ kpc. We perform a clustering analysis on\nconfirmed cluster member galaxies and estimate the line of sight velocity\ndifference between the two subclusters to be 92$\\pm$164 km s$^{-\\text{1}}$. We\nfurther motivate, discuss, and analyze the merger scenario through an analysis\nof the 42 ks of Chandra/ACIS-I and JVLA/C and D polarization data. The X-ray\nsurface brightness profile reveals a remnant core reminiscent of the Bullet\nCluster. The X-ray luminosity in the 0.5-7.0 keV band is\n1.7$\\pm$0.1$\\times$10$^{\\text{44}}$ erg s$^{-\\text{1}}$ and the X-ray\ntemperature is 4.90$\\pm$0.13 keV. The radio relics are polarized up to 40$\\%$.\nWe implement a Monte Carlo dynamical analysis and estimate the merger velocity\nat pericenter to be 1800$^{+\\text{400}}_{-\\text{300}}$ km s$^{-\\text{1}}$. ZwCl\n0008.8+5215 is a low-mass version of the Bullet Cluster and therefore may prove\nuseful in testing alternative models of dark matter. We do not find significant\noffsets between dark matter and galaxies, as the uncertainties are large with\nthe current lensing data. Furthermore, in the east, the BCG is offset from\nother luminous cluster galaxies, which poses a puzzle for defining dark matter\n-- galaxy offsets.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Phase diagram of a generalized off-diagonal Aubry-André model with p-wave pairing.   Off-diagonal Aubry-André (AA) model has recently attracted a great deal\nof attention as they provide condensed matter realization of topological\nphases. We numerically study a generalized off-diagonal AA model with p-wave\nsuperfluid pairing in the presence of both commensurate and incommensurate\nhopping modulations. The phase diagram as functions of the modulation strength\nof incommensurate hopping and the strength of the p-wave pairing is obtained by\nusing the multifractal analysis. We show that with the appearance of the p-wave\npairing, the system exhibits mobility-edge phases and critical phases with\nvarious number of topologically protected zero-energy modes. Predicted\ntopological nature of these exotic phases can be realized in a cold atomic\nsystem of incommensurate bichromatic optical lattice with induced p-wave\nsuperfluid pairing by using a Raman laser in proximity to a molecular\nBose-Einstein condensation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "GSAE: an autoencoder with embedded gene-set nodes for genomics functional characterization.   Bioinformatics tools have been developed to interpret gene expression data at\nthe gene set level, and these gene set based analyses improve the biologists'\ncapability to discover functional relevance of their experiment design. While\nelucidating gene set individually, inter gene sets association is rarely taken\ninto consideration. Deep learning, an emerging machine learning technique in\ncomputational biology, can be used to generate an unbiased combination of gene\nset, and to determine the biological relevance and analysis consistency of\nthese combining gene sets by leveraging large genomic data sets. In this study,\nwe proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model\nwith the incorporation of a priori defined gene sets that retain the crucial\nbiological features in the latent layer. We introduced the concept of the gene\nsuperset, an unbiased combination of gene sets with weights trained by the\nautoencoder, where each node in the latent layer is a superset. Trained with\ngenomic data from TCGA and evaluated with their accompanying clinical\nparameters, we showed gene supersets' ability of discriminating tumor subtypes\nand their prognostic capability. We further demonstrated the biological\nrelevance of the top component gene sets in the significant supersets. Using\nautoencoder model and gene superset at its latent layer, we demonstrated that\ngene supersets retain sufficient biological information with respect to tumor\nsubtypes and clinical prognostic significance. Superset also provides high\nreproducibility on survival analysis and accurate prediction for cancer\nsubtypes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Hidden Binary Search Tree:A Balanced Rotation-Free Search Tree in the AVL RAM Model.   In this paper we generalize the definition of \"Search Trees\" (ST) to enable\nreference values other than the key of prior inserted nodes. The idea builds on\nthe assumption an $n$-node AVL (or Red-Black) requires to assure $O(\\log_2n)$\nworst-case search time, namely, a single comparison between two keys takes\nconstant time. This means the size of each key in bits is fixed to $B=c\\log_2\nn$ ($c\\geq1$) once $n$ is determined, otherwise the $O(1)$-time comparison\nassumption does not hold. Based on this we calculate \\emph{ideal} reference\nvalues from the mid-point of the interval $0..2^B$. This idea follows\n`recursively' to assure each node along the search path is provided a reference\nvalue that guarantees an overall logarithmic time. Because the search tree\nproperty works only when keys are compared to reference values and these values\nare calculated only during searches, we term the data structure as the Hidden\nBinary Search Tree (HBST). We show elementary functions to maintain the HSBT\nheight $O(B)=O(\\log_2n)$. This result requires no special order on the input --\nas does BST -- nor self-balancing procedures, as do AVL and Red-Black.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized orderless pooling performs implicit salient matching.   Most recent CNN architectures use average pooling as a final feature encoding\nstep. In the field of fine-grained recognition, however, recent global\nrepresentations like bilinear pooling offer improved performance. In this\npaper, we generalize average and bilinear pooling to \"alpha-pooling\", allowing\nfor learning the pooling strategy during training. In addition, we present a\nnovel way to visualize decisions made by these approaches. We identify parts of\ntraining images having the highest influence on the prediction of a given test\nimage. It allows for justifying decisions to users and also for analyzing the\ninfluence of semantic parts. For example, we can show that the higher capacity\nVGG16 model focuses much more on the bird's head than, e.g., the lower-capacity\nVGG-M model when recognizing fine-grained bird categories. Both contributions\nallow us to analyze the difference when moving between average and bilinear\npooling. In addition, experiments show that our generalized approach can\noutperform both across a variety of standard datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Time- and spatially-resolved magnetization dynamics driven by spin-orbit torques.   Current-induced spin-orbit torques (SOTs) represent one of the most effective\nways to manipulate the magnetization in spintronic devices. The orthogonal\ntorque-magnetization geometry, the strong damping, and the large domain wall\nvelocities inherent to materials with strong spin-orbit coupling make SOTs\nespecially appealing for fast switching applications in nonvolatile memory and\nlogic units. So far, however, the timescale and evolution of the magnetization\nduring the switching process have remained undetected. Here, we report the\ndirect observation of SOT-driven magnetization dynamics in Pt/Co/AlO$_x$ dots\nduring current pulse injection. Time-resolved x-ray images with 25 nm spatial\nand 100 ps temporal resolution reveal that switching is achieved within the\nduration of a sub-ns current pulse by the fast nucleation of an inverted domain\nat the edge of the dot and propagation of a tilted domain wall across the dot.\nThe nucleation point is deterministic and alternates between the four dot\nquadrants depending on the sign of the magnetization, current, and external\nfield. Our measurements reveal how the magnetic symmetry is broken by the\nconcerted action of both damping-like and field-like SOT and show that\nreproducible switching events can be obtained for over $10^{12}$ reversal\ncycles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Spatio-temporal intermittency of the turbulent energy cascade.   In incompressible and periodic statistically stationary turbulence, exchanges\nof turbulent energy across scales and space are characterised by very intense\nand intermittent spatio-temporal fluctuations around zero of the\ntime-derivative term, the spatial turbulent transport of fluctuating energy,\nand the pressure-velocity term. These fluctuations are correlated with each\nother and with the intense intermittent fluctuations of the interscale energy\ntransfer rate. These correlations are caused by the sweeping effect, the link\nbetween non-linearity and non-locality, and also relate to geometrical\nalignments between the two-point fluctuating pressure force difference and the\ntwo-point fluctuating velocity difference in the case of the correlation\nbetween the interscale transfer rate and the pressure-velocity term. All these\nprocesses are absent from the spatio-temporal average picture of the turbulence\ncascade in statistically stationary and homogeneous turbulence.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Dynamical Mass Generation in Pseudo Quantum Electrodynamics with Four-Fermion Interactions.   We describe dynamical symmetry breaking in a system of massless Dirac\nfermions with both electromagnetic and four-fermion interactions in (2+1)\ndimensions. The former is described by the Pseudo Quantum Electrodynamics\n(PQED) and the latter is given by the so-called Gross-Neveu action. We apply\nthe Hubbard-Stratonovich transformation and the large$-N_f$ expansion in our\nmodel to obtain a Yukawa action. Thereafter, the presence of a symmetry broken\nphase is inferred from the non-perturbative Schwinger-Dyson equation for the\nelectron propagator. This is the physical solution whenever the fine-structure\nconstant is larger than a critical value $\\alpha_c(D N_f)$. In particular, we\nobtain the critical coupling constant $\\alpha_c\\approx 0.36$ for $D N_f=8$.,\nwhere $D=2,4$ corresponds to the SU(2) and SU(4) cases, respectively, and $N_f$\nis the flavor number. Our results show a decreasing of the critical coupling\nconstant in comparison with the case of pure electromagnetic interaction, thus\nyielding a more favorable scenario for the occurrence of dynamical symmetry\nbreaking. For two-dimensional materials,in application in condensed matter\nsystems, it implies an energy gap at the Dirac points or valleys of the\nhoneycomb lattice.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An upper bound on transport.   The linear growth of operators in local quantum systems leads to an effective\nlightcone even if the system is non-relativistic. We show that consistency of\ndiffusive transport with this lightcone places an upper bound on the\ndiffusivity: $D \\lesssim v^2 \\tau_\\text{eq}$. The operator growth velocity $v$\ndefines the lightcone and $\\tau_\\text{eq}$ is the local equilibration\ntimescale, beyond which the dynamics of conserved densities is diffusive. We\nverify that the bound is obeyed in various weakly and strongly interacting\ntheories. In holographic models this bound establishes a relation between the\nhydrodynamic and leading non-hydrodynamic quasinormal modes of planar black\nholes. Our bound relates transport data --- including the electrical\nresistivity and the shear viscosity --- to the local equilibration time, even\nin the absence of a quasiparticle description. In this way, the bound sheds\nlight on the observed $T$-linear resistivity of many unconventional metals, the\nshear viscosity of the quark-gluon plasma and the spin transport of unitary\nfermions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Development of a passive Rehabilitation Robot for the wrist joint through the implementation of an Arduino UNO microcontroller.   In this research was implemented the use of an Arduino UNO R3 microcontroller\nto control the movements of a prototype robotic functional developed to perform\nrehabilitation exercises in the wrist joint; This device can be used to assist\nthe physiatrist to rehabilitate the tendinitis, synovitis, rheumatoid arthritis\nand for pre-operative and post-operative therapy in this joint. During the\ndesign stage of the functional prototype, the methodology of the industrial\ndesign process was used from a concurrent engineering approach, through which\nanthropometric studies could be performed related to the dimensions and angles\nof movement of the wrist joint in the population Venezuelan from the\ninformation collected, the design proposal was elaborated, and the use of CAD\nprograms defined the different forms, geometries and materials of the\ncomponents of the rehabilitation device, which were later analyzed using the\nfinite element method for the determination The tensional state of efforts and\nsafety factors through the use of CAE programs. In addition, a software was\ndeveloped for the acquisition, registration, reproduction and execution of the\ndifferent movements produced during the rehabilitation therapy. Through the\nresearch developed, a device was designed that will help the rehabilitation of\nthe wrist joint allowing the combination of dorsal-palmar flexion and\nulnar-radial movements to recover the joint function of various pathologies\npresented in the Venezuelan population.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Short Laws for Finite Groups and Residual Finiteness Growth.   We prove that for every $n \\in \\mathbb{N}$ and $\\delta>0$ there exists a word\n$w_n \\in F_2$ of length $n^{2/3} \\log(n)^{3+\\delta}$ which is a law for every\nfinite group of order at most $n$. This improves upon the main result of [A.\nThom, About the length of laws for finite groups, Isr. J. Math.]. As an\napplication we prove a new lower bound on the residual finiteness growth of\nnon-abelian free groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analysis of a remarkable singularity in a nonlinear DDE.   In this work we investigate the dynamics of the nonlinear DDE\n(delay-differential equation)\nx''(t)+x(t-T)+x(t)^3=0\nwhere T is the delay. For T=0 this system is conservative and exhibits no\nlimit cycles. For T>0, no matter how small, an infinite number of limit cycles\nexist, their amplitudes going to infinity in the limit as T approaches zero.\nWe investigate this situation in three ways: 1) Harmonic Balance, 2)\nMelnikov's integral, and 3) Adding damping to regularize the singularity.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Topologically protected Dirac plasmons in graphene.   Topological optical states exhibit unique immunity to defects and the ability\nto propagate without losses rendering them ideal for photonic applications.A\npowerful class of such states is based on time-reversal symmetry breaking of\nthe optical response.However, existing proposals either involve sophisticated\nand bulky structural designs or can only operate in the microwave regime. Here,\nwe propose and provide a theoretical proof-of-principle demonstration for\nhighly confined topologically protected optical states to be realized at\ninfrared frequencies in a simple 2D material structure-a periodically patterned\ngraphene monolayer-subject to a magnetic field below 1 tesla. In our graphene\nhoneycomb superlattice structures plasmons exhibit substantial nonreciprocal\nbehavior at the superlattice junctions, leading to the emergence of\ntopologically protected edge states and localized bulk modes enabled by the\nstrong magneto-optical response of this material, which leads to\ntime-reversal-symmetry breaking already at moderate static magnetic fields. The\nproposed approach is simple and robust for realizing topologically nontrivial\n2D optical states, not only in graphene, but also in other 2D atomic layers,\nand could pave the way for realizing fast, nanoscale, defect-immune devices for\nintegrated photonics applications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "High-power closed-cycle $^4$He cryostat with top-loading sample exchange.   We report on the development of a versatile cryogen-free laboratory cryostat\nbased upon a commercial pulse tube cryocooler. It provides enough cooling power\nfor continuous recondensation of circulating $^4$He gas at a condensation\npressure of approximately 250~mbar. Moreover, the cryostat allows for exchange\nof different cryostat-inserts as well as fast and easy \"wet\" top-loading of\nsamples directly into the 1 K pot with a turn-over time of less than 75~min.\nStarting from room temperature and using a $^4$He cryostat-insert, a base\ntemperature of 1.0~K is reached within approximately seven hours and a cooling\npower of 250~mW is established at 1.24~K.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Perturbation theory for cosmologies with non-linear structure.   The next generation of cosmological surveys will operate over unprecedented\nscales, and will therefore provide exciting new opportunities for testing\ngeneral relativity. The standard method for modelling the structures that these\nsurveys will observe is to use cosmological perturbation theory for linear\nstructures on horizon-sized scales, and Newtonian gravity for non-linear\nstructures on much smaller scales. We propose a two-parameter formalism that\ngeneralizes this approach, thereby allowing interactions between large and\nsmall scales to be studied in a self-consistent and well-defined way. This uses\nboth post-Newtonian gravity and cosmological perturbation theory, and can be\nused to model realistic cosmological scenarios including matter, radiation and\na cosmological constant. We find that the resulting field equations can be\nwritten as a hierarchical set of perturbation equations. At leading-order,\nthese equations allow us to recover a standard set of Friedmann equations, as\nwell as a Newton-Poisson equation for the inhomogeneous part of the Newtonian\nenergy density in an expanding background. For the perturbations in the\nlarge-scale cosmology, however, we find that the field equations are sourced by\nboth non-linear and mode-mixing terms, due to the existence of small-scale\nstructures. These extra terms should be expected to give rise to new\ngravitational effects, through the mixing of gravitational modes on small and\nlarge scales - effects that are beyond the scope of standard linear\ncosmological perturbation theory. We expect our formalism to be useful for\naccurately modelling gravitational physics in universes that contain non-linear\nstructures, and for investigating the effects of non-linear gravity in the era\nof ultra-large-scale surveys.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Airy structures and symplectic geometry of topological recursion.   We propose a new approach to the topological recursion of Eynard-Orantin\nbased on the notion of Airy structure, which we introduce in the paper. We\nexplain why Airy structure is a more fundamental object than the one of the\nspectral curve. We explain how the concept of quantization of Airy structure\nleads naturally to the formulas of topological recursion as well as their\ngeneralizations. The notion of spectral curve is also considered in a more\ngeneral framework of Poisson surfaces endowed with foliation. We explain how\nthe deformation theory of spectral curves is related to Airy structures. Few\nother topics (e.g. the Holomorphic Anomaly Equation) are also discussed from\nthe general point of view of Airy structures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Skeleton-based Action Recognition of People Handling Objects.   In visual surveillance systems, it is necessary to recognize the behavior of\npeople handling objects such as a phone, a cup, or a plastic bag. In this\npaper, to address this problem, we propose a new framework for recognizing\nobject-related human actions by graph convolutional networks using human and\nobject poses. In this framework, we construct skeletal graphs of reliable human\nposes by selectively sampling the informative frames in a video, which include\nhuman joints with high confidence scores obtained in pose estimation. The\nskeletal graphs generated from the sampled frames represent human poses related\nto the object position in both the spatial and temporal domains, and these\ngraphs are used as inputs to the graph convolutional networks. Through\nexperiments over an open benchmark and our own data sets, we verify the\nvalidity of our framework in that our method outperforms the state-of-the-art\nmethod for skeleton-based action recognition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Block Compressive Sensing of Image and Video with Nonlocal Lagrangian Multiplier and Patch-based Sparse Representation.   Although block compressive sensing (BCS) makes it tractable to sense\nlarge-sized images and video, its recovery performance has yet to be\nsignificantly improved because its recovered images or video usually suffer\nfrom blurred edges, loss of details, and high-frequency oscillatory artifacts,\nespecially at a low subrate. This paper addresses these problems by designing a\nmodified total variation technique that employs multi-block gradient\nprocessing, a denoised Lagrangian multiplier, and patch-based sparse\nrepresentation. In the case of video, the proposed recovery method is able to\nexploit both spatial and temporal similarities. Simulation results confirm the\nimproved performance of the proposed method for compressive sensing of images\nand video in terms of both objective and subjective qualities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A GAMP Based Low Complexity Sparse Bayesian Learning Algorithm.   In this paper, we present an algorithm for the sparse signal recovery problem\nthat incorporates damped Gaussian generalized approximate message passing\n(GGAMP) into Expectation-Maximization (EM)-based sparse Bayesian learning\n(SBL). In particular, GGAMP is used to implement the E-step in SBL in place of\nmatrix inversion, leveraging the fact that GGAMP is guaranteed to converge with\nappropriate damping. The resulting GGAMP-SBL algorithm is much more robust to\narbitrary measurement matrix $\\boldsymbol{A}$ than the standard damped GAMP\nalgorithm while being much lower complexity than the standard SBL algorithm. We\nthen extend the approach from the single measurement vector (SMV) case to the\ntemporally correlated multiple measurement vector (MMV) case, leading to the\nGGAMP-TSBL algorithm. We verify the robustness and computational advantages of\nthe proposed algorithms through numerical experiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parabolic equations with natural growth approximated by nonlocal equations.   In this paper we study several aspects related with solutions of nonlocal\nproblems whose prototype is $$ u_t =\\displaystyle \\int_{\\mathbb{R}^N} J(x-y)\n\\big( u(y,t) -u(x,t) \\big) \\mathcal G\\big( u(y,t) -u(x,t) \\big) dy \\qquad\n\\mbox{ in } \\, \\Omega \\times (0,T)\\,, $$ being $ u (x,t)=0 \\mbox{ in }\n(\\mathbb{R}^N\\setminus \\Omega )\\times (0,T)\\,$ and $ u(x,0)=u_0 (x) \\mbox{ in }\n\\Omega$. We take, as the most important instance, $\\mathcal G (s) \\sim 1+\n\\frac{\\mu}{2} \\frac{s}{1+\\mu^2 s^2 }$ with $\\mu\\in \\mathbb{R}$ as well as $u_0\n\\in L^1 (\\Omega)$, $J$ is a smooth symmetric function with compact support and\n$\\Omega$ is either a bounded smooth subset of $\\mathbb{R}^N$, with nonlocal\nDirichlet boundary condition, or $\\mathbb{R}^N$ itself.\nThe results deal with existence, uniqueness, comparison principle and\nasymptotic behavior. Moreover we prove that if the kernel rescales in a\nsuitable way, the unique solution of the above problem converges to a solution\nof the deterministic Kardar-Parisi-Zhang equation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast-slow asymptotic for semi-analytical ignition criteria in FitzHugh-Nagumo system.   We study the problem of initiation of excitation waves in the FitzHugh-Nagumo\nmodel. Our approach follows earlier works and is based on the idea of\napproximating the boundary between basins of attraction of propagating waves\nand of the resting state as the stable manifold of a critical solution. Here,\nwe obtain analytical expressions for the essential ingredients of the theory by\nsingular perturbation using two small parameters, the separation of time scales\nof the activator and inhibitor, and the threshold in the activator's kinetics.\nThis results in a closed analytical expression for the strength-duration curve.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Geometric theories of patch and Lawson topologies.   We give geometric characterisations of patch and Lawson topologies in the\ncontext of predicative point-free topology using the constructive notion of\nlocated subset. We present the patch topology of a stably locally compact\nformal topology by a geometric theory whose models are the points of the given\ntopology that are located, and the Lawson topology of a continuous lattice by a\ngeometric theory whose models are the located subsets of the given lattice. We\nalso give a predicative presentation of the frame of perfect nuclei on a stably\nlocally compact formal topology, and show that it is essentially the same as\nour geometric presentation of the patch topology. Moreover, the construction of\nLawson topologies naturally induces a monad on the category of compact regular\nformal topologies, which is shown to be isomorphic to the Vietoris monad.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entanglement Entropy in Excited States of the Quantum Lifshitz Model.   We investigate the entanglement properties of an infinite class of excited\nstates in the quantum Lifshitz model (QLM). The presence of a conformal quantum\ncritical point in the QLM makes it unusually tractable for a model above one\nspatial dimension, enabling the ground state entanglement entropy for an\narbitrary domain to be expressed in terms of geometrical and topological\nquantities. Here we extend this result to excited states and find that the\nentanglement can be naturally written in terms of quantities which we dub\n\"entanglement propagator amplitudes\" (EPAs). EPAs are geometrical probabilities\nthat we explicitly calculate and interpret. A comparison of lattice and\ncontinuum results demonstrates that EPAs are universal. This work shows that\nthe QLM is an example of a 2+1d field theory where the universal behavior of\nexcited-state entanglement may be computed analytically.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Mechanisms of dimensionality reduction and decorrelation in deep neural networks.   Deep neural networks are widely used in various domains. However, the nature\nof computations at each layer of the deep networks is far from being well\nunderstood. Increasing the interpretability of deep neural networks is thus\nimportant. Here, we construct a mean-field framework to understand how compact\nrepresentations are developed across layers, not only in deterministic deep\nnetworks with random weights but also in generative deep networks where an\nunsupervised learning is carried out. Our theory shows that the deep\ncomputation implements a dimensionality reduction while maintaining a finite\nlevel of weak correlations between neurons for possible feature extraction.\nMechanisms of dimensionality reduction and decorrelation are unified in the\nsame framework. This work may pave the way for understanding how a sensory\nhierarchy works.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detection of an Optical Counterpart to the ALFALFA Ultra-compact High Velocity Cloud AGC 249525.   We report on the detection at $>$98% confidence of an optical counterpart to\nAGC 249525, an Ultra-Compact High Velocity Cloud (UCHVC) discovered by the\nALFALFA blind neutral hydrogen survey. UCHVCs are compact, isolated HI clouds\nwith properties consistent with their being nearby low-mass galaxies, but\nwithout identified counterparts in extant optical surveys. Analysis of the\nresolved stellar sources in deep $g$- and $i$-band imaging from the WIYN pODI\ncamera reveals a clustering of possible Red Giant Branch stars associated with\nAGC 249525 at a distance of 1.64$\\pm$0.45 Mpc. Matching our optical detection\nwith the HI synthesis map of AGC 249525 from Adams et al. (2016) shows that the\nstellar overdensity is exactly coincident with the highest-density HI contour\nfrom that study. Combining our optical photometry and the HI properties of this\nobject yields an absolute magnitude of $-7.1 \\leq M_V \\leq -4.5$, a stellar\nmass between $2.2\\pm0.6\\times10^4 M_{\\odot}$ and $3.6\\pm1.0\\times10^5\nM_{\\odot}$, and an HI to stellar mass ratio between 9 and 144. This object has\nstellar properties within the observed range of gas-poor Ultra-Faint Dwarfs in\nthe Local Group, but is gas-dominated.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Design of Real-time Semantic Segmentation Decoder for Automated Driving.   Semantic segmentation remains a computationally intensive algorithm for\nembedded deployment even with the rapid growth of computation power. Thus\nefficient network design is a critical aspect especially for applications like\nautomated driving which requires real-time performance. Recently, there has\nbeen a lot of research on designing efficient encoders that are mostly task\nagnostic. Unlike image classification and bounding box object detection tasks,\ndecoders are computationally expensive as well for semantic segmentation task.\nIn this work, we focus on efficient design of the segmentation decoder and\nassume that an efficient encoder is already designed to provide shared features\nfor a multi-task learning system. We design a novel efficient non-bottleneck\nlayer and a family of decoders which fit into a small run-time budget using\nVGG10 as efficient encoder. We demonstrate in our dataset that experimentation\nwith various design choices led to an improvement of 10\\% from a baseline\nperformance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unified description of dynamics of a repulsive two-component Fermi gas.   We study a binary spin-mixture of a zero-temperature repulsively interacting\n$^6$Li atoms using both the atomic-orbital and the density functional\napproaches. The gas is initially prepared in a configuration of two magnetic\ndomains and we determine the frequency of the spin-dipole oscillations which\nare emerging after the repulsive barrier, initially separating the domains, is\nremoved. We find, in agreement with recent experiment (G. Valtolina et al.,\narXiv:1605.07850 (2016)), the occurrence of a ferromagnetic instability in an\natomic gas while the interaction strength between different spin states is\nincreased, after which the system becomes ferromagnetic. The ferromagnetic\ninstability is preceded by the softening of the spin-dipole mode.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Signaling on the Continuous Spectrum of Nonlinear Optical fiber.   This paper studies different signaling techniques on the continuous spectrum\n(CS) of nonlinear optical fiber defined by nonlinear Fourier transform. Three\ndifferent signaling techniques are proposed and analyzed based on the\nstatistics of the noise added to CS after propagation along the nonlinear\noptical fiber. The proposed methods are compared in terms of error performance,\ndistance reach, and complexity. Furthermore, the effect of chromatic dispersion\non the data rate and noise in nonlinear spectral domain is investigated. It is\ndemonstrated that, for a given sequence of CS symbols, an optimal bandwidth (or\nsymbol rate) can be determined so that the temporal duration of the propagated\nsignal at the end of the fiber is minimized. In effect, the required guard\ninterval between the subsequently transmitted data packets in time is minimized\nand the effective data rate is significantly enhanced. Moreover, by selecting\nthe proper signaling method and design criteria a reach distance of 7100 km is\nreported by only singling on the CS at a rate of 9.6 Gbps.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Quasiparticle entropy in superconductor/normal metal/superconductor proximity junctions in the diffusive limit.   We discuss the quasiparticle entropy and heat capacity of a dirty\nsuperconductor-normal metal-superconductor junction. In the case of short\njunctions, the inverse proximity effect extending in the superconducting banks\nplays a crucial role in determining the thermodynamic quantities. In this case,\ncommonly used approximations can violate thermodynamic relations between\nsupercurrent and quasiparticle entropy. We provide analytical and numerical\nresults as a function of different geometrical parameters. Quantitative\nestimates for the heat capacity can be relevant for the design of caloritronic\ndevices or radiation sensor applications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Convergence rates of least squares regression estimators with heavy-tailed errors.   We study the performance of the Least Squares Estimator (LSE) in a general\nnonparametric regression model, when the errors are independent of the\ncovariates but may only have a $p$-th moment ($p\\geq 1$). In such a\nheavy-tailed regression setting, we show that if the model satisfies a standard\n`entropy condition' with exponent $\\alpha \\in (0,2)$, then the $L_2$ loss of\nthe LSE converges at a rate \\begin{align*}\n\\mathcal{O}_{\\mathbf{P}}\\big(n^{-\\frac{1}{2+\\alpha}} \\vee\nn^{-\\frac{1}{2}+\\frac{1}{2p}}\\big). \\end{align*} Such a rate cannot be improved\nunder the entropy condition alone.\nThis rate quantifies both some positive and negative aspects of the LSE in a\nheavy-tailed regression setting. On the positive side, as long as the errors\nhave $p\\geq 1+2/\\alpha$ moments, the $L_2$ loss of the LSE converges at the\nsame rate as if the errors are Gaussian. On the negative side, if\n$p<1+2/\\alpha$, there are (many) hard models at any entropy level $\\alpha$ for\nwhich the $L_2$ loss of the LSE converges at a strictly slower rate than other\nrobust estimators.\nThe validity of the above rate relies crucially on the independence of the\ncovariates and the errors. In fact, the $L_2$ loss of the LSE can converge\narbitrarily slowly when the independence fails.\nThe key technical ingredient is a new multiplier inequality that gives sharp\nbounds for the `multiplier empirical process' associated with the LSE. We\nfurther give an application to the sparse linear regression model with\nheavy-tailed covariates and errors to demonstrate the scope of this new\ninequality.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Algebras of Quasi-Plücker Coordinates are Koszul.   Motivated by the theory of quasi-determinants, we study non-commutative\nalgebras of quasi-Plücker coordinates. We prove that these algebras provide\nnew examples of non-homogeneous quadratic Koszul algebras by showing that their\nquadratic duals have quadratic Gröbner bases.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Submolecular-resolution non-invasive imaging of interfacial water with atomic force microscopy.   Scanning probe microscopy (SPM) has been extensively applied to probe\ninterfacial water in many interdisciplinary fields but the disturbance of the\nprobes on the hydrogen-bonding structure of water has remained an intractable\nproblem. Here we report submolecular-resolution imaging of the water clusters\non a NaCl(001) surface within the nearly non-invasive region by a qPlus-based\nnoncontact atomic force microscopy. Comparison with theoretical simulations\nreveals that the key lies in probing the weak high-order electrostatic force\nbetween the quadrupole-like CO-terminated tip and the polar water molecules at\nlarge tip-water distances. This interaction allows the imaging and structural\ndetermination of the weakly bonded water clusters and even of their metastable\nstates without inducing any disturbance. This work may open up new possibility\nof studying the intrinsic structure and electrostatics of ice or water on bulk\ninsulating surfaces, ion hydration and biological water with atomic precision.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "One-Shot Learning of Multi-Step Tasks from Observation via Activity Localization in Auxiliary Video.   Due to burdensome data requirements, learning from demonstration often falls\nshort of its promise to allow users to quickly and naturally program robots.\nDemonstrations are inherently ambiguous and incomplete, making correct\ngeneralization to unseen situations difficult without a large number of\ndemonstrations in varying conditions. By contrast, humans are often able to\nlearn complex tasks from a single demonstration (typically observations without\naction labels) by leveraging context learned over a lifetime. Inspired by this\ncapability, our goal is to enable robots to perform one-shot learning of\nmulti-step tasks from observation by leveraging auxiliary video data as\ncontext. Our primary contribution is a novel system that achieves this goal by:\n(1) using a single user-segmented demonstration to define the primitive actions\nthat comprise a task, (2) localizing additional examples of these actions in\nunsegmented auxiliary videos via a metalearning-based approach, (3) using these\nadditional examples to learn a reward function for each action, and (4)\nperforming reinforcement learning on top of the inferred reward functions to\nlearn action policies that can be combined to accomplish the task. We\nempirically demonstrate that a robot can learn multi-step tasks more\neffectively when provided auxiliary video, and that performance greatly\nimproves when localizing individual actions, compared to learning from\nunsegmented videos.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Recursion for the smallest eigenvalue density of $β$-Wishart-Laguerre ensemble.   The statistics of the smallest eigenvalue of Wishart-Laguerre ensemble is\nimportant from several perspectives. The smallest eigenvalue density is\ntypically expressible in terms of determinants or Pfaffians. These results are\nof utmost significance in understanding the spectral behavior of\nWishart-Laguerre ensembles and, among other things, unveil the underlying\nuniversality aspects in the asymptotic limits. However, obtaining exact and\nexplicit expressions by expanding determinants or Pfaffians becomes impractical\nif large dimension matrices are involved. For the real matrices ($\\beta=1$)\nEdelman has provided an efficient recurrence scheme to work out exact and\nexplicit results for the smallest eigenvalue density which does not involve\ndeterminants or matrices. Very recently, an analogous recurrence scheme has\nbeen obtained for the complex matrices ($\\beta=2$). In the present work we\nextend this to $\\beta$-Wishart-Laguerre ensembles for the case when exponent\n$\\alpha$ in the associated Laguerre weight function, $\\lambda^\\alpha\ne^{-\\beta\\lambda/2}$, is a non-negative integer, while $\\beta$ is positive\nreal. This also gives access to the smallest eigenvalue density of fixed trace\n$\\beta$-Wishart-Laguerre ensemble, as well as moments for both cases. Moreover,\ncomparison with earlier results for the smallest eigenvalue density in terms of\ncertain hypergeometric function of matrix argument results in an effective way\nof evaluating these explicitly. Exact evaluations for large values of $n$ (the\nmatrix dimension) and $\\alpha$ also enable us to compare with Tracy-Widom\ndensity and large deviation results of Katzav and Castillo. We also use our\nresult to obtain the density of the largest of the proper delay times which are\neigenvalues of the Wigner-Smith matrix and are relevant to the problem of\nquantum chaotic scattering.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Interpretable Low-Dimensional Regression via Data-Adaptive Smoothing.   We consider the problem of estimating a regression function in the common\nsituation where the number of features is small, where interpretability of the\nmodel is a high priority, and where simple linear or additive models fail to\nprovide adequate performance. To address this problem, we present Maximum\nVariance Total Variation denoising (MVTV), an approach that is conceptually\nrelated both to CART and to the more recent CRISP algorithm, a state-of-the-art\nalternative method for interpretable nonlinear regression. MVTV divides the\nfeature space into blocks of constant value and fits the value of all blocks\njointly via a convex optimization routine. Our method is fully data-adaptive,\nin that it incorporates highly robust routines for tuning all hyperparameters\nautomatically. We compare our approach against CART and CRISP via both a\ncomplexity-accuracy tradeoff metric and a human study, demonstrating that that\nMVTV is a more powerful and interpretable method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bivariate Causal Discovery and its Applications to Gene Expression and Imaging Data Analysis.   The mainstream of research in genetics, epigenetics and imaging data analysis\nfocuses on statistical association or exploring statistical dependence between\nvariables. Despite their significant progresses in genetic research,\nunderstanding the etiology and mechanism of complex phenotypes remains elusive.\nUsing association analysis as a major analytical platform for the complex data\nanalysis is a key issue that hampers the theoretic development of genomic\nscience and its application in practice. Causal inference is an essential\ncomponent for the discovery of mechanical relationships among complex\nphenotypes. Many researchers suggest making the transition from association to\ncausation. Despite its fundamental role in science, engineering and\nbiomedicine, the traditional methods for causal inference require at least\nthree variables. However, quantitative genetic analysis such as QTL, eQTL,\nmQTL, and genomic-imaging data analysis requires exploring the causal\nrelationships between two variables. This paper will focus on bivariate causal\ndiscovery. We will introduce independence of cause and mechanism (ICM) as a\nbasic principle for causal inference, algorithmic information theory and\nadditive noise model (ANM) as major tools for bivariate causal discovery.\nLarge-scale simulations will be performed to evaluate the feasibility of the\nANM for bivariate causal discovery. To further evaluate their performance for\ncausal inference, the ANM will be applied to the construction of gene\nregulatory networks. Also, the ANM will be applied to trait-imaging data\nanalysis to illustrate three scenarios: presence of both causation and\nassociation, presence of association while absence of causation, and presence\nof causation, while lack of association between two variables.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Frechet distribution: Estimation and Application an Overview.   In this article, we consider the problem of estimating the parameters of the\nFréchet distribution from both frequentist and Bayesian points of view. First\nwe briefly describe different frequentist approaches, namely, maximum\nlikelihood, method of moments, percentile estimators, L-moments, ordinary and\nweighted least squares, maximum product of spacings, maximum goodness-of-fit\nestimators and compare them with respect to mean relative estimates, mean\nsquared errors and the 95\\% coverage probability of the asymptotic confidence\nintervals using extensive numerical simulations. Next, we consider the Bayesian\ninference approach using reference priors. The Metropolis-Hasting algorithm is\nused to draw Markov Chain Monte Carlo samples, and they have in turn been used\nto compute the Bayes estimates and also to construct the corresponding credible\nintervals. Five real data sets related to the minimum flow of water on\nPiracicaba river in Brazil are used to illustrate the applicability of the\ndiscussed procedures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Estimating Multi-Attribute Choice Preferences using Private Signals and Matrix Factorization.   Revealed preference theory studies the possibility of modeling an agent's\nrevealed preferences and the construction of a consistent utility function.\nHowever, modeling agent's choices over preference orderings is not always\npractical and demands strong assumptions on human rationality and\ndata-acquisition abilities. Therefore, we propose a simple generative choice\nmodel where agents are assumed to generate the choice probabilities based on\nlatent factor matrices that capture their choice evaluation across multiple\nattributes. Since the multi-attribute evaluation is typically hidden within the\nagent's psyche, we consider a signaling mechanism where agents are provided\nwith choice information through private signals, so that the agent's choices\nprovide more insight about his/her latent evaluation across multiple\nattributes. We estimate the choice model via a novel multi-stage matrix\nfactorization algorithm that minimizes the average deviation of the factor\nestimates from choice data. Simulation results are presented to validate the\nestimation performance of our proposed algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-time correlators in continuous measurement of qubit observables.   We consider multi-time correlators for output signals from linear detectors,\ncontinuously measuring several qubit observables at the same time. Using the\nquantum Bayesian formalism, we show that for unital (symmetric) evolution in\nthe absence of phase backaction, an $N$-time correlator can be expressed as a\nproduct of two-time correlators when $N$ is even. For odd $N$, there is a\nsimilar factorization, which also includes a single-time average. Theoretical\npredictions agree well with experimental results for two detectors, which\nsimultaneously measure non-commuting qubit observables.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Formal Methods for Adaptive Control of Dynamical Systems.   We develop a method to control discrete-time systems with constant but\ninitially unknown parameters from linear temporal logic (LTL) specifications.\nWe introduce the notions of (non-deterministic) parametric and adaptive\ntransition systems and show how to use tools from formal methods to compute\nadaptive control strategies for finite systems. For infinite systems, we first\ncompute abstractions in the form of parametric finite quotient transition\nsystems and then apply the techniques for finite systems. Unlike traditional\nadaptive control methods, our approach is correct by design, does not require a\nreference model, and can deal with a much wider range of systems and\nspecifications. Illustrative case studies are included.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An integral formula for the powered sum of the independent, identically and normally distributed random variables.   The distribution of the sum of r-th power of standard normal random variables\nis a generalization of the chi-squared distribution. In this paper, we\nrepresent the probability density function of the random variable by an\none-dimensional absolutely convergent integral with the characteristic\nfunction. Our integral formula is expected to be applied for evaluation of the\ndensity function. Our integral formula is based on the inversion formula, and\nwe utilize a summation method. We also discuss on our formula in the view point\nof hyperfunctions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved Bounds for Online Dominating Sets of Trees.   The online dominating set problem is an online variant of the minimum\ndominating set problem, which is one of the most important NP-hard problems on\ngraphs. This problem is defined as follows: Given an undirected graph $G = (V,\nE)$, in which $V$ is a set of vertices and $E$ is a set of edges. We say that a\nset $D \\subseteq V$ of vertices is a {\\em dominating set} of $G$ if for each $v\n\\in V \\setminus D$, there exists a vertex $u \\in D$ such that $\\{ u, v \\} \\in\nE$. The vertices are revealed to an online algorithm one by one over time. When\na vertex is revealed, edges between the vertex and vertices revealed in the\npast are also revealed. A revelaed subtree is connected at any time.\nImmediately after the revelation of each vertex, an online algorithm can choose\nvertices which were already revealed irrevocably and must maintain a dominating\nset of a graph revealed so far. The cost of an algorithm on a given tree is the\nnumber of vertices chosen by it, and its objective is to minimize the cost.\nEidenbenz (Technical report, Institute of Theoretical Computer Science, ETH\nZürich, 2002) and Boyar et al.\\ (SWAT 2016) studied the case in which given\ngraphs are trees. They designed a deterministic online algorithm whose\ncompetitive ratio is at most three, and proved that a lower bound on the\ncompetitive ratio of any deterministic algorithm is two. In this paper, we also\nfocus on trees. We establish a matching lower bound for any deterministic\nalgorithm. Moreover, we design a randomized online algorithm whose competitive\nratio is at most $5/2 = 2.5$, and show that the competitive ratio of any\nrandomized algorithm is at least $4/3 \\approx 1.333$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multilingual Hierarchical Attention Networks for Document Classification.   Hierarchical attention networks have recently achieved remarkable performance\nfor document classification in a given language. However, when multilingual\ndocument collections are considered, training such models separately for each\nlanguage entails linear parameter growth and lack of cross-language transfer.\nLearning a single multilingual model with fewer parameters is therefore a\nchallenging but potentially beneficial objective. To this end, we propose\nmultilingual hierarchical attention networks for learning document structures,\nwith shared encoders and/or shared attention mechanisms across languages, using\nmulti-task learning and an aligned semantic space as input. We evaluate the\nproposed models on multilingual document classification with disjoint label\nsets, on a large dataset which we provide, with 600k news documents in 8\nlanguages, and 5k labels. The multilingual models outperform monolingual ones\nin low-resource as well as full-resource settings, and use fewer parameters,\nthus confirming their computational efficiency and the utility of\ncross-language transfer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Magnetic resonance of rubidium atoms passing through a multi-layered transmission magnetic grating.   We measured the magnetic resonance of rubidium atoms passing through periodic\nmagnetic fields generated by two types of multilayered transmission magnetic\ngrating. One of the gratings reported here was assembled by stacking four\nlayers of magnetic films so that the direction of magnetization alternated at\neach level. The other grating was assembled so that the magnetization at each\nlevel was aligned. For both types of grating, the experimental results were in\ngood agreement with our calculations. We studied the feasibility of extending\nthe frequency band of the grating and narrowing its resonance linewidth by\nperforming calculations. For magnetic resonance precision spectroscopy, we\nconclude that the multi-layered transmission magnetic grating can generate\nperiodic fields with narrower linewidths at higher frequencies when a larger\nnumber of layers is assembled at a shorter period length. Moreover, the\nfrequency band of this type of grating can potentially achieve frequencies of\nup to hundreds of PHz.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "OGLE-2013-BLG-1761Lb: A Massive Planet Around an M/K Dwarf.   We report the discovery and the analysis of the planetary microlensing event,\nOGLE-2013-BLG-1761. There are some degenerate solutions in this event because\nthe planetary anomaly is only sparsely sampled. But the detailed light curve\nanalysis ruled out all stellar binary models and shows that the lens to be a\nplanetary system. There is the so-called close/wide degeneracy in the solutions\nwith the planet/host mass ratio of $q \\sim (7.5 \\pm 1.5) \\times 10^{-3}$ and $q\n\\sim (9.3 \\pm 2.9) \\times 10^{-3}$ with the projected separation in Einstein\nradius units of $s = 0.95$ (close) and $s = 1.19$ (wide), respectively. The\nmicrolens parallax effect is not detected but the finite source effect is\ndetected. Our Bayesian analysis indicates that the lens system is located at\n$D_{\\rm L}=6.9_{-1.2}^{+1.0} \\ {\\rm kpc}$ away from us and the host star is an\nM/K-dwarf with the mass of $M_{\\rm L}=0.33_{-0.18}^{+0.32} \\ M_{\\odot}$ orbited\nby a super-Jupiter mass planet with the mass of $m_{\\rm P}=2.8_{-1.5}^{+2.5} \\\nM_{\\rm Jup}$ at the projected separation of $a_{\\perp}=1.8_{-0.5}^{+0.5} \\ {\\rm\nAU}$. The preference of the large lens distance in the Bayesian analysis is due\nto the relatively large observed source star radius. The distance and other\nphysical parameters can be constrained by the future high resolution imaging by\nground large telescopes or HST. If the estimated lens distance is correct, this\nplanet provides another sample for testing the claimed deficit of planets in\nthe Galactic bulge.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Implicit Cooperative Positioning in Vehicular Networks.   Absolute positioning of vehicles is based on Global Navigation Satellite\nSystems (GNSS) combined with on-board sensors and high-resolution maps. In\nCooperative Intelligent Transportation Systems (C-ITS), the positioning\nperformance can be augmented by means of vehicular networks that enable\nvehicles to share location-related information. This paper presents an Implicit\nCooperative Positioning (ICP) algorithm that exploits the Vehicle-to-Vehicle\n(V2V) connectivity in an innovative manner, avoiding the use of explicit V2V\nmeasurements such as ranging. In the ICP approach, vehicles jointly localize\nnon-cooperative physical features (such as people, traffic lights or inactive\ncars) in the surrounding areas, and use them as common noisy reference points\nto refine their location estimates. Information on sensed features are fused\nthrough V2V links by a consensus procedure, nested within a message passing\nalgorithm, to enhance the vehicle localization accuracy. As positioning does\nnot rely on explicit ranging information between vehicles, the proposed ICP\nmethod is amenable to implementation with off-the-shelf vehicular communication\nhardware. The localization algorithm is validated in different traffic\nscenarios, including a crossroad area with heterogeneous conditions in terms of\nfeature density and V2V connectivity, as well as a real urban area by using\nSimulation of Urban MObility (SUMO) for traffic data generation. Performance\nresults show that the proposed ICP method can significantly improve the vehicle\nlocation accuracy compared to the stand-alone GNSS, especially in harsh\nenvironments, such as in urban canyons, where the GNSS signal is highly\ndegraded or denied.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The OGLE Collection of Variable Stars. Over 450 000 Eclipsing and Ellipsoidal Binary Systems Toward the Galactic Bulge.   We present a collection of 450 598 eclipsing and ellipsoidal binary systems\ndetected in the OGLE fields toward the Galactic bulge. The collection consists\nof binary systems of all types: detached, semi-detached, and contact eclipsing\nbinaries, RS CVn stars, cataclysmic variables, HW Vir binaries, double periodic\nvariables, and even planetary transits. For all stars we provide the I- and\nV-band time-series photometry obtained during the OGLE-II, OGLE-III, and\nOGLE-IV surveys. We discuss methods used to identify binary systems in the OGLE\ndata and present several objects of particular interest.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Atmospheric thermal tides and planetary spin I. The complex interplay between stratification and rotation.   Thermal atmospheric tides can torque telluric planets away from spin-orbit\nsynchronous rotation, as observed in the case of Venus. They thus participate\nto determine the possible climates and general circulations of the atmospheres\nof these planets. In this work, we write the equations governing the dynamics\nof thermal tides in a local vertically-stratified section of a rotating\nplanetary atmosphere by taking into account the effects of the complete\nCoriolis acceleration on tidal waves. This allows us to derive analytically the\ntidal torque and the tidally dissipated energy, which we use to discuss the\npossible regimes of tidal dissipation and examine the key role played by\nstratification.\nIn agreement with early studies, we find that the frequency dependence of the\nthermal atmospheric tidal torque in the vicinity of synchronization can be\napproximated by a Maxwell model. This behaviour corresponds to weakly stably\nstratified or convective fluid layers, as observed in ADLM2016a. A strong\nstable stratification allows gravity waves to propagate, which makes the tidal\ntorque become negligible. The transition is continuous between these two\nregimes. The traditional approximation appears to be valid in thin atmospheres\nand in regimes where the rotation frequency is dominated by the forcing or the\nbuoyancy frequencies.\nDepending on the stability of their atmospheres with respect to convection,\nobserved exoplanets can be tidally driven toward synchronous or asynchronous\nfinal rotation rates. The domain of applicability of the traditional\napproximation is rigorously constrained by calculations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Single crystal polarized neutron diffraction study of the magnetic structure of HoFeO$_3$.   Polarised neutron diffraction measurements have been made on HoFeO$_3$ single\ncrystals magnetised in both the [001] and [100] directions ($Pbnm$ setting).\nThe polarisation dependencies of Bragg reflection intensities were measured\nboth with a high field of H = 9 T parallel to [001] at T = 70 K and with the\nlower field H = 0.5 T parallel to [100] at T = 5, 15, 25~K. A Fourier\nprojection of magnetization induced parallel to [001], made using the $hk0$\nreflections measured in 9~T, indicates that almost all of it is due to\nalignment of Ho moments. Further analysis of the asymmetries of general\nreflections in these data showed that although, at 70~K, 9~T applied parallel\nto [001] hardly perturbs the antiferromagnetic order of the Fe sublattices, it\ninduces significant antiferromagnetic order of the Ho sublattices in the\n$x\\mhyphen y$ plane, with the antiferromagnetic components of moment having the\nsame order of magnitude as the induced ferromagnetic ones. Strong intensity\nasymmetries measured in the low temperature $\\Gamma_2$ structure with a lower\nfield, 0.5 T $\\parallel$ [100] allowed the variation of the ordered components\nof the Ho and Fe moments to be followed. Their absolute orientations, in the\n180\\degree\\ domain stabilised by the field were determined relative to the\ndistorted perovskite structure,. This relationship fixes the sign of the\nDzyalshinski-Moriya (D-M) interaction which leads to the weak ferromagnetism.\nOur results indicate that the combination of strong y-axis anisotropy of the Ho\nmoments and Ho-Fe exchange interactions breaks the centrosymmetry of the\nstructure and could lead to ferroelectric polarization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Index coding with erroneous side information.   In this paper, new index coding problems are studied, where each receiver has\nerroneous side information. Although side information is a crucial part of\nindex coding, the existence of erroneous side information has not yet been\nconsidered. We study an index code with receivers that have erroneous side\ninformation symbols in the error-free broadcast channel, which is called an\nindex code with side information errors (ICSIE). The encoding and decoding\nprocedures of the ICSIE are proposed, based on the syndrome decoding. Then, we\nderive the bounds on the optimal codelength of the proposed index code with\nerroneous side information. Furthermore, we introduce a special graph for the\nproposed index coding problem, called a $\\delta_s$-cycle whose properties are\nsimilar to those of the cycle in the conventional index coding problem.\nProperties of the ICSIE are also discussed in the $\\delta_s$-cycle and clique.\nFinally, the proposed ICSIE is generalized to an index code for the scenario\nhaving both additive channel errors and side information errors, called a\ngeneralized error correcting index code (GECIC).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A probabilistic approach to emission-line galaxy classification.   We invoke a Gaussian mixture model (GMM) to jointly analyse two traditional\nemission-line classification schemes of galaxy ionization sources: the\nBaldwin-Phillips-Terlevich (BPT) and $\\rm W_{H\\alpha}$ vs. [NII]/H$\\alpha$\n(WHAN) diagrams, using spectroscopic data from the Sloan Digital Sky Survey\nData Release 7 and SEAGal/STARLIGHT datasets. We apply a GMM to empirically\ndefine classes of galaxies in a three-dimensional space spanned by the $\\log$\n[OIII]/H$\\beta$, $\\log$ [NII]/H$\\alpha$, and $\\log$ EW(H${\\alpha}$), optical\nparameters. The best-fit GMM based on several statistical criteria suggests a\nsolution around four Gaussian components (GCs), which are capable to explain up\nto 97 per cent of the data variance. Using elements of information theory, we\ncompare each GC to their respective astronomical counterpart. GC1 and GC4 are\nassociated with star-forming galaxies, suggesting the need to define a new\nstarburst subgroup. GC2 is associated with BPT's Active Galaxy Nuclei (AGN)\nclass and WHAN's weak AGN class. GC3 is associated with BPT's composite class\nand WHAN's strong AGN class. Conversely, there is no statistical evidence --\nbased on four GCs -- for the existence of a Seyfert/LINER dichotomy in our\nsample. Notwithstanding, the inclusion of an additional GC5 unravels it. The\nGC5 appears associated to the LINER and Passive galaxies on the BPT and WHAN\ndiagrams respectively. Subtleties aside, we demonstrate the potential of our\nmethodology to recover/unravel different objects inside the wilderness of\nastronomical datasets, without lacking the ability to convey physically\ninterpretable results. The probabilistic classifications from the GMM analysis\nare publicly available within the COINtoolbox\n(this https URL\\_Catalogue/).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Secure uniform random number extraction via incoherent strategies.   To guarantee the security of uniform random numbers generated by a quantum\nrandom number generator, we study secure extraction of uniform random numbers\nwhen the environment of a given quantum state is controlled by the third party,\nthe eavesdropper. Here we restrict our operations to incoherent strategies that\nare composed of the measurement on the computational basis and incoherent\noperations (or incoherence-preserving operations). We show that the maximum\nsecure extraction rate is equal to the relative entropy of coherence. By\ncontrast, the coherence of formation gives the extraction rate when a certain\nconstraint is imposed on eavesdropper's operations. The condition under which\nthe two extraction rates coincide is then determined. Furthermore, we find that\nthe exponential decreasing rate of the leaked information is characterized by\nRényi relative entropies of coherence. These results clarify the power of\nincoherent strategies in random number generation, and can be applied to\nguarantee the quality of random numbers generated by a quantum random number\ngenerator.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Estimating functional time series by moving average model fitting.   Functional time series have become an integral part of both functional data\nand time series analysis. Important contributions to methodology, theory and\napplication for the prediction of future trajectories and the estimation of\nfunctional time series parameters have been made in the recent past. This paper\ncontinues this line of research by proposing a first principled approach to\nestimate invertible functional time series by fitting functional moving average\nprocesses. The idea is to estimate the coefficient operators in a functional\nlinear filter. To do this a functional Innovations Algorithm is utilized as a\nstarting point to estimate the corresponding moving average operators via\nsuitable projections into principal directions. In order to establish\nconsistency of the proposed estimators, asymptotic theory is developed for\nincreasing subspaces of these principal directions. For practical purposes,\nseveral strategies to select the number of principal directions to include in\nthe estimation procedure as well as the choice of order of the functional\nmoving average process are discussed. Their empirical performance is evaluated\nthrough simulations and an application to vehicle traffic data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Zermelo deformation of Finsler metrics by Killing vector fields.   We show how geodesics, Jacobi vector fields and flag curvature of a Finsler\nmetric behave under Zermelo deformation with respect to a Killing vector field.\nWe also show that Zermelo deformation with respect to a Killing vector field of\na locally symmetric Finsler metric is also locally symmetric.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Variational Inference of Disentangled Latent Concepts from Unlabeled Observations.   Disentangled representations, where the higher level data generative factors\nare reflected in disjoint latent dimensions, offer several benefits such as\nease of deriving invariant representations, transferability to other tasks,\ninterpretability, etc. We consider the problem of unsupervised learning of\ndisentangled representations from large pool of unlabeled observations, and\npropose a variational inference based approach to infer disentangled latent\nfactors. We introduce a regularizer on the expectation of the approximate\nposterior over observed data that encourages the disentanglement. We also\npropose a new disentanglement metric which is better aligned with the\nqualitative disentanglement observed in the decoder's output. We empirically\nobserve significant improvement over existing methods in terms of both\ndisentanglement and data likelihood (reconstruction quality).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "More on cyclic amenability of the Lau product of Banach algebras defined by a Banach algebra morphism.   For two Banach algebras $A$ and $B$, the $T$-Lau product $A\\times_T B$, was\nrecently introduced and studied for some bounded homomorphism $T:B\\to A$ with\n$\\|T\\|\\leq 1$. Here, we give general nessesary and sufficent conditions for\n$A\\times_T B$ to be (approximately) cyclic amenable. In particular, we extend\nsome recent results on (approximate) cyclic amenability of direct product\n$A\\oplus B$ and $T$-Lau product $A\\times_T B$ and answer a question on cyclic\namenability of $A\\times_T B$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Deep Learning Approach for Population Estimation from Satellite Imagery.   Knowing where people live is a fundamental component of many decision making\nprocesses such as urban development, infectious disease containment, evacuation\nplanning, risk management, conservation planning, and more. While bottom-up,\nsurvey driven censuses can provide a comprehensive view into the population\nlandscape of a country, they are expensive to realize, are infrequently\nperformed, and only provide population counts over broad areas. Population\ndisaggregation techniques and population projection methods individually\naddress these shortcomings, but also have shortcomings of their own. To jointly\nanswer the questions of \"where do people live\" and \"how many people live\nthere,\" we propose a deep learning model for creating high-resolution\npopulation estimations from satellite imagery. Specifically, we train\nconvolutional neural networks to predict population in the USA at a\n$0.01^{\\circ} \\times 0.01^{\\circ}$ resolution grid from 1-year composite\nLandsat imagery. We validate these models in two ways: quantitatively, by\ncomparing our model's grid cell estimates aggregated at a county-level to\nseveral US Census county-level population projections, and qualitatively, by\ndirectly interpreting the model's predictions in terms of the satellite image\ninputs. We find that aggregating our model's estimates gives comparable results\nto the Census county-level population projections and that the predictions made\nby our model can be directly interpreted, which give it advantages over\ntraditional population disaggregation methods. In general, our model is an\nexample of how machine learning techniques can be an effective tool for\nextracting information from inherently unstructured, remotely sensed data to\nprovide effective solutions to social problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sequential detection of low-rank changes using extreme eigenvalues.   We study the problem of detecting an abrupt change to the signal covariance\nmatrix. In particular, the covariance changes from a \"white\" identity matrix to\nan unknown spiked or low-rank matrix. Two sequential change-point detection\nprocedures are presented, based on the largest and the smallest eigenvalues of\nthe sample covariance matrix. To control false-alarm-rate, we present an\naccurate theoretical approximation to the average-run-length (ARL) and expected\ndetection delay (EDD) of the detection, leveraging the extreme eigenvalue\ndistributions from random matrix theory and by capturing a non-negligible\ntemporal correlation in the sequence of scan statistics due to the sliding\nwindow approach. Real data examples demonstrate the good performance of our\nmethod for detecting behavior change of a swarm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Computation of Feedback Control for Constrained Systems.   A method is presented for solving the discrete-time finite-horizon Linear\nQuadratic Regulator (LQR) problem subject to auxiliary linear equality\nconstraints, such as fixed end-point constraints. The method explicitly\ndetermines an affine relationship between the control and state variables, as\nin standard Riccati recursion, giving rise to feedback control policies that\naccount for constraints. Since the linearly-constrained LQR problem arises\ncommonly in robotic trajectory optimization, having a method that can\nefficiently compute these solutions is important. We demonstrate some of the\nuseful properties and interpretations of said control policies, and we compare\nthe computation time of our method against existing methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling Oral Multispecies Biofilm Recovery After Antibacterial Treatment.   Recovery of multispecies oral biofilms is investigated following treatment by\nchlorhexidine gluconate (CHX), iodine-potassium iodide (IPI) and Sodium\nhypochlorite (NaOCl) both experimentally and theoretically. Experimentally,\nbiofilms taken from two donors were exposed to the three antibacterial\nsolutions (irrigants) for 10 minutes, respectively. We observe that (a) live\nbacterial cell ratios decline for a week after the exposure and the trend\nreverses beyond a week; after fifteen weeks, live bacterial cell ratios in\nbiofilms fully return to their pretreatment levels; (b) NaOCl is shown as the\nstrongest antibacterial agent for the oral biofilms; (c) multispecies oral\nbiofilms from different donors showed no difference in their susceptibility to\nall the bacterial solutions. Guided by the experiment, a mathematical model for\nbiofilm dynamics is developed, accounting for multiple bacterial phenotypes,\nquorum sensing, and growth factor proteins, to describe the nonlinear time\nevolutionary behavior of the biofilms. The model captures time evolutionary\ndynamics of biofilms before and after antibacterial treatment very well. It\nreveals the crucial role played by quorum sensing molecules and growth factors\nin biofilm recovery and verifies that the source of biofilms has a minimal to\ntheir recovery. The model is also applied to describe the state of biofilms of\nvarious ages treated by CHX, IPI and NaOCl, taken from different donors. Good\nagreement with experimental data predicted by the model is obtained as well,\nconfirming its applicability to modeling biofilm dynamics in general.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "The structure of rationally factorized Lax type flows and their analytical integrability.   The work is devoted to constructing a wide class of differential-functional\ndynamical systems, whose rich algebraic structure makes their integrability\nanalytically effective. In particular, there is analyzed in detail the operator\nLax type equations for factorized seed elements, there is proved an important\ntheorem about their operator factorization and the related analytical solution\nscheme to the corresponding nonlinear differential-functional dynamical\nsystems.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Frank-Wolfe Optimization for Symmetric-NMF under Simplicial Constraint.   Symmetric nonnegative matrix factorization has found abundant applications in\nvarious domains by providing a symmetric low-rank decomposition of nonnegative\nmatrices. In this paper we propose a Frank-Wolfe (FW) solver to optimize the\nsymmetric nonnegative matrix factorization problem under a simplicial\nconstraint, which has recently been proposed for probabilistic clustering.\nCompared with existing solutions, this algorithm is simple to implement, and\nhas no hyperparameters to be tuned. Building on the recent advances of FW\nalgorithms in nonconvex optimization, we prove an $O(1/\\varepsilon^2)$\nconvergence rate to $\\varepsilon$-approximate KKT points, via a tight bound\n$\\Theta(n^2)$ on the curvature constant, which matches the best known result in\nunconstrained nonconvex setting using gradient methods. Numerical results\ndemonstrate the effectiveness of our algorithm. As a side contribution, we\nconstruct a simple nonsmooth convex problem where the FW algorithm fails to\nconverge to the optimum. This result raises an interesting question about\nnecessary conditions of the success of the FW algorithm on convex problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Converse passivity theorems.   Passivity is an imperative concept and a widely utilized tool in the analysis\nand control of interconnected systems. It naturally arises in the modelling of\nphysical systems involving passive elements and dynamics. While many theorems\non passivity are known in the theory of robust control, very few converse\npassivity results exist. This paper establishes various versions of converse\npassivity theorems for nonlinear feedback systems. In particular, open-loop\npassivity is shown to be necessary to ensure closed-loop passivity from an\ninput-output perspective. Moreover, the stability of the feedback\ninterconnection of a specific system with an arbitrary passive system is shown\nto imply passivity of the system itself.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parameter Sharing Deep Deterministic Policy Gradient for Cooperative Multi-agent Reinforcement Learning.   Deep reinforcement learning for multi-agent cooperation and competition has\nbeen a hot topic recently. This paper focuses on cooperative multi-agent\nproblem based on actor-critic methods under local observations settings. Multi\nagent deep deterministic policy gradient obtained state of art results for some\nmulti-agent games, whereas, it cannot scale well with growing amount of agents.\nIn order to boost scalability, we propose a parameter sharing deterministic\npolicy gradient method with three variants based on neural networks, including\nactor-critic sharing, actor sharing and actor sharing with partially shared\ncritic. Benchmarks from rllab show that the proposed method has advantages in\nlearning speed and memory efficiency, well scales with growing amount of\nagents, and moreover, it can make full use of reward sharing and\nexchangeability if possible.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Private Learning on Networks: Part II.   This paper considers a distributed multi-agent optimization problem, with the\nglobal objective consisting of the sum of local objective functions of the\nagents. The agents solve the optimization problem using local computation and\ncommunication between adjacent agents in the network. We present two randomized\niterative algorithms for distributed optimization. To improve privacy, our\nalgorithms add \"structured\" randomization to the information exchanged between\nthe agents. We prove deterministic correctness (in every execution) of the\nproposed algorithms despite the information being perturbed by noise with\nnon-zero mean. We prove that a special case of a proposed algorithm (called\nfunction sharing) preserves privacy of individual polynomial objective\nfunctions under a suitable connectivity condition on the network topology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Antiferromagnetic structure and electronic properties of BaCr2As2 and BaCrFeAs2.   The chromium arsenides BaCr2As2 and BaCrFeAs2 with ThCr2Si2 type structure\n(space group I4/mmm; also adopted by '122' iron arsenide superconductors) have\nbeen suggested as mother compounds for possible new superconductors. DFT-based\ncalculations of the electronic structure evidence metallic antiferromagnetic\nground states for both compounds. By powder neutron diffraction we confirm for\nBaCr2As2 a robust ordering in the antiferromagnetic G-type structure at T_N =\n580 K with mu_Cr = 1.9 mu_B at T = 2K. Anomalies in the lattice parameters\npoint to magneto-structural coupling effects. In BaCrFeAs2 the Cr and Fe atoms\nrandomly occupy the transition-metal site and G-type order is found below 265 K\nwith mu_Cr/Fe = 1.1 mu_B. 57Fe Moessbauer spectroscopy demonstrates that only a\nsmall ordered moment is associated with the Fe atoms, in agreement with\nelectronic structure calculations with mu_Fe ~ 0. The temperature dependence of\nthe hyperfine field does not follow that of the total moments. Both compounds\nare metallic but show large enhancements of the linear specific heat\ncoefficient gamma with respect to the band structure values. The metallic state\nand the electrical transport in BaCrFeAs2 is dominated by the atomic disorder\nof Cr and Fe and partial magnetic disorder of Fe. Our results indicate that\nNeel-type order is unfavorable for the Fe moments and thus it is destabilized\nwith increasing iron content.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Experimental Determination of the Structural Coefficient of Restitution of a Bouncing Asteroid Lander.   The structural coefficient of restitution describes the kinetic energy\ndissipation upon low-velocity (~0.1 m/s) impact of a small asteroid lander,\nMASCOT, against a hard, ideally elastic plane surface. It is a crucial\nworst-case input for mission analysis for landing MACOT on a 1km asteroid in\n2018. We conducted pendulum tests and describe their analysis and the results.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Throughput-Optimal Broadcast in Wireless Networks with Point-to-Multipoint Transmissions.   We consider the problem of efficient packet dissemination in wireless\nnetworks with point-to-multi-point wireless broadcast channels. We propose a\ndynamic policy, which achieves the broadcast capacity of the network. This\npolicy is obtained by first transforming the original multi-hop network into a\nprecedence-relaxed virtual single-hop network and then finding an optimal\nbroadcast policy for the relaxed network. The resulting policy is shown to be\nthroughput-optimal for the original wireless network using a sample-path\nargument. We also prove the NP-completeness of the finite-horizon broadcast\nproblem, which is in contrast with the polynomial time solvability of the\nproblem with point-to-point channels. Illustrative simulation results\ndemonstrate the efficacy of the proposed broadcast policy in achieving the full\nbroadcast capacity with low delay.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Why Do Neural Dialog Systems Generate Short and Meaningless Replies? A Comparison between Dialog and Translation.   This paper addresses the question: Why do neural dialog systems generate\nshort and meaningless replies? We conjecture that, in a dialog system, an\nutterance may have multiple equally plausible replies, causing the deficiency\nof neural networks in the dialog application. We propose a systematic way to\nmimic the dialog scenario in a machine translation system, and manage to\nreproduce the phenomenon of generating short and less meaningful sentences in\nthe translation setting, showing evidence of our conjecture.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effects of sampling skewness of the importance-weighted risk estimator on model selection.   Importance-weighting is a popular and well-researched technique for dealing\nwith sample selection bias and covariate shift. It has desirable\ncharacteristics such as unbiasedness, consistency and low computational\ncomplexity. However, weighting can have a detrimental effect on an estimator as\nwell. In this work, we empirically show that the sampling distribution of an\nimportance-weighted estimator can be skewed. For sample selection bias\nsettings, and for small sample sizes, the importance-weighted risk estimator\nproduces overestimates for datasets in the body of the sampling distribution,\ni.e. the majority of cases, and large underestimates for data sets in the tail\nof the sampling distribution. These over- and underestimates of the risk lead\nto suboptimal regularization parameters when used for importance-weighted\nvalidation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiplicities of bifurcation sets of Pham singularities.   The local multiplicities of the Maxwell sets in the spaces of versal\ndeformations of Pham holomorphic function singularities are calculated. A\nsimilar calculation for some other bifurcation sets (generalized Stokes' sets)\ndefined by more complicated relations between the critical values is given.\nAplications to the complexity of algorithms enumerating topologically distinct\nmorsifications of complicated real function singularities are discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Hadamard Determinant Inequality - Extensions to Operators on a Hilbert Space.   A generalization of classical determinant inequalities like Hadamard's\ninequality and Fischer's inequality is studied. For a version of the\ninequalities originally proved by Arveson for positive operators in von Neumann\nalgebras with a tracial state, we give a different proof. We also improve and\ngeneralize to the setting of finite von Neumann algebras, some `Fischer-type'\ninequalities by Matic for determinants of perturbed positive-definite matrices.\nIn the process, a conceptual framework is established for viewing these\ninequalities as manifestations of Jensen's inequality in conjunction with the\ntheory of operator monotone and operator convex functions on $[0,\\infty)$. We\nplace emphasis on documenting necessary and sufficient conditions for equality\nto hold.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Commutativity theorems for groups and semigroups.   In this note we prove a selection of commutativity theorems for various\nclasses of semigroups. For instance, if in a separative or completely regular\nsemigroup $S$ we have $x^p y^p = y^p x^p$ and $x^q y^q = y^q x^q$ for all\n$x,y\\in S$ where $p$ and $q$ are relatively prime, then $S$ is commutative. In\na separative or inverse semigroup $S$, if there exist three consecutive\nintegers $i$ such that $(xy)^i = x^i y^i$ for all $x,y\\in S$, then $S$ is\ncommutative. Finally, if $S$ is a separative or inverse semigroup satisfying\n$(xy)^3=x^3y^3$ for all $x,y\\in S$, and if the cubing map $x\\mapsto x^3$ is\ninjective, then $S$ is commutative.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effective One-Dimensional Coupling in the Highly-Frustrated Square-Lattice Itinerant Magnet CaCo$_{\\mathrm{2}-y}$As$_{2}$.   Inelastic neutron scattering measurements on the itinerant antiferromagnet\n(AFM) CaCo$_{\\mathrm{2}-y}$As$_{2}$ at a temperature of 8 K reveal two\northogonal planes of scattering perpendicular to the Co square lattice in\nreciprocal space, demonstrating the presence of effective one-dimensional spin\ninteractions. These results are shown to arise from near-perfect bond\nfrustration within the $J_1$-$J_2$ Heisenberg model on a square lattice with\nferromagnetic $J_1$, and hence indicate that the extensive previous\nexperimental and theoretical study of the $J_1$-$J_2$ Heisenberg model on\nlocal-moment square spin lattices should be expanded to include itinerant spin\nsystems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The effect of surface tension on steadily translating bubbles in an unbounded Hele-Shaw cell.   New numerical solutions to the so-called selection problem for one and two\nsteadily translating bubbles in an unbounded Hele-Shaw cell are presented. Our\napproach relies on conformal mapping which, for the two-bubble problem,\ninvolves the Schottky-Klein prime function associated with an annulus. We show\nthat a countably infinite number of solutions exist for each fixed value of\ndimensionless surface tension, with the bubble shapes becoming more exotic as\nthe solution branch number increases. Our numerical results suggest that a\nsingle solution is selected in the limit that surface tension vanishes, with\nthe scaling between the bubble velocity and surface tension being different to\nthe well-studied problems for a bubble or a finger propagating in a channel\ngeometry.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stochastic evolution equations for large portfolios of stochastic volatility models.   We consider a large market model of defaultable assets in which the asset\nprice processes are modelled as Heston-type stochastic volatility models with\ndefault upon hitting a lower boundary. We assume that both the asset prices and\ntheir volatilities are correlated through systemic Brownian motions. We are\ninterested in the loss process that arises in this setting and we prove the\nexistence of a large portfolio limit for the empirical measure process of this\nsystem. This limit evolves as a measure valued process and we show that it will\nhave a density given in terms of a solution to a stochastic partial\ndifferential equation of filtering type in the two-dimensional half-space, with\na Dirichlet boundary condition. We employ Malliavin calculus to establish the\nexistence of a regular density for the volatility component, and an\napproximation by models of piecewise constant volatilities combined with a\nkernel smoothing technique to obtain existence and regularity for the full\ntwo-dimensional filtering problem. We are able to establish good regularity\nproperties for solutions, however uniqueness remains an open problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Taylor coefficients of a subclass of meromorphic univalent functions.   Let $\\mathcal{V}_p(\\lambda)$ be the collection of all functions $f$ defined\nin the unit disc $\\ID$ having a simple pole at $z=p$ where $0<p<1$ and analytic\nin $\\ID\\setminus\\{p\\}$ with $f(0)=0=f'(0)-1$ and satisfying the differential\ninequality $|(z/f(z))^2 f'(z)-1|< \\lambda $ for $z\\in \\ID$, $0<\\lambda\\leq 1$.\nEach $f\\in\\mathcal{V}_p(\\lambda)$ has the following Taylor expansion:\n$$\nf(z)=z+\\sum_{n=2}^{\\infty}a_n(f) z^n, \\quad |z|<p.\n$$\nIn \\cite{BF-3}, we conjectured that\n$$\n|a_n(f)|\\leq \\frac{1-(\\lambda p^2)^n}{p^{n-1}(1-\\lambda p^2)}\\quad\n\\mbox{for}\\quad n\\geq3. $$ In the present article, we first obtain a\nrepresentation formula for functions in the class $\\mathcal{V}_p(\\lambda)$.\nUsing this representation, we prove the aforementioned conjecture for $n=3,4,5$\nwhenever $p$ belongs to certain subintervals of $(0,1)$. Also we determine non\nsharp bounds for $|a_n(f)|,\\,n\\geq 3$ and for $|a_{n+1}(f)-a_n(f)/p|,\\,n\\geq\n2$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Radio detection of Extensive Air Showers (ECRS 2016).   Detection of the mostly geomagnetically generated radio emission of\ncosmic-ray air showers provides an alternative to air-Cherenkov and\nair-fluorescence detection, since it is not limited to clear nights. Like these\nestablished methods, the radio signal is sensitive to the calorimetric energy\nand the position of the maximum of the electromagnetic shower component. This\nmakes antenna arrays an ideal extension for particle-detector arrays above a\nthreshold energy of about 100 PeV of the primary cosmic-ray particles. In the\nlast few years the digital radio technique for cosmic-ray air showers again\nmade significant progress, and there now is a consistent picture of the\nemission mechanisms confirmed by several measurements. Recent results by the\nantenna arrays AERA and Tunka-Rex confirm that the absolute accuracy for the\nshower energy is as good as the other detection techniques. Moreover, the\nsensitivity to the shower maximum of the radio signal has been confirmed in\ndirect comparison to air-Cherenkov measurements by Tunka-Rex. The dense antenna\narray LOFAR can already compete with the established techniques in accuracy for\ncosmic-ray mass-composition. In the future, a new generation of radio\nexperiments might drive the field: either by providing extremely large exposure\nfor inclined cosmic-ray or neutrino showers or, like the SKA core in Australia\nwith its several 10,000 antennas, by providing extremely detailed measurements.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "IMLS-SLAM: scan-to-model matching based on 3D data.   The Simultaneous Localization And Mapping (SLAM) problem has been well\nstudied in the robotics community, especially using mono, stereo cameras or\ndepth sensors. 3D depth sensors, such as Velodyne LiDAR, have proved in the\nlast 10 years to be very useful to perceive the environment in autonomous\ndriving, but few methods exist that directly use these 3D data for odometry. We\npresent a new low-drift SLAM algorithm based only on 3D LiDAR data. Our method\nrelies on a scan-to-model matching framework. We first have a specific sampling\nstrategy based on the LiDAR scans. We then define our model as the previous\nlocalized LiDAR sweeps and use the Implicit Moving Least Squares (IMLS) surface\nrepresentation. We show experiments with the Velodyne HDL32 with only 0.40%\ndrift over a 4 km acquisition without any loop closure (i.e., 16 m drift after\n4 km). We tested our solution on the KITTI benchmark with a Velodyne HDL64 and\nranked among the best methods (against mono, stereo and LiDAR methods) with a\nglobal drift of only 0.69%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "AdS4 backgrounds with N>16 supersymmetries in 10 and 11 dimensions.   We explore all warped $AdS_4\\times_w M^{D-4}$ backgrounds with the most\ngeneral allowed fluxes that preserve more than 16 supersymmetries in $D=10$-\nand $11$-dimensional supergravities. After imposing the assumption that either\nthe internal space $M^{D-4}$ is compact without boundary or the isometry\nalgebra of the background decomposes into that of AdS$_4$ and that of\n$M^{D-4}$, we find that there are no such backgrounds in IIB supergravity.\nSimilarly in IIA supergravity, there is a unique such background with 24\nsupersymmetries locally isometric to $AdS_4\\times \\mathbb{CP}^3$, and in $D=11$\nsupergravity all such backgrounds are locally isometric to the maximally\nsupersymmetric $AdS_4\\times S^7$ solution.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Occupation times for the finite buffer fluid queue with phase-type ON-times.   In this short communication we study a fluid queue with a finite buffer. The\nperformance measure we are interested in is the occupation time over a finite\ntime period, i.e., the fraction of time the workload process is below some\nfixed target level. We construct an alternating sequence of sojourn times\n$D_1,U_1,...$ where the pairs $(D_i,U_i)_{i\\in\\mathbb{N}}$ are i.i.d. random\nvectors. We use this sequence to determine the distribution function of the\noccupation time in terms of its double transform.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Dictionary Approach to Identifying Transient RFI.   As radio telescopes become more sensitive, the damaging effects of radio\nfrequency interference (RFI) become more apparent. Near radio telescope arrays,\nRFI sources are often easily removed or replaced; the challenge lies in\nidentifying them. Transient (impulsive) RFI is particularly difficult to\nidentify. We propose a novel dictionary-based approach to transient RFI\nidentification. RFI events are treated as sequences of sub-events, drawn from\nparticular labelled classes. We demonstrate an automated method of extracting\nand labelling sub-events using a dataset of transient RFI. A dictionary of\nlabels may be used in conjunction with hidden Markov models to identify the\nsources of RFI events reliably. We attain improved classification accuracy over\ntraditional approaches such as SVMs or a naïve kNN classifier. Finally, we\ninvestigate why transient RFI is difficult to classify. We show that cluster\nseparation in the principal components domain is influenced by the mains supply\nphase for certain sources.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Machine vs Machine: Minimax-Optimal Defense Against Adversarial Examples.   Recently, researchers have discovered that the state-of-the-art object\nclassifiers can be fooled easily by small perturbations in the input\nunnoticeable to human eyes. It is also known that an attacker can generate\nstrong adversarial examples if she knows the classifier parameters. Conversely,\na defender can robustify the classifier by retraining if she has access to the\nadversarial examples. We explain and formulate this adversarial example problem\nas a two-player continuous zero-sum game, and demonstrate the fallacy of\nevaluating a defense or an attack as a static problem. To find the best\nworst-case defense against whitebox attacks, we propose a continuous minimax\noptimization algorithm. We demonstrate the minimax defense with two types of\nattack classes -- gradient-based and neural network-based attacks. Experiments\nwith the MNIST and the CIFAR-10 datasets demonstrate that the defense found by\nnumerical minimax optimization is indeed more robust than non-minimax defenses.\nWe discuss directions for improving the result toward achieving robustness\nagainst multiple types of attack classes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The 2017 DAVIS Challenge on Video Object Segmentation.   We present the 2017 DAVIS Challenge on Video Object Segmentation, a public\ndataset, benchmark, and competition specifically designed for the task of video\nobject segmentation. Following the footsteps of other successful initiatives,\nsuch as ILSVRC and PASCAL VOC, which established the avenue of research in the\nfields of scene classification and semantic segmentation, the DAVIS Challenge\ncomprises a dataset, an evaluation methodology, and a public competition with a\ndedicated workshop co-located with CVPR 2017. The DAVIS Challenge follows up on\nthe recent publication of DAVIS (Densely-Annotated VIdeo Segmentation), which\nhas fostered the development of several novel state-of-the-art video object\nsegmentation techniques. In this paper we describe the scope of the benchmark,\nhighlight the main characteristics of the dataset, define the evaluation\nmetrics of the competition, and present a detailed analysis of the results of\nthe participants to the challenge.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometric Rescaling Algorithms for Submodular Function Minimization.   We present a new class of polynomial-time algorithms for submodular function\nminimization (SFM), as well as a unified framework to obtain strongly\npolynomial SFM algorithms. Our new algorithms are based on simple iterative\nmethods for the minimum-norm problem, such as the conditional gradient and the\nFujishige-Wolfe algorithms. We exhibit two techniques to turn simple iterative\nmethods into polynomial-time algorithms.\nFirstly, we use the geometric rescaling technique, which has recently gained\nattention in linear programming. We adapt this technique to SFM and obtain a\nweakly polynomial bound $O((n^4\\cdot EO + n^5)\\log (n L))$.\nSecondly, we exhibit a general combinatorial black-box approach to turn any\nstrongly polynomial $\\varepsilon L$-approximate SFM oracle into a strongly\npolynomial exact SFM algorithm. This framework can be applied to a wide range\nof combinatorial and continuous algorithms, including pseudo-polynomial ones.\nIn particular, we can obtain strongly polynomial algorithms by a repeated\napplication of the conditional gradient or of the Fujishige-Wolfe algorithm.\nCombined with the geometric rescaling technique, the black-box approach\nprovides a $O((n^5\\cdot EO + n^6)\\log^2 n)$ algorithm. Finally, we show that\none of the techniques we develop in the paper can also be combined with the\ncutting-plane method of Lee, Sidford, and Wong, yielding a simplified variant\nof their $O(n^3 \\log^2 n \\cdot EO + n^4\\log^{O(1)} n)$ algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nondegeneracy and the Jacobi fields of rotationally symmetric solutions to the Cahn-Hillard equation.   In this paper we study rotationally symmetric solutions of the Cahn-Hilliard\nequation in $\\mathbb R^3$ constructed by the authors. These solutions form a\none parameter family analog to the family of Delaunay surfaces and in fact the\nzero level sets of their blowdowns approach these surfaces. Presently we go a\nstep further and show that their stability properties are inherited from the\nstability properties of the Delaunay surfaces. Our main result states that the\nrotationally symmetric solutions are non degenerate and that they have exactly\n$6$ Jacobi fields of temperate growth coming from the natural invariances of\nthe problem (3 translations and 2 rotations) and the variation of the Delaunay\nparameter.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Co-location Epidemic Tracking on London Public Transports Using Low Power Mobile Magnetometer.   The public transports provide an ideal means to enable contagious diseases\ntransmission. This paper introduces a novel idea to detect co-location of\npeople in such environment using just the ubiquitous geomagnetic field sensor\non the smart phone. Essentially, given that all passengers must share the same\njourney between at least two consecutive stations, we have a long window to\nmatch the user trajectory. Our idea was assessed over a painstakingly survey of\nover 150 kilometres of travelling distance, covering different parts of London,\nusing the overground trains, the underground tubes and the buses.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A minimally-dissipative low-Mach number solver for complex reacting flows in OpenFOAM.   Large eddy simulation (LES) has become the de-facto computational tool for\nmodeling complex reacting flows, especially in gas turbine applications.\nHowever, readily usable general-purpose LES codes for complex geometries are\ntypically academic or proprietary/commercial in nature. The objective of this\nwork is to develop and disseminate an open source LES tool for low-Mach number\nturbulent combustion using the OpenFOAM framework. In particular, a\ncollocated-mesh approach suited for unstructured grid formulation is provided.\nUnlike other fluid dynamics models, LES accuracy is intricately linked to\nso-called primary and secondary conservation properties of the numerical\ndiscretization schemes. This implies that although the solver only evolves\nequations for mass, momentum, and energy, the implied discrete equation for\nkinetic energy (square of velocity) should be minimally-dissipative. Here, a\nspecific spatial and temporal discretization is imposed such that this kinetic\nenergy dissipation is minimized. The method is demonstrated using manufactured\nsolutions approach on regular and skewed meshes, a canonical flow problem, and\na turbulent sooting flame in a complex domain relevant to gas turbines\napplications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Spelling Correction as a Foreign Language.   In this paper, we reformulated the spell correction problem as a machine\ntranslation task under the encoder-decoder framework. This reformulation\nenabled us to use a single model for solving the problem that is traditionally\nformulated as learning a language model and an error model. This model employs\nmulti-layer recurrent neural networks as an encoder and a decoder. We\ndemonstrate the effectiveness of this model using an internal dataset, where\nthe training data is automatically obtained from user logs. The model offers\ncompetitive performance as compared to the state of the art methods but does\nnot require any feature engineering nor hand tuning between models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Astrophysical uncertainties on the local dark matter distribution and direct detection experiments.   The differential event rate in Weakly Interacting Massive Particle (WIMP)\ndirect detection experiments depends on the local dark matter density and\nvelocity distribution. Accurate modelling of the local dark matter distribution\nis therefore required to obtain reliable constraints on the WIMP particle\nphysics properties. Data analyses typically use a simple Standard Halo Model\nwhich might not be a good approximation to the real Milky Way (MW) halo. We\nreview observational determinations of the local dark matter density, circular\nspeed and escape speed and also studies of the local dark matter distribution\nin simulated MW-like galaxies. We discuss the effects of the uncertainties in\nthese quantities on the energy spectrum and its time and direction dependence.\nFinally we conclude with an overview of various methods for handling these\nastrophysical uncertainties.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Externalities of Exploration and How Data Diversity Helps Exploitation.   Online learning algorithms, widely used to power search and content\noptimization on the web, must balance exploration and exploitation, potentially\nsacrificing the experience of current users for information that will lead to\nbetter decisions in the future. Recently, concerns have been raised about\nwhether the process of exploration could be viewed as unfair, placing too much\nburden on certain individuals or groups. Motivated by these concerns, we\ninitiate the study of the externalities of exploration - the undesirable side\neffects that the presence of one party may impose on another - under the linear\ncontextual bandits model. We introduce the notion of a group externality,\nmeasuring the extent to which the presence of one population of users impacts\nthe rewards of another. We show that this impact can in some cases be negative,\nand that, in a certain sense, no algorithm can avoid it. We then study\nexternalities at the individual level, interpreting the act of exploration as\nan externality imposed on the current user of a system by future users. This\ndrives us to ask under what conditions inherent diversity in the data makes\nexplicit exploration unnecessary. We build on a recent line of work on the\nsmoothed analysis of the greedy algorithm that always chooses the action that\ncurrently looks optimal, improving on prior results to show that a greedy\napproach almost matches the best possible Bayesian regret rate of any other\nalgorithm on the same problem instance whenever the diversity conditions hold,\nand that this regret is at most $\\tilde{O}(T^{1/3})$. Returning to group-level\neffects, we show that under the same conditions, negative group externalities\nessentially vanish under the greedy algorithm. Together, our results uncover a\nsharp contrast between the high externalities that exist in the worst case, and\nthe ability to remove all externalities if the data is sufficiently diverse.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analytical Approach for Calculating Chemotaxis Sensitivity Function.   We consider the chemotaxis problem for a one-dimensional system. To analyze\nthe interaction of bacteria and attractant we use a modified Keller-Segel model\nwhich accounts attractant absorption. To describe the system we use the\nchemotaxis sensitivity function, which characterizes nonuniformity of bacteria\ndistribution. In particular, we investigate how the chemotaxis sensitivity\nfunction depends on the concentration of attractant at the boundary of the\nsystem. It is known that in the system without absorption the chemotaxis\nsensitivity function has a bell shape maximum. Here we show that attractant\nabsorption and special boundary conditions for bacteria can cause the\nappearance of an additional maximum in the chemotaxis sensitivity function. The\nvalue of this maximum is determined by the intensity of absorption.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Real intersection homology.   We present a definition of intersection homology for real algebraic varieties\nthat is analogous to Goresky and MacPherson's original definition of\nintersection homology for complex varieties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Trace Expressiveness of Timed and Probabilistic Automata.   Automata expressiveness is an essential feature in understanding which of the\nformalisms available should be chosen for modelling a particular problem.\nProbabilistic and stochastic automata are suitable for modelling systems\nexhibiting probabilistic behavior and their expressiveness has been studied\nrelative to non-probabilistic transition systems and Markov chains. In this\npaper, we consider previous formalisms of Timed, Probabilistic and Stochastic\nTimed Automata, we present our new model of Timed Automata with Polynomial\nDelay, we introduce a measure of expressiveness for automata we call trace\nexpressiveness and we characterize the expressiveness of these models relative\nto each other under this new measure.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lee-Carter method for forecasting mortality for Peruvian Population.   In this article, we have modeled mortality rates of Peruvian female and male\npopulations during the period of 1950-2017 using the Lee-Carter (LC) model. The\nstochastic mortality model was introduced by Lee and Carter (1992) and has been\nused by many authors for fitting and forecasting the human mortality rates. The\nSingular Value Decomposition (SVD) approach is used for estimation of the\nparameters of the LC model. Utilizing the best fitted auto regressive\nintegrated moving average (ARIMA) model we forecast the values of the time\ndependent parameter of the LC model for the next thirty years. The forecasted\nvalues of life expectancy at different age group with $95\\%$ confidence\nintervals are also reported for the next thirty years. In this research we use\nthe data, obtained from the Peruvian National Institute of Statistics (INEI).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analysis of the Gibbs Sampler for Gaussian hierarchical models via multigrid decomposition.   We study the convergence properties of the Gibbs Sampler in the context of\nposterior distributions arising from Bayesian analysis of Gaussian hierarchical\nmodels. We consider centred and non-centred parameterizations as well as their\nhybrids including the full family of partially non-centred parameterizations.\nWe develop a novel methodology based on multi-grid decompositions to derive\nanalytic expressions for the convergence rates of the algorithm for an\narbitrary number of layers in the hierarchy, while previous work was typically\nlimited to the two-level case. Our work gives a complete understanding for the\nthree-level symmetric case and this gives rise to approximations for the\nnon-symmetric case. We also give analogous, if less explicit, results for\nmodels of arbitrary level. This theory gives rise to simple and\neasy-to-implement guidelines for the practical implementation of Gibbs samplers\non conditionally Gaussian hierarchical models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometric Analysis of Synchronization in Neuronal Networks with Global Inhibition and Coupling Delays.   We study synaptically coupled neuronal networks to identify the role of\ncoupling delays in network's synchronized behaviors. We consider a network of\nexcitable, relaxation oscillator neurons where two distinct populations, one\nexcitatory and one inhibitory, are coupled and interact with each other. The\nexcitatory population is uncoupled, while the inhibitory population is tightly\ncoupled. A geometric singular perturbation analysis yields existence and\nstability conditions for synchronization states under different firing patterns\nbetween the two populations, along with formulas for the periods of such\nsynchronous solutions. Our results demonstrate that the presence of coupling\ndelays in the network promotes synchronization. Numerical simulations are\nconducted to supplement and validate analytical results. We show the results\ncarry over to a model for spindle sleep rhythms in thalamocortical networks,\none of the biological systems which motivated our study. The analysis helps to\nexplain how coupling delays in either excitatory or inhibitory synapses\ncontribute to producing synchronized rhythms.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Iterative bidding in electricity markets: rationality and robustness.   This paper studies an electricity market consisting of an independent system\noperator (ISO) and a group of generators. The goal is to solve the DC optimal\npower flow (DC-OPF) problem: have the generators collectively meet the power\ndemand while minimizing the aggregate generation cost and respecting line flow\nlimits in the network. The ISO by itself cannot solve the DC-OPF problem as\ngenerators are strategic and do not share their cost functions. Instead, each\ngenerator submits to the ISO a bid, consisting of the price per unit of\nelectricity at which it is willing to provide power. Based on the bids, the ISO\ndecides how much production to allocate to each generator to minimize the total\npayment while meeting the load and satisfying the line limits. We provide a\nprovably correct, decentralized iterative scheme, termed BID ADJUSTMENT\nALGORITHM, for the resulting Bertrand competition game. Regarding convergence,\nwe show that the algorithm takes the generators' bids to any desired\nneighborhood of the efficient Nash equilibrium at a linear convergence rate. As\na consequence, the optimal production of the generators converges to the\noptimizer of the DC-OPF problem. Regarding robustness, we show that the\nalgorithm is robust to affine perturbations in the bid adjustment scheme and\nthat there is no incentive for any individual generator to deviate from the\nalgorithm by using an alternative bid update scheme. We also establish the\nalgorithm robustness to collusion, i.e., we show that, as long as each bus with\ngeneration has a generator following the strategy, there is no incentive for\nany group of generators to share information with the intent of tricking the\nsystem to obtain a higher payoff. Simulations illustrate our results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "r-BTN: Cross-domain Face Composite and Synthesis from Limited Facial Patches.   We start by asking an interesting yet challenging question, \"If an eyewitness\ncan only recall the eye features of the suspect, such that the forensic artist\ncan only produce a sketch of the eyes (e.g., the top-left sketch shown in Fig.\n1), can advanced computer vision techniques help generate the whole face\nimage?\" A more generalized question is that if a large proportion (e.g., more\nthan 50%) of the face/sketch is missing, can a realistic whole face\nsketch/image still be estimated. Existing face completion and generation\nmethods either do not conduct domain transfer learning or can not handle large\nmissing area. For example, the inpainting approach tends to blur the generated\nregion when the missing area is large (i.e., more than 50%). In this paper, we\nexploit the potential of deep learning networks in filling large missing region\n(e.g., as high as 95% missing) and generating realistic faces with\nhigh-fidelity in cross domains. We propose the recursive generation by\nbidirectional transformation networks (r-BTN) that recursively generates a\nwhole face/sketch from a small sketch/face patch. The large missing area and\nthe cross domain challenge make it difficult to generate satisfactory results\nusing a unidirectional cross-domain learning structure. On the other hand, a\nforward and backward bidirectional learning between the face and sketch domains\nwould enable recursive estimation of the missing region in an incremental\nmanner (Fig. 1) and yield appealing results. r-BTN also adopts an adversarial\nconstraint to encourage the generation of realistic faces/sketches. Extensive\nexperiments have been conducted to demonstrate the superior performance from\nr-BTN as compared to existing potential solutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Memory effects, transient growth, and wave breakup in a model of paced atrium.   The mechanisms underlying cardiac fibrillation have been investigated for\nover a century, but we are still finding surprising results that change our\nview of this phenomenon. The present study focuses on the transition from\nnormal rhythm to atrial fibrillation associated with a gradual increase in the\npacing rate. While some of our findings are consistent with existing\nexperimental, numerical, and theoretical studies of this problem, one result\nappears to contradict the accepted picture. Specifically we show that, in a\ntwo-dimensional model of paced homogeneous atrial tissue, transition from\ndiscordant alternans to conduction block, wave breakup, reentry, and spiral\nwave chaos is associated with transient growth of finite amplitude disturbances\nrather than a conventional instability. It is mathematically very similar to\nsubcritical, or bypass, transition from laminar fluid flow to turbulence, which\nallows many of the tools developed in the context of fluid turbulence to be\nused for improving our understanding of cardiac arrhythmias.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "It's Time to Consider \"Time\" when Evaluating Recommender-System Algorithms [Proposal].   In this position paper, we question the current practice of calculating\nevaluation metrics for recommender systems as single numbers (e.g. precision\np=.28 or mean absolute error MAE = 1.21). We argue that single numbers express\nonly average effectiveness over a usually rather long period (e.g. a year or\neven longer), which provides only a vague and static view of the data. We\npropose that recommender-system researchers should instead calculate metrics\nfor time-series such as weeks or months, and plot the results in e.g. a line\nchart. This way, results show how algorithms' effectiveness develops over time,\nand hence the results allow drawing more meaningful conclusions about how an\nalgorithm will perform in the future. In this paper, we explain our reasoning,\nprovide an example to illustrate our reasoning and present suggestions for what\nthe community should do next.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Eigendecompositions of Transfer Operators in Reproducing Kernel Hilbert Spaces.   Transfer operators such as the Perron--Frobenius or Koopman operator play an\nimportant role in the global analysis of complex dynamical systems. The\neigenfunctions of these operators can be used to detect metastable sets, to\nproject the dynamics onto the dominant slow processes, or to separate\nsuperimposed signals. We extend transfer operator theory to reproducing kernel\nHilbert spaces and show that these operators are related to Hilbert space\nrepresentations of conditional distributions, known as conditional mean\nembeddings in the machine learning community. Moreover, numerical methods to\ncompute empirical estimates of these embeddings are akin to data-driven methods\nfor the approximation of transfer operators such as extended dynamic mode\ndecomposition and its variants. One main benefit of the presented kernel-based\napproaches is that these methods can be applied to any domain where a\nsimilarity measure given by a kernel is available. We illustrate the results\nwith the aid of guiding examples and highlight potential applications in\nmolecular dynamics as well as video and text data analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A statistical model for aggregating judgments by incorporating peer predictions.   We propose a probabilistic model to aggregate the answers of respondents\nanswering multiple-choice questions. The model does not assume that everyone\nhas access to the same information, and so does not assume that the consensus\nanswer is correct. Instead, it infers the most probable world state, even if\nonly a minority vote for it. Each respondent is modeled as receiving a signal\ncontingent on the actual world state, and as using this signal to both\ndetermine their own answer and predict the answers given by others. By\nincorporating respondent's predictions of others' answers, the model infers\nlatent parameters corresponding to the prior over world states and the\nprobability of different signals being received in all possible world states,\nincluding counterfactual ones. Unlike other probabilistic models for\naggregation, our model applies to both single and multiple questions, in which\ncase it estimates each respondent's expertise. The model shows good\nperformance, compared to a number of other probabilistic models, on data from\nseven studies covering different types of expertise.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reverse approximation of gradient flows as Minimizing Movements: a conjecture by De Giorgi.   We consider the Cauchy problem for the gradient flow \\begin{equation}\n\\label{eq:81}\n\\tag{$\\star$}\nu'(t)=-\\nabla\\phi(u(t)),\\quad t\\ge 0;\\quad\nu(0)=u_0, \\end{equation} generated by a continuously differentiable function\n$\\phi:\\mathbb H \\to \\mathbb R$ in a Hilbert space $\\mathbb H$ and study the\nreverse approximation of solutions to ($\\star$) by the De Giorgi Minimizing\nMovement approach. We prove that if $\\mathbb H$ has finite dimension and $\\phi$\nis quadratically bounded from below (in particular if $\\phi$ is Lipschitz) then\nfor every solution $u$ to ($\\star$) (which may have an infinite number of\nsolutions) there exist perturbations $\\phi_\\tau:\\mathbb H \\to \\mathbb R \\\n(\\tau>0)$ converging to $\\phi$ in the Lipschitz norm such that $u$ can be\napproximated by the Minimizing Movement scheme generated by the recursive\nminimization of $\\Phi(\\tau,U,V):=\\frac 1{2\\tau}|V-U|^2+ \\phi_\\tau(V)$:\n\\begin{equation}\n\\label{eq:abstract}\n\\tag{$\\star\\star$}\nU_\\tau^n\\in \\operatorname{argmin}_{V\\in \\mathbb H}\n\\Phi(\\tau,U_\\tau^{n-1},V)\\quad n\\in\\mathbb N, \\quad U_\\tau^0:=u_0.\n\\end{equation} We show that the piecewise constant interpolations with time\nstep $\\tau > 0$ of all possible selections of solutions\n$(U_\\tau^n)_{n\\in\\mathbb N}$ to ($\\star\\star$) will converge to $u$ as\n$\\tau\\downarrow 0$. This result solves a question raised by Ennio De Giorgi. We\nalso show that even if $\\mathbb H$ has infinite dimension the above\napproximation holds for the distinguished class of minimal solutions to\n($\\star$), that generate all the other solutions to ($\\star$) by time\nreparametrization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A case study of hurdle and generalized additive models in astronomy: the escape of ionizing radiation.   The dark ages of the Universe end with the formation of the first generation\nof stars residing in primeval galaxies. These objects were the first to produce\nultraviolet ionizing photons in a period when the cosmic gas changed from a\nneutral state to an ionized one, known as Epoch of Reionization (EoR). A\npivotal aspect to comprehend the EoR is to probe the intertwined relationship\nbetween the fraction of ionizing photons capable to escape dark haloes, also\nknown as the escape fraction ($f_{esc}$), and the physical properties of the\ngalaxy. This work develops a sound statistical model suitable to account for\nsuch non-linear relationships and the non-Gaussian nature of $f_{esc}$. This\nmodel simultaneously estimates the probability that a given primordial galaxy\nstarts the ionizing photon production and estimates the mean level of the\n$f_{esc}$ once it is triggered. The model was employed in the First Billion\nYears simulation suite, from which we show that the baryonic fraction and the\nrate of ionizing photons appear to have a larger impact on $f_{esc}$ than\npreviously thought. A naive univariate analysis of the same problem would\nsuggest smaller effects for these properties and a much larger impact for the\nspecific star formation rate, which is lessened after accounting for other\ngalaxy properties and non-linearities in the statistical model.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Improving the upper bound on the length of the shortest reset words.   We improve the best known upper bound on the length of the shortest reset\nwords of synchronizing automata. The new bound is slightly better than $114 n^3\n/ 685 + O(n^2)$. The Černý conjecture states that $(n-1)^2$ is an upper\nbound. So far, the best general upper bound was $(n^3-n)/6-1$ obtained by\nJ.-E.~Pin and P.~Frankl in 1982. Despite a number of efforts, it remained\nunchanged for about 35 years.\nTo obtain the new upper bound we utilize avoiding words. A word is avoiding\nfor a state $q$ if after reading the word the automaton cannot be in $q$. We\nobtain upper bounds on the length of the shortest avoiding words, and using the\napproach of Trahtman from 2011 combined with the well known Frankl theorem from\n1982, we improve the general upper bound on the length of the shortest reset\nwords. For all the bounds, there exist polynomial algorithms finding a word of\nlength not exceeding the bound.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Theory of Solvability for Lossless Power Flow Equations -- Part II: Conditions for Radial Networks.   This two-part paper details a theory of solvability for the power flow\nequations in lossless power networks. In Part I, we derived a new formulation\nof the lossless power flow equations, which we term the fixed-point power flow.\nThe model is parameterized by several graph-theoretic matrices -- the power\nnetwork stiffness matrices -- which quantify the internal coupling strength of\nthe network. In Part II, we leverage the fixed-point power flow to study power\nflow solvability. For radial networks, we derive parametric conditions which\nguarantee the existence and uniqueness of a high-voltage power flow solution,\nand construct examples for which the conditions are also necessary. Our\nconditions (i) imply convergence of the fixed-point power flow iteration, (ii)\nunify and extend recent results on solvability of decoupled power flow, (iii)\ndirectly generalize the textbook two-bus system results, and (iv) provide new\ninsights into how the structure and parameters of the grid influence power flow\nsolvability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An accurate approximation formula for gamma function.   In this paper, we present a very accurate approximation for gamma function:\n\\begin{equation*} \\Gamma \\left( x+1\\right) \\thicksim \\sqrt{2\\pi x}\\left(\n\\dfrac{x}{e}\\right) ^{x}\\left( x\\sinh \\frac{1}{x}\\right) ^{x/2}\\exp \\left(\n\\frac{7}{324}\\frac{1}{ x^{3}\\left( 35x^{2}+33\\right) }\\right) =W_{2}\\left(\nx\\right) \\end{equation*} as $x\\rightarrow \\infty $, and prove that the function\n$x\\mapsto \\ln \\Gamma \\left( x+1\\right) -\\ln W_{2}\\left( x\\right) $ is strictly\ndecreasing and convex from $\\left( 1,\\infty \\right) $ onto $\\left( 0,\\beta\n\\right) $, where \\begin{equation*} \\beta =\\frac{22\\,025}{22\\,032}-\\ln\n\\sqrt{2\\pi \\sinh 1}\\approx 0.00002407. \\end{equation*}",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear probability. A theory with incompatible stochastic variables.   In 1991 J.F. Aarnes introduced the concept of quasi-measures in a compact\ntopological space $\\Omega$ and established the connection between quasi-states\non $C (\\Omega)$ and quasi-measures in $\\Omega$. This work solved the linearity\nproblem of quasi-states on $C^*$-algebras formulated by R.V. Kadison in 1965.\nThe answer is that a quasi-state need not be linear, so a quasi-state need not\nbe a state. We introduce nonlinear measures in a space $\\Omega$ which is a\ngeneralization of a measurable space. In this more general setting we are still\nable to define integration and establish a representation theorem for the\ncorresponding functionals. A probabilistic language is choosen since we feel\nthat the subject should be of some interest to probabilists. In particular we\npoint out that the theory allows for incompatible stochastic variables. The\nneed for incompatible variables is well known in quantum mechanics, but the\nneed seems natural also in other contexts as we try to explain by a questionary\nexample.\nKeywords and phrases: Epistemic probability, Integration with respect to mea-\nsures and other set functions, Banach algebras of continuous functions, Set\nfunc- tions and measures on topological spaces, States, Logical foundations of\nquantum mechanics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Compressed Sensing Approach for Distribution Matching.   In this work, we formulate the fixed-length distribution matching as a\nBayesian inference problem. Our proposed solution is inspired from the\ncompressed sensing paradigm and the sparse superposition (SS) codes. First, we\nintroduce sparsity in the binary source via position modulation (PM). We then\npresent a simple and exact matcher based on Gaussian signal quantization. At\nthe receiver, the dematcher exploits the sparsity in the source and performs\nlow-complexity dematching based on generalized approximate message-passing\n(GAMP). We show that GAMP dematcher and spatial coupling lead to asymptotically\noptimal performance, in the sense that the rate tends to the entropy of the\ntarget distribution with vanishing reconstruction error in a proper limit.\nFurthermore, we assess the performance of the dematcher on practical\nHadamard-based operators. A remarkable feature of our proposed solution is the\npossibility to: i) perform matching at the symbol level (nonbinary); ii)\nperform joint channel coding and matching.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Node Centralities and Classification Performance for Characterizing Node Embedding Algorithms.   Embedding graph nodes into a vector space can allow the use of machine\nlearning to e.g. predict node classes, but the study of node embedding\nalgorithms is immature compared to the natural language processing field\nbecause of a diverse nature of graphs. We examine the performance of node\nembedding algorithms with respect to graph centrality measures that\ncharacterize diverse graphs, through systematic experiments with four node\nembedding algorithms, four or five graph centralities, and six datasets.\nExperimental results give insights into the properties of node embedding\nalgorithms, which can be a basis for further research on this topic.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the essential self-adjointness of singular sub-Laplacians.   We prove a general essential self-adjointness criterion for sub-Laplacians on\ncomplete sub-Riemannian manifolds, defined with respect to singular measures.\nAs a consequence, we show that the intrinsic sub-Laplacian (i.e. defined w.r.t.\nPopp's measure) is essentially self-adjoint on the equiregular connected\ncomponents of a sub-Riemannian manifold. This result holds under mild\nregularity assumptions on the singular region, and when the latter does not\ncontain characteristic points.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Back to the Future: an Even More Nearly Optimal Cardinality Estimation Algorithm.   We describe a new cardinality estimation algorithm that is extremely\nspace-efficient. It applies one of three novel estimators to the compressed\nstate of the Flajolet-Martin-85 coupon collection process. In an\napples-to-apples empirical comparison against compressed HyperLogLog sketches,\nthe new algorithm simultaneously wins on all three dimensions of the\ntime/space/accuracy tradeoff. Our prototype uses the zstd compression library,\nand produces sketches that are smaller than the entropy of HLL, so no possible\nimplementation of compressed HLL can match its space efficiency. The paper's\ntechnical contributions include analyses and simulations of the three new\nestimators, accurate values for the entropies of FM85 and HLL, and a\nnon-trivial method for estimating a double asymptotic limit via simulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Locally free actions of groupoids and proper topological correspondences.   Let $(G,\\alpha)$ and $(H,\\beta)$ be locally compact Hausdorff groupoids with\nHaar systems, and let $(X,\\lambda)$ be a topological correspondence from\n$(G,\\alpha)$ to $(H,\\beta)$ which induce the ${C}^*$-correspondence\n$\\mathcal{H}(X)\\colon {C}^*(G,\\alpha)\\to {C}^*(H,\\beta)$. We give sufficient\ntopological conditions which when satisfied the ${C}^*$-correspondence\n$\\mathcal{H}(X)$ is proper, that is, the ${C}^*$-algebra ${C}^*(G,\\alpha)$ acts\non the Hilbert ${C}^*(H,\\beta)$-module ${H}(X)$ via the comapct operators. Thus\na proper topological correspondence produces an element in\n${KK}({C}^*(G,\\alpha),{C}^*(H,\\beta))$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bootstrapped synthetic likelihood.   Approximate Bayesian computation (ABC) and synthetic likelihood (SL)\ntechniques have enabled the use of Bayesian inference for models that may be\nsimulated, but for which the likelihood cannot be evaluated pointwise at values\nof an unknown parameter $\\theta$. The main idea in ABC and SL is to, for\ndifferent values of $\\theta$ (usually chosen using a Monte Carlo algorithm),\nbuild estimates of the likelihood based on simulations from the model\nconditional on $\\theta$. The quality of these estimates determines the\nefficiency of an ABC/SL algorithm. In standard ABC/SL, the only means to\nimprove an estimated likelihood at $\\theta$ is to simulate more times from the\nmodel conditional on $\\theta$, which is infeasible in cases where the simulator\nis computationally expensive. In this paper we describe how to use\nbootstrapping as a means for improving SL estimates whilst using fewer\nsimulations from the model, and also investigate its use in ABC. Further, we\ninvestigate the use of the bag of little bootstraps as a means for applying\nthis approach to large datasets, yielding Monte Carlo algorithms that\naccurately approximate posterior distributions whilst only simulating\nsubsamples of the full data. Examples of the approach applied to i.i.d.,\ntemporal and spatial data are given.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From arteries to boreholes: Transient response of a poroelastic cylinder to fluid injection.   The radially outward flow of fluid through a porous medium occurs in many\npractical problems, from transport across vascular walls to the pressurisation\nof boreholes in the subsurface. When the driving pressure is non-negligible\nrelative to the stiffness of the solid structure, the poromechanical coupling\nbetween the fluid and the solid can control both the steady-state and the\ntransient mechanics of the system. Very large pressures or very soft materials\nlead to large deformations of the solid skeleton, which introduce kinematic and\nconstitutive nonlinearity that can have a nontrivial impact on these mechanics.\nHere, we study the transient response of a poroelastic cylinder to sudden fluid\ninjection. We consider the impacts of kinematic and constitutive nonlinearity,\nboth separately and in combination, and we highlight the central role of\ndriving method in the evolution of the response. We show that the various\nfacets of nonlinearity may either accelerate or decelerate the transient\nresponse relative to linear poroelasticity, depending on the boundary\nconditions and the initial geometry, and that an imposed fluid pressure leads\nto a much faster response than an imposed fluid flux.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Signal-based Bayesian Seismic Monitoring.   Detecting weak seismic events from noisy sensors is a difficult perceptual\ntask. We formulate this task as Bayesian inference and propose a generative\nmodel of seismic events and signals across a network of spatially distributed\nstations. Our system, SIGVISA, is the first to directly model seismic\nwaveforms, allowing it to incorporate a rich representation of the physics\nunderlying the signal generation process. We use Gaussian processes over\nwavelet parameters to predict detailed waveform fluctuations based on\nhistorical events, while degrading smoothly to simple parametric envelopes in\nregions with no historical seismicity. Evaluating on data from the western US,\nwe recover three times as many events as previous work, and reduce mean\nlocation errors by a factor of four while greatly increasing sensitivity to\nlow-magnitude events.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Symmetric Rank Covariances: a Generalised Framework for Nonparametric Measures of Dependence.   The need to test whether two random vectors are independent has spawned a\nlarge number of competing measures of dependence. We are interested in\nnonparametric measures that are invariant under strictly increasing\ntransformations, such as Kendall's tau, Hoeffding's D, and the more recently\ndiscovered Bergsma--Dassios sign covariance. Each of these measures exhibits\nsymmetries that are not readily apparent from their definitions. Making these\nsymmetries explicit, we define a new class of multivariate nonparametric\nmeasures of dependence that we refer to as Symmetric Rank Covariances. This new\nclass generalises all of the above measures and leads naturally to multivariate\nextensions of the Bergsma--Dassios sign covariance. Symmetric Rank Covariances\nmay be estimated unbiasedly using U-statistics for which we prove results on\ncomputational efficiency and large-sample behavior. The algorithms we develop\nfor their computation include, to the best of our knowledge, the first\nefficient algorithms for the well-known Hoeffding's D statistic in the\nmultivariate setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nearly-tight VC-dimension and pseudodimension bounds for piecewise linear neural networks.   We prove new upper and lower bounds on the VC-dimension of deep neural\nnetworks with the ReLU activation function. These bounds are tight for almost\nthe entire range of parameters. Letting $W$ be the number of weights and $L$ be\nthe number of layers, we prove that the VC-dimension is $O(W L \\log(W))$, and\nprovide examples with VC-dimension $\\Omega( W L \\log(W/L) )$. This improves\nboth the previously known upper bounds and lower bounds. In terms of the number\n$U$ of non-linear units, we prove a tight bound $\\Theta(W U)$ on the\nVC-dimension. All of these bounds generalize to arbitrary piecewise linear\nactivation functions, and also hold for the pseudodimensions of these function\nclasses.\nCombined with previous results, this gives an intriguing range of\ndependencies of the VC-dimension on depth for networks with different\nnon-linearities: there is no dependence for piecewise-constant, linear\ndependence for piecewise-linear, and no more than quadratic dependence for\ngeneral piecewise-polynomial.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sketched Subspace Clustering.   The immense amount of daily generated and communicated data presents unique\nchallenges in their processing. Clustering, the grouping of data without the\npresence of ground-truth labels, is an important tool for drawing inferences\nfrom data. Subspace clustering (SC) is a relatively recent method that is able\nto successfully classify nonlinearly separable data in a multitude of settings.\nIn spite of their high clustering accuracy, SC methods incur prohibitively high\ncomputational complexity when processing large volumes of high-dimensional\ndata. Inspired by random sketching approaches for dimensionality reduction, the\npresent paper introduces a randomized scheme for SC, termed Sketch-SC, tailored\nfor large volumes of high-dimensional data. Sketch-SC accelerates the\ncomputationally heavy parts of state-of-the-art SC approaches by compressing\nthe data matrix across both dimensions using random projections, thus enabling\nfast and accurate large-scale SC. Performance analysis as well as extensive\nnumerical tests on real data corroborate the potential of Sketch-SC and its\ncompetitive performance relative to state-of-the-art scalable SC approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Incremental Boosting.   This paper introduces Deep Incremental Boosting, a new technique derived from\nAdaBoost, specifically adapted to work with Deep Learning methods, that reduces\nthe required training time and improves generalisation. We draw inspiration\nfrom Transfer of Learning approaches to reduce the start-up time to training\neach incremental Ensemble member. We show a set of experiments that outlines\nsome preliminary results on some common Deep Learning datasets and discuss the\npotential improvements Deep Incremental Boosting brings to traditional Ensemble\nmethods in Deep Learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A representation theorem for stochastic processes with separable covariance functions, and its implications for emulation.   Many applications require stochastic processes specified on two- or\nhigher-dimensional domains; spatial or spatial-temporal modelling, for example.\nIn these applications it is attractive, for conceptual simplicity and\ncomputational tractability, to propose a covariance function that is separable;\ne.g., the product of a covariance function in space and one in time. This paper\npresents a representation theorem for such a proposal, and shows that all\nprocesses with continuous separable covariance functions are second-order\nidentical to the product of second-order uncorrelated processes. It discusses\nthe implications of separable or nearly separable prior covariances for the\nstatistical emulation of complicated functions such as computer codes, and\ncritically reexamines the conventional wisdom concerning emulator structure,\nand size of design.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Matrix KP: tropical limit and Yang-Baxter maps.   We study soliton solutions of matrix Kadomtsev-Petviashvili (KP) equations in\na tropical limit, in which their support at fixed time is a planar graph and\npolarizations are attached to its constituting lines. There is a subclass of\n\"pure line soliton solutions\" for which we find that, in this limit, the\ndistribution of polarizations is fully determined by a Yang-Baxter map. For a\nvector KP equation, this map is given by an R-matrix, whereas it is a\nnon-linear map in case of a more general matrix KP equation. We also consider\nthe corresponding Korteweg-deVries (KdV) reduction. Furthermore, exploiting the\nfine structure of soliton interactions in the tropical limit, we obtain a new\nsolution of the tetrahedron (or Zamolodchikov) equation. Moreover, a solution\nof the functional tetrahedron equation arises from the parameter-dependence of\nthe vector KP R-matrix.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Design of Improved Quasi-Cyclic Protograph-Based Raptor-Like LDPC Codes for Short Block-Lengths.   Protograph-based Raptor-like low-density parity-check codes (PBRL codes) are\na recently proposed family of easily encodable and decodable rate-compatible\nLDPC (RC-LDPC) codes. These codes have an excellent iterative decoding\nthreshold and performance across all design rates. PBRL codes designed thus\nfar, for both long and short block-lengths, have been based on optimizing the\niterative decoding threshold of the protograph of the RC code family at various\ndesign rates.\nIn this work, we propose a design method to obtain better quasi-cyclic (QC)\nRC-LDPC codes with PBRL structure for short block-lengths (of a few hundred\nbits). We achieve this by maximizing an upper bound on the minimum distance of\nany QC-LDPC code that can be obtained from the protograph of a PBRL ensemble.\nThe obtained codes outperform the original PBRL codes at short block-lengths by\nsignificantly improving the error floor behavior at all design rates.\nFurthermore, we identify a reduction in complexity of the design procedure,\nfacilitated by the general structure of a PBRL ensemble.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Some results on Ricatti Equations, Floquet Theory and Applications.   In this paper, we present two new results to the classical Floquet theory,\nwhich provides the Floquet multipliers for two classes of the planar periodic\nsystem. One these results provides the Floquet multipliers independently of the\nsolution of system. To demonstrate the application of these analytical results,\nwe consider a cholera epidemic model with phage dynamics and seasonality\nincorporated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "DroidStar: Callback Typestates for Android Classes.   Event-driven programming frameworks, such as Android, are based on components\nwith asynchronous interfaces. The protocols for interacting with these\ncomponents can often be described by finite-state machines we dub *callback\ntypestates*. Callback typestates are akin to classical typestates, with the\ndifference that their outputs (callbacks) are produced asynchronously. While\nuseful, these specifications are not commonly available, because writing them\nis difficult and error-prone.\nOur goal is to make the task of producing callback typestates significantly\neasier. We present a callback typestate assistant tool, DroidStar, that\nrequires only limited user interaction to produce a callback typestate. Our\napproach is based on an active learning algorithm, L*. We improved the\nscalability of equivalence queries (a key component of L*), thus making active\nlearning tractable on the Android system.\nWe use DroidStar to learn callback typestates for Android classes both for\ncases where one is already provided by the documentation, and for cases where\nthe documentation is unclear. The results show that DroidStar learns callback\ntypestates accurately and efficiently. Moreover, in several cases, the\nsynthesized callback typestates uncovered surprising and undocumented\nbehaviors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A framework for Multi-A(rmed)/B(andit) testing with online FDR control.   We propose an alternative framework to existing setups for controlling false\nalarms when multiple A/B tests are run over time. This setup arises in many\npractical applications, e.g. when pharmaceutical companies test new treatment\noptions against control pills for different diseases, or when internet\ncompanies test their default webpages versus various alternatives over time.\nOur framework proposes to replace a sequence of A/B tests by a sequence of\nbest-arm MAB instances, which can be continuously monitored by the data\nscientist. When interleaving the MAB tests with an an online false discovery\nrate (FDR) algorithm, we can obtain the best of both worlds: low sample\ncomplexity and any time online FDR control. Our main contributions are: (i) to\npropose reasonable definitions of a null hypothesis for MAB instances; (ii) to\ndemonstrate how one can derive an always-valid sequential p-value that allows\ncontinuous monitoring of each MAB test; and (iii) to show that using rejection\nthresholds of online-FDR algorithms as the confidence levels for the MAB\nalgorithms results in both sample-optimality, high power and low FDR at any\npoint in time. We run extensive simulations to verify our claims, and also\nreport results on real data collected from the New Yorker Cartoon Caption\ncontest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Functional Observers for LTI Systems.   We study the problem of designing distributed functional observers for LTI\nsystems. Specifically, we consider a setting consisting of a state vector that\nevolves over time according to a dynamical process. A set of nodes distributed\nover a communication network wish to collaboratively estimate certain functions\nof the state. We first show that classical existence conditions for the design\nof centralized functional observers do not directly translate to the\ndistributed setting, due to the coupling that exists between the dynamics of\nthe functions of interest and the diverse measurements at the various nodes.\nAccordingly, we design transformations that reveal such couplings and identify\nportions of the corresponding dynamics that are locally detectable at each\nsensor node. We provide sufficient conditions on the network, along with state\nestimate update and exchange rules for each node, that guarantee asymptotic\nreconstruction of the functions at each sensor node.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The First Detection of Gravitational Waves.   This article deals with the first detection of gravitational waves by the\nadvanced Laser Interferometer Gravitational Wave Observatory (LIGO) detectors\non 14 September 2015, where the signal was generated by two stellar mass black\nholes with masses 36 $ M_{\\odot}$ and 29 $ M_{\\odot}$ that merged to form a 62\n$ M_{\\odot}$ black hole, releasing 3 $M_{\\odot}$ energy in gravitational waves,\nalmost 1.3 billion years ago. We begin by providing a brief overview of\ngravitational waves, their sources and the gravitational wave detectors. We\nthen describe in detail the first detection of gravitational waves from a\nbinary black hole merger. We then comment on the electromagnetic follow up of\nthe detection event with various telescopes. Finally, we conclude with the\ndiscussion on the tests of gravity and fundamental physics with the first\ngravitational wave detection event.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Gas dynamics in strong centrifugal fields.   Dynamics of waves generated by scopes in gas centrifuges (GC) for isotope\nseparation is considered. The centrifugal acceleration in the GC reaches values\nof the order of $10^6$g. The centrifugal and Coriolis forces modify essentially\nthe conventional sound waves. Three families of the waves with different\npolarisation and dispersion exist in these conditions. Dynamics of the flow in\nthe model GC Iguasu is investigated numerically. Comparison of the results of\nthe numerical modelling of the wave dynamics with the analytical predictions is\nperformed. New phenomena of the resonances in the GC is found. The resonances\noccur for the waves polarized along the rotational axis having the smallest\ndumping due to the viscosity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Adversarial Networks for the Detection of Aggressive Prostate Cancer.   Semantic segmentation constitutes an integral part of medical image analyses\nfor which breakthroughs in the field of deep learning were of high relevance.\nThe large number of trainable parameters of deep neural networks however\nrenders them inherently data hungry, a characteristic that heavily challenges\nthe medical imaging community. Though interestingly, with the de facto standard\ntraining of fully convolutional networks (FCNs) for semantic segmentation being\nagnostic towards the `structure' of the predicted label maps, valuable\ncomplementary information about the global quality of the segmentation lies\nidle. In order to tap into this potential, we propose utilizing an adversarial\nnetwork which discriminates between expert and generated annotations in order\nto train FCNs for semantic segmentation. Because the adversary constitutes a\nlearned parametrization of what makes a good segmentation at a global level, we\nhypothesize that the method holds particular advantages for segmentation tasks\non complex structured, small datasets. This holds true in our experiments: We\nlearn to segment aggressive prostate cancer utilizing MRI images of 152\npatients and show that the proposed scheme is superior over the de facto\nstandard in terms of the detection sensitivity and the dice-score for\naggressive prostate cancer. The achieved relative gains are shown to be\nparticularly pronounced in the small dataset limit.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Framework for Dynamic Stability Analysis of Power Systems with Volatile Wind Power.   We propose a framework employing stochastic differential equations to\nfacilitate the long-term stability analysis of power grids with intermittent\nwind power generations. This framework takes into account the discrete dynamics\nwhich play a critical role in the long-term stability analysis, incorporates\nthe model of wind speed with different probability distributions, and also\ndevelops an approximation methodology (by a deterministic hybrid model) for the\nstochastic hybrid model to reduce the computational burden brought about by the\nuncertainty of wind power. The theoretical and numerical studies show that a\ndeterministic hybrid model can provide an accurate trajectory approximation and\nstability assessments for the stochastic hybrid model under mild conditions. In\naddition, we discuss the critical cases that the deterministic hybrid model\nfails and discover that these cases are caused by a violation of the proposed\nsufficient conditions. Such discussion complements the proposed framework and\nmethodology and also reaffirms the importance of the stochastic hybrid model\nwhen the system operates close to its stability limit.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Type Safe Redis Queries: A Case Study of Type-Level Programming in Haskell.   Redis is an in-memory data structure store, often used as a database, with a\nHaskell interface Hedis. Redis is dynamically typed --- a key can be discarded\nand re-associated to a value of a different type, and a command, when fetching\na value of a type it does not expect, signals a runtime error. We develop a\ndomain-specific language that, by exploiting Haskell type-level programming\ntechniques including indexed monad, type-level literals and closed type\nfamilies, keeps track of types of values in the database and statically\nguarantees that type errors cannot happen for a class of Redis programs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Extragalactic source population studies at very high energies in the Cherenkov Telescope Array era.   The Cherenkov Telescope Array (CTA) is the next generation ground-based\n$\\gamma$-ray observatory. It will provide an order of magnitude better\nsensitivity and an extended energy coverage, 20 GeV - 300 TeV, relative to\ncurrent Imaging Atmospheric Cherenkov Telescopes (IACTs). IACTs, despite\nfeaturing an excellent sensitivity, are characterized by a limited field of\nview that makes the blind search of new sources very time inefficient.\nFortunately, the $\\textit{Fermi}$-LAT collaboration recently released a new\ncatalog of 1,556 sources detected in the 10 GeV - 2 TeV range by the Large Area\nTelescope (LAT) in the first 7 years of its operation (the 3FHL catalog). This\ncatalog is currently the most appropriate description of the sky that will be\nenergetically accessible to CTA. Here, we discuss a detailed analysis of the\nextragalactic source population (mostly blazars) that will be studied in the\nnear future by CTA. This analysis is based on simulations built from the\nexpected array configurations and information reported in the 3FHL catalog.\nThese results show the improvements that CTA will provide on the extragalactic\nTeV source population studies, which will be carried out by Key Science\nProjects as well as dedicated proposals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Actions Speak Louder Than Goals: Valuing Player Actions in Soccer.   Assessing the impact of the individual actions performed by soccer players\nduring games is a crucial aspect of the player recruitment process.\nUnfortunately, most traditional metrics fall short in addressing this task as\nthey either focus on rare events like shots and goals alone or fail to account\nfor the context in which the actions occurred. This paper introduces a novel\nadvanced soccer metric for valuing any type of individual player action on the\npitch, be it with or without the ball. Our metric values each player action\nbased on its impact on the game outcome while accounting for the circumstances\nunder which the action happened. When applied to on-the-ball actions like\npasses, dribbles, and shots alone, our metric identifies Argentine forward\nLionel Messi, French teenage star Kylian Mbappé, and Belgian winger Eden\nHazard as the most effective players during the 2016/2017 season.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rapidly star-forming galaxies adjacent to quasars at redshifts exceeding 6.   The existence of massive ($10^{11}$ solar masses) elliptical galaxies by\nredshift z~4 (when the Universe was 1.5 billion years old) necessitates the\npresence of galaxies with star-formation rates exceeding 100 solar masses per\nyear at z>6 (corresponding to an age of the Universe of less than 1 billion\nyears). Surveys have discovered hundreds of galaxies at these early cosmic\nepochs, but their star-formation rates are more than an order of magnitude\nlower. The only known galaxies with very high star-formation rates at z>6 are,\nwith only one exception, the host galaxies of quasars, but these galaxies also\nhost accreting supermassive (more than $10^9$ solar masses) black holes, which\nprobably affect the properties of the galaxies. Here we report observations of\nan emission line of singly ionized carbon ([CII] at a wavelength of 158\nmicrometres) in four galaxies at z>6 that are companions of quasars, with\nvelocity offsets of less than 600 kilometers per second and linear offsets of\nless than 600 kiloparsecs. The discovery of these four galaxies was\nserendipitous; they are close to their companion quasars and appear bright in\nthe far-infrared. On the basis of the [CII] measurements, we estimate\nstar-formation rates in the companions of more than 100 solar masses per year.\nThese sources are similar to the host galaxies of the quasars in [CII]\nbrightness, linewidth and implied dynamical masses, but do not show evidence\nfor accreting supermassive black holes. Similar systems have previously been\nfound at lower redshift. We find such close companions in four out of\ntwenty-five z>6 quasars surveyed, a fraction that needs to be accounted for in\nsimulations. If they are representative of the bright end of the [CII]\nluminosity function, then they can account for the population of massive\nelliptical galaxies at z~4 in terms of cosmic space density.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Robust Recovery of Missing Data in Electricity Distribution Systems.   The advanced operation of future electricity distribution systems is likely\nto require significant observability of the different parameters of interest\n(e.g., demand, voltages, currents, etc.). Ensuring completeness of data is,\ntherefore, paramount. In this context, an algorithm for recovering missing\nstate variable observations in electricity distribution systems is presented.\nThe proposed method exploits the low rank structure of the state variables via\na matrix completion approach while incorporating prior knowledge in the form of\nsecond order statistics. Specifically, the recovery method combines nuclear\nnorm minimization with Bayesian estimation. The performance of the new\nalgorithm is compared to the information-theoretic limits and tested trough\nsimulations using real data of an urban low voltage distribution system. The\nimpact of the prior knowledge is analyzed when a mismatched covariance is used\nand for a Markovian sampling that introduces structure in the observation\npattern. Numerical results demonstrate that the proposed algorithm is robust\nand outperforms existing state of the art algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "OAuthGuard: Protecting User Security and Privacy with OAuth 2.0 and OpenID Connect.   Millions of users routinely use Google to log in to websites supporting OAuth\n2.0 or OpenID Connect; the security of OAuth 2.0 and OpenID Connect is\ntherefore of critical importance. As revealed in previous studies, in practice\nRPs often implement OAuth 2.0 incorrectly, and so many real-world OAuth 2.0 and\nOpenID Connect systems are vulnerable to attack. However, users of such flawed\nsystems are typically unaware of these issues, and so are at risk of attacks\nwhich could result in unauthorised access to the victim user's account at an\nRP. In order to address this threat, we have developed OAuthGuard, an OAuth 2.0\nand OpenID Connect vulnerability scanner and protector, that works with RPs\nusing Google OAuth 2.0 and OpenID Connect services. It protects user security\nand privacy even when RPs do not implement OAuth 2.0 or OpenID Connect\ncorrectly. We used OAuthGuard to survey the 1000 top-ranked websites supporting\nGoogle sign-in for the possible presence of five OAuth 2.0 or OpenID Connect\nsecurity and privacy vulnerabilities, of which one has not previously been\ndescribed in the literature. Of the 137 sites in our study that employ Google\nSign-in, 69 were found to suffer from at least one serious vulnerability.\nOAuthGuard was able to protect user security and privacy for 56 of these 69\nRPs, and for the other 13 was able to warn users that they were using an\ninsecure implementation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effect of Particle Number Conservation on the Berry Phase Resulting from Transport of a Bound Quasiparticle around a Superfluid Vortex.   Motivated by understanding Majorana zero modes in topological superfluids in\nparticle-number conserving framework beyond the present framework, we study the\neffect of particle number conservation on the Berry phase resulting from\ntransport of a bound quasiparticle around a superfluid vortex. We find that\nparticle-number non-conserving calculations based on Bogoliubov-de Gennes (BdG)\nequations are unable to capture the correct physics when the quasiparticle is\nwithin the penetration depth of the vortex core where the superfluid velocity\nis non-zero. Particle number conservation is crucial for deriving the correct\nBerry phase in this context, and the Berry phase takes non-universal values\ndepending on the system parameters and the external trap imposed to bind the\nquasiparticle. Of particular relevance to Majorana physics are the findings\nthat superfluid condensate affects the part of the Berry phase not accounted\nfor in the standard BdG framework, and that the superfluid many-body ground\nstate of odd number of fermions involves superfluid condensate deformation due\nto the presence of the bound quasiparticle - an effect which is beyond the\ndescription of the BdG equations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Micrometer-Sized Water Ice Particles for Planetary Science Experiments: Influence of Surface Structure on Collisional Properties.   Models and observations suggest that ice-particle aggregation at and beyond\nthe snowline dominates the earliest stages of planet-formation, which therefore\nis subject to many laboratory studies. However, the pressure-temperature\ngradients in proto-planetary disks mean that the ices are constantly processed,\nundergoing phase changes between different solid phases and the gas phase. Open\nquestions remain as to whether the properties of the icy particles themselves\ndictate collision outcomes and therefore how effectively collision experiments\nreproduce conditions in pro- toplanetary environments. Previous experiments\noften yielded apparently contradictory results on collision outcomes, only\nagreeing in a temperature dependence setting in above $\\approx$ 210 K. By\nexploiting the unique capabilities of the NIMROD neutron scattering instrument,\nwe characterized the bulk and surface structure of icy particles used in\ncollision experiments, and studied how these structures alter as a function of\ntemperature at a constant pressure of around 30 mbar. Our icy grains, formed\nunder liquid nitrogen, undergo changes in the crystalline ice-phase,\nsublimation, sintering and surface pre-melting as they are heated from 103 to\n247 K. An increase in the thickness of the diffuse surface layer from $\\approx$\n10 to $\\approx$ 30 {\\AA} ($\\approx$ 2.5 to 12 bilayers) proves increased\nmolecular mobility at temperatures above $\\approx$ 210 K. As none of the other\nchanges tie-in with the temperature trends in collisional outcomes, we conclude\nthat the surface pre-melting phenomenon plays a key role in collision\nexperiments at these temperatures. Consequently, the pressure-temperature\nenvironment, may have a larger influence on collision outcomes than previously\nthought.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Confidence Interval Estimators for MOS Values.   For the quantification of QoE, subjects often provide individual rating\nscores on certain rating scales which are then aggregated into Mean Opinion\nScores (MOS). From the observed sample data, the expected value is to be\nestimated. While the sample average only provides a point estimator, confidence\nintervals (CI) are an interval estimate which contains the desired expected\nvalue with a given confidence level. In subjective studies, the number of\nsubjects performing the test is typically small, especially in lab\nenvironments. The used rating scales are bounded and often discrete like the\n5-point ACR rating scale. Therefore, we review statistical approaches in the\nliterature for their applicability in the QoE domain for MOS interval\nestimation (instead of having only a point estimator, which is the MOS). We\nprovide a conservative estimator based on the SOS hypothesis and binomial\ndistributions and compare its performance (CI width, outlier ratio of CI\nviolating the rating scale bounds) and coverage probability with well known CI\nestimators. We show that the provided CI estimator works very well in practice\nfor MOS interval estimators, while the commonly used studentized CIs suffer\nfrom a positive outlier ratio, i.e., CIs beyond the bounds of the rating scale.\nAs an alternative, bootstrapping, i.e., random sampling of the subjective\nratings with replacement, is an efficient CI estimator leading to typically\nsmaller CIs, but lower coverage than the proposed estimator.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rechargeable redox flow batteries: Maximum current density with electrolyte flow reactant penetration in a serpentine flow structure.   Rechargeable redox flow batteries with serpentine flow field designs have\nbeen demonstrated to deliver higher current density and power density in medium\nand large-scale stationary energy storage applications. Nevertheless, the\nfundamental mechanisms involved with improved current density in flow batteries\nwith flow field designs have not been understood. Here we report a maximum\ncurrent density concept associated with stoichiometric availability of\nelectrolyte reactant flow penetration through the porous electrode that can be\nachieved in a flow battery system with a \"zero-gap\"serpentine flow field\narchitecture. This concept can explain a higher current density achieved within\nallowing reactions of all species soluble in the electrolyte. Further\nvalidations with experimental data are confirmed by an example of a vanadium\nflow battery with a serpentine flow structure over carbon paper electrode.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Controllability of temporal networks: An analysis using higher-order networks.   The control of complex networks is a significant challenge, especially when\nthe network topology of the system to be controlled is dynamic. Addressing this\nchallenge, here we introduce a novel approach which allows exploring the\ncontrollability of temporal networks. Studying six empirical data sets, we\nparticularly show that order correlations in the sequence of interactions can\nboth increase or decrease the time needed to achieve full controllability.\nCounter-intuitively, we find that this effect can be opposite than the effect\nof order correlations on other dynamical processes. Specifically, we show that\norder correlations that speed up a diffusion process in a given system can slow\ndown the control of the same system, and vice-versa. Building on the\nhigher-order graphical modeling framework introduced in recent works, we\nfurther demonstrate that spectral properties of higher-order network topologies\ncan be used to analytically explain this phenomenon.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Adaptive Multilevel Monte Carlo Approximation of Distribution Functions.   We analyse a multilevel Monte Carlo method for the approximation of\ndistribution functions of univariate random variables. Since, by assumption,\nthe target distribution is not known explicitly, approximations have to be\nused. We provide an asymptotic analysis of the error and the cost of the\nalgorithm. Furthermore we construct an adaptive version of the algorithm that\ndoes not require any a priori knowledge on weak or strong convergence rates. We\napply the adaptive algorithm to smooth path-independent and path-dependent\nfunctionals and to stopped exit times of SDEs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The composition of Solar system asteroids and Earth/Mars moons, and the Earth-Moon composition similarity.   [abridged] In the typical giant-impact scenario for the Moon formation most\nof the Moon's material originates from the impactor. Any Earth-impactor\ncomposition difference should, therefore, correspond to a comparable Earth-Moon\ncomposition difference. Analysis of Moon rocks shows a close Earth-Moon\ncomposition similarity, posing a challenge for the giant-impact scenario, given\nthat impactors were thought to significantly differ in composition from the\nplanets they impact. Here we use a large set of 140 simulations to show that\nthe composition of impactors could be very similar to that of the planets they\nimpact; in $4.9\\%$-$18.2\\%$ ($1.9\\%$-$6.7\\%$) of the cases the resulting\ncomposition of the Moon is consistent with the observations of\n$\\Delta^{17}O<15$ ($\\Delta^{17}O<6$ ppm). These findings suggest that the\nEarth-Moon composition similarity could be resolved as to arise from the\nprimordial Earth-impactor composition similarity. Note that although we find\nthe likelihood for the suggested competing model of very high mass-ratio\nimpacts (producing significant Earth-impactor composition mixing) is comparable\n($<6.7\\%$), this scenario also requires additional fine-tuned requirements of a\nvery fast spinning Earth. Using the same simulations we also explore the\ncomposition of giant-impact formed Mars-moons as well as Vesta-like asteroids.\nWe find that the Mars-moon composition difference should be large, but smaller\nthan expected if the moons are captured asteroids. Finally, we find that the\nleft-over planetesimals ('asteroids') in our simulations are frequently\nscattered far away from their initial positions, thus potentially explaining\nthe mismatch between the current position and composition of the Vesta\nasteroid.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Do metric fluctuations affect the Higgs dynamics during inflation?.   We show that the dynamics of the Higgs field during inflation is not affected\nby metric fluctuations if the Higgs is an energetically subdominant light\nspectator. For Standard Model parameters we find that couplings between Higgs\nand metric fluctuations are suppressed by $\\mathcal{O}(10^{-7})$. They are\nnegligible compared to both pure Higgs terms in the effective potential and the\nunavoidable non-minimal Higgs coupling to background scalar curvature. The\nquestion of the electroweak vacuum instability during high energy scale\ninflation can therefore be studied consistently using the Jordan frame action\nin a Friedmann--Lemaître--Robertson--Walker metric, where the Higgs-curvature\ncoupling enters as an effective mass contribution. Similar results apply for\nother light spectator scalar fields during inflation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Volume growth in the component of fibered twists.   For a Liouville domain $W$ whose boundary admits a periodic Reeb flow, we can\nconsider the connected component $[\\tau] \\in \\pi_0(\\text{Symp}^c(\\widehat W))$\nof fibered twists. In this paper, we investigate an entropy-type invariant,\ncalled the slow volume growth, of the component $[\\tau]$ and give a uniform\nlower bound of the growth using wrapped Floer homology. We also show that\n$[\\tau]$ has infinite order in $\\pi_0(\\text{Symp}^c(\\widehat W))$ if there is\nan admissible Lagrangian $L$ in $W$ whose wrapped Floer homology is infinite\ndimensional. We apply our results to fibered twists coming from the Milnor\nfibers of $A_k$-type singularities and complements of a symplectic hypersurface\nin a real symplectic manifold. They admit so-called real Lagrangians, and we\ncan explicitly compute wrapped Floer homology groups using a version of\nMorse-Bott spectral sequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Testing Global Constraints.   Every Constraint Programming (CP) solver exposes a library of constraints for\nsolving combinatorial problems. In order to be useful, CP solvers need to be\nbug-free. Therefore the testing of the solver is crucial to make developers and\nusers confident. We present a Java library allowing any JVM based solver to\ntest that the implementations of the individual constraints are correct. The\nlibrary can be used in a test suite executed in a continuous integration tool\nor it can also be used to discover minimalist instances violating some\nproperties (arc-consistency, etc) in order to help the developer to identify\nthe origin of the problem using standard debuggers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectral analysis of jet turbulence.   Informed by LES data and resolvent analysis of the mean flow, we examine the\nstructure of turbulence in jets in the subsonic, transonic, and supersonic\nregimes. Spectral (frequency-space) proper orthogonal decomposition is used to\nextract energy spectra and decompose the flow into energy-ranked coherent\nstructures. The educed structures are generally well predicted by the resolvent\nanalysis. Over a range of low frequencies and the first few azimuthal mode\nnumbers, these jets exhibit a low-rank response characterized by\nKelvin-Helmholtz (KH) type wavepackets associated with the annular shear layer\nup to the end of the potential core and that are excited by forcing in the\nvery-near-nozzle shear layer. These modes too the have been experimentally\nobserved before and predicted by quasi-parallel stability theory and other\napproximations--they comprise a considerable portion of the total turbulent\nenergy. At still lower frequencies, particularly for the axisymmetric mode, and\nagain at high frequencies for all azimuthal wavenumbers, the response is not\nlow rank, but consists of a family of similarly amplified modes. These modes,\nwhich are primarily active downstream of the potential core, are associated\nwith the Orr mechanism. They occur also as sub-dominant modes in the range of\nfrequencies dominated by the KH response. Our global analysis helps tie\ntogether previous observations based on local spatial stability theory, and\nexplains why quasi-parallel predictions were successful at some frequencies and\nazimuthal wavenumbers, but failed at others.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Testing FLUKA on neutron activation of Si and Ge at nuclear research reactor using gamma spectroscopy.   Samples of two characteristic semiconductor sensor materials, silicon and\ngermanium, have been irradiated with neutrons produced at the RP-10 Nuclear\nResearch Reactor at 4.5 MW. Their radionuclides photon spectra have been\nmeasured with high resolution gamma spectroscopy, quantifying four\nradioisotopes ($^{28}$Al, $^{29}$Al for Si and $^{75}$Ge and $^{77}$Ge for Ge).\nWe have compared the radionuclides production and their emission spectrum data\nwith Monte Carlo simulation results from FLUKA. Thus we have tested FLUKA's low\nenergy neutron library (ENDF/B-VIIR) and decay photon scoring with respect to\nthe activation of these semiconductors. We conclude that FLUKA is capable of\npredicting relative photon peak amplitudes, with gamma intensities greater than\n1%, of produced radionuclides with an average uncertainty of 13%. This work\nallows us to estimate the corresponding systematic error on neutron activation\nsimulation studies of these sensor materials.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Perturbed Proximal Descent to Escape Saddle Points for Non-convex and Non-smooth Objective Functions.   We consider the problem of finding local minimizers in non-convex and\nnon-smooth optimization. Under the assumption of strict saddle points, positive\nresults have been derived for first-order methods. We present the first known\nresults for the non-smooth case, which requires different analysis and a\ndifferent algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Parameterized Complexity of Positional Games.   We study the parameterized complexity of several positional games. Our main\nresult is that Short Generalized Hex is W[1]-complete parameterized by the\nnumber of moves. This solves an open problem from Downey and Fellows'\ninfluential list of open problems from 1999. Previously, the problem was\nthought of as a natural candidate for AW[*]-completeness. Our main tool is a\nnew fragment of first-order logic where universally quantified variables only\noccur in inequalities. We show that model-checking on arbitrary relational\nstructures for a formula in this fragment is W[1]-complete when parameterized\nby formula size. We also consider a general framework where a positional game\nis represented as a hypergraph and two players alternately pick vertices. In a\nMaker-Maker game, the first player to have picked all the vertices of some\nhyperedge wins the game. In a Maker-Breaker game, the first player wins if she\npicks all the vertices of some hyperedge, and the second player wins otherwise.\nIn an Enforcer-Avoider game, the first player wins if the second player picks\nall the vertices of some hyperedge, and the second player wins otherwise. Short\nMaker-Maker is AW[*]-complete, whereas Short Maker-Breaker is W[1]-complete and\nShort Enforcer-Avoider co-W[1]-complete parameterized by the number of moves.\nThis suggests a rough parameterized complexity categorization into positional\ngames that are complete for the first level of the W-hierarchy when the winning\nconfigurations only depend on which vertices one player has been able to pick,\nbut AW[*]-completeness when the winning condition depends on which vertices\nboth players have picked. However, some positional games where the board and\nthe winning configurations are highly structured are fixed-parameter tractable.\nWe give another example of such a game, Short k-Connect, which is\nfixed-parameter tractable when parameterized by the number of moves.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Assessment of Data Transfer Performance for Large-Scale Climate Data Analysis and Recommendations for the Data Infrastructure for CMIP6.   We document the data transfer workflow, data transfer performance, and other\naspects of staging approximately 56 terabytes of climate model output data from\nthe distributed Coupled Model Intercomparison Project (CMIP5) archive to the\nNational Energy Research Supercomputing Center (NERSC) at the Lawrence Berkeley\nNational Laboratory required for tracking and characterizing extratropical\nstorms, a phenomena of importance in the mid-latitudes. We present this\nanalysis to illustrate the current challenges in assembling multi-model data\nsets at major computing facilities for large-scale studies of CMIP5 data.\nBecause of the larger archive size of the upcoming CMIP6 phase of model\nintercomparison, we expect such data transfers to become of increasing\nimportance, and perhaps of routine necessity. We find that data transfer rates\nusing the ESGF are often slower than what is typically available to US\nresidences and that there is significant room for improvement in the data\ntransfer capabilities of the ESGF portal and data centers both in terms of\nworkflow mechanics and in data transfer performance. We believe performance\nimprovements of at least an order of magnitude are within technical reach using\ncurrent best practices, as illustrated by the performance we achieved in\ntransferring the complete raw data set between two high performance computing\nfacilities. To achieve these performance improvements, we recommend: that\ncurrent best practices (such as the Science DMZ model) be applied to the data\nservers and networks at ESGF data centers; that sufficient financial and human\nresources be devoted at the ESGF data centers for systems and network\nengineering tasks to support high performance data movement; and that\nperformance metrics for data transfer between ESGF data centers and major\ncomputing facilities used for climate data analysis be established, regularly\ntested, and published.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An arithmetic site of Connes-Consani type for imaginary quadratic fields with class number 1.   We construct, for imaginary quadratic number fields with class number 1, an\narithmetic site of Connes-Consani type. The main difficulty here is that the\nconstructions of Connes and Consani and part of their results strongly rely on\nthe natural order existing on real numbers which is compatible with basic\narithmetic operations. Of course nothing of this sort exists in the case of\nimaginary quadratic number fields with class number 1. We first define what we\ncall arithmetic site for such number fields, we then calculate the points of\nthose arithmetic sites and we express them in terms of the adèles class space\nconsidered by Connes to give a spectral interpretation of zeroes of Hecke L\nfunctions of number fields. We get therefore that for a fixed imaginary\nquadratic number field with class number 1, that the points of our arithmetic\nsite are related to the zeroes of the Dedekind zeta function of the number\nfield considered and to the zeroes of some Hecke L functions. We then study the\nrelation between the spectrum of the ring of integers of the number field and\nthe arithmetic site. Finally we construct the square of the arithmetic site.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Products of random walks on finite groups with moderate growth.   In this article, we consider products of random walks on finite groups with\nmoderate growth and discuss their cutoffs in the total variation. Based on\nseveral comparison techniques, we are able to identify the total variation\ncutoff of discrete time lazy random walks with the Hellinger distance cutoff of\ncontinuous time random walks. Along with the cutoff criterion for Laplace\ntransforms, we derive a series of equivalent conditions on the existence of\ncutoffs, including the existence of pre-cutoffs, Peres' product condition and a\nformula generated by the graph diameters. For illustration, we consider\nproducts of Heisenberg groups and randomized products of finite cycles.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting shim gaps in aircraft assembly with machine learning and sparse sensing.   A modern aircraft may require on the order of thousands of custom shims to\nfill gaps between structural components in the airframe that arise due to\nmanufacturing tolerances adding up across large structures. These shims are\nnecessary to eliminate gaps, maintain structural performance, and minimize\npull-down forces required to bring the aircraft into engineering nominal\nconfiguration for peak aerodynamic efficiency. Gap filling is a time-consuming\nprocess, involving either expensive by-hand inspection or computations on vast\nquantities of measurement data from increasingly sophisticated metrology\nequipment. Either case amounts to significant delays in production, with much\nof the time spent in the critical path of aircraft assembly. This work presents\nan alternative strategy for predictive shimming, based on machine learning and\nsparse sensing to first learn gap distributions from historical data, and then\ndesign optimized sparse sensing strategies to streamline data collection and\nprocessing. This new approach is based on the assumption that patterns exist in\nshim distributions across aircraft, which may be mined and used to reduce the\nburden of data collection and processing in future aircraft. Specifically,\nrobust principal component analysis is used to extract low-dimensional patterns\nin the gap measurements while rejecting outliers. Next, optimized sparse\nsensors are obtained that are most informative about the dimensions of a new\naircraft in these low-dimensional principal components. We demonstrate the\nsuccess of the proposed approach, called PIXel Identification Despite\nUncertainty in Sensor Technology (PIXI-DUST), on historical production data\nfrom 54 representative Boeing commercial aircraft. Our algorithm successfully\npredicts $99\\%$ of shim gaps within the desired measurement tolerance using\n$3\\%$ of the laser scan points typically required; all results are\ncross-validated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Identifiability of Nonparametric Mixture Models and Bayes Optimal Clustering.   Motivated by problems in data clustering, we establish general conditions\nunder which families of nonparametric mixture models are identifiable, by\nintroducing a novel framework involving clustering overfitted \\emph{parametric}\n(i.e. misspecified) mixture models. These identifiability conditions generalize\nexisting conditions in the literature, and are flexible enough to include for\nexample mixtures of Gaussian mixtures. In contrast to the recent literature on\nestimating nonparametric mixtures, we allow for general nonparametric mixture\ncomponents, and instead impose regularity assumptions on the underlying mixing\nmeasure. As our primary application, we apply these results to partition-based\nclustering, generalizing the notion of a Bayes optimal partition from classical\nparametric model-based clustering to nonparametric settings. Furthermore, this\nframework is constructive so that it yields a practical algorithm for learning\nidentified mixtures, which is illustrated through several examples on real\ndata. The key conceptual device in the analysis is the convex, metric geometry\nof probability measures on metric spaces and its connection to the Wasserstein\nconvergence of mixing measures. The result is a flexible framework for\nnonparametric clustering with formal consistency guarantees.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Modelling & Forecasting with range based volatility models and application.   This paper considers an alternative method for fitting CARR models using\ncombined estimating functions (CEF) by showing its usefulness in applications\nin economics and quantitative finance. The associated information matrix for\ncorresponding new estimates is derived to calculate the standard errors. A\nsimulation study is carried out to demonstrate its superiority relative to\nother two competitors: linear estimating functions (LEF) and the maximum\nlikelihood (ML). Results show that CEF estimates are more efficient than LEF\nand ML estimates when the error distribution is mis-specified. Taking a real\ndata set from financial economics, we illustrate the usefulness and\napplicability of the CEF method in practice and report reliable forecast values\nto minimize the risk in the decision making process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A momentum conserving $N$-body scheme with individual timesteps.   $N$-body simulations study the dynamics of $N$ particles under the influence\nof mutual long-distant forces such as gravity. In practice, $N$-body codes will\nviolate Newton's third law if they use either an approximate Poisson solver or\nindividual timesteps. In this study, we construct a novel $N$-body scheme by\ncombining a fast multipole method (FMM) based Poisson solver and a time\nintegrator using a hierarchical Hamiltonian splitting (HHS) technique. We test\nour implementation for collision-less systems using several problems in\ngalactic dynamics. As a result of the momentum conserving nature of these two\nkey components, the new $N$-body scheme is also momentum conserving. Moreover,\nwe can fully utilize the $\\mathcal O(\\textit N)$ complexity of FMM with the\nintegrator. With the restored force symmetry, we can improve both angular\nmomentum conservation and energy conservation substantially. The new scheme\nwill be suitable for many applications in galactic dynamics and structure\nformation. Our implementation, in the code Taichi, is publicly available at\nthis https URL.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On biconservative surfaces in Euclidean spaces.   In this paper, we study biconservative surfaces with parallel normalized mean\ncurvature vector in $\\mathbb{E}^4$. We obtain complete local classification in\n$\\mathbb{E}^4$ for a biconservative PNMCV surface. We also give an example to\nshow the existence of PNMCV biconservative surfaces in $\\mathbb{E}^4$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "In-Hand Object Stabilization by Independent Finger Control.   Grip control during robotic in-hand manipulation is usually modeled as part\nof a monolithic task, relying on complex controllers specialized for specific\nsituations. Such approaches do not generalize well and are difficult to apply\nto novel manipulation tasks. Here, we propose a modular object stabilization\nmethod based on a proposition that explains how humans achieve grasp stability.\nIn this bio-mimetic approach, independent tactile grip stabilization\ncontrollers ensure that slip does not occur locally at the engaged robot\nfingers. Such local slip is predicted from the tactile signals of each\nfingertip sensor i.e., BioTac and BioTac SP by Syntouch. We show that stable\ngrasps emerge without any form of central communication when such independent\ncontrollers are engaged in the control of multi-digit robotic hands. These\ngrasps are resistant to external perturbations while being capable of\nstabilizing a large variety of objects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spherical Planetary Robot for Rugged Terrain Traversal.   Wheeled planetary rovers such as the Mars Exploration Rovers (MERs) and Mars\nScience Laboratory (MSL) have provided unprecedented, detailed images of the\nMars surface. However, these rovers are large and are of high-cost as they need\nto carry sophisticated instruments and science laboratories. We propose the\ndevelopment of low-cost planetary rovers that are the size and shape of\ncantaloupes and that can be deployed from a larger rover. The rover named\nSphereX is 2 kg in mass, is spherical, holonomic and contains a hopping\nmechanism to jump over rugged terrain. A small low-cost rover complements a\nlarger rover, particularly to traverse rugged terrain or roll down a canyon,\ncliff or crater to obtain images and science data. While it may be a one-way\njourney for these small robots, they could be used tactically to obtain\nhigh-reward science data. The robot is equipped with a pair of stereo cameras\nto perform visual navigation and has room for a science payload. In this paper,\nwe analyze the design and development of a laboratory prototype. The results\nshow a promising pathway towards development of a field system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reliable counting of weakly labeled concepts by a single spiking neuron model.   Making an informed, correct and quick decision can be life-saving. It's\ncrucial for animals during an escape behaviour or for autonomous cars during\ndriving. The decision can be complex and may involve an assessment of the\namount of threats present and the nature of each threat. Thus, we should expect\nearly sensory processing to supply classification information fast and\naccurately, even before relying the information to higher brain areas or more\ncomplex system components downstream. Today, advanced convolutional artificial\nneural networks can successfully solve visual detection and classification\ntasks and are commonly used to build complex decision making systems. However,\nin order to perform well on these tasks they require increasingly complex,\n\"very deep\" model structure, which is costly in inference run-time, energy\nconsumption and number of training samples, only trainable on cloud-computing\nclusters. A single spiking neuron has been shown to be able to solve\nrecognition tasks for homogeneous Poisson input statistics, a commonly used\nmodel for spiking activity in the neocortex. When modeled as leaky integrate\nand fire with gradient decent learning algorithm it was shown to posses a\nvariety of complex computational capabilities. Here we improve its\nimplementation. We also account for more natural stimulus generated inputs that\ndeviate from this homogeneous Poisson spiking. The improved gradient-based\nlocal learning rule allows for significantly better and stable generalization.\nWe also show that with its improved capabilities it can count weakly labeled\nconcepts by applying our model to a problem of multiple instance learning (MIL)\nwith counting where labels are only available for collections of concepts. In\nthis counting MNIST task the neuron exploits the improved implementation and\noutperforms conventional ConvNet architecture under similar condtions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Intersection of conjugate solvable subgroups in symmetric groups.   It is shown that for a solvable subgroup $G$ of an almost simple group $S$\nwhich socle is isomorphic to $A_n$ $ (n\\ge5)$ there are $x,y,z,t \\in S$ such\nthat $G \\cap G^x \\cap G^y \\cap G^z \\cap G^t =1.$",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On problems in the calculus of variations in increasingly elongated domains.   We consider minimization problems in the calculus of variations set in a\nsequence of domains the size of which tends to infinity in certain directions\nand such that the data only depend on the coordinates in the directions that\nremain constant. We study the asymptotic behavior of minimizers in various\nsituations and show that they converge in an appropriate sense toward\nminimizers of a related energy functional in the constant directions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparing People with Bibliometrics.   Bibliometric indicators, citation counts and/or download counts are\nincreasingly being used to inform personnel decisions such as hiring or\npromotions. These statistics are very often misused. Here we provide a guide to\nthe factors which should be considered when using these so-called quantitative\nmeasures to evaluate people. Rules of thumb are given for when begin to use\nbibliometric measures when comparing otherwise similar candidates.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Variants on the Berz sublinearity theorem.   We consider variants on the classical Berz sublinearity theorem, using only\nDC, the Axiom of Dependent Choices, rather than AC, the Axiom of Choice which\nBerz used. We consider thinned versions, in which conditions are imposed on\nonly part of the domain of the function -- results of quantifier-weakening\ntype. There are connections with classical results on subadditivity. We close\nwith a discussion of the extensive related literature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Raw Waveform-based Speech Enhancement by Fully Convolutional Networks.   This study proposes a fully convolutional network (FCN) model for raw\nwaveform-based speech enhancement. The proposed system performs speech\nenhancement in an end-to-end (i.e., waveform-in and waveform-out) manner, which\ndif-fers from most existing denoising methods that process the magnitude\nspectrum (e.g., log power spectrum (LPS)) only. Because the fully connected\nlayers, which are involved in deep neural networks (DNN) and convolutional\nneural networks (CNN), may not accurately characterize the local information of\nspeech signals, particularly with high frequency components, we employed fully\nconvolutional layers to model the waveform. More specifically, FCN consists of\nonly convolutional layers and thus the local temporal structures of speech\nsignals can be efficiently and effectively preserved with relatively few\nweights. Experimental results show that DNN- and CNN-based models have limited\ncapability to restore high frequency components of waveforms, thus leading to\ndecreased intelligibility of enhanced speech. By contrast, the proposed FCN\nmodel can not only effectively recover the waveforms but also outperform the\nLPS-based DNN baseline in terms of short-time objective intelligibility (STOI)\nand perceptual evaluation of speech quality (PESQ). In addition, the number of\nmodel parameters in FCN is approximately only 0.2% compared with that in both\nDNN and CNN.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Motivic zeta functions and infinite cyclic covers.   We associate with an infinite cyclic cover of a punctured neighborhood of a\nsimple normal crossing divisor on a complex quasi-projective manifold (assuming\ncertain finiteness conditions are satisfied) a rational function in $K_0({\\rm\nVar}^{\\hat \\mu}_{\\mathbb{C}})[\\mathbb{L}^{-1}]$, which we call {\\it motivic\ninfinite cyclic zeta function}, and show its birational invariance. Our\nconstruction is a natural extension of the notion of {\\it motivic infinite\ncyclic covers} introduced by the authors, and as such, it generalizes the\nDenef-Loeser motivic Milnor zeta function of a complex hypersurface singularity\ngerm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interstellar communication. VII. Benchmarking inscribed matter probes.   We have explored the optimal frequency of interstellar photon communications\nand benchmarked other particles as information carriers in previous papers of\nthis series. We now compare the latency and bandwidth of sending probes with\ninscribed matter. Durability requirements such as shields against dust and\nradiation, as well as data duplication, add negligible weight overhead at\nvelocities <0.2c. Probes may arrive in full, while most of a photon beam is\nlost to diffraction. Probes can be more energy efficient per bit, and can have\nhigher bandwidth, compared to classical communication, unless a photon receiver\nis placed in a stellar gravitational lens. The probe's advantage dominates by\norder of magnitude for long distances (kpc) and low velocities (<0.1c) at the\ncost of higher latency.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Gap Acceptance During Lane Changes by Large-Truck Drivers-An Image-Based Analysis.   This paper presents an analysis of rearward gap acceptance characteristics of\ndrivers of large trucks in highway lane change scenarios. The range between the\nvehicles was inferred from camera images using the estimated lane width\nobtained from the lane tracking camera as the reference. Six-hundred lane\nchange events were acquired from a large-scale naturalistic driving data set.\nThe kinematic variables from the image-based gap analysis were filtered by the\nweighted linear least squares in order to extrapolate them at the lane change\ntime. In addition, the time-to-collision and required deceleration were\ncomputed, and potential safety threshold values are provided. The resulting\nrange and range rate distributions showed directional discrepancies, i.e., in\nleft lane changes, large trucks are often slower than other vehicles in the\ntarget lane, whereas they are usually faster in right lane changes. Video\nobservations have confirmed that major motivations for changing lanes are\ndifferent depending on the direction of move, i.e., moving to the left (faster)\nlane occurs due to a slower vehicle ahead or a merging vehicle on the\nright-hand side, whereas right lane changes are frequently made to return to\nthe original lane after passing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Approximate Value Iteration for Risk-aware Markov Decision Processes.   We consider large-scale Markov decision processes (MDPs) with a risk measure\nof variability in cost, under the risk-aware MDPs paradigm. Previous studies\nshowed that risk-aware MDPs, based on a minimax approach to handling risk, can\nbe solved using dynamic programming for small to medium sized problems.\nHowever, due to the \"curse of dimensionality\", MDPs that model real-life\nproblems are typically prohibitively large for such approaches. In this paper,\nwe employ an approximate dynamic programming approach, and develop a family of\nsimulation-based algorithms to approximately solve large-scale risk-aware MDPs.\nIn parallel, we develop a unified convergence analysis technique to derive\nsample complexity bounds for this new family of algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Northern sky Galactic Cosmic Ray anisotropy between 10-1000 TeV with the Tibet Air Shower Array.   We report the analysis of the $10-1000$ TeV large-scale sidereal anisotropy\nof Galactic cosmic rays (GCRs) with the data collected by the Tibet Air Shower\nArray from October, 1995 to February, 2010. In this analysis, we improve the\nenergy estimate and extend the declination range down to $-30^{\\circ}$. We find\nthat the anisotropy maps above 100 TeV are distinct from that at multi-TeV\nband. The so-called \"tail-in\" and \"loss-cone\" features identified at low\nenergies get less significant and a new component appears at $\\sim100$ TeV. The\nspatial distribution of the GCR intensity with an excess (7.2$\\sigma$\npre-trial, 5.2$\\sigma$ post-trial) and a deficit ($-5.8\\sigma$ pre-trial) are\nobserved in the 300 TeV anisotropy map, in a good agreement with IceCube's\nresults at 400 TeV. Combining the Tibet results in the northern sky with\nIceCube's results in the southern sky, we establish a full-sky picture of the\nanisotropy in hundreds of TeV band. We further find that the amplitude of the\nfirst order anisotropy increases sharply above $\\sim100$ TeV, indicating a new\ncomponent of the anisotropy. All these results may shed new light on\nunderstanding the origin and propagation of GCRs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The occurrence of transverse and longitudinal electric currents in the classical plasma under the action of N transverse electromagnetic waves.   Classical plasma with arbitrary degree of degeneration of electronic gas is\nconsidered. In plasma N (N>2) collinear electromagnatic waves are propagated.\nIt is required to find the response of plasma to these waves. Distribution\nfunction in square-law approximation on quantities of two small parameters from\nVlasov equation is received. The formula for electric current calculation is\ndeduced. It is demonstrated that the nonlinearity account leads to occurrence\nof the longitudinal electric current directed along a wave vector. This\nlongitudinal current is orthogonal to the known transversal current received at\nthe linear analysis. The case of small values of wave number is considered.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Superluminal transmission of phase modulation information by a long macroscopic pulse propagating through interstellar space.   A method of transmitting information in interstellar space at superluminal,\nor $> c$, speeds is proposed. The information is encoded as phase modulation of\nan electromagnetic wave of constant intensity, i.e. fluctuations in the rate of\nenergy transport plays no role in the communication, and no energy is\ntransported at speed $>$ c. Of course, such a constant wave can ultimately last\nonly the duration of its enveloping wave packet. However, as a unique feature\nof this paper, we assume the source is sufficiently steady to be capable of\nemitting wave packets, or pulses, of size much larger than the separation\nbetween sender and receiver. Therefore, if a pre-existing and enduring wave\nenvelope already connects the two sides, the subluminal nature of the\nenvelope's group velocity will no longer slow down the communication, which is\nnow limited by the speed at which information encoded as phase modulation\npropagates through the plasma, i.e. the phase velocity $v_p > c$. The method\ninvolves no sharp structure in either time or frequency. As a working example,\nwe considered two spaceships separated by 1 lt-s in the local hot bubble.\nProvided the bandwidth of the extra Fourier modes generated by the phase\nmodulation is much smaller than the carrier wave frequency, the radio\ncommunication of a message, encoded as a specific alignment between the carrier\nwave phase and the anomalous (modulated) phase, can take place at a speed in\nexcess of light by a few parts in 10$^{11}$ at $\\nu\\approx 1$~GHz, and higher\nat smaller $\\nu$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Self-consistent dynamical model of the Broad Line Region.   We develope a self-consistent description of the Broad Line Region based on\nthe concept of the failed wind powered by the radiation pressure acting on\ndusty accretion disk atmosphere in Keplerian motion. The material raised high\nabove the disk is illuminated, dust evaportes, and the matter falls back\ntowards the disk. This material is the source of emission lines. The model\npredicts the inner and outer radius of the region, the cloud dynamics under the\ndust radiation pressure and, subsequently, just the gravitational field of the\ncentral black hole, which results in assymetry between the rise and fall.\nKnowledge of the dynamics allows to predict the shapes of the emission lines as\nfunctions of the basic parameters of an active nucleus: black hole mass,\naccretion rate, black hole spin (or accretion efficiency) and the viewing angle\nwith respect to the symmetry axis. Here we show preliminary results based on\nanalytical approximations to the cloud motion.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Small Telescope Exoplanet Transit Surveys: XO.   The XO project aims at detecting transiting exoplanets around bright stars\nfrom the ground using small telescopes. The original configuration of XO\n(McCullough et al. 2005) has been changed and extended as described here. The\ninstrumental setup consists of three identical units located at different\nsites, each composed of two lenses equipped with CCD cameras mounted on the\nsame mount. We observed two strips of the sky covering an area of 520 deg$^2$\nfor twice nine months. We build lightcurves for ~20,000 stars up to magnitude\nR~12.5 using a custom-made photometric data reduction pipeline. The photometric\nprecision is around 1-2% for most stars, and the large quantity of data allows\nus to reach a millimagnitude precision when folding the lightcurves on\ntimescales that are relevant to exoplanetary transits. We search for periodic\nsignals and identify several hundreds of variable stars and a few tens of\ntransiting planet candidates. Follow-up observations are underway to confirm or\nreject these candidates. We found two close-in gas giant planets so far, in\nline with the expected yield.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reservoir Computing for Detection of Steady State in Performance Tests of Compressors.   Fabrication of devices in industrial plants often includes undergoing quality\nassurance tests or tests that seek to determine some attributes or capacities\nof the device. For instance, in testing refrigeration compressors, we want to\nfind the true refrigeration capacity of the compressor being tested. Such test\n(also called an episode) may take up to four hours, being an actual hindrance\nto applying it to the total number of compressors produced. This work seeks to\nreduce the time spent on such industrial trials by employing Recurrent Neural\nNetworks (RNNs) as dynamical models for detecting when a test is entering the\nso-called steady-state region. Specifically, we use Reservoir Computing (RC)\nnetworks which simplify the learning of RNNs by speeding up training time and\nshowing convergence to a global optimum. Also, this work proposes a\nself-organized subspace projection method for RC networks which uses\ninformation from the beginning of the episode to define a cluster to which the\nepisode belongs to. This assigned cluster defines a particular binary input\nthat shifts the operating point of the reservoir to a subspace of trajectories\nfor the duration of the episode. This new method is shown to turn the RC model\nrobust in performance with respect to varying combination of reservoir\nparameters, such as spectral radius and leak rate, when compared to a standard\nRC network.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Science with e-ASTROGAM (A space mission for MeV-GeV gamma-ray astrophysics).   e-ASTROGAM (enhanced ASTROGAM) is a breakthrough Observatory space mission,\nwith a detector composed by a Silicon tracker, a calorimeter, and an\nanticoincidence system, dedicated to the study of the non-thermal Universe in\nthe photon energy range from 0.3 MeV to 3 GeV - the lower energy limit can be\npushed to energies as low as 150 keV for the tracker, and to 30 keV for\ncalorimetric detection. The mission is based on an advanced space-proven\ndetector technology, with unprecedented sensitivity, angular and energy\nresolution, combined with polarimetric capability. Thanks to its performance in\nthe MeV-GeV domain, substantially improving its predecessors, e-ASTROGAM will\nopen a new window on the non-thermal Universe, making pioneering observations\nof the most powerful Galactic and extragalactic sources, elucidating the nature\nof their relativistic outflows and their effects on the surroundings. With a\nline sensitivity in the MeV energy range one to two orders of magnitude better\nthan previous generation instruments, e-ASTROGAM will determine the origin of\nkey isotopes fundamental for the understanding of supernova explosion and the\nchemical evolution of our Galaxy. The mission will provide unique data of\nsignificant interest to a broad astronomical community, complementary to\npowerful observatories such as LIGO-Virgo-GEO600-KAGRA, SKA, ALMA, E-ELT, TMT,\nLSST, JWST, Athena, CTA, IceCube, KM3NeT, and LISA.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Optimisation de la QoS dans un r{é}seau de radio cognitive en utilisant la m{é}taheuristique SFLA (Shuffled Frog Leaping Algorithm).   This work proposes a study of quality of service (QoS) in cognitive radio\nnetworks. This study is based on a stochastic optimization method called\nshuffled frog leaping algorithm (SFLA). The interest of the SFLA algorithm is\nto guarantee a better solution in a multi-carrier context in order to satisfy\nthe requirements of the secondary user (SU).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Coupled Lattice Boltzmann Method and Discrete Element Method for Discrete Particle Simulations of Particulate Flows.   Discrete particle simulations are widely used to study large-scale\nparticulate flows in complex geometries where particle-particle and\nparticle-fluid interactions require an adequate representation but the\ncomputational cost has to be kept low. In this work, we present a novel\ncoupling approach for such simulations. A lattice Boltzmann formulation of the\ngeneralized Navier-Stokes equations is used to describe the fluid motion. This\npromises efficient simulations suitable for high performance computing and,\nsince volume displacement effects by the solid phase are considered, our\napproach is also applicable to non-dilute particulate systems. The discrete\nelement method is combined with an explicit evaluation of interparticle\nlubrication forces to simulate the motion of individual submerged particles.\nDrag, pressure and added mass forces determine the momentum transfer by\nfluid-particle interactions. A stable coupling algorithm is presented and\ndiscussed in detail. We demonstrate the validity of our approach for dilute as\nwell as dense systems by predicting the settling velocity of spheres over a\nbroad range of solid volume fractions in good agreement with semi-empirical\ncorrelations. Additionally, the accuracy of particle-wall interactions in a\nviscous fluid is thoroughly tested and established. Our approach can thus be\nreadily used for various particulate systems and can be extended\nstraightforward to e.g. non-spherical particles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Coverage Analysis of a Vehicular Network Modeled as Cox Process Driven by Poisson Line Process.   In this paper, we consider a vehicular network in which the wireless nodes\nare located on a system of roads. We model the roadways, which are\npredominantly straight and randomly oriented, by a Poisson line process (PLP)\nand the locations of nodes on each road as a homogeneous 1D Poisson point\nprocess (PPP). Assuming that each node transmits independently, the locations\nof transmitting and receiving nodes are given by two Cox processes driven by\nthe same PLP. For this setup, we derive the coverage probability of a typical\nreceiver, which is an arbitrarily chosen receiving node, assuming independent\nNakagami-$m$ fading over all wireless channels. Assuming that the typical\nreceiver connects to its closest transmitting node in the network, we first\nderive the distribution of the distance between the typical receiver and the\nserving node to characterize the desired signal power. We then characterize\ncoverage probability for this setup, which involves two key technical\nchallenges. First, we need to handle several cases as the serving node can\npossibly be located on any line in the network and the corresponding\ninterference experienced at the typical receiver is different in each case.\nSecond, conditioning on the serving node imposes constraints on the spatial\nconfiguration of lines, which require careful analysis of the conditional\ndistribution of the lines. We address these challenges in order to accurately\ncharacterize the interference experienced at the typical receiver. We then\nderive an exact expression for coverage probability in terms of the derivative\nof Laplace transform of interference power distribution. We analyze the trends\nin coverage probability as a function of the network parameters: line density\nand node density. We also study the asymptotic behavior of this model and\ncompare the coverage performance with that of a homogeneous 2D PPP model with\nthe same node density.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A Liouville theorem for indefinite fractional diffusion equations and its application to existence of solutions.   In this work we obtain a Liouville theorem for positive, bounded solutions of\nthe equation $$ (-\\Delta)^s u= h(x_N)f(u) \\quad \\hbox{in }\\mathbb{R}^{N} $$\nwhere $(-\\Delta)^s$ stands for the fractional Laplacian with $s\\in (0,1)$, and\nthe functions $h$ and $f$ are nondecreasing. The main feature is that the\nfunction $h$ changes sign in $\\mathbb{R}$, therefore the problem is sometimes\ntermed as indefinite. As an application we obtain a priori bounds for positive\nsolutions of some boundary value problems, which give existence of such\nsolutions by means of bifurcation methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bursting dynamics of viscous film without circular symmetry: the effect of confinement.   We experimentally investigate the bursting dynamics of confined liquid film\nsuspended in air and find a viscous dynamics distinctly different from the\nnon-confined counterpart, due to lack of circular symmetry in the shape of\nexpanding hole: the novel confined-viscous bursting proceeds at a constant\nspeed and a rim formed at the bursting tip does not grow. We find a\nconfined-viscous to confined-inertial crossover, as well as a\nnonconfined-inertial to confined-inertial crossover, at which bursting speed\ndoes not change although the circular symmetry in the hole shape breaks\ndynamically.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Manin's conjecture for a class of singular cubic hypersurfaces.   Let $n$ be a positive multiple of $4$. We establish an asymptotic formula for\nthe number of rational points of bounded height on singular cubic hypersurfaces\n$S_n$ defined by $$ x^3=(y_1^2 + \\cdots + y_n^2)z . $$ This result is new in\ntwo aspects: first, it can be viewed as a modest start on the study of density\nof rational points on those singular cubic hypersurfaces which are not covered\nby the classical theorems of Davenport or Heath-Brown; second, it proves\nManin's conjecture for singular cubic hypersurfaces $S_n$ defined above.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Luminous Efficiency Estimates of Meteors -I. Uncertainty analysis.   The luminous efficiency of meteors is poorly known, but critical for\ndetermining the meteoroid mass. We present an uncertainty analysis of the\nluminous efficiency as determined by the classical ablation equations, and\nsuggest a possible method for determining the luminous efficiency of real\nmeteor events. We find that a two-term exponential fit to simulated lag data is\nable to reproduce simulated luminous efficiencies reasonably well.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Eternal inflation and the quantum birth of cosmic structure.   We consider the eternal inflation scenario of the slow-roll/chaotic type with\nthe additional element of an objective collapse of the wave function. The\nincorporation of this new agent to the traditional inflationary setting might\nrepresent a possible solution to the quantum measurement problem during\ninflation, a subject that has not reached a consensus among the community.\nSpecifically, it could provide an explanation for the generation of the\nprimordial anisotropies and inhomogeneities, starting from a perfectly\nsymmetric background and invoking symmetric dynamics. We adopt the continuous\nspontaneous localization model, in the context of inflation, as the dynamical\nreduction mechanism that generates the primordial inhomogeneities. Furthermore,\nwhen enforcing the objective reduction mechanism, the condition for eternal\ninflation can be bypassed. In particular, the collapse mechanism incites the\nwave function, corresponding to the inflaton, to localize itself around the\nzero mode of the field. Then the zero mode will evolve essentially unperturbed,\ndriving inflation to an end in any region of the Universe where inflation\noccurred. Also, our approach achieves a primordial spectrum with an amplitude\nand shape consistent with the one that best fits the observational data.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Vision and Challenges for Knowledge Centric Networking (KCN).   In the creation of a smart future information society, Internet of Things\n(IoT) and Content Centric Networking (CCN) break two key barriers for both the\nfront-end sensing and back-end networking. However, we still observe the\nmissing piece of the research that dominates the current networking traffic\ncontrol and system management, e.g., lacking of the knowledge penetrated into\nboth sensing and networking to glue them holistically. In this paper, we\nenvision to leverage emerging machine learning or deep learning techniques to\ncreate aspects of knowledge for facilitating the designs. In particular, we can\nextract knowledge from collected data to facilitate reduced data volume,\nenhanced system intelligence and interactivity, improved service quality,\ncommunication with better controllability and lower cost. We name such a\nknowledge-oriented traffic control and networking management paradigm as the\nKnowledge Centric Networking (KCN). This paper presents KCN rationale, KCN\nbenefits, related works and research opportunities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Anisotropic thermophoresis.   Colloidal migration in temperature gradient is referred to as thermophoresis.\nIn contrast to particles with spherical shape, we show that elongated colloids\nmay have a thermophoretic response that varies with the colloid orientation.\nRemarkably, this can translate into a non-vanishing thermophoretic force in the\ndirection perpendicular to the temperature gradient. Oppositely to the friction\nforce, the thermophoretic force of a rod oriented with the temperature gradient\ncan be larger or smaller than when oriented perpendicular to it. The precise\nanisotropic thermophoretic behavior clearly depends on the colloidal rod aspect\nratio, and also on its surface details, which provides an interesting\ntunability to the devices constructed based on this principle. By means of\nmesoscale hydrodynamic simulations, we characterize this effect for different\ntypes of rod-like colloids.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Integral field observations of the blue compact galaxy Haro14. Star formation and feedback in dwarf galaxies.   (Abridged) Low-luminosity, gas-rich blue compact galaxies (BCG) are ideal\nlaboratories to investigate many aspects of the star formation in galaxies. We\nstudy the morphology, stellar content, kinematics, and the nebular excitation\nand ionization mechanism in the BCG Haro 14 by means of integral field\nobservations with VIMOS in the VLT. From these data we build maps in continuum\nand in the brighter emission lines, produce line-ratio maps, and obtain the\nvelocity and velocity dispersion fields. We also generate the integrated\nspectrum of the major HII regions and young stellar clusters identified in the\nmaps to determine reliable physical parameters and oxygen abundances. We find\nas follows: i) the current star formation in Haro 14 is spatially extended with\nthe major HII regions placed along a linear structure, elongated in the\nnorth-south direction, and in a horseshoe-like curvilinear feature that extends\nabout 760 pc eastward; the continuum emission is more concentrated and peaks\nclose to the galaxy center; ii) two different episodes of star formation are\npresent: the recent starburst, with ages $\\leq$ 6 Myrs and the intermediate-age\nclusters, with ages between 10 and 30 Myrs; these stellar components rest on a\nseveral Gyr old underlying host galaxy; iii) the H$\\alpha$/H$\\beta$ pattern is\ninhomogeneous, with excess color values varying from E(B-V)=0.04 up to\nE(B-V)=1.09; iv) shocks play a significant role in the galaxy; and v) the\nvelocity field displays a complicated pattern with regions of material moving\ntoward us in the east and north galaxy areas. The morphology of Haro 14, its\nirregular velocity field, and the presence of shocks speak in favor of a\nscenario of triggered star formation. Ages of the knots are consistent with the\nongoing burst being triggered by the collective action of stellar winds and\nsupernovae originated in the central clusters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "ILP-based Alleviation of Dense Meander Segments with Prioritized Shifting and Progressive Fixing in PCB Routing.   Length-matching is an important technique to bal- ance delays of bus signals\nin high-performance PCB routing. Existing routers, however, may generate very\ndense meander segments. Signals propagating along these meander segments\nexhibit a speedup effect due to crosstalk between the segments of the same\nwire, thus leading to mismatch of arrival times even under the same physical\nwire length. In this paper, we present a post-processing method to enlarge the\nwidth and the distance of meander segments and hence distribute them more\nevenly on the board so that crosstalk can be reduced. In the proposed\nframework, we model the sharing of available routing areas after removing dense\nmeander segments from the initial routing, as well as the generation of relaxed\nmeander segments and their groups for wire length compensation. This model is\ntransformed into an ILP problem and solved for a balanced distribution of wire\npatterns. In addition, we adjust the locations of long wire segments according\nto wire priorities to swap free spaces toward critical wires that need much\nlength compensation. To reduce the problem space of the ILP model, we also\nintroduce a progressive fixing technique so that wire patterns are grown\ngradually from the edge of the routing toward the center area. Experimental\nresults show that the proposed method can expand meander segments significantly\neven under very tight area constraints, so that the speedup effect can be\nalleviated effectively in high- performance PCB designs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quasiconformal mappings and Hölder continuity.   We establish that every $K$-quasiconformal mapping $w$ of the unit ball $\\IB$\nonto a $C^2$-Jordan domain $\\Omega$ is Hölder continuous with constant\n$\\alpha= 2-\\frac{n}{p}$, provided that its weak Laplacean $\\Delta w$ is in $\nL^p(\\IB)$ for some $n/2<p<n$. In particular it is Hölder continuous for every\n$0<\\alpha<1$ provided that $\\Delta w\\in L^n(\\IB)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Genetic interactions from first principles.   We derive a general statistical model of interactions, starting from\nprobabilistic principles and elementary requirements. Prevailing interaction\nmodels in biomedical researches diverge both mathematically and practically. In\nparticular, genetic interaction inquiries are formulated without an obvious\nmathematical unity. Our model reveals theoretical properties unnoticed so far,\nparticularly valuable for genetic interaction mapping, where mechanistic\ndetails are mostly unknown, distribution of gene variants differ between\npopulations, and genetic susceptibilities are spuriously propagated by linkage\ndisequilibrium. When applied to data of the largest interaction mapping\nexperiment on Saccharomyces Cerevisiae to date, our results imply less aversion\nto positive interactions, detection of well-documented hubs and partial\nremapping of functional regions of the currently known genetic interaction\nlandscape. Assessment of divergent annotations across functional categories\nfurther suggests that positive interactions have a more important role on\nribosome biogenesis than previously realized. The unity of arguments elaborated\nhere enables the analysis of dissimilar interaction models and experimental\ndata with a common framework.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Bounding the Radius of Convergence of Analytic Functions.   Contour integration is a crucial technique in many numeric methods of\ninterest in physics ranging from differentiation to evaluating functions of\nmatrices. It is often important to determine whether a given contour contains\nany poles or branch cuts, either to make use of these features or to avoid\nthem. A special case of this problem is that of determining or bounding the\nradius of convergence of a function, as this provides a known circle around a\npoint in which a function remains analytic. We describe a method for\ndetermining whether or not a circular contour of a complex-analytic function\ncontains any poles. We then build on this to produce a robust method for\nbounding the radius of convergence of a complex-analytic function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adversarial Examples: Attacks and Defenses for Deep Learning.   With rapid progress and significant successes in a wide spectrum of\napplications, deep learning is being applied in many safety-critical\nenvironments. However, deep neural networks have been recently found vulnerable\nto well-designed input samples, called adversarial examples. Adversarial\nexamples are imperceptible to human but can easily fool deep neural networks in\nthe testing/deploying stage. The vulnerability to adversarial examples becomes\none of the major risks for applying deep neural networks in safety-critical\nenvironments. Therefore, attacks and defenses on adversarial examples draw\ngreat attention. In this paper, we review recent findings on adversarial\nexamples for deep neural networks, summarize the methods for generating\nadversarial examples, and propose a taxonomy of these methods. Under the\ntaxonomy, applications for adversarial examples are investigated. We further\nelaborate on countermeasures for adversarial examples and explore the\nchallenges and the potential solutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "User Interface (UI) Design Issues for the Multilingual Users: A Case Study.   A multitude of web and desktop applications are now widely available in\ndiverse human languages. This paper explores the design issues that are\nspecifically relevant for multilingual users. It reports on the continued\nstudies of Information System (IS) issues and users' behaviour across\ncross-cultural and transnational boundaries. Taking the BBC website as a model\nthat is internationally recognised, usability tests were conducted to compare\ndifferent versions of the website. The dependant variables derived from the\nquestionnaire were analysed (via descriptive statistics) to elucidate the\nmultilingual UI design issues. Using Principal Component Analysis (PCA), five\nde-correlated variables were identified which were then used for hypotheses\ntests. A modified version of Herzberg's Hygiene-motivational Theory about the\nWorkplace was applied to assess the components used in the website. Overall, it\nwas concluded that the English versions of the website gave superior usability\nresults and this implies the need for deeper study of the problems in usability\nof the translated versions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Linear growth of streaming instability in pressure bumps.   Streaming instability is a powerful mechanism which concentrates dust grains\nin pro- toplanetary discs, eventually up to the stage where they collapse\ngravitationally and form planetesimals. Previous studies inferred that it\nshould be ineffective in viscous discs, too efficient in inviscid discs, and\nmay not operate in local pressure maxima where solids accumulate. From a linear\nanalysis of stability, we show that streaming instability behaves differently\ninside local pressure maxima. Under the action of the strong differential\nadvection imposed by the bump, a novel unstable mode develops and grows even\nwhen gas viscosity is large. Hence, pressure bumps are found to be the only\nplaces where streaming instability occurs in viscous discs. This offers a\npromising way to conciliate models of planet formation with recent observations\nof young discs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A punishment voting algorithm based on super categories construction for acoustic scene classification.   In acoustic scene classification researches, audio segment is usually split\ninto multiple samples. Majority voting is then utilized to ensemble the results\nof the samples. In this paper, we propose a punishment voting algorithm based\non the super categories construction method for acoustic scene classification.\nSpecifically, we propose a DenseNet-like model as the base classifier. The base\nclassifier is trained by the CQT spectrograms generated from the raw audio\nsegments. Taking advantage of the results of the base classifier, we propose a\nsuper categories construction method using the spectral clustering. Super\nclassifiers corresponding to the constructed super categories are further\ntrained. Finally, the super classifiers are utilized to enhance the majority\nvoting of the base classifier by punishment voting. Experiments show that the\npunishment voting obviously improves the performances on both the DCASE2017\nDevelopment dataset and the LITIS Rouen dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust Adversarial Reinforcement Learning.   Deep neural networks coupled with fast simulation and improved computation\nhave led to recent successes in the field of reinforcement learning (RL).\nHowever, most current RL-based approaches fail to generalize since: (a) the gap\nbetween simulation and real world is so large that policy-learning approaches\nfail to transfer; (b) even if policy learning is done in real world, the data\nscarcity leads to failed generalization from training to test scenarios (e.g.,\ndue to different friction or object masses). Inspired from H-infinity control\nmethods, we note that both modeling errors and differences in training and test\nscenarios can be viewed as extra forces/disturbances in the system. This paper\nproposes the idea of robust adversarial reinforcement learning (RARL), where we\ntrain an agent to operate in the presence of a destabilizing adversary that\napplies disturbance forces to the system. The jointly trained adversary is\nreinforced -- that is, it learns an optimal destabilization policy. We\nformulate the policy learning as a zero-sum, minimax objective function.\nExtensive experiments in multiple environments (InvertedPendulum, HalfCheetah,\nSwimmer, Hopper and Walker2d) conclusively demonstrate that our method (a)\nimproves training stability; (b) is robust to differences in training/test\nconditions; and c) outperform the baseline even in the absence of the\nadversary.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bounded cohomology and virtually free hyperbolically embedded subgroups.   Using a probabilistic argument we show that the second bounded cohomology of\nan acylindrically hyperbolic group $G$ (e.g., a non-elementary hyperbolic or\nrelatively hyperbolic group, non-exceptional mapping class group, ${\\rm\nOut}(F_n)$, \\dots) embeds via the natural restriction maps into the inverse\nlimit of the second bounded cohomologies of its virtually free subgroups, and\nin fact even into the inverse limit of the second bounded cohomologies of its\nhyperbolically embedded virtually free subgroups. This result is new and\nnon-trivial even in the case where $G$ is a (non-free) hyperbolic group. The\ncorresponding statement fails in general for the third bounded cohomology, even\nfor surface groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Weighted Random Walk Sampling for Multi-Relational Recommendation.   In the information overloaded web, personalized recommender systems are\nessential tools to help users find most relevant information. The most\nheavily-used recommendation frameworks assume user interactions that are\ncharacterized by a single relation. However, for many tasks, such as\nrecommendation in social networks, user-item interactions must be modeled as a\ncomplex network of multiple relations, not only a single relation. Recently\nresearch on multi-relational factorization and hybrid recommender models has\nshown that using extended meta-paths to capture additional information about\nboth users and items in the network can enhance the accuracy of recommendations\nin such networks. Most of this work is focused on unweighted heterogeneous\nnetworks, and to apply these techniques, weighted relations must be simplified\ninto binary ones. However, information associated with weighted edges, such as\nuser ratings, which may be crucial for recommendation, are lost in such\nbinarization. In this paper, we explore a random walk sampling method in which\nthe frequency of edge sampling is a function of edge weight, and apply this\ngenerate extended meta-paths in weighted heterogeneous networks. With this\nsampling technique, we demonstrate improved performance on multiple data sets\nboth in terms of recommendation accuracy and model generation efficiency.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Reinhardt Conjecture as an Optimal Control Problem.   In 1934, Reinhardt conjectured that the shape of the centrally symmetric\nconvex body in the plane whose densest lattice packing has the smallest density\nis a smoothed octagon. This conjecture is still open. We formulate the\nReinhardt Conjecture as a problem in optimal control theory. The smoothed\noctagon is a Pontryagin extremal trajectory with bang-bang control. More\ngenerally, the smoothed regular $6k+2$-gon is a Pontryagin extremal with\nbang-bang control. The smoothed octagon is a strict (micro) local minimum to\nthe optimal control problem. The optimal solution to the Reinhardt problem is a\ntrajectory without singular arcs. The extremal trajectories that do not meet\nthe singular locus have bang-bang controls with finitely many switching times.\nFinally, we reduce the Reinhardt problem to an optimization problem on a\nfive-dimensional manifold. (Each point on the manifold is an initial condition\nfor a potential Pontryagin extremal lifted trajectory.) We suggest that the\nReinhardt conjecture might eventually be fully resolved through optimal control\ntheory. Some proofs are computer-assisted using a computer algebra system.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Search Rank Fraud De-Anonymization in Online Systems.   We introduce the fraud de-anonymization problem, that goes beyond fraud\ndetection, to unmask the human masterminds responsible for posting search rank\nfraud in online systems. We collect and study search rank fraud data from\nUpwork, and survey the capabilities and behaviors of 58 search rank fraudsters\nrecruited from 6 crowdsourcing sites. We propose Dolos, a fraud\nde-anonymization system that leverages traits and behaviors extracted from\nthese studies, to attribute detected fraud to crowdsourcing site fraudsters,\nthus to real identities and bank accounts. We introduce MCDense, a min-cut\ndense component detection algorithm to uncover groups of user accounts\ncontrolled by different fraudsters, and leverage stylometry and deep learning\nto attribute them to crowdsourcing site profiles. Dolos correctly identified\nthe owners of 95% of fraudster-controlled communities, and uncovered fraudsters\nwho promoted as many as 97.5% of fraud apps we collected from Google Play. When\nevaluated on 13,087 apps (820,760 reviews), which we monitored over more than 6\nmonths, Dolos identified 1,056 apps with suspicious reviewer groups. We report\northogonal evidence of their fraud, including fraud duplicates and fraud\nre-posts.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Optimal Weighted-Delay Scheduling in Input-Queued Switches.   Motivated by relatively few delay-optimal scheduling results, in comparison\nto results on throughput optimality, we investigate an input-queued switch\nscheduling problem in which the objective is to minimize a linear function of\nthe queue-length vector. Theoretical properties of variants of the well-known\nMaxWeight scheduling algorithm are established within this context, which\nincludes showing that these algorithms exhibit optimal heavy-traffic\nqueue-length scaling. For the case of $2 \\times 2$ input-queued switches, we\nderive an optimal scheduling policy and establish its theoretical properties,\ndemonstrating fundamental differences with the variants of MaxWeight\nscheduling. Our theoretical results are expected to be of interest more broadly\nthan input-queued switches. Computational experiments demonstrate and quantify\nthe benefits of our optimal scheduling policy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Control Problems with Vanishing Lie Bracket Arising from Complete Odd Circulant Evolutionary Games.   We study an optimal control problem arising from a generalization of\nrock-paper-scissors in which the number of strategies may be selected from any\npositive odd number greater than 1 and in which the payoff to the winner is\ncontrolled by a control variable $\\gamma$. Using the replicator dynamics as the\nequations of motion, we show that a quasi-linearization of the problem admits a\nspecial optimal control form in which explicit dynamics for the controller can\nbe identified. We show that all optimal controls must satisfy a specific second\norder differential equation parameterized by the number of strategies in the\ngame. We show that as the number of strategies increases, a limiting case\nadmits a closed form for the open-loop optimal control. In performing our\nanalysis we show necessary conditions on an optimal control problem that allow\nthis analytic approach to function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Central Moment Discrepancy (CMD) for Domain-Invariant Representation Learning.   The learning of domain-invariant representations in the context of domain\nadaptation with neural networks is considered. We propose a new regularization\nmethod that minimizes the discrepancy between domain-specific latent feature\nrepresentations directly in the hidden activation space. Although some standard\ndistribution matching approaches exist that can be interpreted as the matching\nof weighted sums of moments, e.g. Maximum Mean Discrepancy (MMD), an explicit\norder-wise matching of higher order moments has not been considered before. We\npropose to match the higher order central moments of probability distributions\nby means of order-wise moment differences. Our model does not require\ncomputationally expensive distance and kernel matrix computations. We utilize\nthe equivalent representation of probability distributions by moment sequences\nto define a new distance function, called Central Moment Discrepancy (CMD). We\nprove that CMD is a metric on the set of probability distributions on a compact\ninterval. We further prove that convergence of probability distributions on\ncompact intervals w.r.t. the new metric implies convergence in distribution of\nthe respective random variables. We test our approach on two different\nbenchmark data sets for object recognition (Office) and sentiment analysis of\nproduct reviews (Amazon reviews). CMD achieves a new state-of-the-art\nperformance on most domain adaptation tasks of Office and outperforms networks\ntrained with MMD, Variational Fair Autoencoders and Domain Adversarial Neural\nNetworks on Amazon reviews. In addition, a post-hoc parameter sensitivity\nanalysis shows that the new approach is stable w.r.t. parameter changes in a\ncertain interval. The source code of the experiments is publicly available.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Conic Integer Programming Approach to Constrained Assortment Optimization under the Mixed Multinomial Logit Model.   We consider the constrained assortment optimization problem under the mixed\nmultinomial logit model. Even moderately sized instances of this problem are\nchallenging to solve directly using standard mixed-integer linear optimization\nformulations. This has motivated recent research exploring customized\noptimization strategies and approximation techniques. In contrast, we develop a\nnovel conic quadratic mixed-integer formulation. This new formulation, together\nwith McCormick inequalities exploiting the capacity constraints, enables the\nsolution of large instances using commercial optimization software.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Pentagonal Inequality.   Given a positive linear combination of five (respectively seven) cosines,\nwhere the angles are positive and sum to pi, the aim of this article is to\nexpress the sharp bound of the combination as a Positive Real Fraction in the\ncoefficients (hence cosine-free). The method uses algebraic and arithmetic\nmanipulations with judicious transformations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non Uniform On Chip Power Delivery Network Synthesis Methodology.   In this paper, we proposed a non-uniform power delivery network (PDN)\nsynthesis methodology. It first constructs initial PDN using uniform approach.\nThen preliminary power integrity analysis is performed to derive IR-safe\ncandidate window. Congestion map is obtained based global route congestion\nestimation. A self-adaptive non-uniform PDN synthesis is then performed to\nglobally and locally optimize PDN over selected regions. The PDN synthesis is\ncongestion-driven and IR- guarded. Experimental results show significant timing\nimportant in trade-off small PDN length reduction with no EM/IR impact. We\nfurther explored potential power savings using our non-uniform PDN synthesis\nmethodology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On algebraically integrable domains in Euclidean spaces.   Let $D$ be a bounded domain $D$ in $\\mathbb R^n $ with infinitely smooth\nboundary and $n$ is odd. We prove that if the volume cut off from the domain by\na hyperplane is an algebraic function of the hyperplane, free of real singular\npoints, then the domain is an ellipsoid. This partially answers a question of\nV.I. Arnold: whether odd-dimensional ellipsoids are the only algebraically\nintegrable domains?",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Numerical analysis of a nonlinear free-energy diminishing Discrete Duality Finite Volume scheme for convection diffusion equations.   We propose a nonlinear Discrete Duality Finite Volume scheme to approximate\nthe solutions of drift diffusion equations. The scheme is built to preserve at\nthe discrete level even on severely distorted meshes the energy / energy\ndissipation relation. This relation is of paramount importance to capture the\nlong-time behavior of the problem in an accurate way. To enforce it, the linear\nconvection diffusion equation is rewritten in a nonlinear form before being\ndiscretized. We establish the existence of positive solutions to the scheme.\nBased on compactness arguments, the convergence of the approximate solution\ntowards a weak solution is established. Finally, we provide numerical evidences\nof the good behavior of the scheme when the discretization parameters tend to 0\nand when time goes to infinity.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "The earliest phases of high-mass star formation, as seen in NGC 6334 by \\emph{Herschel}.   To constrain models of high-mass star formation, the Herschel/HOBYS KP aims\nat discovering massive dense cores (MDCs) able to host the high-mass analogs of\nlow-mass prestellar cores, which have been searched for over the past decade.\nWe here focus on NGC6334, one of the best-studied HOBYS molecular cloud\ncomplexes.\nWe used Herschel PACS and SPIRE 70-500mu images of the NGC6334 complex\ncomplemented with (sub)millimeter and mid-infrared data. We built a complete\nprocedure to extract ~0.1 pc dense cores with the getsources software, which\nsimultaneously measures their far-infrared to millimeter fluxes. We carefully\nestimated the temperatures and masses of these dense cores from their SEDs.\nA cross-correlation with high-mass star formation signposts suggests a mass\nthreshold of 75Msun for MDCs in NGC6334. MDCs have temperatures of 9.5-40K,\nmasses of 75-1000Msun, and densities of 10^5-10^8cm-3. Their mid-IR emission is\nused to separate 6 IR-bright and 10 IR-quiet protostellar MDCs while their 70mu\nemission strength, with respect to fitted SEDs, helps identify 16 starless MDC\ncandidates. The ability of the latter to host high-mass prestellar cores is\ninvestigated here and remains questionable. An increase in mass and density\nfrom the starless to the IR-quiet and IR-bright phases suggests that the\nprotostars and MDCs simultaneously grow in mass. The statistical lifetimes of\nthe high-mass prestellar and protostellar core phases, estimated to be\n1-7x10^4yr and at most 3x10^5yr respectively, suggest a dynamical scenario of\nhigh-mass star formation.\nThe present study provides good mass estimates for a statistically\nsignificant sample, covering the earliest phases of high-mass star formation.\nHigh-mass prestellar cores may not exist in NGC6334, favoring a scenario\npresented here, which simultaneously forms clouds and high-mass protostars.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Privacy and Fairness in Recommender Systems via Adversarial Training of User Representations.   Latent factor models for recommender systems represent users and items as low\ndimensional vectors. Privacy risks of such systems have previously been studied\nmostly in the context of recovery of personal information in the form of usage\nrecords from the training data. However, the user representations themselves\nmay be used together with external data to recover private user information\nsuch as gender and age. In this paper we show that user vectors calculated by a\ncommon recommender system can be exploited in this way. We propose the\nprivacy-adversarial framework to eliminate such leakage of private information,\nand study the trade-off between recommender performance and leakage both\ntheoretically and empirically using a benchmark dataset. An advantage of the\nproposed method is that it also helps guarantee fairness of results, since all\nimplicit knowledge of a set of attributes is scrubbed from the representations\nused by the model, and thus can't enter into the decision making. We discuss\nfurther applications of this method towards the generation of deeper and more\ninsightful recommendations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Neumann Optimizer: A Practical Optimization Algorithm for Deep Neural Networks.   Progress in deep learning is slowed by the days or weeks it takes to train\nlarge models. The natural solution of using more hardware is limited by\ndiminishing returns, and leads to inefficient use of additional resources. In\nthis paper, we present a large batch, stochastic optimization algorithm that is\nboth faster than widely used algorithms for fixed amounts of computation, and\nalso scales up substantially better as more computational resources become\navailable. Our algorithm implicitly computes the inverse Hessian of each\nmini-batch to produce descent directions; we do so without either an explicit\napproximation to the Hessian or Hessian-vector products. We demonstrate the\neffectiveness of our algorithm by successfully training large ImageNet models\n(Inception-V3, Resnet-50, Resnet-101 and Inception-Resnet-V2) with mini-batch\nsizes of up to 32000 with no loss in validation error relative to current\nbaselines, and no increase in the total number of steps. At smaller mini-batch\nsizes, our optimizer improves the validation error in these models by 0.8-0.9%.\nAlternatively, we can trade off this accuracy to reduce the number of training\nsteps needed by roughly 10-30%. Our work is practical and easily usable by\nothers -- only one hyperparameter (learning rate) needs tuning, and\nfurthermore, the algorithm is as computationally cheap as the commonly used\nAdam optimizer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Why Adaptively Collected Data Have Negative Bias and How to Correct for It.   From scientific experiments to online A/B testing, the previously observed\ndata often affects how future experiments are performed, which in turn affects\nwhich data will be collected. Such adaptivity introduces complex correlations\nbetween the data and the collection procedure. In this paper, we prove that\nwhen the data collection procedure satisfies natural conditions, then sample\nmeans of the data have systematic \\emph{negative} biases. As an example,\nconsider an adaptive clinical trial where additional data points are more\nlikely to be tested for treatments that show initial promise. Our surprising\nresult implies that the average observed treatment effects would underestimate\nthe true effects of each treatment. We quantitatively analyze the magnitude and\nbehavior of this negative bias in a variety of settings. We also propose a\nnovel debiasing algorithm based on selective inference techniques. In\nexperiments, our method can effectively reduce bias and estimation error.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlocal Pertubations of Fractional Choquard Equation.   We study the equation \\begin{equation} (-\\Delta)^{s}u+V(x)u=\n(I_{\\alpha}*|u|^{p})|u|^{p-2}u+\\lambda(I_{\\beta}*|u|^{q})|u|^{q-2}u \\quad\\mbox{\nin } \\R^{N}, \\end{equation} where $I_\\gamma(x)=|x|^{-\\gamma}$ for any\n$\\gamma\\in (0,N)$, $p, q >0$, $\\alpha,\\beta\\in (0,N)$, $N\\geq 3$ and $ \\lambda\n\\in R$. First, the existence of a groundstate solutions using minimization\nmethod on the associated Nehari manifold is obtained. Next, the existence of\nleast energy sign-changing solutions is investigated by considering the Nehari\nnodal set.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mathematics of Isogeny Based Cryptography.   These lectures notes were written for a summer school on Mathematics for\npost-quantum cryptography in Thiès, Senegal. They try to provide a guide for\nMasters' students to get through the vast literature on elliptic curves,\nwithout getting lost on their way to learning isogeny based cryptography. They\nare by no means a reference text on the theory of elliptic curves, nor on\ncryptography; students are encouraged to complement these notes with some of\nthe books recommended in the bibliography.\nThe presentation is divided in three parts, roughly corresponding to the\nthree lectures given. In an effort to keep the reader interested, each part\nalternates between the fundamental theory of elliptic curves, and applications\nin cryptography. We often prefer to have the main ideas flow smoothly, rather\nthan having a rigorous presentation as one would have in a more classical book.\nThe reader will excuse us for the inaccuracies and the omissions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Amplitude death and resurgence of oscillation in network of mobile oscillators.   The phenomenon of amplitude death has been explored using a variety of\ndifferent coupling strategies in the last two decades. In most of the work, the\nbasic coupling arrangement is considered to be static over time, although many\nrealistic systems exhibit significant changes in the interaction pattern as\ntime varies. In this article, we study the emergence of amplitude death in a\ndynamical network composed of time-varying interaction amidst a collection of\nrandom walkers in a finite region of three dimensional space. We consider an\noscillator for each walker and demonstrate that depending upon the network\nparameters and hence the interaction between them, global oscillation in the\nnetwork gets suppressed. In this framework, vision range of each oscillator\ndecides the number of oscillators with which it interacts. In addition, with\nthe use of an appropriate feedback parameter in the coupling strategy, we\narticulate how the suppressed oscillation can be resurrected in the systems'\nparameter space. The phenomenon of amplitude death and the resurgence of\noscillation is investigated taking limit cycle and chaotic oscillators for\nbroad ranges of parameters, like interaction strength k between the entities,\nvision range r and the speed of movement v.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Duality of Graphical Models and Tensor Networks.   In this article we show the duality between tensor networks and undirected\ngraphical models with discrete variables. We study tensor networks on\nhypergraphs, which we call tensor hypernetworks. We show that the tensor\nhypernetwork on a hypergraph exactly corresponds to the graphical model given\nby the dual hypergraph. We translate various notions under duality. For\nexample, marginalization in a graphical model is dual to contraction in the\ntensor network. Algorithms also translate under duality. We show that belief\npropagation corresponds to a known algorithm for tensor network contraction.\nThis article is a reminder that the research areas of graphical models and\ntensor networks can benefit from interaction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Incremental Eigenpair Computation for Graph Laplacian Matrices: Theory and Applications.   The smallest eigenvalues and the associated eigenvectors (i.e., eigenpairs)\nof a graph Laplacian matrix have been widely used in spectral clustering and\ncommunity detection. However, in real-life applications the number of clusters\nor communities (say, $K$) is generally unknown a-priori. Consequently, the\nmajority of the existing methods either choose $K$ heuristically or they repeat\nthe clustering method with different choices of $K$ and accept the best\nclustering result. The first option, more often, yields suboptimal result,\nwhile the second option is computationally expensive. In this work, we propose\nan incremental method for constructing the eigenspectrum of the graph Laplacian\nmatrix. This method leverages the eigenstructure of graph Laplacian matrix to\nobtain the $K$-th smallest eigenpair of the Laplacian matrix given a collection\nof all previously computed $K-1$ smallest eigenpairs. Our proposed method\nadapts the Laplacian matrix such that the batch eigenvalue decomposition\nproblem transforms into an efficient sequential leading eigenpair computation\nproblem. As a practical application, we consider user-guided spectral\nclustering. Specifically, we demonstrate that users can utilize the proposed\nincremental method for effective eigenpair computation and for determining the\ndesired number of clusters based on multiple clustering metrics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cause-Effect Deep Information Bottleneck For Incomplete Covariates.   Estimating the causal effects of an intervention in the presence of\nconfounding is a frequently occurring problem in applications such as medicine.\nThe task is challenging since there may be multiple confounding factors, some\nof which may be missing, and inferences must be made from high-dimensional,\nnoisy measurements. In this paper, we propose a decision-theoretic approach to\nestimate the causal effects of interventions where a subset of the covariates\nis unavailable for some patients during testing. Our approach uses the\ninformation bottleneck principle to perform a discrete, low-dimensional\nsufficient reduction of the covariate data to estimate a distribution over\nconfounders. In doing so, we can estimate the causal effect of an intervention\nwhere only partial covariate information is available. Our results on a causal\ninference benchmark and a real application for treating sepsis show that our\nmethod achieves state-of-the-art performance, without sacrificing\ninterpretability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Chimera states in complex networks: interplay of fractal topology and delay.   Chimera states are an example of intriguing partial synchronization patterns\nemerging in networks of identical oscillators. They consist of spatially\ncoexisting domains of coherent (synchronized) and incoherent (desynchronized)\ndynamics. We analyze chimera states in networks of Van der Pol oscillators with\nhierarchical connectivities, and elaborate the role of time delay introduced in\nthe coupling term. In the parameter plane of coupling strength and delay time\nwe find tongue-like regions of existence of chimera states alternating with\nregions of existence of coherent travelling waves. We demonstrate that by\nvarying the time delay one can deliberately stabilize desired spatio-temporal\npatterns in the system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Adaptive p-value weighting with power optimality.   Weighting the p-values is a well-established strategy that improves the power\nof multiple testing procedures while dealing with heterogeneous data. However,\nhow to achieve this task in an optimal way is rarely considered in the\nliterature. This paper contributes to fill the gap in the case of\ngroup-structured null hypotheses, by introducing a new class of procedures\nnamed ADDOW (for Adaptive Data Driven Optimal Weighting) that adapts both to\nthe alternative distribution and to the proportion of true null hypotheses. We\nprove the asymptotical FDR control and power optimality among all weighted\nprocedures of ADDOW, which shows that it dominates all existing procedures in\nthat framework. Some numerical experiments show that the proposed method\npreserves its optimal properties in the finite sample setting when the number\nof tests is moderately large.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coordination game in bidirectional flow.   We have introduced evolutionary game dynamics to a one-dimensional\ncellular-automaton to investigate evolution and maintenance of cooperative\navoiding behavior of self-driven particles in bidirectional flow. In our model,\nthere are two kinds of particles, which are right-going particles and\nleft-going particles. They often face opponent particles, so that they swerve\nto the right or left stochastically in order to avoid conflicts. The particles\nreinforce their preferences of the swerving direction after their successful\navoidance. The preference is also weakened by memory-loss effect.\nResult of our simulation indicates that cooperative avoiding behavior is\nachieved, i.e., swerving directions of the particles are unified, when the\ndensity of particles is close to 1/2 and the memory-loss rate is small.\nFurthermore, when the right-going particles occupy the majority of the system,\nwe observe that their flow increases when the number of left-going particles,\nwhich prevent the smooth movement of right-going particles, becomes large. It\nis also investigated that the critical memory-loss rate of the cooperative\navoiding behavior strongly depends on the size of the system. Small system can\nprolong the cooperative avoiding behavior in wider range of memory-loss rate\nthan large system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Simultaneous Localization and Layout Model Selection in Manhattan Worlds.   In this paper, we will demonstrate how Manhattan structure can be exploited\nto transform the Simultaneous Localization and Mapping (SLAM) problem, which is\ntypically solved by a nonlinear optimization over feature positions, into a\nmodel selection problem solved by a convex optimization over higher order\nlayout structures, namely walls, floors, and ceilings. Furthermore, we show how\nour novel formulation leads to an optimization procedure that automatically\nperforms data association and loop closure and which ultimately produces the\nsimplest model of the environment that is consistent with the available\nmeasurements. We verify our method on real world data sets collected with\nvarious sensing modalities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Studying Magnetic Fields using Low-frequency Pulsar Observations.   Low-frequency polarisation observations of pulsars, facilitated by\nnext-generation radio telescopes, provide powerful probes of astrophysical\nplasmas that span many orders of magnitude in magnetic field strength and\nscale: from pulsar magnetospheres to intervening magneto-ionic plasmas\nincluding the ISM and the ionosphere. Pulsar magnetospheres with teragauss\nfield strengths can be explored through their numerous emission phenomena\nacross multiple frequencies, the mechanism behind which remains elusive.\nPrecise dispersion and Faraday rotation measurements towards a large number of\npulsars probe the three-dimensional large-scale (and eventually small-scale)\nstructure of the Galactic magnetic field, which plays a role in many\nastrophysical processes, but is not yet well understood, especially towards the\nGalactic halo. We describe some results and ongoing work from the Low Frequency\nArray (LOFAR) and the Murchison Widefield Array (MWA) radio telescopes in these\nareas. These and other pathfinder and precursor telescopes have reinvigorated\nlow-frequency science and build towards the Square Kilometre Array (SKA), which\nwill make significant advancements in studies of astrophysical magnetic fields\nin the next 50 years.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Calibrated Boosting-Forest.   Excellent ranking power along with well calibrated probability estimates are\nneeded in many classification tasks. In this paper, we introduce a technique,\nCalibrated Boosting-Forest that captures both. This novel technique is an\nensemble of gradient boosting machines that can support both continuous and\nbinary labels. While offering superior ranking power over any individual\nregression or classification model, Calibrated Boosting-Forest is able to\npreserve well calibrated posterior probabilities. Along with these benefits, we\nprovide an alternative to the tedious step of tuning gradient boosting\nmachines. We demonstrate that tuning Calibrated Boosting-Forest can be reduced\nto a simple hyper-parameter selection. We further establish that increasing\nthis hyper-parameter improves the ranking performance under a diminishing\nreturn. We examine the effectiveness of Calibrated Boosting-Forest on\nligand-based virtual screening where both continuous and binary labels are\navailable and compare the performance of Calibrated Boosting-Forest with\nlogistic regression, gradient boosting machine and deep learning. Calibrated\nBoosting-Forest achieved an approximately 48% improvement compared to a\nstate-of-art deep learning model. Moreover, it achieved around 95% improvement\non probability quality measurement compared to the best individual gradient\nboosting machine. Calibrated Boosting-Forest offers a benchmark demonstration\nthat in the field of ligand-based virtual screening, deep learning is not the\nuniversally dominant machine learning model and good calibrated probabilities\ncan better facilitate virtual screening process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Herschel survey and modelling of externally-illuminated photoevaporating protoplanetary disks.   Protoplanetary disks undergo substantial mass-loss by photoevaporation, a\nmechanism which is crucial to their dynamical evolution. However, the processes\nregulating the gas energetics have not been well constrained by observations so\nfar. We aim at studying the processes involved in disk photoevaporation when it\nis driven by far-UV photons. We present a unique Herschel survey and new ALMA\nobservations of four externally-illuminated photoevaporating disks (a.k.a.\nproplyds). For the analysis of these data, we developed a 1D model of the\nphotodissociation region (PDR) of a proplyd, based on the Meudon PDR code and\ncomputed the far infrared line emission. We successfully reproduce most of the\nobservations and derive key physical parameters, i.e. densities at the disk\nsurface of about $10^{6}$ cm$^{-3}$ and local gas temperatures of about 1000 K.\nOur modelling suggests that all studied disks are found in a transitional\nregime resulting from the interplay between several heating and cooling\nprocesses that we identify. These differ from those dominating in classical\nPDRs, i.e. grain photo-electric effect and cooling by [OI] and [CII] FIR lines.\nThis energetic regime is associated to an equilibrium dynamical point of the\nphotoevaporation flow: the mass-loss rate is self-regulated to set the envelope\ncolumn density at a value that maintains the temperature at the disk surface\naround 1000 K. From our best-fit models, we estimate mass-loss rates - of the\norder of $10^{-7}$ $\\mathrm{M}_\\odot$/yr - that are in agreement with earlier\nspectroscopic observation of ionised gas tracers. This holds only if we assume\nan evaporation flow launched from the disk surface at sound speed\n(supercritical regime). We have identified the energetic regime regulating\nFUV-photoevaporation in proplyds. This regime could be implemented into models\nof the dynamical evolution of protoplanetary disks.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Exact Simulation of the Extrema of Stable Processes.   We exhibit an exact simulation algorithm for the supremum of a stable process\nover a finite time interval using dominated coupling from the past (DCFTP). We\nestablish a novel perpetuity equation for the supremum (via the representation\nof the concave majorants of Lévy processes) and apply it to construct a\nMarkov chain in the DCFTP algorithm. We prove that the number of steps taken\nbackwards in time before the coalescence is detected is finite.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-task Learning with Gradient Guided Policy Specialization.   We present a method for efficient learning of control policies for multiple\nrelated robotic motor skills. Our approach consists of two stages, joint\ntraining and specialization training. During the joint training stage, a neural\nnetwork policy is trained with minimal information to disambiguate the motor\nskills. This forces the policy to learn a common representation of the\ndifferent tasks. Then, during the specialization training stage we selectively\nsplit the weights of the policy based on a per-weight metric that measures the\ndisagreement among the multiple tasks. By splitting part of the control policy,\nit can be further trained to specialize to each task. To update the control\npolicy during learning, we use Trust Region Policy Optimization with\nGeneralized Advantage Function (TRPOGAE). We propose a modification to the\ngradient update stage of TRPO to better accommodate multi-task learning\nscenarios. We evaluate our approach on three continuous motor skill learning\nproblems in simulation: 1) a locomotion task where three single legged robots\nwith considerable difference in shape and size are trained to hop forward, 2) a\nmanipulation task where three robot manipulators with different sizes and joint\ntypes are trained to reach different locations in 3D space, and 3) locomotion\nof a two-legged robot, whose range of motion of one leg is constrained in\ndifferent ways. We compare our training method to three baselines. The first\nbaseline uses only joint training for the policy, the second trains independent\npolicies for each task, and the last randomly selects weights to split. We show\nthat our approach learns more efficiently than each of the baseline methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep generative models of genetic variation capture mutation effects.   The functions of proteins and RNAs are determined by a myriad of interactions\nbetween their constituent residues, but most quantitative models of how\nmolecular phenotype depends on genotype must approximate this by simple\nadditive effects. While recent models have relaxed this constraint to also\naccount for pairwise interactions, these approaches do not provide a tractable\npath towards modeling higher-order dependencies. Here, we show how latent\nvariable models with nonlinear dependencies can be applied to capture\nbeyond-pairwise constraints in biomolecules. We present a new probabilistic\nmodel for sequence families, DeepSequence, that can predict the effects of\nmutations across a variety of deep mutational scanning experiments\nsignificantly better than site independent or pairwise models that are based on\nthe same evolutionary data. The model, learned in an unsupervised manner solely\nfrom sequence information, is grounded with biologically motivated priors,\nreveals latent organization of sequence families, and can be used to\nextrapolate to new parts of sequence space",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Uniform Shapiro-Lopatinski conditions and boundary value problems on manifolds with bounded geometry.   We study the regularity of the solutions of second order boundary value\nproblems on manifolds with boundary and bounded geometry. We first show that\nthe regularity property of a given boundary value problem $(P, C)$ is\nequivalent to the uniform regularity of the natural family $(P_x, C_x)$ of\nassociated boundary value problems in local coordinates. We verify that this\nproperty is satisfied for the Dirichlet boundary conditions and strongly\nelliptic operators via a compactness argument. We then introduce a uniform\nShapiro-Lopatinski regularity condition, which is a modification of the\nclassical one, and we prove that it characterizes the boundary value problems\nthat satisfy the usual regularity property. We also show that the natural Robin\nboundary conditions always satisfy the uniform Shapiro-Lopatinski regularity\ncondition, provided that our operator satisfies the strong Legendre condition.\nThis is achieved by proving that \"well-posedness implies regularity\" via a\nmodification of the classical \"Nirenberg trick\". When combining our regularity\nresults with the Poincaré inequality of (Ammann-Grosse-Nistor, preprint\n2015), one obtains the usual well-posedness results for the classical boundary\nvalue problems in the usual scale of Sobolev spaces, thus extending these\nimportant, well-known theorems from smooth, bounded domains, to manifolds with\nboundary and bounded geometry. As we show in several examples, these results do\nnot hold true anymore if one drops the bounded geometry assumption. We also\nintroduce a uniform Agmon condition and show that it is equivalent to the\ncoerciveness. Consequently, we prove a well-posedness result for parabolic\nequations whose elliptic generator satisfies the uniform Agmon condition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Critical exponent $ω$ in the Gross-Neveu-Yukawa model at $O(1/N)$.   The critcal exponent $\\omega$ is evaluated at $O(1/N)$ in $d$-dimensions in\nthe Gross-Neveu model using the large $N$ critical point formalism. It is shown\nto be in agreement with the recently determined three loop $\\beta$-functions of\nthe Gross-Neveu-Yukawa model in four dimensions. The same exponent is computed\nfor the chiral Gross-Neveu and non-abelian Nambu-Jona-Lasinio universality\nclasses.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "A Loop-Based Methodology for Reducing Computational Redundancy in Workload Sets.   The design of general purpose processors relies heavily on a workload\ngathering step in which representative programs are collected from various\napplication domains. Processor performance, when running the workload set, is\nprofiled using simulators that model the targeted processor architecture.\nHowever, simulating the entire workload set is prohibitively time-consuming,\nwhich precludes considering a large number of programs. To reduce simulation\ntime, several techniques in the literature have exploited the internal program\nrepetitiveness to extract and execute only representative code segments.\nExisting so- lutions are based on reducing cross-program computational\nredundancy or on eliminating internal-program redundancy to decrease execution\ntime. In this work, we propose an orthogonal and complementary loop- centric\nmethodology that targets loop-dominant programs by exploiting internal-program\ncharacteristics to reduce cross-program computational redundancy. The approach\nemploys a newly developed framework that extracts and analyzes core loops\nwithin workloads. The collected characteristics model memory behavior,\ncomputational complexity, and data structures of a program, and are used to\nconstruct a signature vector for each program. From these vectors,\ncross-workload similarity metrics are extracted, which are processed by a novel\nheuristic to exclude similar programs and reduce redundancy within the set.\nFinally, a reverse engineering approach that synthesizes executable\nmicro-benchmarks having the same instruction mix as the loops in the original\nworkload is introduced. A tool that automates the flow steps of the proposed\nmethodology is developed. Simulation results demonstrate that applying the\nproposed methodology to a set of workloads reduces the set size by half, while\npreserving the main characterizations of the initial workloads.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Continuous-Time Gaussian Process Motion Planning via Probabilistic Inference.   We introduce a novel formulation of motion planning, for continuous-time\ntrajectories, as probabilistic inference. We first show how smooth\ncontinuous-time trajectories can be represented by a small number of states\nusing sparse Gaussian process (GP) models. We next develop an efficient\ngradient-based optimization algorithm that exploits this sparsity and GP\ninterpolation. We call this algorithm the Gaussian Process Motion Planner\n(GPMP). We then detail how motion planning problems can be formulated as\nprobabilistic inference on a factor graph. This forms the basis for GPMP2, a\nvery efficient algorithm that combines GP representations of trajectories with\nfast, structure-exploiting inference via numerical optimization. Finally, we\nextend GPMP2 to an incremental algorithm, iGPMP2, that can efficiently replan\nwhen conditions change. We benchmark our algorithms against several\nsampling-based and trajectory optimization-based motion planning algorithms on\nplanning problems in multiple environments. Our evaluation reveals that GPMP2\nis several times faster than previous algorithms while retaining robustness. We\nalso benchmark iGPMP2 on replanning problems, and show that it can find\nsuccessful solutions in a fraction of the time required by GPMP2 to replan from\nscratch.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Formal Approach to Exploiting Multi-Stage Attacks based on File-System Vulnerabilities of Web Applications (Extended Version).   Web applications require access to the file-system for many different tasks.\nWhen analyzing the security of a web application, secu- rity analysts should\nthus consider the impact that file-system operations have on the security of\nthe whole application. Moreover, the analysis should take into consideration\nhow file-system vulnerabilities might in- teract with other vulnerabilities\nleading an attacker to breach into the web application. In this paper, we first\npropose a classification of file- system vulnerabilities, and then, based on\nthis classification, we present a formal approach that allows one to exploit\nfile-system vulnerabilities. We give a formal representation of web\napplications, databases and file- systems, and show how to reason about\nfile-system vulnerabilities. We also show how to combine file-system\nvulnerabilities and SQL-Injection vulnerabilities for the identification of\ncomplex, multi-stage attacks. We have developed an automatic tool that\nimplements our approach and we show its efficiency by discussing several\nreal-world case studies, which are witness to the fact that our tool can\ngenerate, and exploit, complex attacks that, to the best of our knowledge, no\nother state-of-the-art-tool for the security of web applications can find.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-Lane Perception Using Feature Fusion Based on GraphSLAM.   An extensive, precise and robust recognition and modeling of the environment\nis a key factor for next generations of Advanced Driver Assistance Systems and\ndevelopment of autonomous vehicles. In this paper, a real-time approach for the\nperception of multiple lanes on highways is proposed. Lane markings detected by\ncamera systems and observations of other traffic participants provide the input\ndata for the algorithm. The information is accumulated and fused using\nGraphSLAM and the result constitutes the basis for a multilane clothoid model.\nTo allow incorporation of additional information sources, input data is\nprocessed in a generic format. Evaluation of the method is performed by\ncomparing real data, collected with an experimental vehicle on highways, to a\nground truth map. The results show that ego and adjacent lanes are robustly\ndetected with high quality up to a distance of 120 m. In comparison to serial\nlane detection, an increase in the detection range of the ego lane and a\ncontinuous perception of neighboring lanes is achieved. The method can\npotentially be utilized for the longitudinal and lateral control of\nself-driving vehicles.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A taxonomy of learning dynamics in 2 x 2 games.   Learning would be a convincing method to achieve coordination on an\nequilibrium. But does learning converge, and to what? We answer this question\nin generic 2-player, 2-strategy games, using Experience-Weighted Attraction\n(EWA), which encompasses many extensively studied learning algorithms. We\nexhaustively characterize the parameter space of EWA learning, for any payoff\nmatrix, and we understand the generic properties that imply convergent or\nnon-convergent behaviour in 2 x 2 games.\nIrrational choice and lack of incentives imply convergence to a mixed\nstrategy in the centre of the strategy simplex, possibly far from the Nash\nEquilibrium (NE). In the opposite limit, in which the players quickly modify\ntheir strategies, the behaviour depends on the payoff matrix: (i) a strong\ndiscrepancy between the pure strategies describes dominance-solvable games,\nwhich show convergence to a unique fixed point close to the NE; (ii) a\npreference towards profiles of strategies along the main diagonal describes\ncoordination games, with multiple stable fixed points corresponding to the NE;\n(iii) a cycle of best responses defines discoordination games, which commonly\nyield limit cycles or low-dimensional chaos.\nWhile it is well known that mixed strategy equilibria may be unstable, our\napproach is novel from several perspectives: we fully analyse EWA and provide\nexplicit thresholds that define the onset of instability; we find an emerging\ntaxonomy of the learning dynamics, without focusing on specific classes of\ngames ex-ante; we show that chaos can occur even in the simplest games; we make\na precise theoretical prediction that can be tested against data on\nexperimental learning of discoordination games.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Nikol'ski\\uı, Jackson and Ul'yanov type inequalities with Muckenhoupt weights.   In the present work we prove a Nikol'ski inequality for trigonometric\npolynomials and Ul'yanov type inequalities for functions in Lebesgue spaces\nwith Muckenhoupt weights. Realization result and Jackson inequalities are\nobtained. Simultaneous approximation by polynomials is considered. Some uniform\nnorm inequalities are transferred to weighted Lebesgue space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Global behaviour of radially symmetric solutions stable at infinity for gradient systems.   This paper is concerned with radially symmetric solutions of systems of the\nform \\[ u_t = -\\nabla V(u) + \\Delta_x u \\] where space variable $x$ and and\nstate-parameter $u$ are multidimensional, and the potential $V$ is coercive at\ninfinity. For such systems, under generic assumptions on the potential, the\nasymptotic behaviour of solutions \"stable at infinity\", that is approaching a\nspatially homogeneous equilibrium when $|x|$ approaches $+\\infty$, is\ninvestigated. It is proved that every such solutions approaches a stacked\nfamily of radially symmetric bistable fronts travelling to infinity. This\nbehaviour is similar to the one of bistable solutions for gradient systems in\none unbounded spatial dimension, described in a companion paper. It is expected\n(but unfortunately not proved at this stage) that behind these travelling\nfronts the solution again behaves as in the one-dimensional case (that is, the\ntime derivative approaches zero and the solution approaches a pattern of\nstationary solutions).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Noisy Networks for Exploration.   We introduce NoisyNet, a deep reinforcement learning agent with parametric\nnoise added to its weights, and show that the induced stochasticity of the\nagent's policy can be used to aid efficient exploration. The parameters of the\nnoise are learned with gradient descent along with the remaining network\nweights. NoisyNet is straightforward to implement and adds little computational\noverhead. We find that replacing the conventional exploration heuristics for\nA3C, DQN and dueling agents (entropy reward and $\\epsilon$-greedy respectively)\nwith NoisyNet yields substantially higher scores for a wide range of Atari\ngames, in some cases advancing the agent from sub to super-human performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "VSE++: Improving Visual-Semantic Embeddings with Hard Negatives.   We present a new technique for learning visual-semantic embeddings for\ncross-modal retrieval. Inspired by hard negative mining, the use of hard\nnegatives in structured prediction, and ranking loss functions, we introduce a\nsimple change to common loss functions used for multi-modal embeddings. That,\ncombined with fine-tuning and use of augmented data, yields significant gains\nin retrieval performance. We showcase our approach, VSE++, on MS-COCO and\nFlickr30K datasets, using ablation studies and comparisons with existing\nmethods. On MS-COCO our approach outperforms state-of-the-art methods by 8.8%\nin caption retrieval and 11.3% in image retrieval (at R@1).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cepheids with the eyes of photometric space telescopes.   Space photometric missions have been steadily accumulating observations of\nCepheids in recent years, leading to a flow of new discoveries. In this short\nreview we summarize the findings provided by the early missions such as WIRE,\nMOST, and CoRoT, and the recent results of the Kepler and K2 missions. The\nsurprising and fascinating results from the high-precision, quasi-continuous\ndata include the detection of the amplitude increase of Polaris, and exquisite\ndetails about V1154 Cyg within the original Kepler field of view. We also\nbriefly discuss the current opportunities with the K2 mission, and the\nprospects of the TESS space telescope regarding Cepheids.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Recovering Sparse Nonnegative Signals via Non-convex Fraction Function Penalty.   Many real world practical problems can be formulated as\n$\\ell_{0}$-minimization problems with nonnegativity constraints, which seek the\nsparsest nonnegative signals to underdetermined linear systems. They have been\nwidely applied in signal and image processing, machine learning, pattern\nrecognition and computer vision. Unfortunately, this $\\ell_{0}$-minimization\nproblem with nonnegativity constraint is computational and NP-hard because of\nthe discrete and discontinuous nature of the $\\ell_{0}$-norm. In this paper, we\nreplace the $\\ell_{0}$-norm with a non-convex fraction function, and study the\nminimization problem of this non-convex fraction function in recovering the\nsparse nonnegative signals from an underdetermined linear system. Firstly, we\ndiscuss the equivalence between $(P_{0}^{\\geq})$ and $(FP_{a}^{\\geq})$, and the\nequivalence between $(FP_{a}^{\\geq})$ and $(FP_{a,\\lambda}^{\\geq})$. It is\nproved that the optimal solution of the problem $(P_{0}^{\\geq})$ could be\napproximately obtained by solving the regularization problem\n$(FP_{a,\\lambda}^{\\geq})$ if some specific conditions satisfied. Secondly, we\npropose a nonnegative iterative thresholding algorithm to solve the\nregularization problem $(FP_{a,\\lambda}^{\\geq})$ for all $a>0$. Finally, some\nnumerical experiments on sparse nonnegative siganl recovery problems show that\nour method performs effective in finding sparse nonnegative signals compared\nwith the linear programming.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A connection between MAX $κ$-CUT and the inhomogeneous Potts spin glass in the large degree limit.   We study the asymptotic behavior of the Max $\\kappa$-cut on a family of\nsparse, inhomogeneous random graphs. In the large degree limit, the leading\nterm is a variational problem, involving the ground state of a constrained\ninhomogeneous Potts spin glass. We derive a Parisi type formula for the free\nenergy of this model, with possible constraints on the proportions, and derive\nthe limiting ground state energy by a suitable zero temperature limit.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Delayed avalanches in Multi-Pixel Photon Counters.   Hamamatsu Photonics introduced a new generation of their Multi-Pixel Photon\nCounters in 2013 with significantly reduced after-pulsing rate. In this paper,\nwe investigate the causes of after-pulsing by testing pre-2013 and post-2013\ndevices using laser light ranging from 405 to 820nm. Doing so we investigate\nthe possibility that afterpulsing is also due to optical photons produced in\nthe avalanche rather than to impurities trapping charged carriers produced in\nthe avalanches and releasing them at a later time. For pre-2013 devices, we\nobserve avalanches delayed by ns to several 100~ns at 637, 777nm and 820 nm\ndemonstrating that holes created in the zero field region of the silicon bulk\ncan diffuse back to the high field region triggering delayed avalanches. On the\nother hand post-2013 exhibit no delayed avalanches beyond 100~ns at 777nm. We\nalso confirm that post-2013 devices exhibit about 25 times lower after-pulsing.\nTaken together, our measurements show that the absorption of photons from the\navalanche in the bulk of the silicon and the subsequent hole diffusion back to\nthe junction was a significant source of after-pulse for the pre-2013 devices.\nHamamatsu appears to have fixed this problem in 2013 following the preliminary\nrelease of our results. We also show that even at short wavelength the timing\ndistribution exhibit tails in the sub-nanosecond range that may impair the MPPC\ntiming performances.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Machine Assisted Analysis of Vowel Length Contrasts in Wolof.   Growing digital archives and improving algorithms for automatic analysis of\ntext and speech create new research opportunities for fundamental research in\nphonetics. Such empirical approaches allow statistical evaluation of a much\nlarger set of hypothesis about phonetic variation and its conditioning factors\n(among them geographical / dialectal variants). This paper illustrates this\nvision and proposes to challenge automatic methods for the analysis of a not\neasily observable phenomenon: vowel length contrast. We focus on Wolof, an\nunder-resourced language from Sub-Saharan Africa. In particular, we propose\nmultiple features to make a fine evaluation of the degree of length contrast\nunder different factors such as: read vs semi spontaneous speech ; standard vs\ndialectal Wolof. Our measures made fully automatically on more than 20k vowel\ntokens show that our proposed features can highlight different degrees of\ncontrast for each vowel considered. We notably show that contrast is weaker in\nsemi-spontaneous speech and in a non standard semi-spontaneous dialect.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Meta learning Framework for Automated Driving.   The success of automated driving deployment is highly depending on the\nability to develop an efficient and safe driving policy. The problem is well\nformulated under the framework of optimal control as a cost optimization\nproblem. Model based solutions using traditional planning are efficient, but\nrequire the knowledge of the environment model. On the other hand, model free\nsolutions suffer sample inefficiency and require too many interactions with the\nenvironment, which is infeasible in practice. Methods under the Reinforcement\nLearning framework usually require the notion of a reward function, which is\nnot available in the real world. Imitation learning helps in improving sample\nefficiency by introducing prior knowledge obtained from the demonstrated\nbehavior, on the risk of exact behavior cloning without generalizing to unseen\nenvironments. In this paper we propose a Meta learning framework, based on data\nset aggregation, to improve generalization of imitation learning algorithms.\nUnder the proposed framework, we propose MetaDAgger, a novel algorithm which\ntackles the generalization issues in traditional imitation learning. We use The\nOpen Race Car Simulator (TORCS) to test our algorithm. Results on unseen test\ntracks show significant improvement over traditional imitation learning\nalgorithms, improving the learning time and sample efficiency in the same time.\nThe results are also supported by visualization of the learnt features to prove\ngeneralization of the captured details.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Global and local thermometry schemes in coupled quantum systems.   We study the ultimate bounds on the estimation of temperature for an\ninteracting quantum system. We consider two coupled bosonic modes that are\nassumed to be thermal and using quantum estimation theory establish the role\nthe Hamiltonian parameters play in thermometry. We show that in the case of a\nconserved particle number the interaction between the modes leads to a decrease\nin the overall sensitivity to temperature, while interestingly, if particle\nexchange is allowed with the thermal bath the converse is true. We explain this\ndichotomy by examining the energy spectra. Finally, we devise experimentally\nimplementable thermometry schemes that rely only on locally accessible\ninformation from the total system, showing that almost Heisenberg limited\nprecision can still be achieved, and we address the (im)possibility for\nmultiparameter estimation in the system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Analysis of Dropout in Online Learning.   Deep learning is the state-of-the-art in fields such as visual object\nrecognition and speech recognition. This learning uses a large number of layers\nand a huge number of units and connections. Therefore, overfitting is a serious\nproblem with it, and the dropout which is a kind of regularization tool is\nused. However, in online learning, the effect of dropout is not well known.\nThis paper presents our investigation on the effect of dropout in online\nlearning. We analyzed the effect of dropout on convergence speed near the\nsingular point. Our results indicated that dropout is effective in online\nlearning. Dropout tends to avoid the singular point for convergence speed near\nthat point.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A note on conditional covariance matrices for elliptical distributions.   In this short note we provide an analytical formula for the conditional\ncovariance matrices of the elliptically distributed random vectors, when the\nconditioning is based on the values of any linear combination of the marginal\nrandom variables. We show that one could introduce the univariate invariant\ndepending solely on the conditioning set, which greatly simplifies the\ncalculations. As an application, we show that one could define uniquely defined\nquantile-based sets on which conditional covariance matrices must be equal to\neach other if only the vector is multivariate normal. The similar results are\nobtained for conditional correlation matrices of the general elliptic case.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Controllability and optimal control of the transport equation with a localized vector field.   We study controllability of a Partial Differential Equation of transport\ntype, that arises in crowd models. We are interested in controlling such system\nwith a control being a Lipschitz vector field on a fixed control set $\\omega$.\nWe prove that, for each initial and final configuration, one can steer one to\nanother with such class of controls only if the uncontrolled dynamics allows to\ncross the control set $\\omega$. We also prove a minimal time result for such\nsystems. We show that the minimal time to steer one initial configuration to\nanother is related to the condition of having enough mass in $\\omega$ to feed\nthe desired final configuration.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Irreducible characters with bounded root Artin conductor.   In this work, we prove that the growth of the Artin conductor is at most,\nexponential in the degree of the character.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mining Application-aware Community Organization with Expanded Feature Subspaces from Concerned Attributes in Social Networks.   Social networks are typical attributed networks with node attributes.\nDifferent from traditional attribute community detection problem aiming at\nobtaining the whole set of communities in the network, we study an\napplication-oriented problem of mining an application-aware community\norganization with respect to specific concerned attributes. The concerned\nattributes are designated based on the requirements of any application by a\nuser in advance. The application-aware community organization w.r.t. concerned\nattributes consists of the communities with feature subspaces containing these\nconcerned attributes. Besides concerned attributes, feature subspace of each\nrequired community may contain some other relevant attributes. All relevant\nattributes of a feature subspace jointly describe and determine the community\nembedded in such subspace. Thus the problem includes two subproblems, i.e., how\nto expand the set of concerned attributes to complete feature subspaces and how\nto mine the communities embedded in the expanded subspaces. Two subproblems are\njointly solved by optimizing a quality function called subspace fitness. An\nalgorithm called ACM is proposed. In order to locate the communities\npotentially belonging to the application-aware community organization, cohesive\nparts of a network backbone composed of nodes with similar concerned attributes\nare detected and set as the community seeds. The set of concerned attributes is\nset as the initial subspace for all community seeds. Then each community seed\nand its attribute subspace are adjusted iteratively to optimize the subspace\nfitness. Extensive experiments on synthetic datasets demonstrate the\neffectiveness and efficiency of our method and applications on real-world\nnetworks show its application values.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Higher Tetrahedral Algebras.   We introduce and study the higher tetrahedral algebras, an exotic family of\nfinite-dimensional tame symmetric algebras over an algebraically closed field.\nThe Gabriel quiver of such an algebra is the triangulation quiver associated to\nthe coherent orientation of the tetrahedron. Surprisingly, these algebras\noccurred in the classification of all algebras of generalised quaternion type,\nbut are not weighted surface algebras. We prove that a higher tetrahedral\nalgebra is periodic if and only if it is non-singular.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "GraphGAN: Graph Representation Learning with Generative Adversarial Nets.   The goal of graph representation learning is to embed each vertex in a graph\ninto a low-dimensional vector space. Existing graph representation learning\nmethods can be classified into two categories: generative models that learn the\nunderlying connectivity distribution in the graph, and discriminative models\nthat predict the probability of edge existence between a pair of vertices. In\nthis paper, we propose GraphGAN, an innovative graph representation learning\nframework unifying above two classes of methods, in which the generative model\nand discriminative model play a game-theoretical minimax game. Specifically,\nfor a given vertex, the generative model tries to fit its underlying true\nconnectivity distribution over all other vertices and produces \"fake\" samples\nto fool the discriminative model, while the discriminative model tries to\ndetect whether the sampled vertex is from ground truth or generated by the\ngenerative model. With the competition between these two models, both of them\ncan alternately and iteratively boost their performance. Moreover, when\nconsidering the implementation of generative model, we propose a novel graph\nsoftmax to overcome the limitations of traditional softmax function, which can\nbe proven satisfying desirable properties of normalization, graph structure\nawareness, and computational efficiency. Through extensive experiments on\nreal-world datasets, we demonstrate that GraphGAN achieves substantial gains in\na variety of applications, including link prediction, node classification, and\nrecommendation, over state-of-the-art baselines.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Direct Evidence of Spontaneous Abrikosov Vortex State in Ferromagnetic Superconductor EuFe$_2$(As$_{1-x}$P$_x$)$_2$ with $x=0.21$.   Using low-temperature Magnetic Force Microscopy (MFM) we provide direct\nexperimental evidence for spontaneous vortex phase (SVP) formation in\nEuFe$_2$(As$_{0.79}$P$_{0.21}$)$_2$ single crystal with the superconducting\n$T^{\\rm 0}_{\\rm SC}=23.6$~K and ferromagnetic $T_{\\rm FM}\\sim17.7$~K transition\ntemperatures. Spontaneous vortex-antivortex (V-AV) pairs are imaged in the\nvicinity of $T_{\\rm FM}$. Also, upon cooling cycle near $T_{\\rm FM}$ we observe\nthe first-order transition from the short period domain structure, which\nappears in the Meissner state, into the long period domain structure with\nspontaneous vortices. It is the first experimental observation of this scenario\nin the ferromagnetic superconductors. Low-temperature phase is characterized by\nmuch larger domains in V-AV state and peculiar branched striped structures at\nthe surface, which are typical for uniaxial ferromagnets with perpendicular\nmagnetic anisotropy (PMA). The domain wall parameters at various temperatures\nare estimated.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reconstruction via the intrinsic geometric structures of interior transmission eigenfunctions.   We are concerned with the inverse scattering problem of extracting the\ngeometric structures of an unknown/inaccessible inhomogeneous medium by using\nthe corresponding acoustic far-field measurement. Using the intrinsic geometric\nproperties of the so-called interior transmission eigenfunctions, we develop a\nnovel inverse scattering scheme. The proposed method can efficiently capture\nthe cusp singularities of the support of the inhomogeneous medium. If further a\npriori information is available on the support of the medium, say, it is a\nconvex polyhedron, then one can actually recover its shape. Both theoretical\nanalysis and numerical experiments are provided. Our reconstruction method is\nnew to the literature and opens up a new direction in the study of inverse\nscattering problems.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Conceptual Frameworks for Building Online Citizen Science Projects.   In recent years, citizen science has grown in popularity due to a number of\nreasons, including the emphasis on informal learning and creativity potential\nassociated with these initiatives. Citizen science projects address research\nquestions from various domains, ranging from Ecology to Astronomy. Due to the\nadvancement of communication technologies, which makes outreach and engagement\nof wider communities easier, scientists are keen to turn their own research\ninto citizen science projects. However, the development, deployment and\nmanagement of these projects remains challenging. One of the most important\nchallenges is building the project itself. There is no single tool or\nframework, which guides the step-by-step development of the project, since\nevery project has specific characteristics, such as geographical constraints or\nvolunteers' mode of participation. Therefore, in this article, we present a\nseries of conceptual frameworks for categorisation, decision and deployment,\nwhich guide a citizen science project creator in every step of creating a new\nproject starting from the research question to project deployment. The\nframeworks are designed with consideration to the properties of already\nexisting citizen science projects and could be easily extended to include other\ndimensions, which are not currently perceived.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scalable Bayesian shrinkage and uncertainty quantification in high-dimensional regression.   Bayesian shrinkage methods have generated a lot of recent interest as tools\nfor high-dimensional regression and model selection. These methods naturally\nfacilitate tractable uncertainty quantification and incorporation of prior\ninformation. A common feature of these models, including the Bayesian lasso,\nglobal-local shrinkage priors, and spike-and-slab priors is that the\ncorresponding priors on the regression coefficients can be expressed as scale\nmixture of normals. While the three-step Gibbs sampler used to sample from the\noften intractable associated posterior density has been shown to be\ngeometrically ergodic for several of these models (Khare and Hobert, 2013; Pal\nand Khare, 2014), it has been demonstrated recently that convergence of this\nsampler can still be quite slow in modern high-dimensional settings despite\nthis apparent theoretical safeguard. We propose a new method to draw from the\nsame posterior via a tractable two-step blocked Gibbs sampler. We demonstrate\nthat our proposed two-step blocked sampler exhibits vastly superior convergence\nbehavior compared to the original three- step sampler in high-dimensional\nregimes on both real and simulated data. We also provide a detailed theoretical\nunderpinning to the new method in the context of the Bayesian lasso. First, we\nderive explicit upper bounds for the (geometric) rate of convergence.\nFurthermore, we demonstrate theoretically that while the original Bayesian\nlasso chain is not Hilbert-Schmidt, the proposed chain is trace class (and\nhence Hilbert-Schmidt). The trace class property has useful theoretical and\npractical implications. It implies that the corresponding Markov operator is\ncompact, and its eigenvalues are summable. It also facilitates a rigorous\ncomparison of the two-step blocked chain with \"sandwich\" algorithms which aim\nto improve performance of the two-step chain by inserting an inexpensive extra\nstep.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Vertex algebras associated with hypertoric varieties.   We construct a family of vertex algebras associated with a family of\nsymplectic singularity/resolution, called hypertoric varieties. While the\nhypertoric varieties are constructed by a certain Hamiltonian reduction\nassociated with a torus action, our vertex algebras are constructed by\n(semi-infinite) BRST reduction. The construction works algebro-geometrically\nand we construct sheaves of $\\hbar$-adic vertex algebras over hypertoric\nvarieties which localize the vertex algebras. We show when the vertex algebras\nare vertex operator algebras by giving explicit conformal vectors. We also show\nthat the Zhu algebras of the vertex algebras, associative algebras associated\nwith non-negatively graded vertex algebras, gives a certain family of filtered\nquantizations of the coordinate rings of the hypertoric varieties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Joint Task Offloading and Resource Allocation for Multi-Server Mobile-Edge Computing Networks.   Mobile-Edge Computing (MEC) is an emerging paradigm that provides a capillary\ndistribution of cloud computing capabilities to the edge of the wireless access\nnetwork, enabling rich services and applications in close proximity to the end\nusers. In this article, a MEC enabled multi-cell wireless network is considered\nwhere each Base Station (BS) is equipped with a MEC server that can assist\nmobile users in executing computation-intensive tasks via task offloading. The\nproblem of Joint Task Offloading and Resource Allocation (JTORA) is studied in\norder to maximize the users' task offloading gains, which is measured by the\nreduction in task completion time and energy consumption. The considered\nproblem is formulated as a Mixed Integer Non-linear Program (MINLP) that\ninvolves jointly optimizing the task offloading decision, uplink transmission\npower of mobile users, and computing resource allocation at the MEC servers.\nDue to the NP-hardness of this problem, solving for optimal solution is\ndifficult and impractical for a large-scale network. To overcome this drawback,\nour approach is to decompose the original problem into (i) a Resource\nAllocation (RA) problem with fixed task offloading decision and (ii) a Task\nOffloading (TO) problem that optimizes the optimal-value function corresponding\nto the RA problem. We address the RA problem using convex and quasi-convex\noptimization techniques, and propose a novel heuristic algorithm to the TO\nproblem that achieves a suboptimal solution in polynomial time. Numerical\nsimulation results show that our algorithm performs closely to the optimal\nsolution and that it significantly improves the users' offloading utility over\ntraditional approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Threat analysis of IoT networks Using Artificial Neural Network Intrusion Detection System.   The Internet of things (IoT) is still in its infancy and has attracted much\ninterest in many industrial sectors including medical fields, logistics\ntracking, smart cities and automobiles. However as a paradigm, it is\nsusceptible to a range of significant intrusion threats. This paper presents a\nthreat analysis of the IoT and uses an Artificial Neural Network (ANN) to\ncombat these threats. A multi-level perceptron, a type of supervised ANN, is\ntrained using internet packet traces, then is assessed on its ability to thwart\nDistributed Denial of Service (DDoS/DoS) attacks. This paper focuses on the\nclassification of normal and threat patterns on an IoT Network. The ANN\nprocedure is validated against a simulated IoT network. The experimental\nresults demonstrate 99.4% accuracy and can successfully detect various DDoS/DoS\nattacks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topology and experimental distinguishability.   In this work we introduce the idea that the primary application of topology\nin experimental sciences is to keep track of what can be distinguished through\nexperimentation. This link provides understanding and justification as to why\ntopological spaces and continuous functions are pervasive tools in science. We\nfirst define an experimental observation as a statement that can be verified\nusing an experimental procedure and show that observations are closed under\nfinite conjunction and countable disjunction. We then consider observations\nthat identify elements within a set and show how they induce a Hausdorff and\nsecond-countable topology on that set, thus identifying an open set as one that\ncan be associated with an experimental observation. We then show that\nexperimental relationships are continuous functions, as they must preserve\nexperimental distinguishability, and that they are themselves experimentally\ndistinguishable by defining a Hausdorff and second-countable topology for this\ncollection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inter-Subject Analysis: Inferring Sparse Interactions with Dense Intra-Graphs.   We develop a new modeling framework for Inter-Subject Analysis (ISA). The\ngoal of ISA is to explore the dependency structure between different subjects\nwith the intra-subject dependency as nuisance. It has important applications in\nneuroscience to explore the functional connectivity between brain regions under\nnatural stimuli. Our framework is based on the Gaussian graphical models, under\nwhich ISA can be converted to the problem of estimation and inference of the\ninter-subject precision matrix. The main statistical challenge is that we do\nnot impose sparsity constraint on the whole precision matrix and we only assume\nthe inter-subject part is sparse. For estimation, we propose to estimate an\nalternative parameter to get around the non-sparse issue and it can achieve\nasymptotic consistency even if the intra-subject dependency is dense. For\ninference, we propose an \"untangle and chord\" procedure to de-bias our\nestimator. It is valid without the sparsity assumption on the inverse Hessian\nof the log-likelihood function. This inferential method is general and can be\napplied to many other statistical problems, thus it is of independent\ntheoretical interest. Numerical experiments on both simulated and brain imaging\ndata validate our methods and theory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spatial Models with the Integrated Nested Laplace Approximation within Markov Chain Monte Carlo.   The Integrated Nested Laplace Approximation (INLA) is a convenient way to\nobtain approximations to the posterior marginals for parameters in Bayesian\nhierarchical models when the latent effects can be expressed as a Gaussian\nMarkov Random Field (GMRF). In addition, its implementation in the R-INLA\npackage for the R statistical software provides an easy way to fit models using\nINLA in practice. R-INLA implements a number of widely used latent models,\nincluding several spatial models. In addition, R-INLA can fit models in a\nfraction of the time than other computer intensive methods (e.g. Markov Chain\nMonte Carlo) take to fit the same model.\nAlthough INLA provides a fast approximation to the marginals of the model\nparameters, it is difficult to use it with models not implemented in R-INLA. It\nis also difficult to make multivariate posterior inference on the parameters of\nthe model as INLA focuses on the posterior marginals and not the joint\nposterior distribution.\nIn this paper we describe how to use INLA within the Metropolis-Hastings\nalgorithm to fit spatial models and estimate the joint posterior distribution\nof a reduced number of parameters. We will illustrate the benefits of this new\nmethod with two examples on spatial econometrics and disease mapping where\ncomplex spatial models with several spatial structures need to be fitted.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Helium fingers in the intracluster medium.   In this paper we investigate the convection phenomenon in the intracluster\nmedium (the weakly-collisional magnetized inhomogeneous plasma permeating\ngalaxy clusters) where the concentration gradient of the Helium ions is not\nignorable. To this end, we build upon the general machinery employed to study\nthe salt finger instability found in the oceans. The salt finger instability is\na form of double diffusive convection where the diffusions of two physical\nquantities---heat and salt concentrations---occur with different diffusion\nrates. The analogous instability in the intracluster medium may result owing to\nthe magnetic field mediated anisotropic diffusions of the heat and the Helium\nions (in the sea of the Hydrogen ions and the free electrons). These two\ndiffusions have inherently different diffusion rates. Hence the convection\ncaused by the onset of this instability is an example of double diffusive\nconvection in the astrophysical settings. A consequence of this instability is\nthe formation of the vertical filamentary structures having more concentration\nof the Helium ions with respect to the immediate neighbourhoods of the\nfilaments. We term these structures as Helium fingers in analogy with the salt\nfingers found in the case of the salt finger instability. Here we show that the\nwidth of a Helium finger scales as one-fourth power of the radius of the inner\nregion of the intracluster medium in the supercritical regime. We also\ndetermine the explicit mathematical expression of the criterion for the onset\nof the heat-flux-driven buoyancy instability modified by the presence of\ninhomogeneously distributed Helium ions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Core2Vec: A core-preserving feature learning framework for networks.   Recent advances in the field of network representation learning are mostly\nattributed to the application of the skip-gram model in the context of graphs.\nState-of-the-art analogues of skip-gram model in graphs define a notion of\nneighbourhood and aim to find the vector representation for a node, which\nmaximizes the likelihood of preserving this neighborhood.\nIn this paper, we take a drastic departure from the existing notion of\nneighbourhood of a node by utilizing the idea of coreness. More specifically,\nwe utilize the well-established idea that nodes with similar core numbers play\nequivalent roles in the network and hence induce a novel and an organic notion\nof neighbourhood. Based on this idea, we propose core2vec, a new algorithmic\nframework for learning low dimensional continuous feature mapping for a node.\nConsequently, the nodes having similar core numbers are relatively closer in\nthe vector space that we learn.\nWe further demonstrate the effectiveness of core2vec by comparing word\nsimilarity scores obtained by our method where the node representations are\ndrawn from standard word association graphs against scores computed by other\nstate-of-the-art network representation techniques like node2vec, DeepWalk and\nLINE. Our results always outperform these existing methods",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning with Changing Features.   In this paper we study the setting where features are added or change\ninterpretation over time, which has applications in multiple domains such as\nretail, manufacturing, finance. In particular, we propose an approach to\nprovably determine the time instant from which the new/changed features start\nbecoming relevant with respect to an output variable in an agnostic\n(supervised) learning setting. We also suggest an efficient version of our\napproach which has the same asymptotic performance. Moreover, our theory also\napplies when we have more than one such change point. Independent post analysis\nof a change point identified by our method for a large retailer revealed that\nit corresponded in time with certain unflattering news stories about a brand\nthat resulted in the change in customer behavior. We also applied our method to\ndata from an advanced manufacturing plant identifying the time instant from\nwhich downstream features became relevant. To the best of our knowledge this is\nthe first work that formally studies change point detection in a distribution\nindependent agnostic setting, where the change point is based on the changing\nrelationship between input and output.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Premise Selection for Theorem Proving by Deep Graph Embedding.   We propose a deep learning-based approach to the problem of premise\nselection: selecting mathematical statements relevant for proving a given\nconjecture. We represent a higher-order logic formula as a graph that is\ninvariant to variable renaming but still fully preserves syntactic and semantic\ninformation. We then embed the graph into a vector via a novel embedding method\nthat preserves the information of edge ordering. Our approach achieves\nstate-of-the-art results on the HolStep dataset, improving the classification\naccuracy from 83% to 90.3%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the $p'$-subgraph of the Young graph.   Let $p$ be a prime number. In this article we study the restriction to\n$\\mathfrak{S}_{n-1}$ of irreducible characters of degree coprime to $p$ of\n$\\mathfrak{S}_n$. In particular, we study the combinatorial properties of the\nsubgraph $\\mathbb{Y}_{p'}$ of the Young graph $\\mathbb{Y}$. This is an\nextension to odd primes of the work done by Ayyer, Prasad and Spallone for\n$p=2$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Machine learning in protein engineering.   Machine learning-guided protein engineering is a new paradigm that enables\nthe optimization of complex protein functions. Machine-learning methods use\ndata to predict protein function without requiring a detailed model of the\nunderlying physics or biological pathways. They accelerate protein engineering\nby learning from information contained in all measured variants and using it to\nselect variants that are likely to be improved. In this review, we introduce\nthe steps required to collect protein data, train machine-learning models, and\nuse trained models to guide engineering. We make recommendations at each stage\nand look to future opportunities for machine learning to enable the discovery\nof new protein functions and uncover the relationship between protein sequence\nand function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gamma-Band Correlations in Primary Visual Cortex.   Neural field theory is used to quantitatively analyze the two-dimensional\nspatiotemporal correlation properties of gamma-band (30 -- 70 Hz) oscillations\nevoked by stimuli arriving at the primary visual cortex (V1), and modulated by\npatchy connectivities that depend on orientation preference (OP). Correlation\nfunctions are derived analytically under different stimulus and measurement\nconditions. The predictions reproduce a range of published experimental\nresults, including the existence of two-point oscillatory temporal\ncross-correlations with zero time-lag between neurons with similar OP, the\ninfluence of spatial separation of neurons on the strength of the correlations,\nand the effects of differing stimulus orientations.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Optimal learning via local entropies and sample compression.   The aim of this paper is to provide several novel upper bounds on the excess\nrisk with a primal focus on classification problems. We suggest two approaches\nand the obtained bounds are represented via the distribution dependent local\nentropies of the classes or the sizes of specific sample com- pression schemes.\nWe show that in some cases, our guarantees are optimal up to constant factors\nand outperform previously known results. As an application of our results, we\nprovide a new tight PAC bound for the hard-margin SVM, an extended analysis of\ncertain empirical risk minimizers under log-concave distributions, a new\nvariant of an online to batch conversion, and distribution dependent localized\nbounds in the aggregation framework. We also develop techniques that allow to\nreplace empirical covering number or covering numbers with bracketing by the\ncoverings with respect to the distribution of the data. The proofs for the\nsample compression schemes are based on the moment method combined with the\nanalysis of voting algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Systematic Evaluation of Static API-Misuse Detectors.   Application Programming Interfaces (APIs) often have usage constraints, such\nas restrictions on call order or call conditions. API misuses, i.e., violations\nof these constraints, may lead to software crashes, bugs, and vulnerabilities.\nThough researchers developed many API-misuse detectors over the last two\ndecades, recent studies show that API misuses are still prevalent. Therefore,\nwe need to understand the capabilities and limitations of existing detectors in\norder to advance the state of the art. In this paper, we present the first-ever\nqualitative and quantitative evaluation that compares static API-misuse\ndetectors along the same dimensions, and with original author validation. To\naccomplish this, we develop MUC, a classification of API misuses, and\nMUBenchPipe, an automated benchmark for detector comparison, on top of our\nmisuse dataset, MUBench. Our results show that the capabilities of existing\ndetectors vary greatly and that existing detectors, though capable of detecting\nmisuses, suffer from extremely low precision and recall. A systematic\nroot-cause analysis reveals that, most importantly, detectors need to go beyond\nthe naive assumption that a deviation from the most-frequent usage corresponds\nto a misuse and need to obtain additional usage examples to train their models.\nWe present possible directions towards more-powerful API-misuse detectors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Superior lattice thermal conductance of single layer borophene.   By way of the nonequilibrium Green's function simulations and first\nprinciples calculations, we report that borophene, a single layer of boron\natoms that was fabricated recently, possesses an extraordinarily high lattice\nthermal conductance in the ballistic transport regime, which even exceeds\ngraphene. In addition to the obvious reasons of light mass and strong bonding\nof boron atoms, the superior thermal conductance is mainly rooted in its strong\nstructural anisotropy and unusual phonon transmission. For low-frequency\nphonons, the phonon transmission within borophene is nearly isotropic, similar\nto that of graphene. For high frequency phonons, however, the transmission is\none dimensional, that is, all the phonons travel in one direction, giving rise\nto its ultrahigh thermal conductance. The present study suggests that borophene\nis promising for applications in efficient heat dissipation and thermal\nmanagement, and also an ideal material for revealing fundamentals of\ndimensionality effect on phonon transport in ballistic regime.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Timing Aware Dummy Metal Fill Methodology.   In this paper, we analyzed parasitic coupling capacitance coming from dummy\nmetal fill and its impact on timing. Based on the modeling, we proposed two\napproaches to minimize the timing impact from dummy metal fill. The first\napproach applies more spacing between critical nets and metal fill, while the\nsecond approach leverages the shielding effects of reference nets. Experimental\nresults show consistent improvement compared to traditional metal fill method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Charge exchange in galaxy clusters.   Though theoretically expected, the charge exchange emission from galaxy\nclusters has not yet been confidently detected. Accumulating hints were\nreported recently, including a rather marginal detection with the Hitomi data\nof the Perseus cluster. As suggested in Gu et al. (2015), a detection of charge\nexchange line emission from galaxy clusters would not only impact the\ninterpretation of the newly-discovered 3.5 keV line, but also open up a new\nresearch topic on the interaction between hot and cold matter in clusters. We\naim to perform the most systematic search for the O VIII charge exchange line\nin cluster spectra using the RGS on board XMM. We introduce a sample of 21\nclusters observed with the RGS. The dominating thermal plasma emission is\nmodeled and subtracted with a two-temperature CIE component, and the residuals\nare stacked for the line search. The systematic uncertainties in the fits are\nquantified by refitting the spectra with a varying continuum and line\nbroadening. By the residual stacking, we do find a hint of a line-like feature\nat 14.82 A, the characteristic wavelength expected for oxygen charge exchange.\nThis feature has a marginal significance of 2.8 sigma, and the average\nequivalent width is 2.5E-4 keV. We further demonstrate that the putative\nfeature can be hardly affected by the systematic errors from continuum\nmodelling and instrumental effects, or the atomic uncertainties of the\nneighbouring thermal lines. Assuming a realistic temperature and abundance\npattern, the physical model implied by the possible oxygen line agrees well\nwith the theoretical model proposed previously to explain the reported 3.5 keV\nline. If the charge exchange source indeed exists, we would expect that the\noxygen abundance is potentially overestimated by 8-22% in previous X-ray\nmeasurements which assumed pure thermal lines.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bootstrapping Generalization Error Bounds for Time Series.   We consider the problem of finding confidence intervals for the risk of\nforecasting the future of a stationary, ergodic stochastic process, using a\nmodel estimated from the past of the process. We show that a bootstrap\nprocedure provides valid confidence intervals for the risk, when the data\nsource is sufficiently mixing, and the loss function and the estimator are\nsuitably smooth. Autoregressive (AR(d)) models estimated by least squares obey\nthe necessary regularity conditions, even when mis-specified, and simulations\nshow that the finite- sample coverage of our bounds quickly converges to the\ntheoretical, asymptotic level. As an intermediate step, we derive sufficient\nconditions for asymptotic independence between empirical distribution functions\nformed by splitting a realization of a stochastic process, of independent\ninterest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting signatures of anisotropic resonance energy transfer in dye-functionalized nanoparticles.   Resonance energy transfer (RET) is an inherently anisotropic process. Even\nthe simplest, well-known Förster theory, based on the transition\ndipole-dipole coupling, implicitly incorporates the anisotropic character of\nRET. In this theoretical work, we study possible signatures of the fundamental\nanisotropic character of RET in hybrid nanomaterials composed of a\nsemiconductor nanoparticle (NP) decorated with molecular dyes. In particular,\nby means of a realistic kinetic model, we show that the analysis of the dye\nphotoluminescence difference for orthogonal input polarizations reveals the\nanisotropic character of the dye-NP RET which arises from the intrinsic\nanisotropy of the NP lattice. In a prototypical core/shell wurtzite CdSe/ZnS NP\nfunctionalized with cyanine dyes (Cy3B), this difference is predicted to be as\nlarge as 75\\% and it is strongly dependent in amplitude and sign on the dye-NP\ndistance. We account for all the possible RET processes within the system,\ntogether with competing decay pathways in the separate segments. In addition,\nwe show that the anisotropic signature of RET is persistent up to a large\nnumber of dyes per NP.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Possible evidence for spin-transfer torque induced by spin-triplet supercurrent.   Cooper pairs in superconductors are normally spin singlet. Nevertheless,\nrecent studies suggest that spin-triplet Cooper pairs can be created at\ncarefully engineered superconductor-ferromagnet interfaces. If Cooper pairs are\nspin-polarized they would transport not only charge but also a net spin\ncomponent, but without dissipation, and therefore minimize the heating effects\nassociated with spintronic devices. Although it is now established that triplet\nsupercurrents exist, their most interesting property - spin - is only inferred\nindirectly from transport measurements. In conventional spintronics, it is well\nknown that spin currents generate spin-transfer torques that alter\nmagnetization dynamics and switch magnetic moments. The observation of similar\neffects due to spin-triplet supercurrents would not only confirm the net spin\nof triplet pairs but also pave the way for applications of superconducting\nspintronics. Here, we present a possible evidence for spin-transfer torques\ninduced by triplet supercurrents in superconductor/ferromagnet/superconductor\n(S/F/S) Josephson junctions. Below the superconducting transition temperature\nT_c, the ferromagnetic resonance (FMR) field at X-band (~ 9.0 GHz) shifts\nrapidly to a lower field with decreasing temperature due to the spin-transfer\ntorques induced by triplet supercurrents. In contrast, this phenomenon is\nabsent in ferromagnet/superconductor (F/S) bilayers and\nsuperconductor/insulator/ferromagnet/superconductor (S/I/F/S) multilayers where\nno supercurrents pass through the ferromagnetic layer. These experimental\nobservations are discussed with theoretical predictions for ferromagnetic\nJosephson junctions with precessing magnetization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Gibbons-Hawking ansatz over a wedge.   We discuss the Ricci-flat `model metrics' on $\\mathbb{C}^2$ with cone\nsingularities along the conic $\\{zw=1\\}$ constructed by Donaldson using the\nGibbons-Hawking ansatz over wedges in $\\mathbb{R}^3$. In particular we describe\ntheir asymptotic behavior at infinity and compute their energies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Explaining Transition Systems through Program Induction.   Explaining and reasoning about processes which underlie observed black-box\nphenomena enables the discovery of causal mechanisms, derivation of suitable\nabstract representations and the formulation of more robust predictions. We\npropose to learn high level functional programs in order to represent abstract\nmodels which capture the invariant structure in the observed data. We introduce\nthe $\\pi$-machine (program-induction machine) -- an architecture able to induce\ninterpretable LISP-like programs from observed data traces. We propose an\noptimisation procedure for program learning based on backpropagation, gradient\ndescent and A* search. We apply the proposed method to three problems: system\nidentification of dynamical systems, explaining the behaviour of a DQN agent\nand learning by demonstration in a human-robot interaction scenario. Our\nexperimental results show that the $\\pi$-machine can efficiently induce\ninterpretable programs from individual data traces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Genus-One Global Mirror Theorem for the Quintic Threefold.   We prove the genus-one restriction of the all-genus\nLandau-Ginzburg/Calabi-Yau conjecture of Chiodo and Ruan, stated in terms of\nthe geometric quantization of an explicit symplectomorphism determined by\ngenus-zero invariants. This provides the first evidence supporting the\nhigher-genus Landau-Ginzburg/Calabi-Yau correspondence for the quintic\nthreefold, and exhibits the first instance of the \"genus zero controls higher\ngenus\" principle, in the sense of Givental's quantization formalism, for\nnon-semisimple cohomological field theories.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the \"Calligraphy\" of Books.   Authorship attribution is a natural language processing task that has been\nwidely studied, often by considering small order statistics. In this paper, we\nexplore a complex network approach to assign the authorship of texts based on\ntheir mesoscopic representation, in an attempt to capture the flow of the\nnarrative. Indeed, as reported in this work, such an approach allowed the\nidentification of the dominant narrative structure of the studied authors. This\nhas been achieved due to the ability of the mesoscopic approach to take into\naccount relationships between different, not necessarily adjacent, parts of the\ntext, which is able to capture the story flow. The potential of the proposed\napproach has been illustrated through principal component analysis, a\ncomparison with the chance baseline method, and network visualization. Such\nvisualizations reveal individual characteristics of the authors, which can be\nunderstood as a kind of calligraphy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stationary solutions for the ellipsoidal BGK model in a slab.   We address the boundary value problem for the ellipsoidal BGK model of the\nBoltzmann equation posed in a bounded interval. The existence of a unique mild\nsolution is established under the assumption that the inflow boundary data does\nnot concentrate too much around the zero velocity, and the gas is sufficiently\nrarefied.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Exact description of coalescing eigenstates in open quantum systems in terms of microscopic Hamiltonian dynamics.   At the exceptional point where two eigenstates coalesce in open quantum\nsystems, the usual diagonalization scheme breaks down and the Hamiltonian can\nonly be reduced to Jordan block form. Most of the studies on the exceptional\npoint appearing in the literature introduce a phenomenological effective\nHamiltonian that essentially reduces the problem to that of a finite\nnon-Hermitian matrix for which it is straightforward to obtain the Jordan form.\nIn this paper, we demonstrate how the Hamiltonian of an open quantum system\nreduces to Jordan block form at an exceptional point in an exact manner that\ntreats the continuum without any approximation. Our method relies on the\nBrillouin-Wigner-Feshbach projection method according to which we can obtain a\nfinite dimensional effective Hamiltonian that shares the discrete sector of the\nspectrum with the original Hamiltonian. While owing to its eigenvalue\ndependence this effective Hamiltonian cannot be used to write the Jordan block\ndirectly, we show that by formally extending the problem to include eigenstates\nwith complex eigenvalues that reside outside the usual Hilbert space, we can\nobtain the Jordan block form at the exceptional point without introducing any\napproximation. We also introduce an extended Jordan form basis away from the\nexceptional point, which provides an alternative way to obtain the Jordan block\nat an exceptional point. The extended Jordan block connects continuously to the\nJordan block exactly at the exceptional point implying that the observable\nquantities are continuous at the exceptional point.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weighted network estimation by the use of topological graph metrics.   Topological metrics of graphs provide a natural way to describe the prominent\nfeatures of various types of networks. Graph metrics describe the structure and\ninterplay of graph edges and have found applications in many scientific fields.\nIn this work, graph metrics are used in network estimation by developing\noptimisation methods that incorporate prior knowledge of a network's topology.\nThe derivatives of graph metrics are used in gradient descent schemes for\nweighted undirected network denoising, network completion, and network\ndecomposition. The successful performance of our methodology is shown in a\nnumber of toy examples and real-world datasets. Most notably, our work\nestablishes a new link between graph theory, network science and optimisation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Rees algebra of a two-Borel ideal is Koszul.   Let $M$ and $N$ be two monomials of the same degree, and let $I$ be the\nsmallest Borel ideal containing $M$ and $N$. We show that the toric ring of $I$\nis Koszul by constructing a quadratic Gröbner basis for the associated toric\nideal. Our proofs use the construction of graphs corresponding to fibers of the\ntoric map. As a consequence, we conclude that the Rees algebra is also Koszul.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Insulator to Metal Transition in WO$_3$ Induced by Electrolyte Gating.   Tungsten oxide and its associated bronzes (compounds of tungsten oxide and an\nalkali metal) are well known for their interesting optical and electrical\ncharacteristics. We have modified the transport properties of thin WO$_3$ films\nby electrolyte gating using both ionic liquids and polymer electrolytes. We are\nable to tune the resistivity of the gated film by more than five orders of\nmagnitude, and a clear insulator-to-metal transition is observed. To clarify\nthe doping mechanism, we have performed a series of incisive operando\nexperiments, ruling out both a purely electronic effect (charge accumulation\nnear the interface) and oxygen-related mechanisms. We propose instead that\nhydrogen intercalation is responsible for doping WO$_3$ into a highly\nconductive ground state and provide evidence that it can be described as a\ndense polaronic gas.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Measuring filament orientation: a new quantitative, local approach.   The relative orientation between filamentary structures in molecular clouds\nand the ambient magnetic field provides insight into filament formation and\nstability. To calculate the relative orientation, a measurement of filament\norientation is first required. We propose a new method to calculate the\norientation of the one pixel wide filament skeleton that is output by filament\nidentification algorithms such as \\textsc{filfinder}. We derive the local\nfilament orientation from the direction of the intensity gradient in the\nskeleton image using the Sobel filter and a few simple post-processing steps.\nWe call this the `Sobel-gradient method'. The resulting filament orientation\nmap can be compared quantitatively on a local scale with the magnetic field\norientation map to then find the relative orientation of the filament with\nrespect to the magnetic field at each point along the filament. It can also be\nused in constructing radial profiles for filament width fitting. The proposed\nmethod facilitates automation in analysis of filament skeletons, which is\nimperative in this era of `big data'.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Interface magnetism and electronic structure: ZnO(0001)/Co3O4(111).   We have studied the structural, electronic and magnetic properties of spinel\n$\\rm Co_3O_4$(111) surfaces and their interfaces with ZnO (0001) using density\nfunctional theory (DFT) within the Generalized Gradient Approximation with\non-site Coulomb repulsion term (GGA+U). Two possible forms of spinel surface,\ncontaining $\\rm Co^{2+} $ and $\\rm Co^{3+} $ ions and terminated with either\ncobalt or oxygen ions were considered, as well as their interface with zinc\noxide. Our calculations demonstrate that $\\rm Co^{3+} $ ions attain non-zero\nmagnetic moments at the surface and interface, in contrast to the bulk, where\nthey are not magnetic, leading to the ferromagnetic ordering. Since heavily\nCo-doped ZnO samples can contain $\\rm Co_3O_4 $ secondary phase, such a\nmagnetic ordering at the interface might explain the origin of the magnetism in\nthese diluted magnetic semiconductors (DMS).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Prediction Scores as a Window into Classifier Behavior.   Most multi-class classifiers make their prediction for a test sample by\nscoring the classes and selecting the one with the highest score. Analyzing\nthese prediction scores is useful to understand the classifier behavior and to\nassess its reliability. We present an interactive visualization that\nfacilitates per-class analysis of these scores. Our system, called Classilist,\nenables relating these scores to the classification correctness and to the\nunderlying samples and their features. We illustrate how such analysis reveals\nvarying behavior of different classifiers. Classilist is available for use\nonline, along with source code, video tutorials, and plugins for R, RapidMiner,\nand KNIME at this https URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Free Information Flow Benefits Truth Seeking.   How can we approach the truth in a society? It may depend on various factors.\nIn this paper, using a well-established truth seeking model, we show that the\npersistent free information flow will bring us to the truth. Here the free\ninformation flow is modeled as the environmental random noise that could alter\none's cognition. Without the random noise, the model predicts that the truth\ncan only be captured by the truth seekers who own active perceptive ability of\nthe truth and their believers, while the other individuals may stick to\nfalsehood. But under the influence of the random noise, we strictly prove that\neven there is only one truth seeker in the group, all individuals will finally\napproach the truth.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Ab initio effective Hamiltonians for cuprate superconductors.   Ab initio low-energy effective Hamiltonians of two typical high-temperature\ncopper-oxide superconductors, whose mother compounds are La$_2$CuO$_4$ and\nHgBa$_2$CuO$_4$, are derived by utilizing the multi-scale ab initio scheme for\ncorrelated electrons (MACE). The effective Hamiltonians obtained in the present\nstudy serve as platforms of future studies to accurately solve the low-energy\neffective Hamiltonians beyond the density functional theory. It allows further\nstudy on the superconducting mechanism from the first principles and\nquantitative basis without adjustable parameters not only for the available\ncuprates but also for future design of higher Tc in general. More concretely,\nwe derive effective Hamiltonians for three variations, 1)one-band Hamiltonian\nfor the antibonding orbital generated from strongly hybridized Cu\n$3d_{x^2-y^2}$ and O $2p_\\sigma$ orbitals 2)two-band Hamiltonian constructed\nfrom the antibonding orbital and Cu $3d_{3z^2-r^2}$ orbital hybridized mainly\nwith the apex oxygen $p_z$ orbital 3)three-band Hamiltonian consisting mainly\nof Cu $3d_{x^2-y^2}$ orbitals and two O $2p_\\sigma$ orbitals. Differences\nbetween the Hamiltonians for La$_2$CuO$_4$ and HgBa$_2$CuO$_4$, which have\nrelatively low and high critical temperatures, respectively, at optimally doped\ncompounds, are elucidated. The main differences are summarized as i) the oxygen\n$2p_\\sigma$ orbitals are farther(~3.7eV) below from the Cu $d_{x^2-y^2}$\norbital for the La compound than the Hg compound(~2.4eV) in the three-band\nHamiltonian. This causes a substantial difference in the character of the\n$d_{x^2-y^2}-2p_\\sigma$ antibonding band at the Fermi level and makes the\neffective onsite Coulomb interaction U larger for the La compound than the Hg\ncompound for the two- and one-band Hamiltonians. ii)The ratio of the\nsecond-neighbor to the nearest transfer t'/t is also substantially different\n(~0.26) for the Hg and ~0.15 for the La compound in the one-band Hamiltonian.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Magnetic droplet nucleation with homochiral Neel domain wall.   We investigate the effect of the Dzyaloshinskii Moriya interaction (DMI) on\nmagnetic domain nucleation in a ferromagnetic thin film with perpendicular\nmagnetic anisotropy. We propose an extended droplet model to determine the\nnucleation field as a function of the in-plane field. The model can explain the\nexperimentally observed nucleation in a CoNi microstrip with the interfacial\nDMI. The results are also reproduced by micromagnetic simulation based on the\nstring model. The electrical measurement method proposed in this study can be\nwidely used to quantitatively determine the DMI energy density.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "One-loop binding corrections to the electron $g$ factor.   We calculate the one-loop electron self-energy correction of order\n$\\alpha\\,(Z\\,\\alpha)^5$ to the bound electron $g$ factor. Our result is in\nagreement with the extrapolated numerical value and paves the way for the\ncalculation of the analogous, but as yet unknown two-loop correction.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Detection of low dimensionality and data denoising via set estimation techniques.   This work is closely related to the theories of set estimation and manifold\nestimation.\nOur object of interest is a, possibly lower-dimensional, compact set $S\n\\subset {\\mathbb R}^d$.\nThe general aim is to identify (via stochastic procedures) some qualitative\nor quantitative features of $S$, of geometric or topological character. The\navailable information is just a random sample of points drawn on $S$.\nThe term \"to identify\" means here to achieve a correct answer almost surely\n(a.s.) when the sample size tends to infinity. More specifically the paper aims\nat giving some partial answers to the following questions: is $S$ full\ndimensional? Is $S$ \"close to a lower dimensional set\" $\\mathcal{M}$? If so,\ncan we estimate $\\mathcal{M}$ or some functionals of $\\mathcal{M}$ (in\nparticular, the Minkowski content of $\\mathcal{M}$)? As an important auxiliary\ntool in the answers of these questions, a denoising procedure is proposed in\norder to partially remove the noise in the original data. The theoretical\nresults are complemented with some simulations and graphical illustrations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Principal Eigenvalue of Mixed Problem for the Fractional Laplacian: Moving the Boundary Conditions.   We analyze the behavior of the eigenvalues of the following non local mixed\nproblem $\\left\\{ \\begin{array}{rcll} (-\\Delta)^{s} u &=& \\lambda_1(D) \\ u\n&\\inn\\Omega,\\\\ u&=&0&\\inn D,\\\\ \\mathcal{N}_{s}u&=&0&\\inn N. \\end{array}\\right $\nOur goal is to construct different sequences of problems by modifying the\nconfiguration of the sets $D$ and $N$, and to provide sufficient and necessary\nconditions on the size and the location of these sets in order to obtain\nsequences of eigenvalues that in the limit recover the eigenvalues of the\nDirichlet or Neumann problem. We will see that the non locality plays a crucial\nrole here, since the sets $D$ and $N$ can have infinite measure, a phenomenon\nthat does not appear in the local case (see for example \\cite{D,D2,CP}).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efimov Effect in the Dirac Semi-metals.   Efimov effect refers to quantum states with discrete scaling symmetry and a\nuniversal scaling factor, and has attracted considerable interests from nuclear\nto atomic physics communities. In a Dirac semi-metal, when an electron\ninteracts with a static impurity though a Coulomb interaction, the same scaling\nof the kinetic and interaction energies also gives rise to such a Efimov\neffect. However, even when the Fermi energy exactly lies at the Dirac point,\nthe vacuum polarization of electron-hole pair fluctuation can still screen the\nCoulomb interaction, which leads to derivation from this scaling symmetry and\neventually breakdown of the Efimov effect. This distortion of the Efimov bound\nstate energy due to vacuum polarization is a relativistic electron analogy of\nthe Lamb shift for the hydrogen atom. Motivated by recent experimental\nobservations in two- and three-dimensional Dirac semi-metals, in this paper we\ninvestigate this many-body correction to the Efimov effect, and answer the\nquestion that under what condition a good number of Efimov-like bound states\ncan still be observed in these condensed matter experiments.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Interplay between relativistic energy corrections and resonant excitations in x-ray multiphoton ionization dynamics of Xe atoms.   In this paper, we theoretically study x-ray multiphoton ionization dynamics\nof heavy atoms taking into account relativistic and resonance effects. When an\natom is exposed to an intense x-ray pulse generated by an x-ray free-electron\nlaser (XFEL), it is ionized to a highly charged ion via a sequence of\nsingle-photon ionization and accompanying relaxation processes, and its final\ncharge state is limited by the last ionic state that can be ionized by a\nsingle-photon ionization. If x-ray multiphoton ionization involves deep\ninner-shell electrons in heavy atoms, energy shifts by relativistic effects\nplay an important role in ionization dynamics, as pointed out in [Phys.\\ Rev.\\\nLett.\\ \\textbf{110}, 173005 (2013)]. On the other hand, if the x-ray beam has a\nbroad energy bandwidth, the high-intensity x-ray pulse can drive resonant\nphoto-excitations for a broad range of ionic states and ionize even beyond the\ndirect one-photon ionization limit, as first proposed in [Nature\\ Photon.\\\n\\textbf{6}, 858 (2012)]. To investigate both relativistic and resonance\neffects, we extend the \\textsc{xatom} toolkit to incorporate relativistic\nenergy corrections and resonant excitations in x-ray multiphoton ionization\ndynamics calculations. Charge-state distributions are calculated for Xe atoms\ninteracting with intense XFEL pulses at a photon energy of 1.5~keV and 5.5~keV,\nrespectively. For both photon energies, we demonstrate that the role of\nresonant excitations in ionization dynamics is altered due to significant\nshifts of orbital energy levels by relativistic effects. Therefore it is\nnecessary to take into account both effects to accurately simulate multiphoton\nmultiple ionization dynamics at high x-ray intensity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Deconvolutional Latent-Variable Model for Text Sequence Matching.   A latent-variable model is introduced for text matching, inferring sentence\nrepresentations by jointly optimizing generative and discriminative objectives.\nTo alleviate typical optimization challenges in latent-variable models for\ntext, we employ deconvolutional networks as the sequence decoder (generator),\nproviding learned latent codes with more semantic information and better\ngeneralization. Our model, trained in an unsupervised manner, yields stronger\nempirical predictive performance than a decoder based on Long Short-Term Memory\n(LSTM), with less parameters and considerably faster training. Further, we\napply it to text sequence-matching problems. The proposed model significantly\noutperforms several strong sentence-encoding baselines, especially in the\nsemi-supervised setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "FNS: an event-driven spiking neural network framework for efficient simulations of large-scale brain models.   Limitations in processing capabilities and memory of today's computers make\nspiking neuron-based (human) whole-brain simulations inevitably characterized\nby a compromise between bio-plausibility and computational cost. It translates\ninto brain models composed of a reduced number of neurons and a simplified\nneuron's mathematical model. Taking advantage of the sparse character of\nbrain-like computation, eventdriven technique allows us to carry out efficient\nsimulation of large-scale Spiking Neural Networks (SNN). The recent Leaky\nIntegrate-and-Fire with Latency (LIFL) spiking neuron model is event-driven\ncompatible and exhibits some realistic neuronal features, opening new horizons\nin whole-brain modelling. In this paper we present FNS, a LIFL-based exact\nevent-driven spiking neural network framework implemented in Java and oriented\nto wholebrain simulations. FNS combines spiking/synaptic whole-brain modelling\nwith the event-driven approach, allowing us to define heterogeneous modules and\nmulti-scale connectivity with delayed connections and plastic synapses,\nproviding fast simulations at the same time. A novel parallelization strategy\nis also implemented in order to further speed up simulations. This paper\npresents mathematical models, software implementation and simulation routines\non which FNS is based. Finally, a reduced brain network model (1400 neurons and\n45000 synapses) is synthesized on the basis of real brain structural data, and\nthe resulting model activity is compared with associated brain functional\n(source-space MEG) data. The conducted test shows a good matching between the\nactivity of model and that of the emulated subject, in outstanding simulation\ntimes (about 20s for simulating 4s of activity with a normal PC). Dedicated\nsections of stimuli editing and output synthesis allow the neuroscientist to\nintroduce and extract brain-like signals, respectively...",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Łojasiewicz Exponent via The Valuative Hamburger-Noether Process.   Let $k$ be an algebraically closed field of any characteristic. We apply the\nHamburger-Noether process of successive quadratic transformations to show the\nequivalence of two definitions of the {\\L}ojasiewicz exponent\n$\\mathfrak{L}(\\mathfrak{a})$ of an ideal $\\mathfrak{a}\\subset k[[x,y]]$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Satellite Image-based Localization via Learned Embeddings.   We propose a vision-based method that localizes a ground vehicle using\npublicly available satellite imagery as the only prior knowledge of the\nenvironment. Our approach takes as input a sequence of ground-level images\nacquired by the vehicle as it navigates, and outputs an estimate of the\nvehicle's pose relative to a georeferenced satellite image. We overcome the\nsignificant viewpoint and appearance variations between the images through a\nneural multi-view model that learns location-discriminative embeddings in which\nground-level images are matched with their corresponding satellite view of the\nscene. We use this learned function as an observation model in a filtering\nframework to maintain a distribution over the vehicle's pose. We evaluate our\nmethod on different benchmark datasets and demonstrate its ability localize\nground-level images in environments novel relative to training, despite the\nchallenges of significant viewpoint and appearance variations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A convex penalty for switching control of partial differential equations.   A convex penalty for promoting switching controls for partial differential\nequations is introduced; such controls consist of an arbitrary number of\ncomponents of which at most one should be simultaneously active. Using a\nMoreau-Yosida approximation, a family of approximating problems is obtained\nthat is amenable to solution by a semismooth Newton method. The efficiency of\nthis approach and the structure of the obtained controls are demonstrated by\nnumerical examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting Tactical Solutions to Operational Planning Problems under Imperfect Information.   This paper offers a methodological contribution at the intersection of\nmachine learning and operations research. Namely, we propose a methodology to\nquickly predict tactical solutions to a given operational problem. In this\ncontext, the tactical solution is less detailed than the operational one but it\nhas to be computed in very short time and under imperfect information. The\nproblem is of importance in various applications where tactical and operational\nplanning problems are interrelated and information about the operational\nproblem is revealed over time. This is for instance the case in certain\ncapacity planning and demand management systems.\nWe formulate the problem as a two-stage optimal prediction stochastic program\nwhose solution we predict with a supervised machine learning algorithm. The\ntraining data set consists of a large number of deterministic (second stage)\nproblems generated by controlled probabilistic sampling. The labels are\ncomputed based on solutions to the deterministic problems (solved independently\nand offline) employing appropriate aggregation and subselection methods to\naddress uncertainty. Results on our motivating application in load planning for\nrail transportation show that deep learning algorithms produce highly accurate\npredictions in very short computing time (milliseconds or less). The prediction\naccuracy is comparable to solutions computed by sample average approximation of\nthe stochastic program.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Synkhronos: a Multi-GPU Theano Extension for Data Parallelism.   We present Synkhronos, an extension to Theano for multi-GPU computations\nleveraging data parallelism. Our framework provides automated execution and\nsynchronization across devices, allowing users to continue to write serial\nprograms without risk of race conditions. The NVIDIA Collective Communication\nLibrary is used for high-bandwidth inter-GPU communication. Further\nenhancements to the Theano function interface include input slicing (with\naggregation) and input indexing, which perform common data-parallel computation\npatterns efficiently. One example use case is synchronous SGD, which has\nrecently been shown to scale well for a growing set of deep learning problems.\nWhen training ResNet-50, we achieve a near-linear speedup of 7.5x on an NVIDIA\nDGX-1 using 8 GPUs, relative to Theano-only code running a single GPU in\nisolation. Yet Synkhronos remains general to any data-parallel computation\nprogrammable in Theano. By implementing parallelism at the level of individual\nTheano functions, our framework uniquely addresses a niche between manual\nmulti-device programming and prescribed multi-GPU training routines.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Testing Microfluidic Fully Programmable Valve Arrays (FPVAs).   Fully Programmable Valve Array (FPVA) has emerged as a new architecture for\nthe next-generation flow-based microfluidic biochips. This 2D-array consists of\nregularly-arranged valves, which can be dynamically configured by users to\nrealize microfluidic devices of different shapes and sizes as well as\ninterconnections. Additionally, the regularity of the underlying structure\nrenders FPVAs easier to integrate on a tiny chip. However, these arrays may\nsuffer from various manufacturing defects such as blockage and leakage in\ncontrol and flow channels. Unfortunately, no efficient method is yet known for\ntesting such a general-purpose architecture. In this paper, we present a novel\nformulation using the concept of flow paths and cut-sets, and describe an\nILP-based hierarchical strategy for generating compact test sets that can\ndetect multiple faults in FPVAs. Simulation results demonstrate the efficacy of\nthe proposed method in detecting manufacturing faults with only a small number\nof test vectors.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Coastal flood implications of 1.5 °C, 2.0 °C, and 2.5 °C temperature stabilization targets in the 21st and 22nd century.   Sea-level rise (SLR) is magnifying the frequency and severity of coastal\nflooding. The rate and amount of global mean sea-level (GMSL) rise is a\nfunction of the trajectory of global mean surface temperature (GMST).\nTherefore, temperature stabilization targets (e.g., 1.5 °C and 2.0 °C\nof warming above pre-industrial levels, as from the Paris Agreement) have\nimportant implications for coastal flood risk. Here, we assess differences in\nthe return periods of coastal floods at a global network of tide gauges between\nscenarios that stabilize GMST warming at 1.5 °C, 2.0 °C, and 2.5\n°C above pre-industrial levels. We employ probabilistic, localized SLR\nprojections and long-term hourly tide gauge records to construct estimates of\nthe return levels of current and future flood heights for the 21st and 22nd\ncenturies. By 2100, under 1.5 °C, 2.0 °C, and 2.5 °C GMST\nstabilization, median GMSL is projected to rise 47 cm with a very likely range\nof 28-82 cm (90% probability), 55 cm (very likely 30-94 cm), and 58 cm (very\nlikely 36-93 cm), respectively. As an independent comparison, a semi-empirical\nsea level model calibrated to temperature and GMSL over the past two millennia\nestimates median GMSL will rise within < 13% of these projections. By 2150,\nrelative to the 2.0 °C scenario, GMST stabilization of 1.5 °C\ninundates roughly 5 million fewer inhabitants that currently occupy lands,\nincluding 40,000 fewer individuals currently residing in Small Island\nDeveloping States. Relative to a 2.0 °C scenario, the reduction in the\namplification of the frequency of the 100-yr flood arising from a 1.5 °C\nGMST stabilization is greatest in the eastern United States and in Europe, with\nflood frequency amplification being reduced by about half.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lagrangian fibers of Gelfand-Cetlin systems.   Motivated by the study of Nishinou-Nohara-Ueda on the Floer thoery of\nGelfand-Cetlin systems over complex partial flag manifolds, we provide a\ncomplete description of the topology of Gelfand-Cetlin fibers. We prove that\nall fibers are \\emph{smooth} isotropic submanifolds and give a complete\ndescription of the fiber to be Lagrangian in terms of combinatorics of\nGelfand-Cetlin polytope. Then we study (non-)displaceability of Lagrangian\nfibers. After a few combinatorial and numercal tests for the displaceability,\nusing the bulk-deformation of Floer cohomology by Schubert cycles, we prove\nthat every full flag manifold $\\mathcal{F}(n)$ ($n \\geq 3$) with a monotone\nKirillov-Kostant-Souriau symplectic form carries a continuum of\nnon-displaceable Lagrangian tori which degenerates to a non-torus fiber in the\nHausdorff limit. In particular, the Lagrangian $S^3$-fiber in $\\mathcal{F}(3)$\nis non-displaceable the question of which was raised by Nohara-Ueda who\ncomputed its Floer cohomology to be vanishing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Determining Phonon Coherence Using Photon Sideband Detection.   Generating and detection coherent high-frequency heat-carrying phonons has\nbeen a great topic of interest in recent years. While there have been\nsuccessful attempts in generating and observing coherent phonons, rigorous\ntechniques to characterize and detect these phonon coherence in a crystalline\nmaterial have been lagging compared to what has been achieved for photons. One\nmain challenge is a lack of detailed understanding of how detection signals for\nphonons can be related to coherence. The quantum theory of photoelectric\ndetection has greatly advanced the ability to characterize photon coherence in\nthe last century and a similar theory for phonon detection is necessary. Here,\nwe re-examine the optical sideband fluorescence technique that has been used\ndetect high frequency phonons in materials with optically active defects. We\napply the quantum theory of photodetection to the sideband technique and\npropose signatures in sideband photon-counting statistics and second-order\ncorrelation measurement of sideband signals that indicates the degree of phonon\ncoherence. Our theory can be implemented in recently performed experiments to\nbridge the gap of determining phonon coherence to be on par with that of\nphotons.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Antireflection Coated Semiconductor Laser Amplifier.   This paper presents a laser amplifier based on an antireflection coated laser\ndiode. This laser amplifier operates without active temperature stabilisation\nat any wavelength within its gain profile without restrictions on the injection\ncurrent. Using a active feedback from an external detector to the laser current\nthe power stabilized to better than $10^{-4}$, even after additional optical\nelements such as an optical fiber and/or a polarization cleaner. This power can\nalso be modulated and tuned arbitrarily. In the absence of the seeding light,\nthe laser amplifier does not lase, thus resulting in an extremely simple setup,\nwhich requires neither an external Fabry Perot cavity for monitoring the mode\npurity nor a temperature stabilization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Quantum Field Theory, Quantum Geometry, and Quantum Algebras.   We demonstrate how one can see quantization of geometry, and quantum\nalgebraic structure in supersymmetric gauge theory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Duluth at SemEval-2017 Task 6: Language Models in Humor Detection.   This paper describes the Duluth system that participated in SemEval-2017 Task\n6 #HashtagWars: Learning a Sense of Humor. The system participated in Subtasks\nA and B using N-gram language models, ranking highly in the task evaluation.\nThis paper discusses the results of our system in the development and\nevaluation stages and from two post-evaluation runs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust Navigation In GNSS Degraded Environment Using Graph Optimization.   Robust navigation in urban environments has received a considerable amount of\nboth academic and commercial interest over recent years. This is primarily due\nto large commercial organizations such as Google and Uber stepping into the\nautonomous navigation market. Most of this research has shied away from Global\nNavigation Satellite System (GNSS) based navigation. The aversion to utilizing\nGNSS data is due to the degraded nature of the data in urban environment (e.g.,\nmultipath, poor satellite visibility). The degradation of the GNSS data in\nurban environments makes it such that traditional (GNSS) positioning methods\n(e.g., extended Kalman filter, particle filters) perform poorly. However,\nrecent advances in robust graph theoretic based sensor fusion methods,\nprimarily applied to Simultaneous Localization and Mapping (SLAM) based robotic\napplications, can also be applied to GNSS data processing. This paper will\nutilize one such method known as the factor graph in conjunction several robust\noptimization techniques to evaluate their applicability to robust GNSS data\nprocessing. The goals of this study are two-fold. First, for GNSS applications,\nwe will experimentally evaluate the effectiveness of robust optimization\ntechniques within a graph-theoretic estimation framework. Second, by releasing\nthe software developed and data sets used for this study, we will introduce a\nnew open-source front-end to the Georgia Tech Smoothing and Mapping (GTSAM)\nlibrary for the purpose of integrating GNSS pseudorange observations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Free Cooling of a Granular Gas in Three Dimensions.   Granular gases as dilute ensembles of particles in random motion are not only\nat the basis of elementary structure-forming processes in the universe and\ninvolved in many industrial and natural phenomena, but also excellent models to\nstudy fundamental statistical dynamics. A vast number of theoretical and\nnumerical investigations have dealt with this apparently simple non-equilibrium\nsystem. The essential difference to molecular gases is the energy dissipation\nin particle collisions, a subtle distinction with immense impact on their\nglobal dynamics. Its most striking manifestation is the so-called granular\ncooling, the gradual loss of mechanical energy in absence of external\nexcitation.\nWe report an experimental study of homogeneous cooling of three-dimensional\n(3D) granular gases in microgravity. Surprisingly, the asymptotic scaling\n$E(t)\\propto t^{-2}$ obtained by Haff's minimal model [J. Fluid Mech. 134, 401\n(1983)] proves to be robust, despite the violation of several of its central\nassumptions. The shape anisotropy of the grains influences the characteristic\ntime of energy loss quantitatively, but not qualitatively. We compare kinetic\nenergies in the individual degrees of freedom, and find a slight predominance\nof the translational motions. In addition, we detect a certain preference of\nthe grains to align with their long axis in flight direction, a feature known\nfrom active matter or animal flocks, and the onset of clustering.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Deep Learning in Customer Churn Prediction: Unsupervised Feature Learning on Abstract Company Independent Feature Vectors.   As companies increase their efforts in retaining customers, being able to\npredict accurately ahead of time, whether a customer will churn in the\nforeseeable future is an extremely powerful tool for any marketing team. The\npaper describes in depth the application of Deep Learning in the problem of\nchurn prediction. Using abstract feature vectors, that can generated on any\nsubscription based company's user event logs, the paper proves that through the\nuse of the intrinsic property of Deep Neural Networks (learning secondary\nfeatures in an unsupervised manner), the complete pipeline can be applied to\nany subscription based company with extremely good churn predictive\nperformance. Furthermore the research documented in the paper was performed for\nFramed Data (a company that sells churn prediction as a service for other\ncompanies) in conjunction with the Data Science Institute at Lancaster\nUniversity, UK. This paper is the intellectual property of Framed Data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scheduling with regular performance measures and optional job rejection on a single machine.   We address single machine problems with optional jobs - rejection, studied\nrecently in Zhang et al. [21] and Cao et al. [2]. In these papers, the authors\nfocus on minimizing regular performance measures, i.e., functions that are\nnon-decreasing in the jobs completion time, subject to the constraint that the\ntotal rejection cost cannot exceed a predefined upper bound. They also prove\nthat the considered problems are ordinary NP-hard and provide\npseudo-polynomial-time Dynamic Programming (DP) solutions. In this paper, we\nfocus on three of these problems: makespan with release-dates; total completion\ntimes; and total weighted completion, and present enhanced DP solutions\ndemonstrating both theoretical and practical improvements. Moreover, we provide\nextensive numerical studies verifying their efficiency.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Measurements of Three-Level Hierarchical Structure in the Outliers in the Spectrum of Deepnet Hessians.   We consider deep classifying neural networks. We expose a structure in the\nderivative of the logits with respect to the parameters of the model, which is\nused to explain the existence of outliers in the spectrum of the Hessian.\nPrevious works decomposed the Hessian into two components, attributing the\noutliers to one of them, the so-called Covariance of gradients. We show this\nterm is not a Covariance but a second moment matrix, i.e., it is influenced by\nmeans of gradients. These means possess an additive two-way structure that is\nthe source of the outliers in the spectrum. This structure can be used to\napproximate the principal subspace of the Hessian using certain \"averaging\"\noperations, avoiding the need for high-dimensional eigenanalysis. We\ncorroborate this claim across different datasets, architectures and sample\nsizes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Choreographic and Somatic Approaches for the Development of Expressive Robotic Systems.   As robotic systems are moved out of factory work cells into human-facing\nenvironments questions of choreography become central to their design,\nplacement, and application. With a human viewer or counterpart present, a\nsystem will automatically be interpreted within context, style of movement, and\nform factor by human beings as animate elements of their environment. The\ninterpretation by this human counterpart is critical to the success of the\nsystem's integration: knobs on the system need to make sense to a human\ncounterpart; an artificial agent should have a way of notifying a human\ncounterpart of a change in system state, possibly through motion profiles; and\nthe motion of a human counterpart may have important contextual clues for task\ncompletion. Thus, professional choreographers, dance practitioners, and\nmovement analysts are critical to research in robotics. They have design\nmethods for movement that align with human audience perception, can identify\nsimplified features of movement for human-robot interaction goals, and have\ndetailed knowledge of the capacity of human movement. This article provides\napproaches employed by one research lab, specific impacts on technical and\nartistic projects within, and principles that may guide future such work. The\nbackground section reports on choreography, somatic perspectives,\nimprovisation, the Laban/Bartenieff Movement System, and robotics. From this\ncontext methods including embodied exercises, writing prompts, and community\nbuilding activities have been developed to facilitate interdisciplinary\nresearch. The results of this work is presented as an overview of a smattering\nof projects in areas like high-level motion planning, software development for\nrapid prototyping of movement, artistic output, and user studies that help\nunderstand how people interpret movement. Finally, guiding principles for other\ngroups to adopt are posited.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Illumination: Approximating Dynamic Global Illumination with Generative Adversarial Network.   We present Deep Illumination, a novel machine learning technique for\napproximating global illumination (GI) in real-time applications using a\nConditional Generative Adversarial Network. Our primary focus is on generating\nindirect illumination and soft shadows with offline rendering quality at\ninteractive rates. Inspired from recent advancement in image-to-image\ntranslation problems using deep generative convolutional networks, we introduce\na variant of this network that learns a mapping from Gbuffers (depth map,\nnormal map, and diffuse map) and direct illumination to any global illumination\nsolution. Our primary contribution is showing that a generative model can be\nused to learn a density estimation from screen space buffers to an advanced\nillumination model for a 3D environment. Once trained, our network can\napproximate global illumination for scene configurations it has never\nencountered before within the environment it was trained on. We evaluate Deep\nIllumination through a comparison with both a state of the art real-time GI\ntechnique (VXGI) and an offline rendering GI technique (path tracing). We show\nthat our method produces effective GI approximations and is also\ncomputationally cheaper than existing GI techniques. Our technique has the\npotential to replace existing precomputed and screen-space techniques for\nproducing global illumination effects in dynamic scenes with physically-based\nrendering quality.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reconstruction of a compact Riemannian manifold from the scattering data of internal sources.   Given a smooth non-trapping compact manifold with strictly con- vex boundary,\nwe consider an inverse problem of reconstructing the manifold from the\nscattering data initiated from internal sources. This data consist of the exit\ndirections of geodesics that are emaneted from interior points of the manifold.\nWe show that under certain generic assumption of the metric, one can\nreconstruct an isometric copy of the manifold from such scattering data\nmeasured on the boundary.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Impact of Antenna Height Difference on the Performance of Downlink Cellular Networks.   Capable of significantly reducing cell size and enhancing spatial reuse,\nnetwork densification is shown to be one of the most dominant approaches to\nexpand network capacity. Due to the scarcity of available spectrum resources,\nnevertheless, the over-deployment of network infrastructures, e.g., cellular\nbase stations (BSs), would strengthen the inter-cell interference as well, thus\nin turn deteriorating the system performance. On this account, we investigate\nthe performance of downlink cellular networks in terms of user coverage\nprobability (CP) and network spatial throughput (ST), aiming to shed light on\nthe limitation of network densification. Notably, it is shown that both CP and\nST would be degraded and even diminish to be zero when BS density is\nsufficiently large, provided that practical antenna height difference (AHD)\nbetween BSs and users is involved to characterize pathloss. Moreover, the\nresults also reveal that the increase of network ST is at the expense of the\ndegradation of CP. Therefore, to balance the tradeoff between user and network\nperformance, we further study the critical density, under which ST could be\nmaximized under the CP constraint. Through a special case study, it follows\nthat the critical density is inversely proportional to the square of AHD. The\nresults in this work could provide helpful guideline towards the application of\nnetwork densification in the next-generation wireless networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A comparative study of fairness-enhancing interventions in machine learning.   Computers are increasingly used to make decisions that have significant\nimpact in people's lives. Often, these predictions can affect different\npopulation subgroups disproportionately. As a result, the issue of fairness has\nreceived much recent interest, and a number of fairness-enhanced classifiers\nand predictors have appeared in the literature. This paper seeks to study the\nfollowing questions: how do these different techniques fundamentally compare to\none another, and what accounts for the differences? Specifically, we seek to\nbring attention to many under-appreciated aspects of such fairness-enhancing\ninterventions. Concretely, we present the results of an open benchmark we have\ndeveloped that lets us compare a number of different algorithms under a variety\nof fairness measures, and a large number of existing datasets. We find that\nalthough different algorithms tend to prefer specific formulations of fairness\npreservations, many of these measures strongly correlate with one another. In\naddition, we find that fairness-preserving algorithms tend to be sensitive to\nfluctuations in dataset composition (simulated in our benchmark by varying\ntraining-test splits), indicating that fairness interventions might be more\nbrittle than previously thought.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Light curves of hydrogen-poor Superluminous Supernovae from the Palomar Transient Factory.   We investigate the light-curve properties of a sample of 26 spectroscopically\nconfirmed hydrogen-poor superluminous supernovae (SLSNe-I) in the Palomar\nTransient Factory (PTF) survey. These events are brighter than SNe Ib/c and SNe\nIc-BL, on average, by about 4 and 2~mag, respectively. The peak absolute\nmagnitudes of SLSNe-I in rest-frame $g$ band span $-22\\lesssim M_g\n\\lesssim-20$~mag, and these peaks are not powered by radioactive $^{56}$Ni,\nunless strong asymmetries are at play. The rise timescales are longer for SLSNe\nthan for normal SNe Ib/c, by roughly 10 days, for events with similar decay\ntimes. Thus, SLSNe-I can be considered as a separate population based on\nphotometric properties. After peak, SLSNe-I decay with a wide range of slopes,\nwith no obvious gap between rapidly declining and slowly declining events. The\nlatter events show more irregularities (bumps) in the light curves at all\ntimes. At late times, the SLSN-I light curves slow down and cluster around the\n$^{56}$Co radioactive decay rate. Powering the late-time light curves with\nradioactive decay would require between 1 and 10${\\rm M}_\\odot$ of Ni masses.\nAlternatively, a simple magnetar model can reasonably fit the majority of\nSLSNe-I light curves, with four exceptions, and can mimic the radioactive decay\nof $^{56}$Co, up to $\\sim400$ days from explosion. The resulting spin values do\nnot correlate with the host-galaxy metallicities. Finally, the analysis of our\nsample cannot strengthen the case for using SLSNe-I for cosmology.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Instabilities of Internal Gravity Wave Beams.   Internal gravity waves play a primary role in geophysical fluids: they\ncontribute significantly to mixing in the ocean and they redistribute energy\nand momentum in the middle atmosphere. Until recently, most studies were\nfocused on plane wave solutions. However, these solutions are not a\nsatisfactory description of most geophysical manifestations of internal gravity\nwaves, and it is now recognized that internal wave beams with a confined\nprofile are ubiquitous in the geophysical context.\nWe will discuss the reason for the ubiquity of wave beams in stratified\nfluids, related to the fact that they are solutions of the nonlinear governing\nequations. We will focus more specifically on situations with a constant\nbuoyancy frequency. Moreover, in light of recent experimental and analytical\nstudies of internal gravity beams, it is timely to discuss the two main\nmechanisms of instability for those beams. i) The Triadic Resonant Instability\ngenerating two secondary wave beams. ii) The streaming instability\ncorresponding to the spontaneous generation of a mean flow.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Some remarks on Huisken's monotonicity formula for mean curvature flow.   We discuss a monotone quantity related to Huisken's monotonicity formula and\nsome technical consequences for mean curvature flow.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting Future Machine Failure from Machine State Using Logistic Regression.   Accurately predicting machine failures in advance can decrease maintenance\ncost and help allocate maintenance resources more efficiently. Logistic\nregression was applied to predict machine state 24 hours in the future given\nthe current machine state.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exponentially Slow Heating in Short and Long-range Interacting Floquet Systems.   We analyze the dynamics of periodically-driven (Floquet) Hamiltonians with\nshort- and long-range interactions, finding clear evidence for a thermalization\ntime, $\\tau^*$, that increases exponentially with the drive frequency. We\nobserve this behavior, both in systems with short-ranged interactions, where\nour results are consistent with rigorous bounds, and in systems with long-range\ninteractions, where such bounds do not exist at present. Using a combination of\nheating and entanglement dynamics, we explicitly extract the effective energy\nscale controlling the rate of thermalization. Finally, we demonstrate that for\ntimes shorter than $\\tau^*$, the dynamics of the system is well-approximated by\nevolution under a time-independent Hamiltonian $D_{\\mathrm{eff}}$, for both\nshort- and long-range interacting systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A recommender system to restore images with impulse noise.   We build a collaborative filtering recommender system to restore images with\nimpulse noise for which the noisy pixels have been previously identified. We\ndefine this recommender system in terms of a new color image representation\nusing three matrices that depend on the noise-free pixels of the image to\nrestore, and two parameters: $k$, the number of features; and $\\lambda$, the\nregularization factor. We perform experiments on a well known image database to\ntest our algorithm and we provide image quality statistics for the results\nobtained. We discuss the roles of bias and variance in the performance of our\nalgorithm as determined by the values of $k$ and $\\lambda$, and provide\nguidance on how to choose the values of these parameters. Finally, we discuss\nthe possibility of using our collaborative filtering recommender system to\nperform image inpainting and super-resolution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Online Factorization and Partition of Complex Networks From Random Walks.   Finding the reduced-dimensional structure is critical to understanding\ncomplex networks. Existing approaches such as spectral clustering are\napplicable only when the full network is explicitly observed. In this paper, we\nfocus on the online factorization and partition of implicit large-scale\nnetworks based on observations from an associated random walk. We formulate\nthis into a nonconvex stochastic factorization problem and propose an efficient\nand scalable stochastic generalized Hebbian algorithm. The algorithm is able to\nprocess dependent state-transition data dynamically generated by the underlying\nnetwork and learn a low-dimensional representation for each vertex. By applying\na diffusion approximation analysis, we show that the continuous-time limiting\nprocess of the stochastic algorithm converges globally to the \"principal\ncomponents\" of the Markov chain and achieves a nearly optimal sample\ncomplexity. Once given the learned low-dimensional representations, we further\napply clustering techniques to recover the network partition. We show that when\nthe associated Markov process is lumpable, one can recover the partition\nexactly with high probability. We apply the proposed approach to model the\ntraffic flow of Manhattan as city-wide random walks. By using our algorithm to\nanalyze the taxi trip data, we discover a latent partition of the Manhattan\ncity that closely matches the traffic dynamics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Social evolution of structural discrimination.   Structural discrimination appears to be a persistent phenomenon in social\nsystems. We here outline the hypothesis that it can result from the\nevolutionary dynamics of the social system itself. We study the evolutionary\ndynamics of agents with neutral badges in a simple social game and find that\nthe badges are readily discriminated by the system although not being tied to\nthe payoff matrix of the game. The sole property of being distinguishable leads\nto the subsequent discrimination, therefore providing a model for the emergence\nand freezing of social prejudice.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Solitary wave solutions and their interactions for fully nonlinear water waves with surface tension in the generalized Serre equations.   Some effects of surface tension on fully-nonlinear, long, surface water waves\nare studied by numerical means. The differences between various solitary waves\nand their interactions in subcritical and supercritical surface tension regimes\nare presented. Analytical expressions for new peaked travelling wave solutions\nare presented in the case of critical surface tension. The numerical\nexperiments were performed using a high-accurate finite element method based on\nsmooth cubic splines and the four-stage, classical, explicit Runge-Kutta method\nof order four.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hidden Fermi Liquidity and Topological Criticality in the Finite Temperature Kitaev Model.   The fate of exotic spin liquid states with fractionalized excitations at\nfinite temperature ($T$) is of great interest, since signatures of\nfractionalization manifest in finite-temperature ($T$) dynamics in real\nsystems, above the tiny magnetic ordering scales. Here, we study a\nJordan-Wigner fermionized Kitaev spin liquid at finite $T$ employing combined\nExact diagonalization and Monte Carlo simulation methods. We uncover $(i)$\ncheckerboard or stripy-ordered flux crystals depending on density of flux, and\n$(ii)$ establish, surprisingly, that: $(a)$ the finite-$T$ version of the $T=0$\ntransition from a gapless to gapped phases in the Kitaev model is a Mott\ntransition of the fermions, belonging to the two-dimensional Ising universality\nclass. These transitions correspond to a topological transition between a\nstring condensate and a dilute closed string state $(b)$ the Mott \"insulator\"\nphase is a precise realization of Laughlin's gossamer (here, p-wave)\nsuperconductor (g-SC), and $(c)$ the Kitaev Toric Code phase (TC) is a {\\it\nfully} Gutzwiller-projected p-wave SC. These findings establish the finite-$T$\nQSL phases in the $d = 2$ to be {\\it hidden} Fermi liquid(s) of neutral\nfermions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Accuracy of Confidence Intervals for Field Normalised Indicators.   When comparing the average citation impact of research groups, universities\nand countries, field normalisation reduces the influence of discipline and\ntime. Confidence intervals for these indicators can help with attempts to infer\nwhether differences between sets of publications are due to chance factors.\nAlthough both bootstrapping and formulae have been proposed for these, their\naccuracy is unknown. In response, this article uses simulated data to\nsystematically compare the accuracy of confidence limits in the simplest\npossible case, a single field and year. The results suggest that the MNLCS\n(Mean Normalised Log-transformed Citation Score) confidence interval formula is\nconservative for large groups but almost always safe, whereas bootstrap MNLCS\nconfidence intervals tend to be accurate but can be unsafe for smaller world or\ngroup sample sizes. In contrast, bootstrap MNCS (Mean Normalised Citation\nScore) confidence intervals can be very unsafe, although their accuracy\nincreases with sample sizes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rethinking Information Sharing for Actionable Threat Intelligence.   In the past decade, the information security and threat landscape has grown\nsignificantly making it difficult for a single defender to defend against all\nattacks at the same time. This called for introduc- ing information sharing, a\nparadigm in which threat indicators are shared in a community of trust to\nfacilitate defenses. Standards for representation, exchange, and consumption of\nindicators are pro- posed in the literature, although various issues are\nundermined. In this paper, we rethink information sharing for actionable\nintelli- gence, by highlighting various issues that deserve further explo-\nration. We argue that information sharing can benefit from well- defined use\nmodels, threat models, well-understood risk by mea- surement and robust\nscoring, well-understood and preserved pri- vacy and quality of indicators and\nrobust mechanism to avoid free riding behavior of selfish agent. We call for\nusing the differential nature of data and community structures for optimizing\nsharing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rydberg states of helium in electric and magnetic fields of arbitrary relative orientation.   A spectroscopic study of Rydberg states of helium ($n$ = 30 and 45) in\nmagnetic, electric and combined magnetic and electric fields with arbitrary\nrelative orientations of the field vectors is presented. The emphasis is on two\nspecial cases where (i) the diamagnetic term is negligible and both\nparamagnetic Zeeman and Stark effects are linear ($n$ = 30, $B \\leq$ 120 mT and\n$F$ = 0 - 78 V/cm ), and (ii) the diamagnetic term is dominant and the Stark\neffect is linear ($n$ = 45, $B$ = 277 mT and $F$ = 0 - 8 V/cm). Both cases\ncorrespond to regimes where the interactions induced by the electric and\nmagnetic fields are much weaker than the Coulomb interaction, but much stronger\nthan the spin-orbit interaction. The experimental spectra are compared to\nspectra calculated by determining the eigenvalues of the Hamiltonian matrix\ndescribing helium Rydberg states in the external fields. The spectra and the\ncalculated energy-level diagrams in external fields reveal avoided crossings\nbetween levels of different $m_l$ values and pronounced $m_l$-mixing effects at\nall angles between the electric and magnetic field vectors other than 0. These\nobservations are discussed in the context of the development of a method to\ngenerate dense samples of cold atoms and molecules in a magnetic trap following\nRydberg-Stark deceleration.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Topological and non inertial effects on the interbank light absorption.   In this work, we investigate the combined influence of the nontrivial\ntopology introduced by a disclination and non inertial effects due to rotation,\nin the energy levels and the wave functions of a noninteracting electron gas\nconfined to a two-dimensional pseudoharmonic quantum dot, under the influence\nof an external uniform magnetic field. The exact solutions for energy\neigenvalues and wave functions are computed as functions of the applied\nmagnetic field strength, the disclination topological charge, magnetic quantum\nnumber and the rotation speed of the sample. We investigate the modifications\non the light interband absorption coefficient and absorption threshold\nfrequency. We observe novel features in the system, including a range of\nmagnetic field without corresponding absorption phenomena, which is due to a\ntripartite term of the Hamiltonian, involving magnetic field, the topological\ncharge of the defect and the rotation frequency.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Persistent Monitoring of Dynamically Changing Environments Using an Unmanned Vehicle.   We consider the problem of planning a closed walk $\\mathcal W$ for a UAV to\npersistently monitor a finite number of stationary targets with equal\npriorities and dynamically changing properties. A UAV must physically visit the\ntargets in order to monitor them and collect information therein. The frequency\nof monitoring any given target is specified by a target revisit time, $i.e.$,\nthe maximum allowable time between any two successive visits to the target. The\nproblem considered in this paper is the following: Given $n$ targets and $k\n\\geq n$ allowed visits to them, find an optimal closed walk $\\mathcal W^*(k)$\nso that every target is visited at least once and the maximum revisit time over\nall the targets, $\\mathcal R(\\mathcal W(k))$, is minimized. We prove the\nfollowing: If $k \\geq n^2-n$, $\\mathcal R(\\mathcal W^*(k))$ (or simply,\n$\\mathcal R^*(k)$) takes only two values: $\\mathcal R^*(n)$ when $k$ is an\nintegral multiple of $n$, and $\\mathcal R^*(n+1)$ otherwise. This result\nsuggests significant computational savings - one only needs to determine\n$\\mathcal W^*(n)$ and $\\mathcal W^*(n+1)$ to construct an optimal solution\n$\\mathcal W^*(k)$. We provide MILP formulations for computing $\\mathcal W^*(n)$\nand $\\mathcal W^*(n+1)$. Furthermore, for {\\it any} given $k$, we prove that\n$\\mathcal R^*(k) \\geq \\mathcal R^*(k+n)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Boltzmann Exploration Done Right.   Boltzmann exploration is a classic strategy for sequential decision-making\nunder uncertainty, and is one of the most standard tools in Reinforcement\nLearning (RL). Despite its widespread use, there is virtually no theoretical\nunderstanding about the limitations or the actual benefits of this exploration\nscheme. Does it drive exploration in a meaningful way? Is it prone to\nmisidentifying the optimal actions or spending too much time exploring the\nsuboptimal ones? What is the right tuning for the learning rate? In this paper,\nwe address several of these questions in the classic setup of stochastic\nmulti-armed bandits. One of our main results is showing that the Boltzmann\nexploration strategy with any monotone learning-rate sequence will induce\nsuboptimal behavior. As a remedy, we offer a simple non-monotone schedule that\nguarantees near-optimal performance, albeit only when given prior access to key\nproblem parameters that are typically not available in practical situations\n(like the time horizon $T$ and the suboptimality gap $\\Delta$). More\nimportantly, we propose a novel variant that uses different learning rates for\ndifferent arms, and achieves a distribution-dependent regret bound of order\n$\\frac{K\\log^2 T}{\\Delta}$ and a distribution-independent bound of order\n$\\sqrt{KT}\\log K$ without requiring such prior knowledge. To demonstrate the\nflexibility of our technique, we also propose a variant that guarantees the\nsame performance bounds even if the rewards are heavy-tailed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Learning for Classification Tasks on Geospatial Vector Polygons.   In this paper, we evaluate the accuracy of deep learning approaches on\ngeospatial vector geometry classification tasks. The purpose of this evaluation\nis to investigate the ability of deep learning models to learn from geometry\ncoordinates directly. Previous machine learning research applied to geospatial\npolygon data did not use geometries directly, but derived properties thereof.\nThese are produced by way of extracting geometry properties such as Fourier\ndescriptors. Instead, our introduced deep neural net architectures are able to\nlearn on sequences of coordinates mapped directly from polygons. In three\nclassification tasks we show that the deep learning architectures are\ncompetitive with common learning algorithms that require extracted features.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fibers in the NGC1333 proto-cluster.   Are the initial conditions for clustered star formation the same as for\nnon-clustered star formation? To investigate the initial gas properties in\nyoung proto-clusters we carried out a comprehensive and high-sensitivity study\nof the internal structure, density, temperature, and kinematics of the dense\ngas content of the NGC1333 region in Perseus, one of the nearest and best\nstudied embedded clusters. The analysis of the gas velocities in the\nPosition-Position-Velocity space reveals an intricate underlying gas\norganization both in space and velocity. We identified a total of 14\nvelocity-coherent, (tran-)sonic structures within NGC1333, with similar\nphysical and kinematic properties than those quiescent, star-forming (aka\nfertile) fibers previously identified in low-mass star-forming clouds. These\nfibers are arranged in a complex spatial network, build-up the observed total\ncolumn density, and contain the dense cores and protostars in this cloud. Our\nresults demonstrate that the presence of fibers is not restricted to low-mass\nclouds but can be extended to regions of increasing mass and complexity. We\npropose that the observational dichotomy between clustered and non-clustered\nstar-forming regions might be naturally explained by the distinct spatial\ndensity of fertile fibers in these environments.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Monotonicity of non-pluripolar products and complex Monge-Ampère equations with prescribed singularity.   We establish the monotonicity property for the mass of non-pluripolar\nproducts on compact Kahler manifolds, and we initiate the study of complex\nMonge-Ampere type equations with prescribed singularity type. Using the\nvariational method of Berman-Boucksom-Guedj-Zeriahi we prove existence and\nuniqueness of solutions with small unbounded locus. We give applications to\nKahler-Einstein metrics with prescribed singularity, and we show that the\nlog-concavity property holds for non-pluripolar products with small unbounded\nlocus.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Imitating Driver Behavior with Generative Adversarial Networks.   The ability to accurately predict and simulate human driving behavior is\ncritical for the development of intelligent transportation systems. Traditional\nmodeling methods have employed simple parametric models and behavioral cloning.\nThis paper adopts a method for overcoming the problem of cascading errors\ninherent in prior approaches, resulting in realistic behavior that is robust to\ntrajectory perturbations. We extend Generative Adversarial Imitation Learning\nto the training of recurrent policies, and we demonstrate that our model\noutperforms rule-based controllers and maximum likelihood models in realistic\nhighway simulations. Our model both reproduces emergent behavior of human\ndrivers, such as lane change rate, while maintaining realistic control over\nlong time horizons.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Time-reversed magnetically controlled perturbation (TRMCP) optical focusing inside scattering media.   Manipulating and focusing light deep inside biological tissue and tissue-like\ncomplex media has been desired for long yet considered challenging. One\nfeasible strategy is through optical wavefront engineering, where the optical\nscattering-induced phase distortions are time reversed or pre-compensated so\nthat photons travel along different optical paths interfere constructively at\nthe targeted position within a scattering medium. To define the targeted\nposition, an internal guidestar is needed to guide or provide a feedback for\nwavefront engineering. It could be injected or embedded probes such as\nfluorescence or nonlinear microspheres, ultrasonic modulation, as well as\nabsorption perturbation. Here we propose to use a magnetically controlled\noptical absorbing microsphere as the internal guidestar. Using a digital\noptical phase conjugation system, we obtained sharp optical focusing within\nscattering media through time-reversing the scattered light perturbed by the\nmagnetic microshpere. Since the object is magnetically controlled, dynamic\noptical focusing is allowed with a relatively large field-of-view by scanning\nthe magnetic field externally. Moreover, the magnetic microsphere can be\npackaged with an organic membrane, using biological or chemical means to serve\nas a carrier. Therefore the technique may find particular applications for\nenhanced targeted drug delivery, and imaging and photoablation of angiogenic\nvessels in tumours.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Computability of semicomputable manifolds in computable topological spaces.   We study computable topological spaces and semicomputable and computable sets\nin these spaces. In particular, we investigate conditions under which\nsemicomputable sets are computable. We prove that a semicomputable compact\nmanifold $M$ is computable if its boundary $\\partial M$ is computable. We also\nshow how this result combined with certain construction which compactifies a\nsemicomputable set leads to the conclusion that some noncompact semicomputable\nmanifolds in computable metric spaces are computable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Twists of quantum Borel algebras.   We classify Drinfeld twists for the quantum Borel subalgebra u_q(b) in the\nFrobenius-Lusztig kernel u_q(g), where g is a simple Lie algebra over C and q\nan odd root of unity. More specifically, we show that alternating forms on the\ncharacter group of the group of grouplikes for u_q(b) generate all twists for\nu_q(b), under a certain algebraic group action. This implies a simple\nclassification of Hopf algebras whose categories of representations are tensor\nequivalent to that of u_q(b). We also show that cocycle twists for the\ncorresponding De Concini-Kac algebra are in bijection with alternating forms on\nthe aforementioned character group.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust, Deep and Inductive Anomaly Detection.   PCA is a classical statistical technique whose simplicity and maturity has\nseen it find widespread use as an anomaly detection technique. However, it is\nlimited in this regard by being sensitive to gross perturbations of the input,\nand by seeking a linear subspace that captures normal behaviour. The first\nissue has been dealt with by robust PCA, a variant of PCA that explicitly\nallows for some data points to be arbitrarily corrupted, however, this does not\nresolve the second issue, and indeed introduces the new issue that one can no\nlonger inductively find anomalies on a test set. This paper addresses both\nissues in a single model, the robust autoencoder. This method learns a\nnonlinear subspace that captures the majority of data points, while allowing\nfor some data to have arbitrary corruption. The model is simple to train and\nleverages recent advances in the optimisation of deep neural networks.\nExperiments on a range of real-world datasets highlight the model's\neffectiveness.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "High resolution structural characterisation of laser-induced defect clusters inside diamond.   Laser writing with ultrashort pulses provides a potential route for the\nmanufacture of three-dimensional wires, waveguides and defects within diamond.\nWe present a transmission electron microscopy (TEM) study of the intrinsic\nstructure of the laser modifications and reveal a complex distribution of\ndefects. Electron energy loss spectroscopy (EELS) indicates that the majority\nof the irradiated region remains as $sp^3$ bonded diamond.\nElectrically-conductive paths are attributed to the formation of multiple\nnano-scale, $sp^2$-bonded graphitic wires and a network of strain-relieving\nmicro-cracks.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Deep Active Learning for Named Entity Recognition.   Deep learning has yielded state-of-the-art performance on many natural\nlanguage processing tasks including named entity recognition (NER). However,\nthis typically requires large amounts of labeled data. In this work, we\ndemonstrate that the amount of labeled training data can be drastically reduced\nwhen deep learning is combined with active learning. While active learning is\nsample-efficient, it can be computationally expensive since it requires\niterative retraining. To speed this up, we introduce a lightweight architecture\nfor NER, viz., the CNN-CNN-LSTM model consisting of convolutional character and\nword encoders and a long short term memory (LSTM) tag decoder. The model\nachieves nearly state-of-the-art performance on standard datasets for the task\nwhile being computationally much more efficient than best performing models. We\ncarry out incremental active learning, during the training process, and are\nable to nearly match state-of-the-art performance with just 25\\% of the\noriginal training data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Expanded Local Variance Gamma model.   The paper proposes an expanded version of the Local Variance Gamma model of\nCarr and Nadtochiy by adding drift to the governing underlying process. Still\nin this new model it is possible to derive an ordinary differential equation\nfor the option price which plays a role of Dupire's equation for the standard\nlocal volatility model. It is shown how calibration of multiple smiles (the\nwhole local volatility surface) can be done in such a case. Further, assuming\nthe local variance to be a piecewise linear function of strike and piecewise\nconstant function of time this ODE is solved in closed form in terms of\nConfluent hypergeometric functions. Calibration of the model to market smiles\ndoes not require solving any optimization problem and, in contrast, can be done\nterm-by-term by solving a system of non-linear algebraic equations for each\nmaturity, which is fast.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Encoder-Decoder Models for Unsupervised Learning of Controllable Speech Synthesis.   Generating versatile and appropriate synthetic speech requires control over\nthe output expression separate from the spoken text. Important non-textual\nspeech variation is seldom annotated, in which case output control must be\nlearned in an unsupervised fashion. In this paper, we perform an in-depth study\nof methods for unsupervised learning of control in statistical speech\nsynthesis. For example, we show that popular unsupervised training heuristics\ncan be interpreted as variational inference in certain autoencoder models. We\nadditionally connect these models to VQ-VAEs, another, recently-proposed class\nof deep variational autoencoders, which we show can be derived from a very\nsimilar mathematical argument. The implications of these new probabilistic\ninterpretations are discussed. We illustrate the utility of the various\napproaches with an application to acoustic modelling for emotional speech\nsynthesis, where the unsupervised methods for learning expression control\n(without access to emotional labels) are found to give results that in many\naspects match or surpass the previous best supervised approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics.   Deep Neural Networks are increasingly being used in a variety of machine\nlearning applications applied to user data on the cloud. However, this approach\nintroduces a number of privacy and efficiency challenges, as the cloud operator\ncan perform secondary inferences on the available data. Recently, advances in\nedge processing have paved the way for more efficient, and private, data\nprocessing at the source for simple tasks and lighter models, though they\nremain a challenge for larger, and more complicated models. In this paper, we\npresent a hybrid approach for breaking down large, complex deep models for\ncooperative, privacy-preserving analytics. We do this by breaking down the\npopular deep architectures and fine-tune them in a suitable way. We then\nevaluate the privacy benefits of this approach based on the information exposed\nto the cloud service. We also assess the local inference cost of different\nlayers on a modern handset for mobile applications. Our evaluations show that\nby using certain kind of fine-tuning and embedding techniques and at a small\nprocessing cost, we can greatly reduce the level of information available to\nunintended tasks applied to the data features on the cloud, and hence achieving\nthe desired tradeoff between privacy and performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Earth-mass Planet in a 1-AU Orbit around an Ultracool Dwarf.   We combine $Spitzer$ and ground-based KMTNet microlensing observations to\nidentify and precisely measure an Earth-mass ($1.43^{+0.45}_{-0.32} M_\\oplus$)\nplanet OGLE-2016-BLG-1195Lb at $1.16^{+0.16}_{-0.13}$ AU orbiting a\n$0.078^{+0.016}_{-0.012} M_\\odot$ ultracool dwarf. This is the lowest-mass\nmicrolensing planet to date. At $3.91^{+0.42}_{-0.46}$ kpc, it is the third\nconsecutive case among the $Spitzer$ \"Galactic distribution\" planets toward the\nGalactic bulge that lies in the Galactic disk as opposed to the bulge itself,\nhinting at a skewed distribution of planets. Together with previous\nmicrolensing discoveries, the seven Earth-size planets orbiting the ultracool\ndwarf TRAPPIST-1, and the detection of disks around young brown dwarfs,\nOGLE-2016-BLG-1195Lb suggests that such planets might be common around\nultracool dwarfs. It therefore sheds light on the formation of both ultracool\ndwarfs and planetary systems at the limit of low-mass protoplanetary disks.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Centralities of Nodes and Influences of Layers in Large Multiplex Networks.   We formulate and propose an algorithm (MultiRank) for the ranking of nodes\nand layers in large multiplex networks. MultiRank takes into account the full\nmultiplex network structure of the data and exploits the dual nature of the\nnetwork in terms of nodes and layers. The proposed centrality of the layers\n(influences) and the centrality of the nodes are determined by a coupled set of\nequations. The basic idea consists in assigning more centrality to nodes that\nreceive links from highly influential layers and from already central nodes.\nThe layers are more influential if highly central nodes are active in them. The\nalgorithm applies to directed/undirected as well as to weighted/unweighted\nmultiplex networks. We discuss the application of MultiRank to three major\nexamples of multiplex network datasets: the European Air Transportation\nMultiplex Network, the Pierre Auger Multiplex Collaboration Network and the FAO\nMultiplex Trade Network.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "On certain weighted 7-colored partitions.   Inspired by Andrews' 2-colored generalized Frobenius partitions, we consider\ncertain weighted 7-colored partition functions and establish some interesting\nRamanujan-type identities and congruences. Moreover, we provide combinatorial\ninterpretations of some congruences modulo 5 and 7. Finally, we study the\nproperties of weighted 7-colored partitions weighted by the parity of certain\npartition statistics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the optimal investment-consumption and life insurance selection problem with an external stochastic factor.   In this paper, we study a stochastic optimal control problem with stochastic\nvolatility. We prove the sufficient and necessary maximum principle for the\nproposed problem. Then we apply the results to solve an investment, consumption\nand life insurance problem with stochastic volatility, that is, we consider a\nwage earner investing in one risk-free asset and one risky asset described by a\njump-diffusion process and has to decide concerning consumption and life\ninsurance purchase. We assume that the life insurance for the wage earner is\nbought from a market composed of $M>1$ life insurance companies offering\npairwise distinct life insurance contracts. The goal is to maximize the\nexpected utilities derived from the consumption, the legacy in the case of a\npremature death and the investor's terminal wealth.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Optimization Based Control Framework for Balancing and Walking: Implementation on the iCub Robot.   A whole-body torque control framework adapted for balancing and walking tasks\nis presented in this paper. In the proposed approach, centroidal momentum terms\nare excluded in favor of a hierarchy of high-priority position and orientation\ntasks and a low-priority postural task. More specifically, the controller\nstabilizes the position of the center of mass, the orientation of the pelvis\nframe, as well as the position and orientation of the feet frames. The\nlow-priority postural task provides reference positions for each joint of the\nrobot. Joint torques and contact forces to stabilize tasks are obtained through\nquadratic programming optimization. Besides the exclusion of centroidal\nmomentum terms, part of the novelty of the approach lies in the definition of\ncontrol laws in SE(3) which do not require the use of Euler parameterization.\nValidation of the framework was achieved in a scenario where the robot kept\nbalance while walking in place. Experiments have been conducted with the iCub\nrobot, in simulation and in real-world experiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Well-balanced mesh-based and meshless schemes for the shallow-water equations.   We formulate a general criterion for the exact preservation of the \"lake at\nrest\" solution in general mesh-based and meshless numerical schemes for the\nstrong form of the shallow-water equations with bottom topography. The main\nidea is a careful mimetic design for the spatial derivative operators in the\nmomentum flux equation that is paired with a compatible averaging rule for the\nwater column height arising in the bottom topography source term. We prove\nconsistency of the mimetic difference operators analytically and demonstrate\nthe well-balanced property numerically using finite difference and RBF-FD\nschemes in the one- and two-dimensional cases.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lattice thermal expansion and anisotropic displacements in urea, bromomalonic aldehyde, pentachloropyridine and naphthalene.   Anisotropic displacement parameters (ADPs) are commonly used in\ncrystallography, chemistry and related fields to describe and quantify thermal\nmotion of atoms. Within the very recent years, these ADPs have become\npredictable by lattice dynamics in combination with first-principles theory.\nHere, we study four very different molecular crystals, namely urea,\nbromomalonic aldehyde, pentachloropyridine, and naphthalene, by\nfirst-principles theory to assess the quality of ADPs calculated in the\nquasi-harmonic approximation. In addition, we predict both thermal expansion\nand thermal motion within the quasi-harmonic approximation and compare the\npredictions with experimental data. Very reliable ADPs are calculated within\nthe quasi-harmonic approximation for all four cases up to at least 200 K, and\nthey turn out to be in better agreement with experiment than the harmonic ones.\nIn one particular case, ADPs can even reliably be predicted up to room\ntemperature. Our results also hint at the importance of normal-mode\nanharmonicity in the calculation of ADPs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "From atomistic model to the Peierls-Nabarro model with $γ$-surface for dislocations.   The Peierls-Nabarro (PN) model for dislocations is a hybrid model that\nincorporates the atomistic information of the dislocation core structure into\nthe continuum theory. In this paper, we study the convergence from a full\natomistic model to the PN model with $\\gamma$-surface for the dislocation in a\nbilayer system (e.g. bilayer graphene). We prove that the displacement field of\nand the total energy of the dislocation solution of the PN model are\nasymptotically close to those of the full atomistic model. Our work can be\nconsidered as a generalization of the analysis of the convergence from\natomistic model to Cauchy-Born rule for crystals without defects in the\nliterature.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Community Detection in the Network of German Princes in 1225: a Case Study.   Many social networks exhibit some underlying community structure. In\nparticular, in the context of historical research, clustering of different\ngroups into warring or friendly factions can lead to a better understanding of\nhow conflicts may arise, and whether they could be avoided or not. In this work\nwe study the crisis that started in 1225 when the Emperor of the Holy Roman\nEmpire, Frederick II and his son Henry VII got into a conflict which almost led\nto the rupture and dissolution of the Empire. We use a spin-glass-based\ncommunity detection algorithm to see how good this method is in detecting this\nrift and compare the results with an analysis performed by one of the authors\n(Gramsch) using standard social balance theory applied to History.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bilinear approach to the supersymmetric Gardner equation.   We study a supersymmetric version of the Gardner equation (both focusing and\ndefocusing) using the superbilinear formalism. This equation is new and cannot\nbe obtained from supersymmetric modified Korteweg-de Vries equation with a\nnonzero boundary condition. We construct supersymmetric solitons and then by\npassing to the long-wave limit in the focusing case obtain rational nonsingular\nsolutions. We also discuss the supersymmetric version of the defocusing\nequation and the dynamics of its solutions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Magnetization jump in one dimensional $J-Q_{2}$ model with anisotropic exchange.   We investigate the adiabatic magnetization process of the one-dimensional\n$J-Q_{2}$ model with XXZ anisotropy $g$ in an external magnetic field $h$ by\nusing density matrix renormalization group (DMRG) method. According to the\ncharacteristic of the magnetization curves, we draw a magnetization phase\ndiagram consisting of four phases. For a fixed nonzero pair coupling $Q$, i)\nwhen $g<-1$, the ground state is always ferromagnetic in spite of $h$; ii) when\n$g>-1$ but still small, the whole magnetization curve is continuous and smooth;\niii) if further increasing $g$, there is a macroscopic magnetization jump from\npartially- to fully-polarized state; iv) for a sufficiently large $g$, the\nmagnetization jump is from non- to fully-polarized state. By examining the\nenergy per magnon and the correlation function, we find that the origin of the\nmagnetization jump is the condensation of magnons and the formation of magnetic\ndomains. We also demonstrate that while the experienced states are\nHeisenberg-like without long-range order, all the \\textit{jumped-over} states\nhave antiferromagnetic or Néel long-range orders, or their mixing.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Convergence Analysis of Gradient EM for Multi-component Gaussian Mixture.   In this paper, we study convergence properties of the gradient\nExpectation-Maximization algorithm \\cite{lange1995gradient} for Gaussian\nMixture Models for general number of clusters and mixing coefficients. We\nderive the convergence rate depending on the mixing coefficients, minimum and\nmaximum pairwise distances between the true centers and dimensionality and\nnumber of components; and obtain a near-optimal local contraction radius. While\nthere have been some recent notable works that derive local convergence rates\nfor EM in the two equal mixture symmetric GMM, in the more general case, the\nderivations need structurally different and non-trivial arguments. We use\nrecent tools from learning theory and empirical processes to achieve our\ntheoretical results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Evolution of Augmented Born--Infeld Equations.   This paper compares the results of applying a recently developed method of\nstochastic uncertainty quantification designed for fluid dynamics to the\nBorn-Infeld model of nonlinear electromagnetism. The similarities in the\nresults are striking. Namely, the introduction of Stratonovich cylindrical\nnoise into each of their Hamiltonian formulations introduces stochastic Lie\ntransport into their dynamics in the same form for both theories. Moreover, the\nresulting stochastic partial differential equations (SPDE) retain their\nunperturbed form, except for an additional term representing induced Lie\ntransport by the set of divergence-free vector fields associated with the\nspatial correlations of the cylindrical noise. The explanation for this\nremarkable similarity lies in the method of construction of the Hamiltonian for\nthe Stratonovich stochastic contribution to the motion in both cases; which is\ndone via pairing spatial correlation eigenvectors for cylindrical noise with\nthe momentum map for the deterministic motion. This momentum map is responsible\nfor the well-known analogy between hydrodynamics and electromagnetism. The\nmomentum map for the Maxwell and Born-Infeld theories of electromagnetism\ntreated here is the 1-form density known as the Poynting vector. Two Appendices\ntreat the Hamiltonian structures underlying these results.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Design and Analysis of a Secure Three Factor User Authentication Scheme Using Biometric and Smart Card.   Password security can no longer provide enough security in the area of remote\nuser authentication. Considering this security drawback, researchers are trying\nto find solution with multifactor remote user authentication system. Recently,\nthree factor remote user authentication using biometric and smart card has\ndrawn a considerable attention of the researchers. However, most of the current\nproposed schemes have security flaws. They are vulnerable to attacks like user\nimpersonation attack, server masquerading attack, password guessing attack,\ninsider attack, denial of service attack, forgery attack, etc. Also, most of\nthem are unable to provide mutual authentication, session key agreement and\npassword, or smart card recovery system. Considering these drawbacks, we\npropose a secure three factor user authentication scheme using biometric and\nsmart card. Through security analysis, we show that our proposed scheme can\novercome drawbacks of existing systems and ensure high security in remote user\nauthentication.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Search Engine Drives the Evolution of Social Networks.   The search engine is tightly coupled with social networks and is primarily\ndesigned for users to acquire interested information. Specifically, the search\nengine assists the information dissemination for social networks, i.e.,\nenabling users to access interested contents with keywords-searching and\npromoting the process of contents-transferring from the source users directly\nto potential interested users. Accompanying such processes, the social network\nevolves as new links emerge between users with common interests. However, there\nis no clear understanding of such a \"chicken-and-egg\" problem, namely, new\nlinks encourage more social interactions, and vice versa. In this paper, we aim\nto quantitatively characterize the social network evolution phenomenon driven\nby a search engine. First, we propose a search network model for social network\nevolution. Second, we adopt two performance metrics, namely, degree\ndistribution and network diameter. Theoretically, we prove that the degree\ndistribution follows an intensified power-law, and the network diameter\nshrinks. Third, we quantitatively show that the search engine accelerates the\nrumor propagation in social networks. Finally, based on four real-world data\nsets (i.e., CDBLP, Facebook, Weibo Tweets, P2P), we verify our theoretical\nfindings. Furthermore, we find that the search engine dramatically increases\nthe speed of rumor propagation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Detection of irregular QRS complexes using Hermite Transform and Support Vector Machine.   Computer based recognition and detection of abnormalities in ECG signals is\nproposed. For this purpose, the Support Vector Machines (SVM) are combined with\nthe advantages of Hermite transform representation. SVM represent a special\ntype of classification techniques commonly used in medical applications.\nAutomatic classification of ECG could make the work of cardiologic departments\nfaster and more efficient. It would also reduce the number of false diagnosis\nand, as a result, save lives. The working principle of the SVM is based on\ntranslating the data into a high dimensional feature space and separating it\nusing a linear classificator. In order to provide an optimal representation for\nSVM application, the Hermite transform domain is used. This domain is proved to\nbe suitable because of the similarity of the QRS complex with Hermite basis\nfunctions. The maximal signal information is obtained using a small set of\nfeatures that are used for detection of irregular QRS complexes. The aim of the\npaper is to show that these features can be employed for automatic ECG signal\nanalysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Application of Superhalogens in the Design of Organic Superconductors.   Bechgaard salts, (TMTSF)2X (TMTSF = tetramethyl tetraselenafulvalene and X =\ncomplex anion), form the most popular series of organic superconductors. In\nthese salts, TMTSF molecules act as super-electron donor and X as acceptor. We\ncomputationally examine the electronic structure and properties of X in\ncommonly used (TMTSF)2X (X = NO3, BF4, ClO4, PF6) superconductors and notice\nthat they belong to the class of superhalogens due to their higher vertical\ndetachment energy than halogen anions. This prompted us to choose other\nsuperhalogens such as X = BO2, BH4, B2F7, AuF6 and study their (TMTSF)2X\ncomplexes. Our findings suggest that these complexes behave more or less\nsimilar to those of established (TMTSF)2X superconductors, particularly for X =\nBO2 and B2F7. We, therefore, believe that the concept of superhalogen can be\nsuccessfully applied in the design of novel organic superconductors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Homology of the family of hyperelliptic curves.   Homology of braid groups and Artin groups can be related to the study of\nspaces of curves. We completely calculate the integral homology of the family\nof smooth curves of genus $g$ with one boundary component, that are double\ncoverings of the disk ramified over $n = 2g + 1$ points. The main part of such\nhomology is described by the homology of the braid group with coefficients in a\nsymplectic representation, namely the braid group $\\mathrm{Br}_n$ acts on the\nfirst homology group of a genus $g$ surface via Dehn twists. Our computations\nshows that such groups have only $2$-torsion. We also investigate stabilization\nproperties and provide Poincaré series, both for unstable and stable\nhomology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dual gauge field theory of quantum liquid crystals in three dimensions.   The dislocation-mediated quantum melting of solids into quantum liquid\ncrystals is extended from two to three spatial dimensions, using a\ngeneralization of boson-vortex or Abelian-Higgs duality. Dislocations are now\nBurgers-vector-valued strings that trace out worldsheets in spacetime while the\nphonons of the solid dualize into two-form (Kalb-Ramond) gauge fields. We\npropose an effective dual Higgs potential that allows for restoring\ntranslational symmetry in either one, two or three directions, leading to the\nquantum analogues of columnar, smectic or nematic liquid crystals. In these\nphases, transverse phonons turn into gapped, propagating modes while\ncompressional stress remains massless. Rotational Goldstone modes emerge\nwhenever translational symmetry is restored. We also consider electrically\ncharged matter, and find amongst others that as a hard principle only two out\nof the possible three rotational Goldstone modes are observable using\nelectromagnetic means.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the evolution of galaxy spin in a cosmological hydrodynamic simulation of galaxy clusters.   The traditional view of the morphology-spin connection is being challenged by\nrecent integral-field-unit observations, as the majority of early-type galaxies\nare found to have a rotational component that is often as large as a dispersion\ncomponent. Mergers are often suspected to be critical in galaxy spin evolution,\nyet the details of their roles are still unclear. We present the first results\non the spin evolution of galaxies in cluster environments through a\ncosmological hydrodynamic simulation. Galaxies spin down globally with cosmic\nevolution. Major (mass ratios > 1/4) and minor (1/4 $\\geq$ mass ratios > 1/50)\nmergers are important contributors to the spin down in particular in massive\ngalaxies. Minor mergers appear to have stronger cumulative effects than major\nmergers. Surprisingly, the dominant driver of galaxy spin down seems to be\nenvironmental effects rather than mergers. However, since multiple processes\nact in combination, it is difficult to separate their individual roles. We\nbriefly discuss the caveats and future studies that are called for.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "To Pool or Not To Pool? Revisiting an Old Pattern.   We revisit the well-known object-pool design pattern in Java. In the last\ndecade, the pattern has attracted a lot of criticism regarding its validity\nwhen used for light-weight objects that are only meant to hold memory rather\nthan any other resources (database connections, sockets etc.) and in fact,\ncommon opinion holds that is an anti-pattern in such cases. Nevertheless, we\nshow through several experiments in different systems that the use of this\npattern for extremely short-lived and light-weight memory objects can in fact\nsignificantly reduce the response time of high-performance multi-threaded\napplications, especially in memory-constrained environments. In certain\nmulti-threaded applications where high performance is a requirement and/or\nmemory constraints exist, we recommend therefore that the object pool pattern\nbe given consideration and tested for possible run-time as well as memory\nfootprint improvements.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Measuring Sample Quality with Kernels.   Approximate Markov chain Monte Carlo (MCMC) offers the promise of more rapid\nsampling at the cost of more biased inference. Since standard MCMC diagnostics\nfail to detect these biases, researchers have developed computable Stein\ndiscrepancy measures that provably determine the convergence of a sample to its\ntarget distribution. This approach was recently combined with the theory of\nreproducing kernels to define a closed-form kernel Stein discrepancy (KSD)\ncomputable by summing kernel evaluations across pairs of sample points. We\ndevelop a theory of weak convergence for KSDs based on Stein's method,\ndemonstrate that commonly used KSDs fail to detect non-convergence even for\nGaussian targets, and show that kernels with slowly decaying tails provably\ndetermine convergence for a large class of target distributions. The resulting\nconvergence-determining KSDs are suitable for comparing biased, exact, and\ndeterministic sample sequences and simpler to compute and parallelize than\nalternative Stein discrepancies. We use our tools to compare biased samplers,\nselect sampler hyperparameters, and improve upon existing KSD approaches to\none-sample hypothesis testing and sample quality improvement.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Verifying the Medical Specialty from User Profile of Online Community for Health-Related Advices.   The paper describes the verifying methods of medical specialty from user\nprofile of online community for health-related advices. To avoid critical\nsituations with the proliferation of unverified and inaccurate information in\nmedical online community, it is necessary to develop a comprehensive software\nsolution for verifying the user medical specialty of online community for\nhealth-related advices. The algorithm for forming the information profile of a\nmedical online community user is designed. The scheme systems of formation of\nindicators of user specialization in the profession based on a training sample\nis presented. The method of forming the user information profile of online\ncommunity for healthrelated advices by computer-linguistic analysis of the\ninformation content is suggested. The system of indicators based on a training\nsample of users in medical online communities is formed. The matrix of medical\nspecialties indicators and method of determining weight coefficients these\nindicators is investigated. The proposed method of verifying the medical\nspecialty from user profile is tested in online medical community.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Neutron Star Planets: Atmospheric processes and habitability.   Of the roughly 3000 neutron stars known, only a handful have sub-stellar\ncompanions. The most famous of these are the low-mass planets around the\nmillisecond pulsar B1257+12. New evidence indicates that observational biases\ncould still hide a wide variety of planetary systems around most neutron stars.\nWe consider the environment and physical processes relevant to neutron star\nplanets, in particular the effect of X-ray irradiation and the relativistic\npulsar wind on the planetary atmosphere. We discuss the survival time of planet\natmospheres and the planetary surface conditions around different classes of\nneutron stars, and define a neutron star habitable zone. Depending on as-yet\npoorly constrained aspects of the pulsar wind, both Super-Earths around\nB1257+12 could lie within its habitable zone.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Avalanches and Plastic Flow in Crystal Plasticity: An Overview.   Crystal plasticity is mediated through dislocations, which form knotted\nconfigurations in a complex energy landscape. Once they disentangle and move,\nthey may also be impeded by permanent obstacles with finite energy barriers or\nfrustrating long-range interactions. The outcome of such complexity is the\nemergence of dislocation avalanches as the basic mechanism of plastic flow in\nsolids at the nanoscale. While the deformation behavior of bulk materials\nappears smooth, a predictive model should clearly be based upon the character\nof these dislocation avalanches and their associated strain bursts. We provide\nhere a comprehensive overview of experimental observations, theoretical models\nand computational approaches that have been developed to unravel the multiple\naspects of dislocation avalanche physics and the phenomena leading to strain\nbursts in crystal plasticity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Fourier Disparity Layer representation for Light Fields.   In this paper, we present a new Light Field representation for efficient\nLight Field processing and rendering called Fourier Disparity Layers (FDL). The\nproposed FDL representation samples the Light Field in the depth (or\nequivalently the disparity) dimension by decomposing the scene as a discrete\nsum of layers. The layers can be constructed from various types of Light Field\ninputs including a set of sub-aperture images, a focal stack, or even a\ncombination of both. From our derivations in the Fourier domain, the layers are\nsimply obtained by a regularized least square regression performed\nindependently at each spatial frequency, which is efficiently parallelized in a\nGPU implementation. Our model is also used to derive a gradient descent based\ncalibration step that estimates the input view positions and an optimal set of\ndisparity values required for the layer construction. Once the layers are\nknown, they can be simply shifted and filtered to produce different viewpoints\nof the scene while controlling the focus and simulating a camera aperture of\narbitrary shape and size. Our implementation in the Fourier domain allows real\ntime Light Field rendering. Finally, direct applications such as view\ninterpolation or extrapolation and denoising are presented and evaluated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Twisting and Mixing.   We present a framework that connects three interesting classes of groups: the\ntwisted groups (also known as Suzuki-Ree groups), the mixed groups and the\nexotic pseudo-reductive groups.\nFor a given characteristic p, we construct categories of twisted and mixed\nschemes. Ordinary schemes are a full subcategory of the mixed schemes. Mixed\nschemes arise from a twisted scheme by base change, although not every mixed\nscheme arises this way. The group objects in these categories are called\ntwisted and mixed group schemes.\nOur main theorems state: (1) The twisted Chevalley groups ${}^2\\mathsf B_2$,\n${}^2\\mathsf G_2$ and ${}^2\\mathsf F_4$ arise as rational points of twisted\ngroup schemes. (2) The mixed groups in the sense of Tits arise as rational\npoints of mixed group schemes over mixed fields. (3) The exotic\npseudo-reductive groups of Conrad, Gabber and Prasad are Weil restrictions of\nmixed group schemes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On $C$-bases, partition pairs and filtrations for induced or restricted Specht modules.   We obtain alternative explicit Specht filtrations for the induced and the\nrestricted Specht modules in the Hecke algebra of the symmetric group (defined\nover the ring $A=\\mathbb Z[q^{1/2},q^{-1/2}]$ where $q$ is an indeterminate)\nusing $C$-bases for these modules. Moreover, we provide a link between a\ncertain $C$-basis for the induced Specht module and the notion of pairs of\npartitions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Characterizing Feshbach resonances in ultracold scattering calculations.   We describe procedures for converging on and characterizing zero-energy\nFeshbach resonances that appear in scattering lengths as a function of an\nexternal field. The elastic procedure is appropriate for purely elastic\nscattering, where the scattering length is real and displays a true pole. The\nregularized scattering length (RSL) procedure is appropriate when there is weak\nbackground inelasticity, so that the scattering length is complex and displays\nan oscillation rather than a pole, but the resonant scattering length $a_{\\rm\nres}$ is close to real. The fully complex procedure is appropriate when there\nis substantial background inelasticity and the real and complex parts of\n$a_{\\rm res}$ are required. We demonstrate these procedures for scattering of\nultracold $^{85}$Rb in various initial states. All of them can converge on and\nprovide full characterization of resonances, from initial guesses many\nthousands of widths away, using scattering calculations at only about 10 values\nof the external field.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A globally stable attractor that is locally unstable everywhere.   We construct two examples of invariant manifolds that despite being locally\nunstable at every point in the transverse direction are globally stable. Using\nnumerical simulations we show that these invariant manifolds temporarily repel\nnearby trajectories but act as global attractors. We formulate an explanation\nfor such global stability in terms of the `rate of rotation' of the stable and\nunstable eigenvectors spanning the normal subspace associated with each point\nof the invariant manifold. We discuss the role of this rate of rotation on the\ntransitions between the stable and unstable regimes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lie and Noether point Symmetries for a Class of Nonautonomous Dynamical Systems.   We prove two general theorems which determine the Lie and the Noether point\nsymmetries for the equations of motion of a dynamical system which moves in a\ngeneral Riemannian space under the action of a time dependent potential\n$W(t,x)=\\omega(t)V(x)$. We apply the theorems to the case of a time dependent\ncentral potential and the harmonic oscillator and determine all Lie and Noether\npoint symmetries. Finally we prove that these theorems also apply to the case\nof a dynamical system with linear dumping and study two examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The trouble with tensor ring decompositions.   The tensor train decomposition decomposes a tensor into a \"train\" of 3-way\ntensors that are interconnected through the summation of auxiliary indices. The\ndecomposition is stable, has a well-defined notion of rank and enables the user\nto perform various linear algebra operations on vectors and matrices of\nexponential size in a computationally efficient manner. The tensor ring\ndecomposition replaces the train by a ring through the introduction of one\nadditional auxiliary variable. This article discusses a major issue with the\ntensor ring decomposition: its inability to compute an exact minimal-rank\ndecomposition from a decomposition with sub-optimal ranks. Both the contraction\noperation and Hadamard product are motivated from applications and it is shown\nthrough simple examples how the tensor ring-rounding procedure fails to\nretrieve minimal-rank decompositions with these operations. These observations,\ntogether with the already known issue of not being able to find a best low-rank\ntensor ring approximation to a given tensor indicate that the applicability of\ntensor rings is severely limited.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a fractal cohomology: Spectra of Polya--Hilbert operators, regularized determinants and Riemann zeros.   Emil Artin defined a zeta function for algebraic curves over finite fields\nand made a conjecture about them analogous to the famous Riemann hypothesis.\nThis and other conjectures about these zeta functions would come to be called\nthe Weil conjectures, which were proved by Weil for curves and later, by\nDeligne for varieties over finite fields. Much work was done in the search for\na proof of these conjectures, including the development in algebraic geometry\nof a Weil cohomology theory for these varieties, which uses the Frobenius\noperator on a finite field. The zeta function is then expressed as a\ndeterminant, allowing the properties of the function to relate to those of the\noperator. The search for a suitable cohomology theory and associated operator\nto prove the Riemann hypothesis is still on. In this paper, we study the\nproperties of the derivative operator $D = \\frac{d}{dz}$ on a particular\nweighted Bergman space of entire functions. The operator $D$ can be naturally\nviewed as the `infinitesimal shift of the complex plane'. Furthermore, this\noperator is meant to be the replacement for the Frobenius operator in the\ngeneral case and is used to construct an operator associated to any suitable\nmeromorphic function. We then show that the meromorphic function can be\nrecovered by using a regularized determinant involving the above operator. This\nis illustrated in some important special cases: rational functions, zeta\nfunctions of curves over finite fields, the Riemann zeta function, and\nculminating in a quantized version of the Hadamard factorization theorem that\napplies to any entire function of finite order. Our construction is motivated\nin part by [23] on the infinitesimal shift of the real line, as well as by\nearlier work of Deninger [10] on cohomology in number theory and a conjectural\n`fractal cohomology theory' envisioned in [25] and [28].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Progressive Image Deraining Networks: A Better and Simpler Baseline.   Along with the deraining performance improvement of deep networks, their\nstructures and learning become more and more complicated and diverse, making it\ndifficult to analyze the contribution of various network modules when\ndeveloping new deraining networks. To handle this issue, this paper provides a\nbetter and simpler baseline deraining network by considering network\narchitecture, input and output, and loss functions. Specifically, by repeatedly\nunfolding a shallow ResNet, progressive ResNet (PRN) is proposed to take\nadvantage of recursive computation. A recurrent layer is further introduced to\nexploit the dependencies of deep features across stages, forming our\nprogressive recurrent network (PReNet). Furthermore, intra-stage recursive\ncomputation of ResNet can be adopted in PRN and PReNet to notably reduce\nnetwork parameters with graceful degradation in deraining performance. For\nnetwork input and output, we take both stage-wise result and original rainy\nimage as input to each ResNet and finally output the prediction of {residual\nimage}. As for loss functions, single MSE or negative SSIM losses are\nsufficient to train PRN and PReNet. Experiments show that PRN and PReNet\nperform favorably on both synthetic and real rainy images. Considering its\nsimplicity, efficiency and effectiveness, our models are expected to serve as a\nsuitable baseline in future deraining research. The source codes are available\nat this https URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Magnetic Field Dependence of Spin Glass Free Energy Barriers.   We measure the field dependence of spin glass free energy barriers in a thin\namorphous Ge:Mn film through the time dependence of the magnetization. After\nthe correlation length $\\xi(t, T)$ has reached the film thickness $\\mathcal\n{L}=155$~\\AA~so that the dynamics are activated, we change the initial magnetic\nfield by $\\delta H$. In agreement with the scaling behavior exhibited in a\ncompanion Letter [Janus collaboration: M. Baity-Jesi {\\it et al.}, Phys. Rev.\nLett. {\\bf 118}, 157202 (2017)], we find the activation energy is increased\nwhen $\\delta H < 0$. The change is proportional to $(\\delta H)^2$ with the\naddition of a small $(\\delta H)^4$ term. The magnitude of the change of the\nspin glass free energy barriers is in near quantitative agreement with the\nprediction of a barrier model.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Quotients of Buildings as $W$-Groupoids.   We introduce structures which model the quotients of buildings by\ntype-preserving group actions. These structures, which we call W-groupoids,\ngeneralize Bruhat decompositions, chambers systems of type M, and Tits\namalgams. We define the fundamental group of a W-groupoid, and characterize\nbuildings as connected simply connected W-groupoids. We give a brief outline of\nthe covering theory of W-groupoids, which produces buildings as the universal\ncovers of W-groupoids. The local-to-global theorem of Tits concerning spherical\n3-resides allows for the construction of W-groupoids by gluing together\nquotients of generalized polygons. In this way, W-groupoids can be used to\nconstruct exotic, hyperbolic, and wild buildings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phase unwinding, or invariant subspace decompositions of Hardy spaces.   We consider orthogonal decompositions of invariant subspaces of Hardy spaces,\nthese relate to the Blaschke based phase unwinding decompositions. We prove\nconvergence in Lp. In particular we build an explicit multiscale wavelet basis.\nWe also obtain an explicit unwindinig decomposition for the singular inner\nfunction, exp 2i\\pi/x.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The multi-resonant Lugiato-Lefever model.   We introduce a new model describing multiple resonances in Kerr optical\ncavities. It perfectly agrees quantitatively with the Ikeda map and predicts\ncomplex phenomena such as super cavity solitons and coexistence of multiple\nnonlinear states.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Chance-Constrained AC Optimal Power Flow Integrating HVDC Lines and Controllability.   The integration of large-scale renewable generation has major implications on\nthe operation of power systems, two of which we address in this paper. First,\nsystem operators have to deal with higher degrees of uncertainty. Second, with\nabundant potential of renewable generation in remote locations, they need to\nincorporate the operation of High Voltage Direct Current lines (HVDC). This\npaper introduces an optimization tool that addresses both challenges by\nincorporating; the full AC power flow equations and chance constraints to\naddress the uncertainty of renewable infeed, HVDC modeling for point-to-point\nlines, and optimizing generator and HVDC corrective control policies in\nreaction to uncertainty. The main contributions are twofold. First, we\nintroduce a HVDC line model and the corresponding HVDC participation factors in\na chance-constrained AC-OPF framework. Second, we modify an existing algorithm\nfor solving the chance-constrained AC optimal power flow to allow for\noptimization of the generation and HVDC participation factors. Using realistic\nwind forecast data, and a 10 bus system with one HVDC line and two wind farms,\nwe demonstrate the performance of our algorithm and show the benefit of\ncontrollability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Can simple transmission chains foster collective intelligence in binary-choice tasks?.   In many social systems, groups of individuals can find remarkably efficient\nsolutions to complex cognitive problems, sometimes even outperforming a single\nexpert. The success of the group, however, crucially depends on how the\njudgments of the group members are aggregated to produce the collective answer.\nA large variety of such aggregation methods have been described in the\nliterature, such as averaging the independent judgments, relying on the\nmajority or setting up a group discussion. In the present work, we introduce a\nnovel approach for aggregating judgments - the transmission chain - which has\nnot yet been consistently evaluated in the context of collective intelligence.\nIn a transmission chain, all group members have access to a unique collective\nsolution and can improve it sequentially. Over repeated improvements, the\ncollective solution that emerges reflects the judgments of every group members.\nWe address the question of whether such a transmission chain can foster\ncollective intelligence for binary-choice problems. In a series of numerical\nsimulations, we explore the impact of various factors on the performance of the\ntransmission chain, such as the group size, the model parameters, and the\nstructure of the population. The performance of this method is compared to\nthose of the majority rule and the confidence-weighted majority. Finally, we\nrely on two existing datasets of individuals performing a series of binary\ndecisions to evaluate the expected performances of the three methods\nempirically. We find that the parameter space where the transmission chain has\nthe best performance rarely appears in real datasets. We conclude that the\ntransmission chain is best suited for other types of problems, such as those\nthat have cumulative properties.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Carleman estimates for the time-fractional advection-diffusion equations and applications.   In this article, we prove Carleman estimates for the generalized\ntime-fractional advection-diffusion equations by considering the fractional\nderivative as perturbation for the first order time-derivative. As a direct\napplication of the Carleman estimates, we show a conditional stability of a\nlateral Cauchy problem for the time-fractional advection-diffusion equation,\nand we also investigate the stability of an inverse source problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Denoising Adversarial Autoencoders.   Unsupervised learning is of growing interest because it unlocks the potential\nheld in vast amounts of unlabelled data to learn useful representations for\ninference. Autoencoders, a form of generative model, may be trained by learning\nto reconstruct unlabelled input data from a latent representation space. More\nrobust representations may be produced by an autoencoder if it learns to\nrecover clean input samples from corrupted ones. Representations may be further\nimproved by introducing regularisation during training to shape the\ndistribution of the encoded data in latent space. We suggest denoising\nadversarial autoencoders, which combine denoising and regularisation, shaping\nthe distribution of latent space using adversarial training. We introduce a\nnovel analysis that shows how denoising may be incorporated into the training\nand sampling of adversarial autoencoders. Experiments are performed to assess\nthe contributions that denoising makes to the learning of representations for\nclassification and sample synthesis. Our results suggest that autoencoders\ntrained using a denoising criterion achieve higher classification performance,\nand can synthesise samples that are more consistent with the input data than\nthose trained without a corruption process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A deep learning-based method for prostate segmentation in T2-weighted magnetic resonance imaging.   We propose a novel automatic method for accurate segmentation of the prostate\nin T2-weighted magnetic resonance imaging (MRI). Our method is based on\nconvolutional neural networks (CNNs). Because of the large variability in the\nshape, size, and appearance of the prostate and the scarcity of annotated\ntraining data, we suggest training two separate CNNs. A global CNN will\ndetermine a prostate bounding box, which is then resampled and sent to a local\nCNN for accurate delineation of the prostate boundary. This way, the local CNN\ncan effectively learn to segment the fine details that distinguish the prostate\nfrom the surrounding tissue using the small amount of available training data.\nTo fully exploit the training data, we synthesize additional data by deforming\nthe training images and segmentations using a learned shape model. We apply the\nproposed method on the PROMISE12 challenge dataset and achieve state of the art\nresults. Our proposed method generates accurate, smooth, and artifact-free\nsegmentations. On the test images, we achieve an average Dice score of 90.6\nwith a small standard deviation of 2.2, which is superior to all previous\nmethods. Our two-step segmentation approach and data augmentation strategy may\nbe highly effective in segmentation of other organs from small amounts of\nannotated medical images.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scratch iridescence: Wave-optical rendering of diffractive surface structure.   The surface of metal, glass and plastic objects is often characterized by\nmicroscopic scratches caused by manufacturing and/or wear. A closer look onto\nsuch scratches reveals iridescent colors with a complex dependency on viewing\nand lighting conditions. The physics behind this phenomenon is well understood;\nit is caused by diffraction of the incident light by surface features on the\norder of the optical wavelength. Existing analytic models are able to reproduce\nspatially unresolved microstructure such as the iridescent appearance of\ncompact disks and similar materials. Spatially resolved scratches, on the other\nhand, have proven elusive due to the highly complex wave-optical light\ntransport simulations needed to account for their appearance. In this paper, we\npropose a wave-optical shading model based on non-paraxial scalar diffraction\ntheory to render this class of effects. Our model expresses surface roughness\nas a collection of line segments. To shade a point on the surface, the\nindividual diffraction patterns for contributing scratch segments are computed\nanalytically and superimposed coherently. This provides natural transitions\nfrom localized glint-like iridescence to smooth BRDFs representing the\nsuperposition of many reflections at large viewing distances. We demonstrate\nthat our model is capable of recreating the overall appearance as well as\ncharacteristic detail effects observed on real-world examples.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "AXNet: ApproXimate computing using an end-to-end trainable neural network.   Neural network based approximate computing is a universal architecture\npromising to gain tremendous energy-efficiency for many error resilient\napplications. To guarantee the approximation quality, existing works deploy two\nneural networks (NNs), e.g., an approximator and a predictor. The approximator\nprovides the approximate results, while the predictor predicts whether the\ninput data is safe to approximate with the given quality requirement. However,\nit is non-trivial and time-consuming to make these two neural network\ncoordinate---they have different optimization objectives---by training them\nseparately. This paper proposes a novel neural network structure---AXNet---to\nfuse two NNs to a holistic end-to-end trainable NN. Leveraging the philosophy\nof multi-task learning, AXNet can tremendously improve the invocation\n(proportion of safe-to-approximate samples) and reduce the approximation error.\nThe training effort also decrease significantly. Experiment results show 50.7%\nmore invocation and substantial cuts of training time when compared to existing\nneural network based approximate computing framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parabolic subgroup orbits on finite root systems.   Oshima's Lemma describes the orbits of parabolic subgroups of irreducible\nfinite Weyl groups on crystallographic root systems. This note generalises that\nresult to all root systems of finite Coxeter groups, and provides a self\ncontained proof, independent of the representation theory of semisimple complex\nLie algebras.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometry and Arithmetic of Crystallographic Sphere Packings.   We introduce the notion of a \"crystallographic sphere packing,\" defined to be\none whose limit set is that of a geometrically finite hyperbolic reflection\ngroup in one higher dimension. We exhibit for the first time an infinite family\nof conformally-inequivalent such with all radii being reciprocals of integers.\nWe then prove a result in the opposite direction: the \"superintegral\" ones\nexist only in finitely many \"commensurability classes,\" all in dimensions below\n30.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Impact of surface functionalisation on the quantum coherence of nitrogen vacancy centres in nanodiamond.   Nanoscale quantum probes such as the nitrogen-vacancy centre in diamond have\ndemonstrated remarkable sensing capabilities over the past decade as control\nover the fabrication and manipulation of these systems has evolved. However, as\nthe size of these nanoscale quantum probes is reduced, the surface termination\nof the host material begins to play a prominent role as a source of magnetic\nand electric field noise. In this work, we show that borane-reduced nanodiamond\nsurfaces can on average double the spin relaxation time of individual\nnitrogen-vacancy centres in nanodiamonds when compared to the thermally\noxidised surfaces. Using a combination of infra-red and x-ray absorption\nspectroscopy techniques, we correlate the changes in quantum relaxation rates\nwith the conversion of sp2 carbon to C-O and C-H bonds on the diamond surface.\nThese findings implicate double-bonded carbon species as a dominant source of\nspin noise for near surface NV centres and show that through tailored\nengineering of the surface, we can improve the quantum properties and magnetic\nsensitivity of these nanoscale probes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Complex Networks: from Classical to Quantum.   Recent progress in applying complex network theory to problems faced in\nquantum information and computation has resulted in a beneficial crossover\nbetween two fields. Complex network methods have successfully been used to\ncharacterize quantum walk and transport models, entangled communication\nnetworks, graph-theoretic models of emergent space-time and in detecting\nmesoscale structure in quantum systems. Information physics is setting the\nstage for a theory of complex and networked systems with quantum\ninformation-inspired methods appearing in complex network science, including\ninformation-theoretic distance and correlation measures for network\ncharacterization. Novel quantum induced effects have been predicted in random\ngraphs---where edges represent entangled links---and quantum computer\nalgorithms have recently been proposed to offer super-polynomial enhancement\nfor several network and graph theoretic problems. Here we review the results at\nthe cutting edge, pinpointing the similarities and reconciling the differences\nfound in the series of results at the intersection of these two fields.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "CMS-HF Calorimeter Upgrade for Run II.   CMS-HF Calorimeters have been undergoing a major upgrade for the last couple\nof years to alleviate the problems encountered during Run I, especially in the\nPMT and the readout systems. In this poster, the problems caused by the old\nPMTs installed in the detectors and their solutions will be explained.\nInitially, regular PMTs with thicker windows, causing large Cherenkov\nradiation, were used. Instead of the light coming through the fibers from the\ndetector, stray muons passing through the PMT itself produce Cherenkov\nradiation in the PMT window, resulting in erroneously large signals. Usually,\nlarge signals are the result of very high-energy particles in the calorimeter\nand are tagged as important. As a result, these so-called window events\ngenerate false triggers. Four-anode PMTs with thinner windows were selected to\nreduce these window events. Additional channels also help eliminate such\nremaining events through algorithms comparing the output of different PMT\nchannels. During the EYETS 16/17 period in the LHC operations, the final\ncomponents of the modifications to the readout system, namely the two-channel\nfront-end electronics cards, are installed. Complete upgrade of the HF\nCalorimeter, including the preparations for the Run II will be discussed in\nthis poster, with possible effects on the eventual data taking.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Results on the Hilbert coefficients and reduction numbers.   Let $(R,\\frak{m})$ be a $d$-dimensional Cohen-Macaulay local ring, $I$ an\n$\\frak{m}$-primary ideal and $J$ a minimal reduction of $I$. In this paper we\nstudy the independence of reduction ideals and the behavior of the higher\nHilbert coefficients. In addition, we give some examples in this regards.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Resource Allocation for Wireless Networks: A Distributed Optimization Approach.   We consider the multi-cell joint power control and scheduling problem in\ncellular wireless networks as a weighted sum-rate maximization problem. This\nformulation is very general and applies to a wide range of applications and QoS\nrequirements. The problem is inherently hard due to objective's non-convexity\nand the knapsack-like constraints. Moreover, practical system requires a\ndistributed operation. We applied an existing algorithm proposed by Scutari et\nal. in distributed optimization literature to our problem. The algorithm\nperforms local optimization followed by consensus update repeatedly. However,\nit is not fully applicable to our problem, as it requires all decision\nvariables to be maintained at every base station (BS), which is impractical for\nlarge-scale networks; also, it relies on the Lipschitz continuity of the\nobjective function's gradient, which does not hold here. We exploited the\nnature of our objective function, and proposed a localized version of the\nalgorithm. Furthermore, we relaxed the requirements of Lipschitz continuity\nwith the proximal approximation. Convergence to local optimal solutions was\nproved under some conditions. Future work includes proving the above results\nfrom a stochastic approximation perspective, and investigating non-linear\nconsensus schemes to speed up the convergence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detecting Changes in Hidden Markov Models.   We consider the problem of sequential detection of a change in the\nstatistical behavior of a hidden Markov model. By adopting a worst-case\nanalysis with respect to the time of change and by taking into account the data\nthat can be accessed by the change-imposing mechanism we offer alternative\nformulations of the problem. For each formulation we derive the optimum\nShewhart test that maximizes the worst-case detection probability while\nguaranteeing infrequent false alarms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "More declarative tabling in Prolog using multi-prompt delimited control.   Several Prolog implementations include a facility for tabling, an alternative\nresolution strategy which uses memoisation to avoid redundant duplication of\ncomputations. Until relatively recently, tabling has required either low-level\nsupport in the underlying Prolog engine, or extensive program transormation (de\nGuzman et al., 2008). An alternative approach is to augment Prolog with low\nlevel support for continuation capturing control operators, particularly\ndelimited continuations, which have been investigated in the field of\nfunctional programming and found to be capable of supporting a wide variety of\ncomputational effects within an otherwise declarative language.\nThis technical report describes an implementation of tabling in SWI Prolog\nbased on delimited control operators for Prolog recently introduced by\nSchrijvers et al. (2013). In comparison with a previous implementation of\ntabling for SWI Prolog using delimited control (Desouter et al., 2015), this\napproach, based on the functional memoising parser combinators of Johnson\n(1995), stays closer to the declarative core of Prolog, requires less code, and\nis able to deliver solutions from systems of tabled predicates incrementally\n(as opposed to finding all solutions before delivering any to the rest of the\nprogram).\nA collection of benchmarks shows that a small number of carefully targeted\noptimisations yields performance within a factor of about 2 of the optimised\nversion of Desouter et al.'s system currently included in SWI Prolog.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Compressed Model of Residual CNDS.   Convolutional neural networks have achieved a great success in the recent\nyears. Although, the way to maximize the performance of the convolutional\nneural networks still in the beginning. Furthermore, the optimization of the\nsize and the time that need to train the convolutional neural networks is very\nfar away from reaching the researcher's ambition. In this paper, we proposed a\nnew convolutional neural network that combined several techniques to boost the\noptimization of the convolutional neural network in the aspects of speed and\nsize. As we used our previous model Residual-CNDS (ResCNDS), which solved the\nproblems of slower convergence, overfitting, and degradation, and compressed\nit. The outcome model called Residual-Squeeze-CNDS (ResSquCNDS), which we\ndemonstrated on our sold technique to add residual learning and our model of\ncompressing the convolutional neural networks. Our model of compressing adapted\nfrom the SQUEEZENET model, but our model is more generalizable, which can be\napplied almost to any neural network model, and fully integrated into the\nresidual learning, which addresses the problem of the degradation very\nsuccessfully. Our proposed model trained on very large-scale MIT\nPlaces365-Standard scene datasets, which backing our hypothesis that the new\ncompressed model inherited the best of the previous ResCNDS8 model, and almost\nget the same accuracy in the validation Top-1 and Top-5 with 87.64% smaller in\nsize and 13.33% faster in the training time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Short-wavelength out-of-band EUV emission from Sn laser-produced plasma.   We present the results of spectroscopic measurements in the extreme\nultraviolet (EUV) regime (7-17 nm) of molten tin microdroplets illuminated by a\nhigh-intensity 3-J, 60-ns Nd:YAG laser pulse. The strong 13.5 nm emission from\nthis laser-produced plasma is of relevance for next-generation nanolithography\nmachines. Here, we focus on the shorter wavelength features between 7 and 12 nm\nwhich have so far remained poorly investigated despite their diagnostic\nrelevance. Using flexible atomic code calculations and local thermodynamic\nequilibrium arguments, we show that the line features in this region of the\nspectrum can be explained by transitions from high-lying configurations within\nthe Sn$^{8+}$-Sn$^{15+}$ ions. The dominant transitions for all ions but\nSn$^{8+}$ are found to be electric-dipole transitions towards the $n$=4 ground\nstate from the core-excited configuration in which a 4$p$ electron is promoted\nto the 5$s$ sub-shell. Our results resolve some long-standing spectroscopic\nissues and provide reliable charge state identification for Sn laser-produced\nplasma, which could be employed as a useful tool for diagnostic purposes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Community structure: A comparative evaluation of community detection methods.   Discovering community structure in complex networks is a mature field since a\ntremendous number of community detection methods have been introduced in the\nliterature. Nevertheless, it is still very challenging for practioners to\ndetermine which method would be suitable to get insights into the structural\ninformation of the networks they study. Many recent efforts have been devoted\nto investigating various quality scores of the community structure, but the\nproblem of distinguishing between different types of communities is still open.\nIn this paper, we propose a comparative, extensive and empirical study to\ninvestigate what types of communities many state-of-the-art and well-known\ncommunity detection methods are producing. Specifically, we provide\ncomprehensive analyses on computation time, community size distribution, a\ncomparative evaluation of methods according to their optimisation schemes as\nwell as a comparison of their partioning strategy through validation metrics.\nWe process our analyses on a very large corpus of hundreds of networks from\nfive different network categories and propose ways to classify community\ndetection methods, helping a potential user to navigate the complex landscape\nof community detection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Finite homogeneous geometries.   This paper reproduces the text of a part of the Author's DPhil thesis. It\ngives a proof of the classification of non-trivial, finite homogeneous\ngeometries of sufficiently high dimension which does not depend on the\nclassification of the finite simple groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Semantic Evolutionary Concept Distances for Effective Information Retrieval in Query Expansion.   In this work several semantic approaches to concept-based query expansion and\nreranking schemes are studied and compared with different ontology-based\nexpansion methods in web document search and retrieval. In particular, we focus\non concept-based query expansion schemes, where, in order to effectively\nincrease the precision of web document retrieval and to decrease the users\nbrowsing time, the main goal is to quickly provide users with the most suitable\nquery expansion. Two key tasks for query expansion in web document retrieval\nare to find the expansion candidates, as the closest concepts in web document\ndomain, and to rank the expanded queries properly. The approach we propose aims\nat improving the expansion phase for better web document retrieval and\nprecision. The basic idea is to measure the distance between candidate concepts\nusing the PMING distance, a collaborative semantic proximity measure, i.e. a\nmeasure which can be computed by using statistical results from web search\nengine. Experiments show that the proposed technique can provide users with\nmore satisfying expansion results and improve the quality of web document\nretrieval.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fixed points of n-valued maps, the fixed point property and the case of surfaces -- a braid approach.   We study the fixed point theory of n-valued maps of a space X using the fixed\npoint theory of maps between X and its configuration spaces. We give some\ngeneral results to decide whether an n-valued map can be deformed to a fixed\npoint free n-valued map. In the case of surfaces, we provide an algebraic\ncriterion in terms of the braid groups of X to study this problem. If X is\neither the k-dimensional ball or an even-dimensional real or complex projective\nspace, we show that the fixed point property holds for n-valued maps for all n\n$\\ge$ 1, and we prove the same result for even-dimensional spheres for all n\n$\\ge$ 2. If X is the 2-torus, we classify the homotopy classes of 2-valued maps\nin terms of the braid groups of X. We do not currently have a complete\ncharacterisation of the homotopy classes of split 2-valued maps of the 2-torus\nthat contain a fixed point free representative, but we give an infinite family\nof such homotopy classes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Carrier loss mechanisms in textured crystalline Si-based solar cells.   A quite general device analysis method that allows the direct evaluation of\noptical and recombination losses in crystalline silicon (c-Si)-based solar\ncells has been developed. By applying this technique, the optical and physical\nlimiting factors of the state-of-the-art solar cells with ~20% efficiencies\nhave been revealed. In the established method, the carrier loss mechanisms are\ncharacterized from the external quantum efficiency (EQE) analysis with very low\ncomputational cost. In particular, the EQE analyses of textured c-Si solar\ncells are implemented by employing the experimental reflectance spectra\nobtained directly from the actual devices while using flat optical models\nwithout any fitting parameters. We find that the developed method provides\nalmost perfect fitting to EQE spectra reported for various textured c-Si solar\ncells, including c-Si heterojunction solar cells, a dopant-free c-Si solar cell\nwith a MoOx layer, and an n-type passivated emitter with rear locally diffused\n(PERL) solar cell. The modeling of the recombination loss further allows the\nextraction of the minority carrier diffusion length and surface recombination\nvelocity from the EQE analysis. Based on the EQE analysis results, the carrier\nloss mechanisms in different types of c-Si solar cells are discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Rank Two Non-Commutative Laurent Phenomenon and Pseudo-Positivity.   We study polynomial generalizations of the Kontsevich automorphisms acting on\nthe skew-field of formal rational expressions in two non-commuting variables.\nOur main result is the Laurentness and pseudo-positivity of iterations of these\nautomorphisms. The resulting expressions are described combinatorially using a\ngeneralization of the combinatorics of compatible pairs in a maximal Dyck path\ndeveloped by Lee, Li, and Zelevinsky. By specializing to quasi-commuting\nvariables we obtain pseudo-positive expressions for rank 2 quantum generalized\ncluster variables. In the case that all internal exchange coefficients are\nzero, this quantum specialization provides a combinatorial construction of\ncounting polynomials for Grassmannians of submodules in exceptional\nrepresentations of valued quivers with two vertices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Statistical inference in two-sample summary-data Mendelian randomization using robust adjusted profile score.   Mendelian randomization (MR) is a method of exploiting genetic variation to\nunbiasedly estimate a causal effect in presence of unmeasured confounding. MR\nis being widely used in epidemiology and other related areas of population\nscience. In this paper, we study statistical inference in the increasingly\npopular two-sample summary-data MR design. We show a linear model for the\nobserved associations approximately holds in a wide variety of settings when\nall the genetic variants satisfy the exclusion restriction assumption, or in\ngenetic terms, when there is no pleiotropy. In this scenario, we derive a\nmaximum profile likelihood estimator with provable consistency and asymptotic\nnormality. However, through analyzing real datasets, we find strong evidence of\nboth systematic and idiosyncratic pleiotropy in MR, echoing the omnigenic model\nof complex traits that is recently proposed in genetics. We model the\nsystematic pleiotropy by a random effects model, where no genetic variant\nsatisfies the exclusion restriction condition exactly. In this case we propose\na consistent and asymptotically normal estimator by adjusting the profile\nscore. We then tackle the idiosyncratic pleiotropy by robustifying the adjusted\nprofile score. We demonstrate the robustness and efficiency of the proposed\nmethods using several simulated and real datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On gradient regularizers for MMD GANs.   We propose a principled method for gradient-based regularization of the\ncritic of GAN-like models trained by adversarially optimizing the kernel of a\nMaximum Mean Discrepancy (MMD). We show that controlling the gradient of the\ncritic is vital to having a sensible loss function, and devise a method to\nenforce exact, analytical gradient constraints at no additional cost compared\nto existing approximate techniques based on additive regularizers. The new loss\nfunction is provably continuous, and experiments show that it stabilizes and\naccelerates training, giving image generation models that outperform\nstate-of-the art methods on $160 \\times 160$ CelebA and $64 \\times 64$\nunconditional ImageNet.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Geodesic Completeness for Riemannian Metrics on Smooth Probability Densities.   The geometric approach to optimal transport and information theory has\ntriggered the interpretation of probability densities as an\ninfinite-dimensional Riemannian manifold. The most studied Riemannian\nstructures are Otto's metric, yielding the $L^2$-Wasserstein distance of\noptimal mass transport, and the Fisher--Rao metric, predominant in the theory\nof information geometry. On the space of smooth probability densities, none of\nthese Riemannian metrics are geodesically complete---a property desirable for\nexample in imaging applications. That is, the existence interval for solutions\nto the geodesic flow equations cannot be extended to the whole real line. Here\nwe study a class of Hamilton--Jacobi-like partial differential equations\narising as geodesic flow equations for higher-order Sobolev type metrics on the\nspace of smooth probability densities. We give order conditions for global\nexistence and uniqueness, thereby providing geodesic completeness. The system\nwe study is an interesting example of a flow equation with loss of derivatives,\nwhich is well-posed in the smooth category, yet non-parabolic and fully\nnon-linear. On a more general note, the paper establishes a link between\ngeometric analysis on the space of probability densities and analysis of\nEuler-Arnold equations in topological hydrodynamics.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Network analysis of Japanese global business using quasi-exhaustive micro-data for Japanese overseas subsidiaries.   Network analysis techniques remain rarely used for understanding\ninternational management strategies. Our paper highlights their value as\nresearch tool in this field of social science using a large set of micro-data\n(20,000) to investigate the presence of networks of subsidiaries overseas. The\nresearch question is the following: to what extent did/do global Japanese\nbusiness networks mirror organizational models existing in Japan? In\nparticular, we would like to assess how much the links building such business\nnetworks are shaped by the structure of big-size industrial conglomerates of\nfirms headquartered in Japan, also described as HK. The major part of the\nacademic community in the fields of management and industrial organization\nconsiders that formal links can be identified among firms belonging to HK. Miwa\nand Ramseyer (Miwa and Ramseyer 2002; Ramseyer 2006) challenge this claim and\nargue that the evidence supporting the existence of HK is weak. So far,\nquantitative empirical investigation has been conducted exclusively using data\nfor firms incorporated in Japan. Our study tests the Miwa-Ramseyer hypothesis\n(MRH) at the global level using information on the network of Japanese\nsubsidiaries overseas. The results obtained lead us to reject the MRH for the\nglobal dataset, as well as for subsets restricted to the two main\nregions/countries of destination of Japanese foreign investment. The results\nare robust to the weighting of the links, with different specifications, and\nare observed in most industrial sectors. The global Japanese network became\nincreasingly complex during the late 20th century as a consequence of increase\nin the number of Japanese subsidiaries overseas but the key features of the\nstructure remained rather stable. We draw implications of these findings for\nacademic research in international business and for professionals involved in\ncorporate strategy.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Non-orthogonal Multiple Access for High-reliable and Low-latency V2X Communications.   In this paper, we consider a dense vehicular communication network where each\nvehicle broadcasts its safety information to its neighborhood in each\ntransmission period. Such applications require low latency and high\nreliability, and thus, we propose a non-orthogonal multiple access scheme to\nreduce the latency and to improve the packet reception probability. In the\nproposed scheme, the BS performs the semi-persistent scheduling to optimize the\ntime scheduling and allocate frequency resources in a non-orthogonal manner\nwhile the vehicles autonomously perform distributed power control. We formulate\nthe centralized scheduling and resource allocation problem as equivalent to a\nmulti-dimensional stable roommate matching problem, in which the users and\ntime/frequency resources are considered as disjoint sets of players to be\nmatched with each other. We then develop a novel rotation matching algorithm,\nwhich converges to a q-exchange stable matching after a limited number of\niterations. Simulation results show that the proposed scheme outperforms the\ntraditional orthogonal multiple access scheme in terms of the latency and\nreliability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Flexible Procedure for Mixture Proportion Estimation in Positive--Unlabeled Learning.   Positive--unlabeled (PU) learning considers two samples, a positive set P\nwith observations from only one class and an unlabeled set U with observations\nfrom two classes. The goal is to classify observations in U. Class mixture\nproportion estimation (MPE) in U is a key step in PU learning. Blanchard et al.\n[2010] showed that MPE in PU learning is a generalization of the problem of\nestimating the proportion of true null hypotheses in multiple testing problems.\nMotivated by this idea, we propose reducing the problem to one dimension via\nconstruction of a probabilistic classifier trained on the P and U data sets\nfollowed by application of a one--dimensional mixture proportion method from\nthe multiple testing literature to the observation class probabilities. The\nflexibility of this framework lies in the freedom to choose the classifier and\nthe one--dimensional MPE method. We prove consistency of two mixture proportion\nestimators using bounds from empirical process theory, develop tuning parameter\nfree implementations, and demonstrate that they have competitive performance on\nsimulated waveform data and a protein signaling problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The role of complex analysis in modeling economic growth.   Development and growth are complex and tumultuous processes. Modern economic\ngrowth theories identify some key determinants of economic growth. However, the\nrelative importance of the determinants remains unknown, and additional\nvariables may help clarify the directions and dimensions of the interactions.\nThe novel stream of literature on economic complexity goes beyond aggregate\nmeasures of productive inputs, and considers instead a more granular and\nstructural view of the productive possibilities of countries, i.e. their\ncapabilities. Different endowments of capabilities are crucial ingredients in\nexplaining differences in economic performances. In this paper we employ\neconomic fitness, a measure of productive capabilities obtained through complex\nnetwork techniques. Focusing on the combined roles of fitness and some more\ntraditional drivers of growth, we build a bridge between economic growth\ntheories and the economic complexity literature. Our findings, in agreement\nwith other recent empirical studies, show that fitness plays a crucial role in\nfostering economic growth and, when it is included in the analysis, can be\neither complementary to traditional drivers of growth or can completely\novershadow them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Kellogg property and boundary regularity for p-harmonic functions with respect to the Mazurkiewicz boundary and other compactifications.   In this paper boundary regularity for p-harmonic functions is studied with\nrespect to the Mazurkiewicz boundary and other compactifications. In\nparticular, the Kellogg property (which says that the set of irregular boundary\npoints has capacity zero) is obtained for a large class of compactifications,\nbut also two examples when it fails are given. This study is done for complete\nmetric spaces equipped with doubling measures supporting a p-Poincaré\ninequality, but the results are new also in unweighted Euclidean spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Collisions of Dark Matter Axion Stars with Astrophysical Sources.   If QCD axions form a large fraction of the total mass of dark matter, then\naxion stars could be very abundant in galaxies. As a result, collisions with\neach other, and with other astrophysical bodies, can occur. We calculate the\nrate and analyze the consequences of three classes of collisions, those\noccurring between a dilute axion star and: another dilute axion star, an\nordinary star, or a neutron star. In all cases we attempt to quantify the most\nimportant astrophysical uncertainties; we also pay particular attention to\nscenarios in which collisions lead to collapse of otherwise stable axion stars,\nand possible subsequent decay through number changing interactions. Collisions\nbetween two axion stars can occur with a high total rate, but the low relative\nvelocity required for collapse to occur leads to a very low total rate of\ncollapses. On the other hand, collisions between an axion star and an ordinary\nstar have a large rate, $\\Gamma_\\odot \\sim 3000$ collisions/year/galaxy, and\nfor sufficiently heavy axion stars, it is plausible that most or all such\ncollisions lead to collapse. We identify in this case a parameter space which\nhas a stable region and a region in which collision triggers collapse, which\ndepend on the axion number ($N$) in the axion star, and a ratio of mass to\nradius cubed characterizing the ordinary star ($M_s/R_s^3$). Finally, we\nrevisit the calculation of collision rates between axion stars and neutron\nstars, improving on previous estimates by taking cylindrical symmetry of the\nneutron star distribution into account. Collapse and subsequent decay through\ncollision processes, if occurring with a significant rate, can affect dark\nmatter phenomenology and the axion star mass distribution.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Spectral algebra models of unstable v_n-periodic homotopy theory.   We give a survey of a generalization of Quillen-Sullivan rational homotopy\ntheory which gives spectral algebra models of unstable v_n-periodic homotopy\ntypes. In addition to describing and contextualizing our original approach, we\nsketch two other recent approaches which are of a more conceptual nature, due\nto Arone-Ching and Heuts. In the process, we also survey many relevant concepts\nwhich arise in the study of spectral algebra over operads, including\ntopological André-Quillen cohomology, Koszul duality, and Goodwillie\ncalculus.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Imaging anomalous nematic order and strain in optimally doped BaFe$_2$(As,P)$_2$.   We present the strain and temperature dependence of an anomalous nematic\nphase in optimally doped BaFe$_2$(As,P)$_2$. Polarized ultrafast optical\nmeasurements reveal broken 4-fold rotational symmetry in a temperature range\nabove $T_c$ in which bulk probes do not detect a phase transition. Using\nultrafast microscopy, we find that the magnitude and sign of this nematicity\nvary on a ${50{-}100}~\\mu$m length scale, and the temperature at which it\nonsets ranges from 40 K near a domain boundary to 60 K deep within a domain.\nScanning Laue microdiffraction maps of local strain at room temperature\nindicate that the nematic order appears most strongly in regions of weak,\nisotropic strain. These results indicate that nematic order arises in a genuine\nphase transition rather than by enhancement of local anisotropy by a strong\nnematic susceptibility. We interpret our results in the context of a proposed\nsurface nematic phase.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Tomonaga-Luttinger spin liquid in the spin-1/2 inequilateral diamond-chain compound K$_3$Cu$_3$AlO$_2$(SO$_4$)$_4$.   K$_3$Cu$_3$AlO$_2$(SO$_4$)$_4$ is a highly one-dimensional spin-1/2\ninequilateral diamond-chain antiferromagnet. Spinon continuum and spin-singlet\ndimer excitations are observed in the inelastic neutron scattering spectra,\nwhich is in excellent agreement with a theoretical prediction: a dimer-monomer\ncomposite structure, where the dimer is caused by strong antiferromagnetic\n(AFM) coupling and the monomer forms an almost isolated quantum AFM chain\ncontrolling low-energy excitations. Moreover, muon spin rotation/relaxation\nspectroscopy shows no long-range ordering down to 90~mK, which is roughly three\norders of magnitude lower than the exchange interaction of the quantum AFM\nchain. K$_3$Cu$_3$AlO$_2$(SO$_4$)$_4$ is, thus, regarded as a compound that\nexhibits a Tomonaga-Luttinger spin liquid behavior at low temperatures close to\nthe ground state.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The generalized Fermat equation with exponents 2, 3, n.   We study the Generalized Fermat Equation $x^2 + y^3 = z^p$, to be solved in\ncoprime integers, where $p \\ge 7$ is prime. Using modularity and level lowering\ntechniques, the problem can be reduced to the determination of the sets of\nrational points satisfying certain 2-adic and 3-adic conditions on a finite set\nof twists of the modular curve $X(p)$.\nWe first develop new local criteria to decide if two elliptic curves with\ncertain types of potentially good reduction at 2 and 3 can have symplectically\nor anti-symplectically isomorphic $p$-torsion modules. Using these criteria we\nproduce the minimal list of twists of $X(p)$ that have to be considered, based\non local information at 2 and 3; this list depends on $p \\bmod 24$. Using\nrecent results on mod $p$ representations with image in the normalizer of a\nsplit Cartan subgroup, the list can be further reduced in some cases.\nOur second main result is the complete solution of the equation when $p =\n11$, which previously was the smallest unresolved $p$. One relevant new\ningredient is the use of the `Selmer group Chabauty' method introduced by the\nthird author in a recent preprint, applied in an Elliptic Curve Chabauty\ncontext, to determine relevant points on $X_0(11)$ defined over certain number\nfields of degree 12. This result is conditional on GRH, which is needed to show\ncorrectness of the computation of the class groups of five specific number\nfields of degree 36.\nWe also give some partial results for the case $p = 13$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hubble PanCET: An isothermal day-side atmosphere for the bloated gas-giant HAT-P-32Ab.   We present a thermal emission spectrum of the bloated hot Jupiter HAT-P-32Ab\nfrom a single eclipse observation made in spatial scan mode with the Wide Field\nCamera 3 (WFC3) aboard the Hubble Space Telescope (HST). The spectrum covers\nthe wavelength regime from 1.123 to 1.644 microns which is binned into 14\neclipse depths measured to an averaged precision of 104 parts-per million. The\nspectrum is unaffected by a dilution from the close M-dwarf companion\nHAT-P-32B, which was fully resolved. We complemented our spectrum with\nliterature results and performed a comparative forward and retrieval analysis\nwith the 1D radiative-convective ATMO model. Assuming solar abundance of the\nplanet atmosphere, we find that the measured spectrum can best be explained by\nthe spectrum of a blackbody isothermal atmosphere with Tp = 1995 +/- 17K, but\ncan equally-well be described by a spectrum with modest thermal inversion. The\nretrieved spectrum suggests emission from VO at the WFC3 wavelengths and no\nevidence of the 1.4 micron water feature. The emission models with temperature\nprofiles decreasing with height are rejected at a high confidence. An\nisothermal or inverted spectrum can imply a clear atmosphere with an absorber,\na dusty cloud deck or a combination of both. We find that the planet can have\ncontinuum of values for the albedo and recirculation, ranging from high albedo\nand poor recirculation to low albedo and efficient recirculation. Optical\nspectroscopy of the planet's day-side or thermal emission phase curves can\npotentially resolve the current albedo with recirculation degeneracy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Evaluation of Lightweight Block Ciphers in Hardware Implementation: A Comprehensive Survey.   The conventional cryptography solutions are ill-suited to strict memory, size\nand power limitations of resource-constrained devices, so lightweight\ncryptography solutions have been specifically developed for this type of\napplications. In this domain of cryptography, the term lightweight never refers\nto inadequately low security, but rather to establishing the best balance to\nmaintain sufficient security. This paper presents the first comprehensive\nsurvey evaluation of lightweight block ciphers in terms of their speed, cost,\nperformance, and balanced efficiency in hardware implementation, and\nfacilitates the comparison of studied ciphers in these respects. The cost of\nlightweight block ciphers is evaluated with the metric of Gate Equivalent\n(Fig.1), their speed with the metric of clock-cycle-per-block (Fig.2), their\nperformance with the metric of throughput (Fig.3) and their balanced efficiency\nwith the metric of Figure of Merit (Fig.4). The results of these evaluations\nshow that SIMON, SPECK, and Piccolo are the best lightweight block ciphers in\nhardware implementation.(Abstract)",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convexification of Queueing Formulas by Mixed-Integer Second-Order Cone Programming: An Application to a Discrete Location Problem with Congestion.   Mixed-Integer Second-Order Cone Programs (MISOCPs) form a nice class of\nmixed-inter convex programs, which can be solved very efficiently due to the\nrecent advances in optimization solvers. Our paper bridges the gap between\nmodeling a class of optimization problems and using MISOCP solvers. It is shown\nhow various performance metrics of M/G/1 queues can be molded by different\nMISOCPs. To motivate our method practically, it is first applied to a\nchallenging stochastic location problem with congestion, which is broadly used\nto design socially optimal service networks. Four different MISOCPs are\ndeveloped and compared on sets of benchmark test problems. The new formulations\nefficiently solve large-size test problems, which cannot be solved by the best\nexisting method. Then, the general applicability of our method is shown for\nsimilar optimization problems that use queue-theoretic performance measures to\naddress customer satisfaction and service quality.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Large-Scale Low-Rank Matrix Learning with Nonconvex Regularizers.   Low-rank modeling has many important applications in computer vision and\nmachine learning. While the matrix rank is often approximated by the convex\nnuclear norm, the use of nonconvex low-rank regularizers has demonstrated\nbetter empirical performance. However, the resulting optimization problem is\nmuch more challenging. Recent state-of-the-art requires an expensive full SVD\nin each iteration. In this paper, we show that for many commonly-used nonconvex\nlow-rank regularizers, a cutoff can be derived to automatically threshold the\nsingular values obtained from the proximal operator. This allows such operator\nbeing efficiently approximated by power method. Based on it, we develop a\nproximal gradient algorithm (and its accelerated variant) with inexact proximal\nsplitting and prove that a convergence rate of O(1/T) where T is the number of\niterations is guaranteed. Furthermore, we show the proposed algorithm can be\nwell parallelized, which achieves nearly linear speedup w.r.t the number of\nthreads. Extensive experiments are performed on matrix completion and robust\nprincipal component analysis, which shows a significant speedup over the\nstate-of-the-art. Moreover, the matrix solution obtained is more accurate and\nhas a lower rank than that of the nuclear norm regularizer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Determining stellar parameters of asteroseismic targets: going beyond the use of scaling relations.   Asteroseismic parameters allow us to measure the basic stellar properties of\nfield giants observed far across the Galaxy. Most of such determinations are,\nup to now, based on simple scaling relations involving the large frequency\nseparation, \\Delta\\nu, and the frequency of maximum power, \\nu$_{max}$. In this\nwork, we implement \\Delta\\nu\\ and the period spacing, {\\Delta}P, computed along\ndetailed grids of stellar evolutionary tracks, into stellar isochrones and\nhence in a Bayesian method of parameter estimation. Tests with synthetic data\nreveal that masses and ages can be determined with typical precision of 5 and\n19 per cent, respectively, provided precise seismic parameters are available.\nAdding independent information on the stellar luminosity, these values can\ndecrease down to 3 and 10 per cent respectively. The application of these\nmethods to NGC 6819 giants produces a mean age in agreement with those derived\nfrom isochrone fitting, and no evidence of systematic differences between RGB\nand RC stars. The age dispersion of NGC 6819 stars, however, is larger than\nexpected, with at least part of the spread ascribable to stars that underwent\nmass-transfer events.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Connectivity Learning in Multi-Branch Networks.   While much of the work in the design of convolutional networks over the last\nfive years has revolved around the empirical investigation of the importance of\ndepth, filter sizes, and number of feature channels, recent studies have shown\nthat branching, i.e., splitting the computation along parallel but distinct\nthreads and then aggregating their outputs, represents a new promising\ndimension for significant improvements in performance. To combat the complexity\nof design choices in multi-branch architectures, prior work has adopted simple\nstrategies, such as a fixed branching factor, the same input being fed to all\nparallel branches, and an additive combination of the outputs produced by all\nbranches at aggregation points.\nIn this work we remove these predefined choices and propose an algorithm to\nlearn the connections between branches in the network. Instead of being chosen\na priori by the human designer, the multi-branch connectivity is learned\nsimultaneously with the weights of the network by optimizing a single loss\nfunction defined with respect to the end task. We demonstrate our approach on\nthe problem of multi-class image classification using three different datasets\nwhere it yields consistently higher accuracy compared to the state-of-the-art\n\"ResNeXt\" multi-branch network given the same learning capacity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Thermodynamics of Higher Order Entropy Corrected Schwarzschild-Beltrami-de Sitter Black Hole.   In this paper, we consider higher order correction of the entropy and study\nthe thermodynamical properties of recently proposed Schwarzschild-Beltrami-de\nSitter black hole, which is indeed an exact solution of Einstein equation with\na positive cosmological constant. By using the corrected entropy and Hawking\ntemperature we extract some thermodynamical quantities like Gibbs and Helmholtz\nfree energies and heat capacity. We also investigate the first and second laws\nof thermodynamics. We find that presence of higher order corrections, which\ncome from thermal fluctuations, may remove some instabilities of the black\nhole. Also unstable to stable phase transition is possible in presence of the\nfirst and second order corrections.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Fracton topological phases from strongly coupled spin chains.   We provide a new perspective on fracton topological phases, a class of\nthree-dimensional topologically ordered phases with unconventional\nfractionalized excitations that are either completely immobile or only mobile\nalong particular lines or planes. We demonstrate that a wide range of these\nfracton phases can be constructed by strongly coupling mutually intersecting\nspin chains and explain via a concrete example how such a coupled-spin-chain\nconstruction illuminates the generic properties of a fracton phase. In\nparticular, we describe a systematic translation from each coupled-spin-chain\nconstruction into a parton construction where the partons correspond to the\nexcitations that are mobile along lines. Remarkably, our construction of\nfracton phases is inherently based on spin models involving only two-spin\ninteractions and thus brings us closer to their experimental realization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Sampling for Approximate Bipartite Network Projection.   Bipartite networks manifest as a stream of edges that represent transactions,\ne.g., purchases by retail customers. Many machine learning applications employ\nneighborhood-based measures to characterize the similarity among the nodes,\nsuch as the pairwise number of common neighbors (CN) and related metrics. While\nthe number of node pairs that share neighbors is potentially enormous, only a\nrelatively small proportion of them have many common neighbors. This motivates\nfinding a weighted sampling approach to preferentially sample these node pairs.\nThis paper presents a new sampling algorithm that provides a fixed size\nunbiased estimate of the similarity matrix resulting from a bipartite graph\nstream projection. The algorithm has two components. First, it maintains a\nreservoir of sampled bipartite edges with sampling weights that favor selection\nof high similarity nodes. Second, arriving edges generate a stream of\n\\textsl{similarity updates} based on their adjacency with the current sample.\nThese updates are aggregated in a second reservoir sample-based stream\naggregator to yield the final unbiased estimate. Experiments on real world\ngraphs show that a 10% sample at each stage yields estimates of high similarity\nedges with weighted relative errors of about 1%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Joining Extractions of Regular Expressions.   Regular expressions with capture variables, also known as \"regex formulas,\"\nextract relations of spans (interval positions) from text. These relations can\nbe further manipulated via Relational Algebra as studied in the context of\ndocument spanners, Fagin et al.'s formal framework for information extraction.\nWe investigate the complexity of querying text by Conjunctive Queries (CQs) and\nUnions of CQs (UCQs) on top of regex formulas. We show that the lower bounds\n(NP-completeness and W[1]-hardness) from the relational world also hold in our\nsetting; in particular, hardness hits already single-character text! Yet, the\nupper bounds from the relational world do not carry over. Unlike the relational\nworld, acyclic CQs, and even gamma-acyclic CQs, are hard to compute. The source\nof hardness is that it may be intractable to instantiate the relation defined\nby a regex formula, simply because it has an exponential number of tuples. Yet,\nwe are able to establish general upper bounds. In particular, UCQs can be\nevaluated with polynomial delay, provided that every CQ has a bounded number of\natoms (while unions and projection can be arbitrary). Furthermore, UCQ\nevaluation is solvable with FPT (Fixed-Parameter Tractable) delay when the\nparameter is the size of the UCQ.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tuning the effective spin-orbit coupling in molecular semiconductors.   The control of spins and spin to charge conversion in organics requires\nunderstanding the molecular spin-orbit coupling (SOC), and a means to tune its\nstrength. However, quantifying SOC strengths indirectly through spin relaxation\neffects has proven diffi- cult due to competing relaxation mechanisms. Here we\npresent a systematic study of the g-tensor shift in molecular semiconductors\nand link it directly to the SOC strength in a series of high mobility molecular\nsemiconductors with strong potential for future devices. The results\ndemonstrate a rich variability of the molecular g-shifts with the effective\nSOC, depending on subtle aspects of molecular composition and structure. We\ncorrelate the above g -shifts to spin-lattice relaxation times over four orders\nof magnitude, from 200 {\\mu}s to 0.15 {\\mu}s, for isolated molecules in\nsolution and relate our findings for isolated molecules in solution to the spin\nrelaxation mechanisms that are likely to be relevant in solid state systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A short note on the computation of the generalised Jacobsthal function for paired progressions.   Jacobsthal's function was recently generalised for the case of paired\nprogressions. It was proven that a specific bound of this function is\nsufficient for the truth of Goldbach's conjecture and of the prime pairs\nconjecture as well. We extended and adapted algorithms described for the\ncomputation of the common Jacobsthal function, and computed respective function\nvalues of the paired Jacobsthal function for primorial numbers for primes up to\n73. All these values fulfil the conjectured specific bound. In addition to this\nnote, we provide a detailed review of the algorithmic approaches and the\ncomplete computational results in ancillary files.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Judicious partitions of uniform hypergraphs.   The vertices of any graph with $m$ edges may be partitioned into two parts so\nthat each part meets at least $\\frac{2m}{3}$ edges. Bollobás and Thomason\nconjectured that the vertices of any $r$-uniform hypergraph with $m$ edges may\nlikewise be partitioned into $r$ classes such that each part meets at least\n$\\frac{r}{2r-1}m$ edges. In this paper we prove the weaker statement that, for\neach $r\\ge 4$, a partition into $r$ classes may be found in which each class\nmeets at least $\\frac{r}{3r-4}m$ edges, a substantial improvement on previous\nbounds.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Time-domain THz spectroscopy reveals coupled protein-hydration dielectric response in solutions of native and fibrils of human lyso-zyme.   Here we reveal details of the interaction between human lysozyme proteins,\nboth native and fibrils, and their water environment by intense terahertz time\ndomain spectroscopy. With the aid of a rigorous dielectric model, we determine\nthe amplitude and phase of the oscillating dipole induced by the THz field in\nthe volume containing the protein and its hydration water. At low\nconcentrations, the amplitude of this induced dipolar response decreases with\nincreasing concentration. Beyond a certain threshold, marking the onset of the\ninteractions between the extended hydration shells, the amplitude remains fixed\nbut the phase of the induced dipolar response, which is initially in phase with\nthe applied THz field, begins to change. The changes observed in the THz\nresponse reveal protein-protein interactions me-diated by extended hydration\nlayers, which may control fibril formation and may have an important role in\nchemical recognition phenomena.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Passive Classification of Source Printer using Text-line-level Geometric Distortion Signatures from Scanned Images of Printed Documents.   In this digital era, one thing that still holds the convention is a printed\narchive. Printed documents find their use in many critical domains such as\ncontract papers, legal tenders and proof of identity documents. As more\nadvanced printing, scanning and image editing techniques are becoming\navailable, forgeries on these legal tenders pose a serious threat. Ability to\neasily and reliably identify source printer of a printed document can help a\nlot in reducing this menace. During printing procedure, printer hardware\nintroduces certain distortions in printed characters' locations and shapes\nwhich are invisible to naked eyes. These distortions are referred as geometric\ndistortions, their profile (or signature) is generally unique for each printer\nand can be used for printer classification purpose. This paper proposes a set\nof features for characterizing text-line-level geometric distortions, referred\nas geometric distortion signatures and presents a novel system to use them for\nidentification of the origin of a printed document. Detailed experiments\nperformed on a set of thirteen printers demonstrate that the proposed system\nachieves state of the art performance and gives much higher accuracy under\nsmall training size constraint. For four training and six test pages of three\ndifferent fonts, the proposed method gives 99\\% classification accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Observability of characteristic binary-induced structures in circumbinary disks.   Context: A substantial fraction of protoplanetary disks forms around stellar\nbinaries. The binary system generates a time-dependent non-axisymmetric\ngravitational potential, inducing strong tidal forces on the circumbinary disk.\nThis leads to a change in basic physical properties of the circumbinary disk,\nwhich should in turn result in unique structures that are potentially\nobservable with the current generation of instruments.\nAims: The goal of this study is to identify these characteristic structures,\nto constrain the physical conditions that cause them, and to evaluate the\nfeasibility to observe them in circumbinary disks.\nMethods: To achieve this, at first two-dimensional hydrodynamic simulations\nare performed. The resulting density distributions are post-processed with a 3D\nradiative transfer code to generate re-emission and scattered light maps. Based\non these, we study the influence of various parameters, such as the mass of the\nstellar components, the mass of the disk and the binary separation on\nobservable features in circumbinary disks.\nResults: We find that the Atacama Large (sub-)Millimetre Array (ALMA) as well\nas the European Extremely Large Telescope (E-ELT) are capable of tracing\nasymmetries in the inner region of circumbinary disks which are affected most\nby the binary-disk interaction. Observations at submillimetre/millimetre\nwavelengths will allow the detection of the density waves at the inner rim of\nthe disk and the inner cavity. With the E-ELT one can partially resolve the\ninnermost parts of the disk in the infrared wavelength range, including the\ndisk's rim, accretion arms and potentially the expected circumstellar disks\naround each of the binary components.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Unveiling Swarm Intelligence with Network Science$-$the Metaphor Explained.   Self-organization is a natural phenomenon that emerges in systems with a\nlarge number of interacting components. Self-organized systems show robustness,\nscalability, and flexibility, which are essential properties when handling\nreal-world problems. Swarm intelligence seeks to design nature-inspired\nalgorithms with a high degree of self-organization. Yet, we do not know why\nswarm-based algorithms work well and neither we can compare the different\napproaches in the literature. The lack of a common framework capable of\ncharacterizing these several swarm-based algorithms, transcending their\nparticularities, has led to a stream of publications inspired by different\naspects of nature without much regard as to whether they are similar to already\nexisting approaches. We address this gap by introducing a network-based\nframework$-$the interaction network$-$to examine computational swarm-based\nsystems via the optics of social dynamics. We discuss the social dimension of\nseveral swarm classes and provide a case study of the Particle Swarm\nOptimization. The interaction network enables a better understanding of the\nplethora of approaches currently available by looking at them from a general\nperspective focusing on the structure of the social interactions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning a Code: Machine Learning for Approximate Non-Linear Coded Computation.   Machine learning algorithms are typically run on large scale, distributed\ncompute infrastructure that routinely face a number of unavailabilities such as\nfailures and temporary slowdowns. Adding redundant computations using\ncoding-theoretic tools called \"codes\" is an emerging technique to alleviate the\nadverse effects of such unavailabilities. A code consists of an encoding\nfunction that proactively introduces redundant computation and a decoding\nfunction that reconstructs unavailable outputs using the available ones. Past\nwork focuses on using codes to provide resilience for linear computations and\nspecific iterative optimization algorithms. However, computations performed for\na variety of applications including inference on state-of-the-art machine\nlearning algorithms, such as neural networks, typically fall outside this\nrealm. In this paper, we propose taking a learning-based approach to designing\ncodes that can handle non-linear computations. We present carefully designed\nneural network architectures and a training methodology for learning encoding\nand decoding functions that produce approximate reconstructions of unavailable\ncomputation results. We present extensive experimental results demonstrating\nthe effectiveness of the proposed approach: we show that the our learned codes\ncan accurately reconstruct $64 - 98\\%$ of the unavailable predictions from\nneural-network based image classifiers on the MNIST, Fashion-MNIST, and\nCIFAR-10 datasets. To the best of our knowledge, this work proposes the first\nlearning-based approach for designing codes, and also presents the first\ncoding-theoretic solution that can provide resilience for any non-linear\n(differentiable) computation. Our results show that learning can be an\neffective technique for designing codes, and that learned codes are a highly\npromising approach for bringing the benefits of coding to non-linear\ncomputations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum quench dynamics.   Quench dynamics is an active area of study encompassing condensed matter\nphysics and quantum information, with applications to cold-atomic gases and\npump-probe spectroscopy of materials. Recent theoretical progress in studying\nquantum quenches is reviewed. Quenches in interacting one dimensional systems\nas well as systems in higher spatial dimensions are covered. The appearance of\nnon-trivial steady states following a quench in exactly solvable models is\ndiscussed, and the stability of these states to perturbations is described.\nProper conserving approximations needed to capture the onset of thermalization\nat long times are outlined. The appearance of universal scaling for quenches\nnear critical points, and the role of the renormalization group in capturing\nthe transient regime, are reviewed. Finally the effect of quenches near\ncritical points on the dynamics of entanglement entropy and entanglement\nstatistics is discussed. The extraction of critical exponents from the\nentanglement statistics is outlined.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Complexity of Robust Stable Marriage.   Robust Stable Marriage (RSM) is a variant of the classical Stable Marriage\nproblem, where the robustness of a given stable matching is measured by the\nnumber of modifications required for repairing it in case an unforeseen event\noccurs. We focus on the complexity of finding an (a,b)-supermatch. An\n(a,b)-supermatch is defined as a stable matching in which if any 'a'\n(non-fixed) men/women break up it is possible to find another stable matching\nby changing the partners of those 'a' men/women and also the partners of at\nmost 'b' other couples. In order to show deciding if there exists an\n(a,b)-supermatch is NP-Complete, we first introduce a SAT formulation that is\nNP-Complete by using Schaefer's Dichotomy Theorem. Then, we show the\nequivalence between the SAT formulation and finding a (1,1)-supermatch on a\nspecific family of instances.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A geometric second-order-rectifiable stratification for closed subsets of Euclidean space.   Defining the $m$-th stratum of a closed subset of an $n$ dimensional\nEuclidean space to consist of those points, where it can be touched by a ball\nfrom at least $n-m$ linearly independent directions, we establish that the\n$m$-th stratum is second-order rectifiable of dimension $m$ and a Borel set.\nThis was known for convex sets, but is new even for sets of positive reach. The\nresult is based on a new criterion for second-order rectifiability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asteroid mass estimation using Markov-chain Monte Carlo.   Estimates for asteroid masses are based on their gravitational perturbations\non the orbits of other objects such as Mars, spacecraft, or other asteroids\nand/or their satellites. In the case of asteroid-asteroid perturbations, this\nleads to an inverse problem in at least 13 dimensions where the aim is to\nderive the mass of the perturbing asteroid(s) and six orbital elements for both\nthe perturbing asteroid(s) and the test asteroid(s) based on astrometric\nobservations. We have developed and implemented three different mass estimation\nalgorithms utilizing asteroid-asteroid perturbations: the very rough 'marching'\napproximation, in which the asteroids' orbital elements are not fitted, thereby\nreducing the problem to a one-dimensional estimation of the mass, an\nimplementation of the Nelder-Mead simplex method, and most significantly, a\nMarkov-chain Monte Carlo (MCMC) approach. We describe each of these algorithms\nwith particular focus on the MCMC algorithm, and present example results using\nboth synthetic and real data. Our results agree with the published mass\nestimates, but suggest that the published uncertainties may be misleading as a\nconsequence of using linearized mass-estimation methods. Finally, we discuss\nremaining challenges with the algorithms as well as future plans.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On decision regions of narrow deep neural networks.   We show that for neural network functions that have width less or equal to\nthe input dimension all connected components of decision regions are unbounded.\nThe result holds for continuous and strictly monotonic activation functions as\nwell as for ReLU activation. This complements recent results on approximation\ncapabilities of [Hanin 2017 Approximating] and connectivity of decision regions\nof [Nguyen 2018 Neural] for such narrow neural networks. Further, we give an\nexample that negatively answers the question posed in [Nguyen 2018 Neural]\nwhether one of their main results still holds for ReLU activation. Our results\nare illustrated by means of numerical experiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantile Markov Decision Process.   In this paper, we consider the problem of optimizing the quantiles of the\ncumulative rewards of Markov Decision Processes (MDP), to which we refers as\nQuantile Markov Decision Processes (QMDP). Traditionally, the goal of a Markov\nDecision Process (MDP) is to maximize expected cumulative reward over a defined\nhorizon (possibly to be infinite). In many applications, however, a decision\nmaker may be interested in optimizing a specific quantile of the cumulative\nreward instead of its expectation. Our framework of QMDP provides analytical\nresults characterizing the optimal QMDP solution and presents the algorithm for\nsolving the QMDP. We provide analytical results characterizing the optimal QMDP\nsolution and present the algorithms for solving the QMDP. We illustrate the\nmodel with two experiments: a grid game and a HIV optimal treatment experiment.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parameter Estimation for Thurstone Choice Models.   We consider the estimation accuracy of individual strength parameters of a\nThurstone choice model when each input observation consists of a choice of one\nitem from a set of two or more items (so called top-1 lists). This model\naccommodates the well-known choice models such as the Luce choice model for\ncomparison sets of two or more items and the Bradley-Terry model for pair\ncomparisons.\nWe provide a tight characterization of the mean squared error of the maximum\nlikelihood parameter estimator. We also provide similar characterizations for\nparameter estimators defined by a rank-breaking method, which amounts to\ndeducing one or more pair comparisons from a comparison of two or more items,\nassuming independence of these pair comparisons, and maximizing a likelihood\nfunction derived under these assumptions. We also consider a related binary\nclassification problem where each individual parameter takes value from a set\nof two possible values and the goal is to correctly classify all items within a\nprescribed classification error.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fooling the classifier: Ligand antagonism and adversarial examples.   Machine learning algorithms are sensitive to so-called adversarial\nperturbations. This is reminiscent of cellular decision-making where antagonist\nligands may prevent correct signaling, like during the early immune response.\nWe draw a formal analogy between neural networks used in machine learning and\nthe general class of adaptive proofreading networks. We then apply simple\nadversarial strategies from machine learning to models of ligand\ndiscrimination. We show how kinetic proofreading leads to \"boundary tilting\"\nand identify three types of perturbation (adversarial, non adversarial and\nambiguous). We then use a gradient-descent approach to compare different\nadaptive proofreading models, and we reveal the existence of two qualitatively\ndifferent regimes characterized by the presence or absence of a critical point.\nThese regimes are reminiscent of the \"feature-to-prototype\" transition\nidentified in machine learning, corresponding to two strategies in ligand\nantagonism (broad vs. specialized). Overall, our work connects evolved cellular\ndecision-making to classification in machine learning, showing that behaviours\nclose to the decision boundary can be understood through the same mechanisms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Completion of the integrable coupling systems.   In this paper, we proposed an procedure to construct the completion of the\nintegrable system by adding a perturbation to the generalized matrix problem,\nwhich can be used to continuous integrable couplings, discrete integrable\ncouplings and super integrable couplings. As example, we construct the\ncompletion of the Kaup-Newell (KN) integrable coupling, the\nWadati-Konno-Ichikawa (WKI) integrable couplingsis, vector\nAblowitz-Kaup-Newell-Segur (vAKNS) integrable couplings, the Volterra\nintegrable couplings, Dirac type integrable couplings and NLS-mKdV type\nintegrable couplings.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Cosmological searches for a non-cold dark matter component.   We explore an extended cosmological scenario where the dark matter is an\nadmixture of cold and additional non-cold species. The mass and temperature of\nthe non-cold dark matter particles are extracted from a number of cosmological\nmeasurements. Among others, we consider tomographic weak lensing data and Milky\nWay dwarf satellite galaxy counts. We also study the potential of these\nscenarios in alleviating the existing tensions between local measurements and\nCosmic Microwave Background (CMB) estimates of the $S_8$ parameter, with\n$S_8=\\sigma_8\\sqrt{\\Omega_m}$, and of the Hubble constant $H_0$. In principle,\na sub-dominant, non-cold dark matter particle with a mass $m_X\\sim$~keV, could\nachieve the goals above. However, the preferred ranges for its temperature and\nits mass are different when extracted from weak lensing observations and from\nMilky Way dwarf satellite galaxy counts, since these two measurements require\nsuppressions of the matter power spectrum at different scales. Therefore,\nsolving simultaneously the CMB-weak lensing tensions and the small scale crisis\nin the standard cold dark matter picture via only one non-cold dark matter\ncomponent seems to be challenging.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Binets: fundamental building blocks for phylogenetic networks.   Phylogenetic networks are a generalization of evolutionary trees that are\nused by biologists to represent the evolution of organisms which have undergone\nreticulate evolution. Essentially, a phylogenetic network is a directed acyclic\ngraph having a unique root in which the leaves are labelled by a given set of\nspecies. Recently, some approaches have been developed to construct\nphylogenetic networks from collections of networks on 2- and 3-leaved networks,\nwhich are known as binets and trinets, respectively. Here we study in more\ndepth properties of collections of binets, one of the simplest possible types\nof networks into which a phylogenetic network can be decomposed. More\nspecifically, we show that if a collection of level-1 binets is compatible with\nsome binary network, then it is also compatible with a binary level-1 network.\nOur proofs are based on useful structural results concerning lowest stable\nancestors in networks. In addition, we show that, although the binets do not\ndetermine the topology of the network, they do determine the number of\nreticulations in the network, which is one of its most important parameters. We\nalso consider algorithmic questions concerning binets. We show that deciding\nwhether an arbitrary set of binets is compatible with some network is at least\nas hard as the well-known Graph Isomorphism problem. However, if we restrict to\nlevel-1 binets, it is possible to decide in polynomial time whether there\nexists a binary network that displays all the binets. We also show that to find\na network that displays a maximum number of the binets is NP-hard, but that\nthere exists a simple polynomial-time 1/3-approximation algorithm for this\nproblem. It is hoped that these results will eventually assist in the\ndevelopment of new methods for constructing phylogenetic networks from\ncollections of smaller networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bingham flow in porous media with obstacles of different size.   By using the unfolding operators for periodic homogenization, we give a\ngeneral compactness result for a class of functions defined on bounded domains\npresenting perforations of two different size. Then we apply this result to the\nhomogenization of the flow of a Bingham fluid in a porous medium with solid\nobstacles of different size. Next we give the interpretation of the limit\nproblem in term of a non linear Darcy law.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "MMD GAN: Towards Deeper Understanding of Moment Matching Network.   Generative moment matching network (GMMN) is a deep generative model that\ndiffers from Generative Adversarial Network (GAN) by replacing the\ndiscriminator in GAN with a two-sample test based on kernel maximum mean\ndiscrepancy (MMD). Although some theoretical guarantees of MMD have been\nstudied, the empirical performance of GMMN is still not as competitive as that\nof GAN on challenging and large benchmark datasets. The computational\nefficiency of GMMN is also less desirable in comparison with GAN, partially due\nto its requirement for a rather large batch size during the training. In this\npaper, we propose to improve both the model expressiveness of GMMN and its\ncomputational efficiency by introducing adversarial kernel learning techniques,\nas the replacement of a fixed Gaussian kernel in the original GMMN. The new\napproach combines the key ideas in both GMMN and GAN, hence we name it MMD GAN.\nThe new distance measure in MMD GAN is a meaningful loss that enjoys the\nadvantage of weak topology and can be optimized via gradient descent with\nrelatively small batch sizes. In our evaluation on multiple benchmark datasets,\nincluding MNIST, CIFAR- 10, CelebA and LSUN, the performance of MMD-GAN\nsignificantly outperforms GMMN, and is competitive with other representative\nGAN works.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Software Reuse Approach and Its Effect On Software Quality, An Empirical Study for The Software Industry.   Software reusability has become much interesting because of increased quality\nand reduce cost. A good process of software reuse leads to enhance the\nreliability, productivity, quality and the reduction of time and cost. Current\nreuse techniques focuses on the reuse of software artifact which grounded on\nanticipated functionality whereas, the non-functional (quality) aspect are also\nimportant. So, Software reusability used here to expand quality and\nproductivity of software. It improves overall quality of software in minimum\nenergy and time. Main objective of this study was to present a reuse approach\nthat discovered that how software reuse improves the quality in Software\nIndustry. The V&V technique used for this purpose which is part of software\nquality management process, it checks the quality and correctness during the\nsoftware life cycle. A survey study conducted as QUESTIONAIR to find the impact\nof reuse approach on quality attributes which are requirement specification and\ndesign specification. Other quality enhancement techniques like ad hoc, CBSE,\nMBSE, Product line, COTS reuse checked on existing software industry. Results\nanalyzed with the help of MATLAB tool as it provides effective data management,\nwide range of options, better output organization, to check weather quality\nenhancement technique is affected due to reusability and how quality will\nimprove.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The maximal order of iterated multiplicative functions.   Following Wigert, a great number of authors including Ramanujan, Gronwall,\nErdős, Ivić, Heppner, J. Knopfmacher, Nicolas, Schwarz, Wirsing,\nFreiman, Shiu et al. determined the maximal order of several multiplicative\nfunctions, generalizing Wigert's result \\[\\max_{n\\leq x} \\log d(n)= (\\log\n2+o(1))\\frac{\\log x}{\\log \\log x}.\\]\nOn the contrary, for many multiplicative functions, the maximal order of\niterations of the functions remains wide open. The case of the iterated divisor\nfunction was only recently solved, answering a question of Ramanujan (1915).\nHere, we determine the maximal order of $\\log f(f(n))$ for a class of\nmultiplicative functions $f$ which are related to the divisor function. As a\ncorollary, we apply this to the function counting representations as sums of\ntwo squares of non-negative integers, also known as $r_2(n)/4$, and obtain an\nasymptotic formula: \\[\\max_{n\\leq x} \\log f(f(n))= (c+o(1))\\frac{\\sqrt{\\log\nx}}{\\log \\log x},\\] with some explicitly given positive constant $c$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A connection between the good property of an Artinian Gorenstein local ring and that of its quotient modulo socle.   Following Roos, we say that a local ring $R$ is good if all finitely\ngenerated $R$-modules have rational Poincaré series over $R$, sharing a\ncommon denominator. Rings with the Backelin-Roos property and generalised Golod\nrings are good due to results of Levin and Avramov respectively. Let $R$ be an\nArtinian Gorenstein local ring. The ring $R$ is shown to have the Backelin-Roos\nproperty if $R/ soc(R)$ is a Golod ring. Furthermore the ring $R$ is\ngeneralised Golod if and only if $R/ soc(R)$ is so.\nWe explore when connected sums of Artinian Gorenstein local rings are good.\nWe provide a uniform argument to show that stretched, almost stretched\nGorenstein rings are good and show further that the Auslander-Reiten conjecture\nholds true for such rings. We prove that Gorenstein rings of multiplicity at\nmost eleven are good. We recover a result of Rossi-Şega on the good\nproperty of compressed Gorenstein local rings in a stronger form by a shorter\nargument.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The duration of load effect in lumber as stochastic degradation.   This paper proposes a gamma process for modelling the damage that accumulates\nover time in the lumber used in structural engineering applications when stress\nis applied. The model separates the stochastic processes representing features\ninternal to the piece of lumber on the one hand, from those representing\nexternal forces due to applied dead and live loads. The model applies those\nexternal forces through a time-varying population level function designed for\ntime-varying loads. The application of this type of model, which is standard in\nreliability analysis, is novel in this context, which has been dominated by\naccumulated damage models (ADMs) over more than half a century. The proposed\nmodel is compared with one of the traditional ADMs. Our statistical results\nbased on a Bayesian analysis of experimental data highlight the limitations of\nusing accelerated testing data to assess long-term reliability, as seen in the\nwide posterior intervals. This suggests the need for more comprehensive testing\nin future applications, or to encode appropriate expert knowledge in the priors\nused for Bayesian analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling of hysteresis loop and its applications in ferroelectric materials.   In order to understand the physical hysteresis loops clearly, we constructed\na novel model, which is combined with the electric field, the temperature, and\nthe stress as one synthetically parameter. This model revealed the shape of\nhysteresis loop was determined by few variables in ferroelectric materials: the\nsaturation of polarization, the coercive field, the electric susceptibility and\nthe equivalent field. Comparison with experimental results revealed the model\ncan retrace polarization versus electric field and temperature. As a\napplications of this model, the calculate formula of energy storage efficiency,\nthe electrocaloric effect, and the P(E,T) function have also been included in\nthis article.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Persistence barcodes and Laplace eigenfunctions on surfaces.   We obtain restrictions on the persistence barcodes of Laplace-Beltrami\neigenfunctions and their linear combinations on compact surfaces with\nRiemannian metrics. Some applications to uniform approximation by linear\ncombinations of Laplace eigenfunctions are also discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Single-beam dielectric-microsphere trapping with optical heterodyne detection.   A technique to levitate and measure the three-dimensional position of\nmicrometer-sized dielectric spheres with heterodyne detection is presented. The\ntwo radial degrees of freedom are measured by interfering light transmitted\nthrough the microsphere with a reference wavefront, while the axial degree of\nfreedom is measured from the phase of the light reflected from the surface of\nthe microsphere. This method pairs the simplicity and accessibility of single\nbeam optical traps to a measurement of displacement that is intrinsically\ncalibrated by the wavelength of the trapping light and has exceptional immunity\nto stray light. A theoretical shot noise limit of\n$1.3\\times10^{-13}\\,\\text{m}/\\sqrt{\\text{Hz}}$ for the radial degrees of\nfreedom, and $3.0\\times10^{-15} \\, \\text{m}/\\sqrt{\\text{Hz}}$ for the axial\ndegree of freedom can be obtained in the system described. The measured\nacceleration noise in the radial direction is $7.5\\times10^{-5} \\,\n(\\text{m/s}^2)/\\sqrt{\\text{Hz}}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Memories of a Theoretical Physicist.   While I was dealing with a brain injury and finding it difficult to work, two\nfriends (Derek Westen, a friend of the KITP, and Steve Shenker, with whom I was\nrecently collaborating), suggested that a new direction might be good. Steve in\nparticular regarded me as a good writer and suggested that I try that. I\nquickly took to Steve's suggestion. Having only two bodies of knowledge, myself\nand physics, I decided to write an autobiography about my development as a\ntheoretical physicist.\nThis is not written for any particular audience, but just to give myself a\ngoal. It will probably have too much physics for a nontechnical reader, and too\nlittle for a physicist, but perhaps there with be different things for each.\nParts may be tedious. But it is somewhat unique, I think, a blow-by-blow\nhistory of where I started and where I got to.\nProbably the target audience is theoretical physicists, especially young\nones, who may enjoy comparing my struggles with their own. Some disclaimers:\nThis is based on my own memories, jogged by the arXiv and Inspire. There will\nsurely be errors and omissions. And note the title: this is about my memories,\nwhich will be different for other people. Also, it would not be possible for me\nto mention all the authors whose work might intersect mine, so this should not\nbe treated as a reference work.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Time-Spectral Method for Initial-Value Problems Using a Novel Spatial Subdomain Scheme.   We analyse a new subdomain scheme for a time-spectral method for solving\ninitial boundary value problems. Whilst spectral methods are commonplace for\nspatially dependent systems, finite difference schemes are typically applied\nfor the temporal domain. The Generalized Weighted Residual Method (GWRM) is a\nfully spectral method in that it spectrally decomposes all specified domains,\nincluding the temporal domain, with multivariate Chebyshev polynomials. The\nCommon Boundary-Condition method (CBC) is a spatial subdomain scheme that\nsolves the physical equations independently from the global connection of\nsubdomains. It is here evaluated against two finite difference methods. For the\nlinearised Burger equation the CBC-GWRM is $\\sim30\\%$ faster and $\\sim50\\%$\nmore memory efficient than the semi implicit Crank-Nicolson method at a maximum\nerror $\\sim10^{-5}$. For a forced wave equation the CBC-GWRM manages to average\nefficiently over the small time-scale in the entire temporal domain. The\nCBC-GWRM is also applied to the linearised ideal magnetohydrodynamic (MHD)\nequations for a screw pinch equilibrium. The growth rate of the most unstable\nmode was efficiently computed with an error $<0.1\\%$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ultra-Fast Relaxation, Decoherence and Localization of Photoexcited States in $π$-Conjugated Polymers: A TEBD Study.   The exciton relaxation dynamics of photoexcited electronic states in\npoly($p$-phenylenevinylene) (PPV) are theoretically investigated within a\ncoarse-grained model, in which both the exciton and nuclear degrees of freedom\nare treated quantum mechanically. The Frenkel-Holstein Hamiltonian is used to\ndescribe the strong exciton-phonon coupling present in the system, while\nexternal damping of the internal nuclear degrees of freedom are accounted for\nby a Lindblad master equation. Numerically, the dynamics are computed using the\ntime evolving block decimation (TEBD) and quantum jump trajectory techniques.\nThe values of the model parameters physically relevant to polymer systems\nnaturally lead to a separation of time scales, with the ultra-fast dynamics\ncorresponding to energy transfer from the exciton to the internal phonon modes\n(i.e., the C-C bond oscillations), while the longer time dynamics correspond to\ndamping of these phonon modes by the external dissipation. Associated with\nthese time scales, we investigate the following processes that are indicative\nof the system relaxing onto the emissive chromophores of the polymer: 1)\nExciton-polaron formation occurs on an ultra-fast time scale, with the\nassociated exciton-phonon correlations present within half a vibrational time\nperiod of the C-C bond oscillations. 2) Exciton decoherence is driven by the\ndecay in the vibrational overlaps associated with exciton-polaron formation,\noccurring on the same time scale. 3) Exciton density localization is driven by\nthe external dissipation, arising from `wavefunction collapse' occurring as a\nresult of the system-environment interactions. Finally, we show how\nfluorescence anisotropy measurements can be used to investigate the exciton\ndecoherence process during the relaxation dynamics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The ALMA View of the OMC1 Explosion in Orion.   Most massive stars form in dense clusters where gravitational interactions\nwith other stars may be common. The two nearest forming massive stars, the BN\nobject and Source I, located behind the Orion Nebula, were ejected with\nvelocities of $\\sim$29 and $\\sim$13 km s$^{-1}$ about 500 years ago by such\ninteractions. This event generated an explosion in the gas. New ALMA\nobservations show in unprecedented detail, a roughly spherically symmetric\ndistribution of over a hundred $^{12}$CO J=2$-$1 streamers with velocities\nextending from V$_{LSR}$ =$-$150 to +145 km s$^{-1}$. The streamer radial\nvelocities increase (or decrease) linearly with projected distance from the\nexplosion center, forming a `Hubble Flow' confined to within 50 arcseconds of\nthe explosion center. They point toward the high proper-motion, shock-excited\nH$_2$ and [Fe ii ] `fingertips' and lower-velocity CO in the H$_2$ wakes\ncomprising Orion's `fingers'. In some directions, the H$_2$ `fingers' extend\nmore than a factor of two farther from the ejection center than the CO\nstreamers. Such deviations from spherical symmetry may be caused by ejecta\nrunning into dense gas or the dynamics of the N-body interaction that ejected\nthe stars and produced the explosion. This $\\sim$10$^{48}$ erg event may have\nbeen powered by the release of gravitational potential energy associated with\nthe formation of a compact binary or a protostellar merger. Orion may be the\nprototype for a new class of stellar explosion responsible for luminous\ninfrared transients in nearby galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Nematic superconductivity in Cu$_{x}$Bi$_{2}$Se$_{3}$: The surface Andreev bound states.   We study theoretically the topological surface states (TSSs) and the possible\nsurface Andreev bound states (SABSs) of Cu$_{x}$Bi$_{2}$Se$_{3}$ which is known\nto be a topological insulator at $x=0$. The superconductivity (SC) pairing of\nthis compound is assumed to have the broken spin-rotation symmetry, similar to\nthat of the A-phase of $^{3}$He as suggested by recent nuclear-magnetic\nresonance experiments. For both spheroidal and corrugated cylindrical Fermi\nsurfaces with the hexagonal warping terms, we show that the bulk SC gap is\nrather anisotropic; the minimum of the gap is negligibly small as comparing to\nthe maximum of the gap. This would make the fully-gapped pairing effectively\nnodal. For a clean system, our results indicate the bulk of this compound to be\na topological superconductor with the SABSs appearing inside the bulk SC gap.\nThe zero-energy SABSs which are Majorana fermions, together with the TSSs not\ngapped by the pairing, produce a zero-energy peak in the surface density of\nstates (SDOS). The SABSs are expected to be stable against short-range\nnonmagnetic impurities, and the local SDOS is calculated around a nonmagnetic\nimpurity. The relevance of our results to experiments is discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Buy your coffee with bitcoin: Real-world deployment of a bitcoin point of sale terminal.   In this paper we discuss existing approaches for Bitcoin payments, as\nsuitable for a small business for small-value transactions. We develop an\nevaluation framework utilizing security, usability, deployability criteria,,\nexamine several existing systems, tools. Following a requirements engineering\napproach, we designed, implemented a new Point of Sale (PoS) system that\nsatisfies an optimal set of criteria within our evaluation framework. Our open\nsource system, Aunja PoS, has been deployed in a real world cafe since October\n2014.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Provability Logics of Hierarchies.   The branch of provability logic investigates the provability-based behavior\nof the mathematical theories. In a more precise way, it studies the relation\nbetween a mathematical theory $T$ and a modal logic $L$ via the provability\ninterpretation which interprets the modality as the provability predicate of\n$T$. In this paper we will extend this relation to investigate the\nprovability-based behavior of a hierarchy of theories. More precisely, using\nthe modal language with infinitely many modalities,\n$\\{\\Box_n\\}_{n=0}^{\\infty}$, we will define the hierarchical counterparts of\nsome of the classical modal theories such as $\\mathbf{K4}$, $\\mathbf{KD4}$,\n$\\mathbf{GL}$ and $\\mathbf{S4}$. Then we will define their canonical\nprovability interpretations and their corresponding soundness-completeness\ntheorems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Two-domain and three-domain limit cycles in a typical aeroelastic system with freeplay in pitch.   Freeplay is a significant source of nonlinearity in aeroelastic systems and\nis strictly regulated by airworthiness authorities. It splits the phase plane\nof such systems into three piecewise linear subdomains. Depending on the\nlocation of the freeplay, limit cycle oscillations can result that span either\ntwo or three of these subdomains. The purpose of this work is to demonstrate\nthe existence of two-domain cycles both theoretically and experimentally. A\nsimple aeroelastic system with pitch, plunge and control deflection degrees of\nfreedom is investigated in the presence of freeplay in pitch. It is shown that\ntwo-domain and three-domain cycles can result from a grazing bifurcation and\npropagate in the decreasing airspeed direction. Close to the bifurcation, the\ntwo limit cycle branches interact with each other and aperiodic oscillations\nensue. Equivalent linearization is used to derive the conditions of existence\nof each type of limit cycle and to predict their amplitudes and frequencies.\nComparisons with measurements from wind tunnel experiments demonstrate that the\ntheory describes these phenomena with accuracy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Improved self-energy correction method for accurate and efficient band structure calculation.   The LDA-1/2 method for self-energy correction is a powerful tool for\ncalculating accurate band structures of semiconductors, while keeping the\ncomputational load as low as standard LDA. Nevertheless, controversies remain\nregarding the arbitrariness of choice between (1/2)e and (1/4)e charge\nstripping from the atoms in group IV semiconductors, the incorrect direct band\ngap predicted for Ge, and inaccurate band structures for III-V semiconductors.\nHere we propose an improved method named shell-LDA-1/2 (shLDA-1/2 for short),\nwhich is based on a shell-like trimming function for the self-energy potential.\nWith the new approach, we obtained accurate band structures for group IV, and\nfor III-V and II-VI compound semiconductors. In particular, we reproduced the\ncomplete band structure of Ge in good agreement with experimental data.\nMoreover, we have defined clear rules for choosing when (1/2)e or (1/4)e charge\nought to be stripped in covalent semiconductors, and for identifying materials\nfor which shLDA-1/2 is expected to fail.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Abstracting Event-Driven Systems with Lifestate Rules.   We present lifestate rules--an approach for abstracting event-driven object\nprotocols. Developing applications against event-driven software frameworks is\nnotoriously difficult. One reason why is that to create functioning\napplications, developers must know about and understand the complex protocols\nthat abstract the internal behavior of the framework. Such protocols intertwine\nthe proper registering of callbacks to receive control from the framework with\nappropriate application programming interface (API) calls to delegate back to\nit. Lifestate rules unify lifecycle and typestate constraints in one common\nspecification language. Our primary contribution is a model of event-driven\nsystems from which lifestate rules can be derived. We then apply specification\nmining techniques to learn lifestate specifications for Android framework\ntypes. In the end, our implementation is able to find several rules that\ncharacterize actual behavior of the Android framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generating Representative Executions [Extended Abstract].   Analyzing the behaviour of a concurrent program is made difficult by the\nnumber of possible executions. This problem can be alleviated by applying the\ntheory of Mazurkiewicz traces to focus only on the canonical representatives of\nthe equivalence classes of the possible executions of the program. This paper\npresents a generic framework that allows to specify the possible behaviours of\nthe execution environment, and generate all Foata-normal executions of a\nprogram, for that environment, by discarding abnormal executions during the\ngeneration phase. The key ingredient of Mazurkiewicz trace theory, the\ndependency relation, is used in the framework in two roles: first, as part of\nthe specification of which executions are allowed at all, and then as part of\nthe normality checking algorithm, which is used to discard the abnormal\nexecutions. The framework is instantiated to the relaxed memory models of the\nSPARC hierarchy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Massive CO White Dwarf in the Symbiotic Recurrent Nova RS Ophiuchi.   If accreting white dwarfs (WD) in binary systems are to produce type Ia\nsupernovae (SNIa), they must grow to nearly the Chandrasekhar mass and ignite\ncarbon burning. Proving conclusively that a WD has grown substantially since\nits birth is a challenging task. Slow accretion of hydrogen inevitably leads to\nthe erosion, rather than the growth of WDs. Rapid hydrogen accretion does lead\nto growth of a helium layer, due to both decreased degeneracy and the\ninhibition of mixing of the accreted hydrogen with the underlying WD. However,\nuntil recently, simulations of helium-accreting WDs all claimed to show the\nexplosive ejection of a helium envelope once it exceeded $\\sim 10^{-1}\\, \\rm\nM_{\\odot}$. Because CO WDs cannot be born with masses in excess of $\\sim 1.1\\,\n\\rm M_{\\odot}$, any such object, in excess of $\\sim 1.2\\, \\rm M_{\\odot}$, must\nhave grown substantially. We demonstrate that the WD in the symbiotic nova RS\nOph is in the mass range 1.2-1.4\\,M$_{\\odot}$. We compare UV spectra of RS Oph\nwith those of novae with ONe WDs, and with novae erupting on CO WDs. The RS Oph\nWD is clearly made of CO, demonstrating that it has grown substantially since\nbirth. It is a prime candidate to eventually produce an SNIa.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Perturbing Eisenstein polynomials over local fields.   Let $K$ be a local field whose residue field has characteristic $p$ and let\n$L/K$ be a finite separable totally ramified extension. Let $\\pi_L$ be a\nuniformizer for $L$ and let $f(X)$ be the minimum polynomial for $\\pi_L$ over\n$K$. Suppose $\\tilde{\\pi}_L$ is another uniformizer for $L$ such that\n$\\tilde{\\pi}_L\\equiv\\pi_L+r\\pi_L^{\\ell+1} \\pmod{\\pi_L^{\\ell+2}}$ for some\n$\\ell\\ge1$ and $r\\in O_K$. Let $\\tilde{f}(X)$ be the minimum polynomial for\n$\\tilde{\\pi}_L$ over $K$. In this paper we give congruences for the\ncoefficients of $\\tilde{f}(X)$ in terms of $r$ and the coefficients of $f(X)$.\nThese congruences improve and extend work of Krasner.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Automata-Guided Hierarchical Reinforcement Learning for Skill Composition.   Skills learned through (deep) reinforcement learning often generalizes poorly\nacross domains and re-training is necessary when presented with a new task. We\npresent a framework that combines techniques in \\textit{formal methods} with\n\\textit{reinforcement learning} (RL). The methods we provide allows for\nconvenient specification of tasks with logical expressions, learns hierarchical\npolicies (meta-controller and low-level controllers) with well-defined\nintrinsic rewards, and construct new skills from existing ones with little to\nno additional exploration. We evaluate the proposed methods in a simple grid\nworld simulation as well as a more complicated kitchen environment in AI2Thor",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Glitch Classification and Clustering for LIGO with Deep Transfer Learning.   The detection of gravitational waves with LIGO and Virgo requires a detailed\nunderstanding of the response of these instruments in the presence of\nenvironmental and instrumental noise. Of particular interest is the study of\nanomalous non-Gaussian noise transients known as glitches, since their high\noccurrence rate in LIGO/Virgo data can obscure or even mimic true gravitational\nwave signals. Therefore, successfully identifying and excising glitches is of\nutmost importance to detect and characterize gravitational waves. In this\narticle, we present the first application of Deep Learning combined with\nTransfer Learning for glitch classification, using real data from LIGO's first\ndiscovery campaign labeled by Gravity Spy, showing that knowledge from\npre-trained models for real-world object recognition can be transferred for\nclassifying spectrograms of glitches. We demonstrate that this method enables\nthe optimal use of very deep convolutional neural networks for glitch\nclassification given small unbalanced training datasets, significantly reduces\nthe training time, and achieves state-of-the-art accuracy above 98.8%. Once\ntrained via transfer learning, we show that the networks can be truncated and\nused as feature extractors for unsupervised clustering to automatically group\ntogether new classes of glitches and anomalies. This novel capability is of\ncritical importance to identify and remove new types of glitches which will\noccur as the LIGO/Virgo detectors gradually attain design sensitivity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Orbit classification in the Hill problem: I. The classical case.   The case of the classical Hill problem is numerically investigated by\nperforming a thorough and systematic classification of the initial conditions\nof the orbits. More precisely, the initial conditions of the orbits are\nclassified into four categories: (i) non-escaping regular orbits; (ii) trapped\nchaotic orbits; (iii) escaping orbits; and (iv) collision orbits. In order to\nobtain a more general and complete view of the orbital structure of the\ndynamical system our exploration takes place in both planar (2D) and the\nspatial (3D) version of the Hill problem. For the 2D system we numerically\nintegrate large sets of initial conditions in several types of planes, while\nfor the system with three degrees of freedom, three-dimensional distributions\nof initial conditions of orbits are examined. For distinguishing between\nordered and chaotic bounded motion the Smaller ALingment Index (SALI) method is\nused. We managed to locate the several bounded basins, as well as the basins of\nescape and collision and also to relate them with the corresponding escape and\ncollision time of the orbits. Our numerical calculations indicate that the\noverall orbital dynamics of the Hamiltonian system is a complicated but highly\ninterested problem. We hope our contribution to be useful for a further\nunderstanding of the orbital properties of the classical Hill problem.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Efficient Test-based Variable Selection for High-dimensional Linear Models.   Variable selection plays a fundamental role in high-dimensional data\nanalysis. Various methods have been developed for variable selection in recent\nyears. Well-known examples are forward stepwise regression (FSR) and least\nangle regression (LARS), among others. These methods typically add variables\ninto the model one by one. For such selection procedures, it is crucial to find\na stopping criterion that controls model complexity. One of the most commonly\nused techniques to this end is cross-validation (CV) which, in spite of its\npopularity, has two major drawbacks: expensive computational cost and lack of\nstatistical interpretation. To overcome these drawbacks, we introduce a\nflexible and efficient test-based variable selection approach that can be\nincorporated into any sequential selection procedure. The test, which is on the\noverall signal in the remaining inactive variables, is based on the maximal\nabsolute partial correlation between the inactive variables and the response\ngiven active variables. We develop the asymptotic null distribution of the\nproposed test statistic as the dimension tends to infinity uniformly in the\nsample size. We also show that the test is consistent. With this test, at each\nstep of the selection, a new variable is included if and only if the $p$-value\nis below some pre-defined level. Numerical studies show that the proposed\nmethod delivers very competitive performance in terms of variable selection\naccuracy and computational complexity compared to CV.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "3D-PRNN: Generating Shape Primitives with Recurrent Neural Networks.   The success of various applications including robotics, digital content\ncreation, and visualization demand a structured and abstract representation of\nthe 3D world from limited sensor data. Inspired by the nature of human\nperception of 3D shapes as a collection of simple parts, we explore such an\nabstract shape representation based on primitives. Given a single depth image\nof an object, we present 3D-PRNN, a generative recurrent neural network that\nsynthesizes multiple plausible shapes composed of a set of primitives. Our\ngenerative model encodes symmetry characteristics of common man-made objects,\npreserves long-range structural coherence, and describes objects of varying\ncomplexity with a compact representation. We also propose a method based on\nGaussian Fields to generate a large scale dataset of primitive-based shape\nrepresentations to train our network. We evaluate our approach on a wide range\nof examples and show that it outperforms nearest-neighbor based shape retrieval\nmethods and is on-par with voxel-based generative models while using a\nsignificantly reduced parameter space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SAGA and Restricted Strong Convexity.   SAGA is a fast incremental gradient method on the finite sum problem and its\neffectiveness has been tested on a vast of applications. In this paper, we\nanalyze SAGA on a class of non-strongly convex and non-convex statistical\nproblem such as Lasso, group Lasso, Logistic regression with $\\ell_1$\nregularization, linear regression with SCAD regularization and Correct Lasso.\nWe prove that SAGA enjoys the linear convergence rate up to the statistical\nestimation accuracy, under the assumption of restricted strong convexity (RSC).\nIt significantly extends the applicability of SAGA in convex and non-convex\noptimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Yangians and their Poisson counterparts.   By a generalized Yangian we mean a Yangian-like algebra of one of two\nclasses. One of these classes consists of the so-called braided Yangians,\nintroduced in our previous paper. The braided Yangians are in a sense similar\nto the reflection equation algebra. The generalized Yangians of second class,\ncalled the Yangians of RTT type, are defined by the same formulae as the usual\nYangians are but with other quantum $R$-matrices. If such an $R$-matrix is the\nsimplest trigonometrical $R$-matrix, the corresponding Yangian of RTT type is\nthe so-called q-Yangian. We claim that each generalized Yangian is a\ndeformation of the commutative algebra ${\\rm Sym}(gl(m)[t^{-1}])$ provided that\nthe corresponding $R$-matrix is a deformation of the flip. Also, we exhibit the\ncorresponding Poisson brackets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Direct Mapping Hidden Excited State Interaction Patterns from ab initio Dynamics and Its Implications on Force Field Development.   The excited states of polyatomic systems are rather complex, and often\nexhibit meta-stable dynamical behaviors. Static analysis of reaction pathway\noften fails to sufficiently characterize excited state motions due to their\nhighly non-equilibrium nature. Here, we proposed a time series guided\nclustering algorithm to generate most relevant meta-stable patterns directly\nfrom ab initio dynamic trajectories. Based on the knowledge of these\nmeta-stable patterns, we suggested an interpolation scheme with only a concrete\nand finite set of known patterns to accurately predict the ground and excited\nstate properties of the entire dynamics trajectories. As illustrated with the\nexample of sinapic acids, the estimation error for both ground and excited\nstate is very close, which indicates one could predict the ground and excited\nstate molecular properties with similar accuracy. These results may provide us\nsome insights to construct an excited state force field with compatible energy\nterms as traditional ones.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Anisotropic triangulations via discrete Riemannian Voronoi diagrams.   The construction of anisotropic triangulations is desirable for various\napplications, such as the numerical solving of partial differential equations\nand the representation of surfaces in graphics. To solve this notoriously\ndifficult problem in a practical way, we introduce the discrete Riemannian\nVoronoi diagram, a discrete structure that approximates the Riemannian Voronoi\ndiagram. This structure has been implemented and was shown to lead to good\ntriangulations in $\\mathbb{R}^2$ and on surfaces embedded in $\\mathbb{R}^3$ as\ndetailed in our experimental companion paper.\nIn this paper, we study theoretical aspects of our structure. Given a finite\nset of points $\\cal P$ in a domain $\\Omega$ equipped with a Riemannian metric,\nwe compare the discrete Riemannian Voronoi diagram of $\\cal P$ to its\nRiemannian Voronoi diagram. Both diagrams have dual structures called the\ndiscrete Riemannian Delaunay and the Riemannian Delaunay complex. We provide\nconditions that guarantee that these dual structures are identical. It then\nfollows from previous results that the discrete Riemannian Delaunay complex can\nbe embedded in $\\Omega$ under sufficient conditions, leading to an anisotropic\ntriangulation with curved simplices. Furthermore, we show that, under similar\nconditions, the simplices of this triangulation can be straightened.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Efficient Deep Learning Technique for the Navier-Stokes Equations: Application to Unsteady Wake Flow Dynamics.   We present an efficient deep learning technique for the model reduction of\nthe Navier-Stokes equations for unsteady flow problems. The proposed technique\nrelies on the Convolutional Neural Network (CNN) and the stochastic gradient\ndescent method. Of particular interest is to predict the unsteady fluid forces\nfor different bluff body shapes at low Reynolds number. The discrete\nconvolution process with a nonlinear rectification is employed to approximate\nthe mapping between the bluff-body shape and the fluid forces. The deep neural\nnetwork is fed by the Euclidean distance function as the input and the target\ndata generated by the full-order Navier-Stokes computations for primitive bluff\nbody shapes. The convolutional networks are iteratively trained using the\nstochastic gradient descent method with the momentum term to predict the fluid\nforce coefficients of different geometries and the results are compared with\nthe full-order computations. We attempt to provide a physical analogy of the\nstochastic gradient method with the momentum term with the simplified form of\nthe incompressible Navier-Stokes momentum equation. We also construct a direct\nrelationship between the CNN-based deep learning and the Mori-Zwanzig formalism\nfor the model reduction of a fluid dynamical system. A systematic convergence\nand sensitivity study is performed to identify the effective dimensions of the\ndeep-learned CNN process such as the convolution kernel size, the number of\nkernels and the convolution layers. Within the error threshold, the prediction\nbased on our deep convolutional network has a speed-up nearly four orders of\nmagnitude compared to the full-order results and consumes an insignificant\nfraction of computational resources. The proposed CNN-based approximation\nprocedure has a profound impact on the parametric design of bluff bodies and\nthe feedback control of separated flows.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Go game formal revealing by Ising model.   Go gaming is a struggle for territory control between rival, black and white,\nstones on a board. We model the Go dynamics in a game by means of the Ising\nmodel whose interaction coefficients reflect essential rules and tactics\nemployed in Go to build long-term strategies. At any step of the game, the\nenergy functional of the model provides the control degree (strength) of a\nplayer over the board. A close fit between predictions of the model with actual\ngames is obtained.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Three-Dimensional Electronic Structure of type-II Weyl Semimetal WTe$_2$.   By combining bulk sensitive soft-X-ray angular-resolved photoemission\nspectroscopy and accurate first-principles calculations we explored the bulk\nelectronic properties of WTe$_2$, a candidate type-II Weyl semimetal featuring\na large non-saturating magnetoresistance. Despite the layered geometry\nsuggesting a two-dimensional electronic structure, we find a three-dimensional\nelectronic dispersion. We report an evident band dispersion in the reciprocal\ndirection perpendicular to the layers, implying that electrons can also travel\ncoherently when crossing from one layer to the other. The measured Fermi\nsurface is characterized by two well-separated electron and hole pockets at\neither side of the $\\Gamma$ point, differently from previous more surface\nsensitive ARPES experiments that additionally found a significant quasiparticle\nweight at the zone center. Moreover, we observe a significant sensitivity of\nthe bulk electronic structure of WTe$_2$ around the Fermi level to electronic\ncorrelations and renormalizations due to self-energy effects, previously\nneglected in first-principles descriptions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Cognitive networks: brains, internet, and civilizations.   In this short essay, we discuss some basic features of cognitive activity at\nseveral different space-time scales: from neural networks in the brain to\ncivilizations. One motivation for such comparative study is its heuristic\nvalue. Attempts to better understand the functioning of \"wetware\" involved in\ncognitive activities of central nervous system by comparing it with a computing\ndevice have a long tradition. We suggest that comparison with Internet might be\nmore adequate. We briefly touch upon such subjects as encoding, compression,\nand Saussurean trichotomy langue/langage/parole in various environments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "HARP: Hierarchical Representation Learning for Networks.   We present HARP, a novel method for learning low dimensional embeddings of a\ngraph's nodes which preserves higher-order structural features. Our proposed\nmethod achieves this by compressing the input graph prior to embedding it,\neffectively avoiding troublesome embedding configurations (i.e. local minima)\nwhich can pose problems to non-convex optimization. HARP works by finding a\nsmaller graph which approximates the global structure of its input. This\nsimplified graph is used to learn a set of initial representations, which serve\nas good initializations for learning representations in the original, detailed\ngraph. We inductively extend this idea, by decomposing a graph in a series of\nlevels, and then embed the hierarchy of graphs from the coarsest one to the\noriginal graph. HARP is a general meta-strategy to improve all of the\nstate-of-the-art neural algorithms for embedding graphs, including DeepWalk,\nLINE, and Node2vec. Indeed, we demonstrate that applying HARP's hierarchical\nparadigm yields improved implementations for all three of these methods, as\nevaluated on both classification tasks on real-world graphs such as DBLP,\nBlogCatalog, CiteSeer, and Arxiv, where we achieve a performance gain over the\noriginal implementations by up to 14% Macro F1.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Almost sure scattering for the energy-critical NLS with radial data below $H^1(\\mathbb{R}^4)$.   We prove almost sure global existence and scattering for the energy-critical\nnonlinear Schrödinger equation with randomized spherically symmetric initial\ndata in $H^s(\\mathbb{R}^4)$ with $\\frac56<s<1$. We were inspired to consider\nthis problem by the recent work of Dodson--Lührmann--Mendelson, which treated\nthe analogous problem for the energy-critical wave equation.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Passivity Based Whole-body Control for Quadrupedal Locomotion on Challenging Terrain.   We present a passivity-based Whole-Body Control approach for quadruped robots\nthat achieves dynamic locomotion while compliantly balancing the robot's trunk.\nWe formulate the motion tracking as a Quadratic Program that takes into account\nthe full robot rigid body dynamics, the actuation limit, the joint limits and\nthe contact interaction. We analyze the controller robustness against\ninaccurate friction coefficient estimates and unstable footholds, as well as\nits capability to redistribute the load as a consequence of enforcing actuation\nlimits. Additionally, we present some practical implementation details gained\nfrom the experience with the real platform. Extensive experimental trials on\nthe 90 Kg Hydraulically actuated Quadruped robot validate the capabilities of\nthis controller under various terrain conditions and gaits. The proposed\napproach is expedient for accurate execution of high dynamic motions with\nrespect to the current state of the art.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Temporal Difference Learning with Neural Networks - Study of the Leakage Propagation Problem.   Temporal-Difference learning (TD) [Sutton, 1988] with function approximation\ncan converge to solutions that are worse than those obtained by Monte-Carlo\nregression, even in the simple case of on-policy evaluation. To increase our\nunderstanding of the problem, we investigate the issue of approximation errors\nin areas of sharp discontinuities of the value function being further\npropagated by bootstrap updates. We show empirical evidence of this leakage\npropagation, and show analytically that it must occur, in a simple Markov\nchain, when function approximation errors are present. For reversible policies,\nthe result can be interpreted as the tension between two terms of the loss\nfunction that TD minimises, as recently described by [Ollivier, 2018]. We show\nthat the upper bounds from [Tsitsiklis and Van Roy, 1997] hold, but they do not\nimply that leakage propagation occurs and under what conditions. Finally, we\ntest whether the problem could be mitigated with a better state representation,\nand whether it can be learned in an unsupervised manner, without rewards or\nprivileged information.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Matching for Expert Systems with Uncertain Task Types.   A matching in a two-sided market often incurs an externality: a matched\nresource may become unavailable to the other side of the market, at least for a\nwhile. This is especially an issue in online platforms involving human experts\nas the expert resources are often scarce. The efficient utilization of experts\nin these platforms is made challenging by the fact that the information\navailable about the parties involved is usually limited.\nTo address this challenge, we develop a model of a task-expert matching\nsystem where a task is matched to an expert using not only the prior\ninformation about the task but also the feedback obtained from the past\nmatches. In our model the tasks arrive online while the experts are fixed and\nconstrained by a finite service capacity. For this model, we characterize the\nmaximum task resolution throughput a platform can achieve. We show that the\nnatural greedy approaches where each expert is assigned a task most suitable to\nher skill is suboptimal, as it does not internalize the above externality. We\ndevelop a throughput optimal backpressure algorithm which does so by accounting\nfor the `congestion' among different task types. Finally, we validate our model\nand confirm our theoretical findings with data-driven simulations via logs of\nMath.StackExchange, a StackOverflow forum dedicated to mathematics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sea of Lights: Practical Device-to-Device Security Bootstrapping in the Dark.   Practical solutions to bootstrap security in today's information and\ncommunication systems critically depend on centralized services for\nauthentication as well as key and trust management. This is particularly true\nfor mobile users. Identity providers such as Google or Facebook have active\nuser bases of two billion each, and the subscriber number of mobile operators\nexceeds five billion unique users as of early 2018. If these centralized\nservices go completely `dark' due to natural or man made disasters, large scale\nblackouts, or country-wide censorship, the users are left without practical\nsolutions to bootstrap security on their mobile devices. Existing distributed\nsolutions, for instance, the so-called web-of-trust are not sufficiently\nlightweight. Furthermore, they support neither cross-application on mobile\ndevices nor strong protection of key material using hardware security modules.\nWe propose Sea of Lights(SoL), a practical lightweight scheme for bootstrapping\ndevice-to-device security wirelessly, thus, enabling secure distributed\nself-organized networks. It is tailored to operate `in the dark' and provides\nstrong protection of key material as well as an intuitive means to build a\nlightweight web-of-trust. SoL is particularly well suited for local or urban\noperation in scenarios such as the coordination of emergency response, where it\nhelps containing/limiting the spreading of misinformation. As a proof of\nconcept, we implement SoL in the Android platform and hence test its\nfeasibility on real mobile devices. We further evaluate its key performance\naspects using simulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Radial Surface Density Profiles of Gas and Dust in the Debris Disk around 49 Ceti.   We present ~0.4 resolution images of CO(3-2) and associated continuum\nemission from the gas-bearing debris disk around the nearby A star 49 Ceti,\nobserved with the Atacama Large Millimeter/Submillimeter Array (ALMA). We\nanalyze the ALMA visibilities in tandem with the broad-band spectral energy\ndistribution to measure the radial surface density profiles of dust and gas\nemission from the system. The dust surface density decreases with radius\nbetween ~100 and 310 au, with a marginally significant enhancement of surface\ndensity at a radius of ~110 au. The SED requires an inner disk of small grains\nin addition to the outer disk of larger grains resolved by ALMA. The gas disk\nexhibits a surface density profile that increases with radius, contrary to most\nprevious spatially resolved observations of circumstellar gas disks. While ~80%\nof the CO flux is well described by an axisymmetric power-law disk in Keplerian\nrotation about the central star, residuals at ~20% of the peak flux exhibit a\ndeparture from axisymmetry suggestive of spiral arms or a warp in the gas disk.\nThe radial extent of the gas disk (~220 au) is smaller than that of the dust\ndisk (~300 au), consistent with recent observations of other gas-bearing debris\ndisks. While there are so far only three broad debris disks with well\ncharacterized radial dust profiles at millimeter wavelengths, 49 Ceti's disk\nshows a markedly different structure from two radially resolved gas-poor debris\ndisks, implying that the physical processes generating and sculpting the gas\nand dust are fundamentally different.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Extraordinary linear dynamic range in laser-defined functionalized graphene photodetectors.   Graphene-based photodetectors have demonstrated mechanical flexibility, large\noperating bandwidth, and broadband spectral response. However, their linear\ndynamic range (LDR) is limited by graphene's intrinsichot-carrier dynamics,\nwhich causes deviation from a linear photoresponse at low incident powers. At\nthe same time, multiplication of hot carriers causes the photoactive region to\nbe smeared over distances of a few micro-meters, limiting the use of graphene\nin high-resolution applications. We present a novel method for engineer-ing\nphotoactive junctions in FeCl3-intercalated graphene using laser irradiation.\nPhotocurrent measured at these planar junctions shows an extraordinary linear\nresponse with an LDR value at least 4500 times larger than that of other\ngraphene devices (44 dB) while maintaining high stability against environmental\ncontamination without the need for encapsulation. The observed photoresponse is\npurely photovoltaic, demonstrating complete quenching of hot-carrier effects.\nThese results pave the way toward the design of ultrathin photode-tectors with\nunprecedented LDR for high-definition imaging and sensing.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Identifiability of phylogenetic parameters from k-mer data under the coalescent.   Distances between sequences based on their $k$-mer frequency counts can be\nused to reconstruct phylogenies without first computing a sequence alignment.\nPast work has shown that effective use of k-mer methods depends on 1)\nmodel-based corrections to distances based on $k$-mers and 2) breaking long\nsequences into blocks to obtain repeated trials from the sequence-generating\nprocess. Good performance of such methods is based on having many high-quality\nblocks with many homologous sites, which can be problematic to guarantee a\npriori.\nNature provides natural blocks of sequences into homologous regions---namely,\nthe genes. However, directly using past work in this setting is problematic\nbecause of possible discordance between different gene trees and the underlying\nspecies tree. Using the multispecies coalescent model as a basis, we derive\nmodel-based moment formulas that involve the divergence times and the\ncoalescent parameters. From this setting, we prove identifiability results for\nthe tree and branch length parameters under the Jukes-Cantor model of sequence\nmutations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Active set algorithms for estimating shape-constrained density ratios.   We review and modify the active set algorithm by Duembgen et al. (2011) for\nnonparametric maximum-likelihood estimation of a log-concave density. This\nparticular estimation problem is embedded into a more general framework\nincluding also the estimation of a log-convex tail inflation function as\nproposed by McCullagh and Polson (2012).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Binary systems with an RR Lyrae component - progress in 2016.   In this contribution, we summarize the progress made in the investigation of\nbinary candidates with an RR Lyrae component in 2016. We also discuss the\nactual status of the RRLyrBinCan database.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Estimating Local Interactions Among Many Agents Who Observe Their Neighbors.   In various economic environments, people observe those with whom they\nstrategically interact. We can model such information-sharing relations as an\ninformation network, and the strategic interactions as a game on the network.\nWhen any two agents in the network are connected either directly or indirectly,\nempirical modeling using an equilibrium approach is cumbersome, since the\ntestable implications from an equilibrium generally involve all the players of\nthe game, whereas a researcher's data set may contain only a fraction of these\nplayers in practice. This paper develops a tractable empirical model of linear\ninteractions where each agent, after observing part of his neighbors' types,\nnot knowing the full information network, uses best responses that are linear\nin his and other players' types that he observes, based on simple beliefs about\nother players' strategies. We provide conditions on information networks and\nbeliefs such that best responses take an explicit form with multiple intuitive\nfeatures. Furthermore, the best responses reveal how local payoff\ninterdependence among agents is translated into local stochastic dependence of\ntheir actions, allowing the econometrician to perform asymptotic inference\nwithout having to observe all the players in the game or having to know\nprecisely the sampling process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Controlled Set-Up Experiment to Establish Personalized Baselines for Real-Life Emotion Recognition.   We design, conduct and present the results of a highly personalized baseline\nemotion recognition experiment, which aims to set reliable ground-truth\nestimates for the subject's emotional state for real-life prediction under\nsimilar conditions using a small number of physiological sensors. We also\npropose an adaptive stimuli-selection mechanism that would use the user's\nfeedback as guide for future stimuli selection in the controlled-setup\nexperiment and generate optimal ground-truth personalized sessions\nsystematically. Initial results are very promising (85% accuracy) and variable\nimportance analysis shows that only a few features, which are easy-to-implement\nin portable devices, would suffice to predict the subject's emotional state.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Integrability of dispersionless Hirota type equations in 4D and the symplectic Monge-Ampere property.   We prove that integrability of a dispersionless Hirota type equation implies\nthe symplectic Monge-Ampere property in any dimension $\\geq 4$. In 4D this\nyields a complete classification of integrable dispersionless PDEs of Hirota\ntype through a list of heavenly type equations arising in self-dual gravity. As\na by-product of our approach we derive an involutive system of relations\ncharacterising symplectic Monge-Ampere equations in any dimension.\nMoreover, we demonstrate that in 4D the requirement of integrability is\nequivalent to self-duality of the conformal structure defined by the\ncharacteristic variety of the equation on every solution, which is in turn\nequivalent to the existence of a dispersionless Lax pair. We also give a\ncriterion of linerisability of a Hirota type equation via flatness of the\ncorresponding conformal structure, and study symmetry properties of integrable\nequations.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Optical quality assurance of GEM foils.   An analysis software was developed for the high aspect ratio optical scanning\nsystem in the Detec- tor Laboratory of the University of Helsinki and the\nHelsinki Institute of Physics. The system is used e.g. in the quality assurance\nof the GEM-TPC detectors being developed for the beam diagnostics system of the\nSuperFRS at future FAIR facility. The software was tested by analyzing five\nCERN standard GEM foils scanned with the optical scanning system. The\nmeasurement uncertainty of the diameter of the GEM holes and the pitch of the\nhole pattern was found to be 0.5 {\\mu}m and 0.3 {\\mu}m, respectively. The\nsoftware design and the performance are discussed. The correlation between the\nGEM hole size distribution and the corresponding gain variation was studied by\ncomparing them against a detailed gain mapping of a foil and a set of six lower\nprecision control measurements. It can be seen that a qualitative estimation of\nthe behavior of the local variation in gain across the GEM foil can be made\nbased on the measured sizes of the outer and inner holes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "GP-SUM. Gaussian Processes Filtering of non-Gaussian Beliefs.   This work studies the problem of stochastic dynamic filtering and state\npropagation with complex beliefs. The main contribution is GP-SUM, a filtering\nalgorithm tailored to dynamic systems and observation models expressed as\nGaussian Processes (GP), and to states represented as a weighted sum of\nGaussians. The key attribute of GP-SUM is that it does not rely on\nlinearizations of the dynamic or observation models, or on unimodal Gaussian\napproximations of the belief, hence enables tracking complex state\ndistributions. The algorithm can be seen as a combination of a sampling-based\nfilter with a probabilistic Bayes filter. On the one hand, GP-SUM operates by\nsampling the state distribution and propagating each sample through the dynamic\nsystem and observation models. On the other hand, it achieves effective\nsampling and accurate probabilistic propagation by relying on the GP form of\nthe system, and the sum-of-Gaussian form of the belief. We show that GP-SUM\noutperforms several GP-Bayes and Particle Filters on a standard benchmark. We\nalso demonstrate its use in a pushing task, predicting with experimental\naccuracy the naturally occurring non-Gaussian distributions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reflexive Regular Equivalence for Bipartite Data.   Bipartite data is common in data engineering and brings unique challenges,\nparticularly when it comes to clustering tasks that impose on strong structural\nassumptions. This work presents an unsupervised method for assessing similarity\nin bipartite data. Similar to some co-clustering methods, the method is based\non regular equivalence in graphs. The algorithm uses spectral properties of a\nbipartite adjacency matrix to estimate similarity in both dimensions. The\nmethod is reflexive in that similarity in one dimension is used to inform\nsimilarity in the other. Reflexive regular equivalence can also use the\nstructure of transitivities -- in a network sense -- the contribution of which\nis controlled by the algorithm's only free-parameter, $\\alpha$. The method is\ncompletely unsupervised and can be used to validate assumptions of\nco-similarity, which are required but often untested, in co-clustering\nanalyses. Three variants of the method with different normalizations are tested\non synthetic data. The method is found to be robust to noise and well-suited to\nasymmetric co-similar structure, making it particularly informative for cluster\nanalysis and recommendation in bipartite data of unknown structure. In\nexperiments, the convergence and speed of the algorithm are found to be stable\nfor different levels of noise. Real-world data from a network of malaria genes\nare analyzed, where the similarity produced by the reflexive method is shown to\nout-perform other measures' ability to correctly classify genes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Overcomplete HMMs.   We study the problem of learning overcomplete HMMs---those that have many\nhidden states but a small output alphabet. Despite having significant practical\nimportance, such HMMs are poorly understood with no known positive or negative\nresults for efficient learning. In this paper, we present several new\nresults---both positive and negative---which help define the boundaries between\nthe tractable and intractable settings. Specifically, we show positive results\nfor a large subclass of HMMs whose transition matrices are sparse,\nwell-conditioned, and have small probability mass on short cycles. On the other\nhand, we show that learning is impossible given only a polynomial number of\nsamples for HMMs with a small output alphabet and whose transition matrices are\nrandom regular graphs with large degree. We also discuss these results in the\ncontext of learning HMMs which can capture long-term dependencies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bounds on the Approximation Power of Feedforward Neural Networks.   The approximation power of general feedforward neural networks with piecewise\nlinear activation functions is investigated. First, lower bounds on the size of\na network are established in terms of the approximation error and network depth\nand width. These bounds improve upon state-of-the-art bounds for certain\nclasses of functions, such as strongly convex functions. Second, an upper bound\nis established on the difference of two neural networks with identical weights\nbut different activation functions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Incentivized Advertising: Treatment Effect and Adverse Selection.   Incentivized advertising is a new ad format that is gaining popularity in\ndigital mobile advertising. In incentivized advertising, the publisher rewards\nusers for watching an ad. An endemic issue here is adverse selection, where\nreward-seeking users select into incentivized ad placements to obtain rewards.\nAdverse selection reduces the publisher's ad profit as well as poses a\ndifficulty to causal inference of the effectiveness of incentivized\nadvertising. To this end, we develop a treatment effect model that allows and\ncontrols for unobserved adverse selection, and estimate the model using data\nfrom a mobile gaming app that offers both incentivized and non-incentivized\nads. We find that rewarding users to watch an ad has an overall positive effect\non the ad conversion rate. A user is 27% more likely to convert when being\nrewarded to watch an ad. However there is a negative offsetting effect that\nreduces the effectiveness of incentivized ads. Some users are averse to delayed\nrewards, they prefer to collect their rewards immediately after watching the\nincentivized ads, instead of pursuing the content of the ads further. For the\nsubset of users who are averse to delayed rewards, the treatment effect is only\n13%, while it can be as high as 47% for other users.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the complexity of generalized chromatic polynomials.   J. Makowsky and B. Zilber (2004) showed that many variations of graph\ncolorings, called CP-colorings in the sequel, give rise to graph polynomials.\nThis is true in particular for harmonious colorings, convex colorings,\nmcc_t-colorings, and rainbow colorings, and many more. N. Linial (1986) showed\nthat the chromatic polynomial $\\chi(G;X)$ is #P-hard to evaluate for all but\nthree values X=0,1,2, where evaluation is in P. This dichotomy includes\nevaluation at real or complex values, and has the further property that the set\nof points for which evaluation is in P is finite. We investigate how the\ncomplexity of evaluating univariate graph polynomials that arise from\nCP-colorings varies for different evaluation points. We show that for some\nCP-colorings (harmonious, convex) the complexity of evaluation follows a\nsimilar pattern to the chromatic polynomial. However, in other cases (proper\nedge colorings, mcc_t-colorings, H-free colorings) we could only obtain a\ndichotomy for evaluations at non-negative integer points. We also discuss some\nCP-colorings where we only have very partial results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Algorithmic Inflection of Russian and Generation of Grammatically Correct Text.   We present a deterministic algorithm for Russian inflection. This algorithm\nis implemented in a publicly available web-service www.passare.ru which\nprovides functions for inflection of single words, word matching and synthesis\nof grammatically correct Russian text. The inflectional functions have been\ntested against the annotated corpus of Russian language OpenCorpora.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multidimensional upwind hydrodynamics on unstructured meshes using Graphics Processing Units I. Two-dimensional uniform meshes.   We present a new method for numerical hydrodynamics which uses a\nmultidimensional generalisation of the Roe solver and operates on an\nunstructured triangular mesh. The main advantage over traditional methods based\non Riemann solvers, which commonly use one-dimensional flux estimates as\nbuilding blocks for a multidimensional integration, is its inherently\nmultidimensional nature, and as a consequence its ability to recognise\nmultidimensional stationary states that are not hydrostatic. A second novelty\nis the focus on Graphics Processing Units (GPUs). By tailoring the algorithms\nspecifically to GPUs we are able to get speedups of 100-250 compared to a\ndesktop machine. We compare the multidimensional upwind scheme to a\ntraditional, dimensionally split implementation of the Roe solver on several\ntest problems, and we find that the new method significantly outperforms the\nRoe solver in almost all cases. This comes with increased computational costs\nper time step, which makes the new method approximately a factor of 2 slower\nthan a dimensionally split scheme acting on a structured grid.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Universal abstract elementary classes and locally multipresentable categories.   We exhibit an equivalence between the model-theoretic framework of universal\nclasses and the category-theoretic framework of locally multipresentable\ncategories. We similarly give an equivalence between abstract elementary\nclasses (AECs) admitting intersections and locally polypresentable categories.\nWe use these results to shed light on Shelah's presentation theorem for AECs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Shannon's entropy and its Generalizations towards Statistics, Reliability and Information Science during 1948-2018.   Starting from the pioneering works of Shannon and Weiner in 1948, a plethora\nof works have been reported on entropy in different directions. Entropy-related\nreview work in the direction of statistics, reliability and information\nscience, to the best of our knowledge, has not been reported so far. Here we\nhave tried to collect all possible works in this direction during the period\n1948-2018 so that people interested in entropy, specially the new researchers,\nget benefited.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simple labeled graph $C^*$-algebras are associated to disagreeable labeled spaces.   By a labeled graph $C^*$-algebra we mean a $C^*$-algebra associated to a\nlabeled space $(E,\\mathcal L,\\mathcal E)$ consisting of a labeled graph\n$(E,\\mathcal L)$ and the smallest normal accommodating set $\\mathcal E$ of\nvertex subsets. Every graph $C^*$-algebra $C^*(E)$ is a labeled graph\n$C^*$-algebra and it is well known that $C^*(E)$ is simple if and only if the\ngraph $E$ is cofinal and satisfies Condition (L). Bates and Pask extend these\nconditions of graphs $E$ to labeled spaces, and show that if a set-finite and\nreceiver set-finite labeled space $(E,\\mathcal L, \\mathcal E)$ is cofinal and\ndisagreeable, then its $C^*$-algebra $C^*(E,\\mathcal L, \\mathcal E)$ is simple.\nIn this paper, we show that the converse is also true.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantification of the memory effect of steady-state currents from interaction-induced transport in quantum systems.   Dynamics of a system in general depends on its initial state and how the\nsystem is driven, but in many-body systems the memory is usually averaged out\nduring evolution. Here, interacting quantum systems without external\nrelaxations are shown to retain long-time memory effects in steady states. To\nidentify memory effects, we first show quasi-steady state currents form in\nfinite, isolated Bose and Fermi Hubbard models driven by interaction imbalance\nand they become steady-state currents in the thermodynamic limit. By comparing\nthe steady state currents from different initial states or ramping rates of the\nimbalance, long-time memory effects can be quantified. While the memory effects\nof initial states are more ubiquitous, the memory effects of switching\nprotocols are mostly visible in interaction-induced transport in lattices. Our\nsimulations suggest the systems enter a regime governed by a generalized Fick's\nlaw and memory effects lead to initial-state dependent diffusion coefficients.\nWe also identify conditions for enhancing memory effects and discuss possible\nexperimental implications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "SETI in vivo: testing the we-are-them hypothesis.   After it was proposed that life on Earth might descend from seeding by an\nearlier civilization, some authors noted that this alternative offers a\ntestable aspect: the seeds could be supplied with a signature that might be\nfound in extant organisms. In particular, it was suggested that the optimal\nlocation for such an artifact is the genetic code, as the least evolving part\nof cells. However, as the mainstream view goes, this scenario is too\nspeculative and cannot be meaningfully tested because encoding/decoding a\nsignature within the genetic code is ill-defined, so any retrieval attempt is\ndoomed to guesswork. Here we refresh the seeded-Earth hypothesis and discuss\nthe motivation for inserting a signature. We then show that \"biological SETI\"\ninvolves even weaker assumptions than traditional SETI and admits a\nwell-defined methodological framework. After assessing the possibility in terms\nof molecular and evolutionary biology, we formalize the approach and, adopting\nthe guideline of SETI that encoding/decoding should follow from first\nprinciples and be convention-free, develop a retrieval strategy. Applied to the\ncanonical code, it reveals a nontrivial precision structure of interlocked\nsystematic attributes. To assess this result in view of the initial assumption,\nwe perform statistical, comparison, interdependence, and semiotic analyses.\nStatistical analysis reveals no causal connection to evolutionary models of the\ncode, interdependence analysis precludes overinterpretation, and comparison\nanalysis shows that known code variations lack any precision-logic structures,\nin agreement with these variations being post-seeding deviations from the\ncanonical code. Finally, semiotic analysis shows that not only the found\nattributes are consistent with the initial assumption, but that they make\nperfect sense from SETI perspective, as they maintain some of the most\nuniversal codes of culture.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Transaction Support over Redis: An Overview.   This document outlines the approach to supporting cross-node transactions\nover a Redis cluster.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "EV-FlowNet: Self-Supervised Optical Flow Estimation for Event-based Cameras.   Event-based cameras have shown great promise in a variety of situations where\nframe based cameras suffer, such as high speed motions and high dynamic range\nscenes. However, developing algorithms for event measurements requires a new\nclass of hand crafted algorithms. Deep learning has shown great success in\nproviding model free solutions to many problems in the vision community, but\nexisting networks have been developed with frame based images in mind, and\nthere does not exist the wealth of labeled data for events as there does for\nimages for supervised training. To these points, we present EV-FlowNet, a novel\nself-supervised deep learning pipeline for optical flow estimation for event\nbased cameras. In particular, we introduce an image based representation of a\ngiven event stream, which is fed into a self-supervised neural network as the\nsole input. The corresponding grayscale images captured from the same camera at\nthe same time as the events are then used as a supervisory signal to provide a\nloss function at training time, given the estimated flow from the network. We\nshow that the resulting network is able to accurately predict optical flow from\nevents only in a variety of different scenes, with performance competitive to\nimage based networks. This method not only allows for accurate estimation of\ndense optical flow, but also provides a framework for the transfer of other\nself-supervised methods to the event-based domain.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fermion condensation and super pivotal categories.   We study fermionic topological phases using the technique of fermion\ncondensation. We give a prescription for performing fermion condensation in\nbosonic topological phases which contain a fermion. Our approach to fermion\ncondensation can roughly be understood as coupling the parent bosonic\ntopological phase to a phase of physical fermions, and condensing pairs of\nphysical and emergent fermions. There are two distinct types of objects in\nfermionic theories, which we call \"m-type\" and \"q-type\" particles. The\nendomorphism algebras of q-type particles are complex Clifford algebras, and\nthey have no analogues in bosonic theories. We construct a fermionic\ngeneralization of the tube category, which allows us to compute the\nquasiparticle excitations in fermionic topological phases. We then prove a\nseries of results relating data in condensed theories to data in their parent\ntheories; for example, if $\\mathcal{C}$ is a modular tensor category containing\na fermion, then the tube category of the condensed theory satisfies\n$\\textbf{Tube}(\\mathcal{C}/\\psi) \\cong \\mathcal{C} \\times (\\mathcal{C}/\\psi)$.\nWe also study how modular transformations, fusion rules, and coherence\nrelations are modified in the fermionic setting, prove a fermionic version of\nthe Verlinde dimension formula, construct a commuting projector lattice\nHamiltonian for fermionic theories, and write down a fermionic version of the\nTuraev-Viro-Barrett-Westbury state sum. A large portion of this work is devoted\nto three detailed examples of performing fermion condensation to produce\nfermionic topological phases: we condense fermions in the Ising theory, the\n$SO(3)_6$ theory, and the $\\frac{1}{2}\\text{E}_6$ theory, and compute the\nquasiparticle excitation spectrum in each of these examples.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Computer Self-efficacy and Its Relationship with Web Portal Usage: Evidence from the University of the East.   The University of the East Web Portal is an academic, web based system that\nprovides educational electronic materials and e-learning services. To fully\noptimize its usage, it is imperative to determine the factors that relate to\nits usage. Thus, this study, to determine the computer self-efficacy of the\nfaculty members of the University of the East and its relationship with their\nweb portal usage, was conceived. Using a validated questionnaire, the profile\nof the respondents, their computer self-efficacy, and web portal usage were\ngathered. Data showed that the respondents were relatively young (M = 40 years\nold), majority had masters degree (f = 85, 72%), most had been using the web\nportal for four semesters (f = 60, 51%), and the large part were intermediate\nweb portal users (f = 69, 59%). They were highly skilled in using the computer\n(M = 4.29) and skilled in using the Internet (M = 4.28). E-learning services (M\n= 3.29) and online library resources (M = 3.12) were only used occasionally.\nPearson correlation revealed that age was positively correlated with online\nlibrary resources (r = 0.267, p < 0.05) and a negative relationship existed\nbetween perceived skill level in using the portal and online library resources\nusage (r = -0.206, p < 0.05). A 2x2 chi square revealed that the highest\neducational attainment had a significant relationship with online library\nresources (chi square = 5.489, df = 1, p < 0.05). Basic computer (r = 0.196, p\n< 0.05) and Internet skills (r = 0.303, p < 0.05) were significantly and\npositively related with e-learning services usage but not with online library\nresources usage. Other individual factors such as attitudes towards the web\nportal and anxiety towards using the web portal can be investigated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Itineraries for Inverse Limits of Tent Maps: a Backward View.   Previously published admissibility conditions for an element of\n$\\{0,1\\}^{\\mathbb{Z}}$ to be the itinerary of a point of the inverse limit of a\ntent map are expressed in terms of forward orbits. We give necessary and\nsufficient conditions in terms of backward orbits, which is more natural for\ninverse limits. These backward admissibility conditions are not symmetric\nversions of the forward ones: in particular, the maximum backward itinerary\nwhich can be realised by a tent map mode locks on intervals of kneading\nsequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Charge compensation at the interface between the polar NaCl(111) surface and a NaCl aqueous solution.   Periodic supercell models of electric double layers formed at the interface\nbetween a charged surface and an electrolyte are subject to serious finite size\nerrors and require certain adjustments in the treatment of the long-range\nelectrostatic interactions. In a previous publication (C. Zhang, M. Sprik,\nPhys. Rev. B 94, 245309 (2016)) we have shown how this can be achieved using\nfinite field methods. The test system was the familiar simple point charge\nmodel of a NaCl aqueous solution confined between two oppositely charged walls.\nHere this method is extended to the interface between the (111) polar surface\nof a NaCl crystal and a high concentration NaCl aqueous solution. The crystal\nis kept completely rigid and the compensating charge screening the polarization\ncan only be provided by the electrolyte. We verify that the excess electrolyte\nionic charge at the interface conforms to the Tasker 1/2 rule for compensating\ncharge in the theory of polar rocksalt (111) surfaces. The interface can be\nviewed as an electric double layer with a net charge. We define a generalized\nHelmholtz capacitance $C_\\text{H}$ which can be computed by varying the applied\nelectric field. We find $C_\\text{H} = 8.23 \\, \\mu \\mathrm{Fcm}^{-2}$, which\nshould be compared to the $4.23 \\, \\mu \\mathrm{Fcm}^{-2}$ for the (100)\nnon-polar surface of the same NaCl crystal. This is rationalized by the\nobservation that compensating ions shed their first solvation shell adsorbing\nas contact ions pairs on the polar surface.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Geometric Surface-Based Tracking Control of a Quadrotor UAV under Actuator Constraints.   This paper presents contributions on nonlinear tracking control systems for a\nquadrotor unmanned micro aerial vehicle. New controllers are proposed based on\nnonlinear surfaces composed by tracking errors that evolve directly on the\nnonlinear configuration manifold thus inherently including in the control\ndesign the nonlinear characteristics of the SE(3) configuration space. In\nparticular geometric surface-based controllers are developed, and through\nrigorous stability proofs they are shown to have desirable closed loop\nproperties that are almost global. A region of attraction, independent of the\nposition error, is produced and its effects are analyzed. A strategy allowing\nthe quadrotor to achieve precise attitude tracking while simultaneously\nfollowing a desired position command and complying to actuator constraints in a\ncomputationally inexpensive manner is derived. This important contribution\ndifferentiates this work from existing Geometric Nonlinear Control System\nsolutions (GNCSs) since the commanded thrusts can be realized by the majority\nof quadrotors produced by the industry. The new features of the proposed GNCSs\nare illustrated by numerical simulations of aggressive maneuvers and a\ncomparison with a GNCSs from the bibliography.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On the computability of graph Turing machines.   We consider graph Turing machines, a model of parallel computation on a\ngraph, in which each vertex is only capable of performing one of a finite\nnumber of operations. This model of computation is a natural generalization of\nseveral well-studied notions of computation, including ordinary Turing\nmachines, cellular automata, and parallel graph dynamical systems. We analyze\nthe power of computations that can take place in this model, both in terms of\nthe degrees of computability of the functions that can be computed, and the\ntime and space resources needed to carry out these computations. We further\nshow that properties of the underlying graph have significant consequences for\nthe power of computation thereby obtained. In particular, we show that every\narithmetically definable set can be computed by a graph Turing machine in\nconstant time, and that every computably enumerable Turing degree can be\ncomputed in constant time and linear space by a graph Turing machine whose\nunderlying graph has finite degree.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Taggle: Scalable Visualization of Tabular Data through Aggregation.   Visualization of tabular data---for both presentation and exploration\npurposes---is a well-researched area. Although effective visual presentations\nof complex tables are supported by various plotting libraries, creating such\ntables is a tedious process and requires scripting skills. In contrast,\ninteractive table visualizations that are designed for exploration purposes\neither operate at the level of individual rows, where large parts of the table\nare accessible only via scrolling, or provide a high-level overview that often\nlacks context-preserving drill-down capabilities. In this work we present\nTaggle, a novel visualization technique for exploring and presenting large and\ncomplex tables that are composed of individual columns of categorical or\nnumerical data and homogeneous matrices. The key contribution of Taggle is the\nhierarchical aggregation of data subsets, for which the user can also choose\nsuitable visual representations.The aggregation strategy is complemented by the\nability to sort hierarchically such that groups of items can be flexibly\ndefined by combining categorical stratifications and by rich data selection and\nfiltering capabilities. We demonstrate the usefulness of Taggle for interactive\nanalysis and presentation of complex genomics data for the purpose of drug\ndiscovery.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spatial interactions and oscillatory tragedies of the commons.   A tragedy of the commons (TOC) occurs when individuals acting in their own\nself-interest deplete commonly-held resources, leading to a worse outcome than\nhad they cooperated. Over time, the depletion of resources can change\nincentives for subsequent actions. Here, we investigate long-term feedback\nbetween game and environment across a continuum of incentives in an\nindividual-based framework. We identify payoff-dependent transition rules that\nlead to oscillatory TOC-s in stochastic simulations and the mean field limit.\nFurther extending the stochastic model, we find that spatially explicit\ninteractions can lead to emergent, localized dynamics, including the\npropagation of cooperative wave fronts and cluster formation of both social\ncontext and resources. These dynamics suggest new mechanisms underlying how\nTOCs arise and how they might be averted.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Do Developers Update Their Library Dependencies? An Empirical Study on the Impact of Security Advisories on Library Migration.   Third-party library reuse has become common practice in contemporary software\ndevelopment, as it includes several benefits for developers. Library\ndependencies are constantly evolving, with newly added features and patches\nthat fix bugs in older versions. To take full advantage of third-party reuse,\ndevelopers should always keep up to date with the latest versions of their\nlibrary dependencies. In this paper, we investigate the extent of which\ndevelopers update their library dependencies. Specifically, we conducted an\nempirical study on library migration that covers over 4,600 GitHub software\nprojects and 2,700 library dependencies. Results show that although many of\nthese systems rely heavily on dependencies, 81.5% of the studied systems still\nkeep their outdated dependencies. In the case of updating a vulnerable\ndependency, the study reveals that affected developers are not likely to\nrespond to a security advisory. Surveying these developers, we find that 69% of\nthe interviewees claim that they were unaware of their vulnerable dependencies.\nFurthermore, developers are not likely to prioritize library updates, citing it\nas extra effort and added responsibility. This study concludes that even though\nthird-party reuse is commonplace, the practice of updating a dependency is not\nas common for many developers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fermionic Matrix Product States and One-Dimensional Short-Range Entangled Phases with Anti-Unitary Symmetries.   We extend the formalism of Matrix Product States (MPS) to describe\none-dimensional gapped systems of fermions with both unitary and anti-unitary\nsymmetries. Additionally, systems with orientation-reversing spatial symmetries\nare considered. The short-ranged entangled phases of such systems are\nclassified by three invariants, which characterize the projective action of the\nsymmetry on edge states. We give interpretations of these invariants as\nproperties of states on the closed chain. The relationship between fermionic\nMPS systems at an RG fixed point and equivariant algebras is exploited to\nderive a group law for the stacking of fermionic phases. The result generalizes\nknown classifications to symmetry groups that are non-trivial extensions of\nfermion parity and time-reversal.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Analysing Temporal Evolution of Interlingual Wikipedia Article Pairs.   Wikipedia articles representing an entity or a topic in different language\neditions evolve independently within the scope of the language-specific user\ncommunities. This can lead to different points of views reflected in the\narticles, as well as complementary and inconsistent information. An analysis of\nhow the information is propagated across the Wikipedia language editions can\nprovide important insights in the article evolution along the temporal and\ncultural dimensions and support quality control. To facilitate such analysis,\nwe present MultiWiki - a novel web-based user interface that provides an\noverview of the similarities and differences across the article pairs\noriginating from different language editions on a timeline. MultiWiki enables\nusers to observe the changes in the interlingual article similarity over time\nand to perform a detailed visual comparison of the article snapshots at a\nparticular time point.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Generative Models with Learnable Knowledge Constraints.   The broad set of deep generative models (DGMs) has achieved remarkable\nadvances. However, it is often difficult to incorporate rich structured domain\nknowledge with the end-to-end DGMs. Posterior regularization (PR) offers a\nprincipled framework to impose structured constraints on probabilistic models,\nbut has limited applicability to the diverse DGMs that can lack a Bayesian\nformulation or even explicit density evaluation. PR also requires constraints\nto be fully specified a priori, which is impractical or suboptimal for complex\nknowledge with learnable uncertain parts. In this paper, we establish\nmathematical correspondence between PR and reinforcement learning (RL), and,\nbased on the connection, expand PR to learn constraints as the extrinsic reward\nin RL. The resulting algorithm is model-agnostic to apply to any DGMs, and is\nflexible to adapt arbitrary constraints with the model jointly. Experiments on\nhuman image generation and templated sentence generation show models with\nlearned knowledge constraints by our algorithm greatly improve over base\ngenerative models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the complexity of the projective splitting and Spingarn's methods for the sum of two maximal monotone operators.   In this work we study the pointwise and ergodic iteration-complexity of a\nfamily of projective splitting methods proposed by Eckstein and Svaiter, for\nfinding a zero of the sum of two maximal monotone operators. As a consequence\nof the complexity analysis of the projective splitting methods, we obtain\ncomplexity bounds for the two-operator case of Spingarn's partial inverse\nmethod. We also present inexact variants of two specific instances of this\nfamily of algorithms, and derive corresponding convergence rate results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accumulation Bit-Width Scaling For Ultra-Low Precision Training Of Deep Networks.   Efforts to reduce the numerical precision of computations in deep learning\ntraining have yielded systems that aggressively quantize weights and\nactivations, yet employ wide high-precision accumulators for partial sums in\ninner-product operations to preserve the quality of convergence. The absence of\nany framework to analyze the precision requirements of partial sum\naccumulations results in conservative design choices. This imposes an\nupper-bound on the reduction of complexity of multiply-accumulate units. We\npresent a statistical approach to analyze the impact of reduced accumulation\nprecision on deep learning training. Observing that a bad choice for\naccumulation precision results in loss of information that manifests itself as\na reduction in variance in an ensemble of partial sums, we derive a set of\nequations that relate this variance to the length of accumulation and the\nminimum number of bits needed for accumulation. We apply our analysis to three\nbenchmark networks: CIFAR-10 ResNet 32, ImageNet ResNet 18 and ImageNet\nAlexNet. In each case, with accumulation precision set in accordance with our\nproposed equations, the networks successfully converge to the single precision\nfloating-point baseline. We also show that reducing accumulation precision\nfurther degrades the quality of the trained network, proving that our equations\nproduce tight bounds. Overall this analysis enables precise tailoring of\ncomputation hardware to the application, yielding area- and power-optimal\nsystems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Estimation of the asymptotic variance of univariate and multivariate random fields and statistical inference.   Correlated random fields are a common way to model dependence struc- tures in\nhigh-dimensional data, especially for data collected in imaging. One important\nparameter characterizing the degree of dependence is the asymp- totic variance\nwhich adds up all autocovariances in the temporal and spatial domain.\nEspecially, it arises in the standardization of test statistics based on\npartial sums of random fields and thus the construction of tests requires its\nestimation. In this paper we propose consistent estimators for this parameter\nfor strictly stationary {\\phi}-mixing random fields with arbitrary dimension of\nthe domain and taking values in a Euclidean space of arbitrary dimension, thus\nallowing for multivariate random fields. We establish consistency, provide cen-\ntral limit theorems and show that distributional approximations of related test\nstatistics based on sample autocovariances of random fields can be obtained by\nthe subsampling approach. As in applications the spatial-temporal correlations\nare often quite local, such that a large number of autocovariances vanish or\nare negligible, we also investigate a thresholding approach where sample\nautocovariances of small magnitude are omitted. Extensive simulation studies\nshow that the proposed estimators work well in practice and, when used to\nstandardize image test statistics, can provide highly accurate image testing\nprocedures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Family-specific scaling laws in bacterial genomes.   Among several quantitative invariants found in evolutionary genomics, one of\nthe most striking is the scaling of the overall abundance of proteins, or\nprotein domains, sharing a specific functional annotation across genomes of\ngiven size. The size of these functional categories change, on average, as\npower-laws in the total number of protein-coding genes. Here, we show that such\nregularities are not restricted to the overall behavior of high-level\nfunctional categories, but also exist systematically at the level of single\nevolutionary families of protein domains. Specifically, the number of proteins\nwithin each family follows family-specific scaling laws with genome size.\nFunctionally similar sets of families tend to follow similar scaling laws, but\nthis is not always the case. To understand this systematically, we provide a\ncomprehensive classification of families based on their scaling properties.\nAdditionally, we develop a quantitative score for the heterogeneity of the\nscaling of families belonging to a given category or predefined group. Under\nthe common reasonable assumption that selection is driven solely or mainly by\nbiological function, these findings point to fine-tuned and interdependent\nfunctional roles of specific protein domains, beyond our current functional\nannotations. This analysis provides a deeper view on the links between\nevolutionary expansion of protein families and the functional constraints\nshaping the gene repertoire of bacterial genomes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning Navigation Behaviors End to End.   A longstanding goal of behavior-based robotics is to solve high-level\nnavigation tasks using end to end navigation behaviors that directly map\nsensors to actions. Navigation behaviors, such as reaching a goal or following\na path without collisions, can be learned from exploration and interaction with\nthe environment, but are constrained by the type and quality of a robot's\nsensors, dynamics, and actuators. Traditional motion planning handles varied\nrobot geometry and dynamics, but typically assumes high-quality observations.\nModern vision-based navigation typically considers imperfect or partial\nobservations, but simplifies the robot action space. With both approaches, the\ntransition from simulation to reality can be difficult. Here, we learn two end\nto end navigation behaviors that avoid moving obstacles: point to point and\npath following. These policies receive noisy lidar observations and output\nrobot linear and angular velocities. We train these policies in small, static\nenvironments with Shaped-DDPG, an adaptation of the Deep Deterministic Policy\nGradient (DDPG) reinforcement learning method which optimizes reward and\nnetwork architecture. Over 500 meters of on-robot experiments show , these\npolicies generalize to new environments and moving obstacles, are robust to\nsensor, actuator, and localization noise, and can serve as robust building\nblocks for larger navigation tasks. The path following and point and point\npolicies are 83% and 56% more successful than the baseline, respectively.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Classification of Casimirs in 2D hydrodynamics.   We describe a complete list of Casimirs for 2D Euler hydrodynamics on a\nsurface without boundary: we define generalized enstrophies which, along with\ncirculations, form a complete set of invariants for coadjoint orbits of\narea-preserving diffeomorphisms on a surface. We also outline a possible\nextension of main notions to the boundary case and formulate several open\nquestions in that setting.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "On a backward problem for multidimensional Ginzburg-Landau equation with random data.   In this paper, we consider a backward in time problem for Ginzburg-Landau\nequation in multidimensional domain associated with some random data. The\nproblem is ill-posed in the sense of Hadamard. To regularize the instable\nsolution, we develop a new regularized method combined with statistical\napproach to solve this problem. We prove a upper bound, on the rate of\nconvergence of the mean integrated squared error in $L^2 $ norm and $H^1$ norm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "II-FCN for skin lesion analysis towards melanoma detection.   Dermoscopy image detection stays a tough task due to the weak distinguishable\nproperty of the object.Although the deep convolution neural network\nsignifigantly boosted the performance on prevelance computer vision tasks in\nrecent years,there remains a room to explore more robust and precise models to\nthe problem of low contrast image segmentation.Towards the challenge of Lesion\nSegmentation in ISBI 2017,we built a symmetrical identity inception fully\nconvolution network which is based on only 10 reversible inception blocks,every\nblock composed of four convolution branches with combination of different layer\ndepth and kernel size to extract sundry semantic features.Then we proposed an\napproximate loss function for jaccard index metrics to train our model.To\novercome the drawbacks of traditional convolution,we adopted the dilation\nconvolution and conditional random field method to rectify our segmentation.We\nalso introduced multiple ways to prevent the problem of overfitting.The\nexperimental results shows that our model achived jaccard index of 0.82 and\nkept learning from epoch to epoch.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SCRank: Spammer and Celebrity Ranking in Directed Social Networks.   Many online social networks allow directed edges: Alice can unilaterally add\nan \"edge\" to Bob, typically indicating interest in Bob or Bob's content,\nwithout Bob's permission or reciprocation. In directed social networks we\nobserve the rise of two distinctive classes of users: celebrities who accrue\nunreciprocated incoming links, and follow spammers, who generate unreciprocated\noutgoing links. Identifying users in these two classes is important for abuse\ndetection, user and content ranking, privacy choices, and other social network\nfeatures.\nIn this paper we develop SCRank, an iterative algorithm to identify such\nusers. We analyze SCRank both theoretically and experimentally. The\nspammer-celebrity definition is not amenable to analysis using standard power\niteration, so we develop a novel potential function argument to show\nconvergence to an approximate equilibrium point for a class of algorithms\nincluding SCRank. We then use experimental evaluation on a real global-scale\nsocial network and on synthetically generated graphs to observe that the\nalgorithm converges quickly and consistently. Using synthetic data with\nbuilt-in ground truth, we also experimentally show that the algorithm provides\na good approximation to planted celebrities and spammers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On topological obstructions to global stabilization of an inverted pendulum.   We consider a classical problem of control of an inverted pendulum by means\nof a horizontal motion of its pivot point. We suppose that the control law can\nbe non-autonomous and non-periodic w.r.t. the position of the pendulum. It is\nshown that global stabilization of the vertical upward position of the pendulum\ncannot be obtained for any Lipschitz control law, provided some natural\nassumptions. Moreover, we show that there always exists a solution separated\nfrom the vertical position and along which the pendulum never becomes\nhorizontal. Hence, we also prove that global stabilization cannot be obtained\nin the system where the pendulum can impact the horizontal plane (for any\nmechanical model of impact). Similar results are presented for several\nanalogous systems: a pendulum on a cart, a spherical pendulum, and a pendulum\nwith an additional torque control.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Regulating Highly Automated Robot Ecologies: Insights from Three User Studies.   Highly automated robot ecologies (HARE), or societies of independent\nautonomous robots or agents, are rapidly becoming an important part of much of\nthe world's critical infrastructure. As with human societies, regulation,\nwherein a governing body designs rules and processes for the society, plays an\nimportant role in ensuring that HARE meet societal objectives. However, to\ndate, a careful study of interactions between a regulator and HARE is lacking.\nIn this paper, we report on three user studies which give insights into how to\ndesign systems that allow people, acting as the regulatory authority, to\neffectively interact with HARE. As in the study of political systems in which\ngovernments regulate human societies, our studies analyze how interactions\nbetween HARE and regulators are impacted by regulatory power and individual\n(robot or agent) autonomy. Our results show that regulator power, decision\nsupport, and adaptive autonomy can each diminish the social welfare of HARE,\nand hint at how these seemingly desirable mechanisms can be designed so that\nthey become part of successful HARE.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "State-of-the-art Speech Recognition With Sequence-to-Sequence Models.   Attention-based encoder-decoder architectures such as Listen, Attend, and\nSpell (LAS), subsume the acoustic, pronunciation and language model components\nof a traditional automatic speech recognition (ASR) system into a single neural\nnetwork. In previous work, we have shown that such architectures are comparable\nto state-of-theart ASR systems on dictation tasks, but it was not clear if such\narchitectures would be practical for more challenging tasks such as voice\nsearch. In this work, we explore a variety of structural and optimization\nimprovements to our LAS model which significantly improve performance. On the\nstructural side, we show that word piece models can be used instead of\ngraphemes. We also introduce a multi-head attention architecture, which offers\nimprovements over the commonly-used single-head attention. On the optimization\nside, we explore synchronous training, scheduled sampling, label smoothing, and\nminimum word error rate optimization, which are all shown to improve accuracy.\nWe present results with a unidirectional LSTM encoder for streaming\nrecognition. On a 12, 500 hour voice search task, we find that the proposed\nchanges improve the WER from 9.2% to 5.6%, while the best conventional system\nachieves 6.7%; on a dictation task our model achieves a WER of 4.1% compared to\n5% for the conventional system.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Microscopic Conductivity of Lattice Fermions at Equilibrium - Part II: Interacting Particles.   We apply Lieb-Robinson bounds for multi-commutators we recently derived to\nstudy the (possibly non-linear) response of interacting fermions at thermal\nequilibrium to perturbations of the external electromagnetic field. This\nanalysis leads to an extension of the results for quasi-free fermions of\n\\cite{OhmI,OhmII} to fermion systems on the lattice with short-range\ninteractions. More precisely, we investigate entropy production and charge\ntransport properties of non-autonomous $C^{\\ast }$-dynamical systems associated\nwith interacting lattice fermions within bounded static potentials and in\npresence of an electric field that is time- and space-dependent. We verify the\n1st law of thermodynamics for the heat production of the system under\nconsideration. In linear response theory, the latter is related with Ohm and\nJoule's laws. These laws are proven here to hold at the microscopic scale,\nuniformly with respect to the size of the (microscopic) region where the\nelectric field is applied. An important outcome is the extension of the notion\nof conductivity measures to interacting fermions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Many cubic surfaces contain rational points.   Building on recent work of Bhargava--Elkies--Schnidman and Kriz--Li, we\nproduce infinitely many smooth cubic surfaces defined over the field of\nrational numbers that contain rational points.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Network of sensitive magnetometers for urban studies.   The magnetic signature of an urban environment is investigated using a\ngeographically distributed network of fluxgate magnetometers deployed in and\naround Berkeley, California. The system hardware and software are described and\nresults from initial operation of the network are reported. The sensors sample\nthe vector magnetic field with a 4 kHz resolution and are sensitive to\nfluctuations below 0.1 $\\textrm{nT}/\\sqrt{\\textrm{Hz}}$. Data from separate\nstations are synchronized to around $\\pm100$ $\\mu{s}$ using GPS and computer\nsystem clocks. Data from all sensors are automatically uploaded to a central\nserver. Anomalous events, such as lightning strikes, have been observed. A\nwavelet analysis is used to study observations over a wide range of temporal\nscales up to daily variations that show strong differences between weekend and\nweekdays. The Bay Area Rapid Transit (BART) is identified as the most dominant\nsignal from these observations and a superposed epoch analysis is used to study\nand extract the BART signal. Initial results of the correlation between sensors\nare also presented.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Cross-label Suppression: A Discriminative and Fast Dictionary Learning with Group Regularization.   This paper addresses image classification through learning a compact and\ndiscriminative dictionary efficiently. Given a structured dictionary with each\natom (columns in the dictionary matrix) related to some label, we propose\ncross-label suppression constraint to enlarge the difference among\nrepresentations for different classes. Meanwhile, we introduce group\nregularization to enforce representations to preserve label properties of\noriginal samples, meaning the representations for the same class are encouraged\nto be similar. Upon the cross-label suppression, we don't resort to\nfrequently-used $\\ell_0$-norm or $\\ell_1$-norm for coding, and obtain\ncomputational efficiency without losing the discriminative power for\ncategorization. Moreover, two simple classification schemes are also developed\nto take full advantage of the learnt dictionary. Extensive experiments on six\ndata sets including face recognition, object categorization, scene\nclassification, texture recognition and sport action categorization are\nconducted, and the results show that the proposed approach can outperform lots\nof recently presented dictionary algorithms on both recognition accuracy and\ncomputational efficiency.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Radially distributed values and normal families.   Let $L_0$ and $L_1$ be two distinct rays emanating from the origin and let\n${\\mathcal F}$ be the family of all functions holomorphic in the unit disk\n${\\mathbb D}$ for which all zeros lie on $L_0$ while all $1$-points lie on\n$L_1$. It is shown that ${\\mathcal F}$ is normal in ${\\mathbb\nD}\\backslash\\{0\\}$. The case where $L_0$ is the positive real axis and $L_1$ is\nthe negative real axis is studied in more detail.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Universal Constraints on the Location of Extrema of Eigenfunctions of Non-Local Schrödinger Operators.   We derive a lower bound on the location of global extrema of eigenfunctions\nfor a large class of non-local Schrödinger operators in convex domains under\nDirichlet exterior conditions, featuring the symbol of the kinetic term, the\nstrength of the potential, and the corresponding eigenvalue, and involving a\nnew universal constant. We show a number of probabilistic and spectral\ngeometric implications, and derive a Faber-Krahn type inequality for non-local\noperators. Our study also extends to potentials with compact support, and we\nestablish bounds on the location of extrema relative to the boundary edge of\nthe support or level sets around minima of the potential.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Continuous Beam Steering Slotted Waveguide Antenna Using Rotating Dielectric Slabs.   The design, simulation and measurement of a beam steerable slotted waveguide\nantenna operating in X band are presented. The proposed beam steerable antenna\nconsists of a standard rectangular waveguide (RWG) section with longitudinal\nslots in the broad wall. The beam steering in this configuration is achieved by\nrotating two dielectric slabs inside the waveguide and consequently changing\nthe phase of the slots excitations. In order to confirm the usefulness of this\nconcept, a non-resonant 20-slot waveguide array antenna with an element spacing\nof d = 0.58{\\lambda}0 has been designed, built and measured. A 14 deg beam\nscanning from near broadside ({\\theta} = 4 deg) toward end-fire ({\\theta} = 18\ndeg) direction is observed. The gain varies from 18.33 dB to 19.11 dB which\ncorresponds to the radiation efficiencies between 95% and 79%. The side-lobe\nlevel is -14 dB at the design frequency of 9.35 GHz. The simulated co-polarized\nrealized gain closely matches the fabricated prototype patterns.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning Wasserstein Embeddings.   The Wasserstein distance received a lot of attention recently in the\ncommunity of machine learning, especially for its principled way of comparing\ndistributions. It has found numerous applications in several hard problems,\nsuch as domain adaptation, dimensionality reduction or generative models.\nHowever, its use is still limited by a heavy computational cost. Our goal is to\nalleviate this problem by providing an approximation mechanism that allows to\nbreak its inherent complexity. It relies on the search of an embedding where\nthe Euclidean distance mimics the Wasserstein distance. We show that such an\nembedding can be found with a siamese architecture associated with a decoder\nnetwork that allows to move from the embedding space back to the original input\nspace. Once this embedding has been found, computing optimization problems in\nthe Wasserstein space (e.g. barycenters, principal directions or even\narchetypes) can be conducted extremely fast. Numerical experiments supporting\nthis idea are conducted on image datasets, and show the wide potential benefits\nof our method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Contraction and uniform convergence of isotonic regression.   We consider the problem of isotonic regression, where the underlying signal\n$x$ is assumed to satisfy a monotonicity constraint, that is, $x$ lies in the\ncone $\\{ x\\in\\mathbb{R}^n : x_1 \\leq \\dots \\leq x_n\\}$. We study the isotonic\nprojection operator (projection to this cone), and find a necessary and\nsufficient condition characterizing all norms with respect to which this\nprojection is contractive. This enables a simple and non-asymptotic analysis of\nthe convergence properties of isotonic regression, yielding uniform confidence\nbands that adapt to the local Lipschitz properties of the signal.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Moment conditions in strong laws of large numbers for multiple sums and random measures.   The validity of the strong law of large numbers for multiple sums $S_n$ of\nindependent identically distributed random variables $Z_k$, $k\\leq n$, with\n$r$-dimensional indices is equivalent to the integrability of\n$|Z|(\\log^+|Z|)^{r-1}$, where $Z$ is the typical summand. We consider the\nstrong law of large numbers for more general normalisations, without assuming\nthat the summands $Z_k$ are identically distributed, and prove a multiple sum\ngeneralisation of the Brunk--Prohorov strong law of large numbers. In the case\nof identical finite moments of irder $2q$ with integer $q\\geq1$, we show that\nthe strong law of large numbers holds with the normalisation $\\|n_1\\cdots\nn_r\\|^{1/2}(\\log n_1\\cdots\\log n_r)^{1/(2q)+\\varepsilon}$ for any\n$\\varepsilon>0$. The obtained results are also formulated in the setting of\nergodic theorems for random measures, in particular those generated by marked\npoint processes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Practical Bayesian Optimization for Transportation Simulators.   We provide a method to solve optimization problem when objective function is\na complex stochastic simulator of an urban transportation system. To reach this\ngoal, a Bayesian optimization framework is introduced. We show how the choice\nof prior and inference algorithm effect the outcome of our optimization\nprocedure. We develop dimensionality reduction techniques that allow for our\noptimization techniques to be applicable for real-life problems. We develop a\ndistributed, Gaussian Process Bayesian regression and active learning models\nthat allow parallel execution of our algorithms and enable usage of high\nperformance computing. We present a fully Bayesian approach that is more sample\nefficient and reduces computational budget. Our framework is supported by\ntheoretical analysis and an empirical study. We demonstrate our framework on\nthe problem of calibrating a multi-modal transportation network of city of\nBloomington, Illinois. Finally, we discuss directions for further research.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From acquaintance to best friend forever: robust and fine-grained inference of social tie strengths.   Social networks often provide only a binary perspective on social ties: two\nindividuals are either connected or not. While sometimes external information\ncan be used to infer the strength of social ties, access to such information\nmay be restricted or impractical. Sintos and Tsaparas (KDD 2014) first\nsuggested to infer the strength of social ties from the topology of the network\nalone, by leveraging the Strong Triadic Closure (STC) property. The STC\nproperty states that if person A has strong social ties with persons B and C, B\nand C must be connected to each other as well (whether with a weak or strong\ntie). Sintos and Tsaparas exploited this to formulate the inference of the\nstrength of social ties as NP-hard optimization problem, and proposed two\napproximation algorithms. We refine and improve upon this landmark paper, by\ndeveloping a sequence of linear relaxations of this problem that can be solved\nexactly in polynomial time. Usefully, these relaxations infer more fine-grained\nlevels of tie strength (beyond strong and weak), which also allows to avoid\nmaking arbitrary strong/weak strength assignments when the network topology\nprovides inconclusive evidence. One of the relaxations simultaneously infers\nthe presence of a limited number of STC violations. An extensive theoretical\nanalysis leads to two efficient algorithmic approaches. Finally, our\nexperimental results elucidate the strengths of the proposed approach, and\nsheds new light on the validity of the STC property in practice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning the Kernel for Classification and Regression.   We investigate a series of learning kernel problems with polynomial\ncombinations of base kernels, which will help us solve regression and\nclassification problems. We also perform some numerical experiments of\npolynomial kernels with regression and classification tasks on different\ndatasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal boundary gradient estimates for Lamé systems with partially infinite coefficients.   In this paper, we derive the pointwise upper bounds and lower bounds on the\ngradients of solutions to the Lamé systems with partially infinite\ncoefficients as the surface of discontinuity of the coefficients of the system\nis located very close to the boundary. When the distance tends to zero, the\noptimal blow-up rates of the gradients are established for inclusions with\narbitrary shapes and in all dimensions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A new, large-scale map of interstellar reddening derived from HI emission.   We present a new map of interstellar reddening, covering the 39\\% of the sky\nwith low {\\rm HI} column densities ($N_{\\rm HI} < 4\\times10^{20}\\,\\rm cm^{-2}$\nor $E(B-V)\\approx 45\\rm\\, mmag$) at $16\\overset{'}{.}1$ resolution, based on\nall-sky observations of Galactic HI emission by the HI4PI Survey. In this low\ncolumn density regime, we derive a characteristic value of $N_{\\rm HI}/E(B-V) =\n8.8\\times10^{21}\\, \\rm\\, cm^{2}\\, mag^{-1}$ for gas with $|v_{\\rm LSR}| <\n90\\,\\rm km\\, s^{-1}$ and find no significant reddening associated with gas at\nhigher velocities. We compare our HI-based reddening map with the Schlegel,\nFinkbeiner, and Davis (1998, SFD) reddening map and find them consistent to\nwithin a scatter of $\\simeq 5\\,\\rm mmag$. Further, the differences between our\nmap and the SFD map are in excellent agreement with the low resolution\n($4\\overset{\\circ}{.}5$) corrections to the SFD map derived by Peek and Graves\n(2010) based on observed reddening toward passive galaxies. We therefore argue\nthat our HI-based map provides the most accurate interstellar reddening\nestimates in the low column density regime to date. Our reddening map is made\npublicly available (this http URL).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Theoretical study of HfF$^+$ cation to search for the T,P-odd interactions.   The combined all-electron and two-step approach is applied to calculate the\nmolecular parameters which are required to interpret the ongoing experiment to\nsearch for the effects of manifestation of the T,P-odd fundamental interactions\nin the HfF$^+$ cation by Cornell/Ye group [Science 342, 1220 (2013); J. Mol.\nSpectrosc. 300, 12 (2014)]. The effective electric field that is required to\ninterpret the experiment in terms of the electron electric dipole moment is\nfound to be 22.5 GV/cm. In Ref. [Phys. Rev. D 89, 056006 (2014)] it was shown\nthat another source of T,P-odd interaction, the scalar-pseudoscalar\nnucleus-electron interaction with the dimensionless strength constant $k_{T,P}$\ncan dominate over the direct contribution from the electron EDM within the\nstandard model and some of its extensions. Therefore, for the comprehensive and\ncorrect interpretation of the HfF$^+$ experiment one should also know the\nmolecular parameter $W_{T,P}$ the value of which is reported here to be 20.1\nkHz.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Good Similar Patches for Image Denoising.   Patch-based denoising algorithms like BM3D have achieved outstanding\nperformance. An important idea for the success of these methods is to exploit\nthe recurrence of similar patches in an input image to estimate the underlying\nimage structures. However, in these algorithms, the similar patches used for\ndenoising are obtained via Nearest Neighbour Search (NNS) and are sometimes not\noptimal. First, due to the existence of noise, NNS can select similar patches\nwith similar noise patterns to the reference patch. Second, the unreliable\nnoisy pixels in digital images can bring a bias to the patch searching process\nand result in a loss of color fidelity in the final denoising result. We\nobserve that given a set of good similar patches, their distribution is not\nnecessarily centered at the noisy reference patch and can be approximated by a\nGaussian component. Based on this observation, we present a patch searching\nmethod that clusters similar patch candidates into patch groups using Gaussian\nMixture Model-based clustering, and selects the patch group that contains the\nreference patch as the final patches for denoising. We also use an unreliable\npixel estimation algorithm to pre-process the input noisy images to further\nimprove the patch searching. Our experiments show that our approach can better\ncapture the underlying patch structures and can consistently enable the\nstate-of-the-art patch-based denoising algorithms, such as BM3D, LPCA and PLOW,\nto better denoise images by providing them with patches found by our approach\nwhile without modifying these algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Integrating Lipschitzian Dynamical Systems using Piecewise Algorithmic Differentiation.   In this article we analyze a generalized trapezoidal rule for initial value\nproblems with piecewise smooth right hand side \\(F:\\R^n\\to\\R^n\\). When applied\nto such a problem the classical trapezoidal rule suffers from a loss of\naccuracy if the solution trajectory intersects a nondifferentiability of \\(F\\).\nThe advantage of the proposed generalized trapezoidal rule is threefold:\nFirstly we can achieve a higher convergence order than with the classical\nmethod. Moreover, the method is energy preserving for piecewise linear\nHamiltonian systems. Finally, in analogy to the classical case we derive a\nthird order interpolation polynomial for the numerical trajectory. In the\nsmooth case the generalized rule reduces to the classical one. Hence, it is a\nproper extension of the classical theory. An error estimator is given and\nnumerical results are presented.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Variational Autoencoders for Learning Latent Representations of Speech Emotion: A Preliminary Study.   Learning the latent representation of data in unsupervised fashion is a very\ninteresting process that provides relevant features for enhancing the\nperformance of a classifier. For speech emotion recognition tasks, generating\neffective features is crucial. Currently, handcrafted features are mostly used\nfor speech emotion recognition, however, features learned automatically using\ndeep learning have shown strong success in many problems, especially in image\nprocessing. In particular, deep generative models such as Variational\nAutoencoders (VAEs) have gained enormous success for generating features for\nnatural images. Inspired by this, we propose VAEs for deriving the latent\nrepresentation of speech signals and use this representation to classify\nemotions. To the best of our knowledge, we are the first to propose VAEs for\nspeech emotion classification. Evaluations on the IEMOCAP dataset demonstrate\nthat features learned by VAEs can produce state-of-the-art results for speech\nemotion classification.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Probing magnetism in the vortex phase of PuCoGa$_5$ by X-ray magnetic circular dichroism.   We have measured X-ray magnetic circular dichroism (XMCD) spectra at the Pu\n$M_{4,5}$ absorption edges from a newly-prepared high-quality single crystal of\nthe heavy fermion superconductor $^{242}$PuCoGa$_{5}$, exhibiting a critical\ntemperature $T_{c} = 18.7~{\\rm K}$. The experiment probes the vortex phase\nbelow $T_{c}$ and shows that an external magnetic field induces a Pu 5$f$\nmagnetic moment at 2 K equal to the temperature-independent moment measured in\nthe normal phase up to 300 K by a SQUID device. This observation is in\nagreement with theoretical models claiming that the Pu atoms in PuCoGa$_{5}$\nhave a nonmagnetic singlet ground state resulting from the hybridization of the\nconduction electrons with the intermediate-valence 5$f$ electronic shell.\nUnexpectedly, XMCD spectra show that the orbital component of the $5f$ magnetic\nmoment increases significantly between 30 and 2 K; the antiparallel spin\ncomponent increases as well, leaving the total moment practically constant. We\nsuggest that this indicates a low-temperature breakdown of the complete\nKondo-like screening of the local 5$f$ moment.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Scatteract: Automated extraction of data from scatter plots.   Charts are an excellent way to convey patterns and trends in data, but they\ndo not facilitate further modeling of the data or close inspection of\nindividual data points. We present a fully automated system for extracting the\nnumerical values of data points from images of scatter plots. We use deep\nlearning techniques to identify the key components of the chart, and optical\ncharacter recognition together with robust regression to map from pixels to the\ncoordinate system of the chart. We focus on scatter plots with linear scales,\nwhich already have several interesting challenges. Previous work has done fully\nautomatic extraction for other types of charts, but to our knowledge this is\nthe first approach that is fully automatic for scatter plots. Our method\nperforms well, achieving successful data extraction on 89% of the plots in our\ntest set.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A combinatorial model for the path fibration.   We introduce the abstract notion of a necklical set in order to describe a\nfunctorial combinatorial model of the path fibration over the geometric\nrealization of a path connected simplicial set. In particular, to any path\nconnected simplicial set $X$ we associate a necklical set\n$\\widehat{\\mathbf{\\Omega}}X$ such that its geometric realization\n$|\\widehat{\\mathbf{\\Omega}}X|$, a space built out of gluing cubical cells, is\nhomotopy equivalent to the based loop space on $|X|$ and the differential\ngraded module of chains $C_*(\\widehat{\\mathbf{\\Omega}}X)$ is a differential\ngraded associative algebra generalizing Adams' cobar construction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantized Minimum Error Entropy Criterion.   Comparing with traditional learning criteria, such as mean square error\n(MSE), the minimum error entropy (MEE) criterion is superior in nonlinear and\nnon-Gaussian signal processing and machine learning. The argument of the\nlogarithm in Renyis entropy estimator, called information potential (IP), is a\npopular MEE cost in information theoretic learning (ITL). The computational\ncomplexity of IP is however quadratic in terms of sample number due to double\nsummation. This creates computational bottlenecks especially for large-scale\ndatasets. To address this problem, in this work we propose an efficient\nquantization approach to reduce the computational burden of IP, which decreases\nthe complexity from O(N*N) to O (MN) with M << N. The new learning criterion is\ncalled the quantized MEE (QMEE). Some basic properties of QMEE are presented.\nIllustrative examples are provided to verify the excellent performance of QMEE.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Deep Networks from Noisy Labels with Dropout Regularization.   Large datasets often have unreliable labels-such as those obtained from\nAmazon's Mechanical Turk or social media platforms-and classifiers trained on\nmislabeled datasets often exhibit poor performance. We present a simple,\neffective technique for accounting for label noise when training deep neural\nnetworks. We augment a standard deep network with a softmax layer that models\nthe label noise statistics. Then, we train the deep network and noise model\njointly via end-to-end stochastic gradient descent on the (perhaps mislabeled)\ndataset. The augmented model is overdetermined, so in order to encourage the\nlearning of a non-trivial noise model, we apply dropout regularization to the\nweights of the noise model during training. Numerical experiments on noisy\nversions of the CIFAR-10 and MNIST datasets show that the proposed dropout\ntechnique outperforms state-of-the-art methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Divergence Bound for Hybrids of MCMC and Variational Inference and an Application to Langevin Dynamics and SGVI.   Two popular classes of methods for approximate inference are Markov chain\nMonte Carlo (MCMC) and variational inference. MCMC tends to be accurate if run\nfor a long enough time, while variational inference tends to give better\napproximations at shorter time horizons. However, the amount of time needed for\nMCMC to exceed the performance of variational methods can be quite high,\nmotivating more fine-grained tradeoffs. This paper derives a distribution over\nvariational parameters, designed to minimize a bound on the divergence between\nthe resulting marginal distribution and the target, and gives an example of how\nto sample from this distribution in a way that interpolates between the\nbehavior of existing methods based on Langevin dynamics and stochastic gradient\nvariational inference (SGVI).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Local asymptotic equivalence of pure quantum states ensembles and quantum Gaussian white noise.   Quantum technology is increasingly relying on specialised statistical\ninference methods for analysing quantum measurement data. This motivates the\ndevelopment of \"quantum statistics\", a field that is shaping up at the overlap\nof quantum physics and \"classical\" statistics. One of the less investigated\ntopics to date is that of statistical inference for infinite dimensional\nquantum systems, which can be seen as quantum counterpart of non-parametric\nstatistics. In this paper we analyse the asymptotic theory of quantum\nstatistical models consisting of ensembles of quantum systems which are\nidentically prepared in a pure state. In the limit of large ensembles we\nestablish the local asymptotic equivalence (LAE) of this i.i.d. model to a\nquantum Gaussian white noise model. We use the LAE result in order to establish\nminimax rates for the estimation of pure states belonging to Hermite-Sobolev\nclasses of wave functions. Moreover, for quadratic functional estimation of the\nsame states we note an elbow effect in the rates, whereas for testing a pure\nstate a sharp parametric rate is attained over the nonparametric\nHermite-Sobolev class.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Dark matter spin determination with directional direct detection experiments.   If the dark matter particle has spin 0, only two types of WIMP-nucleon\ninteraction can arise from the non-relativistic reduction of renormalisable\nsingle-mediator models for dark matter-quark interactions. Based on this\ncrucial observation, we show that about 100 signal events at next generation\ndirectional detection experiments can be enough to enable a $2\\sigma$ rejection\nof the spin 0 dark matter hypothesis in favour of alternative hypotheses where\nthe dark matter particle has spin 1/2 or 1. In this context directional\nsensitivity is crucial, since anisotropy patterns in the sphere of nuclear\nrecoil directions depend on the spin of the dark matter particle. For\ncomparison, about 100 signal events are expected in a CF$_4$ detector operating\nat a pressure of 30 torr with an exposure of approximately 26,000\ncubic-meter-detector days for WIMPs of 100 GeV mass and a WIMP-Fluorine\nscattering cross-section of 0.25 pb. Comparable exposures are within reach of\nan array of cubic meter time projection chamber detectors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Class-Splitting Generative Adversarial Networks.   Generative Adversarial Networks (GANs) produce systematically better quality\nsamples when class label information is provided., i.e. in the conditional GAN\nsetup. This is still observed for the recently proposed Wasserstein GAN\nformulation which stabilized adversarial training and allows considering high\ncapacity network architectures such as ResNet. In this work we show how to\nboost conditional GAN by augmenting available class labels. The new classes\ncome from clustering in the representation space learned by the same GAN model.\nThe proposed strategy is also feasible when no class information is available,\ni.e. in the unsupervised setup. Our generated samples reach state-of-the-art\nInception scores for CIFAR-10 and STL-10 datasets in both supervised and\nunsupervised setup.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam.   Uncertainty computation in deep learning is essential to design robust and\nreliable systems. Variational inference (VI) is a promising approach for such\ncomputation, but requires more effort to implement and execute compared to\nmaximum-likelihood methods. In this paper, we propose new natural-gradient\nalgorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms\ncan be implemented within the Adam optimizer by perturbing the network weights\nduring gradient evaluations, and uncertainty estimates can be cheaply obtained\nby using the vector that adapts the learning rate. This requires lower memory,\ncomputation, and implementation effort than existing VI methods, while\nobtaining uncertainty estimates of comparable quality. Our empirical results\nconfirm this and further suggest that the weight-perturbation in our algorithm\ncould be useful for exploration in reinforcement learning and stochastic\noptimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Long ties accelerate noisy threshold-based contagions.   Changes to network structure can substantially affect when and how widely new\nideas, products, and conventions are adopted. In models of biological\ncontagion, interventions that randomly rewire edges (making them \"longer\")\naccelerate spread. However, there are other models relevant to social\ncontagion, such as those motivated by myopic best-response in games with\nstrategic complements, in which individual's behavior is described by a\nthreshold number of adopting neighbors above which adoption occurs (i.e.,\ncomplex contagions). Recent work has argued that highly clustered, rather than\nrandom, networks facilitate spread of these complex contagions. Here we show\nthat minor modifications of prior analyses, which make them more realistic,\nreverse this result. The modification is that we allow very rarely below\nthreshold adoption, i.e., very rarely adoption occurs, where there is only one\nadopting neighbor. To model the trade-off between long and short edges we\nconsider networks that are the union of cycle-power-$k$ graphs and random\ngraphs on $n$ nodes. We study how the time to global spread changes as we\nreplace the cycle edges with (random) long ties. Allowing adoptions below\nthreshold to occur with order $1/\\sqrt{n}$ probability is enough to ensure that\nrandom rewiring accelerates spread. Simulations illustrate the robustness of\nthese results to other commonly-posited models for noisy best-response\nbehavior. We then examine empirical social networks, where we find that\nhypothetical interventions that (a) randomly rewire existing edges or (b) add\nrandom edges reduce time to spread compared with the original network or\naddition of \"short\", triad-closing edges, respectively. This substantially\nrevises conclusions about how interventions change the spread of behavior,\nsuggesting that those wanting to increase spread should induce formation of\nlong ties, rather than triad-closing ties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fluid-Structure Interaction with the Entropic Lattice Boltzmann Method.   We propose a novel fluid-structure interaction (FSI) scheme using the\nentropic multi-relaxation time lattice Boltzmann (KBC) model for the fluid\ndomain in combination with a nonlinear finite element solver for the structural\npart. We show validity of the proposed scheme for various challenging set-ups\nby comparison to literature data. Beyond validation, we extend the KBC model to\nmultiphase flows and couple it with FEM solver. Robustness and viability of the\nentropic multi-relaxation time model for complex FSI applications is shown by\nsimulations of droplet impact on elastic superhydrophobic surfaces.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Analysis and Control of a Non-Standard Hyperbolic PDE Traffic Flow Model.   The paper provides results for a non-standard, hyperbolic, 1-D, nonlinear\ntraffic flow model on a bounded domain. The model consists of two first-order\nPDEs with a dynamic boundary condition that involves the time derivative of the\nvelocity. The proposed model has features that are important from a\ntraffic-theoretic point of view: is completely anisotropic and information\ntravels forward exactly at the same speed as traffic. It is shown that, for all\nphysically meaningful initial conditions, the model admits a globally defined,\nunique, classical solution that remains positive and bounded for all times.\nMoreover, it is shown that global stabilization can be achieved for arbitrary\nequilibria by means of an explicit boundary feedback law. The stabilizing\nfeedback law depends only on the inlet velocity and consequently, the\nmeasurement requirements for the implementation of the proposed boundary\nfeedback law are minimal. The efficiency of the proposed boundary feedback law\nis demonstrated by means of a numerical example.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Equilibrium distributions and discrete Schur-constant models.   This paper introduces Schur-constant equilibrium distribution models of\ndimension n for arithmetic non-negative random variables. Such a model is\ndefined through the (several orders) equilibrium distributions of a univariate\nsurvival function. First, the bivariate case is considered and analyzed in\ndepth, stressing the main characteristics of the Poisson case. The analysis is\nthen extended to the multivariate case. Several properties are derived,\nincluding the implicit correlation and the distribution of the sum.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributive Minimization Comprehensions and the Polynomial Hierarchy.   A categorical point of view about minimization in subrecursive classes is\npresented by extending the concept of Symmetric Monoidal Comprehension to that\nof Distributive Minimization Comprehension. This is achieved by endowing the\nformer with coproducts and a finality condition for coalgebras over the\nendofunctor sending X to ${1}\\oplus{X}$ to perform a safe minimization\noperator. By relying on the characterization given by Bellantoni, a tiered\nstructure is presented from which one can obtain the levels of the Polytime\nHierarchy as those classes of partial functions obtained after a certain number\nof minimizations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phase transitions of the dimerized Kane-Mele model with/without the strong interaction.   The dimerized Kane-Mele model with/without the strong interaction is studied\nusing analytical methods. The boundary of the topological phase transition of\nthe model without strong interaction is obtained. Our results show that the\noccurrence of the transition only depends on dimerized parameter . From the\none-particle spectrum, we obtain the completed phase diagram including the\nquantum spin Hall (QSH) state and the topologically trivial insulator. Then,\nusing different mean-field methods, we investigate the Mott transition and the\nmagnetic transition of the strongly correlated dimerized Kane-Mele model. In\nthe region between the two transitions, the topological Mott insulator (TMI)\nwith characters of Mott insulators and topological phases may be the most\ninteresting phase. In this work, effects of the hopping anisotropy and Hubbard\ninteraction U on boundaries of the two transitions are observed in detail. The\ncompleted phase diagram of the dimerized Kane-Mele-Hubbard model is also\nobtained in this work. Quantum fluctuations have extremely important influences\non a quantum system. However, investigations are under the framework of the\nmean field treatment in this work and the effects of fluctuations in this model\nwill be discussed in the future.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Explaining Parochialism: A Causal Account for Political Polarization in Changing Economic Environments.   Political and social polarization are a significant cause of conflict and\npoor governance in many societies, thus understanding their causes is of\nconsiderable importance. Here we demonstrate that shifts in socialization\nstrategy similar to political polarization and/or identity politics could be a\nconstructive response to periods of apparent economic decline. We start from\nthe observation that economies, like ecologies are seldom at equilibrium.\nRather, they often suffer both negative and positive shocks. We show that even\nwhere in an expanding economy, interacting with diverse out-groups can afford\nbenefits through innovation and exploration, if that economy contracts, a\nstrategy of seeking homogeneous groups can be important to maintaining\nindividual solvency. This is true even where the expected value of out group\ninteraction exceeds that of in group interactions. Our account unifies what\nwere previously seen as conflicting explanations: identity threat versus\neconomic anxiety. Our model indicates that in periods of extreme deprivation,\ncooperation with diversity again becomes the best (in fact, only viable)\nstrategy. However, our model also shows that while polarization may increase\ngradually in response to shifts in the economy, gradual decrease of\npolarization may not be an available strategy; thus returning to previous\nlevels of cooperation may require structural change.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiple Hypothesis Tracking Algorithm for Multi-Target Multi-Camera Tracking with Disjoint Views.   In this study, a multiple hypothesis tracking (MHT) algorithm for\nmulti-target multi-camera tracking (MCT) with disjoint views is proposed. Our\nmethod forms track-hypothesis trees, and each branch of them represents a\nmulti-camera track of a target that may move within a camera as well as move\nacross cameras. Furthermore, multi-target tracking within a camera is performed\nsimultaneously with the tree formation by manipulating a status of each track\nhypothesis. Each status represents three different stages of a multi-camera\ntrack: tracking, searching, and end-of-track. The tracking status means targets\nare tracked by a single camera tracker. In the searching status, the\ndisappeared targets are examined if they reappear in other cameras. The\nend-of-track status does the target exited the camera network due to its\nlengthy invisibility. These three status assists MHT to form the\ntrack-hypothesis trees for multi-camera tracking. Furthermore, they present a\ngating technique for eliminating of unlikely observation-to-track association.\nIn the experiments, they evaluate the proposed method using two datasets,\nDukeMTMC and NLPR-MCT, which demonstrates that the proposed method outperforms\nthe state-of-the-art method in terms of improvement of the accuracy. In\naddition, they show that the proposed method can operate in real-time and\nonline.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adversarially Regularized Graph Autoencoder for Graph Embedding.   Graph embedding is an effective method to represent graph data in a low\ndimensional space for graph analytics. Most existing embedding algorithms\ntypically focus on preserving the topological structure or minimizing the\nreconstruction errors of graph data, but they have mostly ignored the data\ndistribution of the latent codes from the graphs, which often results in\ninferior embedding in real-world graph data. In this paper, we propose a novel\nadversarial graph embedding framework for graph data. The framework encodes the\ntopological structure and node content in a graph to a compact representation,\non which a decoder is trained to reconstruct the graph structure. Furthermore,\nthe latent representation is enforced to match a prior distribution via an\nadversarial training scheme. To learn a robust embedding, two variants of\nadversarial approaches, adversarially regularized graph autoencoder (ARGA) and\nadversarially regularized variational graph autoencoder (ARVGA), are developed.\nExperimental studies on real-world graphs validate our design and demonstrate\nthat our algorithms outperform baselines by a wide margin in link prediction,\ngraph clustering, and graph visualization tasks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "T-duality in rational homotopy theory via $L_\\infty$-algebras.   We combine Sullivan models from rational homotopy theory with Stasheff's\n$L_\\infty$-algebras to describe a duality in string theory. Namely, what in\nstring theory is known as topological T-duality between $K^0$-cocycles in type\nIIA string theory and $K^1$-cocycles in type IIB string theory, or as Hori's\nformula, can be recognized as a Fourier-Mukai transform between twisted\ncohomologies when looked through the lenses of rational homotopy theory. We\nshow this as an example of topological T-duality in rational homotopy theory,\nwhich in turn can be completely formulated in terms of morphisms of\n$L_\\infty$-algebras.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "PPMF: A Patient-based Predictive Modeling Framework for Early ICU Mortality Prediction.   To date, developing a good model for early intensive care unit (ICU)\nmortality prediction is still challenging. This paper presents a patient based\npredictive modeling framework (PPMF) to improve the performance of ICU\nmortality prediction using data collected during the first 48 hours of ICU\nadmission. PPMF consists of three main components verifying three related\nresearch hypotheses. The first component captures dynamic changes of patients\nstatus in the ICU using their time series data (e.g., vital signs and\nlaboratory tests). The second component is a local approximation algorithm that\nclassifies patients based on their similarities. The third component is a\nGradient Decent wrapper that updates feature weights according to the\nclassification feedback. Experiments using data from MIMICIII show that PPMF\nsignificantly outperforms: (1) the severity score systems, namely SASP III,\nAPACHE IV, and MPM0III, (2) the aggregation based classifiers that utilize\nsummarized time series, and (3) baseline feature selection methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From Attention to Participation: Reviewing and Modelling Engagement with Computers.   Over the last decades, the Internet and mobile technology have consolidated\nthe digital as a public sphere of life. Designers are asked to create engaging\ndigital experiences. However, in some cases engagement is seen as a\npsychological state, while in others it emphasizes a participative vein. In\nthis paper, I review and discuss both and propose a new definition to clarify\nthe concept engagement with computers. Thus, engagement is a quality of an\nactive connection between a user and a computing product, either a website or a\nmobile phone app. Studying it requires understanding a set of aspects like the\nuser's affect, motivation and attention, as well as the product's design,\ncontent and composition. Finally, I propose explaining these concepts aligned\nwith engagement and integrate them into a preliminary model to measure the\nmanifestations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mixed one-bit compressive sensing with applications to overexposure correction for CT reconstruction.   When a measurement falls outside the quantization or measurable range, it\nbecomes saturated and cannot be used in classical reconstruction methods. For\nexample, in C-arm angiography systems, which provide projection radiography,\nfluoroscopy, digital subtraction angiography, and are widely used for medical\ndiagnoses and interventions, the limited dynamic range of C-arm flat detectors\nleads to overexposure in some projections during an acquisition, such as\nimaging relatively thin body parts (e.g., the knee). Aiming at overexposure\ncorrection for computed tomography (CT) reconstruction, we in this paper\npropose a mixed one-bit compressive sensing (M1bit-CS) to acquire information\nfrom both regular and saturated measurements. This method is inspired by the\nrecent progress on one-bit compressive sensing, which deals with only sign\nobservations. Its successful applications imply that information carried by\nsaturated measurements is useful to improve recovery quality. For the proposed\nM1bit-CS model, alternating direction methods of multipliers is developed and\nan iterative saturation detection scheme is established. Then we evaluate\nM1bit-CS on one-dimensional signal recovery tasks. In some experiments, the\nperformance of the proposed algorithms on mixed measurements is almost the same\nas recovery on unsaturated ones with the same amount of measurements. Finally,\nwe apply the proposed method to overexposure correction for CT reconstruction\non a phantom and a simulated clinical image. The results are promising, as the\ntypical streaking artifacts and capping artifacts introduced by saturated\nprojection data are effectively reduced, yielding significant error reduction\ncompared with existing algorithms based on extrapolation.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Probabilistic Forwarding of Coded Packets on Networks.   We consider a scenario of broadcasting information over a network of nodes\nconnected by noiseless communication links. A source node in the network has\n$k$ data packets to broadcast, and it suffices that a large fraction of the\nnetwork nodes receives the broadcast. The source encodes the $k$ data packets\ninto $n \\ge k$ coded packets using a maximum distance separable (MDS) code, and\ntransmits them to its one-hop neighbours. Every other node in the network\nfollows a probabilistic forwarding protocol, in which it forwards a previously\nunreceived packet to all its neighbours with a certain probability $p$. A\n\"near-broadcast\" is when the expected fraction of nodes that receive at least\n$k$ of the $n$ coded packets is close to $1$. The forwarding probability $p$ is\nchosen so as to minimize the expected total number of transmissions needed for\na near-broadcast. In this paper, we analyze the probabilistic forwarding of\ncoded packets on two specific network topologies: binary trees and square\ngrids. For trees, our analysis shows that for fixed $k$, the expected total\nnumber of transmissions increases with $n$. On the other hand, on grids, we use\nideas from percolation theory to show that a judicious choice of $n$ will\nsignificantly reduce the expected total number of transmissions needed for a\nnear-broadcast.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detecting Qualia in Natural and Artificial Agents.   The Hard Problem of consciousness has been dismissed as an illusion. By\nshowing that computers are capable of experiencing, we show that they are at\nleast rudimentarily conscious with potential to eventually reach\nsuperconsciousness. The main contribution of the paper is a test for confirming\ncertain subjective experiences in a tested agent. We follow with analysis of\nbenefits and problems with conscious machines and implications of such\ncapability on future of computing, machine rights and artificial intelligence\nsafety.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effect of stellar flares on the upper atmospheres of HD 189733b and HD 209458b.   Stellar flares are a frequent occurrence on young low-mass stars around which\nmany detected exoplanets orbit. Flares are energetic, impulsive events, and\ntheir impact on exoplanetary atmospheres needs to be taken into account when\ninterpreting transit observations. We have developed a model to describe the\nupper atmosphere of Extrasolar Giant Planets (EGPs) orbiting flaring stars. The\nmodel simulates thermal escape from the upper atmospheres of close-in EGPs.\nIonisation by solar radiation and electron impact is included and photochemical\nand diffusive transport processes are simulated. This model is used to study\nthe effect of stellar flares from the solar-like G star HD209458 and the young\nK star HD189733 on their respective planets. A hypothetical HD209458b-like\nplanet orbiting the active M star AU Mic is also simulated. We find that the\nneutral upper atmosphere of EGPs is not significantly affected by typical\nflares. Therefore, stellar flares alone would not cause large enough changes in\nplanetary mass loss to explain the variations in HD189733b transit depth seen\nin previous studies, although we show that it may be possible that an extreme\nstellar proton event could result in the required mass loss. Our simulations do\nhowever reveal an enhancement in electron number density in the ionosphere of\nthese planets, the peak of which is located in the layer where stellar X-rays\nare absorbed. Electron densities are found to reach 2.2 to 3.5 times pre-flare\nlevels and enhanced electron densities last from about 3 to 10 hours after the\nonset of the flare. The strength of the flare and the width of its spectral\nenergy distribution affect the range of altitudes that see enhancements in\nionisation. A large broadband continuum component in the XUV portion of the\nflaring spectrum in very young flare stars, such as AU Mic, results in a broad\nrange of altitudes affected in planets orbiting this star.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Mathematical Knowledge and the Role of an Observer: Ontological and epistemological aspects.   As David Berlinski writes (1997), the existence and nature of mathematics is\na more compelling and far deeper problem than any of the problems raised by\nmathematics itself. Here we analyze the essence of mathematics making the main\nemphasis on mathematics as an advanced system of knowledge. This knowledge\nconsists of structures and represents structures, existence of which depends on\nobservers in a nonstandard way. Structural nature of mathematics explains its\nreasonable effectiveness.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "DeepProbe: Information Directed Sequence Understanding and Chatbot Design via Recurrent Neural Networks.   Information extraction and user intention identification are central topics\nin modern query understanding and recommendation systems. In this paper, we\npropose DeepProbe, a generic information-directed interaction framework which\nis built around an attention-based sequence to sequence (seq2seq) recurrent\nneural network. DeepProbe can rephrase, evaluate, and even actively ask\nquestions, leveraging the generative ability and likelihood estimation made\npossible by seq2seq models. DeepProbe makes decisions based on a derived\nuncertainty (entropy) measure conditioned on user inputs, possibly with\nmultiple rounds of interactions. Three applications, namely a rewritter, a\nrelevance scorer and a chatbot for ad recommendation, were built around\nDeepProbe, with the first two serving as precursory building blocks for the\nthird. We first use the seq2seq model in DeepProbe to rewrite a user query into\none of standard query form, which is submitted to an ordinary recommendation\nsystem. Secondly, we evaluate DeepProbe's seq2seq model-based relevance\nscoring. Finally, we build a chatbot prototype capable of making active user\ninteractions, which can ask questions that maximize information gain, allowing\nfor a more efficient user intention idenfication process. We evaluate first two\napplications by 1) comparing with baselines by BLEU and AUC, and 2) human judge\nevaluation. Both demonstrate significant improvements compared with current\nstate-of-the-art systems, proving their values as useful tools on their own,\nand at the same time laying a good foundation for the ongoing chatbot\napplication.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quasi Maximum-Likelihood Estimation of Dynamic Panel Data Models.   This paper establishes the almost sure convergence and asymptotic normality\nof levels and differenced quasi maximum-likelihood (QML) estimators of dynamic\npanel data models. The QML estimators are robust with respect to initial\nconditions, conditional and time-series heteroskedasticity, and\nmisspecification of the log-likelihood. The paper also provides an ECME\nalgorithm for calculating levels QML estimates. Finally, it uses Monte Carlo\nexperiments to compare the finite sample performance of levels and differenced\nQML estimators, the differenced GMM estimator, and the system GMM estimator. In\nthese experiments the QML estimators usually have smaller --- typically\nsubstantially smaller --- bias and root mean squared errors than the panel data\nGMM estimators.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coarse Grained Parallel Selection.   We analyze the running time of the Saukas-Song algorithm for selection on a\ncoarse grained multicomputer without expressing the running time in terms of\ncommunication rounds. This shows that while in the best case the Saukas-Song\nalgorithm runs in asymptotically optimal time, in general it does not. We\npropose other algorithms for coarse grained selection that have optimal\nexpected running time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Cross-section of a Spherical Double Cone.   We show that the poset of $SL(n)$-orbit closures in the product of two\npartial flag varieties is a lattice if the action of $SL(n)$ is spherical.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Full Quantification of Left Ventricle via Deep Multitask Learning Network Respecting Intra- and Inter-Task Relatedness.   Cardiac left ventricle (LV) quantification is among the most clinically\nimportant tasks for identification and diagnosis of cardiac diseases, yet still\na challenge due to the high variability of cardiac structure and the complexity\nof temporal dynamics. Full quantification, i.e., to simultaneously quantify all\nLV indices including two areas (cavity and myocardium), six regional wall\nthicknesses (RWT), three LV dimensions, and one cardiac phase, is even more\nchallenging since the uncertain relatedness intra and inter each type of\nindices may hinder the learning procedure from better convergence and\ngeneralization. In this paper, we propose a newly-designed multitask learning\nnetwork (FullLVNet), which is constituted by a deep convolution neural network\n(CNN) for expressive feature embedding of cardiac structure; two followed\nparallel recurrent neural network (RNN) modules for temporal dynamic modeling;\nand four linear models for the final estimation. During the final estimation,\nboth intra- and inter-task relatedness are modeled to enforce improvement of\ngeneralization: 1) respecting intra-task relatedness, group lasso is applied to\neach of the regression tasks for sparse and common feature selection and\nconsistent prediction; 2) respecting inter-task relatedness, three phase-guided\nconstraints are proposed to penalize violation of the temporal behavior of the\nobtained LV indices. Experiments on MR sequences of 145 subjects show that\nFullLVNet achieves high accurate prediction with our intra- and inter-task\nrelatedness, leading to MAE of 190mm$^2$, 1.41mm, 2.68mm for average areas,\nRWT, dimensions and error rate of 10.4\\% for the phase classification. This\nendows our method a great potential in comprehensive clinical assessment of\nglobal, regional and dynamic cardiac function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fabrication of antenna-coupled KID array for Cosmic Microwave Background detection.   Kinetic Inductance Detectors (KIDs) have become an attractive alternative to\ntraditional bolometers in the sub-mm and mm observing community due to their\ninnate frequency multiplexing capabilities and simple lithographic processes.\nThese advantages make KIDs a viable option for the $O(500,000)$ detectors\nneeded for the upcoming Cosmic Microwave Background - Stage 4 (CMB-S4)\nexperiment. We have fabricated antenna-coupled MKID array in the 150GHz band\noptimized for CMB detection. Our design uses a twin slot antenna coupled to\ninverted microstrip made from a superconducting Nb/Al bilayer and SiN$_x$,\nwhich is then coupled to an Al KID grown on high resistivity Si. We present the\nfabrication process and measurements of SiN$_x$ microstrip resonators.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Core of communities in bipartite networks.   We use the information present in a bipartite network to detect cores of\ncommunities of each set of the bipartite system. Cores of communities are found\nby investigating statistically validated projected networks obtained using\ninformation present in the bipartite network. Cores of communities are highly\ninformative and robust with respect to the presence of errors or missing\nentries in the bipartite network. We assess the statistical robustness of cores\nby investigating an artificial benchmark network, the co-authorship network,\nand the actor-movie network. The accuracy and precision of the partition\nobtained with respect to the reference partition are measured in terms of the\nadjusted Rand index and of the adjusted Wallace index respectively. The\ndetection of cores is highly precise although the accuracy of the methodology\ncan be limited in some cases.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Four-dimensional Lens Space Index from Two-dimensional Chiral Algebra.   We study the supersymmetric partition function on $S^1 \\times L(r, 1)$, or\nthe lens space index of four-dimensional $\\mathcal{N}=2$ superconformal field\ntheories and their connection to two-dimensional chiral algebras. We primarily\nfocus on free theories as well as Argyres-Douglas theories of type $(A_1, A_k)$\nand $(A_1, D_k)$. We observe that in specific limits, the lens space index is\nreproduced in terms of the (refined) character of an appropriately twisted\nmodule of the associated two-dimensional chiral algebra or a generalized vertex\noperator algebra. The particular twisted module is determined by the choice of\ndiscrete holonomies for the flavor symmetry in four-dimensions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convexity in scientific collaboration networks.   Convexity in a network (graph) has been recently defined as a property of\neach of its subgraphs to include all shortest paths between the nodes of that\nsubgraph. It can be measured on the scale [0, 1] with 1 being assigned to fully\nconvex networks. The largest convex component of a graph that emerges after the\nremoval of the least number of edges is called a convex skeleton. It is\nbasically a tree of cliques, which has been shown to have many interesting\nfeatures. In this article the notions of convexity and convex skeletons in the\ncontext of scientific collaboration networks are discussed. More specifically,\nwe analyze the co-authorship networks of Slovenian researchers in computer\nscience, physics, sociology, mathematics, and economics and extract convex\nskeletons from them. We then compare these convex skeletons with the residual\ngraphs (remainders) in terms of collaboration frequency distributions by\nvarious parameters such as the publication year and type, co-authors' birth\nyear, status, gender, discipline, etc. We also show the top-ranked scientists\nby four basic centrality measures as calculated on the original networks and\ntheir skeletons and conclude that convex skeletons may help detect influential\nscholars that are hardly identifiable in the original collaboration network. As\ntheir inherent feature, convex skeletons retain the properties of collaboration\nnetworks. These include high-level structural properties but also the fact that\nthe same authors are highlighted by centrality measures. Moreover, the most\nimportant ties and thus the most important collaborations are retained in the\nskeletons.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Batch-Incremental Video Background Estimation Model using Weighted Low-Rank Approximation of Matrices.   Principal component pursuit (PCP) is a state-of-the-art approach for\nbackground estimation problems. Due to their higher computational cost, PCP\nalgorithms, such as robust principal component analysis (RPCA) and its\nvariants, are not feasible in processing high definition videos. To avoid the\ncurse of dimensionality in those algorithms, several methods have been proposed\nto solve the background estimation problem in an incremental manner. We propose\na batch-incremental background estimation model using a special weighted\nlow-rank approximation of matrices. Through experiments with real and synthetic\nvideo sequences, we demonstrate that our method is superior to the\nstate-of-the-art background estimation algorithms such as GRASTA, ReProCS,\nincPCP, and GFL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A cyclic system with delay and its characteristic equation.   A nonlinear cyclic system with delay and the overall negative feedback is\nconsidered. The characteristic equation of the linearized system is studied in\ndetail. Sufficient conditions for the oscillation of all solutions and for the\nexistence of monotone solutions are derived in terms of roots of the\ncharacteristic equation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Small Resolution Proofs for QBF using Dependency Treewidth.   In spite of the close connection between the evaluation of quantified Boolean\nformulas (QBF) and propositional satisfiability (SAT), tools and techniques\nwhich exploit structural properties of SAT instances are known to fail for QBF.\nThis is especially true for the structural parameter treewidth, which has\nallowed the design of successful algorithms for SAT but cannot be\nstraightforwardly applied to QBF since it does not take into account the\ninterdependencies between quantified variables.\nIn this work we introduce and develop dependency treewidth, a new structural\nparameter based on treewidth which allows the efficient solution of QBF\ninstances. Dependency treewidth pushes the frontiers of tractability for QBF by\novercoming the limitations of previously introduced variants of treewidth for\nQBF. We augment our results by developing algorithms for computing the\ndecompositions that are required to use the parameter.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "21 cm Angular Power Spectrum from Minihalos as a Probe of Primordial Spectral Runnings.   Measurements of 21 cm line fluctuations from minihalos have been discussed as\na powerful probe of a wide range of cosmological models. However, previous\nstudies have taken into account only the pixel variance, where contributions\nfrom different scales are integrated. In order to sort out information from\ndifferent scales, we formulate the angular power spectrum of 21 cm line\nfluctuations from minihalos at different redshifts, which can enhance the\nconstraining power enormously. By adopting this formalism, we investigate\nexpected constraints on parameters characterizing the primordial power\nspectrum, particularly focusing on the spectral index $n_s$ and its runnings\n$\\alpha_s$ and $\\beta_s$. We show that future observations of 21 cm line\nfluctuations from minihalos, in combination with cosmic microwave background,\ncan potentially probe these runnings as $\\alpha_s \\sim {\\cal O}(10^{-3})$ and\n$\\beta_s \\sim {\\cal O}(10^{-4})$. Its implications to the test of inflationary\nmodels are also discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Regular characters of classical groups over complete discrete valuation rings.   Let $\\mathfrak{o}$ be a complete discrete valuation ring with finide residue\nfield $\\mathsf{k}$ of odd characteristic, and let $\\mathbf{G}$ be a symplectic\nor special orthogonal group scheme over $\\mathfrak{o}$. For any\n$\\ell\\in\\mathbb{N}$ let $G^\\ell$ denote the $\\ell$-th principal congruence\nsubgroup of $\\mathbf{G}(\\mathfrak{o})$. An irreducible character of the group\n$\\mathbf{G}(\\mathfrak{o})$ is said to be regular if it is trivial on a subgroup\n$G^{\\ell+1}$ for some $\\ell$, and if its restriction to\n$G^\\ell/G^{\\ell+1}\\simeq \\mathrm{Lie}(\\mathbf{G})(\\mathsf{k})$ consists of\ncharacters of minimal $\\mathbf{G}(\\mathsf{k}^{\\rm alg})$ stabilizer dimension.\nIn the present paper we consider the regular characters of such classical\ngroups over $\\mathfrak{o}$, and construct and enumerate all regular characters\nof $\\mathbf{G}(\\mathfrak{o})$, when the characteristic of $\\mathsf{k}$ is\ngreater than two. As a result, we compute the regular part of their\nrepresentation zeta function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Are Deep Policy Gradient Algorithms Truly Policy Gradient Algorithms?.   We study how the behavior of deep policy gradient algorithms reflects the\nconceptual framework motivating their development. We propose a fine-grained\nanalysis of state-of-the-art methods based on key aspects of this framework:\ngradient estimation, value prediction, optimization landscapes, and trust\nregion enforcement. We find that from this perspective, the behavior of deep\npolicy gradient algorithms often deviates from what their motivating framework\nwould predict. Our analysis suggests first steps towards solidifying the\nfoundations of these algorithms, and in particular indicates that we may need\nto move beyond the current benchmark-centric evaluation methodology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pore lifetimes in cell electroporation: Complex dark pores?.   We review some of the basic concepts and the possible pore structures\nassociated with electroporation (EP) for times after electrical pulsing. We\npurposefully give only a short description of pore creation and subsequent\nevolution of pore populations, as these are adequately discussed in both\nreviews and original research reports. In contrast, post-pulse pore concepts\nhave changed dramatically. For perspective we note that pores are not directly\nobserved. Instead understanding of pores is based on inference from experiments\nand, increasingly, molecular dynamics (MD) simulations. In the past decade\nconcepts for post-pulse pores have changed significantly: The idea of pure\nlipidic transient pores (TPs) that exist for milliseconds or longer post-pulse\nhas become inconsistent with MD results, which support TP lifetimes of only\n$\\sim$100 ns. A typical large TP number during cell EP pulsing is of order\n$10^6$. In twenty MD-based TP lifetimes (2 us total), the TP number plummets to\n$\\sim$0.001. In short, TPs vanish 2 us after a pulse ends, and cannot account\nfor post-pulse behavior such as large and relatively non-specific ionic and\nmolecular transport. Instead, an early conjecture of complex pores (CPs) with\nboth lipidic and other molecule should be taken seriously. Indeed, in the past\ndecade several experiments provide partial support for complex pores (CPs).\nPresently, CPs are \"dark\", in the sense that while some CP functions are known,\nlittle is known about their structure(s). There may be a wide range of\nlifetimes and permeabilities, not yet revealed by experiments. Like cosmology's\ndark matter, these unseen pores present us with an outstanding problem.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Single-Queue Decoding for Neural Machine Translation.   Neural machine translation models rely on the beam search algorithm for\ndecoding. In practice, we found that the quality of hypotheses in the search\nspace is negatively affected owing to the fixed beam size. To mitigate this\nproblem, we store all hypotheses in a single priority queue and use a universal\nscore function for hypothesis selection. The proposed algorithm is more\nflexible as the discarded hypotheses can be revisited in a later step. We\nfurther design a penalty function to punish the hypotheses that tend to produce\na final translation that is much longer or shorter than expected. Despite its\nsimplicity, we show that the proposed decoding algorithm is able to select\nhypotheses with better qualities and improve the translation performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On reproduction of On the regularization of Wasserstein GANs.   This report has several purposes. First, our report is written to investigate\nthe reproducibility of the submitted paper On the regularization of Wasserstein\nGANs (2018). Second, among the experiments performed in the submitted paper,\nfive aspects were emphasized and reproduced: learning speed, stability,\nrobustness against hyperparameter, estimating the Wasserstein distance, and\nvarious sampling method. Finally, we identify which parts of the contribution\ncan be reproduced, and at what cost in terms of resources. All source code for\nreproduction is open to the public.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimization of Executable Formal Interpreters developed in Higher-order Theorem Proving Systems.   In recent publications, we presented a novel formal symbolic process virtual\nmachine (FSPVM) framework that combined higher-order theorem proving and\nsymbolic execution for verifying the reliability and security of smart\ncontracts developed in the Ethereum blockchain system without suffering the\nstandard issues surrounding reusability, consistency, and automation. A\nspecific FSPVM, denoted as FSPVM-E, was developed in Coq based on a general,\nextensible, and reusable formal memory (GERM) framework, an extensible and\nuniversal formal intermediate programming language, denoted as Lolisa, which is\na large subset of the Solidity programming language that uses generalized\nalgebraic datatypes, and a corresponding formally verified interpreter for\nLolisa, denoted as FEther, which serves as a crucial component of FSPVM-E.\nHowever, our past work has demonstrated that the execution efficiency of the\nstandard development of FEther is extremely low. As a result, FSPVM-E fails to\nachieve its expected verification effect. The present work addresses this issue\nby first identifying three root causes of the low execution efficiency of\nformal interpreters. We then build abstract models of these causes, and present\nrespective optimization schemes for rectifying the identified conditions.\nFinally, we apply these optimization schemes to FEther, and demonstrate that\nits execution efficiency has been improved significantly.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hydra: An Accelerator for Real-Time Edge-Aware Permeability Filtering in 65nm CMOS.   Many modern video processing pipelines rely on edge-aware (EA) filtering\nmethods. However, recent high-quality methods are challenging to run in\nreal-time on embedded hardware due to their computational load. To this end, we\npropose an area-efficient and real-time capable hardware implementation of a\nhigh quality EA method. In particular, we focus on the recently proposed\npermeability filter (PF) that delivers promising quality and performance in the\ndomains of HDR tone mapping, disparity and optical flow estimation. We present\nan efficient hardware accelerator that implements a tiled variant of the PF\nwith low on-chip memory requirements and a significantly reduced external\nmemory bandwidth (6.4x w.r.t. the non-tiled PF). The design has been taped out\nin 65 nm CMOS technology, is able to filter 720p grayscale video at 24.8 Hz and\nachieves a high compute density of 6.7 GFLOPS/mm2 (12x higher than embedded\nGPUs when scaled to the same technology node). The low area and bandwidth\nrequirements make the accelerator highly suitable for integration into SoCs\nwhere silicon area budget is constrained and external memory is typically a\nheavily contended resource.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Suppression of Hall number due to charge density wave order in high-$T_c$ cuprates.   Understanding the pseudogap phase in hole-doped high temperature cuprate\nsuperconductors remains a central challenge in condensed matter physics. From a\nhost of recent experiments there is now compelling evidence of translational\nsymmetry breaking charge density wave (CDW) order in a wide range of doping\ninside this phase. Two distinct types of incommensurate charge order --\nbidirectional at zero or low magnetic fields and unidirectional at high\nmagnetic fields close to the upper critical field $H_{c2}$ -- have been\nreported so far in approximately the same doping range between $p\\simeq 0.08$\nand $p\\simeq 0.16$. In concurrent developments, recent high field Hall\nexperiments have also revealed two indirect but striking signatures of Fermi\nsurface reconstruction in the pseudogap phase, namely, a sign change of the\nHall coefficient to negative values at low temperatures at intermediate range\nof hole doping and a rapid suppression of the positive Hall number without\nchange in sign near optimal doping $p \\sim 0.19$. We show that the assumption\nof a unidirectional incommensurate CDW (with or without a coexisting weak\nbidirectional order) at high magnetic fields near optimal doping and a\ncoexistence of both types of orders of approximately equal magnitude at high\nmagnetic fields at intermediate range of doping may help explain the striking\nbehavior of low temperature Hall effect in the entire pseudogap phase.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Field dependent neutron diffraction study in Ni50Mn38Sb12 Heusler alloy.   In this paper, we present temperature and field dependent neutron diffraction\n(ND) study to unravel the structural and the magnetic properties in\nNi50Mn38Sb12 Heusler system. This alloy shows martensitic transition from high\ntemperature austenite cubic phase to low temperature martensite orthorhombic\nphase on cooling. At 3 K, the lattice parameters and magnetic moments are found\nto be almost insensitive to field. Just below the martensitic transition\ntemperature, the martensite phase fraction is found to be 85%. Upon applying\nthe field, the austenite phase becomes dominant, and the field induced reverse\nmartensitic transition is clearly observed in the ND data. Therefore, the\npresent study gives an estimate of the strength of the martensite phase or the\nsharpness of the martensitic transition. Variation of individual moments and\nthe change in the phase fraction obtained from the analysis of the ND data\nvividly show the change in the magneto-structural state of the material across\nthe transition.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Nontrivial Turmites are Turing-universal.   A Turmit is a Turing machine that works over a two-dimensional grid, that is,\nan agent that moves, reads and writes symbols over the cells of the grid. Its\nstate is an arrow and, depending on the symbol that it reads, it turns to the\nleft or to the right, switching the symbol at the same time. Several symbols\nare admitted, and the rule is specified by the turning sense that the machine\nhas over each symbol. Turmites are a generalization of Langtons ant, and they\npresent very complex and diverse behaviors. We prove that any Turmite, except\nfor those whose rule does not depend on the symbol, can simulate any Turing\nMachine. We also prove the P-completeness of prediction their future behavior\nby explicitly giving a log-space reduction from the Topological Circuit Value\nProblem. A similar result was already established for Langtons ant; here we use\na similar technique but prove a stronger notion of simulation, and for a more\ngeneral family.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Ro-vibrational states of H$_2^+$. Variational calculations.   The nonrelativistic variational calculation of a complete set of\nro-vibrational states in the H$_2^+$ molecular ion supported by the ground\n$1s\\sigma$ adiabatic potential is presented. It includes both bound states and\nresonances located above the $n=1$ threshold. In the latter case we also\nevaluate a predissociation width of a state wherever it is significant.\nRelativistic and radiative corrections are discussed and effective adiabatic\npotentials of these corrections are included as supplementary files.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "RDMAvisor: Toward Deploying Scalable and Simple RDMA as a Service in Datacenters.   RDMA is increasingly adopted by cloud computing platforms to provide low CPU\noverhead, low latency, high throughput network services. On the other hand,\nhowever, it is still challenging for developers to realize fast deployment of\nRDMA-aware applications in the datacenter, since the performance is highly\nrelated to many lowlevel details of RDMA operations. To address this problem,\nwe present a simple and scalable RDMA as Service (RaaS) to mitigate the impact\nof RDMA operational details. RaaS provides careful message buffer management to\nimprove CPU/memory utilization and improve the scalability of RDMA operations.\nThese optimized designs lead to simple and flexible programming model for\ncommon and knowledgeable users. We have implemented a prototype of RaaS, named\nRDMAvisor, and evaluated its performance on a cluster with a large number of\nconnections. Our experiment results demonstrate that RDMAvisor achieves high\nthroughput for thousand of connections and maintains low CPU and memory\noverhead through adaptive RDMA transport selection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Life in the \"Matrix\": Human Mobility Patterns in the Cyber Space.   With the wide adoption of the multi-community setting in many popular social\nmedia platforms, the increasing user engagements across multiple online\ncommunities warrant research attention. In this paper, we introduce a novel\nanalogy between the movements in the cyber space and the physical space. This\nanalogy implies a new way of studying human online activities by modelling the\nactivities across online communities in a similar fashion as the movements\namong locations. First, we quantitatively validate the analogy by comparing\nseveral important properties of human online activities and physical movements.\nOur experiments reveal striking similarities between the cyber space and the\nphysical space. Next, inspired by the established methodology on human mobility\nin the physical space, we propose a framework to study human \"mobility\" across\nonline platforms. We discover three interesting patterns of user engagements in\nonline communities. Furthermore, our experiments indicate that people with\ndifferent mobility patterns also exhibit divergent preferences to online\ncommunities. This work not only attempts to achieve a better understanding of\nhuman online activities, but also intends to open a promising research\ndirection with rich implications and applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Annealed Generative Adversarial Networks.   We introduce a novel framework for adversarial training where the target\ndistribution is annealed between the uniform distribution and the data\ndistribution. We posited a conjecture that learning under continuous annealing\nin the nonparametric regime is stable irrespective of the divergence measures\nin the objective function and proposed an algorithm, dubbed {\\ss}-GAN, in\ncorollary. In this framework, the fact that the initial support of the\ngenerative network is the whole ambient space combined with annealing are key\nto balancing the minimax game. In our experiments on synthetic data, MNIST, and\nCelebA, {\\ss}-GAN with a fixed annealing schedule was stable and did not suffer\nfrom mode collapse.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Polishness of some topologies related to word or tree automata.   We prove that the Büchi topology and the automatic topology are Polish. We\nalso show that this cannot be fully extended to the case of a space of infinite\nlabelled binary trees; in particular the Büchi and the Muller topologies are\nnot Polish in this case.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Knowledge Reuse for Customization: Metamodels in an Open Design Community for 3d Printing.   Theories of knowledge reuse posit two distinct processes: reuse for\nreplication and reuse for innovation. We identify another distinct process,\nreuse for customization. Reuse for customization is a process in which\ndesigners manipulate the parameters of metamodels to produce models that\nfulfill their personal needs. We test hypotheses about reuse for customization\nin Thingiverse, a community of designers that shares files for\nthree-dimensional printing. 3D metamodels are reused more often than the 3D\nmodels they generate. The reuse of metamodels is amplified when the metamodels\nare created by designers with greater community experience. Metamodels make the\ncommunity's design knowledge available for reuse for customization-or further\nextension of the metamodels, a kind of reuse for innovation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coupled spin-charge dynamics in helical Fermi liquids beyond the random phase approximation.   We consider a helical system of fermions with a generic spin (or pseudospin)\norbit coupling. Using the equation of motion approach for the single-particle\ndistribution functions, and a mean-field decoupling of the higher order\ndistribution functions, we find a closed form for the charge and spin density\nfluctuations in terms of the charge and spin density linear response functions.\nApproximating the nonlocal exchange term with a Hubbard-like local-field\nfactor, we obtain coupled spin and charge density response matrix beyond the\nrandom phase approximation, whose poles give the dispersion of four collective\nspin-charge modes. We apply our generic technique to the well-explored\ntwo-dimensional system with Rashba spin-orbit coupling and illustrate how it\ngives results for the collective modes, Drude weight, and spin-Hall\nconductivity which are in very good agreement with the results obtained from\nother more sophisticated approaches.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Unsupervised robust nonparametric learning of hidden community properties.   We consider learning of fundamental properties of communities in large noisy\nnetworks, in the prototypical situation where the nodes or users are split into\ntwo classes according to a binary property, e.g., according to their opinions\nor preferences on a topic. For learning these properties, we propose a\nnonparametric, unsupervised, and scalable graph scan procedure that is, in\naddition, robust against a class of powerful adversaries. In our setup, one of\nthe communities can fall under the influence of a knowledgeable adversarial\nleader, who knows the full network structure, has unlimited computational\nresources and can completely foresee our planned actions on the network. We\nprove strong consistency of our results in this setup with minimal assumptions.\nIn particular, the learning procedure estimates the baseline activity of normal\nusers asymptotically correctly with probability 1; the only assumption being\nthe existence of a single implicit community of asymptotically negligible\nlogarithmic size. We provide experiments on real and synthetic data to\nillustrate the performance of our method, including examples with adversaries.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Low Rank Matrix Recovery with Simultaneous Presence of Outliers and Sparse Corruption.   We study a data model in which the data matrix D can be expressed as D = L +\nS + C, where L is a low rank matrix, S an element-wise sparse matrix and C a\nmatrix whose non-zero columns are outlying data points. To date, robust PCA\nalgorithms have solely considered models with either S or C, but not both. As\nsuch, existing algorithms cannot account for simultaneous element-wise and\ncolumn-wise corruptions. In this paper, a new robust PCA algorithm that is\nrobust to simultaneous types of corruption is proposed. Our approach hinges on\nthe sparse approximation of a sparsely corrupted column so that the sparse\nexpansion of a column with respect to the other data points is used to\ndistinguish a sparsely corrupted inlier column from an outlying data point. We\nalso develop a randomized design which provides a scalable implementation of\nthe proposed approach. The core idea of sparse approximation is analyzed\nanalytically where we show that the underlying ell_1-norm minimization can\nobtain the representation of an inlier in presence of sparse corruptions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Recovering piecewise constant refractive indices by a single far-field pattern.   We are concerned with the inverse scattering problem of recovering an\ninhomogeneous medium by the associated acoustic wave measurement. We prove that\nunder certain assumptions, a single far-field pattern determines the values of\na perturbation to the refractive index on the corners of its support. These\nassumptions are satisfied for example in the low acoustic frequency regime. As\na consequence if the perturbation is piecewise constant with either a\npolyhedral nest geometry or a known polyhedral cell geometry, such as a pixel\nor voxel array, we establish the injectivity of the perturbation to far-field\nmap given a fixed incident wave. This is the first unique determinancy result\nof its type in the literature, and all of the existing results essentially make\nuse of infinitely many measurements.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Remote Sensing Image Scene Classification: Benchmark and State of the Art.   Remote sensing image scene classification plays an important role in a wide\nrange of applications and hence has been receiving remarkable attention. During\nthe past years, significant efforts have been made to develop various datasets\nor present a variety of approaches for scene classification from remote sensing\nimages. However, a systematic review of the literature concerning datasets and\nmethods for scene classification is still lacking. In addition, almost all\nexisting datasets have a number of limitations, including the small scale of\nscene classes and the image numbers, the lack of image variations and\ndiversity, and the saturation of accuracy. These limitations severely limit the\ndevelopment of new approaches especially deep learning-based methods. This\npaper first provides a comprehensive review of the recent progress. Then, we\npropose a large-scale dataset, termed \"NWPU-RESISC45\", which is a publicly\navailable benchmark for REmote Sensing Image Scene Classification (RESISC),\ncreated by Northwestern Polytechnical University (NWPU). This dataset contains\n31,500 images, covering 45 scene classes with 700 images in each class. The\nproposed NWPU-RESISC45 (i) is large-scale on the scene classes and the total\nimage number, (ii) holds big variations in translation, spatial resolution,\nviewpoint, object pose, illumination, background, and occlusion, and (iii) has\nhigh within-class diversity and between-class similarity. The creation of this\ndataset will enable the community to develop and evaluate various data-driven\nalgorithms. Finally, several representative methods are evaluated using the\nproposed dataset and the results are reported as a useful baseline for future\nresearch.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nearly-Linear Time Spectral Graph Reduction for Scalable Graph Partitioning and Data Visualization.   This paper proposes a scalable algorithmic framework for spectral reduction\nof large undirected graphs. The proposed method allows computing much smaller\ngraphs while preserving the key spectral (structural) properties of the\noriginal graph. Our framework is built upon the following two key components: a\nspectrum-preserving node aggregation (reduction) scheme, as well as a spectral\ngraph sparsification framework with iterative edge weight scaling. We show that\nthe resulting spectrally-reduced graphs can robustly preserve the first few\nnontrivial eigenvalues and eigenvectors of the original graph Laplacian. In\naddition, the spectral graph reduction method has been leveraged to develop\nmuch faster algorithms for multilevel spectral graph partitioning as well as\nt-distributed Stochastic Neighbor Embedding (t-SNE) of large data sets. We\nconducted extensive experiments using a variety of large graphs and data sets,\nand obtained very promising results. For instance, we are able to reduce the\n\"coPapersCiteseer\" graph with 0.43 million nodes and 16 million edges to a much\nsmaller graph with only 13K (32X fewer) nodes and 17K (950X fewer) edges in\nabout 16 seconds; the spectrally-reduced graphs also allow us to achieve up to\n1100X speedup for spectral graph partitioning and up to 60X speedup for t-SNE\nvisualization of large data sets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Advanced Bayesian Multilevel Modeling with the R Package brms.   The brms package allows R users to easily specify a wide range of Bayesian\nsingle-level and multilevel models, which are fitted with the probabilistic\nprogramming language Stan behind the scenes. Several response distributions are\nsupported, of which all parameters (e.g., location, scale, and shape) can be\npredicted at the same time thus allowing for distributional regression.\nNon-linear relationships may be specified using non-linear predictor terms or\nsemi-parametric approaches such as splines or Gaussian processes. To make all\nof these modeling options possible in a multilevel framework, brms provides an\nintuitive and powerful formula syntax, which extends the well known formula\nsyntax of lme4. The purpose of the present paper is to introduce this syntax in\ndetail and to demonstrate its usefulness with four examples, each showing other\nrelevant aspects of the syntax.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Semi-Supervised Learning via New Deep Network Inversion.   We exploit a recently derived inversion scheme for arbitrary deep neural\nnetworks to develop a new semi-supervised learning framework that applies to a\nwide range of systems and problems. The approach outperforms current\nstate-of-the-art methods on MNIST reaching $99.14\\%$ of test set accuracy while\nusing $5$ labeled examples per class. Experiments with one-dimensional signals\nhighlight the generality of the method. Importantly, our approach is simple,\nefficient, and requires no change in the deep network architecture.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coherence for braided and symmetric pseudomonoids.   Presentations for unbraided, braided and symmetric pseudomonoids are defined.\nBiequivalences characterising the semistrict bicategories generated by these\npresentations are proven. It is shown that these biequivalences categorify\nresults in the theory of monoids and commutative monoids, and generalise\nstandard coherence theorems for braided and symmetric monoidal categories.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamics beyond dynamic jam; unfolding the Painlevé paradox singularity.   This paper analyses in detail the dynamics in a neighbourhood of a\nGénot-Brogliato point, colloquially termed the G-spot, which physically\nrepresents so-called dynamic jam in rigid body mechanics with unilateral\ncontact and Coulomb friction. Such singular points arise in planar rigid body\nproblems with slipping point contacts at the intersection between the\nconditions for onset of lift-off and for the Painlevé paradox. The G-spot can\nbe approached in finite time by an open set of initial conditions in a general\nclass of problems. The key question addressed is what happens next. In\nprinciple trajectories could, at least instantaneously, lift off, continue in\nslip, or undergo a so-called impact without collision. Such impacts are\nnon-local in momentum space and depend on properties evaluated away from the\nG-spot. The results are illustrated on a particular physical example, namely\nthe a frictional impact oscillator first studied by Leine et al.\nThe answer is obtained via an analysis that involves a consistent contact\nregularisation with a stiffness proportional to $1/\\varepsilon^2$. Taking a\nsingular limit as $\\varepsilon \\to 0$, one finds an inner and an outer\nasymptotic zone in the neighbourhood of the G-spot. Two distinct cases are\nfound according to whether the contact force becomes infinite or remains finite\nas the G-spot is approached. In the former case it is argued that there can be\nno such canards and so an impact without collision must occur. In the latter\ncase, the canard trajectory acts as a dividing surface between trajectories\nthat momentarily lift off and those that do not before taking the impact. The\norientation of the initial condition set leading to each eventuality is shown\nto change each time a certain positive parameter $\\beta$ passes through an\ninteger.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Sharp total variation results for maximal functions.   In this article, we prove some total variation inequalities for maximal\nfunctions. Our results deal with two possible generalizations of the results\ncontained in Aldaz and Pérez Lázaro's work, one of whose considers a\nvariable truncation of the maximal function, and the other one interpolates the\ncentered and the uncentered maximal functions. In both contexts, we find sharp\nconstants for the desired inequalities, which can be viewed as progress towards\nthe conjecture that the best constant for the variation inequality in the\ncentered context is one. We also provide counterexamples showing that our\nmethods do not apply outside the stated parameter ranges.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the composition of an arbitrary collection of $SU(2)$ spins: An Enumerative Combinatoric Approach.   The whole enterprise of spin compositions can be recast as simple enumerative\ncombinatoric problems. We show here that enumerative combinatorics\n(EC)\\citep{book:Stanley-2011} is a natural setting for spin composition, and\neasily leads to very general analytic formulae -- many of which hitherto not\npresent in the literature. Based on it, we propose three general methods for\ncomputing spin multiplicities; namely, 1) the multi-restricted composition, 2)\nthe generalized binomial and 3) the generating function methods. Symmetric and\nanti-symmetric compositions of $SU(2)$ spins are also discussed, using\ngenerating functions. Of particular importance is the observation that while\nthe common Clebsch-Gordan decomposition (CGD) -- which considers the spins as\ndistinguishable -- is related to integer compositions, the symmetric and\nanti-symmetric compositions (where one considers the spins as\nindistinguishable) are obtained considering integer partitions. The integers in\nquestion here are none other but the occupation numbers of the\nHolstein-Primakoff bosons.\n\\par The pervasiveness of $q-$analogues in our approach is a testament to the\nfundamental role they play in spin compositions. In the appendix, some new\nresults in the power series representation of Gaussian polynomials (or\n$q-$binomial coefficients) -- relevant to symmetric and antisymmetric\ncompositions -- are presented.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Probabilistic learning of nonlinear dynamical systems using sequential Monte Carlo.   Probabilistic modeling provides the capability to represent and manipulate\nuncertainty in data, models, predictions and decisions. We are concerned with\nthe problem of learning probabilistic models of dynamical systems from measured\ndata. Specifically, we consider learning of probabilistic nonlinear state-space\nmodels. There is no closed-form solution available for this problem, implying\nthat we are forced to use approximations. In this tutorial we will provide a\nself-contained introduction to one of the state-of-the-art methods---the\nparticle Metropolis--Hastings algorithm---which has proven to offer a practical\napproximation. This is a Monte Carlo based method, where the particle filter is\nused to guide a Markov chain Monte Carlo method through the parameter space.\nOne of the key merits of the particle Metropolis--Hastings algorithm is that it\nis guaranteed to converge to the \"true solution\" under mild assumptions,\ndespite being based on a particle filter with only a finite number of\nparticles. We will also provide a motivating numerical example illustrating the\nmethod using a modeling language tailored for sequential Monte Carlo methods.\nThe intention of modeling languages of this kind is to open up the power of\nsophisticated Monte Carlo methods---including particle\nMetropolis--Hastings---to a large group of users without requiring them to know\nall the underlying mathematical details.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mobility tensor of a sphere moving on a super-hydrophobic wall: application to particle separation.   The paper addresses the hydrodynamic behavior of a sphere close to a\nmicro-patterned superhydrophobic surface described in terms of alternated\nno-slip and perfect-slip stripes. Physically, the perfect-slip stripes model\nthe parallel grooves where a large gas cushion forms between fluid and solid\nwall, giving rise to slippage at the gas-liquid interface. The potential of the\nboundary element method (BEM) in dealing with mixed no-slip/perfect-slip\nboundary conditions is exploited to systematically calculate the mobility\ntensor for different particle-to-wall relative positions and for different\nparticle radii. The particle hydrodynamics is characterized by a non trivial\nmobility field which presents a distinct near wall behavior where the wall\npatterning directly affects the particle motion. In the far field, the effects\nof the wall pattern can be accurately represented via an effective description\nin terms of a homogeneous wall with a suitably defined apparent slippage. The\ntrajectory of the sphere under the action of an external force is also\ndescribed in some detail. A resonant regime is found when the frequency of the\ntransversal component of the force matches a characteristic crossing frequency\nimposed by the wall pattern. It is found that, under resonance, the particle\nundergoes a mean transversal drift. Since the resonance condition depends on\nthe particle radius the effect can in principle be used to conceive devices for\nparticle sorting based on superhydrophobic surfaces.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Variational characterization of H^p.   In this paper we obtain the variational characterization of Hardy space $H^p$\nfor $p\\in(\\frac n{n+1},1]$ and get estimates for the oscillation operator and\nthe $\\lambda$-jump operator associated with approximate identities acting on\n$H^p$ for $p\\in(\\frac n{n+1},1]$. Moreover, we give counterexamples to show\nthat the oscillation and $\\lambda$-jump associated with some approximate\nidentity can not be used to characterize $H^p$ for $p\\in(\\frac n{n+1},1]$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Task-Oriented Grasping for Tool Manipulation from Simulated Self-Supervision.   Tool manipulation is vital for facilitating robots to complete challenging\ntask goals. It requires reasoning about the desired effect of the task and thus\nproperly grasping and manipulating the tool to achieve the task. Task-agnostic\ngrasping optimizes for grasp robustness while ignoring crucial task-specific\nconstraints. In this paper, we propose the Task-Oriented Grasping Network\n(TOG-Net) to jointly optimize both task-oriented grasping of a tool and the\nmanipulation policy for that tool. The training process of the model is based\non large-scale simulated self-supervision with procedurally generated tool\nobjects. We perform both simulated and real-world experiments on two tool-based\nmanipulation tasks: sweeping and hammering. Our model achieves overall 71.1%\ntask success rate for sweeping and 80.0% task success rate for hammering.\nSupplementary material is available at: bit.ly/task-oriented-grasp",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A central limit theorem for the realised covariation of a bivariate Brownian semistationary process.   This article presents a weak law of large numbers and a central limit theorem\nfor the scaled realised covariation of a bivariate Brownian semistationary\nprocess. The novelty of our results lies in the fact that we derive the\nsuitable asymptotic theory both in a multivariate setting and outside the\nclassical semimartingale framework. The proofs rely heavily on recent\ndevelopments in Malliavin calculus.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Multilevel Coding Schemes Based on Non-Binary LDPC Codes.   We address the problem of constructing of coding schemes for the channels\nwith high-order modulations. It is known, that non-binary LDPC codes are\nespecially good for such channels and significantly outperform their binary\ncounterparts. Unfortunately, their decoding complexity is still large. In order\nto reduce the decoding complexity we consider multilevel coding schemes based\non non-binary LDPC codes (NB-LDPC-MLC schemes) over smaller fields. The use of\nsuch schemes gives us a reasonable gain in complexity. At the same time the\nperformance of NB-LDPC-MLC schemes is practically the same as the performance\nof LDPC codes over the field matching the modulation order. In particular by\nmeans of simulations we showed that the performance of NB-LDPC-MLC schemes over\nGF(16) is the same as the performance of non-binary LDPC codes over GF(64) and\nGF(256) in AWGN channel with QAM64 and QAM256 accordingly. We also perform a\ncomparison with binary LDPC codes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Wild theories with o-minimal open core.   Let $T$ be a consistent o-minimal theory extending the theory of densely\nordered groups and let $T'$ be a consistent theory. Then there is a complete\ntheory $T^*$ extending $T$ such that $T$ is an open core of $T^*$, but every\nmodel of $T^*$ interprets a model of $T'$. If $T'$ is NIP, $T^*$ can be chosen\nto be NIP as well. From this we deduce the existence of an NIP expansion of the\nreal field that has no distal expansion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The careless use of language in quantum information.   An imperative aspect of modern science is that scientific institutions act\nfor the benefit of a common scientific enterprise, rather than for the personal\ngain of individuals within them. This implies that science should not\nperpetuate existing or historical unequal social orders. Some scientific\nterminology, though, gives a very different impression. I will give two\nexamples of terminology invented recently for the field of quantum information\nwhich use language associated with subordination, slavery, and racial\nsegregation: 'ancilla qubit' and 'quantum supremacy'.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Monte-Carlo Tree Search by Best Arm Identification.   Recent advances in bandit tools and techniques for sequential learning are\nsteadily enabling new applications and are promising the resolution of a range\nof challenging related problems. We study the game tree search problem, where\nthe goal is to quickly identify the optimal move in a given game tree by\nsequentially sampling its stochastic payoffs. We develop new algorithms for\ntrees of arbitrary depth, that operate by summarizing all deeper levels of the\ntree into confidence intervals at depth one, and applying a best arm\nidentification procedure at the root. We prove new sample complexity guarantees\nwith a refined dependence on the problem instance. We show experimentally that\nour algorithms outperform existing elimination-based algorithms and match\nprevious special-purpose methods for depth-two trees.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Panchromatic Hubble Andromeda Treasury XVIII. The High-mass Truncation of the Star Cluster Mass Function.   We measure the mass function for a sample of 840 young star clusters with\nages between 10-300 Myr observed by the Panchromatic Hubble Andromeda Treasury\n(PHAT) survey in M31. The data show clear evidence of a high-mass truncation:\nonly 15 clusters more massive than $10^4$ $M_{\\odot}$ are observed, compared to\n$\\sim$100 expected for a canonical $M^{-2}$ pure power-law mass function with\nthe same total number of clusters above the catalog completeness limit.\nAdopting a Schechter function parameterization, we fit a characteristic\ntruncation mass of $M_c = 8.5^{+2.8}_{-1.8} \\times 10^3$ $M_{\\odot}$. While\nprevious studies have measured cluster mass function truncations, the\ncharacteristic truncation mass we measure is the lowest ever reported.\nCombining this M31 measurement with previous results, we find that the cluster\nmass function truncation correlates strongly with the characteristic star\nformation rate surface density of the host galaxy, where $M_c \\propto$ $\\langle\n\\Sigma_{\\mathrm{SFR}} \\rangle^{\\sim1.1}$. We also find evidence that suggests\nthe observed $M_c$-$\\Sigma_{\\mathrm{SFR}}$ relation also applies to globular\nclusters, linking the two populations via a common formation pathway. If so,\nglobular cluster mass functions could be useful tools for constraining the star\nformation properties of their progenitor host galaxies in the early Universe.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weighted blowup correspondence of orbifold Gromov--Witten invariants and applications.   Let $\\sf X$ be a symplectic orbifold groupoid with $\\sf S$ being a symplectic\nsub-orbifold groupoid, and $\\sf X_{\\mathfrak a}$ be the weight-$\\mathfrak a$\nblowup of $\\sf X$ along $\\sf S$ with $\\sf Z$ being the corresponding\nexceptional divisor. We show that there is a weighted blowup correspondence\nbetween some certain absolute orbifold Gromov--Witten invariants of $\\sf X$\nrelative to $\\sf S$ and some certain relative orbifold Gromov--Witten\ninvariants of the pair $(\\sf X_{\\mathfrak a}|Z)$. As an application, we prove\nthat the symplectic uniruledness of symplectic orbifold groupoids is a weighted\nblowup invariant.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Information Pursuit: A Bayesian Framework for Sequential Scene Parsing.   Despite enormous progress in object detection and classification, the problem\nof incorporating expected contextual relationships among object instances into\nmodern recognition systems remains a key challenge. In this work we propose\nInformation Pursuit, a Bayesian framework for scene parsing that combines prior\nmodels for the geometry of the scene and the spatial arrangement of objects\ninstances with a data model for the output of high-level image classifiers\ntrained to answer specific questions about the scene. In the proposed\nframework, the scene interpretation is progressively refined as evidence\naccumulates from the answers to a sequence of questions. At each step, we\nchoose the question to maximize the mutual information between the new answer\nand the full interpretation given the current evidence obtained from previous\ninquiries. We also propose a method for learning the parameters of the model\nfrom synthesized, annotated scenes obtained by top-down sampling from an\neasy-to-learn generative scene model. Finally, we introduce a database of\nannotated indoor scenes of dining room tables, which we use to evaluate the\nproposed approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Characterization of a Deuterium-Deuterium Plasma Fusion Neutron Generator.   We characterize the neutron output of a deuterium-deuterium plasma fusion\nneutron generator, model 35-DD-W-S, manufactured by NSD/Gradel-Fusion. The\nmeasured energy spectrum is found to be dominated by neutron peaks at 2.2 MeV\nand 2.7 MeV. A detailed GEANT4 simulation accurately reproduces the measured\nenergy spectrum and confirms our understanding of the fusion process in this\ngenerator. Additionally, a contribution of 14.1 MeV neutrons from\ndeuterium-tritium fusion is found at a level of~$3.5\\%$, from tritium produced\nin previous deuterium-deuterium reactions. We have measured both the absolute\nneutron flux as well as its relative variation on the operational parameters of\nthe generator. We find the flux to be proportional to voltage $V^{3.32 \\pm\n0.14}$ and current $I^{0.97 \\pm 0.01}$. Further, we have measured the angular\ndependence of the neutron emission with respect to the polar angle. We conclude\nthat it is well described by isotropic production of neutrons within the\ncathode field cage.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Prevalence of DNSSEC for hospital websites in Illinois.   The domain name system translates human friendly web addresses to a computer\nreadable internet protocol address. This basic infrastructure is insecure and\ncan be manipulated. Deployment of technology to secure the DNS system has been\nslow, reaching about 20% of all web sites based in the USA. Little is known\nabout the efforts hospitals and health systems make to secure the domain name\nsystem for their websites. To investigate the prevalence of implementing Domain\nName System Security Extensions (DNSSEC), we analyzed the websites of the 210\npublic hospitals in the state of Illinois, USA. Only one Illinois hospital\nwebsite was found to have implemented DNSSEC by December, 2017.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Deep Neural Network Surrogate for High-Dimensional Random Partial Differential Equations.   Developing efficient numerical algorithms for the solution of high\ndimensional random Partial Differential Equations (PDEs) has been a challenging\ntask due to the well-known curse of dimensionality. We present a new solution\nframework for these problems based on a deep learning approach. Specifically,\nthe random PDE is approximated by a feed-forward fully-connected deep residual\nnetwork, with either strong or weak enforcement of initial and boundary\nconstraints. The framework is mesh-free, and can handle irregular computational\ndomains. Parameters of the approximating deep neural network are determined\niteratively using variants of the Stochastic Gradient Descent (SGD) algorithm.\nThe satisfactory accuracy of the proposed frameworks is numerically\ndemonstrated on diffusion and heat conduction problems, in comparison with the\nconverged Monte Carlo-based finite element results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stellar Abundances for Galactic Archaeology Database IV - Compilation of Stars in Dwarf Galaxies.   We have constructed the database of stars in the local group using the\nextended version of the SAGA (Stellar Abundances for Galactic Archaeology)\ndatabase that contains stars in 24 dwarf spheroidal galaxies and ultra faint\ndwarfs. The new version of the database includes more than 4500 stars in the\nMilky Way, by removing the previous metallicity criterion of [Fe/H] <= -2.5,\nand more than 6000 stars in the local group galaxies. We examined a validity of\nusing a combined data set for elemental abundances. We also checked a\nconsistency between the derived distances to individual stars and those to\ngalaxies in the literature values. Using the updated database, the\ncharacteristics of stars in dwarf galaxies are discussed. Our statistical\nanalyses of alpha-element abundances show that the change of the slope of the\n[alpha/Fe] relative to [Fe/H] (so-called \"knee\") occurs at [Fe/H] = -1.0+-0.1\nfor the Milky Way. The knee positions for selected galaxies are derived by\napplying the same method. Star formation history of individual galaxies are\nexplored using the slope of the cumulative metallicity distribution function.\nRadial gradients along the four directions are inspected in six galaxies where\nwe find no direction dependence of metallicity gradients along the major and\nminor axes. The compilation of all the available data shows a lack of CEMP-s\npopulation in dwarf galaxies, while there may be some CEMP-no stars at [Fe/H]\n<~ -3 even in the very small sample. The inspection of the relationship between\nEu and Ba abundances confirms an anomalously Ba-rich population in Fornax,\nwhich indicates a pre-enrichment of interstellar gas with r-process elements.\nWe do not find any evidence of anti-correlations in O-Na and Mg-Al abundances,\nwhich characterises the abundance trends in the Galactic globular clusters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Existence of infinite Viterbi path for pairwise Markov models.   For hidden Markov models one of the most popular estimates of the hidden\nchain is the Viterbi path -- the path maximising the posterior probability. We\nconsider a more general setting, called the pairwise Markov model, where the\njoint process consisting of finite-state hidden regime and observation process\nis assumed to be a Markov chain. We prove that under some conditions it is\npossible to extend the Viterbi path to infinity for almost every observation\nsequence which in turn enables to define an infinite Viterbi decoding of the\nobservation process, called the Viterbi process. This is done by constructing a\nblock of observations, called a barrier, which ensures that the Viterbi path\ngoes trough a given state whenever this block occurs in the observation\nsequence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simulating optical coherence tomography for observing nerve activity: a finite difference time domain bi-dimensional model.   We present a finite difference time domain (FDTD) model for computation of A\nline scans in time domain optical coherence tomography (OCT). By simulating\nonly the end of the two arms of the interferometer and computing the\ninterference signal in post processing, it is possible to reduce the\ncomputational time required by the simulations and, thus, to simulate much\nbigger environments. Moreover, it is possible to simulate successive A lines\nand thus obtaining a cross section of the sample considered. In this paper we\npresent the model applied to two different samples: a glass rod filled with\nwater-sucrose solution at different concentrations and a peripheral nerve. This\nwork demonstrates the feasibility of using OCT for non-invasive, direct optical\nmonitoring of peripheral nerve activity, which is a long-sought goal of\nneuroscience.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Training Neural Networks as Learning Data-adaptive Kernels: Provable Representation and Approximation Benefits.   Consider the problem: given data pair $(\\mathbf{x}, \\mathbf{y})$ drawn from a\npopulation with $f_*(x) = \\mathbf{E}[\\mathbf{y} | \\mathbf{x} = x]$, specify a\nneural network and run gradient flow on the weights over time until reaching\nany stationarity. How does $f_t$, the function computed by the neural network\nat time $t$, relate to $f_*$, in terms of approximation and representation?\nWhat are the provable benefits of the adaptive representation by neural\nnetworks compared to the pre-specified fixed basis representation in the\nclassical nonparametric literature? We answer the above questions via a dynamic\nreproducing kernel Hilbert space (RKHS) approach indexed by the training\nprocess of neural networks. We show that when reaching any local stationarity,\ngradient flow learns an adaptive RKHS representation, and performs the global\nleast squares projection onto the adaptive RKHS, simultaneously. In addition,\nwe prove that as the RKHS is data-adaptive and task-specific, the residual for\n$f_*$ lies in a subspace that is smaller than the orthogonal complement of the\nRKHS, formalizing the representation and approximation benefits of neural\nnetworks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Polymorphism and the obstinate circularity of second order logic: a victims' tale.   The investigations on higher-order type theories and on the related notion of\nparametric polymorphism constitute the technical counterpart of the old\nfoundational problem of the circularity (or impredicativity) of second and\nhigher order logic. However, the epistemological significance of such\ninvestigations, and of their often non trivial results, has not received much\nattention in the contemporary foundational debate. The results recalled in this\npaper suggest that the question of the circularity of second order logic cannot\nbe reduced to the simple assessment of a vicious circle. Through a comparison\nbetween the faulty consistency arguments given by Frege and Martin-Löf,\nrespectively for the logical system of the Grundgesetze (shown inconsistent by\nRussell's paradox) and for the intuitionistic type theory with a type of all\ntypes (shown inconsistent by Girard's paradox), and the normalization argument\nfor second order type theory (or System F), we indicate a bunch of subtle\nmathematical problems and logical concepts hidden behind the hazardous idea of\nimpredicative quantification, constituting a vast (and largely unexplored)\ndomain for foundational research.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Document Retrieval for Large Scale Content Analysis using Contextualized Dictionaries.   This paper presents a procedure to retrieve subsets of relevant documents\nfrom large text collections for Content Analysis, e.g. in social sciences.\nDocument retrieval for this purpose needs to take account of the fact that\nanalysts often cannot describe their research objective with a small set of key\nterms, especially when dealing with theoretical or rather abstract research\ninterests. Instead, it is much easier to define a set of paradigmatic documents\nwhich reflect topics of interest as well as targeted manner of speech. Thus, in\ncontrast to classic information retrieval tasks we employ manually compiled\ncollections of reference documents to compose large queries of several hundred\nkey terms, called dictionaries. We extract dictionaries via Topic Models and\nalso use co-occurrence data from reference collections. Evaluations show that\nthe procedure improves retrieval results for this purpose compared to\nalternative methods of key term extraction as well as neglecting co-occurrence\ndata.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deorbitalization strategies for meta-GGA exchange-correlation functionals.   We explore the simplification of widely used meta-generalized-gradient\napproximation (mGGA) exchange-correlation functionals to the Laplacian level of\nrefinement by use of approximate kinetic energy density functionals (KEDFs).\nSuch deorbitalization is motivated by the prospect of reducing computational\ncost while recovering a strictly Kohn-Sham local potential framework (rather\nthan the usual generalized Kohn-Sham treatment of mGGAs). A KEDF that has been\nrather successful in solid simulations proves to be inadequate for\ndeorbitalization but we produce other forms which, with parametrization to\nKohn-Sham results (not experimental data) on a small training set, yield rather\ngood results on standard molecular test sets when used to deorbitalize the\nmeta-GGA made very simple, TPSS, and SCAN functionals. We also study the\ndifference between high-fidelity and best-performing deorbitalizations and\ndiscuss possible implications for use in ab initio molecular dynamics\nsimulations of complicated condensed phase systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Fréchet Analysis Of Variance For Random Objects.   Fréchet mean and variance provide a way of obtaining mean and variance for\ngeneral metric space valued random variables and can be used for statistical\nanalysis of data objects that lie in abstract spaces devoid of algebraic\nstructure and operations. Examples of such spaces include covariance matrices,\ngraph Laplacians of networks and univariate probability distribution functions.\nWe derive a central limit theorem for Fréchet variance under mild regularity\nconditions, utilizing empirical process theory, and also provide a consistent\nestimator of the asymptotic variance. These results lead to a test to compare k\npopulations based on Fréchet variance for general metric space valued data\nobjects, with emphasis on comparing means and variances. We examine the finite\nsample performance of this inference procedure through simulation studies for\nseveral special cases that include probability distributions and graph\nLaplacians, which leads to tests to compare populations of networks. The\nproposed methodology has good finite sample performance in simulations for\ndifferent kinds of random objects. We illustrate the proposed methods with data\non mortality profiles of various countries and resting state Functional\nMagnetic Resonance Imaging data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Principal Boundary on Riemannian Manifolds.   We revisit the classification problem and focus on nonlinear methods for\nclassification on manifolds. For multivariate datasets lying on an embedded\nnonlinear Riemannian manifold within the higher-dimensional space, our aim is\nto acquire a classification boundary between the classes with labels. Motivated\nby the principal flow [Panaretos, Pham and Yao, 2014], a curve that moves along\na path of the maximum variation of the data, we introduce the principal\nboundary. From the classification perspective, the principal boundary is\ndefined as an optimal curve that moves in between the principal flows traced\nout from two classes of the data, and at any point on the boundary, it\nmaximizes the margin between the two classes. We estimate the boundary in\nquality with its direction supervised by the two principal flows. We show that\nthe principal boundary yields the usual decision boundary found by the support\nvector machine, in the sense that locally, the two boundaries coincide. By\nmeans of examples, we illustrate how to find, use and interpret the principal\nboundary.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectral determination of semi-regular polygons.   Let us say that an $n$-sided polygon is semi-regular if it is\ncircumscriptible and its angles are all equal but possibly one, which is then\nlarger than the rest. Regular polygons, in particular, are semi-regular. We\nprove that semi-regular polygons are spectrally determined in the class of\nconvex piecewise smooth domains. Specifically, we show that if $\\Omega$ is a\nconvex piecewise smooth planar domain, possibly with straight corners, whose\nDirichlet or Neumann spectrum coincides with that of an $n$-sided semi-regular\npolygon $P_n$, then $\\Omega$ is congruent to $P_n$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lifelong Multi-Agent Path Finding for Online Pickup and Delivery Tasks.   The multi-agent path-finding (MAPF) problem has recently received a lot of\nattention. However, it does not capture important characteristics of many\nreal-world domains, such as automated warehouses, where agents are constantly\nengaged with new tasks. In this paper, we therefore study a lifelong version of\nthe MAPF problem, called the multi-agent pickup and delivery (MAPD) problem. In\nthe MAPD problem, agents have to attend to a stream of delivery tasks in an\nonline setting. One agent has to be assigned to each delivery task. This agent\nhas to first move to a given pickup location and then to a given delivery\nlocation while avoiding collisions with other agents. We present two decoupled\nMAPD algorithms, Token Passing (TP) and Token Passing with Task Swaps (TPTS).\nTheoretically, we show that they solve all well-formed MAPD instances, a\nrealistic subclass of MAPD instances. Experimentally, we compare them against a\ncentralized strawman MAPD algorithm without this guarantee in a simulated\nwarehouse system. TP can easily be extended to a fully distributed MAPD\nalgorithm and is the best choice when real-time computation is of primary\nconcern since it remains efficient for MAPD instances with hundreds of agents\nand tasks. TPTS requires limited communication among agents and balances well\nbetween TP and the centralized MAPD algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Data-Driven Approach for Predicting Vegetation-Related Outages in Power Distribution Systems.   This paper presents a novel data-driven approach for predicting the number of\nvegetation-related outages that occur in power distribution systems on a\nmonthly basis. In order to develop an approach that is able to successfully\nfulfill this objective, there are two main challenges that ought to be\naddressed. The first challenge is to define the extent of the target area. An\nunsupervised machine learning approach is proposed to overcome this difficulty.\nThe second challenge is to correctly identify the main causes of\nvegetation-related outages and to thoroughly investigate their nature. In this\npaper, these outages are categorized into two main groups: growth-related and\nweather-related outages, and two types of models, namely time series and\nnon-linear machine learning regression models are proposed to conduct the\nprediction tasks, respectively. Moreover, various features that can explain the\nvariability in vegetation-related outages are engineered and employed. Actual\noutage data, obtained from a major utility in the U.S., in addition to\ndifferent types of weather and geographical data are utilized to build the\nproposed approach. Finally, a comprehensive case study is carried out to\ndemonstrate how the proposed approach can be used to successfully predict the\nnumber of vegetation-related outages and to help decision-makers to detect\nvulnerable zones in their systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the wave propagation analysis and supratransmission prediction of a metastable modular metastructure for adaptive non-reciprocal energy transmission.   In this research, we investigate the nonlinear energy transmission phenomenon\nin a reconfigurable and adaptable metastable modular metastructure. Numerical\nstudies on a 1D metastable chain uncover that when the driving frequency is\nwithin the stopband of the periodic structure, there exists a threshold input\namplitude, beyond which sudden increase in the energy transmission can be\nobserved. This onset of transmission is due to nonlinear instability and is\nknown as supratransmission. We show that due to spatial asymmetry of\nstrategically configured constituents, such transmission thresholds could shift\nconsiderably when the structure is excited from different ends and therefore\nenabling the non-reciprocal energy transmission. We discover that the critical\nthreshold amplitude can be predicted analytically using a localized\nnonlinear-linear model combining harmonic balancing and transfer matrix\nanalyses. Additionally, influences of important parameters on the change of\nthreshold amplitude are investigated to provide insight on synthesizing systems\nwith desired non-reciprocal characteristics. These investigations elucidate the\nrich and intricate dynamics achievable by nonlinearity, asymmetry, and\nmetastability, and provide new insights and opportunities to accomplish\nadaptable non-reciprocal wave energy transmission.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The dependence of protostar formation on the geometry and strength of the initial magnetic field.   We report results from twelve simulations of the collapse of a molecular\ncloud core to form one or more protostars, comprising three field strengths\n(mass-to-flux ratios, {\\mu}, of 5, 10, and 20) and four field geometries (with\nvalues of the angle between the field and rotation axes, {\\theta}, of 0°,\n20°, 45°, and 90°), using a smoothed particle\nmagnetohydrodynamics method. We find that the values of both parameters have a\nstrong effect on the resultant protostellar system and outflows. This ranges\nfrom the formation of binary systems when {\\mu} = 20 to strikingly differing\noutflow structures for differing values of {\\theta}, in particular highly\nsuppressed outflows when {\\theta} = 90°. Misaligned magnetic fields can\nalso produce warped pseudo-discs where the outer regions align perpendicular to\nthe magnetic field but the innermost region re-orientates to be perpendicular\nto the rotation axis. We follow the collapse to sizes comparable to those of\nfirst cores and find that none of the outflow speeds exceed 8 km s$^{-1}$.\nThese results may place constraints on both observed protostellar outflows, and\nalso on which molecular cloud cores may eventually form either single stars and\nbinaries: a sufficiently weak magnetic field may allow for disc fragmentation,\nwhilst conversely the greater angular momentum transport of a strong field may\ninhibit disc fragmentation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Secure Search on the Cloud via Coresets and Sketches.   \\emph{Secure Search} is the problem of retrieving from a database table (or\nany unsorted array) the records matching specified attributes, as in SQL SELECT\nqueries, but where the database and the query are encrypted. Secure search has\nbeen the leading example for practical applications of Fully Homomorphic\nEncryption (FHE) starting in Gentry's seminal work; however, to the best of our\nknowledge all state-of-the-art secure search algorithms to date are realized by\na polynomial of degree $\\Omega(m)$ for $m$ the number of records, which is\ntypically too slow in practice even for moderate size $m$.\nIn this work we present the first algorithm for secure search that is\nrealized by a polynomial of degree polynomial in $\\log m$. We implemented our\nalgorithm in an open source library based on HELib implementation for the\nBrakerski-Gentry-Vaikuntanthan's FHE scheme, and ran experiments on Amazon's\nEC2 cloud. Our experiments show that we can retrieve the first match in a\ndatabase of millions of entries in less than an hour using a single machine;\nthe time reduced almost linearly with the number of machines.\nOur result utilizes a new paradigm of employing coresets and sketches, which\nare modern data summarization techniques common in computational geometry and\nmachine learning, for efficiency enhancement for homomorphic encryption. As a\ncentral tool we design a novel sketch that returns the first positive entry in\na (not necessarily sparse) array; this sketch may be of independent interest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Large-Margin Classification in Hyperbolic Space.   Representing data in hyperbolic space can effectively capture latent\nhierarchical relationships. With the goal of enabling accurate classification\nof points in hyperbolic space while respecting their hyperbolic geometry, we\nintroduce hyperbolic SVM, a hyperbolic formulation of support vector machine\nclassifiers, and elucidate through new theoretical work its connection to the\nEuclidean counterpart. We demonstrate the performance improvement of hyperbolic\nSVM for multi-class prediction tasks on real-world complex networks as well as\nsimulated datasets. Our work allows analytic pipelines that take the inherent\nhyperbolic geometry of the data into account in an end-to-end fashion without\nresorting to ill-fitting tools developed for Euclidean space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Doing Things Twice (Or Differently): Strategies to Identify Studies for Targeted Validation.   The \"reproducibility crisis\" has been a highly visible source of scientific\ncontroversy and dispute. Here, I propose and review several avenues for\nidentifying and prioritizing research studies for the purpose of targeted\nvalidation. Of the various proposals discussed, I identify scientific data\nscience as being a strategy that merits greater attention among those\ninterested in reproducibility. I argue that the tremendous potential of\nscientific data science for uncovering high-value research studies is a\nsignificant and rarely discussed benefit of the transition to a fully\nopen-access publishing model.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Empirical study on social groups in pedestrian evacuation dynamics.   Pedestrian crowds often include social groups, i.e. pedestrians that walk\ntogether because of social relationships. They show characteristic\nconfigurations and influence the dynamics of the entire crowd. In order to\ninvestigate the impact of social groups on evacuations we performed an\nempirical study with pupils. Several evacuation runs with groups of different\nsizes and different interactions were performed. New group parameters are\nintroduced which allow to describe the dynamics of the groups and the\nconfiguration of the group members quantitatively. The analysis shows a\npossible decrease of evacuation times for large groups due to self-ordering\neffects. Social groups can be approximated as ellipses that orientate along\ntheir direction of motion. Furthermore, explicitly cooperative behaviour among\ngroup members leads to a stronger aggregation of group members and an\nintermittent way of evacuation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence Learning.   We present Deep Voice 3, a fully-convolutional attention-based neural\ntext-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural\nspeech synthesis systems in naturalness while training ten times faster. We\nscale Deep Voice 3 to data set sizes unprecedented for TTS, training on more\nthan eight hundred hours of audio from over two thousand speakers. In addition,\nwe identify common error modes of attention-based speech synthesis networks,\ndemonstrate how to mitigate them, and compare several different waveform\nsynthesis methods. We also describe how to scale inference to ten million\nqueries per day on one single-GPU server.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Impossibility of Supersized Machines.   In recent years, a number of prominent computer scientists, along with\nacademics in fields such as philosophy and physics, have lent credence to the\nnotion that machines may one day become as large as humans. Many have further\nargued that machines could even come to exceed human size by a significant\nmargin. However, there are at least seven distinct arguments that preclude this\noutcome. We show that it is not only implausible that machines will ever exceed\nhuman size, but in fact impossible.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "End-to-End Multi-Task Denoising for joint SDR and PESQ Optimization.   Supervised learning based on a deep neural network recently has achieved\nsubstantial improvement on speech enhancement. Denoising networks learn mapping\nfrom noisy speech to clean one directly, or to a spectra mask which is the\nratio between clean and noisy spectrum. In either case, the network is\noptimized by minimizing mean square error (MSE) between predefined labels and\nnetwork output of spectra or time-domain signal. However, existing schemes have\neither of two critical issues: spectra and metric mismatches. The spectra\nmismatch is a well known issue that any spectra modification after short-time\nFourier transform (STFT), in general, cannot be fully recovered after inverse\nSTFT. The metric mismatch is that a conventional MSE metric is sub-optimal to\nmaximize our target metrics, signal-to-distortion ratio (SDR) and perceptual\nevaluation of speech quality (PESQ). This paper presents a new end-to-end\ndenoising framework with the goal of joint SDR and PESQ optimization. First,\nthe network optimization is performed on the time-domain signals after ISTFT to\navoid spectra mismatch. Second, two loss functions which have improved\ncorrelations with SDR and PESQ metrics are proposed to minimize metric\nmismatch. The experimental result showed that the proposed denoising scheme\nsignificantly improved both SDR and PESQ performance over the existing methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Local Receptive Fields and their Weight Sharing Scheme on Graphs.   We propose a simple and generic layer formulation that extends the properties\nof convolutional layers to any domain that can be described by a graph. Namely,\nwe use the support of its adjacency matrix to design learnable weight sharing\nfilters able to exploit the underlying structure of signals in the same fashion\nas for images. The proposed formulation makes it possible to learn the weights\nof the filter as well as a scheme that controls how they are shared across the\ngraph. We perform validation experiments with image datasets and show that\nthese filters offer performances comparable with convolutional ones.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Certified-Complete Bimanual Manipulation Planner.   Planning motions for two robot arms to move an object collaboratively is a\ndifficult problem, mainly because of the closed-chain constraint, which arises\nwhenever two robot hands simultaneously grasp a single rigid object. In this\npaper, we propose a manipulation planning algorithm to bring an object from an\ninitial stable placement (position and orientation of the object on the support\nsurface) towards a goal stable placement. The key specificity of our algorithm\nis that it is certified-complete: for a given object and a given environment,\nwe provide a certificate that the algorithm will find a solution to any\nbimanual manipulation query in that environment whenever one exists. Moreover,\nthe certificate is constructive: at run-time, it can be used to quickly find a\nsolution to a given query. The algorithm is tested in software and hardware on\na number of large pieces of furniture.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Orbital-dependent correlations in PuCoGa$_5$.   We investigate the normal state of the superconducting compound PuCoGa$_5$\nusing the combination of density functional theory (DFT) and dynamical mean\nfield theory (DMFT), with the continuous time quantum Monte Carlo (CTQMC) and\nthe vertex-corrected one-crossing approximation (OCA) as the impurity solvers.\nOur DFT+DMFT(CTQMC) calculations suggest a strong tendency of Pu-5$f$ orbitals\nto differentiate at low temperatures. The renormalized 5$f_{5/2}$ states\nexhibit a Fermi-liquid behavior whereas one electron in the 5$f_{7/2}$ states\nis at the edge of a Mott localization. We find that the orbital differentiation\nis manifested as the removing of 5$f_{7/2}$ spectral weight from the Fermi\nlevel relative to DFT. We corroborate these conclusions with DFT+DMFT(OCA)\ncalculations which demonstrate that 5$f_{5/2}$ electrons have a much larger\nKondo scale than the 5$f_{7/2}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Non-parametric estimation of Jensen-Shannon Divergence in Generative Adversarial Network training.   Generative Adversarial Networks (GANs) have become a widely popular framework\nfor generative modelling of high-dimensional datasets. However their training\nis well-known to be difficult. This work presents a rigorous statistical\nanalysis of GANs providing straight-forward explanations for common training\npathologies such as vanishing gradients. Furthermore, it proposes a new\ntraining objective, Kernel GANs, and demonstrates its practical effectiveness\non large-scale real-world data sets. A key element in the analysis is the\ndistinction between training with respect to the (unknown) data distribution,\nand its empirical counterpart. To overcome issues in GAN training, we pursue\nthe idea of smoothing the Jensen-Shannon Divergence (JSD) by incorporating\nnoise in the input distributions of the discriminator. As we show, this\neffectively leads to an empirical version of the JSD in which the true and the\ngenerator densities are replaced by kernel density estimates, which leads to\nKernel GANs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal Service Elasticity in Large-Scale Distributed Systems.   A fundamental challenge in large-scale cloud networks and data centers is to\nachieve highly efficient server utilization and limit energy consumption, while\nproviding excellent user-perceived performance in the presence of uncertain and\ntime-varying demand patterns. Auto-scaling provides a popular paradigm for\nautomatically adjusting service capacity in response to demand while meeting\nperformance targets, and queue-driven auto-scaling techniques have been widely\ninvestigated in the literature. In typical data center architectures and cloud\nenvironments however, no centralized queue is maintained, and load balancing\nalgorithms immediately distribute incoming tasks among parallel queues. In\nthese distributed settings with vast numbers of servers, centralized\nqueue-driven auto-scaling techniques involve a substantial communication\noverhead and major implementation burden, or may not even be viable at all.\nMotivated by the above issues, we propose a joint auto-scaling and load\nbalancing scheme which does not require any global queue length information or\nexplicit knowledge of system parameters, and yet provides provably near-optimal\nservice elasticity. We establish the fluid-level dynamics for the proposed\nscheme in a regime where the total traffic volume and nominal service capacity\ngrow large in proportion. The fluid-limit results show that the proposed scheme\nachieves asymptotic optimality in terms of user-perceived delay performance as\nwell as energy consumption. Specifically, we prove that both the waiting time\nof tasks and the relative energy portion consumed by idle servers vanish in the\nlimit. At the same time, the proposed scheme operates in a distributed fashion\nand involves only constant communication overhead per task, thus ensuring\nscalability in massive data center operations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Linear-time approximation schemes for planar minimum three-edge connected and three-vertex connected spanning subgraphs.   We present the first polynomial-time approximation schemes, i.e., (1 +\n{\\epsilon})-approximation algorithm for any constant {\\epsilon} > 0, for the\nminimum three-edge connected spanning subgraph problem and the minimum\nthree-vertex connected spanning subgraph problem in undirected planar graphs.\nBoth the approximation schemes run in linear time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bi-National Delay Pattern Analysis For Commercial and Passenger Vehicles at Niagara Frontier Border.   Border crossing delays between New York State and Southern Ontario cause\nproblems like enormous economic loss and massive environmental pollutions. In\nthis area, there are three border-crossing ports: Peace Bridge (PB), Rainbow\nBridge (RB) and Lewiston-Queenston Bridge (LQ) at Niagara Frontier border. The\ngoals of this paper are to figure out whether the distributions of bi-national\nwait times for commercial and passenger vehicles are evenly distributed among\nthe three ports and uncover the hidden significant influential factors that\nresult in the possible insufficient utilization. The historical border wait\ntime data from 7:00 to 21:00 between 08/22/2016 and 06/20/2017 are archived, as\nwell as the corresponding temporal and weather data. For each vehicle type\ntowards each direction, a Decision Tree is built to identify the various border\ndelay patterns over the three bridges. We find that for the passenger vehicles\nto the USA, the convenient connections between the Canada freeways with USA\nI-190 by LQ and PB may cause these two bridges more congested than RB,\nespecially when it is a holiday in Canada. For the passenger vehicles in the\nother bound, RB is much more congested than LQ and PB in some cases, and the\nvisitors to Niagara Falls in the USA in summer may be a reason. For the\ncommercial trucks to the USA, the various delay patterns show PB is always more\ncongested than LQ. Hour interval and weekend are the most significant factors\nappearing in all the four Decision Trees. These Decision Trees can help the\nauthorities to make specific routing suggestions when the corresponding\nconditions are satisfied.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Construction of curve pairs and their applications.   In this study, we introduce a new approach to curve pairs by using integral\ncurves. We consider the direction curve and donor curve to study curve couples\nsuch as involute-evolute curves, Mannheim partner curves and Bertrand partner\ncurves. We obtain new methods to construct partner curves of a unit speed curve\nand give some applications related to helices, slant helices and plane curves.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Methodological Approach for the Design of a Complex Inclusive Human-Machine System.   Modern industrial automatic machines and robotic cells are equipped with\nhighly complex human-machine interfaces (HMIs) that often prevent human\noperators from an effective use of the automatic systems. In particular, this\napplies to vulnerable users, such as those with low experience or education\nlevel, the elderly and the disabled. To tackle this issue, it becomes necessary\nto design user-oriented HMIs, which adapt to the capabilities and skills of\nusers, thus compensating their limitations and taking full advantage of their\nknowledge. In this paper, we propose a methodological approach to the design of\ncomplex adaptive human-machine systems that might be inclusive of all users, in\nparticular the vulnerable ones. The proposed approach takes into account both\nthe technical requirements and the requirements for ethical, legal and social\nimplications (ELSI) for the design of automatic systems. The technical\nrequirements derive from a thorough analysis of three use cases taken from the\nEuropean project INCLUSIVE. To achieve the ELSI requirements, the MEESTAR\napproach is combined with the specific legal issues for occupational systems\nand requirements of the target users.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotics and Optimal Bandwidth Selection for Nonparametric Estimation of Density Level Sets.   Bandwidth selection is crucial in the kernel estimation of density level\nsets. Risk based on the symmetric difference between the estimated and true\nlevel sets is usually used to measure their proximity. In this paper we provide\nan asymptotic $L^p$ approximation to this risk, where $p$ is characterized by\nthe weight function in the risk. In particular the excess risk corresponds to\nan $L^2$ type of risk, and is adopted in an optimal bandwidth selection rule\nfor nonparametric level set estimation of $d$-dimensional density functions\n($d\\geq 1$).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the compressibility of the transition-metal carbides and nitrides alloys Zr_xNb_{1-x}C and Zr_xNb_{1-x}N.   The 4d-transition-metals carbides (ZrC, NbC) and nitrides (ZrN, NbN) in the\nrocksalt structure, as well as their ternary alloys, have been recently studied\nby means of a first-principles full potential linearized augmented plane waves\nmethod within the local density approximation. These materials are important\nbecause of their interesting mechanical and physical properties, which make\nthem suitable for many technological applications. Here, by using a simple\ntheoretical model, we estimate the bulk moduli of their ternary alloys\nZr$_x$Nb$_{1-x}$C and Zr$_x$Nb$_{1-x}$N in terms of the bulk moduli of the end\nmembers alone. The results are comparable to those deduced from the\nfirst-principles calculations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Modeling and Control of Humanoid Robots in Dynamic Environments: iCub Balancing on a Seesaw.   Forthcoming applications concerning humanoid robots may involve physical\ninteraction between the robot and a dynamic environment. In such scenario,\nclassical balancing and walking controllers that neglect the environment\ndynamics may not be sufficient for achieving a stable robot behavior. This\npaper presents a modeling and control framework for balancing humanoid robots\nin contact with a dynamic environment. We first model the robot and environment\ndynamics, together with the contact constraints. Then, a control strategy for\nstabilizing the full system is proposed. Theoretical results are verified in\nsimulation with robot iCub balancing on a seesaw.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Banach-Alaoglu theorem for Hilbert $H^*$-module.   We provided an analogue Banach-Alaoglu theorem for Hilbert $H^*$-module. We\nconstruct a $\\Lambda$-weak$^*$ topology on a Hilbert $H^*$-module over a proper\n$H^*$-algebra $\\Lambda$, such that the unit ball is compact with respect to\n$\\Lambda$-weak$^*$ topology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Life and work of Egbert Brieskorn (1936 - 2013).   Egbert Brieskorn died on July 11, 2013, a few days after his 77th birthday.\nHe was an impressive personality who has left a lasting impression on all who\nknew him, whether inside or outside of mathematics. Brieskorn was a great\nmathematician, but his interests, his knowledge, and activities ranged far\nbeyond mathematics. In this contribution, which is strongly influenced by many\nyears of personal connectedness of the authors with Brieskorn, we try to give a\ndeeper insight into the life and work of Brieskorn. We illuminate both his\npersonal commitment to peace and the environment as well as his long-term study\nof the life and work of Felix Hausdorff and the publication of Hausdorff's\ncollected works. However, the main focus of the article is on the presentation\nof his remarkable and influential mathematical work.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Identification of Treatment Effects under Conditional Partial Independence.   Conditional independence of treatment assignment from potential outcomes is a\ncommonly used but nonrefutable assumption. We derive identified sets for\nvarious treatment effect parameters under nonparametric deviations from this\nconditional independence assumption. These deviations are defined via a\nconditional treatment assignment probability, which makes it straightforward to\ninterpret. Our results can be used to assess the robustness of empirical\nconclusions obtained under the baseline conditional independence assumption.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Canonical correlation coefficients of high-dimensional Gaussian vectors: finite rank case.   Consider a Gaussian vector $\\mathbf{z}=(\\mathbf{x}',\\mathbf{y}')'$,\nconsisting of two sub-vectors $\\mathbf{x}$ and $\\mathbf{y}$ with dimensions $p$\nand $q$ respectively, where both $p$ and $q$ are proportional to the sample\nsize $n$. Denote by $\\Sigma_{\\mathbf{u}\\mathbf{v}}$ the population\ncross-covariance matrix of random vectors $\\mathbf{u}$ and $\\mathbf{v}$, and\ndenote by $S_{\\mathbf{u}\\mathbf{v}}$ the sample counterpart. The canonical\ncorrelation coefficients between $\\mathbf{x}$ and $\\mathbf{y}$ are known as the\nsquare roots of the nonzero eigenvalues of the canonical correlation matrix\n$\\Sigma_{\\mathbf{x}\\mathbf{x}}^{-1}\\Sigma_{\\mathbf{x}\\mathbf{y}}\\Sigma_{\\mathbf{y}\\mathbf{y}}^{-1}\\Sigma_{\\mathbf{y}\\mathbf{x}}$.\nIn this paper, we focus on the case that $\\Sigma_{\\mathbf{x}\\mathbf{y}}$ is of\nfinite rank $k$, i.e. there are $k$ nonzero canonical correlation coefficients,\nwhose squares are denoted by $r_1\\geq\\cdots\\geq r_k>0$. We study the sample\ncounterparts of $r_i,i=1,\\ldots,k$, i.e. the largest $k$ eigenvalues of the\nsample canonical correlation matrix\n$§_{\\mathbf{x}\\mathbf{x}}^{-1}§_{\\mathbf{x}\\mathbf{y}}§_{\\mathbf{y}\\mathbf{y}}^{-1}§_{\\mathbf{y}\\mathbf{x}}$,\ndenoted by $\\lambda_1\\geq\\cdots\\geq \\lambda_k$. We show that there exists a\nthreshold $r_c\\in(0,1)$, such that for each $i\\in\\{1,\\ldots,k\\}$, when $r_i\\leq\nr_c$, $\\lambda_i$ converges almost surely to the right edge of the limiting\nspectral distribution of the sample canonical correlation matrix, denoted by\n$d_{+}$. When $r_i>r_c$, $\\lambda_i$ possesses an almost sure limit in\n$(d_{+},1]$. We also obtain the limiting distribution of $\\lambda_i$'s under\nappropriate normalization. Specifically, $\\lambda_i$ possesses Gaussian type\nfluctuation if $r_i>r_c$, and follows Tracy-Widom distribution if $r_i<r_c$.\nSome applications of our results are also discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Computational Approach to Extinction Events in Chemical Reaction Networks with Discrete State Spaces.   Recent work of M.D. Johnston et al. has produced sufficient conditions on the\nstructure of a chemical reaction network which guarantee that the corresponding\ndiscrete state space system exhibits an extinction event. The conditions\nconsist of a series of systems of equalities and inequalities on the edges of a\nmodified reaction network called a domination-expanded reaction network. In\nthis paper, we present a computational implementation of these conditions\nwritten in Python and apply the program on examples drawn from the biochemical\nliterature, including a model of polyamine metabolism in mammals and a model of\nthe pentose phosphate pathway in Trypanosoma brucei. We also run the program on\n458 models from the European Bioinformatics Institute's BioModels Database and\nreport our results.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A General Scheme Implicit Force Control for a Flexible-Link Manipulator.   In this paper we propose an implicit force control scheme for a one-link\nflexible manipulator that interact with a compliant environment. The controller\nwas based in the mathematical model of the manipulator, considering the\ndynamics of the beam flexible and the gravitational force. With this method,\nthe controller parameters are obtained from the structural parameters of the\nbeam (link) of the manipulator. This controller ensure the stability based in\nthe Lyapunov Theory. The controller proposed has two closed loops: the inner\nloop is a tracking control with gravitational force and vibration frequencies\ncompensation and the outer loop is a implicit force control. To evaluate the\nperformance of the controller, we have considered to three different\nmanipulators (the length, the diameter were modified) and three environments\nwith compliance modified. The results obtained from simulations verify the\nasymptotic tracking and regulated in position and force respectively and the\nvibrations suppression of the beam in a finite time.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Thickening and sickening the SYK model.   We discuss higher dimensional generalizations of the 0+1-dimensional\nSachdev-Ye-Kitaev (SYK) model that has recently become the focus of intensive\ninterdisciplinary studies by, both, the condensed matter and field-theoretical\ncommunities. Unlike the previous constructions where multiple SYK copies would\nbe coupled to each other and/or hybridized with itinerant fermions via\nspatially short-ranged random hopping processes, we study algebraically varying\nlong-range (spatially and/or temporally) correlated random couplings in the\ngeneral d+1 dimensions. Such pertinent topics as translationally-invariant\nstrong-coupling solutions, emergent reparametrization symmetry, effective\naction for fluctuations, chaotic behavior, and diffusive transport (or a lack\nthereof) are all addressed. We find that the most appealing properties of the\noriginal SYK model that suggest the existence of its 1+1-dimensional\nholographic gravity dual do not survive the aforementioned generalizations,\nthus lending no additional support to the hypothetical broad (including\n'non-AdS/non-CFT') holographic correspondence.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Basic concepts and tools for the Toki Pona minimal and constructed language: description of the language and main issues; analysis of the vocabulary; text synthesis and syntax highlighting; Wordnet synsets.   A minimal constructed language (conlang) is useful for experiments and\ncomfortable for making tools. The Toki Pona (TP) conlang is minimal both in the\nvocabulary (with only 14 letters and 124 lemmas) and in the (about) 10 syntax\nrules. The language is useful for being a used and somewhat established minimal\nconlang with at least hundreds of fluent speakers. This article exposes current\nconcepts and resources for TP, and makes available Python (and Vim) scripted\nroutines for the analysis of the language, synthesis of texts, syntax\nhighlighting schemes, and the achievement of a preliminary TP Wordnet. Focus is\non the analysis of the basic vocabulary, as corpus analyses were found. The\nsynthesis is based on sentence templates, relates to context by keeping track\nof used words, and renders larger texts by using a fixed number of phonemes\n(e.g. for poems) and number of sentences, words and letters (e.g. for\nparagraphs). Syntax highlighting reflects morphosyntactic classes given in the\nofficial dictionary and different solutions are described and implemented in\nthe well-established Vim text editor. The tentative TP Wordnet is made\navailable in three patterns of relations between synsets and word lemmas. In\nsummary, this text holds potentially novel conceptualizations about, and tools\nand results in analyzing, synthesizing and syntax highlighting the TP language.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "BSDEs and SDEs with time-advanced and -delayed coefficients.   This paper introduces a class of backward stochastic differential equations\n(BSDEs), whose coefficients not only depend on the value of its solutions of\nthe present but also the past and the future. For a sufficiently small time\ndelay or a sufficiently small Lipschitz constant, the existence and uniqueness\nof such BSDEs is obtained. As an adjoint process, a class of stochastic\ndifferential equations (SDEs) is introduced, whose coefficients also depend on\nthe present, the past and the future of its solutions. The existence and\nuniqueness of such SDEs is proved for a sufficiently small time advance or a\nsufficiently small Lipschitz constant. A duality between such BSDEs and SDEs is\nestablished.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Radiation Hardness Test of Eljen EJ-500 Optical Cement.   We present a comprehensive account of the proton radiation hardness of Eljen\nTechnology's EJ-500 optical cement used in the construction of experiment\ndetectors. The cement was embedded into five plastic scintillator tiles which\nwere each exposed to one of five different levels of radiation by a 50 MeV\nproton beam produced at the 88-Inch Cyclotron at Lawrence Berkeley National\nLaboratory. A cosmic ray telescope setup was used to measure signal amplitudes\nbefore and after irradiation. Another post-radiation measurement was taken four\nmonths after the experiment to investigate whether the radiation damage to the\ncement recovers after a short amount of time. We verified that the radiation\ndamage to the tiles increased with increasing dose but showed significant\nimprovement after the four months time interval.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Data Distillation for Controlling Specificity in Dialogue Generation.   People speak at different levels of specificity in different situations.\nDepending on their knowledge, interlocutors, mood, etc.} A conversational agent\nshould have this ability and know when to be specific and when to be general.\nWe propose an approach that gives a neural network--based conversational agent\nthis ability. Our approach involves alternating between \\emph{data\ndistillation} and model training : removing training examples that are closest\nto the responses most commonly produced by the model trained from the last\nround and then retrain the model on the remaining dataset. Dialogue generation\nmodels trained with different degrees of data distillation manifest different\nlevels of specificity.\nWe then train a reinforcement learning system for selecting among this pool\nof generation models, to choose the best level of specificity for a given\ninput. Compared to the original generative model trained without distillation,\nthe proposed system is capable of generating more interesting and\nhigher-quality responses, in addition to appropriately adjusting specificity\ndepending on the context.\nOur research constitutes a specific case of a broader approach involving\ntraining multiple subsystems from a single dataset distinguished by differences\nin a specific property one wishes to model. We show that from such a set of\nsubsystems, one can use reinforcement learning to build a system that tailors\nits output to different input contexts at test time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Lifelong Learning Approach to Brain MR Segmentation Across Scanners and Protocols.   Convolutional neural networks (CNNs) have shown promising results on several\nsegmentation tasks in magnetic resonance (MR) images. However, the accuracy of\nCNNs may degrade severely when segmenting images acquired with different\nscanners and/or protocols as compared to the training data, thus limiting their\npractical utility. We address this shortcoming in a lifelong multi-domain\nlearning setting by treating images acquired with different scanners or\nprotocols as samples from different, but related domains. Our solution is a\nsingle CNN with shared convolutional filters and domain-specific batch\nnormalization layers, which can be tuned to new domains with only a few\n($\\approx$ 4) labelled images. Importantly, this is achieved while retaining\nperformance on the older domains whose training data may no longer be\navailable. We evaluate the method for brain structure segmentation in MR\nimages. Results demonstrate that the proposed method largely closes the gap to\nthe benchmark, which is training a dedicated CNN for each scanner.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Disentangled Representations with Semi-Supervised Deep Generative Models.   Variational autoencoders (VAEs) learn representations of data by jointly\ntraining a probabilistic encoder and decoder network. Typically these models\nencode all features of the data into a single variable. Here we are interested\nin learning disentangled representations that encode distinct aspects of the\ndata into separate variables. We propose to learn such representations using\nmodel architectures that generalise from standard VAEs, employing a general\ngraphical model structure in the encoder and decoder. This allows us to train\npartially-specified models that make relatively strong assumptions about a\nsubset of interpretable variables and rely on the flexibility of neural\nnetworks to learn representations for the remaining variables. We further\ndefine a general objective for semi-supervised learning in this model class,\nwhich can be approximated using an importance sampling procedure. We evaluate\nour framework's ability to learn disentangled representations, both by\nqualitative exploration of its generative capacity, and quantitative evaluation\nof its discriminative ability on a variety of models and datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SceneCut: Joint Geometric and Object Segmentation for Indoor Scenes.   This paper presents SceneCut, a novel approach to jointly discover previously\nunseen objects and non-object surfaces using a single RGB-D image. SceneCut's\njoint reasoning over scene semantics and geometry allows a robot to detect and\nsegment object instances in complex scenes where modern deep learning-based\nmethods either fail to separate object instances, or fail to detect objects\nthat were not seen during training. SceneCut automatically decomposes a scene\ninto meaningful regions which either represent objects or scene surfaces. The\ndecomposition is qualified by an unified energy function over objectness and\ngeometric fitting. We show how this energy function can be optimized\nefficiently by utilizing hierarchical segmentation trees. Moreover, we leverage\na pre-trained convolutional oriented boundary network to predict accurate\nboundaries from images, which are used to construct high-quality region\nhierarchies. We evaluate SceneCut on several different indoor environments, and\nthe results show that SceneCut significantly outperforms all the existing\nmethods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ADE surfaces and their moduli.   We define a class of surfaces and surface pairs corresponding to the ADE root\nlattices and construct compactifications of their moduli spaces, generalizing\nLosev-Manin spaces of curves.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Classification of Local Field Potentials using Gaussian Sequence Model.   A problem of classification of local field potentials (LFPs), recorded from\nthe prefrontal cortex of a macaque monkey, is considered. An adult macaque\nmonkey is trained to perform a memory-based saccade. The objective is to decode\nthe eye movement goals from the LFP collected during a memory period. The LFP\nclassification problem is modeled as that of classification of smooth functions\nembedded in Gaussian noise. It is then argued that using minimax function\nestimators as features would lead to consistent LFP classifiers. The theory of\nGaussian sequence models allows us to represent minimax estimators as finite\ndimensional objects. The LFP classifier resulting from this mathematical\nendeavor is a spectrum based technique, where Fourier series coefficients of\nthe LFP data, followed by appropriate shrinkage and thresholding, are used as\nfeatures in a linear discriminant classifier. The classifier is then applied to\nthe LFP data to achieve high decoding accuracy. The function classification\napproach taken in the paper also provides a systematic justification for using\nFourier series, with shrinkage and thresholding, as features for the problem,\nas opposed to using the power spectrum. It also suggests that phase information\nis crucial to the decision making.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discovering Visual Concept Structure with Sparse and Incomplete Tags.   Discovering automatically the semantic structure of tagged visual data (e.g.\nweb videos and images) is important for visual data analysis and\ninterpretation, enabling the machine intelligence for effectively processing\nthe fast-growing amount of multi-media data. However, this is non-trivial due\nto the need for jointly learning underlying correlations between heterogeneous\nvisual and tag data. The task is made more challenging by inherently sparse and\nincomplete tags. In this work, we develop a method for modelling the inherent\nvisual data concept structures based on a novel Hierarchical-Multi-Label Random\nForest model capable of correlating structured visual and tag information so as\nto more accurately interpret the visual semantics, e.g. disclosing meaningful\nvisual groups with similar high-level concepts, and recovering missing tags for\nindividual visual data samples. Specifically, our model exploits hierarchically\nstructured tags of different semantic abstractness and multiple tag statistical\ncorrelations in addition to modelling visual and tag interactions. As a result,\nour model is able to discover more accurate semantic correlation between\ntextual tags and visual features, and finally providing favourable visual\nsemantics interpretation even with highly sparse and incomplete tags. We\ndemonstrate the advantages of our proposed approach in two fundamental\napplications, visual data clustering and missing tag completion, on\nbenchmarking video (i.e. TRECVID MED 2011) and image (i.e. NUS-WIDE) datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Maximum a posteriori estimation through simulated annealing for binary asteroid orbit determination.   This paper considers a new method for the binary asteroid orbit determination\nproblem. The method is based on the Bayesian approach with a global\noptimisation algorithm. The orbital parameters to be determined are modelled\nthrough an a posteriori distribution made of a priori and likelihood terms. The\nfirst term constrains the parameters space and it allows the introduction of\navailable knowledge about the orbit. The second term is based on given\nobservations and it allows us to use and compare different observational error\nmodels. Once the a posteriori model is built, the estimator of the orbital\nparameters is computed using a global optimisation procedure: the simulated\nannealing algorithm. The maximum a posteriori (MAP) techniques are verified\nusing simulated and real data. The obtained results validate the proposed\nmethod. The new approach guarantees independence of the initial parameters\nestimation and theoretical convergence towards the global optimisation\nsolution. It is particularly useful in these situations, whenever a good\ninitial orbit estimation is difficult to get, whenever observations are not\nwell-sampled, and whenever the statistical behaviour of the observational\nerrors cannot be stated Gaussian like.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stability of laminar Couette flow of compressible fluids.   Cylindrical Couette flow is a subject where the main focus has long been on\nthe onset of turbulence or, more precisely, the limit of stability of the\nsimplest laminar flow. The theoretical framework of this paper is a recently\ndeveloped action principle for hydrodynamics. It incorporates Euler-Lagrange\nequations that are in essential agreement with the Navier-Stokes equation, but\napplicable to the general case of a compressible fluid. The variational\nprinciple incorporates the equation of continuity, a canonical structure and a\nconserved Hamiltonian. The density is compressible, characterized by a general\n(non-polar) equation of state, and homogeneous. The onset of instability is\noften accompanied by bubble formation. It is proposed that the limit of\nstability of laminar Couette flow may some times be related to cavitation. In\ncontrast to traditional stability theory we are not looking for mathematical\ninstabilities of a system of differential equations, but instead for the\npossibility that the system is driven to a metastable or unstable\nconfiguration. The application of this idea to cylindrical Couette flow\nreported here turns out to account rather well for the observations. The\nfailure of a famous criterion due to Rayleigh is well known. It is here shown\nthat it may be due to the use of methods that are appropriate only in the case\nthat the equations of motion are derived from an action principle.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Tractable and Scalable Schatten Quasi-Norm Approximations for Rank Minimization.   The Schatten quasi-norm was introduced to bridge the gap between the trace\nnorm and rank function. However, existing algorithms are too slow or even\nimpractical for large-scale problems. Motivated by the equivalence relation\nbetween the trace norm and its bilinear spectral penalty, we define two\ntractable Schatten norms, i.e.\\ the bi-trace and tri-trace norms, and prove\nthat they are in essence the Schatten-$1/2$ and $1/3$ quasi-norms,\nrespectively. By applying the two defined Schatten quasi-norms to various rank\nminimization problems such as MC and RPCA, we only need to solve much smaller\nfactor matrices. We design two efficient linearized alternating minimization\nalgorithms to solve our problems and establish that each bounded sequence\ngenerated by our algorithms converges to a critical point. We also provide the\nrestricted strong convexity (RSC) based and MC error bounds for our algorithms.\nOur experimental results verified both the efficiency and effectiveness of our\nalgorithms compared with the state-of-the-art methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Word Problem of $\\mathbb{Z}^n$ Is a Multiple Context-Free Language.   The \\emph{word problem} of a group $G = \\langle \\Sigma \\rangle$ can be\ndefined as the set of formal words in $\\Sigma^*$ that represent the identity in\n$G$. When viewed as formal languages, this gives a strong connection between\nclasses of groups and classes of formal languages. For example, Anisimov showed\nthat a group is finite if and only if its word problem is a regular language,\nand Muller and Schupp showed that a group is virtually-free if and only if its\nword problem is a context-free language. Above this, not much was known, until\nSalvati showed recently that the word problem of $\\mathbb{Z}^2$ is a multiple\ncontext-free language, giving first such example. We generalize Salvati's\nresult to show that the word problem of $\\mathbb{Z}^n$ is a multiple\ncontext-free language for any $n$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using Matching to Detect Infeasibility of Some Integer Programs.   A novel matching based heuristic algorithm designed to detect specially\nformulated infeasible zero-one IPs is presented. The algorithm input is a set\nof nested doubly stochastic subsystems and a set E of instance defining\nvariables set at zero level. The algorithm deduces additional variables at zero\nlevel until either a constraint is violated (the IP is infeasible), or no more\nvariables can be deduced zero (the IP is undecided). All feasible IPs, and all\ninfeasible IPs not detected infeasible are undecided. We successfully apply the\nalgorithm to a small set of specially formulated infeasible zero-one IP\ninstances of the Hamilton cycle decision problem. We show how to model both the\ngraph and subgraph isomorphism decision problems for input to the algorithm.\nIncreased levels of nested doubly stochastic subsystems can be implemented\ndynamically. The algorithm is designed for parallel processing, and for\ninclusion of techniques in addition to matching.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Baryon acoustic oscillations from the complete SDSS-III Ly$α$-quasar cross-correlation function at $z=2.4$.   We present a measurement of baryon acoustic oscillations (BAO) in the\ncross-correlation of quasars with the Ly$\\alpha$-forest flux-transmission at a\nmean redshift $z=2.40$. The measurement uses the complete SDSS-III data sample:\n168,889 forests and 234,367 quasars from the SDSS Data Release DR12. In\naddition to the statistical improvement on our previous study using DR11, we\nhave implemented numerous improvements at the analysis level allowing a more\naccurate measurement of this cross-correlation. We also developed the first\nsimulations of the cross-correlation allowing us to test different aspects of\nour data analysis and to search for potential systematic errors in the\ndetermination of the BAO peak position. We measure the two ratios\n$D_{H}(z=2.40)/r_{d} = 9.01 \\pm 0.36$ and $D_{M}(z=2.40)/r_{d} = 35.7 \\pm 1.7$,\nwhere the errors include marginalization over the non-linear velocity of\nquasars and the metal - quasar cross-correlation contribution, among other\neffects. These results are within $1.8\\sigma$ of the prediction of the\nflat-$\\Lambda$CDM model describing the observed CMB anisotropies. We combine\nthis study with the Ly$\\alpha$-forest auto-correlation function\n[2017A&A...603A..12B], yielding $D_{H}(z=2.40)/r_{d} = 8.94 \\pm 0.22$ and\n$D_{M}(z=2.40)/r_{d} = 36.6 \\pm 1.2$, within $2.3\\sigma$ of the same\nflat-$\\Lambda$CDM model.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Power Spectral Density Applied to the Analysis of Old Canvases.   A routine task for art historians is painting diagnostics, such as dating or\nattribution. Signal processing of the X-ray image of a canvas provides useful\ninformation about its fabric. However, previous methods may fail when very old\nand deteriorated artworks or simply canvases of small size are studied. We\npresent a new framework to analyze and further characterize the paintings from\ntheir radiographs. First, we start from a general analysis of lattices and\nprovide new unifying results about the theoretical spectra of weaves. Then, we\nuse these results to infer the main structure of the fabric, like the type of\nweave and the thread densities. We propose a practical estimation of these\ntheoretical results from paintings with the averaged power spectral density\n(PSD), which provides a more robust tool. Furthermore, we found that the PSD\nprovides a fingerprint that characterizes the whole canvas. We search and\ndiscuss some distinctive features we may find in that fingerprint. We apply\nthese results to several masterpieces of the 17th and 18th centuries from the\nMuseo Nacional del Prado to show that this approach yields accurate results in\nthread counting and is very useful for paintings comparison, even in situations\nwhere previous methods fail.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Ground-state properties of unitary bosons: from clusters to matter.   The properties of cold Bose gases at unitarity have been extensively\ninvestigated in the last few years both theoretically and experimentally. In\nthis paper we use a family of interactions tuned to two-body unitarity and very\nweak three-body binding to demonstrate the universal properties of both\nclusters and matter. We determine the universal properties of finite clusters\nup to 60 particles and, for the first time, explicitly demonstrate the\nsaturation of energy and density with particle number and compare with bulk\nproperties. At saturation in the bulk we determine the energy, density, two-\nand three-body contacts and the condensate fraction. We find that uniform\nmatter is more bound than three-body clusters by nearly two orders of\nmagnitude, the two-body contact is very large in absolute terms, and yet the\ncondensate fraction is also very large, greater than 90%. Equilibrium\nproperties of these systems may be experimentally accessible through rapid\nquenching of weakly-interacting boson superfluids.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Performance Analysis of Robust Stable PID Controllers Using Dominant Pole Placement for SOPTD Process Models.   This paper derives new formulations for designing dominant pole placement\nbased proportional-integral-derivative (PID) controllers to handle second order\nprocesses with time delays (SOPTD). Previously, similar attempts have been made\nfor pole placement in delay-free systems. The presence of the time delay term\nmanifests itself as a higher order system with variable number of interlaced\npoles and zeros upon Pade approximation, which makes it difficult to achieve\nprecise pole placement control. We here report the analytical expressions to\nconstrain the closed loop dominant and non-dominant poles at the desired\nlocations in the complex s-plane, using a third order Pade approximation for\nthe delay term. However, invariance of the closed loop performance with\ndifferent time delay approximation has also been verified using increasing\norder of Pade, representing a closed to reality higher order delay dynamics.\nThe choice of the nature of non-dominant poles e.g. all being complex, real or\na combination of them modifies the characteristic equation and influences the\nachievable stability regions. The effect of different types of non-dominant\npoles and the corresponding stability regions are obtained for nine test-bench\nprocesses indicating different levels of open-loop damping and lag to delay\nratio. Next, we investigate which expression yields a wider stability region in\nthe design parameter space by using Monte Carlo simulations while uniformly\nsampling a chosen design parameter space. Various time and frequency domain\ncontrol performance parameters are investigated next, as well as their\ndeviations with uncertain process parameters, using thousands of Monte Carlo\nsimulations, around the robust stable solution for each of the nine test-bench\nprocesses.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Attack Analysis for Distributed Control Systems: An Internal Model Principle Approach.   Although adverse effects of attacks have been acknowledged in many\ncyber-physical systems, there is no system-theoretic comprehension of how a\ncompromised agent can leverage communication capabilities to maximize the\ndamage in distributed multi-agent systems. A rigorous analysis of\ncyber-physical attacks enables us to increase the system awareness against\nattacks and design more resilient control protocols. To this end, we will take\nthe role of the attacker to identify the worst effects of attacks on root nodes\nand non-root nodes in a distributed control system. More specifically, we show\nthat a stealthy attack on root nodes can mislead the entire network to a wrong\nunderstanding of the situation and even destabilize the synchronization\nprocess. This will be called the internal model principle for the attacker and\nwill intensify the urgency of designing novel control protocols to mitigate\nthese types of attacks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Information Diffusion in Social Networks: Friendship Paradox based Models and Statistical Inference.   Dynamic models and statistical inference for the diffusion of information in\nsocial networks is an area which has witnessed remarkable progress in the last\ndecade due to the proliferation of social networks. Modeling and inference of\ndiffusion of information has applications in targeted advertising and\nmarketing, forecasting elections, predicting investor sentiment and identifying\nepidemic outbreaks. This chapter discusses three important aspects related to\ninformation diffusion in social networks: (i) How does observation bias named\nfriendship paradox (a graph theoretic consequence) and monophilic contagion\n(influence of friends of friends) affect information diffusion dynamics. (ii)\nHow can social networks adapt their structural connectivity depending on the\nstate of information diffusion. (iii) How one can estimate the state of the\nnetwork induced by information diffusion. The motivation for all three topics\nconsidered in this chapter stems from recent findings in network science and\nsocial sensing. Further, several directions for future research that arise from\nthese topics are also discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Multi-layer Information Bottleneck Problem.   The muti-layer information bottleneck (IB) problem, where information is\npropagated (or successively refined) from layer to layer, is considered. Based\non information forwarded by the preceding layer, each stage of the network is\nrequired to preserve a certain level of relevance with regards to a specific\nhidden variable, quantified by the mutual information. The hidden variables and\nthe source can be arbitrarily correlated. The optimal trade-off between rates\nof relevance and compression (or complexity) is obtained through a\nsingle-letter characterization, referred to as the rate-relevance region.\nConditions of successive refinabilty are given. Binary source with BSC hidden\nvariables and binary source with BSC/BEC mixed hidden variables are both proved\nto be successively refinable. We further extend our result to Guassian models.\nA counterexample of successive refinability is also provided.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The GBT Beam Shape at 109 GHz.   With the installation of the Argus 16-pixel receiver covering 75-115 GHz on\nthe Green Bank Telescope (GBT), it is now possible to characterize the antenna\nbeam at very high frequencies, where the use of the active surface and\nout-of-focus holography are critical to the telescope's performance. A recent\nmeasurement in good weather conditions (low atmospheric opacity, low winds, and\nstable night-time thermal conditions) at 109.4 GHz yielded a FWHM beam of\n6.7\"x6.4\" in azimuth and elevation, respectively. This corresponds to\n1.16+/-0.03 Lambda/D at 109.4 GHz. The derived ratio agrees well with the\nlow-frequency value of 1.18+/-0.03 Lambda/D measured at 9.0 GHz. There are no\ndetectable side-lobes at either frequency. In good weather conditions and after\napplying the standard antenna corrections (pointing, focus, and the active\nsurface corrections for gravity and thermal effects), there is no measurable\ndegradation of the beam of the GBT at its highest operational frequencies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Structure Preserving Model Reduction of Parametric Hamiltonian Systems.   While reduced-order models (ROMs) have been popular for efficiently solving\nlarge systems of differential equations, the stability of reduced models over\nlong-time integration is of present challenges. We present a greedy approach\nfor ROM generation of parametric Hamiltonian systems that captures the\nsymplectic structure of Hamiltonian systems to ensure stability of the reduced\nmodel. Through the greedy selection of basis vectors, two new vectors are added\nat each iteration to the linear vector space to increase the accuracy of the\nreduced basis. We use the error in the Hamiltonian due to model reduction as an\nerror indicator to search the parameter space and identify the next best basis\nvectors. Under natural assumptions on the set of all solutions of the\nHamiltonian system under variation of the parameters, we show that the greedy\nalgorithm converges with exponential rate. Moreover, we demonstrate that\ncombining the greedy basis with the discrete empirical interpolation method\nalso preserves the symplectic structure. This enables the reduction of the\ncomputational cost for nonlinear Hamiltonian systems. The efficiency, accuracy,\nand stability of this model reduction technique is illustrated through\nsimulations of the parametric wave equation and the parametric Schrodinger\nequation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Exploratory Study of Field Failures.   Field failures, that is, failures caused by faults that escape the testing\nphase leading to failures in the field, are unavoidable. Improving verification\nand validation activities before deployment can identify and timely remove many\nbut not all faults, and users may still experience a number of annoying\nproblems while using their software systems. This paper investigates the nature\nof field failures, to understand to what extent further improving in-house\nverification and validation activities can reduce the number of failures in the\nfield, and frames the need of new approaches that operate in the field. We\nreport the results of the analysis of the bug reports of five applications\nbelonging to three different ecosystems, propose a taxonomy of field failures,\nand discuss the reasons why failures belonging to the identified classes cannot\nbe detected at design time but shall be addressed at runtime. We observe that\nmany faults (70%) are intrinsically hard to detect at design-time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Neural Architecture Search with Bayesian Optimisation and Optimal Transport.   Bayesian Optimisation (BO) refers to a class of methods for global\noptimisation of a function $f$ which is only accessible via point evaluations.\nIt is typically used in settings where $f$ is expensive to evaluate. A common\nuse case for BO in machine learning is model selection, where it is not\npossible to analytically model the generalisation performance of a statistical\nmodel, and we resort to noisy and expensive training and validation procedures\nto choose the best model. Conventional BO methods have focused on Euclidean and\ncategorical domains, which, in the context of model selection, only permits\ntuning scalar hyper-parameters of machine learning algorithms. However, with\nthe surge of interest in deep learning, there is an increasing demand to tune\nneural network \\emph{architectures}. In this work, we develop NASBOT, a\nGaussian process based BO framework for neural architecture search. To\naccomplish this, we develop a distance metric in the space of neural network\narchitectures which can be computed efficiently via an optimal transport\nprogram. This distance might be of independent interest to the deep learning\ncommunity as it may find applications outside of BO. We demonstrate that NASBOT\noutperforms other alternatives for architecture search in several cross\nvalidation based model selection tasks on multi-layer perceptrons and\nconvolutional neural networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Landau levels from neutral Bogoliubov particles in two-dimensional nodal superconductors under strain and doping gradients.   Motivated by recent work on strain-induced pseudo-magnetic fields in Dirac\nand Weyl semimetals, we analyze the possibility of analogous fields in\ntwo-dimensional nodal superconductors. We consider the prototypical case of a\nd-wave superconductor, a representative of the cuprate family, and find that\nthe presence of weak strain leads to pseudo-magnetic fields and Landau\nquantization of Bogoliubov quasiparticles in the low-energy sector. A similar\neffect is induced by the presence of generic, weak doping gradients. In\ncontrast to genuine magnetic fields in superconductors, the strain- and doping\ngradient-induced pseudo-magnetic fields couple in a way that preserves\ntime-reversal symmetry and is not subject to the screening associated with the\nMeissner effect. These effects can be probed by tuning weak applied\nsupercurrents which lead to shifts in the energies of the Landau levels and\nhence to quantum oscillations in thermodynamic and transport quantities.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Space dependent adhesion forces mediated by transient elastic linkages : new convergence and global existence results.   In the first part of this work we show the convergence with respect to an\nasymptotic parameter {\\epsilon} of a delayed heat equation. It represents a\nmathematical extension of works considered previously by the authors [Milisic\net al. 2011, Milisic et al. 2016]. Namely, this is the first result involving\ndelay operators approximating protein linkages coupled with a spatial elliptic\nsecond order operator. For the sake of simplicity we choose the Laplace\noperator, although more general results could be derived. The main arguments\nare (i) new energy estimates and (ii) a stability result extended from the\nprevious work to this more involved context. They allow to prove convergence of\nthe delay operator to a friction term together with the Laplace operator in the\nsame asymptotic regime considered without the space dependence in [Milisic et\nal, 2011]. In a second part we extend fixed-point results for the fully\nnon-linear model introduced in [Milisic et al, 2016] and prove global existence\nin time. This shows that the blow-up scenario observed previously does not\noccur. Since the latter result was interpreted as a rupture of adhesion forces,\nwe discuss the possibility of bond breaking both from the analytic and\nnumerical point of view.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "The dependence of cluster galaxy properties on the central entropy of their host cluster.   We present a study of the connection between brightest cluster galaxies\n(BCGs) and their host galaxy clusters. Using galaxy clusters at $0.1<z<0.3$\nfrom the Hectospec Cluster Survey (HeCS) with X-ray information from the\nArchive of {\\it Chandra} Cluster Entropy Profile Tables (ACCEPT), we confirm\nthat BCGs in low central entropy clusters are well aligned with the X-ray\ncenter. Additionally, the magnitude difference between BCG and the 2nd\nbrightest one also correlates with the central entropy of the intracluster\nmedium. From the red-sequence (RS) galaxies, we cannot find significant\ndependence of RS color scatter and stellar population on the central entropy of\nthe intracluster medium of their host cluster. However, BCGs in low entropy\nclusters are systematically less massive than those in high entropy clusters,\nalthough this is dependent on the method used to derive the stellar mass of\nBCGs. In contrast, the stellar velocity dispersion of BCGs shows no dependence\non BCG activity and cluster central entropy. This implies that the potential of\nthe BCG is established earlier and the activity leading to optical emission\nlines is dictated by the properties of the intracluster medium in the cluster\ncore.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Real-World Modeling of a Pathfinding Robot Using Robot Operating System (ROS).   This paper presents a practical approach towards implementing pathfinding\nalgorithms on real-world and low-cost non- commercial hardware platforms. While\nusing robotics simulation platforms as a test-bed for our algorithms we easily\noverlook real- world exogenous problems that are developed by external factors.\nSuch problems involve robot wheel slips, asynchronous motors, abnormal sensory\ndata or unstable power sources. The real-world dynamics tend to be very painful\neven for executing simple algorithms like a Wavefront planner or A-star search.\nThis paper addresses designing techniques that tend to be robust as well as\nreusable for any hardware platforms; covering problems like controlling\nasynchronous drives, odometry offset issues and handling abnormal sensory\nfeedback. The algorithm implementation medium and hardware design tools have\nbeen kept general in order to present our work as a serving platform for future\nresearchers and robotics enthusiast working in the field of path planning\nrobotics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Casas-Alvero conjecture.   The conjecture is formulated in an affine structure and linked with\ndimension=1 of the defined CA sets. Then some known results are proved in this\ncontext. The short intended proof relies on a direct yet unclear statement\nabout homogeneous dependence of algebraic equations. This might not be a\ncomplete proof or even one on the right track, but it may provoke more thoughts\nin this respect as expected.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Computer-assisted proof of heteroclinic connections in the one-dimensional Ohta-Kawasaki model.   We present a computer-assisted proof of heteroclinic connections in the\none-dimensional Ohta-Kawasaki model of diblock copolymers. The model is a\nfourth-order parabolic partial differential equation subject to homogeneous\nNeumann boundary conditions, which contains as a special case the celebrated\nCahn-Hilliard equation. While the attractor structure of the latter model is\ncompletely understood for one-dimensional domains, the diblock copolymer\nextension exhibits considerably richer long-term dynamical behavior, which\nincludes a high level of multistability. In this paper, we establish the\nexistence of certain heteroclinic connections between the homogeneous\nequilibrium state, which represents a perfect copolymer mixture, and all local\nand global energy minimizers. In this way, we show that not every solution\noriginating near the homogeneous state will converge to the global energy\nminimizer, but rather is trapped by a stable state with higher energy. This\nphenomenon can not be observed in the one-dimensional Cahn-Hillard equation,\nwhere generic solutions are attracted by a global minimizer.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "AC-Biased Shift Registers as Fabrication Process Benchmark Circuits and Flux Trapping Diagnostic Tool.   We develop an ac-biased shift register introduced in our previous work (V.K.\nSemenov et al., IEEE Trans. Appl. Supercond., vol. 25, no. 3, 1301507, June\n2015) into a benchmark circuit for evaluation of superconductor electronics\nfabrication technology. The developed testing technique allows for extracting\nmargins of all individual cells in the shift register, which in turn makes it\npossible to estimate statistical distribution of Josephson junctions in the\ncircuit. We applied this approach to successfully test registers having 8, 16,\n36, and 202 thousand cells and, respectively, about 33000, 65000, 144000, and\n809000 Josephson junctions. The circuits were fabricated at MIT Lincoln\nLaboratory, using a fully planarized process, 0.4 {\\mu}m inductor linewidth,\nand 1.33x10^6 cm^-2 junction density. They are presently the largest\noperational superconducting SFQ circuits ever made. The developed technique\ndistinguishes between hard defects (fabrication-related) and soft defects\n(measurement-related) and locates them in the circuit. The soft defects are\nspecific to superconducting circuits and caused by magnetic flux trapping\neither inside the active cells or in the dedicated flux-trapping moats near the\ncells. The number and distribution of soft defects depend on the ambient\nmagnetic field and vary with thermal cycling even if done in the same magnetic\nenvironment.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Survey of Riccati Equation Results in Negative Imaginary Systems Theory and Quantum Control Theory.   This paper presents a survey of some new applications of algebraic Riccati\nequations. In particular, the paper surveys some recent results on the use of\nalgebraic Riccati equations in testing whether a system is negative imaginary\nand in synthesizing state feedback controllers which make the closed loop\nsystem negative imaginary. The paper also surveys the use of Riccati equation\nmethods in the control of quantum linear systems including coherent $H^\\infty$\ncontrol.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Poisoning Attacks to Graph-Based Recommender Systems.   Recommender system is an important component of many web services to help\nusers locate items that match their interests. Several studies showed that\nrecommender systems are vulnerable to poisoning attacks, in which an attacker\ninjects fake data to a given system such that the system makes recommendations\nas the attacker desires. However, these poisoning attacks are either agnostic\nto recommendation algorithms or optimized to recommender systems that are not\ngraph-based. Like association-rule-based and matrix-factorization-based\nrecommender systems, graph-based recommender system is also deployed in\npractice, e.g., eBay, Huawei App Store. However, how to design optimized\npoisoning attacks for graph-based recommender systems is still an open problem.\nIn this work, we perform a systematic study on poisoning attacks to graph-based\nrecommender systems. Due to limited resources and to avoid detection, we assume\nthe number of fake users that can be injected into the system is bounded. The\nkey challenge is how to assign rating scores to the fake users such that the\ntarget item is recommended to as many normal users as possible. To address the\nchallenge, we formulate the poisoning attacks as an optimization problem,\nsolving which determines the rating scores for the fake users. We also propose\ntechniques to solve the optimization problem. We evaluate our attacks and\ncompare them with existing attacks under white-box (recommendation algorithm\nand its parameters are known), gray-box (recommendation algorithm is known but\nits parameters are unknown), and black-box (recommendation algorithm is\nunknown) settings using two real-world datasets. Our results show that our\nattack is effective and outperforms existing attacks for graph-based\nrecommender systems. For instance, when 1% fake users are injected, our attack\ncan make a target item recommended to 580 times more normal users in certain\nscenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Minimax Rényi Redundancy.   The redundancy for universal lossless compression of discrete memoryless\nsources in Campbell's setting is characterized as a minimax Rényi divergence,\nwhich is shown to be equal to the maximal $\\alpha$-mutual information via a\ngeneralized redundancy-capacity theorem. Special attention is placed on the\nanalysis of the asymptotics of minimax Rényi divergence, which is determined\nup to a term vanishing in blocklength.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reverse Quantum Annealing Approach to Portfolio Optimization Problems.   We investigate a hybrid quantum-classical solution method to the\nmean-variance portfolio optimization problems. Starting from real financial\ndata statistics and following the principles of the Modern Portfolio Theory, we\ngenerate parametrized samples of portfolio optimization problems that can be\nrelated to quadratic binary optimization forms programmable in the analog\nD-Wave Quantum Annealer 2000Q. The instances are also solvable by an\nindustry-established Genetic Algorithm approach, which we use as a classical\nbenchmark. We investigate several options to run the quantum computation\noptimally, ultimately discovering that the best results in terms of expected\ntime-to-solution as a function of number of variables for the hardest instances\nset are obtained by seeding the quantum annealer with a solution candidate\nfound by a greedy local search and then performing a reverse annealing\nprotocol. The optimized reverse annealing protocol is found to be more than 100\ntimes faster than the corresponding forward quantum annealing on average.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "PS-DBSCAN: An Efficient Parallel DBSCAN Algorithm Based on Platform Of AI (PAI).   We present PS-DBSCAN, a communication efficient parallel DBSCAN algorithm\nthat combines the disjoint-set data structure and Parameter Server framework in\nPlatform of AI (PAI). Since data points within the same cluster may be\ndistributed over different workers which result in several disjoint-sets,\nmerging them incurs large communication costs. In our algorithm, we employ a\nfast global union approach to union the disjoint-sets to alleviate the\ncommunication burden. Experiments over the datasets of different scales\ndemonstrate that PS-DBSCAN outperforms the PDSDBSCAN with 2-10 times speedup on\ncommunication efficiency.\nWe have released our PS-DBSCAN in an algorithm platform called Platform of AI\n(PAI - this https URL) in Alibaba Cloud. We have also\ndemonstrated how to use the method in PAI.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Learning for Environmentally Robust Speech Recognition: An Overview of Recent Developments.   Eliminating the negative effect of non-stationary environmental noise is a\nlong-standing research topic for automatic speech recognition that stills\nremains an important challenge. Data-driven supervised approaches, including\nones based on deep neural networks, have recently emerged as potential\nalternatives to traditional unsupervised approaches and with sufficient\ntraining, can alleviate the shortcomings of the unsupervised methods in various\nreal-life acoustic environments. In this light, we review recently developed,\nrepresentative deep learning approaches for tackling non-stationary additive\nand convolutional degradation of speech with the aim of providing guidelines\nfor those involved in the development of environmentally robust speech\nrecognition systems. We separately discuss single- and multi-channel techniques\ndeveloped for the front-end and back-end of speech recognition systems, as well\nas joint front-end and back-end training frameworks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Attention-Based Models for Text-Dependent Speaker Verification.   Attention-based models have recently shown great performance on a range of\ntasks, such as speech recognition, machine translation, and image captioning\ndue to their ability to summarize relevant information that expands through the\nentire length of an input sequence. In this paper, we analyze the usage of\nattention mechanisms to the problem of sequence summarization in our end-to-end\ntext-dependent speaker recognition system. We explore different topologies and\ntheir variants of the attention layer, and compare different pooling methods on\nthe attention weights. Ultimately, we show that attention-based models can\nimproves the Equal Error Rate (EER) of our speaker verification system by\nrelatively 14% compared to our non-attention LSTM baseline model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Overcomplete Frame Thresholding for Acoustic Scene Analysis.   In this work, we derive a generic overcomplete frame thresholding scheme\nbased on risk minimization. Overcomplete frames being favored for analysis\ntasks such as classification, regression or anomaly detection, we provide a way\nto leverage those optimal representations in real-world applications through\nthe use of thresholding. We validate the method on a large scale bird activity\ndetection task via the scattering network architecture performed by means of\ncontinuous wavelets, known for being an adequate dictionary in audio\nenvironments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Statistical Physics of the Symmetric Group.   Ordered chains (such as chains of amino acids) are ubiquitous in biological\ncells, and these chains perform specific functions contingent on the sequence\nof their components. Using the existence and general properties of such\nsequences as a theoretical motivation, we study the statistical physics of\nsystems whose state space is defined by the possible permutations of an ordered\nlist, i.e., the symmetric group, and whose energy is a function of how certain\npermutations deviate from some chosen correct ordering. Such a non-factorizable\nstate space is quite different from the state spaces typically considered in\nstatistical physics systems and consequently has novel behavior in systems with\ninteracting and even non-interacting Hamiltonians. Various parameter choices of\na mean-field model reveal the system to contain five different physical regimes\ndefined by two transition temperatures, a triple point, and a quadruple point.\nFinally, we conclude by discussing how the general analysis can be extended to\nstate spaces with more complex combinatorial properties and to other standard\nquestions of statistical mechanics models.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Normalized Maximum Likelihood with Luckiness for Multivariate Normal Distributions.   The normalized maximum likelihood (NML) is one of the most important\ndistribution in coding theory and statistics. NML is the unique solution (if\nexists) to the pointwise minimax regret problem. However, NML is not defined\neven for simple family of distributions such as the normal distributions. Since\nthere does not exist any meaningful minimax-regret distribution for such case,\nit is pointed out that NML with luckiness (LNML) can be employed as an\nalternative to NML. In this paper, we develop the closed form of LNMLs for\nmultivariate normal distributions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Replicator equation on networks with degree regular communities.   The replicator equation is one of the fundamental tools to study evolutionary\ndynamics in well-mixed populations. This paper contributes to the literature on\nevolutionary graph theory, providing a version of the replicator equation for a\nfamily of connected networks with communities, where nodes in the same\ncommunity have the same degree. This replicator equation is applied to the\nstudy of different classes of games, exploring the impact of the graph\nstructure on the equilibria of the evolutionary dynamics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Who Said What: Modeling Individual Labelers Improves Classification.   Data are often labeled by many different experts with each expert only\nlabeling a small fraction of the data and each data point being labeled by\nseveral experts. This reduces the workload on individual experts and also gives\na better estimate of the unobserved ground truth. When experts disagree, the\nstandard approaches are to treat the majority opinion as the correct label or\nto model the correct label as a distribution. These approaches, however, do not\nmake any use of potentially valuable information about which expert produced\nwhich label. To make use of this extra information, we propose modeling the\nexperts individually and then learning averaging weights for combining them,\npossibly in sample-specific ways. This allows us to give more weight to more\nreliable experts and take advantage of the unique strengths of individual\nexperts at classifying certain types of data. Here we show that our approach\nleads to improvements in computer-aided diagnosis of diabetic retinopathy. We\nalso show that our method performs better than competing algorithms by Welinder\nand Perona (2010), and by Mnih and Hinton (2012). Our work offers an innovative\napproach for dealing with the myriad real-world settings that use expert\nopinions to define labels for training.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Graph Attention Networks.   We present graph attention networks (GATs), novel neural network\narchitectures that operate on graph-structured data, leveraging masked\nself-attentional layers to address the shortcomings of prior methods based on\ngraph convolutions or their approximations. By stacking layers in which nodes\nare able to attend over their neighborhoods' features, we enable (implicitly)\nspecifying different weights to different nodes in a neighborhood, without\nrequiring any kind of costly matrix operation (such as inversion) or depending\non knowing the graph structure upfront. In this way, we address several key\nchallenges of spectral-based graph neural networks simultaneously, and make our\nmodel readily applicable to inductive as well as transductive problems. Our GAT\nmodels have achieved or matched state-of-the-art results across four\nestablished transductive and inductive graph benchmarks: the Cora, Citeseer and\nPubmed citation network datasets, as well as a protein-protein interaction\ndataset (wherein test graphs remain unseen during training).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Siamese Networks with Location Prior for Landmark Tracking in Liver Ultrasound Sequences.   Image-guided radiation therapy can benefit from accurate motion tracking by\nultrasound imaging, in order to minimize treatment margins and radiate moving\nanatomical targets, e.g., due to breathing. One way to formulate this tracking\nproblem is the automatic localization of given tracked anatomical landmarks\nthroughout a temporal ultrasound sequence. For this, we herein propose a\nfully-convolutional Siamese network that learns the similarity between pairs of\nimage regions containing the same landmark. Accordingly, it learns to localize\nand thus track arbitrary image features, not only predefined anatomical\nstructures. We employ a temporal consistency model as a location prior, which\nwe combine with the network-predicted location probability map to track a\ntarget iteratively in ultrasound sequences. We applied this method on the\ndataset of the Challenge on Liver Ultrasound Tracking (CLUST) with competitive\nresults, where our work is the first to effectively apply CNNs on this tracking\nproblem, thanks to our temporal regularization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Three principles of data science: predictability, computability, and stability (PCS).   We propose the predictability, computability, and stability (PCS) framework\nto extract reproducible knowledge from data that can guide scientific\nhypothesis generation and experimental design. The PCS framework builds on key\nideas in machine learning, using predictability as a reality check and\nevaluating computational considerations in data collection, data storage, and\nalgorithm design. It augments PC with an overarching stability principle, which\nlargely expands traditional statistical uncertainty considerations. In\nparticular, stability assesses how results vary with respect to choices (or\nperturbations) made across the data science life cycle, including problem\nformulation, pre-processing, modeling (data and algorithm perturbations), and\nexploratory data analysis (EDA) before and after modeling.\nFurthermore, we develop PCS inference to investigate the stability of data\nresults and identify when models are consistent with relatively simple\nphenomena. We compare PCS inference with existing methods, such as selective\ninference, in high-dimensional sparse linear model simulations to demonstrate\nthat our methods consistently outperform others in terms of ROC curves over a\nwide range of simulation settings. Finally, we propose a PCS documentation\nbased on Rmarkdown, iPython, or Jupyter Notebook, with publicly available,\nreproducible codes and narratives to back up human choices made throughout an\nanalysis. The PCS workflow and documentation are demonstrated in a genomics\ncase study available on Zenodo.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Application of Coulomb energy density functional for atomic nuclei: Case studies of local density approximation and generalized gradient approximation.   We test the Coulomb exchange and correlation energy density functionals of\nelectron systems for atomic nuclei in the local density approximation (LDA) and\nthe generalized gradient approximation (GGA). For the exchange Coulomb\nenergies, it is found that the deviation between the LDA and GGA ranges from\naround $ 11 \\, \\% $ in $ {}^{4} \\mathrm{He} $ to around $ 2.2 \\, \\% $ in $\n{}^{208} \\mathrm{Pb} $, by taking the Perdew-Burke-Ernzerhof (PBE) functional\nas an example of the GGA\\@. For the correlation Coulomb energies, it is shown\nthat those functionals of electron systems are not suitable for atomic nuclei.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Distributed Policy Iteration for Scalable Approximation of Cooperative Multi-Agent Policies.   Decision making in multi-agent systems (MAS) is a great challenge due to\nenormous state and joint action spaces as well as uncertainty, making\ncentralized control generally infeasible. Decentralized control offers better\nscalability and robustness but requires mechanisms to coordinate on joint tasks\nand to avoid conflicts. Common approaches to learn decentralized policies for\ncooperative MAS suffer from non-stationarity and lacking credit assignment,\nwhich can lead to unstable and uncoordinated behavior in complex environments.\nIn this paper, we propose Strong Emergent Policy approximation (STEP), a\nscalable approach to learn strong decentralized policies for cooperative MAS\nwith a distributed variant of policy iteration. For that, we use function\napproximation to learn from action recommendations of a decentralized\nmulti-agent planning algorithm. STEP combines decentralized multi-agent\nplanning with centralized learning, only requiring a generative model for\ndistributed black box optimization. We experimentally evaluate STEP in two\nchallenging and stochastic domains with large state and joint action spaces and\nshow that STEP is able to learn stronger policies than standard multi-agent\nreinforcement learning algorithms, when combining multi-agent open-loop\nplanning with centralized function approximation. The learned policies can be\nreintegrated into the multi-agent planning process to further improve\nperformance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Observational Equivalence in System Estimation: Contractions in Complex Networks.   Observability of complex systems/networks is the focus of this paper, which\nis shown to be closely related to the concept of contraction. Indeed, for\nobservable network tracking it is necessary/sufficient to have one node in each\ncontraction measured. Therefore, nodes in a contraction are equivalent to\nrecover for loss of observability, implying that contraction size is a key\nfactor for observability recovery. Here, using a polynomial order contraction\ndetection algorithm, we analyze the distribution of contractions, studying its\nrelation with key network properties. Our results show that contraction size is\nrelated to network clustering coefficient and degree heterogeneity.\nParticularly, in networks with power-law degree distribution, if the clustering\ncoefficient is high there are less contractions with smaller size on average.\nThe implication is that estimation/tracking of such systems requires less\nnumber of measurements, while their observational recovery is more restrictive\nin case of sensor failure. Further, in Small-World networks higher degree\nheterogeneity implies that there are more contractions with smaller size on\naverage. Therefore, the estimation of representing system requires more\nmeasurements, and also the recovery of measurement failure is more limited.\nThese results imply that one can tune the properties of synthetic networks to\nalleviate their estimation/observability recovery.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bouncy Hybrid Sampler as a Unifying Device.   This work introduces a class of rejection-free Markov chain Monte Carlo\n(MCMC) samplers, named the Bouncy Hybrid Sampler, which unifies several\nexisting methods from the literature. Examples include the Bouncy Particle\nSampler of Peters and de With (2012), Bouchard-Cote et al. (2015) and the\nHamiltonian MCMC. Following the introduced general framework, we derive a new\nsampler called the Quadratic Bouncy Hybrid Sampler. We apply this novel sampler\nto the problem of sampling from a truncated Gaussian distribution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simulation assisted machine learning.   Predicting how a proposed cancer treatment will affect a given tumor can be\ncast as a machine learning problem, but the complexity of biological systems,\nthe number of potentially relevant genomic and clinical features, and the lack\nof very large scale patient data repositories make this a unique challenge.\n\"Pure data\" approaches to this problem are underpowered to detect\ncombinatorially complex interactions and are bound to uncover false\ncorrelations despite statistical precautions taken (1). To investigate this\nsetting, we propose a method to integrate simulations, a strong form of prior\nknowledge, into machine learning, a combination which to date has been largely\nunexplored. The results of multiple simulations (under various uncertainty\nscenarios) are used to compute similarity measures between every pair of\nsamples: sample pairs are given a high similarity score if they behave\nsimilarly under a wide range of simulation parameters. These similarity values,\nrather than the original high dimensional feature data, are used to train\nkernelized machine learning algorithms such as support vector machines, thus\nhandling the curse-of-dimensionality that typically affects genomic machine\nlearning. Using four synthetic datasets of complex systems--three biological\nmodels and one network flow optimization model--we demonstrate that when the\nnumber of training samples is small compared to the number of features, the\nsimulation kernel approach dominates over no-prior-knowledge methods. In\naddition to biology and medicine, this approach should be applicable to other\ndisciplines, such as weather forecasting, financial markets, and agricultural\nmanagement, where predictive models are sought and informative yet approximate\nsimulations are available. The Python SimKern software, the models (in MATLAB,\nOctave, and R), and the datasets are made freely available at\nthis https URL .",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Really? Well. Apparently Bootstrapping Improves the Performance of Sarcasm and Nastiness Classifiers for Online Dialogue.   More and more of the information on the web is dialogic, from Facebook\nnewsfeeds, to forum conversations, to comment threads on news articles. In\ncontrast to traditional, monologic Natural Language Processing resources such\nas news, highly social dialogue is frequent in social media, making it a\nchallenging context for NLP. This paper tests a bootstrapping method,\noriginally proposed in a monologic domain, to train classifiers to identify two\ndifferent types of subjective language in dialogue: sarcasm and nastiness. We\nexplore two methods of developing linguistic indicators to be used in a first\nlevel classifier aimed at maximizing precision at the expense of recall. The\nbest performing classifier for the first phase achieves 54% precision and 38%\nrecall for sarcastic utterances. We then use general syntactic patterns from\nprevious work to create more general sarcasm indicators, improving precision to\n62% and recall to 52%. To further test the generality of the method, we then\napply it to bootstrapping a classifier for nastiness dialogic acts. Our first\nphase, using crowdsourced nasty indicators, achieves 58% precision and 49%\nrecall, which increases to 75% precision and 62% recall when we bootstrap over\nthe first level with generalized syntactic patterns.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comprehension-guided referring expressions.   We consider generation and comprehension of natural language referring\nexpression for objects in an image. Unlike generic \"image captioning\" which\nlacks natural standard evaluation criteria, quality of a referring expression\nmay be measured by the receiver's ability to correctly infer which object is\nbeing described. Following this intuition, we propose two approaches to utilize\nmodels trained for comprehension task to generate better expressions. First, we\nuse a comprehension module trained on human-generated expressions, as a\n\"critic\" of referring expression generator. The comprehension module serves as\na differentiable proxy of human evaluation, providing training signal to the\ngeneration module. Second, we use the comprehension module in a\ngenerate-and-rerank pipeline, which chooses from candidate expressions\ngenerated by a model according to their performance on the comprehension task.\nWe show that both approaches lead to improved referring expression generation\non multiple benchmark datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Algorithms for solving optimization problems arising from deep neural net models: nonsmooth problems.   Machine Learning models incorporating multiple layered learning networks have\nbeen seen to provide effective models for various classification problems. The\nresulting optimization problem to solve for the optimal vector minimizing the\nempirical risk is, however, highly nonconvex. This alone presents a challenge\nto application and development of appropriate optimization algorithms for\nsolving the problem. However, in addition, there are a number of interesting\nproblems for which the objective function is non- smooth and nonseparable. In\nthis paper, we summarize the primary challenges involved, the state of the art,\nand present some numerical results on an interesting and representative class\nof problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parameter and State Estimation in Queues and Related Stochastic Models: A Bibliography.   This is an annotated bibliography on estimation and inference results for\nqueues and related stochastic models. The purpose of this document is to\ncollect and categorise works in the field, allowing for researchers and\npractitioners to explore the various types of results that exist. This\nbibliography attempts to include all known works that satisfy both of these\nrequirements: -Works that deal with queueing models. -Works that contain\ncontributions related to the methodology of parameter estimation, state\nestimation, hypothesis testing, confidence interval and/or actual datasets of\napplication areas. Our attempt is to make this bibliography exhaustive, yet\nthere are possibly some papers that we have missed. As it is updated\ncontinuously, additions and comments are welcomed. The sections below\ncategorise the works based on several categories. A single paper may appear in\nseveral categories simultaneously. The final section lists all works in\nchronological order along with short descriptions of the contributions. This\nbibliography is maintained at\nthis http URL and may be cited as such.\nWe welcome additions and corrections.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Turbulent gas accretion between supermassive black holes and star-forming rings in the circumnuclear disk.   While supermassive black holes are known to co-evolve with their host galaxy,\nthe precise nature and origin of this co-evolution is not clear. We here\nexplore the possible connection between star formation and black hole growth in\nthe circumnuclear disk (CND) to probe this connection in the vicinity close to\nthe black hole. We adopt here the circumnuclear disk model developed by\nKawakatu & Wada (2008) and Wutschik et al. (2013), and explore both the\ndependence on the star formation recipe as well as the role of the\ngravitational field, which can be dominated by the central black hole, the CND\nitself or the host galaxy. A specific emphasis is put on the turbulence\nregulated star formation model by Krumholz et al. (2005) to explore the impact\nof a realistic star formation recipe. It is shown that this model helps to\nintroduce realistic fluctuations in the black hole and star formation rate,\nwithout overestimating them. Consistent with previous works, we show that the\nfinal black hole masses are rather insensitive to the masses of the initial\nseeds, even for seed masses of up to 10^6 M_sol. In addition, we apply our\nmodel to the formation of high-redshift quasars, as well as to the nearby\nsystem NGC 6951, where a tentative comparison is made in spite of the presence\nof a bar in the galaxy. We show that our model can reproduce the high black\nhole masses of the high-redshift quasars within a sufficiently short time,\nprovided a high mass supply rate from the host galaxy. In addition, it\nreproduces several of the properties observed in NGC 6951. With respect to the\nlatter system, our analysis suggests that supernova feedback may be important\nto create the observed fluctuations in the star formation history as a result\nof negative feedback effects.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Spin Transport and Accumulation in 2D Weyl Fermion System.   In this work, we study the spin Hall effect and Rashba-Edelstein effect of a\n2D Weyl fermion system in the clean limit using the Kubo formalism. Spin\ntransport is solely due to the spin-torque current in this strongly spin-orbit\ncoupled (SOC) system, and chiral spin-flip scattering off non-SOC scalar\nimpurities, with potential strength $V$ and size $a$, gives rise to a\nskew-scattering mechanism for the spin Hall effect. The key result is that the\nresultant spin-Hall angle has a fixed sign, with $\\theta^{SH} \\sim O\n\\left(\\tfrac{V^2}{v_F^2/a^2} (k_F a)^4 \\right)$ being a strongly-dependent\nfunction of $k_F a$, with $k_F$ and $v_F$ being the Fermi wave-vector and Fermi\nvelocity respectively. This, therefore, allows for the possibility of tuning\nthe SHE by adjusting the Fermi energy or impurity size.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Wasserstein Introspective Neural Networks.   We present Wasserstein introspective neural networks (WINN) that are both a\ngenerator and a discriminator within a single model. WINN provides a\nsignificant improvement over the recent introspective neural networks (INN)\nmethod by enhancing INN's generative modeling capability. WINN has three\ninteresting properties: (1) A mathematical connection between the formulation\nof the INN algorithm and that of Wasserstein generative adversarial networks\n(WGAN) is made. (2) The explicit adoption of the Wasserstein distance into INN\nresults in a large enhancement to INN, achieving compelling results even with a\nsingle classifier --- e.g., providing nearly a 20 times reduction in model size\nover INN for unsupervised generative modeling. (3) When applied to supervised\nclassification, WINN also gives rise to improved robustness against adversarial\nexamples in terms of the error reduction. In the experiments, we report\nencouraging results on unsupervised learning problems including texture, face,\nand object modeling, as well as a supervised classification task against\nadversarial attacks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear parametric excitation effect induces stability transitions in swimming direction of flexible superparamagnetic microswimmers.   Microscopic artificial swimmers have recently become highly attractive due to\ntheir promising potential for biomedical applications. The pioneering work of\nDreyfus et al (2005) has demonstrated the motion of a microswimmer with an\nundulating chain of superparamagnetic beads, which is actuated by an\noscillating external magnetic field. Interestingly, it has also been\ntheoretically predicted that the swimming direction of this swimmer will\nundergo a $90^\\circ$-transition when the magnetic field's oscillations\namplitude is increased above a critical value of $\\sqrt{2}$. In this work, we\nfurther investigate this transition both theoretically and experimentally by\nusing numerical simulations and presenting a novel flexible microswimmer with a\nsuperparamagnetic head. We realize the $90^\\circ$-transition in swimming\ndirection, prove that this effect depends on both frequency and amplitude of\nthe oscillating magnetic field, and demonstrate the existence of an optimal\namplitude, under which, maximal swimming speed can be achieved. By\nasymptotically analyzing the dynamic motion of microswimmer with a minimal\ntwo-link model, we reveal that the stability transitions representing the\nchanges in the swimming direction are induced by the effect of nonlinear\nparametric excitation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Bootstrap Method for Error Estimation in Randomized Matrix Multiplication.   In recent years, randomized methods for numerical linear algebra have\nreceived growing interest as a general approach to large-scale problems.\nTypically, the essential ingredient of these methods is some form of randomized\ndimension reduction, which accelerates computations, but also creates random\napproximation error. In this way, the dimension reduction step encodes a\ntradeoff between cost and accuracy. However, the exact numerical relationship\nbetween cost and accuracy is typically unknown, and consequently, it may be\ndifficult for the user to precisely know (1) how accurate a given solution is,\nor (2) how much computation is needed to achieve a given level of accuracy. In\nthe current paper, we study randomized matrix multiplication (sketching) as a\nprototype setting for addressing these general problems. As a solution, we\ndevelop a bootstrap method for {directly estimating} the accuracy as a function\nof the reduced dimension (as opposed to deriving worst-case bounds on the\naccuracy in terms of the reduced dimension). From a computational standpoint,\nthe proposed method does not substantially increase the cost of standard\nsketching methods, and this is made possible by an \"extrapolation\" technique.\nIn addition, we provide both theoretical and empirical results to demonstrate\nthe effectiveness of the proposed method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Force and torque of a string on a pulley.   Every university introductory physics course considers the problem of\nAtwood's machine taking into account the mass of the pulley. In the usual\ntreatment the tensions at the two ends of the string are offhandedly taken to\nact on the pulley and be responsible for its rotation. However such a free-body\ndiagram of the forces on the pulley is not {\\it a priori} justified, inducing\nstudents to construct wrong hypotheses such as that the string transfers its\ntension to the pulley or that some symmetry is in operation. We reexamine this\nproblem by integrating the contact forces between each element of the string\nand the pulley and show that although the pulley does behave as if the tensions\nwere acting on it, this comes only as the end result of a detailed analysis. We\nalso address the question of how much friction is needed to prevent the string\nfrom slipping over the pulley. Finally, we deal with the case in which the\nstring is on the verge of sliding and show that this will never happen unless\ncertain conditions are met by the coefficient of friction and the masses\ninvolved.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multi-User Multi-Armed Bandits for Uncoordinated Spectrum Access.   A multi-user multi-armed bandit (MAB) framework is used to develop algorithms\nfor uncoordinated spectrum access. The number of users is assumed to be unknown\nto each user. A stochastic setting is first considered, where the rewards on a\nchannel are the same for each user. In contrast to prior work, it is assumed\nthat the number of users can possibly exceed the number of channels, and that\nrewards can be non-zero even under collisions. The proposed algorithm consists\nof an estimation phase and an allocation phase. It is shown that if every user\nadopts the algorithm, the system wide regret is constant with time with high\nprobability. The regret guarantees hold for any number of users and channels,\nin particular, even when the number of users is less than the number of\nchannels. Next, an adversarial multi-user MAB framework is considered, where\nthe rewards on the channels are user-dependent. It is assumed that the number\nof users is less than the number of channels, and that the users receive zero\nreward on collision. The proposed algorithm combines the Exp3.P algorithm\ndeveloped in prior work for single user adversarial bandits with a collision\nresolution mechanism to achieve sub-linear regret. It is shown that if every\nuser employs the proposed algorithm, the system wide regret is of the order\n$O(T^\\frac{3}{4})$ over a horizon of time $T$. The algorithms in both\nstochastic and adversarial scenarios are extended to the dynamic case where the\nnumber of users in the system evolves over time and are shown to lead to\nsub-linear regret.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mechanism of the double heterostructure TiO2/ZnO/TiO2 for photocatalytic and photovoltaic applications: A theoretical study.   Understanding the mechanism of the heterojunction is an important step\ntowards controllable and tunable interfaces for photocatalytic and photovoltaic\nbased devices. To this aim, we propose a thorough study of a double\nheterostructure system consisting of two semiconductors with large band gap,\nnamely, wurtzite ZnO and anatase TiO2. We demonstrate via first-principle\ncalculations two stable configurations of ZnO/TiO2 interfaces. Our structural\nanalysis provides a key information on the nature of the complex interface and\nlattice distortions occurring when combining these materials. The study of the\nelectronic properties of the sandwich nanostructure TiO2/ZnO/TiO2 reveals that\nconduction band arises mainly from Ti3d orbitals, while valence band is\nmaintained by O2p of ZnO, and that the trapped states within the gap region\nfrequent in single heterostructure are substantially reduced in the double\ninterface system. Moreover, our work explains the origin of certain optical\ntransitions observed in the experimental studies. Unexpectedly, as a\nconsequence of different bond distortions, the results on the band alignments\nshow electron accumulation in the left shell of TiO2 rather than the right one.\nSuch behavior provides more choice for the sensitization and functionalization\nof TiO2 surfaces.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ultracold Atomic Gases in Artificial Magnetic Fields (PhD thesis).   A phenomenon can hardly be found that accompanied physical paradigms and\ntheoretical concepts in a more reflecting way than magnetism. From the\nbeginnings of metaphysics and the first classical approaches to magnetic poles\nand streamlines of the field, it has inspired modern physics on its way to the\nclassical field description of electrodynamics, and further to the quantum\nmechanical description of internal degrees of freedom of elementary particles.\nMeanwhile, magnetic manifestations have posed and still do pose complex and\noften controversially debated questions. This regards so various and utterly\ndistinct topics as quantum spin systems and the grand unification theory. This\nmay be foremost caused by the fact that all of these effects are based on\ncorrelated structures, which are induced by the interplay of dynamics and\nelementary interactions. It is strongly correlated systems that certainly\nrepresent one of the most fascinating and universal fields of research. In\nparticular, low dimensional systems are in the focus of interest, as they\nreveal strongly pronounced correlations of counterintuitive nature. As regards\nthis framework, the quantum Hall effect must be seen as one of the most\nintriguing and complex problems of modern solid state physics. Even after two\ndecades and the same number of Nobel prizes, it still keeps researchers of\nnearly all fields of physics occupied. In spite of seminal progress, its\ninherent correlated order still lacks understanding on a microscopic level.\nDespite this, it is obvious that the phenomenon is thoroughly fundamental of\nnature. To resolve some puzzles of this nature is a key topic of this thesis.\n(excerpt from abstract)",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Defect entropies and enthalpies in Barium Fluoride.   Various experimental techniques, have revealed that the predominant intrinsic\npoint defects in BaF$_2$ are anion Frenkel defects. Their formation enthalpy\nand entropy as well as the corresponding parameters for the fluorine vacancy\nand fluorine interstitial motion have been determined. In addition, low\ntemperature dielectric relaxation measurements in BaF$_2$ doped with uranium\nleads to the parameters {\\tau}$_0$, E in the Arrhenius relation\n{\\tau}={\\tau}$_0$exp(E/kBT) for the relaxation time {\\tau}. For the relaxation\npeak associated with a single tetravalent uranium, the migration entropy\ndeduced from the pre-exponential factor {\\tau}$_0$, is smaller than the anion\nFrenkel defect formation entropy by almost two orders of magnitude. We show\nthat, despite their great variation, the defect entropies and enthalpies are\ninterconnected through a model based on anharmonic properties of the bulk\nmaterial that have been recently studied by employing density-functional theory\nand density-functional perturbation theory.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multipath IP Routing on End Devices: Motivation, Design, and Performance.   Most end devices are now equipped with multiple network interfaces.\nApplications can exploit all available interfaces and benefit from multipath\ntransmission. Recently Multipath TCP (MPTCP) was proposed to implement\nmultipath transmission at the transport layer and has attracted lots of\nattention from academia and industry. However, MPTCP only supports TCP-based\napplications and its multipath routing flexibility is limited. In this paper,\nwe investigate the possibility of orchestrating multipath transmission from the\nnetwork layer of end devices, and develop a Multipath IP (MPIP) design\nconsisting of signaling, session and path management, multipath routing, and\nNAT traversal. We implement MPIP in Linux and Android kernels. Through\ncontrolled lab experiments and Internet experiments, we demonstrate that MPIP\ncan effectively achieve multipath gains at the network layer. It not only\nsupports the legacy TCP and UDP protocols, but also works seamlessly with\nMPTCP. By facilitating user-defined customized routing, MPIP can route traffic\nfrom competing applications in a coordinated fashion to maximize the aggregate\nuser Quality-of-Experience.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sylvester's Problem and Mock Heegner Points.   We prove that if $p \\equiv 4,7 \\pmod{9}$ is prime and $3$ is not a cube\nmodulo $p$, then both of the equations $x^3+y^3=p$ and $x^3+y^3=p^2$ have a\nsolution with $x,y \\in \\mathbb{Q}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Commissioning and performance results of the WFIRST/PISCES integral field spectrograph.   The Prototype Imaging Spectrograph for Coronagraphic Exoplanet Studies\n(PISCES) is a high contrast integral field spectrograph (IFS) whose design was\ndriven by WFIRST coronagraph instrument requirements. We present commissioning\nand operational results using PISCES as a camera on the High Contrast Imaging\nTestbed at JPL. PISCES has demonstrated ability to achieve high contrast\nspectral retrieval with flight-like data reduction and analysis techniques.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Classification of rank two Lie conformal algebras.   We give a complete classification (up to isomorphism) of Lie conformal\nalgebras which are free of rank two as $\\C[\\partial]$-modules, and determine\ntheir automorphism groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-Spherical Szekeres models in the language of Cosmological Perturbations.   We study the differences and equivalences between the non-perturbative\ndescription of the evolution of cosmic structure furnished by the Szekeres dust\nmodels (a non-spherical exact solution of Einstein's equations) and the\ndynamics of Cosmological Perturbation Theory (CPT) for dust sources in a\n$\\Lambda$CDM background. We show how the dynamics of Szekeres models can be\ndescribed by evolution equations given in terms of \"exact fluctuations\" that\nidentically reduce (at all orders) to evolution equations of CPT in the\ncomoving isochronous gauge. We explicitly show how Szekeres linearised exact\nfluctuations are specific (deterministic) realisations of standard linear\nperturbations of CPT given as random fields but, as opposed to the latter\nperturbations, they can be evolved exactly into the full non-linear regime. We\nprove two important results: (i) the conservation of the curvature perturbation\n(at all scales) also holds for the appropriate approximation of the exact\nSzekeres fluctuations in a $\\Lambda$CDM background, and (ii) the different\ncollapse morphologies of Szekeres models yields, at nonlinear order, different\nfunctional forms for the growth factor that follows from the study of redshift\nspace distortions. The metric based potentials used in linear CPT are computed\nin terms of the parameters of the linearised Szekeres models, thus allowing us\nto relate our results to linear CPT results in other gauges. We believe that\nthese results provide a solid starting stage to examine the role of\nnon-perturbative General Relativity in current cosmological research.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Effects of tunnelling and asymmetry for system-bath models of electron transfer.   We apply the newly derived nonadiabatic golden-rule instanton theory to\nasymmetric models describing electron-transfer in solution. The models go\nbeyond the usual spin-boson description and have anharmonic free-energy\nsurfaces with different values for the reactant and product reorganization\nenergies. The instanton method gives an excellent description of the behaviour\nof the rate constant with respect to asymmetry for the whole range studied. We\nderive a general formula for an asymmetric version of Marcus theory based on\nthe classical limit of the instanton and find that this gives significant\ncorrections to the standard Marcus theory. A scheme is given to compute this\nrate based only on equilibrium simulations. We also compare the rate constants\nobtained by the instanton method with its classical limit to study the effect\nof tunnelling and other quantum nuclear effects. These quantum effects can\nincrease the rate constant by orders of magnitude.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Procedural Texture Generation Framework Based on Semantic Descriptions.   Procedural textures are normally generated from mathematical models with\nparameters carefully selected by experienced users. However, for naive users,\nthe intuitive way to obtain a desired texture is to provide semantic\ndescriptions such as \"regular,\" \"lacelike,\" and \"repetitive\" and then a\nprocedural model with proper parameters will be automatically suggested to\ngenerate the corresponding textures. By contrast, it is less practical for\nusers to learn mathematical models and tune parameters based on multiple\nexaminations of large numbers of generated textures. In this study, we propose\na novel framework that generates procedural textures according to user-defined\nsemantic descriptions, and we establish a mapping between procedural models and\nsemantic texture descriptions. First, based on a vocabulary of semantic\nattributes collected from psychophysical experiments, a multi-label learning\nmethod is employed to annotate a large number of textures with semantic\nattributes to form a semantic procedural texture dataset. Then, we derive a low\ndimensional semantic space in which the semantic descriptions can be separated\nfrom one other. Finally, given a set of semantic descriptions, the diverse\nproperties of the samples in the semantic space can lead the framework to find\nan appropriate generation model that uses appropriate parameters to produce a\ndesired texture. The experimental results show that the proposed framework is\neffective and that the generated textures closely correlate with the input\nsemantic descriptions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Game Theory for Multi-Access Edge Computing: Survey, Use Cases, and Future Trends.   Game Theory (GT) has been used with significant success to formulate, and\neither design or optimize, the operation of many representative communications\nand networking scenarios. The games in these scenarios involve, as usual,\ndiverse players with conflicting goals. This paper primarily surveys the\nliterature that has applied theoretical games to wireless networks, emphasizing\nuse cases of upcoming Multi-Access Edge Computing (MEC). MEC is relatively new\nand offers cloud services at the network periphery, aiming to reduce service\nlatency backhaul load, and enhance relevant operational aspects such as Quality\nof Experience or security. Our presentation of GT is focused on the major\nchallenges imposed by MEC services over the wireless resources. The survey is\ndivided into classical and evolutionary games. Then, our discussion proceeds to\nmore specific aspects which have a considerable impact on the game usefulness,\nnamely: rational vs. evolving strategies, cooperation among players, available\ngame information, the way the game is played (single turn, repeated), the game\nmodel evaluation, and how the model results can be applied for both optimizing\nresource-constrained resources and balancing diverse trade-offs in real edge\nnetworking scenarios. Finally, we reflect on lessons learned, highlighting\nfuture trends and research directions for applying theoretical model games in\nupcoming MEC services, considering both network design issues and usage\nscenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Forecasting Internally Displaced Population Migration Patterns in Syria and Yemen.   Armed conflict has led to an unprecedented number of internally displaced\npersons (IDPs) - individuals who are forced out of their homes but remain\nwithin their country. IDPs often urgently require shelter, food, and\nhealthcare, yet prediction of when large fluxes of IDPs will cross into an area\nremains a major challenge for aid delivery organizations. Accurate forecasting\nof IDP migration would empower humanitarian aid groups to more effectively\nallocate resources during conflicts. We show that monthly flow of IDPs from\nprovince to province in both Syria and Yemen can be accurately forecasted one\nmonth in advance, using publicly available data. We model monthly IDP flow\nusing data on food price, fuel price, wage, geospatial, and news data. We find\nthat machine learning approaches can more accurately forecast migration trends\nthan baseline persistence models. Our findings thus potentially enable\nproactive aid allocation for IDPs in anticipation of forecasted arrivals.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Thermal and non-thermal emission from the cocoon of a gamma-ray burst jet.   We present hydrodynamic simulations of the hot cocoon produced when a\nrelativistic jet passes through the gamma-ray burst (GRB) progenitor star and\nits environment, and we compute the lightcurve and spectrum of the radiation\nemitted by the cocoon. The radiation from the cocoon has a nearly thermal\nspectrum with a peak in the X-ray band, and it lasts for a few minutes in the\nobserver frame; the cocoon radiation starts at roughly the same time as when\n$\\gamma$-rays from a burst trigger detectors aboard GRB satellites. The\nisotropic cocoon luminosity ($\\sim 10^{47}$ erg s$^{-1}$) is of the same order\nof magnitude as the X-ray luminosity of a typical long-GRB afterglow during the\nplateau phase. This radiation should be identifiable in the Swift data because\nof its nearly thermal spectrum which is distinct from the somewhat brighter\npower-law component. The detection of this thermal component would provide\ninformation regarding the size and density stratification of the GRB progenitor\nstar. Photons from the cocoon are also inverse-Compton (IC) scattered by\nelectrons in the relativistic jet. We present the IC lightcurve and spectrum,\nby post-processing the results of the numerical simulations. The IC spectrum\nlies in 10 keV--MeV band for typical GRB parameters. The detection of this IC\ncomponent would provide an independent measurement of GRB jet Lorentz factor\nand it would also help to determine the jet magnetisation parameter.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Crowdsourcing Multiple Choice Science Questions.   We present a novel method for obtaining high-quality, domain-targeted\nmultiple choice questions from crowd workers. Generating these questions can be\ndifficult without trading away originality, relevance or diversity in the\nanswer options. Our method addresses these problems by leveraging a large\ncorpus of domain-specific text and a small set of existing questions. It\nproduces model suggestions for document selection and answer distractor choice\nwhich aid the human question generation process. With this method we have\nassembled SciQ, a dataset of 13.7K multiple choice science exam questions\n(Dataset available at this http URL). We demonstrate that the\nmethod produces in-domain questions by providing an analysis of this new\ndataset and by showing that humans cannot distinguish the crowdsourced\nquestions from original questions. When using SciQ as additional training data\nto existing questions, we observe accuracy improvements on real science exams.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entanglement Entropy of Eigenstates of Quadratic Fermionic Hamiltonians.   In a seminal paper [D. N. Page, Phys. Rev. Lett. 71, 1291 (1993)], Page\nproved that the average entanglement entropy of subsystems of random pure\nstates is $S_{\\rm ave}\\simeq\\ln{\\cal D}_{\\rm A} - (1/2) {\\cal D}_{\\rm\nA}^2/{\\cal D}$ for $1\\ll{\\cal D}_{\\rm A}\\leq\\sqrt{\\cal D}$, where ${\\cal\nD}_{\\rm A}$ and ${\\cal D}$ are the Hilbert space dimensions of the subsystem\nand the system, respectively. Hence, typical pure states are (nearly) maximally\nentangled. We develop tools to compute the average entanglement entropy\n$\\langle S\\rangle$ of all eigenstates of quadratic fermionic Hamiltonians. In\nparticular, we derive exact bounds for the most general translationally\ninvariant models $\\ln{\\cal D}_{\\rm A} - (\\ln{\\cal D}_{\\rm A})^2/\\ln{\\cal D}\n\\leq \\langle S \\rangle \\leq \\ln{\\cal D}_{\\rm A} - [1/(2\\ln2)] (\\ln{\\cal D}_{\\rm\nA})^2/\\ln{\\cal D}$. Consequently we prove that: (i) if the subsystem size is a\nfinite fraction of the system size then $\\langle S\\rangle<\\ln{\\cal D}_{\\rm A}$\nin the thermodynamic limit, i.e., the average over eigenstates of the\nHamiltonian departs from the result for typical pure states, and (ii) in the\nlimit in which the subsystem size is a vanishing fraction of the system size,\nthe average entanglement entropy is maximal, i.e., typical eigenstates of such\nHamiltonians exhibit eigenstate thermalization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Facets of a mixed-integer bilinear covering set with bounds on variables.   We derive a closed form description of the convex hull of mixed-integer\nbilinear covering set with bounds on the integer variables. This convex hull\ndescription is completely determined by considering some orthogonal disjunctive\nsets defined in a certain way. Our description does not introduce any new\nvariables. We also derive a linear time separation algorithm for finding the\nfacet defining inequalities of this convex hull. We show the effectiveness of\nthe new inequalities using some examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evolution Strategies as a Scalable Alternative to Reinforcement Learning.   We explore the use of Evolution Strategies (ES), a class of black box\noptimization algorithms, as an alternative to popular MDP-based RL techniques\nsuch as Q-learning and Policy Gradients. Experiments on MuJoCo and Atari show\nthat ES is a viable solution strategy that scales extremely well with the\nnumber of CPUs available: By using a novel communication strategy based on\ncommon random numbers, our ES implementation only needs to communicate scalars,\nmaking it possible to scale to over a thousand parallel workers. This allows us\nto solve 3D humanoid walking in 10 minutes and obtain competitive results on\nmost Atari games after one hour of training. In addition, we highlight several\nadvantages of ES as a black box optimization technique: it is invariant to\naction frequency and delayed rewards, tolerant of extremely long horizons, and\ndoes not need temporal discounting or value function approximation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Regularizing nonlinear Schroedinger equations through partial off-axis variations.   We study a class of focusing nonlinear Schroedinger-type equations derived\nrecently by Dumas, Lannes and Szeftel within the mathematical description of\nhigh intensity laser beams [7]. These equations incorporate the possibility of\na (partial) off-axis variation of the group velocity of such laser beams\nthrough a second order partial differential operator acting in some, but not\nnecessarily all, spatial directions. We study the well-posedness theory for\nsuch models and obtain a regularizing effect, even in the case of only partial\noff-axis dependence. This provides an answer to an open problem posed in [7].",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Unoriented Cobordism Maps on Link Floer Homology.   We study the problem of defining maps on link Floer homology induced by\nunoriented link cobordisms. We provide a natural notion of link cobordism,\ndisoriented link cobordism, which tracks the motion of index zero and index\nthree critical points. Then we construct a map on unoriented link Floer\nhomology associated to a disoriented link cobordism. Furthermore, we give a\ncomparison with Oszváth-Stipsicz-Szabó's and Manolescu's constructions of\nlink cobordism maps for an unoriented band move.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Homogeneity Pursuit in Single Index Models based Panel Data Analysis.   Panel data analysis is an important topic in statistics and econometrics.\nTraditionally, in panel data analysis, all individuals are assumed to share the\nsame unknown parameters, e.g. the same coefficients of covariates when the\nlinear models are used, and the differences between the individuals are\naccounted for by cluster effects. This kind of modelling only makes sense if\nour main interest is on the global trend, this is because it would not be able\nto tell us anything about the individual attributes which are sometimes very\nimportant. In this paper, we proposed a modelling based on the single index\nmodels embedded with homogeneity for panel data analysis, which builds the\nindividual attributes in the model and is parsimonious at the same time. We\ndevelop a data driven approach to identify the structure of homogeneity, and\nestimate the unknown parameters and functions based on the identified\nstructure. Asymptotic properties of the resulting estimators are established.\nIntensive simulation studies conducted in this paper also show the resulting\nestimators work very well when sample size is finite. Finally, the proposed\nmodelling is applied to a public financial dataset and a UK climate dataset,\nthe results reveal some interesting findings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Impact of Detour-Aware Policies on Maximizing Profit in Ridesharing.   This paper provides efficient solutions to maximize profit for commercial\nridesharing services, under a pricing model with detour-based discounts for\npassengers. We propose greedy heuristics for real-time ride matching that offer\ndifferent trade-offs between optimality and speed. Simulations on New York City\n(NYC) taxi trip data show that our heuristics are up to 90% optimal and 10^5\ntimes faster than the (necessarily) exponential-time optimal algorithm.\nCommercial ridesharing service providers generate significant savings by\nmatching multiple ride requests using heuristic methods. The resulting savings\nare typically shared between the service provider (in the form of increased\nprofit) and the ridesharing passengers (in the form of discounts). It is not\nclear a priori how this split should be effected, since higher discounts would\nencourage more ridesharing, thereby increasing total savings, but the fraction\nof savings taken as profit is reduced. We simulate a scenario where the\ndecisions of the passengers to opt for ridesharing depend on the discount\noffered by the service provider. We provide an adaptive learning algorithm\nIDFLA that learns the optimal profit-maximizing discount factor for the\nprovider. An evaluation over NYC data shows that IDFLA, on average, learns the\noptimal discount factor in under 16 iterations.\nFinally, we investigate the impact of imposing a detour-aware routing policy\nbased on sequential individual rationality, a recently proposed concept. Such\nrestricted policies offer a better ride experience, increasing the provider's\nmarket share, but at the cost of decreased average per-ride profit due to the\nreduced number of matched rides. We construct a model that captures these\nopposing effects, wherein simulations based on NYC data show that a 7% increase\nin market share would suffice to offset the decreased average per-ride profit.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ensemble representation learning: an analysis of fitness and survival for wrapper-based genetic programming methods.   Recently we proposed a general, ensemble-based feature engineering wrapper\n(FEW) that was paired with a number of machine learning methods to solve\nregression problems. Here, we adapt FEW for supervised classification and\nperform a thorough analysis of fitness and survival methods within this\nframework. Our tests demonstrate that two fitness metrics, one introduced as an\nadaptation of the silhouette score, outperform the more commonly used Fisher\ncriterion. We analyze survival methods and demonstrate that $\\epsilon$-lexicase\nsurvival works best across our test problems, followed by random survival which\noutperforms both tournament and deterministic crowding. We conduct a benchmark\ncomparison to several classification methods using a large set of problems and\nshow that FEW can improve the best classifier performance in several cases. We\nshow that FEW generates consistent, meaningful features for a biomedical\nproblem with different ML pairings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Design Considerations for Proposed Fermilab Integrable RCS.   Integrable optics is an innovation in particle accelerator design that\nprovides strong nonlinear focusing while avoiding parametric resonances. One\npromising application of integrable optics is to overcome the traditional\nlimits on accelerator intensity imposed by betatron tune-spread and collective\ninstabilities. The efficacy of high-intensity integrable accelerators will be\nundergo comprehensive testing over the next several years at the Fermilab\nIntegrable Optics Test Accelerator (IOTA) and the University of Maryland\nElectron Ring (UMER). We propose an integrable Rapid-Cycling Synchrotron (iRCS)\nas a replacement for the Fermilab Booster to achieve multi-MW beam power for\nthe Fermilab high-energy neutrino program. We provide a overview of the machine\nparameters and discuss an approach to lattice optimization. Integrable optics\nrequires arcs with integer-pi phase advance followed by drifts with matched\nbeta functions. We provide an example integrable lattice with features of a\nmodern RCS - long dispersion-free drifts, low momentum compaction,\nsuperperiodicity, chromaticity correction, separate-function magnets, and\nbounded beta functions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Surrogate-Based Bayesian Inverse Modeling of the Hydrological System: An Adaptive Approach Considering Surrogate Approximation Erro.   Bayesian inverse modeling is important for a better understanding of\nhydrological processes. However, this approach can be computationally demanding\nas it usually requires a large number of model evaluations. To address this\nissue, one can take advantage of surrogate modeling techniques. Nevertheless,\nwhen approximation error of the surrogate model is neglected in inverse\nmodeling, the inversion result will be biased. In this paper, we develop a\nsurrogate-based Bayesian inversion framework that explicitly quantifies and\ngradually reduces the approximation error of the surrogate. Specifically, two\nstrategies are proposed and compared. The first strategy works by obtaining an\nensemble of sparse polynomial chaos expansion (PCE) surrogates with Markov\nchain Monte Carlo sampling, while the second one uses Gaussian process (GP) to\nsimulate the approximation error of a single sparse PCE surrogate. The two\nstrategies can also be applied with other surrogates, thus they have general\napplicability. By adaptively refining the surrogate over the posterior\ndistribution, we can gradually reduce the surrogate approximation error to a\nsmall level. Demonstrated with three case studies involving\nhigh-dimensionality, multi-modality and a real-world application, respectively,\nit is found that both strategies can reduce the bias introduced by surrogate\nmodeling, while the second strategy has a better performance as it integrates\ntwo methods (i.e., sparse PCE and GP) that complement each other.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Perception-in-the-Loop Adversarial Examples.   We present a scalable, black box, perception-in-the-loop technique to find\nadversarial examples for deep neural network classifiers. Black box means that\nour procedure only has input-output access to the classifier, and not to the\ninternal structure, parameters, or intermediate confidence values.\nPerception-in-the-loop means that the notion of proximity between inputs can be\ndirectly queried from human participants rather than an arbitrarily chosen\nmetric. Our technique is based on covariance matrix adaptation evolution\nstrategy (CMA-ES), a black box optimization approach. CMA-ES explores the\nsearch space iteratively in a black box manner, by generating populations of\ncandidates according to a distribution, choosing the best candidates according\nto a cost function, and updating the posterior distribution to favor the best\ncandidates. We run CMA-ES using human participants to provide the fitness\nfunction, using the insight that the choice of best candidates in CMA-ES can be\nnaturally modeled as a perception task: pick the top $k$ inputs perceptually\nclosest to a fixed input. We empirically demonstrate that finding adversarial\nexamples is feasible using small populations and few iterations. We compare the\nperformance of CMA-ES on the MNIST benchmark with other black-box approaches\nusing $L_p$ norms as a cost function, and show that it performs favorably both\nin terms of success in finding adversarial examples and in minimizing the\ndistance between the original and the adversarial input. In experiments on the\nMNIST, CIFAR10, and GTSRB benchmarks, we demonstrate that CMA-ES can find\nperceptually similar adversarial inputs with a small number of iterations and\nsmall population sizes when using perception-in-the-loop. Finally, we show that\nnetworks trained specifically to be robust against $L_\\infty$ norm can still be\nsusceptible to perceptually similar adversarial examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "EasyInterface: A toolkit for rapid development of GUIs for research prototype tools.   In this paper we describe EasyInterface, an open-source toolkit for rapid\ndevelopment of web-based graphical user interfaces (GUIs). This toolkit\naddresses the need of researchers to make their research prototype tools\navailable to the community, and integrating them in a common environment,\nrapidly and without being familiar with web programming or GUI libraries in\ngeneral. If a tool can be executed from a command-line and its output goes to\nthe standard output, then in few minutes one can make it accessible via a\nweb-interface or within Eclipse. Moreover, the toolkit defines a text-based\nlanguage that can be used to get more sophisticated GUIs, e.g., syntax\nhighlighting, dialog boxes, user interactions, etc. EasyInterface was\noriginally developed for building a common frontend for tools developed in the\nEnvisage project.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A New Torsion Pendulum for Gravitational Reference Sensor Technology Development.   We report on the design and sensitivity of a new torsion pendulum for\nmeasuring the performance of ultra-precise inertial sensors and for the\ndevelopment of associated technologies for space-based gravitational wave\nobservatories and geodesy missions. The apparatus comprises a 1 m-long, 50\num-diameter, tungsten fiber that supports an inertial member inside a vacuum\nsystem. The inertial member is an aluminum crossbar with four hollow cubic test\nmasses at each end. This structure converts the rotation of the torsion\npendulum into translation of the test masses. Two test masses are enclosed in\ncapacitive sensors which provide readout and actuation. These test masses are\nelectrically insulated from the rest of the cross-bar and their electrical\ncharge is controlled by photoemission using fiber-coupled ultraviolet light\nemitting diodes. The capacitive readout measures the test mass displacement\nwith a broadband sensitivity of 30 nm / sqrt(Hz), and is complemented by a\nlaser interferometer with a sensitivity of about 0.5 nm / sqrt(Hz). The\nperformance of the pendulum, as determined by the measured residual torque\nnoise and expressed in terms of equivalent force acting on a single test mass,\nis roughly 200 fN / sqrt(Hz) around 2 mHz, which is about a factor of 20 above\nthe thermal noise limit of the fiber.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lax orthogonal factorisations in monad-quantale-enriched categories.   We show that, for a quantale $V$ and a $\\mathsf{Set}$-monad $\\mathbb{T}$\nlaxly extended to $V$-$\\mathsf{Rel}$, the presheaf monad on the category of\n$(\\mathbb{T},V)$-categories is simple, giving rise to a lax orthogonal\nfactorisation system (lofs) whose corresponding weak factorisation system has\nembeddings as left part. In addition, we present presheaf submonads and study\nthe LOFSs they define. This provides a method of constructing weak\nfactorisation systems on some well-known examples of topological categories\nover $\\mathsf{Set}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tunneling of Glashow-Weinberg-Salam model particles from Black Hole Solutions in Rastall Theory.   Using the semiclassical WKB approximation and Hamilton-Jacobi method, we\nsolve an equation of motion for the Glashow-Weinberg-Salam model, which is\nimportant for understanding the unified gauge-theory of weak and\nelectromagnetic interactions. We calculate the tunneling rate of the massive\ncharged W-bosons in a background of electromagnetic field to investigate the\nHawking temperature of black holes surrounded by perfect fluid in Rastall\ntheory. Then, we study the quantum gravity effects on the generalized Proca\nequation with generalized uncertainty principle (GUP) on this background. We\nshow that quantum gravity effects leave the remnants on the Hawking temperature\nand the Hawking radiation becomes nonthermal.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Virtual plane-wave imaging via Marchenko redatuming.   Marchenko redatuming is a novel scheme used to retrieve up- and down-going\nGreen's functions in an unknown medium. Marchenko equations are based on\nreciprocity theorems and are derived on the assumption of the existence of so\ncalled focusing functions, i.e. functions which exhibit time-space focusing\nproperties once injected in the subsurface. In contrast to interferometry but\nsimilarly to standard migration methods, Marchenko redatuming only requires an\nestimate of the direct wave from the virtual source (or to the virtual\nreceiver), illumination from only one side of the medium, and no physical\nsources (or receivers) inside the medium. In this contribution we consider a\ndifferent time-focusing condition within the frame of Marchenko redatuming and\nshow how this can lead to the retrieval of virtual plane-wave responses, thus\nallowing multiple-free imaging using only a 1 dimensional sampling of the\ntargeted model. The potential of the new method is demonstrated on a 2D\nsynthetic model.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Autonomous drone cinematographer: Using artistic principles to create smooth, safe, occlusion-free trajectories for aerial filming.   Autonomous aerial cinematography has the potential to enable automatic\ncapture of aesthetically pleasing videos without requiring human intervention,\nempowering individuals with the capability of high-end film studios. Current\napproaches either only handle off-line trajectory generation, or offer\nstrategies that reason over short time horizons and simplistic representations\nfor obstacles, which result in jerky movement and low real-life applicability.\nIn this work we develop a method for aerial filming that is able to trade off\nshot smoothness, occlusion, and cinematography guidelines in a principled\nmanner, even under noisy actor predictions. We present a novel algorithm for\nreal-time covariant gradient descent that we use to efficiently find the\ndesired trajectories by optimizing a set of cost functions. Experimental\nresults show that our approach creates attractive shots, avoiding obstacles and\nocclusion 65 times over 1.25 hours of flight time, re-planning at 5 Hz with a\n10 s time horizon. We robustly film human actors, cars and bicycles performing\ndifferent motion among obstacles, using various shot types.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Polarisation of submillimetre lines from interstellar medium.   Magnetic fields play important roles in many astrophysical processes.\nHowever, there is no universal diagnostic for the magnetic fields in the\ninterstellar medium (ISM) and each magnetic tracer has its limitation. Any new\ndetection method is thus valuable. Theoretical studies have shown that\nsubmillimetre fine-structure lines are polarised due to atomic alignment by\nUltraviolet (UV) photon-excitation, which opens up a new avenue to probe\ninterstellar magnetic fields. We will, for the first time, perform synthetic\nobservations on the simulated three-dimensional ISM to demonstrate the\nmeasurability of the polarisation of submillimetre atomic lines. The maximum\npolarisation for different absorption and emission lines expected from various\nsources, including Star-Forming Regions (SFRs) are provided. Our results\ndemonstrate that the polarisation of submillimetre atomic lines is a powerful\nmagnetic tracer and add great value to the observational studies of the\nsubmilimetre astronomy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the structure of radial solutions for some quasilinear elliptic equations.   In this paper we study entire radial solutions for the quasilinear\n$p$-Laplace equation $\\Delta_p u + k(x) f(u) = 0$ where $k$ is a radial\npositive weight and the nonlinearity behaves e.g. as\n$f(u)=u|u|^{q-2}-u|u|^{Q-2}$ with $q<Q$. In particular we focus our attention\non solutions (positive and sign changing) which are infinitesimal at infinity,\nthus providing an extension of a previous result by Tang (2001).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Resilience of Complex Networks.   This article determines and characterizes the minimal number of actuators\nneeded to ensure structural controllability of a linear system under structural\nalterations that can severe the connection between any two states. We assume\nthat initially the system is structurally controllable with respect to a given\nset of controls, and propose an efficient system-synthesis mechanism to find\nthe minimal number of additional actuators required for resilience of the\nsystem w.r.t such structural changes. The effectiveness of this approach is\ndemonstrated by using standard IEEE power networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Heavy Traffic Limit for a Tandem Queue with Identical Service Times.   We consider a two-node tandem queueing network in which the upstream queue is\nM/G/1 and each job reuses its upstream service requirement when moving to the\ndownstream queue. Both servers employ the first-in-first-out policy. We\ninvestigate the amount of work in the second queue at certain embedded arrival\ntime points, namely when the upstream queue has just emptied. We focus on the\ncase of infinite-variance service times and obtain a heavy traffic process\nlimit for the embedded Markov chain.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-Kernel LS-SVM Based Bio-Clinical Data Integration: Applications to Ovarian Cancer.   The medical research facilitates to acquire a diverse type of data from the\nsame individual for particular cancer. Recent studies show that utilizing such\ndiverse data results in more accurate predictions. The major challenge faced is\nhow to utilize such diverse data sets in an effective way. In this paper, we\nintroduce a multiple kernel based pipeline for integrative analysis of\nhigh-throughput molecular data (somatic mutation, copy number alteration, DNA\nmethylation and mRNA) and clinical data. We apply the pipeline on Ovarian\ncancer data from TCGA. After multiple kernels have been generated from the\nweighted sum of individual kernels, it is used to stratify patients and predict\nclinical outcomes. We examine the survival time, vital status, and neoplasm\ncancer status of each subtype to verify how well they cluster. We have also\nexamined the power of molecular and clinical data in predicting dichotomized\noverall survival data and to classify the tumor grade for the cancer samples.\nIt was observed that the integration of various data types yields higher\nlog-rank statistics value. We were also able to predict clinical status with\nhigher accuracy as compared to using individual data types.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum Klein Space and Superspace.   We give an algebraic quantization, in the sense of quantum groups, of the\ncomplex Minkowski space, and we examine the real forms corresponding to the\nsignatures $(3,1)$, $(2,2)$, $(4,0)$, constructing the corresponding quantum\nmetrics and providing an explicit presentation of the quantized coordinate\nalgebras. In particular, we focus on the Kleinian signature $(2,2)$. The\nquantizations of the complex and real spaces come together with a coaction of\nthe quantizations of the respective symmetry groups. We also extend such\nquantizations to the $\\mathcal{N}=1$ supersetting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Structure of the Broad-Line Region In Active Galactic Nuclei. II. Dynamical Modeling of Data from the AGN10 Reverberation Mapping Campaign.   We present inferences on the geometry and kinematics of the broad-Hbeta\nline-emitting region in four active galactic nuclei monitored as a part of the\nfall 2010 reverberation mapping campaign at MDM Observatory led by the Ohio\nState University. From modeling the continuum variability and response in\nemission-line profile changes as a function of time, we infer the geometry of\nthe Hbeta- emitting broad line regions to be thick disks that are close to\nface-on to the observer with kinematics that are well-described by either\nelliptical orbits or inflowing gas. We measure the black hole mass to be log\n(MBH) = 7.25 (+/-0.10) for Mrk 335, 7.86 (+0.20, -0.17) for Mrk 1501, 7.84\n(+0.14, -0.19) for 3C 120, and 6.92 (+0.24, -0.23) for PG 2130+099. These black\nhole mass measurements are not based on a particular assumed value of the\nvirial scale factor f, allowing us to compute individual f factors for each\ntarget. Our results nearly double the number of targets that have been modeled\nin this manner, and investigate the properties of a more diverse sample by\nincluding previously modeled objects. We measure an average scale factor f in\nthe entire sample to be log10(f) = 0.54 +/- 0.17 when the line dispersion is\nused to characterize the line width, which is consistent with values derived\nusing the normalization of the MBH-sigma relation. We find that the scale\nfactor f for individual targets is likely correlated with the black hole mass,\ninclination angle, and opening angle of the broad line region but we do not\nfind any correlation with the luminosity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "SMT Solving for Vesicle Traffic Systems in Cells.   In biology, there are several questions that translate to combinatorial\nsearch. For example, vesicle traffic systems that move cargo within eukaryotic\ncells have been proposed to exhibit several graph properties such as three\nconnectivity. These properties are consequences of underlying biophysical\nconstraints. A natural question for biologists is: what are the possible\nnetworks for various combinations of those properties? In this paper, we\npresent novel SMT based encodings of the properties over vesicle traffic\nsystems and a tool that searches for the networks that satisfies the properties\nusing SMT solvers. In our experiments, we show that our tool can search for\nnetworks of sizes that are considered to be relevant by biologists.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interactive Certificates for Polynomial Matrices with Sub-Linear Communication.   We develop and analyze new protocols to verify the correctness of various\ncomputations on matrices over F[x], where F is a field. The properties we\nverify concern an F[x]-module and therefore cannot simply rely on\npreviously-developed linear algebra certificates which work only for vector\nspaces. Our protocols are interactive certificates, often randomized, and\nfeaturing a constant number of rounds of communication between the prover and\nverifier. We seek to minimize the communication cost so that the amount of data\nsent during the protocol is significantly smaller than the size of the result\nbeing verified, which can be useful when combining protocols or in some\nmulti-party settings. The main tools we use are reductions to existing linear\nalgebra certificates and a new protocol to verify that a given vector is in the\nF[x]-linear span of a given matrix.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Simple Convolutional Generative Network for Next Item Recommendation.   Convolutional Neural Networks (CNNs) have been recently introduced in the\ndomain of session-based next item recommendation. An ordered collection of past\nitems the user has interacted with in a session (or sequence) are embedded into\na 2-dimensional latent matrix, and treated as an image. The convolution and\npooling operations are then applied to the mapped item embeddings. In this\npaper, we first examine the typical session-based CNN recommender and show that\nboth the generative model and network architecture are suboptimal when modeling\nlong-range dependencies in the item sequence. To address the issues, we\nintroduce a simple, but very effective generative model that is capable of\nlearning high-level representation from both short- and long-range item\ndependencies. The network architecture of the proposed model is formed of a\nstack of \\emph{holed} convolutional layers, which can efficiently increase the\nreceptive fields without relying on the pooling operation. Another contribution\nis the effective use of residual block structure in recommender systems, which\ncan ease the optimization for much deeper networks. The proposed generative\nmodel attains state-of-the-art accuracy with less training time in the next\nitem recommendation task. It accordingly can be used as a powerful\nrecommendation baseline to beat in future, especially when there are long\nsequences of user feedback.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Instrument-Armed Bandits.   We extend the classic multi-armed bandit (MAB) model to the setting of\nnoncompliance, where the arm pull is a mere instrument and the treatment\napplied may differ from it, which gives rise to the instrument-armed bandit\n(IAB) problem. The IAB setting is relevant whenever the experimental units are\nhuman since free will, ethics, and the law may prohibit unrestricted or forced\napplication of treatment. In particular, the setting is relevant in bandit\nmodels of dynamic clinical trials and other controlled trials on human\ninterventions. Nonetheless, the setting has not been fully investigate in the\nbandit literature. We show that there are various and divergent notions of\nregret in this setting, all of which coincide only in the classic MAB setting.\nWe characterize the behavior of these regrets and analyze standard MAB\nalgorithms. We argue for a particular kind of regret that captures the causal\neffect of treatments but show that standard MAB algorithms cannot achieve\nsublinear control on this regret. Instead, we develop new algorithms for the\nIAB problem, prove new regret bounds for them, and compare them to standard MAB\nalgorithms in numerical examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Brief Notes on Hard Takeoff, Value Alignment, and Coherent Extrapolated Volition.   I make some basic observations about hard takeoff, value alignment, and\ncoherent extrapolated volition, concepts which have been central in analyses of\nsuperintelligent AI systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Massively-Parallel Feature Selection for Big Data.   We present the Parallel, Forward-Backward with Pruning (PFBP) algorithm for\nfeature selection (FS) in Big Data settings (high dimensionality and/or sample\nsize). To tackle the challenges of Big Data FS PFBP partitions the data matrix\nboth in terms of rows (samples, training examples) as well as columns\n(features). By employing the concepts of $p$-values of conditional independence\ntests and meta-analysis techniques PFBP manages to rely only on computations\nlocal to a partition while minimizing communication costs. Then, it employs\npowerful and safe (asymptotically sound) heuristics to make early, approximate\ndecisions, such as Early Dropping of features from consideration in subsequent\niterations, Early Stopping of consideration of features within the same\niteration, or Early Return of the winner in each iteration. PFBP provides\nasymptotic guarantees of optimality for data distributions faithfully\nrepresentable by a causal network (Bayesian network or maximal ancestral\ngraph). Our empirical analysis confirms a super-linear speedup of the algorithm\nwith increasing sample size, linear scalability with respect to the number of\nfeatures and processing cores, while dominating other competitive algorithms in\nits class.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a Unified Taxonomy of Biclustering Methods.   Being an unsupervised machine learning and data mining technique,\nbiclustering and its multimodal extensions are becoming popular tools for\nanalysing object-attribute data in different domains. Apart from conventional\nclustering techniques, biclustering is searching for homogeneous groups of\nobjects while keeping their common description, e.g., in binary setting, their\nshared attributes. In bioinformatics, biclustering is used to find genes, which\nare active in a subset of situations, thus being candidates for biomarkers.\nHowever, the authors of those biclustering techniques that are popular in gene\nexpression analysis, may overlook the existing methods. For instance, BiMax\nalgorithm is aimed at finding biclusters, which are well-known for decades as\nformal concepts. Moreover, even if bioinformatics classify the biclustering\nmethods according to reasonable domain-driven criteria, their classification\ntaxonomies may be different from survey to survey and not full as well. So, in\nthis paper we propose to use concept lattices as a tool for taxonomy building\n(in the biclustering domain) and attribute exploration as means for\ncross-domain taxonomy completion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved Fixed-Rank Nyström Approximation via QR Decomposition: Practical and Theoretical Aspects.   The Nyström method is a popular technique for computing fixed-rank\napproximations of large kernel matrices using a small number of landmark\npoints. In practice, to ensure high quality approximations, the number of\nlandmark points is chosen to be greater than the target rank. However, the\nstandard Nyström method uses a sub-optimal procedure for rank reduction\nmainly due to its simplicity. In this paper, we highlight the drawbacks of\nstandard Nyström in terms of poor performance and lack of theoretical\nguarantees. To address these issues, we present an efficient method for\ngenerating improved fixed-rank Nyström approximations. Theoretical analysis\nand numerical experiments are provided to demonstrate the advantages of the\nmodified method over the standard Nyström method. Overall, the aim of this\npaper is to convince researchers to use the modified method, as it has nearly\nidentical computational complexity, is easy to code, and has greatly improved\naccuracy in many cases.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "End-to-end semantic face segmentation with conditional random fields as convolutional, recurrent and adversarial networks.   Recent years have seen a sharp increase in the number of related yet distinct\nadvances in semantic segmentation. Here, we tackle this problem by leveraging\nthe respective strengths of these advances. That is, we formulate a conditional\nrandom field over a four-connected graph as end-to-end trainable convolutional\nand recurrent networks, and estimate them via an adversarial process.\nImportantly, our model learns not only unary potentials but also pairwise\npotentials, while aggregating multi-scale contexts and controlling higher-order\ninconsistencies. We evaluate our model on two standard benchmark datasets for\nsemantic face segmentation, achieving state-of-the-art results on both of them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Viscosity solutions and the minimal surface system.   We give a definition of viscosity solution for the minimal surface system and\nprove a version of Allard regularity theorem in this setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sharper and Simpler Nonlinear Interpolants for Program Verification.   Interpolation of jointly infeasible predicates plays important roles in\nvarious program verification techniques such as invariant synthesis and CEGAR.\nIntrigued by the recent result by Dai et al.\\ that combines real algebraic\ngeometry and SDP optimization in synthesis of polynomial interpolants, the\ncurrent paper contributes its enhancement that yields sharper and simpler\ninterpolants. The enhancement is made possible by: theoretical observations in\nreal algebraic geometry; and our continued fraction-based algorithm that rounds\noff (potentially erroneous) numerical solutions of SDP solvers. Experiment\nresults support our tool's effectiveness; we also demonstrate the benefit of\nsharp and simple interpolants in program verification examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Rice-Shapiro theorem in Computable Topology.   We provide requirements on effectively enumerable topological spaces which\nguarantee that the Rice-Shapiro theorem holds for the computable elements of\nthese spaces. We show that the relaxation of these requirements leads to the\nclasses of effectively enumerable topological spaces where the Rice-Shapiro\ntheorem does not hold. We propose two constructions that generate effectively\nenumerable topological spaces with particular properties from wn--families and\ncomputable trees without computable infinite paths. Using them we propose\nexamples that give a flavor of this class.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Controlling Sources of Inaccuracy in Stochastic Kriging.   Scientists and engineers commonly use simulation models to study real systems\nfor which actual experimentation is costly, difficult, or impossible. Many\nsimulations are stochastic in the sense that repeated runs with the same input\nconfiguration will result in different outputs. For expensive or time-consuming\nsimulations, stochastic kriging \\citep{ankenman} is commonly used to generate\npredictions for simulation model outputs subject to uncertainty due to both\nfunction approximation and stochastic variation. Here, we develop and justify a\nfew guidelines for experimental design, which ensure accuracy of stochastic\nkriging emulators. We decompose error in stochastic kriging predictions into\nnominal, numeric, parameter estimation and parameter estimation numeric\ncomponents and provide means to control each in terms of properties of the\nunderlying experimental design. The design properties implied for each source\nof error are weakly conflicting and broad principles are proposed. In brief,\nspace-filling properties \"small fill distance\" and \"large separation distance\"\nshould balance with replication at distinct input configurations, with number\nof replications depending on the relative magnitudes of stochastic and process\nvariability. Non-stationarity implies higher input density in more active\nregions, while regression functions imply a balance with traditional design\nproperties. A few examples are presented to illustrate the results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Correspondence Theorem between Holomorphic Discs and Tropical Discs on K3 Surfaces.   We prove that the open Gromov-Witten invariants on K3 surfaces satisfy the\nKontsevich-Soibelman wall-crossing formula. One one hand, this gives a\ngeometric interpretation of the slab functions in Gross-Siebert program. On the\nother hands, the open Gromov-Witten invariants coincide with the weighted\ncounting of tropical discs. This is an analog of the corresponding theorem on\ntoric varieties \\cite{M2}\\cite{NS} but on compact Calabi-Yau surfaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Visual Analogies between Atari Games for Studying Transfer Learning in RL.   In this work, we ask the following question: Can visual analogies, learned in\nan unsupervised way, be used in order to transfer knowledge between pairs of\ngames and even play one game using an agent trained for another game? We\nattempt to answer this research question by creating visual analogies between a\npair of games: a source game and a target game. For example, given a video\nframe in the target game, we map it to an analogous state in the source game\nand then attempt to play using a trained policy learned for the source game. We\ndemonstrate convincing visual mapping between four pairs of games (eight\nmappings), which are used to evaluate three transfer learning approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "In search of a new economic model determined by logistic growth.   In this paper we extend the work by Ryuzo Sato devoted to the development of\neconomic growth models within the framework of the Lie group theory. We propose\na new growth model based on the assumption of logistic growth in factors. It is\nemployed to derive new production functions and introduce a new notion of wage\nshare. In the process it is shown that the new functions compare reasonably\nwell against relevant economic data. The corresponding problem of maximization\nof profit under conditions of perfect competition is solved with the aid of one\nof these functions. In addition, it is explained in reasonably rigorous\nmathematical terms why Bowley's law no longer holds true in post-1960 data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Axiomatizability of the Multiplicative Theory of Numbers.   The multiplicative theory of a set of numbers (which could be natural,\ninteger, rational, real or complex numbers) is the first-order theory of the\nstructure of that set with (solely) the multiplication operation (that set is\ntaken to be multiplicative, i.e., closed under multiplication). In this paper\nwe study the multiplicative theories of the complex, real and (positive)\nrational numbers. These theories (and also the multiplicative theories of\nnatural and integer numbers) are known to be decidable (i.e., there exists an\nalgorithm that decides whether a given sentence is derivable form the theory);\nhere we present explicit axiomatizations for them and show that they are not\nfinitely axiomatizable. For each of these sets (of complex, real and [positive]\nrational numbers) a language, including the multiplication operation, is\nintroduced in a way that it allows quantifier elimination (for the theory of\nthat set).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Health Care Text Classification.   Health related social media mining is a valuable apparatus for the early\nrecognition of the diverse antagonistic medicinal conditions. Mostly, the\nexisting methods are based on machine learning with knowledge-based learning.\nThis working note presents the Recurrent neural network (RNN) and Long\nshort-term memory (LSTM) based embedding for automatic health text\nclassification in the social media mining. For each task, two systems are built\nand that classify the tweet at the tweet level. RNN and LSTM are used for\nextracting features and non-linear activation function at the last layer\nfacilitates to distinguish the tweets of different categories. The experiments\nare conducted on 2nd Social Media Mining for Health Applications Shared Task at\nAMIA 2017. The experiment results are considerable; however the proposed method\nis appropriate for the health text classification. This is primarily due to the\nreason that, it doesn't rely on any feature engineering mechanisms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal compromise between incompatible conditional probability distributions, with application to Objective Bayesian Kriging.   Models are often defined through conditional rather than joint distributions,\nbut it can be difficult to check whether the conditional distributions are\ncompatible, i.e. whether there exists a joint probability distribution which\ngenerates them. When they are compatible, a Gibbs sampler can be used to sample\nfrom this joint distribution. When they are not, the Gibbs sampling algorithm\nmay still be applied, resulting in a \"pseudo-Gibbs sampler\". We show its\nstationary probability distribution to be the optimal compromise between the\nconditional distributions, in the sense that it minimizes a mean squared misfit\nbetween them and its own conditional distributions. This allows us to perform\nObjective Bayesian analysis of correlation parameters in Kriging models by\nusing univariate conditional Jeffreys-rule posterior distributions instead of\nthe widely used multivariate Jeffreys-rule posterior. This strategy makes the\nfull-Bayesian procedure tractable. Numerical examples show it has near-optimal\nfrequentist performance in terms of prediction interval coverage.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Jamming transitions induced by an attraction in pedestrian flow.   We numerically study jamming transitions in pedestrian flow interacting with\nan attraction, mostly based on the social force model for pedestrians who can\njoin the attraction. We formulate the joining probability as a function of\nsocial influence from others, reflecting that individual choice behavior is\nlikely influenced by others. By controlling pedestrian influx and the social\ninfluence parameter, we identify various pedestrian flow patterns. For the\nbidirectional flow scenario, we observe a transition from the free flow phase\nto the freezing phase, in which oppositely walking pedestrians reach a complete\nstop and block each other. On the other hand, a different transition behavior\nappears in the unidirectional flow scenario, i.e., from the free flow phase to\nthe localized jam phase and then to the extended jam phase. It is also observed\nthat the extended jam phase can end up in freezing phenomena with a certain\nprobability when pedestrian flux is high with strong social influence. This\nstudy highlights that attractive interactions between pedestrians and an\nattraction can trigger jamming transitions by increasing the number of\nconflicts among pedestrians near the attraction. In order to avoid excessive\npedestrian jams, we suggest suppressing the number of conflicts under a certain\nlevel by moderating pedestrian influx especially when the social influence is\nstrong.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Robust Guaranteed-Cost Adaptive Quantum Phase Estimation.   Quantum parameter estimation plays a key role in many fields like quantum\ncomputation, communication and metrology. Optimal estimation allows one to\nachieve the most precise parameter estimates, but requires accurate knowledge\nof the model. Any inevitable uncertainty in the model parameters may heavily\ndegrade the quality of the estimate. It is therefore desired to make the\nestimation process robust to such uncertainties. Robust estimation was\npreviously studied for a varying phase, where the goal was to estimate the\nphase at some time in the past, using the measurement results from both before\nand after that time within a fixed time interval up to current time. Here, we\nconsider a robust guaranteed-cost filter yielding robust estimates of a varying\nphase in real time, where the current phase is estimated using only past\nmeasurements. Our filter minimizes the largest (worst-case) variance in the\nallowable range of the uncertain model parameter(s) and this determines its\nguaranteed cost. It outperforms in the worst case the optimal Kalman filter\ndesigned for the model with no uncertainty, that corresponds to the center of\nthe possible range of the uncertain parameter(s). Moreover, unlike the Kalman\nfilter, our filter in the worst case always performs better than the best\nachievable variance for heterodyne measurements, that we consider as the\ntolerable threshold for our system. Furthermore, we consider effective quantum\nefficiency and effective noise power, and show that our filter provides the\nbest results by these measures in the worst case.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Global well-posedness for 2-D Boussinesq system with the temperature-dependent viscosity and supercritical dissipation.   The present paper is dedicated to the global well-posedness issue for the\nBoussinesq system with the temperature-dependent viscosity in $\\mathbb{R}^2.$\nWe aim at extending the work by Abidi and Zhang ( Adv. Math. 2017 (305)\n1202--1249 ) to a supercritical dissipation for temperature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "User-friendly guarantees for the Langevin Monte Carlo with inaccurate gradient.   In this paper, we study the problem of sampling from a given probability\ndensity function that is known to be smooth and strongly log-concave. We\nanalyze several methods of approximate sampling based on discretizations of the\n(highly overdamped) Langevin diffusion and establish guarantees on its error\nmeasured in the Wasserstein-2 distance. Our guarantees improve or extend the\nstate-of-the-art results in three directions. First, we provide an upper bound\non the error of the first-order Langevin Monte Carlo (LMC) algorithm with\noptimized varying step-size. This result has the advantage of being horizon\nfree (we do not need to know in advance the target precision) and to improve by\na logarithmic factor the corresponding result for the constant step-size.\nSecond, we study the case where accurate evaluations of the gradient of the\nlog-density are unavailable, but one can have access to approximations of the\naforementioned gradient. In such a situation, we consider both deterministic\nand stochastic approximations of the gradient and provide an upper bound on the\nsampling error of the first-order LMC that quantifies the impact of the\ngradient evaluation inaccuracies. Third, we establish upper bounds for two\nversions of the second-order LMC, which leverage the Hessian of the\nlog-density. We nonasymptotic guarantees on the sampling error of these\nsecond-order LMCs. These guarantees reveal that the second-order LMC algorithms\nimprove on the first-order LMC in ill-conditioned settings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonparametric estimation of locally stationary Hawkes processe.   In this paper we consider multivariate Hawkes processes with baseline hazard\nand kernel functions that depend on time. This defines a class of locally\nstationary processes. We discuss estimation of the time-dependent baseline\nhazard and kernel functions based on a localized criterion. Theory on\nstationary Hawkes processes is extended to develop asymptotic theory for the\nestimator in the locally stationary model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Excitonic gap generation in thin-film topological insulators.   In this work, we analyze the excitonic gap generation in the strong-coupling\nregime of thin films of three-dimensional time-reversal-invariant topological\ninsulators. We start by writing down the effective gauge theory in\n2+1-dimensions from the projection of the 3+1-dimensional quantum\nelectrodynamics. Within this method, we obtain a short-range interaction, which\nhas the form of a Thirring-like term, and a long-range one. The interaction\nbetween the two surface states of the material induces an excitonic gap. By\nusing the large-$N$ approximation in the strong-coupling limit, we find that\nthere is a dynamical mass generation for the excitonic states that preserves\ntime-reversal symmetry and is related to the dynamical chiral-symmetry breaking\nof our model. This symmetry breaking occurs only for values of the\nfermion-flavor number smaller than $N_{c}\\approx 11.8$. Our results show that\nthe inclusion of the full dynamical interaction strongly modifies the critical\nnumber of flavors for the occurrence of exciton condensation, and therefore,\ncannot be neglected.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Lion and man in non-metric spaces.   A lion and a man move continuously in a space $X$. The aim of the lion is to\ncapture his prey while the man wants to escape forever. Which of them has a\nstrategy? This question has been studied for different metric domains. In this\narticle we consider the case of general topological spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonzero positive solutions of a multi-parameter elliptic system with functional BCs.   We prove, by topological methods, new results on the existence of nonzero\npositive weak solutions for a class of multi-parameter second order elliptic\nsystems subject to functional boundary conditions. The setting is fairly\ngeneral and covers the case of multi-point, integral and nonlinear boundary\nconditions. We also present a non-existence result. We provide some examples to\nillustrate the applicability our theoretical results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discretization error estimates for penalty formulations of a linearized Canham-Helfrich type energy.   This paper is concerned with minimization of a fourth-order linearized\nCanham-Helfrich energy subject to Dirichlet boundary conditions on curves\ninside the domain. Such problems arise in the modeling of the mechanical\ninteraction of biomembranes with embedded particles. There, the curve\nconditions result from the imposed particle--membrane coupling. We prove\nalmost-$H^{\\frac{5}{2}}$ regularity of the solution and then consider two\npossible penalty formulations. For the combination of these penalty\nformulations with a Bogner-Fox-Schmit finite element discretization we prove\ndiscretization error estimates which are optimal in view of the solution's\nreduced regularity. The error estimates are based on a general estimate for\nlinear penalty problems in Hilbert spaces. Finally, we illustrate the\ntheoretical results by numerical computations. An important feature of the\npresented discretization is that it does not require to resolve the particle\nboundary. This is crucial in order to avoid re-meshing if the presented problem\narises as subproblem in a model where particles are allowed to move or rotate.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Birth of isolated nested cylinders and limit cycles in 3D piecewise smooth vector fields with symmetry.   Our start point is a 3D piecewise smooth vector field defined in two zones\nand presenting a shared fold curve for the two smooth vector fields considered.\nMoreover, these smooth vector fields are symmetric relative to the fold curve,\ngiving raise to a continuum of nested topological cylinders such that each\northogonal section of these cylinders is filled by centers. First we prove that\nthe normal form considered represents a whole class of piecewise smooth vector\nfields. After we perturb the initial model in order to obtain exactly\n$\\mathcal{L}$ invariant planes containing centers. A second perturbation of the\ninitial model also is considered in order to obtain exactly $k$ isolated\ncylinders filled by periodic orbits. Finally, joining the two previous\nbifurcations we are able to exhibit a model, preserving the symmetry relative\nto the fold curve, and having exactly $k.\\mathcal{L}$ limit cycles.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The James construction and $π_4(\\mathbb{S}^3)$ in homotopy type theory.   In the first part of this paper we present a formalization in Agda of the\nJames construction in homotopy type theory. We include several fragments of\ncode to show what the Agda code looks like, and we explain several techniques\nthat we used in the formalization. In the second part, we use the James\nconstruction to give a constructive proof that $\\pi_4(\\mathbb{S}^3)$ is of the\nform $\\mathbb{Z}/n\\mathbb{Z}$ (but we do not compute the $n$ here).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Variants of RMSProp and Adagrad with Logarithmic Regret Bounds.   Adaptive gradient methods have become recently very popular, in particular as\nthey have been shown to be useful in the training of deep neural networks. In\nthis paper we have analyzed RMSProp, originally proposed for the training of\ndeep neural networks, in the context of online convex optimization and show\n$\\sqrt{T}$-type regret bounds. Moreover, we propose two variants SC-Adagrad and\nSC-RMSProp for which we show logarithmic regret bounds for strongly convex\nfunctions. Finally, we demonstrate in the experiments that these new variants\noutperform other adaptive gradient techniques or stochastic gradient descent in\nthe optimization of strongly convex functions as well as in training of deep\nneural networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gravitational radiation from compact binary systems in screened modified gravity.   Screened modified gravity (SMG) is a kind of scalar-tensor theory with\nscreening mechanisms, which can suppress the fifth force in dense regions and\nallow theories to evade the solar system and laboratory tests. In this paper,\nwe investigate how the screening mechanisms in SMG affect the gravitational\nradiation damping effects, calculate in detail the rate of the energy loss due\nto the emission of tensor and scalar gravitational radiations, and derive their\ncontributions to the change in the orbital period of the binary system. We find\nthat the scalar radiation depends on the screened parameters and the\npropagation speed of scalar waves, and the scalar dipole radiation dominates\nthe orbital decay of the binary system. For strongly self-gravitating bodies,\nall effects of scalar sector are strongly suppressed by the screening\nmechanisms in SMG. By comparing our results to observations of binary system\nPSR J1738+0333, we place the stringent constraints on the screening mechanisms\nin SMG. As an application of these results, we focus on three specific models\nof SMG (chameleon, symmetron, and dilaton), and derive the constraints on the\nmodel parameters, respectively.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stochastic Dynamic Optimal Power Flow in Distribution Network with Distributed Renewable Energy and Battery Energy Storage.   The penetration of distributed renewable energy (DRE) greatly raises the risk\nof distribution network operation such as peak shaving and voltage stability.\nBattery energy storage (BES) has been widely accepted as the most potential\napplication to cope with the challenge of high penetration of DRE. To cope with\nthe uncertainties and variability of DRE, a stochastic day-ahead dynamic\noptimal power flow (DOPF) and its algorithm are proposed. The overall economy\nis achieved by fully considering the DRE, BES, electricity purchasing and\nactive power losses. The rainflow algorithm-based cycle counting method of BES\nis incorporated in the DOPF model to capture the cell degradation, greatly\nextending the expected BES lifetime and achieving a better economy. DRE\nscenarios are generated to consider the uncertainties and correlations based on\nthe Copula theory. To solve the DOPF model, we propose a Lagrange\nrelaxation-based algorithm, which has a significantly reduced complexity with\nrespect to the existing techniques. For this reason, the proposed algorithm\nenables much more scenarios incorporated in the DOPF model and better captures\nthe DRE uncertainties and correlations. Finally, numerical studies for the\nday-ahead DOPF in the IEEE 123-node test feeder are presented to demonstrate\nthe merits of the proposed method. Results show that the actual BES life\nexpectancy of the proposed model has increased to 4.89 times compared with the\ntraditional ones. The problems caused by DRE are greatly alleviated by fully\ncapturing the uncertainties and correlations with the proposed method.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "NodeTrix Planarity Testing with Small Clusters.   We study the NodeTrix planarity testing problem for flat clustered graphs\nwhen the maximum size of each cluster is bounded by a constant $k$. We consider\nboth the case when the sides of the matrices to which the edges are incident\nare fixed and the case when they can be arbitrarily chosen. We show that\nNodeTrix planarity testing with fixed sides can be solved in\n$O(k^{3k+\\frac{3}{2}} n^3)$ time for every flat clustered graph that can be\nreduced to a partial 2-tree by collapsing its clusters into single vertices. In\nthe general case, NodeTrix planarity testing with fixed sides can be solved in\n$O(n^3)$ time for $k = 2$, but it is NP-complete for any $k \\geq 3$. NodeTrix\nplanarity testing remains NP-complete also in the free side model when $k > 4$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inverse problems in models of resource distribution.   We continue to study the problem of modeling of substitution of production\nfactors motivated by the need for computable mathematical models of economics\nthat could be used as a basis in applied developments. This problem has been\nstudied for several decades, and several connections to complex analysis and\ngeometry has been established. We describe several models of resource\ndistribution and discuss the inverse problems for the generalized Radon\ntransform arising is these models. We give a simple explicit range\ncharacterization for a particular case of the generalized Radon transform, and\nwe apply it to show that the most popular production functions are compatible\nwith these models. Besides, we give a necessary condition and a sufficient\ncondition for solvability of the model identification problem in the form of an\nappropriate moment problem. These conditions are formulated in terms of rhombic\ntilings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "KZ-Calogero correspondence revisited.   We discuss the correspondence between the Knizhnik-Zamolodchikov equations\nassociated with $GL(N)$ and the $n$-particle quantum Calogero model in the case\nwhen $n$ is not necessarily equal to $N$. This can be viewed as a natural\n\"quantization\" of the quantum-classical correspondence between quantum Gaudin\nand classical Calogero models.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Just-infinite C*-algebras and their invariants.   Just-infinite C*-algebras, i.e., infinite dimensional C*-algebras, whose\nproper quotients are finite dimensional, were investigated in\n[Grigorchuk-Musat-Rordam, 2016]. One particular example of a just-infinite\nresidually finite dimensional AF-algebras was constructed in that article. In\nthis paper we extend that construction by showing that each infinite\ndimensional metrizable Choquet simplex is affinely homeomorphic to the trace\nsimplex of a just-infinite residually finite dimensional C*-algebras. The trace\nsimplex of any unital residually finite dimensional C*-algebra is hence\nrealized by a just-infinite one. We determine the trace simplex of the\nparticular residually finite dimensional AF-algebras constructed in the above\nmentioned article, and we show that it has precisely one extremal trace of type\nII_1.\nWe give a complete description of the Bratteli diagrams corresponding to\nresidually finite dimensional AF-algebras. We show that a modification of any\nsuch Bratteli diagram, similar to the modification that makes an arbitrary\nBratteli diagram simple, will yield a just-infinite residually finite\ndimensional AF-algebra.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Never Forget: Balancing Exploration and Exploitation via Learning Optical Flow.   Exploration bonus derived from the novelty of the states in an environment\nhas become a popular approach to motivate exploration for deep reinforcement\nlearning agents in the past few years. Recent methods such as curiosity-driven\nexploration usually estimate the novelty of new observations by the prediction\nerrors of their system dynamics models. Due to the capacity limitation of the\nmodels and difficulty of performing next-frame prediction, however, these\nmethods typically fail to balance between exploration and exploitation in\nhigh-dimensional observation tasks, resulting in the agents forgetting the\nvisited paths and exploring those states repeatedly. Such inefficient\nexploration behavior causes significant performance drops, especially in large\nenvironments with sparse reward signals. In this paper, we propose to introduce\nthe concept of optical flow estimation from the field of computer vision to\ndeal with the above issue. We propose to employ optical flow estimation errors\nto examine the novelty of new observations, such that agents are able to\nmemorize and understand the visited states in a more comprehensive fashion. We\ncompare our method against the previous approaches in a number of experimental\nexperiments. Our results indicate that the proposed method appears to deliver\nsuperior and long-lasting performance than the previous methods. We further\nprovide a set of comprehensive ablative analysis of the proposed method, and\ninvestigate the impact of optical flow estimation on the learning curves of the\nDRL agents.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Combating Fake News: A Survey on Identification and Mitigation Techniques.   The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Symmetries and multipeakon solutions for the modified two-component Camassa-Holm system.   Compared with the two-component Camassa-Holm system, the modified\ntwo-component Camassa-Holm system introduces a regularized density which makes\npossible the existence of solutions of lower regularity, and in particular of\nmultipeakon solutions. In this paper, we derive a new pointwise invariant for\nthe modified two-component Camassa-Holm system. The derivation of the invariant\nuses directly the symmetry of the system, following the classical argument of\nNoether's theorem. The existence of the multipeakon solutions can be directly\ninferred from this pointwise invariant. This derivation shows the strong\nconnection between symmetries and the existence of special solutions. The\nobservation also holds for the scalar Camassa-Holm equation and, for\ncomparison, we have also included the corresponding derivation. Finally, we\ncompute explicitly the solutions obtained for the peakon-antipeakon case. We\nobserve the existence of a periodic solution which has not been reported in the\nliterature previously. This case shows the attractive effect that the\nintroduction of an elastic potential can have on the solutions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Zeroth order regular approximation approach to electric dipole moment interactions of the electron.   A quasi-relativistic two-component approach for an efficient calculation of\n$\\mathcal{P,T}$-odd interactions caused by a permanent electric dipole moment\nof the electron (eEDM) is presented. The approach uses a (two-component)\ncomplex generalized Hartree-Fock (cGHF) and a complex generalized Kohn-Sham\n(cGKS) scheme within the zeroth order regular approximation (ZORA). In\napplications to select heavy-elemental polar diatomic molecular radicals, which\nare promising candidates for an eEDM experiment, the method is compared to\nrelativistic four-component electron-correlation calculations and confirms\nvalues for the effective electrical field acting on the unpaired electron for\nRaF, BaF, YbF and HgF. The calculations show that purely relativistic effects,\ninvolving only the lower component of the Dirac bi-spinor, are well described\nby treating only the upper component explicitly.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Systems of cubic forms in many variables.   We consider a system of $R$ cubic forms in $n$ variables, with integer\ncoefficients, which define a smooth complete intersection in projective space.\nProvided $n\\geq 25R$, we prove an asymptotic formula for the number of integer\npoints in an expanding box at which these forms simultaneously vanish. In\nparticular we can handle systems of forms in $O(R)$ variables, previous work\nhaving required that $n \\gg R^2$. One conjectures that $n \\geq 6R+1$ should be\nsufficient. We reduce the problem to an upper bound for the number of solutions\nto a certain auxiliary inequality. To prove this bound we adapt a method of\nDavenport.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unsupervised prototype learning in an associative-memory network.   Unsupervised learning in a generalized Hopfield associative-memory network is\ninvestigated in this work. First, we prove that the (generalized) Hopfield\nmodel is equivalent to a semi-restricted Boltzmann machine with a layer of\nvisible neurons and another layer of hidden binary neurons, so it could serve\nas the building block for a multilayered deep-learning system. We then\ndemonstrate that the Hopfield network can learn to form a faithful internal\nrepresentation of the observed samples, with the learned memory patterns being\nprototypes of the input data. Furthermore, we propose a spectral method to\nextract a small set of concepts (idealized prototypes) as the most concise\nsummary or abstraction of the empirical data.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Searching for the Transit of the Earth--mass exoplanet Proxima~Centauri~b in Antarctica: Preliminary Result.   Proxima Centauri is known as the closest star from the Sun. Recently, radial\nvelocity observations revealed the existence of an Earth-mass planet around it.\nWith an orbital period of ~11 days, the surface of Proxima Centauri b is\ntemperate and might be habitable. We took a photometric monitoring campaign to\nsearch for its transit, using the Bright Star Survey Telescope at the Zhongshan\nStation in Antarctica. A transit-like signal appearing on 2016 September 8th,\nis identified tentatively. Its midtime, $T_{C}=2,457,640.1990\\pm0.0017$ HJD, is\nconsistent with the predicted ephemeris based on RV orbit in a 1$\\sigma$\nconfidence interval. Time-correlated noise is pronounced in the light curve of\nProxima Centauri, affecting detection of transits. We develop a technique, in a\nGaussian process framework, to gauge the statistical significance of potential\ntransit detection. The tentative transit signal reported here, has a confidence\nlevel of $2.5\\sigma$. Further detection of its periodic signals is necessary to\nconfirm the planetary transit of Proxima Centauri b. We plan to monitor Proxima\nCentauri in next Polar night at Dome A in Antarctica, taking the advantage of\ncontinuous darkness. \\citet{Kipping17} reported two tentative transit-like\nsignals of Proxima Centauri b, observed by the Microvariability and Oscillation\nof Stars space Telescope in 2014 and 2015, respectively. The midtransit time of\nour detection is 138 minutes later than that predicted by their transit\nephemeris. If all the signals are real transits, the misalignment of the epochs\nplausibly suggests transit timing variations of Proxima Centauri b induced by\nan outer planet in this system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Indoor Office Wideband Penetration Loss Measurements at 73 GHz.   This paper presents millimeter wave (mmWave) penetration loss measurements\nand analysis at 73 GHz using a wideband sliding correlator channel sounder in\nan indoor office environment. Penetration loss was measured using a carefully\ncontrolled measurement setup for many common indoor building materials such as\nglass doors, glass windows, closet doors, steel doors, and whiteboard writing\nwalls. Measurements were conducted using narrowbeam transmitter (TX) and\nreceiver (RX) horn antennas that were boresight-aligned with a test material\nbetween the antennas. Overall, 21 different locations were measured for 6\ndifferent materials such that the same type of material was tested in at least\ntwo locations in order to characterize the effect of penetration loss for\nmaterials with similar composition. As shown here, attenuation through common\nmaterials ranged between 0.8 dB/cm and 9.9 dB/cm for co-polarized antennas,\nwhile cross-polarized antennas exhibited similar attenuation for most\nmaterials, but up to 23.4 dB/cm of attenuation for others. The penetration loss\nresults presented here are useful for site-specific planning tools that will\nmodel indoor mmWave networks, without the need for expensive measurement\ncampaigns.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On types of degenerate critical points of real polynomial functions.   In this paper, we consider the problem of identifying the type (local\nminimizer, maximizer or saddle point) of a given isolated real critical point\n$c$, which is degenerate, of a multivariate polynomial function $f$. To this\nend, we introduce the definition of faithful radius of $c$ by means of the\ncurve of tangency of $f$. We show that the type of $c$ can be determined by the\nglobal extrema of $f$ over the Euclidean ball centered at $c$ with a faithful\nradius.We propose algorithms to compute a faithful radius of $c$ and determine\nits type.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Projection-Free Bandit Convex Optimization.   In this paper, we propose the first computationally efficient projection-free\nalgorithm for bandit convex optimization (BCO). We show that our algorithm\nachieves a sublinear regret of $O(nT^{4/5})$ (where $T$ is the horizon and $n$\nis the dimension) for any bounded convex functions with uniformly bounded\ngradients. We also evaluate the performance of our algorithm against baselines\non both synthetic and real data sets for quadratic programming, portfolio\nselection and matrix completion problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometric Fluctuation Theorem.   We derive an extended fluctuation theorem for a geometric pumping in a\nspin-boson system under a periodic control of environmental temperatures by\nusing a Markovian quantum master equation. We perform the Monte-Carlo\nsimulation and obtain the current distribution, the average current and the\nfluctuation. Using the extended fluctuation theorem we try to explain the\nresults of our simulation. The fluctuation theorem leads to the fluctuation\ndissipation relations but the absence of the conventional reciprocal relation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "More investment in Research and Development for better Education in the future?.   The question in this paper is whether R&D efforts affect education\nperformance in small classes. Merging two datasets collected from the PISA\nstudies and the World Development Indicators and using Learning Bayesian\nNetworks, we prove the existence of a statistical causal relationship between\ninvestment in R&D of a country and its education performance (PISA scores). We\nalso prove that the effect of R\\&D on Education is long term as a country has\nto invest at least 10 years before beginning to improve the level of young\npupils.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exploring light mediators with low-threshold direct detection experiments.   We explore the potential of future cryogenic direct detection experiments to\ndetermine the properties of the mediator that communicates the interactions\nbetween dark matter and nuclei. Due to their low thresholds and large\nexposures, experiments like CRESST-III, SuperCDMS SNOLAB and EDELWEISS-III will\nhave excellent capability to reconstruct mediator masses in the MeV range for a\nlarge class of models. Combining the information from several experiments\nfurther improves the parameter reconstruction, even when taking into account\nadditional nuisance parameters related to background uncertainties and the dark\nmatter velocity distribution. These observations may offer the intriguing\npossibility of studying dark matter self-interactions with direct detection\nexperiments.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Geometry of Manifolds with Some Tensor Structures and Metrics of Norden Type.   The object of study in the present dissertation are some topics in\ndifferential geometry of smooth manifolds with additional tensor structures and\nmetrics of Norden type. There are considered four cases depending on the\ndimension of the manifold: 2n, 2n + 1, 4n and 4n + 3. The studied tensor\nstructures, which are counterparts in the different related dimensions, are the\nalmost complex/contact/hypercomplex structure and the almost contact\n3-structure. The considered metric on the 2n-dimensional case is the Norden\nmetric, and the metrics in the other three cases are generated by it. The\npurpose of the dissertation is to carry out the following: 1. Further\ninvestigations of almost complex manifolds with Norden metric including\nstudying of natural connections with conditions for their torsion and invariant\ntensors under the twin interchange of Norden metrics. 2. Further investigations\nof almost contact manifolds with B-metric including studying of natural\nconnections with conditions for their torsion and associated Schouten-van\nKampen connections as well as a classification of affine connections. 3.\nIntroducing and studying of Sasaki-like almost contact complex Riemannian\nmanifolds. 4. Further investigations of almost hypercomplex manifolds with\nHermitian-Norden metrics including studying of integrable structures of the\nconsidered type on 4-dimensional Lie algebra and tangent bundles with the\ncomplete lift of the base metric; introducing of associated Nijenhuis tensors\nin relation with natural connections having totally skew-symmetric torsion as\nwell as quaternionic Kähler manifolds with Hermitian-Norden metrics. 5.\nIntroducing and studying of manifolds with almost contact 3-structures and\nmetrics of Hermitian-Norden type and, in particular, associated Nijenhuis\ntensors and their relationship with natural connections having totally\nskew-symmetric torsion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hierarchical Adversarially Learned Inference.   We propose a novel hierarchical generative model with a simple Markovian\nstructure and a corresponding inference model. Both the generative and\ninference model are trained using the adversarial learning paradigm. We\ndemonstrate that the hierarchical structure supports the learning of\nprogressively more abstract representations as well as providing semantically\nmeaningful reconstructions with different levels of fidelity. Furthermore, we\nshow that minimizing the Jensen-Shanon divergence between the generative and\ninference network is enough to minimize the reconstruction error. The resulting\nsemantically meaningful hierarchical latent structure discovery is exemplified\non the CelebA dataset. There, we show that the features learned by our model in\nan unsupervised way outperform the best handcrafted features. Furthermore, the\nextracted features remain competitive when compared to several recent deep\nsupervised approaches on an attribute prediction task on CelebA. Finally, we\nleverage the model's inference network to achieve state-of-the-art performance\non a semi-supervised variant of the MNIST digit classification task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A gradient estimate for nonlocal minimal graphs.   We consider the class of measurable functions defined in all of\n$\\mathbb{R}^n$ that give rise to a nonlocal minimal graph over a ball of\n$\\mathbb{R}^n$. We establish that the gradient of any such function is bounded\nin the interior of the ball by a power of its oscillation. This estimate,\ntogether with previously known results, leads to the $C^\\infty$ regularity of\nthe function in the ball. While the smoothness of nonlocal minimal graphs was\nknown for $n = 1, 2$ (but without a quantitative bound), in higher dimensions\nonly their continuity had been established.\nTo prove the gradient bound, we show that the normal to a nonlocal minimal\ngraph is a supersolution of a truncated fractional Jacobi operator, for which\nwe prove a weak Harnack inequality. To this end, we establish a new universal\nfractional Sobolev inequality on nonlocal minimal surfaces.\nOur estimate provides an extension to the fractional setting of the\ncelebrated gradient bounds of Finn and of Bombieri, De Giorgi & Miranda for\nsolutions of the classical mean curvature equation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Switching Isotropic and Directional Exploration with Parameter Space Noise in Deep Reinforcement Learning.   This paper proposes an exploration method for deep reinforcement learning\nbased on parameter space noise. Recent studies have experimentally shown that\nparameter space noise results in better exploration than the commonly used\naction space noise. Previous methods devised a way to update the diagonal\ncovariance matrix of a noise distribution and did not consider the direction of\nthe noise vector and its correlation. In addition, fast updates of the noise\ndistribution are required to facilitate policy learning. We propose a method\nthat deforms the noise distribution according to the accumulated returns and\nthe noises that have led to the returns. Moreover, this method switches\nisotropic exploration and directional exploration in parameter space with\nregard to obtained rewards. We validate our exploration strategy in the OpenAI\nGym continuous environments and modified environments with sparse rewards. The\nproposed method achieves results that are competitive with a previous method at\nbaseline tasks. Moreover, our approach exhibits better performance in sparse\nreward environments by exploration with the switching strategy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum critical response: from conformal perturbation theory to holography.   We discuss dynamical response functions near quantum critical points,\nallowing for both a finite temperature and detuning by a relevant operator.\nWhen the quantum critical point is described by a conformal field theory (CFT),\nconformal perturbation theory and the operator product expansion can be used to\nfix the first few leading terms at high frequencies. Knowledge of the high\nfrequency response allows us then to derive non-perturbative sum rules. We\nshow, via explicit computations, how holography recovers the general results of\nCFT, and the associated sum rules, for any holographic field theory with a\nconformal UV completion -- regardless of any possible new ordering and/or\nscaling physics in the IR. We numerically obtain holographic response functions\nat all frequencies, allowing us to probe the breakdown of the asymptotic\nhigh-frequency regime. Finally, we show that high frequency response functions\nin holographic Lifshitz theories are quite similar to their conformal\ncounterparts, even though they are not strongly constrained by symmetry.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Optimal Invariant Tests in an Instrumental Variables Regression With Heteroskedastic and Autocorrelated Errors.   This paper uses model symmetries in the instrumental variable (IV) regression\nto derive an invariant test for the causal structural parameter. Contrary to\npopular belief, we show there exist model symmetries when equation errors are\nheteroskedastic and autocorrelated (HAC). Our theory is consistent with\nexisting results for the homoskedastic model (Andrews, Moreira and Stock(2006}\nand Chamberlain (2007}), but in general uses information on the structural\nparameter beyond the Anderson-Rubin, score, and rank statistics. This suggests\nthat tests based only the Anderson-Rubin and score statistics discard\ninformation on the causal parameter of interest. We apply our theory to\nconstruct designs in which these tests indeed have power arbitrarily close to\nsize. Other tests, including other adaptations to the CLR test, do not suffer\nthe same deficiencies. Finally, we use the model symmetries to propose novel\nweighted-average power tests for the HAC-IV model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Warped Product Space-times.   Many classical results in relativity theory concerning spherically symmetric\nspace-times have easy generalizations to warped product space-times, with a\ntwo-dimensional Lorentzian base and arbitrary dimensional Riemannian fibers. We\nfirst give a systematic presentation of the main geometric constructions, with\nemphasis on the Kodama vector field and the Hawking energy; the construction is\nsignature independent. This leads to proofs of general Birkhoff-type theorems\nfor warped product manifolds; our theorems in particular apply to situations\nwhere the warped product manifold is not necessarily Einstein, and thus can be\napplied to solutions with matter content in general relativity. Next we\nspecialize to the Lorentzian case and study the propagation of null expansions\nunder the assumption of the dominant energy condition. We prove several\nnon-existence results relating to the Yamabe class of the fibers, in the spirit\nof the black-hole topology theorem of Hawking-Galloway-Schoen. Finally we\ndiscuss the effect of the warped product ansatz on matter models. In particular\nwe construct several cosmological solutions to the Einstein-Euler equations\nwhose spatial geometry is generally not isotropic.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Robust Regression via Mutivariate Regression Depth.   This paper studies robust regression in the settings of Huber's\n$\\epsilon$-contamination models. We consider estimators that are maximizers of\nmultivariate regression depth functions. These estimators are shown to achieve\nminimax rates in the settings of $\\epsilon$-contamination models for various\nregression problems including nonparametric regression, sparse linear\nregression, reduced rank regression, etc. We also discuss a general notion of\ndepth function for linear operators that has potential applications in robust\nfunctional linear regression.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Galaxy-Halo Connection Over The Last 13.3 Gyrs.   We present new determinations of the stellar-to-halo mass relation (SHMR) at\n$z=0-10$ that match the evolution of the galaxy stellar mass function, the\nSFR$-M_*$ relation,and the cosmic star formation rate. We utilize a compilation\nof 40 observational studies from the literature and correct them for potential\nbiases. Using our robust determinations of halo mass assembly and the SHMR, we\ninfer star formation histories, merger rates, and structural properties for\naverage galaxies, combining star-forming and quenched galaxies. Our main\nfindings: (1) The halo mass $M_{50}$ above which 50\\% of galaxies are quenched\ncoincides with sSFR/sMAR$\\sim1$, where sMAR is the specific halo mass accretion\nrate. (2) $M_{50}$ increases with redshift, presumably due to cold streams\nbeing more efficient at high redshift while virial shocks and AGN feedback\nbecome more relevant at lower redshifts. (3) The ratio sSFR/sMAR has a peak\nvalue, which occurs around $M_{\\rm vir}\\sim2\\times10^{11}M_{\\odot}$. (4) The\nstellar mass density within 1 kpc, $\\Sigma_1$, is a good indicator of the\ngalactic global sSFR. (5) Galaxies are statistically quenched after they reach\na maximum in $\\Sigma_1$, consistent with theoretical expectations of the gas\ncompaction model; this maximum depends on redshift. (6) In-situ star formation\nis responsible for most galactic stellar mass growth, especially for lower-mass\ngalaxies. (7) Galaxies grow inside out. The marked change in the slope of the\nsize--mass relation when galaxies became quenched, from $d\\log R_{\\rm\neff}/d\\log M_*\\sim0.35$ to $\\sim2.5$, could be the result of dry minor mergers.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Slow Spin Dynamics and Self-Sustained Clusters in Sparsely Connected Systems.   To identify emerging microscopic structures in low temperature spin glasses,\nwe study self-sustained clusters (SSC) in spin models defined on sparse random\ngraphs. A message-passing algorithm is developed to determine the probability\nof individual spins to belong to SSC. Results for specific instances, which\ncompare the predicted SSC associations with the dynamical properties of spins\nobtained from numerical simulations, show that SSC association identifies\nindividual slow-evolving spins. This insight gives rise to a powerful approach\nfor predicting individual spin dynamics from a single snapshot of an\nequilibrium spin configuration, namely from limited static information, which\ncan be used to devise generic prediction tools applicable to a wide range of\nareas.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Convergence of extreme value statistics in a two-layer quasi-geostrophic atmospheric model.   We search for the signature of universal properties of extreme events,\ntheoretically predicted for Axiom A flows, in a chaotic and high dimensional\ndynamical system by studying the convergence of GEV (Generalized Extreme Value)\nand GP (Generalized Pareto) shape parameter estimates to a theoretical value,\nexpressed in terms of partial dimensions of the attractor, which are global\nproperties. We consider a two layer quasi-geostrophic (QG) atmospheric model\nusing two forcing levels, and analyse extremes of different types of physical\nobservables (local, zonally-averaged energy, and the average value of energy\nover the mid-latitudes). Regarding the predicted universality, we find closer\nagreement in the shape parameter estimates only in the case of strong forcing,\nproducing a highly chaotic behaviour, for some observables (the local energy at\nevery latitude). Due to the limited (though very large) data size and the\npresence of serial correlations, it is difficult to obtain robust statistics of\nextremes in case of the other observables. In the case of weak forcing,\ninducing a less pronounced chaotic flow with regime behaviour, we find worse\nagreement with the theory developed for Axiom A flows, which is unsurprising\nconsidering the properties of the system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "One-shot and few-shot learning of word embeddings.   Standard deep learning systems require thousands or millions of examples to\nlearn a concept, and cannot integrate new concepts easily. By contrast, humans\nhave an incredible ability to do one-shot or few-shot learning. For instance,\nfrom just hearing a word used in a sentence, humans can infer a great deal\nabout it, by leveraging what the syntax and semantics of the surrounding words\ntells us. Here, we draw inspiration from this to highlight a simple technique\nby which deep recurrent networks can similarly exploit their prior knowledge to\nlearn a useful representation for a new word from little data. This could make\nnatural language processing systems much more flexible, by allowing them to\nlearn continually from the new words they encounter.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Controlling Physical Attributes in GAN-Accelerated Simulation of Electromagnetic Calorimeters.   High-precision modeling of subatomic particle interactions is critical for\nmany fields within the physical sciences, such as nuclear physics and high\nenergy particle physics. Most simulation pipelines in the sciences are\ncomputationally intensive -- in a variety of scientific fields, Generative\nAdversarial Networks have been suggested as a solution to speed up the forward\ncomponent of simulation, with promising results. An important component of any\nsimulation system for the sciences is the ability to condition on any number of\nphysically meaningful latent characteristics that can effect the forward\ngeneration procedure. We introduce an auxiliary task to the training of a\nGenerative Adversarial Network on particle showers in a multi-layer\nelectromagnetic calorimeter, which allows our model to learn an attribute-aware\nconditioning mechanism.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Feature Model-to-Ontology for SPL Application Realisation.   Feature model are widely used to capture commonalities and variabilities of\nartefacts in Software Product Line (SPL). Several studies have discussed the\nformal representation of feature diagram using ontologies with different styles\nof mapping. However, they still focused on the ontology approach for problem\nspace and keep the solution space aside. In this paper, we present the\nmodelling of feature model using OWL ontology and produce an application based\non the ontology. Firstly, we map the features in a running example feature\ndiagram to OWL classes and properties. Secondly, we verify the consistency of\nthe OWL ontology by using reasoning engines. Finally, we use the ontology as an\ninput of Zotonic framework for application realisation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Intrinsic geometry and analysis of Finsler structures.   In this short note, we prove that if $F$ is a weak upper semicontinuous\nadmissible Finsler structure on a domain in $\\mathbb{R}^n$, $n\\geq 2$, then the\nintrinsic distance and differential structures coincide.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Critical neural networks with short and long term plasticity.   In recent years self organised critical neuronal models have provided\ninsights regarding the origin of the experimentally observed avalanching\nbehaviour of neuronal systems. It has been shown that dynamical synapses, as a\nform of short-term plasticity, can cause critical neuronal dynamics. Whereas\nlong-term plasticity, such as hebbian or activity dependent plasticity, have a\ncrucial role in shaping the network structure and endowing neural systems with\nlearning abilities. In this work we provide a model which combines both\nplasticity mechanisms, acting on two different time-scales. The measured\navalanche statistics are compatible with experimental results for both the\navalanche size and duration distribution with biologically observed percentages\nof inhibitory neurons. The time-series of neuronal activity exhibits temporal\nbursts leading to 1/f decay in the power spectrum. The presence of long-term\nplasticity gives the system the ability to learn binary rules such as XOR,\nproviding the foundation of future research on more complicated tasks such as\npattern recognition.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Parallel Simultaneous Perturbation Optimization.   Stochastic computer simulations enable users to gain new insights into\ncomplex physical systems. Optimization is a common problem in this context:\nusers seek to find model inputs that maximize the expected value of an\nobjective function. The objective function, however, is time-intensive to\nevaluate, and cannot be directly measured. Instead, the stochastic nature of\nthe model means that individual realizations are corrupted by noise. More\nformally, we consider the problem of optimizing the expected value of an\nexpensive black-box function with continuously-differentiable mean, from which\nobservations are corrupted by Gaussian noise. We present Parallel Simultaneous\nPerturbation Optimization (PSPO), which extends a well-known stochastic\noptimization algorithm, simultaneous perturbation stochastic approximation, in\nseveral important ways. Our modifications allow the algorithm to fully take\nadvantage of parallel computing resources, like high-performance cloud\ncomputing. The resulting PSPO algorithm takes fewer time-consuming iterations\nto converge, automatically chooses the step size, and can vary the error\ntolerance by step. Theoretical results are supported by a numerical example. To\ndemonstrate the performance of the algorithm, we implemented the algorithm to\nmaximize the pseudo-likelihood of a stochastic epidemiological model to data of\na measles outbreak.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Some Ultraspheroidal Monogenic Clifford Gegenbauer Jacobi Polynomials and Associated Wavelets.   In the present paper, new classes of wavelet functions are presented in the\nframework of Clifford analysis. Firstly, some classes of orthogonal polynomials\nare provided based on 2-parameters weight functions. Such classes englobe the\nwell known ones of Jacobi and Gegenbauer polynomials when relaxing one of the\nparameters. The discovered polynomial sets are next applied to introduce new\nwavelet functions. Reconstruction formula as well as Fourier-Plancherel rules\nhave been proved.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nef partitions for codimension 2 weighted complete intersections.   We prove that a smooth well formed Fano weighted complete intersection of\ncodimension 2 has a nef partition. We discuss applications of this fact to\nMirror Symmetry. In particular we list all nef partitions for smooth well\nformed Fano weighted complete intersections of dimensions 4 and 5 and present\nweak Landau--Ginzburg models for them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Estimation of Principal Eigenspaces.   Principal component analysis (PCA) is fundamental to statistical machine\nlearning. It extracts latent principal factors that contribute to the most\nvariation of the data. When data are stored across multiple machines, however,\ncommunication cost can prohibit the computation of PCA in a central location\nand distributed algorithms for PCA are thus needed. This paper proposes and\nstudies a distributed PCA algorithm: each node machine computes the top $K$\neigenvectors and transmits them to the central server; the central server then\naggregates the information from all the node machines and conducts a PCA based\non the aggregated information. We investigate the bias and variance for the\nresulting distributed estimator of the top $K$ eigenvectors. In particular, we\nshow that for distributions with symmetric innovation, the empirical top\neigenspaces are unbiased and hence the distributed PCA is \"unbiased\". We derive\nthe rate of convergence for distributed PCA estimators, which depends\nexplicitly on the effective rank of covariance, eigen-gap, and the number of\nmachines. We show that when the number of machines is not unreasonably large,\nthe distributed PCA performs as well as the whole sample PCA, even without full\naccess of whole data. The theoretical results are verified by an extensive\nsimulation study. We also extend our analysis to the heterogeneous case where\nthe population covariance matrices are different across local machines but\nshare similar top eigen-structures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Impact of Feature Selection on Micro-Text Classification.   Social media datasets, especially Twitter tweets, are popular in the field of\ntext classification. Tweets are a valuable source of micro-text (sometimes\nreferred to as \"micro-blogs\"), and have been studied in domains such as\nsentiment analysis, recommendation systems, spam detection, clustering, among\nothers. Tweets often include keywords referred to as \"Hashtags\" that can be\nused as labels for the tweet. Using tweets encompassing 50 labels, we studied\nthe impact of word versus character-level feature selection and extraction on\ndifferent learners to solve a multi-class classification task. We show that\nfeature extraction of simple character-level groups performs better than simple\nword groups and pre-processing methods like normalizing using Porter's Stemming\nand Part-of-Speech (\"POS\")-Lemmatization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "High-frequency approximation of the interior dirichlet-to-neumann map and applications to the transmission eigenvalues.   We study the high-frequency behavior of the Dirichlet-to-Neumann map for an\narbitrary compact Riemannian manifold with a non-empty smooth boundary. We show\nthat far from the real axis it can be approximated by a simpler operator. We\nuse this fact to get new results concerning the location of the transmission\neigenvalues on the complex plane. In some cases we obtain optimal transmission\neigenvalue-free regions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accelerating Permutation Testing in Voxel-wise Analysis through Subspace Tracking: A new plugin for SnPM.   Permutation testing is a non-parametric method for obtaining the max null\ndistribution used to compute corrected $p$-values that provide strong control\nof false positives. In neuroimaging, however, the computational burden of\nrunning such an algorithm can be significant. We find that by viewing the\npermutation testing procedure as the construction of a very large permutation\ntesting matrix, $T$, one can exploit structural properties derived from the\ndata and the test statistics to reduce the runtime under certain conditions. In\nparticular, we see that $T$ is low-rank plus a low-variance residual. This\nmakes $T$ a good candidate for low-rank matrix completion, where only a very\nsmall number of entries of $T$ ($\\sim0.35\\%$ of all entries in our experiments)\nhave to be computed to obtain a good estimate. Based on this observation, we\npresent RapidPT, an algorithm that efficiently recovers the max null\ndistribution commonly obtained through regular permutation testing in\nvoxel-wise analysis. We present an extensive validation on a synthetic dataset\nand four varying sized datasets against two baselines: Statistical\nNonParametric Mapping (SnPM13) and a standard permutation testing\nimplementation (referred as NaivePT). We find that RapidPT achieves its best\nruntime performance on medium sized datasets ($50 \\leq n \\leq 200$), with\nspeedups of 1.5x - 38x (vs. SnPM13) and 20x-1000x (vs. NaivePT). For larger\ndatasets ($n \\geq 200$) RapidPT outperforms NaivePT (6x - 200x) on all\ndatasets, and provides large speedups over SnPM13 when more than 10000\npermutations (2x - 15x) are needed. The implementation is a standalone toolbox\nand also integrated within SnPM13, able to leverage multi-core architectures\nwhen available.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Enhanced clustering tendency of Cu-impurities with a number of oxygen vacancies in heavy carbon-loaded TiO2 - the bulk and surface morphologies.   The over threshold carbon-loadings (~50 at.%) of initial TiO2-hosts and\nposterior Cu-sensitization (~7 at.%) was made using pulsed ion-implantation\ntechnique in sequential mode with 1 hour vacuum-idle cycle between sequential\nstages of embedding. The final Cx-TiO2:Cu samples were qualified using XPS\nwide-scan elemental analysis, core-levels and valence band mappings. The\nresults obtained were discussed on the theoretic background employing\nDFT-calculations. The combined XPS and DFT analysis allows to establish and\nprove the final formula of the synthesized samples as Cx-TiO2:[Cu+][Cu2+] for\nthe bulk and Cx-TiO2:[Cu+][Cu0] for thin-films. It was demonstrated the in the\nmode of heavy carbon-loadings the remaining majority of neutral C-C bonds\n(sp3-type) is dominating and only a lack of embedded carbon is fabricating the\nO-C=O clusters. No valence base-band width altering was established after\nsequential carbon-copper modification of the atomic structure of initial\nTiO2-hosts except the dominating majority of Cu 3s states after\nCu-sensitization. The crucial role of neutral carbon low-dimensional impurities\nas the precursors for the new phases growth was shown for Cu-sensitized Cx-TiO2\nintermediate-state hosts.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Mutation invariance for the zeroth coefficients of the colored HOMFLY polynomial.   We show that the zeroth coefficient of the cables of the HOMFLY polynomial\n(colored HOMFLY polynomials) does not distinguish mutants. This makes a sharp\ncontrast with the total HOMFLY polynomial whose 3-cables can distinguish\nmutants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotic Normality of Extensible Grid Sampling.   Recently, He and Owen (2016) proposed the use of Hilbert's space filling\ncurve (HSFC) in numerical integration as a way of reducing the dimension from\n$d>1$ to $d=1$. This paper studies the asymptotic normality of the HSFC-based\nestimate when using scrambled van der Corput sequence as input. We show that\nthe estimate has an asymptotic normal distribution for functions in\n$C^1([0,1]^d)$, excluding the trivial case of constant functions. The\nasymptotic normality also holds for discontinuous functions under mild\nconditions. It was previously known only that scrambled $(0,m,d)$-net\nquadratures enjoy the asymptotic normality for smooth enough functions, whose\nmixed partial gradients satisfy a Hölder condition. As a by-product, we find\nlower bounds for the variance of the HSFC-based estimate. Particularly, for\nnontrivial functions in $C^1([0,1]^d)$, the low bound is of order $n^{-1-2/d}$,\nwhich matches the rate of the upper bound established in He and Owen (2016).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Some new bounds of placement delivery arrays.   Coded caching scheme is a technique which reduce the load during peak traffic\ntimes in a wireless network system. Placement delivery array (PDA in short) was\nfirst introduced by Yan et al.. It can be used to design coded caching scheme.\nIn this paper, we prove some lower bounds of PDA on the element and some lower\nbounds of PDA on the column. We also give some constructions for optimal PDA.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adsorption and desorption of hydrogen at nonpolar GaN(1-100) surfaces: Kinetics and impact on surface vibrational and electronic properties.   The adsorption of hydrogen at nonpolar GaN(1-100) surfaces and its impact on\nthe electronic and vibrational properties is investigated using surface\nelectron spectroscopy in combination with density functional theory (DFT)\ncalculations. For the surface mediated dissociation of H2 and the subsequent\nadsorption of H, an energy barrier of 0.55 eV has to be overcome. The\ncalculated kinetic surface phase diagram indicates that the reaction is\nkinetically hindered at low pressures and low temperatures. At higher\ntemperatures ab-initio thermodynamics show, that the H-free surface is\nenergetically favored. To validate these theoretical predictions experiments at\nroom temperature and under ultrahigh vacuum conditions were performed. They\nreveal that molecular hydrogen does not dissociatively adsorb at the GaN(1-100)\nsurface. Only activated atomic hydrogen atoms attach to the surface. At\ntemperatures above 820 K, the attached hydrogen gets desorbed. The adsorbed\nhydrogen atoms saturate the dangling bonds of the gallium and nitrogen surface\natoms and result in an inversion of the Ga-N surface dimer buckling. The\nsignatures of the Ga-H and N-H vibrational modes on the H-covered surface have\nexperimentally been identified and are in good agreement with the DFT\ncalculations of the surface phonon modes. Both theory and experiment show that\nH adsorption results in a removal of occupied and unoccupied intragap electron\nstates of the clean GaN(1-100) surface and a reduction of the surface upward\nband bending by 0.4 eV. The latter mechanism largely reduces surface electron\ndepletion.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "SegMap: 3D Segment Mapping using Data-Driven Descriptors.   When performing localization and mapping, working at the level of structure\ncan be advantageous in terms of robustness to environmental changes and\ndifferences in illumination. This paper presents SegMap: a map representation\nsolution to the localization and mapping problem based on the extraction of\nsegments in 3D point clouds. In addition to facilitating the computationally\nintensive task of processing 3D point clouds, working at the level of segments\naddresses the data compression requirements of real-time single- and\nmulti-robot systems. While current methods extract descriptors for the single\ntask of localization, SegMap leverages a data-driven descriptor in order to\nextract meaningful features that can also be used for reconstructing a dense 3D\nmap of the environment and for extracting semantic information. This is\nparticularly interesting for navigation tasks and for providing visual feedback\nto end-users such as robot operators, for example in search and rescue\nscenarios. These capabilities are demonstrated in multiple urban driving and\nsearch and rescue experiments. Our method leads to an increase of area under\nthe ROC curve of 28.3% over current state of the art using eigenvalue based\nfeatures. We also obtain very similar reconstruction capabilities to a model\nspecifically trained for this task. The SegMap implementation will be made\navailable open-source along with easy to run demonstrations at\nwww.github.com/ethz-asl/segmap. A video demonstration is available at\nthis https URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Proposal for a High Precision Tensor Processing Unit.   This whitepaper proposes the design and adoption of a new generation of\nTensor Processing Unit which has the performance of Google's TPU, yet performs\noperations on wide precision data. The new generation TPU is made possible by\nimplementing arithmetic circuits which compute using a new general purpose,\nfractional arithmetic based on the residue number system.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reward Maximization Under Uncertainty: Leveraging Side-Observations on Networks.   We study the stochastic multi-armed bandit (MAB) problem in the presence of\nside-observations across actions that occur as a result of an underlying\nnetwork structure. In our model, a bipartite graph captures the relationship\nbetween actions and a common set of unknowns such that choosing an action\nreveals observations for the unknowns that it is connected to. This models a\ncommon scenario in online social networks where users respond to their friends'\nactivity, thus providing side information about each other's preferences. Our\ncontributions are as follows: 1) We derive an asymptotic lower bound (with\nrespect to time) as a function of the bi-partite network structure on the\nregret of any uniformly good policy that achieves the maximum long-term average\nreward. 2) We propose two policies - a randomized policy; and a policy based on\nthe well-known upper confidence bound (UCB) policies - both of which explore\neach action at a rate that is a function of its network position. We show,\nunder mild assumptions, that these policies achieve the asymptotic lower bound\non the regret up to a multiplicative factor, independent of the network\nstructure. Finally, we use numerical examples on a real-world social network\nand a routing example network to demonstrate the benefits obtained by our\npolicies over other existing policies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Fast Interior Point Method for Atomic Norm Soft Thresholding.   The atomic norm provides a generalization of the $\\ell_1$-norm to continuous\nparameter spaces. When applied as a sparse regularizer for line spectral\nestimation the solution can be obtained by solving a convex optimization\nproblem. This problem is known as atomic norm soft thresholding (AST). It can\nbe cast as a semidefinite program and solved by standard methods. In the\nsemidefinite formulation there are $O(N^2)$ dual variables and a standard\nprimal-dual interior point method requires at least $O(N^6)$ flops per\niteration. That has lead researcher to consider alternating direction method of\nmultipliers (ADMM) for the solution of AST, but this method is still somewhat\nslow for large problem sizes. To obtain a faster algorithm we reformulate AST\nas a non-symmetric conic program. That has two properties of key importance to\nits numerical solution: the conic formulation has only $O(N)$ dual variables\nand the Toeplitz structure inherent to AST is preserved. Based on it we derive\nFastAST which is a primal-dual interior point method for solving AST. Two\nvariants are considered with the fastest one requiring only $O(N^2)$ flops per\niteration. Extensive numerical experiments demonstrate that FastAST solves AST\nsignificantly faster than a state-of-the-art solver based on ADMM.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Free fermions on a piecewise linear four-manifold. II: Pachner moves.   This is the second in a series of papers where we construct an invariant of a\nfour-dimensional piecewise linear manifold $M$ with a given middle cohomology\nclass $h\\in H^2(M,\\mathbb C)$. This invariant is the square root of the torsion\nof unusual chain complex introduced in Part I (arXiv:1605.06498) of our work,\nmultiplied by a correcting factor. Here we find this factor by studying the\nbehavior of our construction under all four-dimensional Pachner moves, and show\nthat it can be represented in a multiplicative form: a product of same-type\nmultipliers over all 2-faces, multiplied by a product of same-type multipliers\nover all pentachora.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convergence Analysis of Deterministic Kernel-Based Quadrature Rules in Misspecified Settings.   This paper presents a convergence analysis of kernel-based quadrature rules\nin misspecified settings, focusing on deterministic quadrature in Sobolev\nspaces. In particular, we deal with misspecified settings where a test\nintegrand is less smooth than a Sobolev RKHS based on which a quadrature rule\nis constructed. We provide convergence guarantees based on two different\nassumptions on a quadrature rule: one on quadrature weights, and the other on\ndesign points. More precisely, we show that convergence rates can be derived\n(i) if the sum of absolute weights remains constant (or does not increase\nquickly), or (ii) if the minimum distance between design points does not\ndecrease very quickly. As a consequence of the latter result, we derive a rate\nof convergence for Bayesian quadrature in misspecified settings. We reveal a\ncondition on design points to make Bayesian quadrature robust to\nmisspecification, and show that, under this condition, it may adaptively\nachieve the optimal rate of convergence in the Sobolev space of a lesser order\n(i.e., of the unknown smoothness of a test integrand), under a slightly\nstronger regularity condition on the integrand.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hydra: a C++11 framework for data analysis in massively parallel platforms.   Hydra is a header-only, templated and C++11-compliant framework designed to\nperform the typical bottleneck calculations found in common HEP data analyses\non massively parallel platforms. The framework is implemented on top of the\nC++11 Standard Library and a variadic version of the Thrust library and is\ndesigned to run on Linux systems, using OpenMP, CUDA and TBB enabled devices.\nThis contribution summarizes the main features of Hydra. A basic description of\nthe overall design, functionality and user interface is provided, along with\nsome code examples and measurements of performance.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Interacting superradiance samples: modified intensities and timescales, and frequency shifts.   We consider the interaction between distinct superradiance (SR) systems and\nuse the dressed state formalism to solve the case of two interacting two-atom\nSR samples at resonance. We show that the ensuing entanglement modifies the\ntransition rates and intensities of radiation, as well as introduces a\npotentially measurable frequency chirp in the SR cascade, the magnitude of\nwhich being a function of the separation between the samples. For the dominant\nSR cascade we find a significant reduction in the duration and an increase of\nthe intensity of the SR pulse relative to the case of a single two-atom SR\nsample.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Thermal diffusivity and chaos in metals without quasiparticles.   We study the thermal diffusivity $D_T$ in models of metals without\nquasiparticle excitations (`strange metals'). The many-body quantum chaos and\ntransport properties of such metals can be efficiently described by a\nholographic representation in a gravitational theory in an emergent curved\nspacetime with an additional spatial dimension. We find that at generic\ninfra-red fixed points $D_T$ is always related to parameters characterizing\nmany-body quantum chaos: the butterfly velocity $v_B$, and Lyapunov time\n$\\tau_L$ through $D_T \\sim v_B^2 \\tau_L$. The relationship holds independently\nof the charge density, periodic potential strength or magnetic field at the\nfixed point. The generality of this result follows from the observation that\nthe thermal conductivity of strange metals depends only on the metric near the\nhorizon of a black hole in the emergent spacetime, and is otherwise insensitive\nto the profile of any matter fields.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "General Refraction Problems with Phase Discontinuity.   This paper provides a mathematical approach to study metasurfaces in non flat\ngeometries. Analytical conditions between the curvature of the surface and the\nset of refracted directions are introduced to guarantee the existence of phase\ndiscontinuities. The approach contains both the near and far field cases. A\nstarting point is the formulation of a vector Snell law in presence of abrupt\ndiscontinuities on the interfaces.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Zero-temperature magnetic response of small fullerene molecules at the classical and full quantum limit.   The ground-state magnetic response of fullerene molecules with up to 36\nvertices is calculated, when spins classical or with magnitude $s=\\frac{1}{2}$\nare located on their vertices and interact according to the nearest-neighbor\nantiferromagnetic Heisenberg model. The frustrated topology, which originates\nin the pentagons of the fullerenes and is enhanced by their close proximity,\nleads to a significant number of classical magnetization and susceptibility\ndiscontinuities, something not expected for a model lacking magnetic\nanisotropy. This establishes the classical discontinuities as a generic feature\nof fullerene molecules irrespective of their symmetry. The largest number of\ndiscontinuities have the molecule with 26 sites, four of the magnetization and\ntwo of the susceptibility, and an isomer with 34 sites, which has three each.\nIn addition, for several of the fullerenes the classical zero-field lowest\nenergy configuration has finite magnetization, which is unexpected for\nantiferromagnetic interactions between an even number of spins and with each\nspin having the same number of nearest-neighbors. The molecules come in\ndifferent symmetries and topologies and there are only a few patterns of\nmagnetic behavior that can be detected from such a small sample of relatively\nsmall fullerenes. Contrary to the classical case, in the full quantum limit\n$s=\\frac{1}{2}$ there are no discontinuities for a subset of the molecules that\nwas considered. This leaves the icosahedral symmetry fullerenes as the only\nones known supporting ground-state magnetization discontinuities for\n$s=\\frac{1}{2}$. It is also found that a molecule with 34 sites has a\ndoubly-degenerate ground state when $s=\\frac{1}{2}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Leverage Score Sampling for Faster Accelerated Regression and ERM.   Given a matrix $\\mathbf{A}\\in\\mathbb{R}^{n\\times d}$ and a vector $b\n\\in\\mathbb{R}^{d}$, we show how to compute an $\\epsilon$-approximate solution\nto the regression problem $ \\min_{x\\in\\mathbb{R}^{d}}\\frac{1}{2} \\|\\mathbf{A} x\n- b\\|_{2}^{2} $ in time $ \\tilde{O} ((n+\\sqrt{d\\cdot\\kappa_{\\text{sum}}})\\cdot\ns\\cdot\\log\\epsilon^{-1}) $ where\n$\\kappa_{\\text{sum}}=\\mathrm{tr}\\left(\\mathbf{A}^{\\top}\\mathbf{A}\\right)/\\lambda_{\\min}(\\mathbf{A}^{T}\\mathbf{A})$\nand $s$ is the maximum number of non-zero entries in a row of $\\mathbf{A}$. Our\nalgorithm improves upon the previous best running time of $ \\tilde{O}\n((n+\\sqrt{n \\cdot\\kappa_{\\text{sum}}})\\cdot s\\cdot\\log\\epsilon^{-1})$.\nWe achieve our result through a careful combination of leverage score\nsampling techniques, proximal point methods, and accelerated coordinate\ndescent. Our method not only matches the performance of previous methods, but\nfurther improves whenever leverage scores of rows are small (up to\npolylogarithmic factors). We also provide a non-linear generalization of these\nresults that improves the running time for solving a broader class of ERM\nproblems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "KATE: K-Competitive Autoencoder for Text.   Autoencoders have been successful in learning meaningful representations from\nimage datasets. However, their performance on text datasets has not been widely\nstudied. Traditional autoencoders tend to learn possibly trivial\nrepresentations of text documents due to their confounding properties such as\nhigh-dimensionality, sparsity and power-law word distributions. In this paper,\nwe propose a novel k-competitive autoencoder, called KATE, for text documents.\nDue to the competition between the neurons in the hidden layer, each neuron\nbecomes specialized in recognizing specific data patterns, and overall the\nmodel can learn meaningful representations of textual data. A comprehensive set\nof experiments show that KATE can learn better representations than traditional\nautoencoders including denoising, contractive, variational, and k-sparse\nautoencoders. Our model also outperforms deep generative models, probabilistic\ntopic models, and even word representation models (e.g., Word2Vec) in terms of\nseveral downstream tasks such as document classification, regression, and\nretrieval.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Small-scale Effects of Thermal Inflation on Halo Abundance at High-$z$, Galaxy Substructure Abundance and 21-cm Power Spectrum.   We study the impact of thermal inflation on the formation of cosmological\nstructures and present astrophysical observables which can be used to constrain\nand possibly probe the thermal inflation scenario. These are dark matter halo\nabundance at high redshifts, satellite galaxy abundance in the Milky Way, and\nfluctuation in the 21-cm radiation background before the epoch of reionization.\nThe thermal inflation scenario leaves a characteristic signature on the matter\npower spectrum by boosting the amplitude at a specific wavenumber determined by\nthe number of e-foldings during thermal inflation ($N_{\\rm bc}$), and strongly\nsuppressing the amplitude for modes at smaller scales. For a reasonable range\nof parameter space, one of the consequences is the suppression of minihalo\nformation at high redshifts and that of satellite galaxies in the Milky Way.\nWhile this effect is substantial, it is degenerate with other cosmological or\nastrophysical effects. The power spectrum of the 21-cm background probes this\nimpact more directly, and its observation may be the best way to constrain the\nthermal inflation scenario due to the characteristic signature in the power\nspectrum. The Square Kilometre Array (SKA) in phase 1 (SKA1) has sensitivity\nlarge enough to achieve this goal for models with $N_{\\rm bc}\\gtrsim 26$ if a\n10000-hr observation is performed. The final phase SKA, with anticipated\nsensitivity about an order of magnitude higher, seems more promising and will\ncover a wider parameter space.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A branch-and-bound algorithm for the minimum radius $k$-enclosing ball problem.   The minimum $k$-enclosing ball problem seeks the ball with smallest radius\nthat contains at least~$k$ of~$m$ given points in a general $n$-dimensional\nEuclidean space. This problem is NP-hard. We present a branch-and-bound\nalgorithm on the tree of the subsets of~$k$ points to solve this problem. The\nnodes on the tree are ordered in a suitable way, which, complemented with a\nlast-in-first-out search strategy, allows for only a small fraction of nodes to\nbe explored. Additionally, an efficient dual algorithm to solve the subproblems\nat each node is employed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reinforcement Learning of Speech Recognition System Based on Policy Gradient and Hypothesis Selection.   Speech recognition systems have achieved high recognition performance for\nseveral tasks. However, the performance of such systems is dependent on the\ntremendously costly development work of preparing vast amounts of task-matched\ntranscribed speech data for supervised training. The key problem here is the\ncost of transcribing speech data. The cost is repeatedly required to support\nnew languages and new tasks. Assuming broad network services for transcribing\nspeech data for many users, a system would become more self-sufficient and more\nuseful if it possessed the ability to learn from very light feedback from the\nusers without annoying them. In this paper, we propose a general reinforcement\nlearning framework for speech recognition systems based on the policy gradient\nmethod. As a particular instance of the framework, we also propose a hypothesis\nselection-based reinforcement learning method. The proposed framework provides\na new view for several existing training and adaptation methods. The\nexperimental results show that the proposed method improves the recognition\nperformance compared to unsupervised adaptation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A construction of trivial Beltrami coefficients.   A measurable function $\\mu$ on the unit disk $\\mathbb{D}$ of the complex\nplane with $\\|\\mu\\|_\\infty<1$ is sometimes called a Beltrami coefficient. We\nsay that $\\mu$ is trivial if it is the complex dilatation $f_{\\bar z}/f_z$ of a\nquasiconformal automorphism $f$ of $\\mathbb{D}$ satisfying the trivial boundary\ncondition $f(z)=z,~|z|=1.$ Since it is not easy to solve the Beltrami equation\nexplicitly, to detect triviality of a given Beltrami coefficient is a hard\nproblem, in general. In the present article, we offer a sufficient condition\nfor a Beltrami coefficient to be trivial. Our proof is based on Betker's\ntheorem on Löwner chains.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Four revolutions in physics and the second quantum revolution -- a unification of force and matter by quantum information.   Newton's mechanical revolution unifies the motion of planets in the sky and\nfalling of apple on earth. Maxwell's electromagnetic revolution unifies\nelectricity, magnetism, and light. Einstein's relativity revolution unifies\nspace with time, and gravity with space-time distortion. The quantum revolution\nunifies particle with waves, and energy with frequency. Each of those\nrevolution changes our world view. In this article, we will describe a\nrevolution that is happening now: the second quantum revolution which unifies\nmatter/space with information. In other words, the new world view suggests that\nelementary particles (the bosonic force particles and fermionic matter\nparticles) all originated from quantum information (qubits): they are\ncollective excitations of an entangled qubit ocean that corresponds to our\nspace. The beautiful geometric Yang-Mills gauge theory and the strange Fermi\nstatistics of matter particles now have a common algebraic quantum\ninformational origin.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Convexity of level lines of Martin functions and applications.   Let $\\Omega$ be an unbounded domain in $\\mathbb{R}\\times\\mathbb{R}^{d}.$ A\npositive harmonic function $u$ on $\\Omega$ that vanishes on the boundary of\n$\\Omega$ is called a Martin function. In this note, we show that, when $\\Omega$\nis convex, the superlevel sets of a Martin function are also convex. As a\nconsequence we obtain that if in addition $\\Omega$ is symmetric, then the\nmaximum of any Martin function along a slice $\\Omega\\cap\n(\\{t\\}\\times\\mathbb{R}^d)$ is attained at $(t,0).$",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The statistical significance filter leads to overconfident expectations of replicability.   We show that publishing results using the statistical significance\nfilter---publishing only when the p-value is less than 0.05---leads to a\nvicious cycle of overoptimistic expectation of the replicability of results.\nFirst, we show analytically that when true statistical power is relatively low,\ncomputing power based on statistically significant results will lead to\noverestimates of power. Then, we present a case study using 10 experimental\ncomparisons drawn from a recently published meta-analysis in psycholinguistics\n(Jäger et al., 2017). We show that the statistically significant results\nyield an illusion of replicability. This illusion holds even if the researcher\ndoesn't conduct any formal power analysis but just uses statistical\nsignificance to informally assess robustness (i.e., replicability) of results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamical Tides in Highly Eccentric Binaries: Chaos, Dissipation and Quasi-Steady State.   Highly eccentric binary systems appear in many astrophysical contexts,\nranging from tidal capture in dense star clusters, precursors of stellar\ndisruption by massive black holes, to high-eccentricity migration of giant\nplanets. In a highly eccentric binary, the tidal potential of one body can\nexcite oscillatory modes in the other during a pericenter passage, resulting in\nenergy exchange between the modes and the binary orbit. These modes exhibit one\nof three behaviors over multiple passages: low-amplitude oscillations, large\namplitude oscillations corresponding to a resonance between the orbital\nfrequency and the mode frequency, and chaotic growth. We study these phenomena\nwith an iterative map, fully exploring how the mode evolution depends on the\npericenter distance and other parameters. In addition, we show that the\ndissipation of mode energy results in a quasi-steady state, with gradual\norbital decay punctuated by resonances, even in systems where the mode\namplitude would initially grow stochastically. A newly captured star around a\nblack hole can experience significant orbital decay and heating due to the\nchaotic growth of the mode amplitude and dissipation. A giant planet pushed\ninto a high-eccentricity orbit may experience a similar effect and become a hot\nor warm Jupiter.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Linear-time Algorithm for Orthogonal Watchman Route Problem with Minimum Bends.   Given an orthogonal polygon $ P $ with $ n $ vertices, the goal of the\nwatchman route problem is finding a path $ S $ of the minimum length in $ P $\nsuch that every point of the polygon $ P $ is visible from at least one of the\npoint of $ S $. In the other words, in the watchman route problem we must\ncompute a shortest watchman route inside a simple polygon of $ n $ vertices\nsuch that all the points interior to the polygon and on its boundary are\nvisible to at least one point on the route. If route and polygon be orthogonal,\nit is called orthogonal watchman route problem. One of the targets of this\nproblem is finding the orthogonal path with the minimum number of bends as\npossible. We present a linear-time algorithm for the orthogonal watchman route\nproblem, in which the given polygon is monotone. Our algorithm can be used also\nfor the problem on simple orthogonal polygons $ P $ for which the dual graph\ninduced by the vertical decomposition of $ P $ is a path, which is called path\npolygon.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "$z^\\circ$-ideals in intermediate rings of ordered field valued continuous functions.   A proper ideal $I$ in a commutative ring with unity is called a\n$z^\\circ$-ideal if for each $a$ in $I$, the intersection of all minimal prime\nideals in $R$ which contain $a$ is contained in $I$. For any totally ordered\nfield $F$ and a completely $F$-regular topological space $X$, let $C(X,F)$ be\nthe ring of all $F$-valued continuous functions on $X$ and $B(X,F)$ the\naggregate of all those functions which are bounded over $X$. An explicit\nformula for all the $z^\\circ$-ideals in $A(X,F)$ in terms of ideals of closed\nsets in $X$ is given. It turns out that an intermediate ring $A(X,F)\\neq\nC(X,F)$ is never regular in the sense of Von-Neumann. This property further\ncharacterizes $C(X,F)$ amongst the intermediate rings within the class of\n$P_F$-spaces $X$. It is also realized that $X$ is an almost $P_F$-space if and\nonly if each maximal ideal in $C(X,F)$ is $z^\\circ$-ideal. Incidentally this\nproperty also characterizes $C(X,F)$ amongst the intermediate rings within the\nfamily of almost $P_F$-spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Valley polarized relaxation and upconversion luminescence from Tamm-Plasmon Trion-Polaritons with a MoSe2 monolayer.   Transition metal dichalcogenides represent an ideal testbed to study\nexcitonic effects, spin-related phenomena and fundamental light-matter coupling\nin nanoscopic condensed matter systems. In particular, the valley degree of\nfreedom, which is unique to such direct band gap monolayers with broken\ninversion symmetry, adds fundamental interest in these materials. Here, we\nimplement a Tamm-plasmon structure with an embedded MoSe2 monolayer and study\nthe formation of polaritonic quasi-particles. Strong coupling conditions\nbetween the Tamm-mode and the trion resonance of MoSe2 are established,\nyielding bright luminescence from the polaritonic ground state under\nnon-resonant optical excitation. We demonstrate, that tailoring the\nelectrodynamic environment of the monolayer results in a significantly\nincreased valley polarization. This enhancement can be related to change in\nrecombination dynamics shown in time-resolved photoluminescence measurements.\nWe furthermore observe strong upconversion luminescence from resonantly excited\npolariton states in the lower polariton branch. This upconverted polariton\nluminescence is shown to preserve the valley polarization of the\ntrion-polariton, which paves the way towards combining spin-valley physics and\nexciton scattering experiments.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Status updates through M/G/1/1 queues with HARQ.   We consider a system where randomly generated updates are to be transmitted\nto a monitor, but only a single update can be in the transmission service at a\ntime. Therefore, the source has to prioritize between the two possible\ntransmission policies: preempting the current update or discarding the new one.\nWe consider Poisson arrivals and general service time, and refer to this system\nas the M/G/1/1 queue. We start by studying the average status update age and\nthe optimal update arrival rate for these two schemes under general service\ntime distribution. We then apply these results on two practical scenarios in\nwhich updates are sent through an erasure channel using (a) an infinite\nincremental redundancy (IIR) HARQ system and (b) a fixed redundancy (FR) HARQ\nsystem. We show that in both schemes the best strategy would be not to preempt.\nMoreover, we also prove that, from an age point of view, IIR is better than FR.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Hypernetworks.   We study Bayesian hypernetworks: a framework for approximate Bayesian\ninference in neural networks. A Bayesian hypernetwork $\\h$ is a neural network\nwhich learns to transform a simple noise distribution, $p(\\vec\\epsilon) =\n\\N(\\vec 0,\\mat I)$, to a distribution $q(\\pp) := q(h(\\vec\\epsilon))$ over the\nparameters $\\pp$ of another neural network (the \"primary network\")\\@. We train\n$q$ with variational inference, using an invertible $\\h$ to enable efficient\nestimation of the variational lower bound on the posterior $p(\\pp | \\D)$ via\nsampling. In contrast to most methods for Bayesian deep learning, Bayesian\nhypernets can represent a complex multimodal approximate posterior with\ncorrelations between parameters, while enabling cheap iid sampling of~$q(\\pp)$.\nIn practice, Bayesian hypernets can provide a better defense against\nadversarial examples than dropout, and also exhibit competitive performance on\na suite of tasks which evaluate model uncertainty, including regularization,\nactive learning, and anomaly detection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Khovanov homology and periodic links.   Based on the results of the second author, we define an equivariant version\nof Lee and Bar-Natan homology for periodic links and show that there exists an\nequivariant spectral sequence from the equivariant Khovanov homology to\nequivariant Lee homology. As a result we obtain new obstructions for a link to\nbe periodic. These obstructions generalize previous results of Przytycki and of\nthe second author.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modelling the descent of nitric oxide during the elevated stratopause event of January 2013.   Using simulations with a whole-atmosphere chemistry-climate model nudged by\nmeteorological analyses, global satellite observations of nitrogen oxide (NO)\nand water vapour by the Sub-Millimetre Radiometer instrument (SMR), of\ntemperature by the Microwave Limb Sounder (MLS), as well as local radar\nobservations, this study examines the recent major stratospheric sudden warming\naccompanied by an elevated stratopause event (ESE) that occurred in January\n2013. We examine dynamical processes during the ESE, including the role of\nplanetary wave, gravity wave and tidal forcing on the initiation of the descent\nin the mesosphere-lower thermosphere (MLT) and its continuation throughout the\nmesosphere and stratosphere, as well as the impact of model eddy diffusion. We\nanalyse the transport of NO and find the model underestimates the large descent\nof NO compared to SMR observations. We demonstrate that the discrepancy arises\nabruptly in the MLT region at a time when the resolved wave forcing and the\nplanetary wave activity increase, just before the elevated stratopause reforms.\nThe discrepancy persists despite doubling the model eddy diffusion. While the\nsimulations reproduce an enhancement of the semi-diurnal tide following the\nonset of the 2013 SSW, corroborating new meteor radar observations at high\nnorthern latitudes over Trondheim (63.4$^{\\circ}$N), the modelled tidal\ncontribution to the forcing of the mean meridional circulation and to the\ndescent is a small portion of the resolved wave forcing, and lags it by about\nten days.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Scaling Limits for Super--replication with Transient Price Impact.   We prove limit theorems for the super-replication cost of European options in\na Binomial model with transient price impact. We show that if the time step\ngoes to zero and the effective resilience between consecutive trading times\nremains constant then the limit of the super--replication prices coincide with\nthe scaling limit for temporary price impact with a modified market depth.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust two-qubit gates in a linear ion crystal using a frequency-modulated driving force.   In an ion trap quantum computer, collective motional modes are used to\nentangle two or more qubits in order to execute multi-qubit logical gates. Any\nresidual entanglement between the internal and motional states of the ions\nresults in loss of fidelity, especially when there are many spectator ions in\nthe crystal. We propose using a frequency-modulated (FM) driving force to\nminimize such errors. In simulation, we obtained an optimized FM two-qubit gate\nthat can suppress errors to less than 0.01\\% and is robust against frequency\ndrifts over $\\pm$1 kHz. Experimentally, we have obtained a two-qubit gate\nfidelity of $98.3(4)\\%$, a state-of-the-art result for two-qubit gates with 5\nions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Origin of Deep Learning.   This paper is a review of the evolutionary history of deep learning models.\nIt covers from the genesis of neural networks when associationism modeling of\nthe brain is studied, to the models that dominate the last decade of research\nin deep learning like convolutional neural networks, deep belief networks, and\nrecurrent neural networks. In addition to a review of these models, this paper\nprimarily focuses on the precedents of the models above, examining how the\ninitial ideas are assembled to construct the early models and how these\npreliminary models are developed into their current forms. Many of these\nevolutionary paths last more than half a century and have a diversity of\ndirections. For example, CNN is built on prior knowledge of biological vision\nsystem; DBN is evolved from a trade-off of modeling power and computation\ncomplexity of graphical models and many nowadays models are neural counterparts\nof ancient linear models. This paper reviews these evolutionary paths and\noffers a concise thought flow of how these models are developed, and aims to\nprovide a thorough background for deep learning. More importantly, along with\nthe path, this paper summarizes the gist behind these milestones and proposes\nmany directions to guide the future research of deep learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Water sub-diffusion in membranes for fuel cells.   We investigate the dynamics of water confined in soft ionic nano-assemblies,\nan issue critical for a general understanding of the multi-scale\nstructure-function interplay in advanced materials. We focus in particular on\nhydrated perfluoro-sulfonic acid compounds employed as electrolytes in fuel\ncells. These materials form phase-separated morphologies that show outstanding\nproton-conducting properties, directly related to the state and dynamics of the\nabsorbed water. We have quantified water motion and ion transport by combining\nQuasi Elastic Neutron Scattering, Pulsed Field Gradient Nuclear Magnetic\nResonance, and Molecular Dynamics computer simulation. Effective water and ion\ndiffusion coefficients have been determined together with their variation upon\nhydration at the relevant atomic, nanoscopic and macroscopic scales, providing\na complete picture of transport. We demonstrate that confinement at the\nnanoscale and direct interaction with the charged interfaces produce anomalous\nsub-diffusion, due to a heterogeneous space-dependent dynamics within the ionic\nnanochannels. This is irrespective of the details of the chemistry of the\nhydrophobic confining matrix, confirming the statistical significance of our\nconclusions. Our findings turn out to indicate interesting connections and\npossibilities of cross-fertilization with other domains, including biophysics.\nThey also establish fruitful correspondences with advanced topics in\nstatistical mechanics, resulting in new possibilities for the analysis of\nNeutron scattering data.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Understanding News Outlets' Audience-Targeting Patterns.   The power of the press to shape the informational landscape of a population\nis unparalleled, even now in the era of democratic access to all information\noutlets. However, it is known that news outlets (particularly more traditional\nones) tend to discriminate who they want to reach, and who to leave aside. In\nthis work, we attempt to shed some light on the audience targeting patterns of\nnewspapers, using the Chilean media ecosystem. First, we use the gravity model\nto analyze geography as a factor in explaining audience reachability. This\nshows that some newspapers are indeed driven by geographical factors (mostly\nlocal news outlets) but some others are not (national-distribution outlets).\nFor those which are not, we use a regression model to study the influence of\nsocioeconomic and political characteristics in news outlets adoption. We\nconclude that indeed larger, national-distribution news outlets target\npopulations based on these factors, rather than on geography or immediacy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Summarized Network Behavior Prediction.   This work studies the entity-wise topical behavior from massive network logs.\nBoth the temporal and the spatial relationships of the behavior are explored\nwith the learning architectures combing the recurrent neural network (RNN) and\nthe convolutional neural network (CNN). To make the behavioral data appropriate\nfor the spatial learning in CNN, several reduction steps are taken to form the\ntopical metrics and place them homogeneously like pixels in the images. The\nexperimental result shows both the temporal- and the spatial- gains when\ncompared to a multilayer perceptron (MLP) network. A new learning framework\ncalled spatially connected convolutional networks (SCCN) is introduced to more\nefficiently predict the behavior.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "NIP formulas and Baire 1 definability.   In this short note, using results of Bourgain, Fremlin, and Talagrand\n\\cite{BFT}, we show that for a countable structure $M$, a saturated elementary\nextension $M^*$ of $M$ and a formula $\\phi(x,y)$ the following are equivalent:\n(i) $\\phi(x,y)$ is NIP on $M$ (in the sense of Definition 2.1).\n(ii) Whenever $p(x)\\in S_\\phi(M^*)$ is finitely satisfiable in $M$ then it is\nBaire 1 definable over $M$ (in sense of Definition 2.5).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ringel duality as an instance of Koszul duality.   In their previous work, S. Koenig, S. Ovsienko and the second author showed\nthat every quasi-hereditary algebra is Morita equivalent to the right algebra,\ni.e. the opposite algebra of the left dual, of a coring. Let $A$ be an\nassociative algebra and $V$ an $A$-coring whose right algebra $R$ is\nquasi-hereditary. In this paper, we give a combinatorial description of an\nassociative algebra $B$ and a $B$-coring $W$ whose right algebra is the Ringel\ndual of $R$. We apply our results in small examples to obtain restrictions on\nthe $A_\\infty$-structure of the $\\textrm{Ext}$-algebra of standard modules over\na class of quasi-hereditary algebras related to birational morphisms of smooth\nsurfaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A general framework for data-driven uncertainty quantification under complex input dependencies using vine copulas.   Systems subject to uncertain inputs produce uncertain responses. Uncertainty\nquantification (UQ) deals with the estimation of statistics of the system\nresponse, given a computational model of the system and a probabilistic model\nof its inputs. In engineering applications it is common to assume that the\ninputs are mutually independent or coupled by a Gaussian or elliptical\ndependence structure (copula). In this paper we overcome such limitations by\nmodelling the dependence structure of multivariate inputs as vine copulas. Vine\ncopulas are models of multivariate dependence built from simpler pair-copulas.\nThe vine representation is flexible enough to capture complex dependencies.\nThis paper formalises the framework needed to build vine copula models of\nmultivariate inputs and to combine them with virtually any UQ method. The\nframework allows for a fully automated, data-driven inference of the\nprobabilistic input model on available input data. The procedure is exemplified\non two finite element models of truss structures, both subject to inputs with\nnon-Gaussian dependence structures. For each case, we analyse the moments of\nthe model response (using polynomial chaos expansions), and perform a\nstructural reliability analysis to calculate the probability of failure of the\nsystem (using the first order reliability method and importance sampling).\nReference solutions are obtained by Monte Carlo simulation. The results show\nthat, while the Gaussian assumption yields biased statistics, the vine copula\nrepresentation achieves significantly more precise estimates, even when its\nstructure needs to be fully inferred from a limited amount of observations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Game of Life on Penrose tilings.   We define rules for cellular automata played on quasiperiodic tilings of the\nplane arising from the multigrid method in such a way that these cellular\nautomata are isomorphic to Conway's Game of Life. Although these tilings are\nnonperiodic, determining the next state of each tile is a local computation,\nrequiring only knowledge of the local structure of the tiling and the states of\nfinitely many nearby tiles. As an example, we show a version of a \"glider\"\nmoving through a region of a Penrose tiling. This constitutes a potential\ntheoretical framework for a method of executing computations in\nnon-periodically structured substrates such as quasicrystals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Binary Voting with Delegable Proxy: An Analysis of Liquid Democracy.   The paper provides an analysis of the voting method known as delegable proxy\nvoting, or liquid democracy. The analysis first positions liquid democracy\nwithin the theory of binary aggregation. It then focuses on two issues of the\nsystem: the occurrence of delegation cycles; and the effect of delegations on\nindividual rationality when voting on logically interdependent propositions. It\nfinally points to proposals on how the system may be modified in order to\naddress the above issues.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Nesterov gradient methods over arbitrary graphs.   In this letter, we introduce a distributed Nesterov method, termed as\n$\\mathcal{ABN}$, that does not require doubly-stochastic weight matrices.\nInstead, the implementation is based on a simultaneous application of both row-\nand column-stochastic weights that makes this method applicable to arbitrary\n(strongly-connected) graphs. Since constructing column-stochastic weights needs\nadditional information (the number of outgoing neighbors at each agent), not\navailable in certain communication protocols, we derive a variation, termed as\nFROZEN, that only requires row-stochastic weights but at the expense of\nadditional iterations for eigenvector learning. We numerically study these\nalgorithms for various objective functions and network parameters and show that\nthe proposed distributed Nesterov methods achieve acceleration compared to the\ncurrent state-of-the-art methods for distributed optimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Routing in FRET-based Nanonetworks.   Nanocommunications, understood as communications between nanoscale devices,\nis commonly regarded as a technology essential for cooperation of large groups\nof nanomachines and thus crucial for development of the whole area of\nnanotechnology. While solutions for point-to-point nanocommunications have been\nalready proposed, larger networks cannot function properly without routing. In\nthis article we focus on the nanocommunications via Forster Resonance Energy\nTransfer (FRET), which was found to be a technique with a very high signal\npropagation speed, and discuss how to route signals through nanonetworks. We\nintroduce five new routing mechanisms, based on biological properties of\nspecific molecules. We experimentally validate one of these mechanisms.\nFinally, we analyze open issues showing the technical challenges for signal\ntransmission and routing in FRET-based nanocommunications.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Resonant Drag Instabilities in protoplanetary disks: the streaming instability and new, faster-growing instabilities.   We identify and study a number of new, rapidly growing instabilities of dust\ngrains in protoplanetary disks, which may be important for planetesimal\nformation. The study is based on the recognition that dust-gas mixtures are\ngenerically unstable to a Resonant Drag Instability (RDI), whenever the gas,\nabsent dust, supports undamped linear modes. We show that the \"streaming\ninstability\" is an RDI associated with epicyclic oscillations; this provides\nsimple interpretations for its mechanisms and accurate analytic expressions for\nits growth rates and fastest-growing wavelengths. We extend this analysis to\nmore general dust streaming motions and other waves, including buoyancy and\nmagnetohydrodynamic oscillations, finding various new instabilities. Most\nimportantly, we identify the disk \"settling instability,\" which occurs as dust\nsettles vertically into the midplane of a rotating disk. For small grains, this\ninstability grows many orders of magnitude faster than the standard streaming\ninstability, with a growth rate that is independent of grain size. Growth\ntimescales for realistic dust-to-gas ratios are comparable to the disk orbital\nperiod, and the characteristic wavelengths are more than an order of magnitude\nlarger than the streaming instability (allowing the instability to concentrate\nlarger masses). This suggests that in the process of settling, dust will band\ninto rings then filaments or clumps, potentially seeding dust traps,\nhigh-metallicity regions that in turn seed the streaming instability, or even\noverdensities that coagulate or directly collapse to planetesimals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Replication issues in syntax-based aspect extraction for opinion mining.   Reproducing experiments is an important instrument to validate previous work\nand build upon existing approaches. It has been tackled numerous times in\ndifferent areas of science. In this paper, we introduce an empirical\nreplicability study of three well-known algorithms for syntactic centric\naspect-based opinion mining. We show that reproducing results continues to be a\ndifficult endeavor, mainly due to the lack of details regarding preprocessing\nand parameter setting, as well as due to the absence of available\nimplementations that clarify these details. We consider these are important\nthreats to validity of the research on the field, specifically when compared to\nother problems in NLP where public datasets and code availability are critical\nvalidity components. We conclude by encouraging code-based research, which we\nthink has a key role in helping researchers to understand the meaning of the\nstate-of-the-art better and to generate continuous advances.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A GNS construction of three-dimensional abelian Dijkgraaf-Witten theories.   We give a detailed account of the so-called \"universal construction\" that\naims to extend invariants of closed manifolds, possibly with additional\nstructure, to topological field theories and show that it amounts to a\ngeneralization of the GNS construction. We apply this construction to an\ninvariant defined in terms of the groupoid cardinality of groupoids of bundles\nto recover Dijkgraaf-Witten theories, including the vector spaces obtained as a\nlinearization of spaces of principal bundles.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using angular pair upweighting to improve 3D clustering measurements.   Three dimensional galaxy clustering measurements provide a wealth of\ncosmological information. However, obtaining spectra of galaxies is expensive,\nand surveys often only measure redshifts for a subsample of a target galaxy\npopulation. Provided that the spectroscopic data is representative, we argue\nthat angular pair upweighting should be used in these situations to improve the\n3D clustering measurements. We present a toy model showing mathematically how\nsuch a weighting can improve measurements, and provide a practical example of\nits application using mocks created for the Baryon Oscillation Spectroscopic\nSurvey (BOSS). Our analysis of mocks suggests that, if an angular clustering\nmeasurement is available over twice the area covered spectroscopically,\nweighting gives a $\\sim$10-20% reduction of the variance of the monopole\ncorrelation function on the BAO scale.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Estimating occupation time functionals.   We study the estimation of integral type functionals $\\int_{0}^{t}f(X_{r})dr$\nfor a function $f$ and a $d$-dimensional càdlàg process $X$ with respect to\ndiscrete observations by a Riemann-sum estimator. Based on novel semimartingale\napproximations in the Fourier domain, central limit theorems are proved for\n$L^{2}$-Sobolev functions $f$ with fractional smoothness and continuous Itô\nsemimartingales $X$. General $L^{2}(\\mathbb{P})$-upper bounds on the error for\ncàdlàg processes are given under weak assumptions. These bounds combine and\ngeneralize all previously obtained results in the literature and apply also to\nnon-Markovian processes. Several detailed examples are discussed. As\napplication the approximation of local times for fractional Brownian motion is\nstudied. The optimality of the $L^{2}(\\mathbb{P})$-upper bounds is shown by\nproving the corresponding lower bounds in case of Brownian motion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Wind accretion onto compact objects.   X-ray emission associated to accretion onto compact objects displays\nimportant levels of photometric and spectroscopic time-variability. When the\naccretor orbits a Supergiant star, it captures a fraction of the supersonic\nradiatively-driven wind which forms shocks in its vicinity. The amplitude and\nstability of this gravitational beaming of the flow conditions the mass\naccretion rate responsible, in fine, for the X-ray luminosity of those\nSupergiant X-ray Binaries. The capacity of this low angular momentum inflow to\nform a disc-like structure susceptible to be the stage of well-known\ninstabilities remains at stake. Using state-of-the-art numerical setups, we\ncharacterized the structure of a Bondi-Hoyle-Lyttleton flow onto a compact\nobject, from the shock down to the vicinity of the accretor, typically five\norders of magnitude smaller. The evolution of the mass accretion rate and of\nthe bow shock which forms around the accretor (transverse structure, opening\nangle, stability, temperature profile) with the Mach number of the incoming\nflow is described in detail. The robustness of those simulations based on the\nHigh Performance Computing MPI-AMRVAC code is supported by the topology of the\ninner sonic surface, in agreement with theoretical expectations. We developed a\nsynthetic model of mass transfer in Supergiant X-ray Binaries which couples the\nlaunching of the wind accordingly to the stellar parameters, the orbital\nevolution of the streamlines in a modified Roche potential and the accretion\nprocess. We show that the shape of the permanent flow is entirely determined by\nthe mass ratio, the filling factor, the Eddington factor and the alpha-force\nmultiplier. Provided scales such as the orbital period are known, we can trace\nback the observables to evaluate the mass accretion rates, the accretion\nmechanism (stream or wind-dominated) and the shearing of the inflow.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An Empirical Analysis of Proximal Policy Optimization with Kronecker-factored Natural Gradients.   In this technical report, we consider an approach that combines the PPO\nobjective and K-FAC natural gradient optimization, for which we call PPOKFAC.\nWe perform a range of empirical analysis on various aspects of the algorithm,\nsuch as sample complexity, training speed, and sensitivity to batch size and\ntraining epochs. We observe that PPOKFAC is able to outperform PPO in terms of\nsample complexity and speed in a range of MuJoCo environments, while being\nscalable in terms of batch size. In spite of this, it seems that adding more\nepochs is not necessarily helpful for sample efficiency, and PPOKFAC seems to\nbe worse than its A2C counterpart, ACKTR.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved Power Decoding of One-Point Hermitian Codes.   We propose a new partial decoding algorithm for one-point Hermitian codes\nthat can decode up to the same number of errors as the Guruswami--Sudan\ndecoder. Simulations suggest that it has a similar failure probability as the\nlatter one. The algorithm is based on a recent generalization of the power\ndecoding algorithm for Reed--Solomon codes and does not require an expensive\nroot-finding step. In addition, it promises improvements for decoding\ninterleaved Hermitian codes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Extended Vertical Lists for Temporal Pattern Mining from Multivariate Time Series.   Temporal Pattern Mining (TPM) is the problem of mining predictive complex\ntemporal patterns from multivariate time series in a supervised setting. We\ndevelop a new method called the Fast Temporal Pattern Mining with Extended\nVertical Lists. This method utilizes an extension of the Apriori property which\nrequires a more complex pattern to appear within records only at places where\nall of its subpatterns are detected as well. The approach is based on a novel\ndata structure called the Extended Vertical List that tracks positions of the\nfirst state of the pattern inside records. Extensive computational results\nindicate that the new method performs significantly faster than the previous\nversion of the algorithm for TMP. However, the speed-up comes at the expense of\nmemory usage.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Flow equations for cold Bose gases.   We derive flow equations for cold atomic gases with one macroscopically\npopulated energy level. The generator is chosen such that the ground state\ndecouples from all other states in the system as the renormalization group flow\nprogresses. We propose a self-consistent truncation scheme for the flow\nequations at the level of three-body operators and show how they can be used to\ncalculate the ground state energy of a general $N$-body system. Moreover, we\nprovide a general method to estimate the truncation error in the calculated\nenergies. Finally, we test our scheme by benchmarking to the exactly solvable\nLieb-Liniger model and find good agreement for weak and moderate interaction\nstrengths.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Icing on the Cake: An Easy and Quick Post-Learnig Method You Can Try After Deep Learning.   We found an easy and quick post-learning method named \"Icing on the Cake\" to\nenhance a classification performance in deep learning. The method is that we\ntrain only the final classifier again after an ordinary training is done.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Priv'IT: Private and Sample Efficient Identity Testing.   We develop differentially private hypothesis testing methods for the small\nsample regime. Given a sample $\\cal D$ from a categorical distribution $p$ over\nsome domain $\\Sigma$, an explicitly described distribution $q$ over $\\Sigma$,\nsome privacy parameter $\\varepsilon$, accuracy parameter $\\alpha$, and\nrequirements $\\beta_{\\rm I}$ and $\\beta_{\\rm II}$ for the type I and type II\nerrors of our test, the goal is to distinguish between $p=q$ and\n$d_{\\rm{TV}}(p,q) \\geq \\alpha$.\nWe provide theoretical bounds for the sample size $|{\\cal D}|$ so that our\nmethod both satisfies $(\\varepsilon,0)$-differential privacy, and guarantees\n$\\beta_{\\rm I}$ and $\\beta_{\\rm II}$ type I and type II errors. We show that\ndifferential privacy may come for free in some regimes of parameters, and we\nalways beat the sample complexity resulting from running the $\\chi^2$-test with\nnoisy counts, or standard approaches such as repetition for endowing\nnon-private $\\chi^2$-style statistics with differential privacy guarantees. We\nexperimentally compare the sample complexity of our method to that of recently\nproposed methods for private hypothesis testing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The sequence of open and closed prefixes of a Sturmian word.   A finite word is closed if it contains a factor that occurs both as a prefix\nand as a suffix but does not have internal occurrences, otherwise it is open.\nWe are interested in the {\\it oc-sequence} of a word, which is the binary\nsequence whose $n$-th element is $0$ if the prefix of length $n$ of the word is\nopen, or $1$ if it is closed. We exhibit results showing that this sequence is\ndeeply related to the combinatorial and periodic structure of a word. In the\ncase of Sturmian words, we show that these are uniquely determined (up to\nrenaming letters) by their oc-sequence. Moreover, we prove that the class of\nfinite Sturmian words is a maximal element with this property in the class of\nbinary factorial languages. We then discuss several aspects of Sturmian words\nthat can be expressed through this sequence. Finally, we provide a linear-time\nalgorithm that computes the oc-sequence of a finite word, and a linear-time\nalgorithm that reconstructs a finite Sturmian word from its oc-sequence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Treewidth distance on phylogenetic trees.   In this article we study the treewidth of the \\emph{display graph}, an\nauxiliary graph structure obtained from the fusion of phylogenetic (i.e.,\nevolutionary) trees at their leaves. Earlier work has shown that the treewidth\nof the display graph is bounded if the trees are in some formal sense\ntopologically similar. Here we further expand upon this relationship. We\nanalyse a number of reduction rules which are commonly used in the\nphylogenetics literature to obtain fixed parameter tractable algorithms. In\nsome cases (the \\emph{subtree} reduction) the reduction rules behave similarly\nwith respect to treewidth, while others (the \\emph{cluster} reduction) behave\nvery differently, and the behaviour of the \\emph{chain reduction} is\nparticularly intriguing because of its link with graph separators and forbidden\nminors. We also show that the gap between treewidth and Tree Bisection and\nReconnect (TBR) distance can be infinitely large, and that unlike, for example,\nplanar graphs the treewidth of the display graph can be as much as linear in\nits number of vertices. On a slightly different note we show that if a display\ngraph is formed from the fusion of a phylogenetic network and a tree, rather\nthan from two trees, the treewidth of the display graph is bounded whenever the\ntree can be topologically embedded (\"displayed\") within the network. This opens\nthe door to the formulation of the display problem in Monadic Second Order\nLogic (MSOL). A number of other auxiliary results are given. We conclude with a\ndiscussion and list a number of open problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Flashes of Hidden Worlds at Colliders.   (This is a general physics level overview article about hidden sectors, and\nhow they motivate searches for long-lived particles. Intended for publication\nin Physics Today.)\nSearches for new physics at the Large Hadron Collider have so far come up\nempty, but we just might not be looking in the right place. Spectacular bursts\nof particles appearing seemingly out of nowhere could shed light on some of\nnature's most profound mysteries.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Versality of the relative Fukaya category.   Seidel introduced the notion of a Fukaya category `relative to an ample\ndivisor', explained that it is a deformation of the Fukaya category of the\naffine variety that is the complement of the divisor, and showed how the\nrelevant deformation theory is controlled by the symplectic cohomology of the\ncomplement. We elaborate on Seidel's definition of the relative Fukaya\ncategory, and give a criterion under which the deformation is versal.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Future Energy Consumption Prediction Based on Grey Forecast Model.   We use grey forecast model to predict the future energy consumption of four\nstates in the U.S, and make some improvments to the model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evaporation and scattering of momentum- and velocity-dependent dark matter in the Sun.   Dark matter with momentum- or velocity-dependent interactions with nuclei has\nshown significant promise for explaining the so-called Solar Abundance Problem,\na longstanding discrepancy between solar spectroscopy and helioseismology. The\nbest-fit models are all rather light, typically with masses in the range of 3-5\nGeV. This is exactly the mass range where dark matter evaporation from the Sun\ncan be important, but to date no detailed calculation of the evaporation of\nsuch models has been performed. Here we carry out this calculation, for the\nfirst time including arbitrary velocity- and momentum-dependent interactions,\nthermal effects, and a completely general treatment valid from the optically\nthin limit all the way through to the optically thick regime. We find that\ndepending on the dark matter mass, interaction strength and type, the mass\nbelow which evaporation is relevant can vary from 1 to 4 GeV. This has the\neffect of weakening some of the better-fitting solutions to the Solar Abundance\nProblem, but also improving a number of others. As a by-product, we also\nprovide an improved derivation of the capture rate that takes into account\nthermal and optical depth effects, allowing the standard result to be smoothly\nmatched to the well-known saturation limit.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Scalable Twin Neural Networks for Classification of Unbalanced Data.   Twin Support Vector Machines (TWSVMs) have emerged an efficient alternative\nto Support Vector Machines (SVM) for learning from imbalanced datasets. The\nTWSVM learns two non-parallel classifying hyperplanes by solving a couple of\nsmaller sized problems. However, it is unsuitable for large datasets, as it\ninvolves matrix operations. In this paper, we discuss a Twin Neural Network\n(Twin NN) architecture for learning from large unbalanced datasets. The Twin NN\nalso learns an optimal feature map, allowing for better discrimination between\nclasses. We also present an extension of this network architecture for\nmulticlass datasets. Results presented in the paper demonstrate that the Twin\nNN generalizes well and scales well on large unbalanced datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "LinNet: Probabilistic Lineup Evaluation Through Network Embedding.   Which of your team's possible lineups has the best chances against each of\nyour opponents possible lineups? In order to answer this question we develop\nLinNet. LinNet exploits the dynamics of a directed network that captures the\nperformance of lineups at their matchups. The nodes of this network represent\nthe different lineups, while an edge from node j to node i exists if lineup i\nhas outperformed lineup j. We further annotate each edge with the corresponding\nperformance margin (point margin per minute). We then utilize this structure to\nlearn a set of latent features for each node (i.e., lineup) using the node2vec\nframework. Consequently, LinNet builds a model on this latent space for the\nprobability of lineup A beating lineup B. We evaluate LinNet using NBA lineup\ndata from the five seasons between 2007-08 and 2011-12. Our results indicate\nthat our method has an out-of-sample accuracy of 69%. In comparison, utilizing\nthe adjusted plus-minus of the players within a lineup for the same prediction\nproblem provides an accuracy of 56%. More importantly, the probabilities are\nwell-calibrated as shown by the probability validation curves. One of the\nbenefits of LinNet - apart from its accuracy - is that it is generic and can be\napplied in different sports since the only input required is the lineups'\nmatchup performances, i.e., not sport-specific features are needed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Deep CNN Denoiser Prior for Image Restoration.   Model-based optimization methods and discriminative learning methods have\nbeen the two dominant strategies for solving various inverse problems in\nlow-level vision. Typically, those two kinds of methods have their respective\nmerits and drawbacks, e.g., model-based optimization methods are flexible for\nhandling different inverse problems but are usually time-consuming with\nsophisticated priors for the purpose of good performance; in the meanwhile,\ndiscriminative learning methods have fast testing speed but their application\nrange is greatly restricted by the specialized task. Recent works have revealed\nthat, with the aid of variable splitting techniques, denoiser prior can be\nplugged in as a modular part of model-based optimization methods to solve other\ninverse problems (e.g., deblurring). Such an integration induces considerable\nadvantage when the denoiser is obtained via discriminative learning. However,\nthe study of integration with fast discriminative denoiser prior is still\nlacking. To this end, this paper aims to train a set of fast and effective CNN\n(convolutional neural network) denoisers and integrate them into model-based\noptimization method to solve other inverse problems. Experimental results\ndemonstrate that the learned set of denoisers not only achieve promising\nGaussian denoising results but also can be used as prior to deliver good\nperformance for various low-level vision applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Droplet states in quantum XXZ spin systems on general graphs.   We study XXZ spin systems on general graphs. In particular, we describe the\nformation of droplet states near the bottom of the spectrum in the Ising phase\nof the model, where the Z-term dominates the XX-term. As key tools we use\nparticle number conservation of XXZ systems and symmetric products of graphs\nwith their associated adjacency matrices and Laplacians. Of particular interest\nto us are strips and multi-dimensional Euclidean lattices, for which we discuss\nthe existence of spectral gaps above the droplet regime. We also prove a\nCombes-Thomas bound which shows that the eigenstates in the droplet regime are\nexponentially small perturbations of strict (classical) droplets.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Mining Public Opinion about Economic Issues: Twitter and the U.S. Presidential Election.   Opinion polls have been the bridge between public opinion and politicians in\nelections. However, developing surveys to disclose people's feedback with\nrespect to economic issues is limited, expensive, and time-consuming. In recent\nyears, social media such as Twitter has enabled people to share their opinions\nregarding elections. Social media has provided a platform for collecting a\nlarge amount of social media data. This paper proposes a computational public\nopinion mining approach to explore the discussion of economic issues in social\nmedia during an election. Current related studies use text mining methods\nindependently for election analysis and election prediction; this research\ncombines two text mining methods: sentiment analysis and topic modeling. The\nproposed approach has effectively been deployed on millions of tweets to\nanalyze economic concerns of people during the 2012 US presidential election.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emergence of magnetic long-range order in kagome quantum antiferromagnets.   The existence of a spin-liquid ground state of the $s=1/2$ Heisenberg kagome\nantiferromagnet (KAFM) is well established. Meanwhile, also for the $s=1$\nHeisenberg KAFM evidence for the absence of magnetic long-range order (LRO) was\nfound. Magnetic LRO in Heisenberg KAFMs can emerge by increasing the spin\nquantum number $s$ to $s>1$ and for $s=1$ by an easy-plane anisotropy. In the\npresent paper we discuss the route to magnetic order in $s=1/2$ KAFMs by\nincluding an isotropic interlayer coupling (ILC) $J_\\perp$ as well as an\neasy-plane anisotropy in the kagome layers by using the coupled-cluster method\nto high orders of approximation. We consider ferro- as well as\nantiferromagnetic $J_\\perp$. To discuss the general question for the crossover\nfrom a purely two-dimensional (2D) to a quasi-2D and finally to a\nthree-dimensional system we consider the simplest model of stacked (unshifted)\nkagome layers. Although the ILC of real kagome compounds is often more\nsophisticated, such a geometry of the ILC can be relevant for barlowite. We\nfind that the spin-liquid ground state present for the strictly 2D $s=1/2$\n$XXZ$ KAFM survives a finite ILC, where the spin-liquid region shrinks\nmonotonously with increasing anisotropy. If the ILC becomes large enough (about\n15\\% of intralayer coupling for the isotropic Heisenberg case and about 4\\% for\nthe $XY$ limit) magnetic LRO can be established, where the $q=0$ symmetry is\nfavorable if $J_\\perp$ is of moderate strength. If the strength of the ILC\nfurther increases, $\\sqrt{3}\\times \\sqrt{3}$ LRO can become favorable against\n$q=0$ LRO.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Binary orbits from combined astrometric and spectroscopic data.   An efficient Bayesian technique for estimation problems in fundamental\nstellar astronomy is tested on simulated data for a binary observed both\nastrometrically and spectroscopically. Posterior distributions are computed for\nthe components' masses and for the binary's parallax. One thousand independent\nrepetitions of the simulation demonstrate that the 1- and 2-$\\!\\sigma$\ncredibility intervals for these fundamental quantities have close to the\ncorrect coverage fractions. In addition, the simulations allow the\ninvestigation of the statistical properties of a Bayesian goodness-of-fit\ncriterion and of the corresponding p-value. The criterion has closely similar\nproperties to the traditional chi^{2} test for minimum-chi^{2} solutions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Anomalous current in diffusive ferromagnetic Josephson junctions.   We demonstrate that in diffusive superconductor/ferromagnet/superconductor\n(S/F/S) junctions a finite, {\\it anomalous}, Josephson current can flow even at\nzero phase difference between the S electrodes. The conditions for the\nobservation of this effect are non-coplanar magnetization distribution and a\nbroken magnetization inversion symmetry of the superconducting current. The\nlatter symmetry is intrinsic for the widely used quasiclassical approximation\nand prevent previous works, based on this approximation, from obtaining the\nJosephson anomalous current. We show that this symmetry can be removed by\nintroducing spin-dependent boundary conditions for the quasiclassical equations\nat the superconducting/ferromagnet interfaces in diffusive systems. Using this\nrecipe we considered generic multilayer magnetic systems and determine the\nideal experimental conditions in order to maximize the anomalous current.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Performance of Network Parallel Training in Artificial Neural Networks.   Artificial Neural Networks (ANNs) have received increasing attention in\nrecent years with applications that span a wide range of disciplines including\nvital domains such as medicine, network security and autonomous transportation.\nHowever, neural network architectures are becoming increasingly complex and\nwith an increasing need to obtain real-time results from such models, it has\nbecome pivotal to use parallelization as a mechanism for speeding up network\ntraining and deployment. In this work we propose an implementation of Network\nParallel Training through Cannon's Algorithm for matrix multiplication. We show\nthat increasing the number of processes speeds up training until the point\nwhere process communication costs become prohibitive; this point varies by\nnetwork complexity. We also show through empirical efficiency calculations that\nthe speedup obtained is superlinear.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the martingale property in the rough Bergomi model.   We consider a class of fractional stochastic volatility models (including the\nso-called rough Bergomi model), where the volatility is a superlinear function\nof a fractional Gaussian process. We show that the stock price is a true\nmartingale if and only if the correlation $\\rho$ between the driving Brownian\nmotions of the stock and the volatility is nonpositive. We also show that for\neach $\\rho<0$ and $m> \\frac{1}{1-\\rho^2}$, the $m$-th moment of the stock\nprice is infinite at each positive time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Neural Machine Translation and Sequence-to-sequence Models: A Tutorial.   This tutorial introduces a new and powerful set of techniques variously\ncalled \"neural machine translation\" or \"neural sequence-to-sequence models\".\nThese techniques have been used in a number of tasks regarding the handling of\nhuman language, and can be a powerful tool in the toolbox of anyone who wants\nto model sequential data of some sort. The tutorial assumes that the reader\nknows the basics of math and programming, but does not assume any particular\nexperience with neural networks or natural language processing. It attempts to\nexplain the intuition behind the various methods covered, then delves into them\nwith enough mathematical detail to understand them concretely, and culiminates\nwith a suggestion for an implementation exercise, where readers can test that\nthey understood the content in practice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Refining Trace Abstraction using Abstract Interpretation.   The CEGAR loop in software model checking notoriously diverges when the\nabstraction refinement procedure does not derive a loop invariant. An\nabstraction refinement procedure based on an SMT solver is applied to a trace,\ni.e., a restricted form of a program (without loops). In this paper, we present\na new abstraction refinement procedure that aims at circumventing this\nrestriction whenever possible. We apply abstract interpretation to a program\nthat we derive from the given trace. If the program contains a loop, we are\nguaranteed to obtain a loop invariant. We call an SMT solver only in the case\nwhere the abstract interpretation returns an indefinite answer. That is, the\nidea is to use abstract interpretation and an SMT solver in tandem. An\nexperimental evaluation in the setting of trace abstraction indicates the\npractical potential of this idea.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effect of viscosity ratio on the self-sustained instabilities in planar immiscible jets.   Previous studies have shown that intermediate surface tension has a\ncounterintuitive destabilizing effect on 2-phase planar jets. Here, the\ntransition process in confined 2D jets of two fluids with varying viscosity\nratio is investigated using DNS. Neutral curves for persistent oscillations are\nfound by recording the norm of the velocity residuals in DNS for over 1000\nnondimensional time units, or until the signal has reached a constant level in\na logarithmic scale - either a converged steady state, or a \"statistically\nsteady\" oscillatory state. Oscillatory final states are found for all viscosity\nratios (0.1-10). For uniform viscosity (m=1), the first bifurcation is through\na surface tension-driven global instability. For low viscosity of the outer\nfluid, there is a mode competition between a steady asymmetric Coanda-type\nattachment mode and the surface tension-induced mode. At moderate surface\ntension, the Coanda-type attachment dominates and eventually triggers\ntime-dependent convective bursts. At high surface tension, the surface\ntension-dominated mode dominates. For high viscosity of the outer fluid,\npersistent oscillations appear due to a strong convective instability. Finally,\nthe m=1 jet remains unstable far from the inlet when the shear profile is\nnearly constant. Comparing this to a parallel Couette flow (without inflection\npoints), we show that in both flows, a hidden interfacial mode brought out by\nsurface tension becomes temporally and absolutely unstable in an intermediate\nWeber and Reynolds regime. An energy analysis of the Couette setup shows that\nsurface tension, although dissipative, induces a velocity field near the\ninterface which extracts energy from the flow through a viscous mechanism. This\nstudy highlights the rich dynamics of immiscible planar uniform-density jets,\nwhere several self-sustained and convective mechanisms compete depending on the\nexact parameters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Shape analysis on Lie groups and homogeneous spaces.   In this paper we are concerned with the approach to shape analysis based on\nthe so called Square Root Velocity Transform (SRVT). We propose a\ngeneralisation of the SRVT from Euclidean spaces to shape spaces of curves on\nLie groups and on homogeneous manifolds. The main idea behind our approach is\nto exploit the geometry of the natural Lie group actions on these spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Highrisk Prediction from Electronic Medical Records via Deep Attention Networks.   Predicting highrisk vascular diseases is a significant issue in the medical\ndomain. Most predicting methods predict the prognosis of patients from\npathological and radiological measurements, which are expensive and require\nmuch time to be analyzed. Here we propose deep attention models that predict\nthe onset of the high risky vascular disease from symbolic medical histories\nsequence of hypertension patients such as ICD-10 and pharmacy codes only,\nMedical History-based Prediction using Attention Network (MeHPAN). We\ndemonstrate two types of attention models based on 1) bidirectional gated\nrecurrent unit (R-MeHPAN) and 2) 1D convolutional multilayer model (C-MeHPAN).\nTwo MeHPAN models are evaluated on approximately 50,000 hypertension patients\nwith respect to precision, recall, f1-measure and area under the curve (AUC).\nExperimental results show that our MeHPAN methods outperform standard\nclassification models. Comparing two MeHPANs, R-MeHPAN provides more better\ndiscriminative capability with respect to all metrics while C-MeHPAN presents\nmuch shorter training time with competitive accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inverse mean curvature flow in quaternionic hyperbolic space.   In this paper we complete the study started in [Pi2] of evolution by inverse\nmean curvature flow of star-shaped hypersurface in non-compact rank one\nsymmetric spaces. We consider the evolution by inverse mean curvature flow of a\nclosed, mean convex and star-shaped hypersurface in the quaternionic hyperbolic\nspace. We prove that the flow is defined for any positive time, the evolving\nhypersurface stays star-shaped and mean convex. Moreover the induced metric\nconverges, after rescaling, to a conformal multiple of the standard\nsub-Riemannian metric on the sphere defined on a codimension 3 distribution.\nFinally we show that there exists a family of examples such that the qc-scalar\ncurvature of this sub-Riemannian limit is not constant.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Stability criteria for the 2D $α$-Euler equations.   We derive analogues of the classical Rayleigh, Fjortoft and Arnold stability\nand instability theorems in the context of the 2D $\\alpha$-Euler equations.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Guessing Attacks on Distributed-Storage Systems.   The secrecy of a distributed-storage system for passwords is studied. The\nencoder, Alice, observes a length-n password and describes it using two hints,\nwhich she stores in different locations. The legitimate receiver, Bob, observes\nboth hints. In one scenario the requirement is that the expected number of\nguesses it takes Bob to guess the password approach one as n tends to infinity,\nand in the other that the expected size of the shortest list that Bob must form\nto guarantee that it contain the password approach one. The eavesdropper, Eve,\nsees only one of the hints. Assuming that Alice cannot control which hints Eve\nobserves, the largest normalized (by n) exponent that can be guaranteed for the\nexpected number of guesses it takes Eve to guess the password is characterized\nfor each scenario. Key to the proof are new results on Arikan's guessing and\nBunte and Lapidoth's task-encoding problem; in particular, the paper\nestablishes a close relation between the two problems. A rate-distortion\nversion of the model is also discussed, as is a generalization that allows for\nAlice to produce {\\delta} (not necessarily two) hints, for Bob to observe {\\nu}\n(not necessarily two) of the hints, and for Eve to observe {\\eta} (not\nnecessarily one) of the hints. The generalized model is robust against {\\delta}\n- {\\nu} disk failures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Regrasping by Fixtureless Fixturing.   This paper presents a fixturing strategy for regrasping that does not require\na physical fixture. To regrasp an object in a gripper, a robot pushes the\nobject against external contact/s in the environment such that the external\ncontact keeps the object stationary while the fingers slide over the object. We\ncall this manipulation technique fixtureless fixturing. Exploiting the\nmechanics of pushing, we characterize a convex polyhedral set of pushes that\nresults in fixtureless fixturing. These pushes are robust against uncertainty\nin the object inertia, grasping force, and the friction at the contacts. We\npropose a sampling-based planner that uses the sets of robust pushes to rapidly\nbuild a tree of reachable grasps. A path in this tree is a pushing strategy,\npossibly involving pushes from different sides, to regrasp the object. We\ndemonstrate the experimental validity and robustness of the proposed\nmanipulation technique with different regrasp examples on a manipulation\nplatform. Such a fast and flexible regrasp planner facilitates versatile and\nflexible automation solutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The infrared to X-ray correlation spectra of unobscured type 1 active galactic nuclei.   We use new X-ray data obtained with the Nuclear Spectroscopic Telescope Array\n(NuSTAR), near-infrared (NIR) fluxes, and mid-infrared (MIR) spectra of a\nsample of 24 unobscured type 1 active galactic nuclei (AGN) to study the\ncorrelation between various hard X-ray bands between 3 and 80 keV and the\ninfrared (IR) emission. The IR to X-ray correlation spectrum (IRXCS) shows a\nmaximum at ~15-20 micron, coincident with the peak of the AGN contribution to\nthe MIR spectra of the majority of the sample. There is also a NIR correlation\npeak at ~2 micron, which we associate with the NIR bump observed in some type 1\nAGN at ~1-5 micron and is likely produced by nuclear hot dust emission. The\nIRXCS shows practically the same behaviour in all the X-ray bands considered,\nindicating a common origin for all of them. We finally evaluated correlations\nbetween the X-ray luminosities and various MIR emission lines. All the lines\nshow a good correlation with the hard X-rays (rho>0.7), but we do not find the\nexpected correlation between their ionization potentials and the strength of\nthe IRXCS.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Probing the accretion disc structure by the twin kHz QPOs and spins of neutron stars in LMXBs.   We analyze the relation between the emission radii of twin kilohertz\nquasi-periodic oscillations (kHz QPOs) and the co-rotation radii of the 12\nneutron star low mass X-ray binaries (NS-LMXBs) which are simultaneously\ndetected with the twin kHz QPOs and NS spins. We find that the average\nco-rotation radius of these sources is r_co about 32 km, and all the emission\npositions of twin kHz QPOs lie inside the corotation radii, indicating that the\ntwin kHz QPOs are formed in the spin-up process. It is noticed that the upper\nfrequency of twin kHz QPOs is higher than NS spin frequency by > 10%, which may\naccount for a critical velocity difference between the Keplerian motion of\naccretion matter and NS spin that is corresponding to the production of twin\nkHz QPOs. In addition, we also find that about 83% of twin kHz QPOs cluster\naround the radius range of 15-20 km, which may be affected by the hard surface\nor the local strong magnetic field of NS. As a special case, SAX J1808.4-3658\nshows the larger emission radii of twin kHz QPOs of r about 21-24 km, which may\nbe due to its low accretion rate or small measured NS mass (< 1.4 solar mass).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the n-th row of the graded Betti table of an n-dimensional toric variety.   We prove an explicit formula for the first non-zero entry in the n-th row of\nthe graded Betti table of an n-dimensional projective toric variety associated\nto a normal polytope with at least one interior lattice point. This applies to\nVeronese embeddings of projective space where we prove a special case of a\nconjecture of Ein and Lazarsfeld. We also prove an explicit formula for the\nentire n-th row when the interior of the polytope is one-dimensional. All\nresults are valid over an arbitrary field k.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Privacy-Aware Guessing Efficiency.   We investigate the problem of guessing a discrete random variable $Y$ under a\nprivacy constraint dictated by another correlated discrete random variable $X$,\nwhere both guessing efficiency and privacy are assessed in terms of the\nprobability of correct guessing. We define $h(P_{XY}, \\epsilon)$ as the maximum\nprobability of correctly guessing $Y$ given an auxiliary random variable $Z$,\nwhere the maximization is taken over all $P_{Z|Y}$ ensuring that the\nprobability of correctly guessing $X$ given $Z$ does not exceed $\\epsilon$. We\nshow that the map $\\epsilon\\mapsto h(P_{XY}, \\epsilon)$ is strictly increasing,\nconcave, and piecewise linear, which allows us to derive a closed form\nexpression for $h(P_{XY}, \\epsilon)$ when $X$ and $Y$ are connected via a\nbinary-input binary-output channel. For $(X^n, Y^n)$ being pairs of independent\nand identically distributed binary random vectors, we similarly define\n$\\underline{h}_n(P_{X^nY^n}, \\epsilon)$ under the assumption that $Z^n$ is also\na binary vector. Then we obtain a closed form expression for\n$\\underline{h}_n(P_{X^nY^n}, \\epsilon)$ for sufficiently large, but nontrivial\nvalues of $\\epsilon$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Calculation of Effective Interaction Potential During Positron Channeling in Ionic Crystals.   An analytical expression is received for the effective interaction potential\nof a fast charged particle with the ionic crystal CsCl near the direction of\n<100> axis as a function of the temperature of the medium. By numerical\nanalysis it is shown that the effective potential of axial channeling of\npositrons along the axis <100> of negatively charged ions practically does not\ndepend on temperature of the media",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "End-to-end Recurrent Neural Network Models for Vietnamese Named Entity Recognition: Word-level vs. Character-level.   This paper demonstrates end-to-end neural network architectures for\nVietnamese named entity recognition. Our best model is a combination of\nbidirectional Long Short-Term Memory (Bi-LSTM), Convolutional Neural Network\n(CNN), Conditional Random Field (CRF), using pre-trained word embeddings as\ninput, which achieves an F1 score of 88.59% on a standard test set. Our system\nis able to achieve a comparable performance to the first-rank system of the\nVLSP campaign without using any syntactic or hand-crafted features. We also\ngive an extensive empirical study on using common deep learning models for\nVietnamese NER, at both word and character level.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "MSO+nabla is undecidable.   This paper is about an extension of monadic second-order logic over infinite\ntrees, which adds a quantifier that says \"the set of branches \\pi which satisfy\na formula \\phi(\\pi) has probability one\". This logic was introduced by\nMichalewski and Mio; we call it MSO+nabla following Shelah and Lehmann. The\nlogic MSO+nabla subsumes many qualitative probabilistic formalisms, including\nqualitative probabilistic CTL, probabilistic LTL, or parity tree automata with\nprobabilistic acceptance conditions. We consider the decision problem: decide\nif a sentence of MSO+nabla is true in the infinite binary tree? For sentences\nfrom the weak variant of this logic (set quantifiers range only over finite\nsets) the problem was known to be decidable, but the question for the full\nlogic remained open. In this paper we show that the problem for the full logic\nMSO+nabla is undecidable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strongly Hierarchical Factorization Machines and ANOVA Kernel Regression.   High-order parametric models that include terms for feature interactions are\napplied to various data mining tasks, where ground truth depends on\ninteractions of features. However, with sparse data, the high- dimensional\nparameters for feature interactions often face three issues: expensive\ncomputation, difficulty in parameter estimation and lack of structure. Previous\nwork has proposed approaches which can partially re- solve the three issues. In\nparticular, models with factorized parameters (e.g. Factorization Machines) and\nsparse learning algorithms (e.g. FTRL-Proximal) can tackle the first two issues\nbut fail to address the third. Regarding to unstructured parameters,\nconstraints or complicated regularization terms are applied such that\nhierarchical structures can be imposed. However, these methods make the\noptimization problem more challenging. In this work, we propose Strongly\nHierarchical Factorization Machines and ANOVA kernel regression where all the\nthree issues can be addressed without making the optimization problem more\ndifficult. Experimental results show the proposed models significantly\noutperform the state-of-the-art in two data mining tasks: cold-start user\nresponse time prediction and stock volatility prediction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantification of market efficiency based on informational-entropy.   Since the 1960s, the question whether markets are efficient or not is\ncontroversially discussed. One reason for the difficulty to overcome the\ncontroversy is the lack of a universal, but also precise, quantitative\ndefinition of efficiency that is able to graduate between different states of\nefficiency. The main purpose of this article is to fill this gap by developing\na measure for the efficiency of markets that fulfill all the stated\nrequirements. It is shown that the new definition of efficiency, based on\ninformational-entropy, is equivalent to the two most used definitions of\nefficiency from Fama and Jensen. The new measure therefore enables steps to\nsettle the dispute over the state of efficiency in markets. Moreover, it is\nshown that inefficiency in a market can either arise from the possibility to\nuse information to predict an event with higher than chance level, or can\nemerge from wrong pricing/ quotes that do not reflect the right probabilities\nof possible events. Finally, the calculation of efficiency is demonstrated on a\nsimple game (of coin tossing), to show how one could exactly quantify the\nefficiency in any market-like system, if all probabilities are known.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards parallelizable sampling-based Nonlinear Model Predictive Control.   This paper proposes a new sampling-based nonlinear model predictive control\n(MPC) algorithm, with a bound on complexity quadratic in the prediction horizon\nN and linear in the number of samples. The idea of the proposed algorithm is to\nuse the sequence of predicted inputs from the previous time step as a warm\nstart, and to iteratively update this sequence by changing its elements one by\none, starting from the last predicted input and ending with the first predicted\ninput. This strategy, which resembles the dynamic programming principle, allows\nfor parallelization up to a certain level and yields a suboptimal nonlinear MPC\nalgorithm with guaranteed recursive feasibility, stability and improved cost\nfunction at every iteration, which is suitable for real-time implementation.\nThe complexity of the algorithm per each time step in the prediction horizon\ndepends only on the horizon, the number of samples and parallel threads, and it\nis independent of the measured system state. Comparisons with the fmincon\nnonlinear optimization solver on benchmark examples indicate that as the\nsimulation time progresses, the proposed algorithm converges rapidly to the\n\"optimal\" solution, even when using a small number of samples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Error Analysis of the Stochastic Linear Feedback Particle Filter.   This paper is concerned with the convergence and long-term stability analysis\nof the feedback particle filter (FPF) algorithm. The FPF is an interacting\nsystem of $N$ particles where the interaction is designed such that the\nempirical distribution of the particles approximates the posterior\ndistribution. It is known that in the mean-field limit ($N=\\infty$), the\ndistribution of the particles is equal to the posterior distribution. However\nlittle is known about the convergence to the mean-field limit. In this paper,\nwe consider the FPF algorithm for the linear Gaussian setting. In this setting,\nthe algorithm is similar to the ensemble Kalman-Bucy filter algorithm. Although\nthese algorithms have been numerically evaluated and widely used in\napplications, their convergence and long-term stability analysis remains an\nactive area of research. In this paper, we show that, (i) the mean-field limit\nis well-defined with a unique strong solution; (ii) the mean-field process is\nstable with respect to the initial condition; (iii) we provide conditions such\nthat the finite-$N$ system is long term stable and we obtain some mean-squared\nerror estimates that are uniform in time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Rates for Kernel-Based Expectile Regression.   Conditional expectiles are becoming an increasingly important tool in finance\nas well as in other areas of applications. We analyse a support vector machine\ntype approach for estimating conditional expectiles and establish learning\nrates that are minimax optimal modulo a logarithmic factor if Gaussian RBF\nkernels are used and the desired expectile is smooth in a Besov sense. As a\nspecial case, our learning rates improve the best known rates for kernel-based\nleast squares regression in this scenario. Key ingredients of our statistical\nanalysis are a general calibration inequality for the asymmetric least squares\nloss, a corresponding variance bound as well as an improved entropy number\nbound for Gaussian RBF kernels.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Blind Source Separation Using Mixtures of Alpha-Stable Distributions.   We propose a new blind source separation algorithm based on mixtures of\nalpha-stable distributions. Complex symmetric alpha-stable distributions have\nbeen recently showed to better model audio signals in the time-frequency domain\nthan classical Gaussian distributions thanks to their larger dynamic range.\nHowever, inference of these models is notoriously hard to perform because their\nprobability density functions do not have a closed-form expression in general.\nHere, we introduce a novel method for estimating mixture of alpha-stable\ndistributions based on characteristic function matching. We apply this to the\nblind estimation of binary masks in individual frequency bands from\nmultichannel convolutive audio mixes. We show that the proposed method yields\nbetter separation performance than Gaussian-based binary-masking methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Semi-Supervised Learning for Detecting Human Trafficking.   Human trafficking is one of the most atrocious crimes and among the\nchallenging problems facing law enforcement which demands attention of global\nmagnitude. In this study, we leverage textual data from the website \"Backpage\"-\nused for classified advertisement- to discern potential patterns of human\ntrafficking activities which manifest online and identify advertisements of\nhigh interest to law enforcement. Due to the lack of ground truth, we rely on a\nhuman analyst from law enforcement, for hand-labeling a small portion of the\ncrawled data. We extend the existing Laplacian SVM and present S3VM-R, by\nadding a regularization term to exploit exogenous information embedded in our\nfeature space in favor of the task at hand. We train the proposed method using\nlabeled and unlabeled data and evaluate it on a fraction of the unlabeled data,\nherein referred to as unseen data, with our expert's further verification.\nResults from comparisons between our method and other semi-supervised and\nsupervised approaches on the labeled data demonstrate that our learner is\neffective in identifying advertisements of high interest to law enforcement",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bounds on layer potentials with rough inputs for higher order elliptic equations.   In this paper we establish square-function estimates on the double and single\nlayer potentials with rough inputs for divergence form elliptic operators, of\narbitrary even order 2m, with variable t-independent coefficients in the upper\nhalf-space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Seven Lessons from Manyfield Inflation in Random Potentials.   We study inflation in models with many interacting fields subject to randomly\ngenerated scalar potentials. We use methods from non-equilibrium random matrix\ntheory to construct the potentials and an adaption of the 'transport method' to\nevolve the two-point correlators during inflation. This construction allows,\nfor the first time, for an explicit study of models with up to 100 interacting\nfields supporting a period of 'approximately saddle-point' inflation. We\ndetermine the statistical predictions for observables by generating over 30,000\nmodels with 2-100 fields supporting at least 60 efolds of inflation. These\nstudies lead us to seven lessons: i) Manyfield inflation is not single-field\ninflation, ii) The larger the number of fields, the simpler and sharper the\npredictions, iii) Planck compatibility is not rare, but future experiments may\nrule out this class of models, iv) The smoother the potentials, the sharper the\npredictions, v) Hyperparameters can transition from stiff to sloppy, vi)\nDespite tachyons, isocurvature can decay, vii) Eigenvalue repulsion drives the\npredictions. We conclude that many of the 'generic predictions' of single-field\ninflation can be emergent features of complex inflation models.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Long term availability of raw experimental data in experimental fracture mechanics.   Experimental data availability is a cornerstone for reproducibility in\nexperimental fracture mechanics, which is crucial to the scientific method.\nThis short communication focuses on the accessibility and long term\navailability of raw experimental data. The corresponding authors of the eleven\nmost cited papers, related to experimental fracture mechanics, for every year\nfrom 2000 up to 2016, were kindly asked about the availability of the raw\nexperimental data associated with each publication. For the 187 e-mails sent:\n22.46% resulted in outdated contact information, 57.75% of the authors did\nreceived our request and did not reply, and 19.79 replied to our request. The\navailability of data is generally low with only $11$ available data sets\n(5.9%). The authors identified two main issues for the lacking availability of\nraw experimental data. First, the ability to retrieve data is strongly attached\nto the the possibility to contact the corresponding author. This study suggests\nthat institutional e-mail addresses are insufficient means for obtaining\nexperimental data sets. Second, lack of experimental data is also due that\nsubmission and publication does not require to make the raw experimental data\navailable. The following solutions are proposed: (1) Requirement of unique\nidentifiers, like ORCID or ResearcherID, to detach the author(s) from their\ninstitutional e-mail address, (2) Provide DOIs, like Zenodo or Dataverse, to\nmake raw experimental data citable, and (3) grant providing organizations\nshould ensure that experimental data by public funded projects is available to\nthe public.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The comprehension construction.   In this paper we construct an analogue of Lurie's \"unstraightening\"\nconstruction that we refer to as the \"comprehension construction\". Its input is\na cocartesian fibration $p \\colon E \\to B$ between $\\infty$-categories together\nwith a third $\\infty$-category $A$. The comprehension construction then defines\na map from the quasi-category of functors from $A$ to $B$ to the large\nquasi-category of cocartesian fibrations over $A$ that acts on $f \\colon A \\to\nB$ by forming the pullback of $p$ along $f$. To illustrate the versatility of\nthis construction, we define the covariant and contravariant Yoneda embeddings\nas special cases of the comprehension functor. We then prove that the hom-wise\naction of the comprehension functor coincides with an \"external action\" of the\nhom-spaces of $B$ on the fibres of $p$ and use this to prove that the Yoneda\nembedding is fully faithful, providing an explicit equivalence between a\nquasi-category and the homotopy coherent nerve of a Kan-complex enriched\ncategory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Calibrated Filtered Reduced Order Modeling.   We propose a calibrated filtered reduced order model (CF-ROM) framework for\nthe numerical simulation of general nonlinear PDEs that are amenable to reduced\norder modeling. The novel CF-ROM framework consists of two steps: (i) In the\nfirst step, we use explicit ROM spatial filtering of the nonlinear PDE to\nconstruct a filtered ROM. This filtered ROM is low-dimensional, but is not\nclosed (because of the nonlinearity in the given PDE). (ii) In the second step,\nwe use a calibration procedure to close the filtered ROM, i.e., to model the\ninteraction between the resolved and unresolved modes. To this end, we use a\nlinear or quadratic ansatz to model this interaction and close the filtered\nROM. To find the new coefficients in the closed filtered ROM, we solve an\noptimization problem that minimizes the difference between the full order model\ndata and our ansatz. Although we use a fluid dynamics setting to illustrate how\nto construct and use the CF-ROM framework, we emphasize that it is built on\ngeneral ideas of spatial filtering and optimization and is independent of\n(restrictive) phenomenological arguments. Thus, the CF-ROM framework can be\napplied to a wide variety of PDEs.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "A Fourier-Chebyshev Spectral Method for Cavitation Computation in Nonlinear Elasticity.   A Fourier-Chebyshev spectral method is proposed in this paper for solving the\ncavitation problem in nonlinear elasticity. The interpolation error for the\ncavitation solution is analyzed, the elastic energy error estimate for the\ndiscrete cavitation solution is obtained, and the convergence of the method is\nproved. An algorithm combined a gradient type method with a damped quasi-Newton\nmethod is applied to solve the discretized nonlinear equilibrium equations.\nNumerical experiments show that the Fourier-Chebyshev spectral method is\nefficient and capable of producing accurate numerical cavitation solutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fabrication tolerant chalcogenide mid-infrared multimode interference coupler design with application for Bracewell nulling interferometry.   Understanding exoplanet formation and finding potentially habitable\nexoplanets is vital to an enhanced understanding of the universe. The use of\nnulling interferometry to strongly attenuate the central starlight provides the\nopportunity to see objects closer to the star than ever before. Given that\nexoplanets are usually warm, the 4 microns Mid-Infrared region is advantageous\nfor such observations. The key performance parameters for a nulling\ninterferometer are the extinction ratio it can attain and how well that is\nmaintained across the operational bandwidth. Both parameters depend on the\ndesign and fabrication accuracy of the subcomponents and their wavelength\ndependence. Via detailed simulation it is shown in this paper that a planar\nchalcogenide photonic chip, consisting of three highly fabrication tolerant\nmultimode interference couplers, can exceed an extinction ratio of 60 dB in\ndouble nulling operation and up to 40 dB for a single nulling operation across\na wavelength window of 3.9 to 4.2 microns. This provides a beam combiner with\nsufficient performance, in theory, to image exoplanets.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A model for Faraday pilot waves over variable topography.   Couder and Fort discovered that droplets walking on a vibrating bath possess\ncertain features previously thought to be exclusive to quantum systems. These\nmillimetric droplets synchronize with their Faraday wavefield, creating a\nmacroscopic pilot-wave system. In this paper we exploit the fact that the waves\ngenerated are nearly monochromatic and propose a hydrodynamic model capable of\nquantitatively capturing the interaction between bouncing drops and a variable\ntopography. We show that our reduced model is able to reproduce some important\nexperiments involving the drop-topography interaction, such as non-specular\nreflection and single-slit diffraction.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Distributed Learning for Cooperative Inference.   We study the problem of cooperative inference where a group of agents\ninteract over a network and seek to estimate a joint parameter that best\nexplains a set of observations. Agents do not know the network topology or the\nobservations of other agents. We explore a variational interpretation of the\nBayesian posterior density, and its relation to the stochastic mirror descent\nalgorithm, to propose a new distributed learning algorithm. We show that, under\nappropriate assumptions, the beliefs generated by the proposed algorithm\nconcentrate around the true parameter exponentially fast. We provide explicit\nnon-asymptotic bounds for the convergence rate. Moreover, we develop explicit\nand computationally efficient algorithms for observation models belonging to\nexponential families.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Assortative Mixing Equilibria in Social Network Games.   It is known that individuals in social networks tend to exhibit homophily\n(a.k.a. assortative mixing) in their social ties, which implies that they\nprefer bonding with others of their own kind. But what are the reasons for this\nphenomenon? Is it that such relations are more convenient and easier to\nmaintain? Or are there also some more tangible benefits to be gained from this\ncollective behaviour?\nThe current work takes a game-theoretic perspective on this phenomenon, and\nstudies the conditions under which different assortative mixing strategies lead\nto equilibrium in an evolving social network. We focus on a biased preferential\nattachment model where the strategy of each group (e.g., political or social\nminority) determines the level of bias of its members toward other group\nmembers and non-members. Our first result is that if the utility function that\nthe group attempts to maximize is the degree centrality of the group,\ninterpreted as the sum of degrees of the group members in the network, then the\nonly strategy achieving Nash equilibrium is a perfect homophily, which implies\nthat cooperation with other groups is harmful to this utility function. A\nsecond, and perhaps more surprising, result is that if a reward for inter-group\ncooperation is added to the utility function (e.g., externally enforced by an\nauthority as a regulation), then there are only two possible equilibria,\nnamely, perfect homophily or perfect heterophily, and it is possible to\ncharacterize their feasibility spaces. Interestingly, these results hold\nregardless of the minority-majority ratio in the population.\nWe believe that these results, as well as the game-theoretic perspective\npresented herein, may contribute to a better understanding of the forces that\nshape the groups and communities of our society.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Rethinking Reprojection: Closing the Loop for Pose-aware ShapeReconstruction from a Single Image.   An emerging problem in computer vision is the reconstruction of 3D shape and\npose of an object from a single image. Hitherto, the problem has been addressed\nthrough the application of canonical deep learning methods to regress from the\nimage directly to the 3D shape and pose labels. These approaches, however, are\nproblematic from two perspectives. First, they are minimizing the error between\n3D shapes and pose labels - with little thought about the nature of this label\nerror when reprojecting the shape back onto the image. Second, they rely on the\nonerous and ill-posed task of hand labeling natural images with respect to 3D\nshape and pose. In this paper we define the new task of pose-aware shape\nreconstruction from a single image, and we advocate that cheaper 2D annotations\nof objects silhouettes in natural images can be utilized. We design\narchitectures of pose-aware shape reconstruction which re-project the predicted\nshape back on to the image using the predicted pose. Our evaluation on several\nobject categories demonstrates the superiority of our method for predicting\npose-aware 3D shapes from natural images.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Proceedings of the IJCAI 2017 Workshop on Learning in the Presence of Class Imbalance and Concept Drift (LPCICD'17).   With the wide application of machine learning algorithms to the real world,\nclass imbalance and concept drift have become crucial learning issues. Class\nimbalance happens when the data categories are not equally represented, i.e.,\nat least one category is minority compared to other categories. It can cause\nlearning bias towards the majority class and poor generalization. Concept drift\nis a change in the underlying distribution of the problem, and is a significant\nissue specially when learning from data streams. It requires learners to be\nadaptive to dynamic changes.\nClass imbalance and concept drift can significantly hinder predictive\nperformance, and the problem becomes particularly challenging when they occur\nsimultaneously. This challenge arises from the fact that one problem can affect\nthe treatment of the other. For example, drift detection algorithms based on\nthe traditional classification error may be sensitive to the imbalanced degree\nand become less effective; and class imbalance techniques need to be adaptive\nto changing imbalance rates, otherwise the class receiving the preferential\ntreatment may not be the correct minority class at the current moment.\nTherefore, the mutual effect of class imbalance and concept drift should be\nconsidered during algorithm design.\nThe aim of this workshop is to bring together researchers from the areas of\nclass imbalance learning and concept drift in order to encourage discussions\nand new collaborations on solving the combined issue of class imbalance and\nconcept drift. It provides a forum for international researchers and\npractitioners to share and discuss their original work on addressing new\nchallenges and research issues in class imbalance learning, concept drift, and\nthe combined issues of class imbalance and concept drift. The proceedings\ninclude 8 papers on these topics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "WebPol: Fine-grained Information Flow Policies for Web Browsers.   In the standard web browser programming model, third-party scripts included\nin an application execute with the same privilege as the application's own\ncode. This leaves the application's confidential data vulnerable to theft and\nleakage by malicious code and inadvertent bugs in the third-party scripts.\nSecurity mechanisms in modern browsers (the same-origin policy, cross-origin\nresource sharing and content security policies) are too coarse to suit this\nprogramming model. All these mechanisms (and their extensions) describe whether\nor not a script can access certain data, whereas the meaningful requirement is\nto allow untrusted scripts access to confidential data that they need and to\nprevent the scripts from leaking data on the side. Motivated by this gap, we\npropose WebPol, a policy mechanism that allows a website developer to include\nfine-grained policies on confidential application data in the familiar syntax\nof the JavaScript programming language. The policies can be associated with any\nwebpage element, and specify what aspects of the element can be accessed by\nwhich third-party domains. A script can access data that the policy allows it\nto, but it cannot pass the data (or data derived from it) to other scripts or\nremote hosts in contravention of the policy. To specify the policies, we expose\na small set of new native APIs in JavaScript. Our policies can be enforced\nusing any of the numerous existing proposals for information flow tracking in\nweb browsers. We have integrated our policies into one such proposal that we\nuse to evaluate performance overheads and to test our examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Precision matrix expansion - efficient use of numerical simulations in estimating errors on cosmological parameters.   Computing the inverse covariance matrix (or precision matrix) of large data\nvectors is crucial in weak lensing (and multi-probe) analyses of the large\nscale structure of the universe. Analytically computed covariances are\nnoise-free and hence straightforward to invert, however the model\napproximations might be insufficient for the statistical precision of future\ncosmological data. Estimating covariances from numerical simulations improves\non these approximations, but the sample covariance estimator is inherently\nnoisy, which introduces uncertainties in the error bars on cosmological\nparameters and also additional scatter in their best fit values. For future\nsurveys, reducing both effects to an acceptable level requires an unfeasibly\nlarge number of simulations.\nIn this paper we describe a way to expand the true precision matrix around a\ncovariance model and show how to estimate the leading order terms of this\nexpansion from simulations. This is especially powerful if the covariance\nmatrix is the sum of two contributions, $\\smash{\\mathbf{C} =\n\\mathbf{A}+\\mathbf{B}}$, where $\\smash{\\mathbf{A}}$ is well understood\nanalytically and can be turned off in simulations (e.g. shape-noise for cosmic\nshear) to yield a direct estimate of $\\smash{\\mathbf{B}}$. We test our method\nin mock experiments resembling tomographic weak lensing data vectors from the\nDark Energy Survey (DES) and the Large Synoptic Survey Telecope (LSST). For DES\nwe find that $400$ N-body simulations are sufficient to achive negligible\nstatistical uncertainties on parameter constraints. For LSST this is achieved\nwith $2400$ simulations. The standard covariance estimator would require\n>$10^5$ simulations to reach a similar precision. We extend our analysis to a\nDES multi-probe case finding a similar performance.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Perception-based energy functions in seam-cutting.   Image stitching is challenging in consumer-level photography, due to\nalignment difficulties in unconstrained shooting environment. Recent studies\nshow that seam-cutting approaches can effectively relieve artifacts generated\nby local misalignment. Normally, seam-cutting is described in terms of energy\nminimization, however, few of existing methods consider human perception in\ntheir energy functions, which sometimes causes that a seam with minimum energy\nis not most invisible in the overlapping region. In this paper, we propose a\nnovel perception-based energy function in the seam-cutting framework, which\nconsiders the nonlinearity and the nonuniformity of human perception in energy\nminimization. Our perception-based approach adopts a sigmoid metric to\ncharacterize the perception of color discrimination, and a saliency weight to\nsimulate that human eyes incline to pay more attention to salient objects. In\naddition, our seam-cutting composition can be easily implemented into other\nstitching pipelines. Experiments show that our method outperforms the\nseam-cutting method of the normal energy function, and a user study\ndemonstrates that our composed results are more consistent with human\nperception.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interpretations of family size distributions: The Datura example.   Young asteroid families are unique sources of information about fragmentation\nphysics and the structure of their parent bodies, since their physical\nproperties have not changed much since their birth. Families have different\nproperties such as age, size, taxonomy, collision severity and others, and\nunderstanding the effect of those properties on our observations of the\nsize-frequency distribution (SFD) of family fragments can give us important\ninsights into the hypervelocity collision processes at scales we cannot achieve\nin our laboratories. Here we take as an example the very young Datura family,\nwith a small 8-km parent body, and compare its size distribution to other\nfamilies, with both large and small parent bodies, and created by both\ncatastrophic and cratering formation events. We conclude that most likely\nexplanation for the shallower size distribution compared to larger families is\na more pronounced observational bias because of its small size. Its size\ndistribution is perfectly normal when its parent body size is taken into\naccount. We also discuss some other possibilities. In addition, we study\nanother common feature: an offset or \"bump\" in the distribution occurring for a\nfew of the larger elements. We hypothesize that it can be explained by a newly\ndescribed regime of cratering, \"spall cratering\", which controls the majority\nof impact craters on the surface of small asteroids like Datura.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Semi-classical limit of the Levy-Lieb functional in Density Functional Theory.   In a recent work, Bindini and De Pascale have introduced a regularization of\n$N$-particle symmetric probabilities which preserves their one-particle\nmarginals. In this short note, we extend their construction to mixed quantum\nfermionic states. This enables us to prove the convergence of the Levy-Lieb\nfunctional in Density Functional Theory , to the corresponding multi-marginal\noptimal transport in the semi-classical limit. Our result holds for mixed\nstates of any particle number $N$, with or without spin.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the accuracy and usefulness of analytic energy models for contemporary multicore processors.   This paper presents refinements to the execution-cache-memory performance\nmodel and a previously published power model for multicore processors. The\ncombination of both enables a very accurate prediction of performance and\nenergy consumption of contemporary multicore processors as a function of\nrelevant parameters such as number of active cores as well as core and Uncore\nfrequencies. Model validation is performed on the Sandy Bridge-EP and\nBroadwell-EP microarchitectures. Production-related variations in chip quality\nare demonstrated through a statistical analysis of the fit parameters obtained\non one hundred Broadwell-EP CPUs of the same model. Insights from the models\nare used to explain the performance- and energy-related behavior of the\nprocessors for scalable as well as saturating (i.e., memory-bound) codes. In\nthe process we demonstrate the models' capability to identify optimal operating\npoints with respect to highest performance, lowest energy-to-solution, and\nlowest energy-delay product and identify a set of best practices for\nenergy-efficient execution.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Nonlocal Nonlinear Schrödinger Equations and Their Soliton Solutions.   We study standard and nonlocal nonlinear Schrödinger (NLS) equations\nobtained from the coupled NLS system of equations (Ablowitz-Kaup-Newell-Segur\n(AKNS) equations) by using standard and nonlocal reductions respectively. By\nusing the Hirota bilinear method we first find soliton solutions of the coupled\nNLS system of equations then using the reduction formulas we find the soliton\nsolutions of the standard and nonlocal NLS equations. We give examples for\nparticular values of the parameters and plot the function $|q(t,x)|^2$ for the\nstandard and nonlocal NLS equations.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Modified mean curvature flow of entire locally Lipschitz radial graphs in hyperbolic space.   In a previous joint work of Xiao and the second author, the modified mean\ncurvature flow (MMCF) in hyperbolic space $\\mathbb{H}^{n+1}$: $$\\frac{\\partial\n\\mathbf{F}}{\\partial t} = (H-\\sigma)\\,\\vnu\\,,\\quad \\quad \\sigma\\in (-n,n)$$ was\nfirst introduced and the flow starting from an entire Lipschitz continuous\nradial graph with uniform local ball condition on the asymptotic boundary was\nshown to exist for all time and converge to a complete hypersurface of constant\nmean curvature with prescribed asymptotic boundary at infinity. In this paper,\nwe remove the uniform local ball condition on the asymptotic boundary of the\ninitial hypersurface, and prove that the MMCF starting from an entire locally\nLipschitz continuous radial graph exists and stays radially graphic for all\ntime.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Learning Neural Models for End-to-End Clustering.   We propose a novel end-to-end neural network architecture that, once trained,\ndirectly outputs a probabilistic clustering of a batch of input examples in one\npass. It estimates a distribution over the number of clusters $k$, and for each\n$1 \\leq k \\leq k_\\mathrm{max}$, a distribution over the individual cluster\nassignment for each data point. The network is trained in advance in a\nsupervised fashion on separate data to learn grouping by any perceptual\nsimilarity criterion based on pairwise labels (same/different group). It can\nthen be applied to different data containing different groups. We demonstrate\npromising performance on high-dimensional data like images (COIL-100) and\nspeech (TIMIT). We call this ``learning to cluster'' and show its conceptual\ndifference to deep metric learning, semi-supervise clustering and other related\napproaches while having the advantage of performing learnable clustering fully\nend-to-end.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discrete time Pontryagin maximum principle for optimal control problems under state-action-frequency constraints.   We establish a Pontryagin maximum principle for discrete time optimal control\nproblems under the following three types of constraints: a) constraints on the\nstates pointwise in time, b) constraints on the control actions pointwise in\ntime, and c) constraints on the frequency spectrum of the optimal control\ntrajectories. While the first two types of constraints are already included in\nthe existing versions of the Pontryagin maximum principle, it turns out that\nthe third type of constraints cannot be recast in any of the standard forms of\nthe existing results for the original control system. We provide two different\nproofs of our Pontryagin maximum principle in this article, and include several\nspecial cases fine-tuned to control-affine nonlinear and linear system models.\nIn particular, for minimization of quadratic cost functions and linear time\ninvariant control systems, we provide tight conditions under which the optimal\ncontrols under frequency constraints are either normal or abnormal.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Momentum Distribution of Liquid $^4$He.   We report high-resolution neutron Compton scattering measurements of liquid\n$^4$He under saturated vapor pressure. There is excellent agreement between the\nobserved scattering and ab initio predictions of its lineshape. Quantum Monte\nCarlo calculations predict that the Bose condensate fraction is zero in the\nnormal fluid, builds up rapidly just below the superfluid transition\ntemperature, and reaches a value of approximately $7.5\\%$ below 1 K. We also\nused model fit functions to obtain from the scattering data empirical estimates\nfor the average atomic kinetic energy and Bose condensate fraction. These\nquantities are also in excellent agreement with ab initio calculations. The\nconvergence between the scattering data and Quantum Monte Carlo calculations is\nstrong evidence for a Bose broken symmetry in superfluid $^4$He.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Semi-equivelar maps on the torus are Archimedean.   If the face-cycles at all the vertices in a map on a surface are of same type\nthen the map is called semi-equivelar. There are eleven types of Archimedean\ntilings on the plane. All the Archimedean tilings are semi-equivelar maps. If a\nmap $X$ on the torus is a quotient of an Archimedean tiling on the plane then\nthe map $X$ is semi-equivelar. We show that each semi-equivelar map on the\ntorus is a quotient of an Archimedean tiling on the plane.\nVertex-transitive maps are semi-equivelar maps. We know that four types of\nsemi-equivelar maps on the torus are always vertex-transitive and there are\nexamples of other seven types of semi-equivelar maps which are not\nvertex-transitive. We show that the number of ${\\rm Aut}(Y)$-orbits of vertices\nfor any semi-equivelar map $Y$ on the torus is at most six. In fact, the number\nof orbits is at most three except one type of semi-equivelar maps. Our bounds\non the number of orbits are sharp.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Electrically driven quantum light emission in electromechanically-tuneable photonic crystal cavities.   A single quantum dot deterministically coupled to a photonic crystal\nenvironment constitutes an indispensable elementary unit to both generate and\nmanipulate single-photons in next-generation quantum photonic circuits. To\ndate, the scaling of the number of these quantum nodes on a fully-integrated\nchip has been prevented by the use of optical pumping strategies that require a\nbulky off-chip laser along with the lack of methods to control the energies of\nnano-cavities and emitters. Here, we concurrently overcome these limitations by\ndemonstrating electrical injection of single excitonic lines within a\nnano-electro-mechanically tuneable photonic crystal cavity. When an\nelectrically-driven dot line is brought into resonance with a photonic crystal\nmode, its emission rate is enhanced. Anti-bunching experiments reveal the\nquantum nature of these on-demand sources emitting in the telecom range. These\nresults represent an important step forward in the realization of integrated\nquantum optics experiments featuring multiple electrically-triggered\nPurcell-enhanced single-photon sources embedded in a reconfigurable\nsemiconductor architecture.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Analisis of the power flow in Low Voltage DC grids.   Power flow in a low voltage direct current grid (LVDC) is a non-linear\nproblem just as its counterpart ac. This paper demonstrates that, unlike in ac\ngrids, convergence and uniqueness of the solution can be guaranteed in this\ntype of grids. The result is not a linearization nor an approximation, but an\nanalysis of the set of non-linear algebraic equations, which is valid for any\nLVDC grid regardless its size, topology or load condition. Computer simulation\ncorroborate the theoretical analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Clustering Patients with Tensor Decomposition.   In this paper we present a method for the unsupervised clustering of\nhigh-dimensional binary data, with a special focus on electronic healthcare\nrecords. We present a robust and efficient heuristic to face this problem using\ntensor decomposition. We present the reasons why this approach is preferable\nfor tasks such as clustering patient records, to more commonly used\ndistance-based methods. We run the algorithm on two datasets of healthcare\nrecords, obtaining clinically meaningful results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On well-posedness of a velocity-vorticity formulation of the Navier-Stokes equations with no-slip boundary conditions.   We study well-posedness of a velocity-vorticity formulation of the\nNavier--Stokes equations, supplemented with no-slip velocity boundary\nconditions, a no-penetration vorticity boundary condition, along with a natural\nvorticity boundary condition depending on a pressure functional. In the\nstationary case we prove existence and uniqueness of a suitable weak solution\nto the system under a small data condition. The topic of the paper is driven by\nrecent developments of vorticity based numerical methods for the Navier--Stokes\nequations.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Millisecond Pulsars as Standards: Timing, positioning and communication.   Millisecond pulsars (MSPs) have a great potential to set standards in\ntimekeeping, positioning and metadata communication.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Learning to Price with Reference Effects.   As a firm varies the price of a product, consumers exhibit reference effects,\nmaking purchase decisions based not only on the prevailing price but also the\nproduct's price history. We consider the problem of learning such behavioral\npatterns as a monopolist releases, markets, and prices products. This context\ncalls for pricing decisions that intelligently trade off between maximizing\nrevenue generated by a current product and probing to gain information for\nfuture benefit. Due to dependence on price history, realized demand can reflect\ndelayed consequences of earlier pricing decisions. As such, inference entails\nattribution of outcomes to prior decisions and effective exploration requires\nplanning price sequences that yield informative future outcomes. Despite the\nconsiderable complexity of this problem, we offer a tractable systematic\napproach. In particular, we frame the problem as one of reinforcement learning\nand leverage Thompson sampling. We also establish a regret bound that provides\ngraceful guarantees on how performance improves as data is gathered and how\nthis depends on the complexity of the demand model. We illustrate merits of the\napproach through simulations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "DF-SLAM: A Deep-Learning Enhanced Visual SLAM System based on Deep Local Features.   As the foundation of driverless vehicle and intelligent robots, Simultaneous\nLocalization and Mapping(SLAM) has attracted much attention these days.\nHowever, non-geometric modules of traditional SLAM algorithms are limited by\ndata association tasks and have become a bottleneck preventing the development\nof SLAM. To deal with such problems, many researchers seek to Deep Learning for\nhelp. But most of these studies are limited to virtual datasets or specific\nenvironments, and even sacrifice efficiency for accuracy. Thus, they are not\npractical enough.\nWe propose DF-SLAM system that uses deep local feature descriptors obtained\nby the neural network as a substitute for traditional hand-made features.\nExperimental results demonstrate its improvements in efficiency and stability.\nDF-SLAM outperforms popular traditional SLAM systems in various scenes,\nincluding challenging scenes with intense illumination changes. Its versatility\nand mobility fit well into the need for exploring new environments. Since we\nadopt a shallow network to extract local descriptors and remain others the same\nas original SLAM systems, our DF-SLAM can still run in real-time on GPU.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Highly Nonlinear and Low Confinement Loss Photonic Crystal Fiber Using GaP Slot Core.   This paper presents a triangular lattice photonic crystal fiber with very\nhigh nonlinear coefficient. Finite element method (FEM) is used to scrutinize\ndifferent optical properties of proposed highly nonlinear photonic crystal\nfiber (HNL-PCF). The HNL-PCF exhibits a high nonlinearity up to $10\\times10^{4}\nW^{-1}km^{-1}$ over the wavelength of 1500 nm to 1700 nm. Moreover, proposed\nHNL-PCF shows a very low confinement loss of $10^{-3} dB/km$ at 1550 nm\nwavelength. Furthermore, chromatic dispersion, dispersion slope, effective area\netc. are also analyzed thoroughly. The proposed fiber will be a suitable\ncandidate for broadband dispersion compensation, sensor devices and\nsupercontinuum generation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Effect of Isopropanol on Gold Assisted Chemical Etching of Silicon Microstructures.   Wet etching is an essential and complex step in semiconductor device\nprocessing. Metal-Assisted Chemical Etching (MacEtch) is fundamentally a wet\nbut anisotropic etching method. In the MacEtch technique, there are still a\nnumber of unresolved challenges preventing the optimal fabrication of\nhigh-aspect-ratio semiconductor micro- and nanostructures, such as undesired\netching, uncontrolled catalyst movement, non-uniformity and micro-porosity in\nthe metal-free areas. Here, an optimized MacEtch process using with a\nnanostructured Au catalyst is proposed for fabrication of Si high aspect ratio\nmicrostructures. The addition of isopropanol as surfactant in the HF-H2O2 water\nsolution improves the uniformity and the control of the H2 gas release. An\nadditional KOH etching removes eventually the unwanted nanowires left by the\nMacEtch through the nanoporous catalyst film. We demonstrate the benefits of\nthe isopropanol addition for reducing the etching rate and the nanoporosity of\netched structures with a monothonical decrease as a function of the isopropanol\nconcentration.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Road to safe autonomy with data and formal reasoning.   We present an overview of recently developed data-driven tools for safety\nanalysis of autonomous vehicles and advanced driver assist systems. The core\nalgorithms combine model-based, hybrid system reachability analysis with\nsensitivity analysis of components with unknown or inaccessible models. We\nillustrate the applicability of this approach with a new case study of\nemergency braking systems in scenarios with two or three vehicles. This problem\nis representative of the most common type of rear-end crashes, which is\nrelevant for safety analysis of automatic emergency braking (AEB) and forward\ncollision avoidance systems. We show that our verification tool can effectively\nprove the safety of certain scenarios (specified by several parameters like\nbraking profiles, initial velocities, uncertainties in position and reaction\ntimes), and also compute the severity of accidents for unsafe scenarios.\nThrough hundreds of verification experiments, we quantified the safety envelope\nof the system across relevant parameters. These results show that the approach\nis promising for design, debugging and certification. We also show how the\nreachability analysis can be combined with statistical information about the\nparameters, to assess the risk level of the control system, which in turn is\nessential, for example, for determining Automotive Safety Integrity Levels\n(ASIL) for the ISO26262 standard.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Risk ratios for contagious outcomes.   The risk ratio is a popular tool for summarizing the relationship between a\nbinary covariate and outcome, even when outcomes may be dependent.\nInvestigations of infectious disease outcomes in cohort studies of individuals\nembedded within clusters -- households, villages, or small groups -- often\nreport risk ratios. Epidemiologists have warned that risk ratios may be\nmisleading when outcomes are contagious, but the nature and severity of this\nerror is not well understood. In this study, we assess the epidemiologic\nmeaning of the risk ratio when outcomes are contagious. We first give a\nstructural definition of infectious disease transmission within clusters, based\non the canonical susceptible-infective epidemic model. From this standard\ncharacterization, we define the individual-level ratio of instantaneous risks\n(hazard ratio) as the inferential target, and evaluate the properties of the\nrisk ratio as an estimate of this quantity. We exhibit analytically and by\nsimulation the circumstances under which the risk ratio implies an effect whose\ndirection is opposite that of the true individual-level hazard ratio. In\nparticular, the risk ratio can be greater than one even when the covariate of\ninterest reduces both individual-level susceptibility to infection, and\ntransmissibility once infected. We explain these findings in the epidemiologic\nlanguage of confounding and relate the direction bias to Simpson's paradox.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inductive Representation Learning on Large Graphs.   Low-dimensional embeddings of nodes in large graphs have proved extremely\nuseful in a variety of prediction tasks, from content recommendation to\nidentifying protein functions. However, most existing approaches require that\nall nodes in the graph are present during training of the embeddings; these\nprevious approaches are inherently transductive and do not naturally generalize\nto unseen nodes. Here we present GraphSAGE, a general, inductive framework that\nleverages node feature information (e.g., text attributes) to efficiently\ngenerate node embeddings for previously unseen data. Instead of training\nindividual embeddings for each node, we learn a function that generates\nembeddings by sampling and aggregating features from a node's local\nneighborhood. Our algorithm outperforms strong baselines on three inductive\nnode-classification benchmarks: we classify the category of unseen nodes in\nevolving information graphs based on citation and Reddit post data, and we show\nthat our algorithm generalizes to completely unseen graphs using a multi-graph\ndataset of protein-protein interactions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Data-Driven Supply-Side Approach for Measuring Cross-Border Internet Purchases.   The digital economy is a highly relevant item on the European Union's policy\nagenda. Cross-border internet purchases are part of the digital economy, but\ntheir total value can currently not be accurately measured or estimated.\nTraditional approaches based on consumer surveys or business surveys are shown\nto be inadequate for this purpose, due to language bias and sampling issues,\nrespectively. We address both problems by proposing a novel approach based on\nsupply-side data, namely tax returns. The proposed data-driven record-linkage\ntechniques and machine learning algorithms utilize two additional open data\nsources: European business registers and internet data. Our main finding is\nthat the value of total cross-border internet purchases within the European\nUnion by Dutch consumers was over EUR 1.3 billion in 2016. This is more than 6\ntimes as high as current estimates. Our finding motivates the implementation of\nthe proposed methodology in other EU member states. Ultimately, it could lead\nto more accurate estimates of cross-border internet purchases within the entire\nEuropean Union.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discrete Dynamic Causal Modeling and Its Relationship with Directed Information.   This paper explores the discrete Dynamic Causal Modeling (DDCM) and its\nrelationship with Directed Information (DI). We prove the conditional\nequivalence between DDCM and DI in characterizing the causal relationship\nbetween two brain regions. The theoretical results are demonstrated using fMRI\ndata obtained under both resting state and stimulus based state. Our numerical\nanalysis is consistent with that reported in previous study.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Laplacian Prior Variational Automatic Relevance Determination for Transmission Tomography.   In the classic sparsity-driven problems, the fundamental L-1 penalty method\nhas been shown to have good performance in reconstructing signals for a wide\nrange of problems. However this performance relies on a good choice of penalty\nweight which is often found from empirical experiments. We propose an algorithm\ncalled the Laplacian variational automatic relevance determination (Lap-VARD)\nthat takes this penalty weight as a parameter of a prior Laplace distribution.\nOptimization of this parameter using an automatic relevance determination\nframework results in a balance between the sparsity and accuracy of signal\nreconstruction. Our algorithm is implemented in a transmission tomography model\nwith sparsity constraint in wavelet domain.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "EAD: Elastic-Net Attacks to Deep Neural Networks via Adversarial Examples.   Recent studies have highlighted the vulnerability of deep neural networks\n(DNNs) to adversarial examples - a visually indistinguishable adversarial image\ncan easily be crafted to cause a well-trained model to misclassify. Existing\nmethods for crafting adversarial examples are based on $L_2$ and $L_\\infty$\ndistortion metrics. However, despite the fact that $L_1$ distortion accounts\nfor the total variation and encourages sparsity in the perturbation, little has\nbeen developed for crafting $L_1$-based adversarial examples. In this paper, we\nformulate the process of attacking DNNs via adversarial examples as an\nelastic-net regularized optimization problem. Our elastic-net attacks to DNNs\n(EAD) feature $L_1$-oriented adversarial examples and include the\nstate-of-the-art $L_2$ attack as a special case. Experimental results on MNIST,\nCIFAR10 and ImageNet show that EAD can yield a distinct set of adversarial\nexamples with small $L_1$ distortion and attains similar attack performance to\nthe state-of-the-art methods in different attack scenarios. More importantly,\nEAD leads to improved attack transferability and complements adversarial\ntraining for DNNs, suggesting novel insights on leveraging $L_1$ distortion in\nadversarial machine learning and security implications of DNNs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust and Flexible Estimation of Stochastic Mediation Effects: A Proposed Method and Example in a Randomized Trial Setting.   Causal mediation analysis can improve understanding of the mechanisms\nunderlying epidemiologic associations. However, the utility of natural direct\nand indirect effect estimation has been limited by the assumption of no\nconfounder of the mediator-outcome relationship that is affected by prior\nexposure---an assumption frequently violated in practice. We build on recent\nwork that identified alternative estimands that do not require this assumption\nand propose a flexible and double robust semiparametric targeted minimum\nloss-based estimator for data-dependent stochastic direct and indirect effects.\nThe proposed method treats the intermediate confounder affected by prior\nexposure as a time-varying confounder and intervenes stochastically on the\nmediator using a distribution which conditions on baseline covariates and\nmarginalizes over the intermediate confounder. In addition, we assume the\nstochastic intervention is given, conditional on observed data, which results\nin a simpler estimator and weaker identification assumptions. We demonstrate\nthe estimator's finite sample and robustness properties in a simple simulation\nstudy. We apply the method to an example from the Moving to Opportunity\nexperiment. In this application, randomization to receive a housing voucher is\nthe treatment/instrument that influenced moving to a low-poverty neighborhood,\nwhich is the intermediate confounder. We estimate the data-dependent stochastic\ndirect effect of randomization to the voucher group on adolescent marijuana use\nnot mediated by change in school district and the stochastic indirect effect\nmediated by change in school district. We find no evidence of mediation. Our\nestimator is easy to implement in standard statistical software, and we provide\nannotated R code to further lower implementation barriers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "First-principles insights into ultrashort laser spectroscopy of molecular nitrogen.   In this research, we employ accurate time-dependent density functional\ncalculations for ultrashort laser spectroscopy of nitrogen molecule. Laser\npulses with different frequencies, intensities, and durations are applied to\nthe molecule and the resulting photoelectron spectra are analyzed. It is argued\nthat relative orientation of the molecule in the laser pulse significantly\ninfluence the orbital character of the emitted photoelectrons. Moreover, the\nduration of the laser pulse is also found to be very effective in controlling\nthe orbital resolution and intensity of photoelectrons. Angular resolved\ndistribution of photoelectrons are computed at different pulse frequencies and\nrecording times. By exponential growth of the laser pulse intensity, the\ntheoretical threshold of two photons absorption in nitrogen molecule is\ndetermined.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Exploring one particle orbitals in large Many-Body Localized systems.   Strong disorder in interacting quantum systems can give rise to the\nphenomenon of Many-Body Localization (MBL), which defies thermalization due to\nthe formation of an extensive number of quasi local integrals of motion. The\none particle operator content of these integrals of motion is related to the\none particle orbitals of the one particle density matrix and shows a strong\nsignature across the MBL transition as recently pointed out by Bera et al.\n[Phys. Rev. Lett. 115, 046603 (2015); Ann. Phys. 529, 1600356 (2017)]. We study\nthe properties of the one particle orbitals of many-body eigenstates of an MBL\nsystem in one dimension. Using shift-and-invert MPS (SIMPS), a matrix product\nstate method to target highly excited many-body eigenstates introduced in\n[Phys. Rev. Lett. 118, 017201 (2017)], we are able to obtain accurate results\nfor large systems of sizes up to L = 64. We find that the one particle orbitals\ndrawn from eigenstates at different energy densities have high overlap and\ntheir occupations are correlated with the energy of the eigenstates. Moreover,\nthe standard deviation of the inverse participation ratio of these orbitals is\nmaximal at the nose of the mobility edge. Also, the one particle orbitals decay\nexponentially in real space, with a correlation length that increases at low\ndisorder. In addition, we find a 1/f distribution of the coupling constants of\na certain range of the number operators of the OPOs, which is related to their\nexponential decay.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning to Compose Task-Specific Tree Structures.   For years, recursive neural networks (RvNNs) have been shown to be suitable\nfor representing text into fixed-length vectors and achieved good performance\non several natural language processing tasks. However, the main drawback of\nRvNNs is that they require structured input, which makes data preparation and\nmodel implementation hard. In this paper, we propose Gumbel Tree-LSTM, a novel\ntree-structured long short-term memory architecture that learns how to compose\ntask-specific tree structures only from plain text data efficiently. Our model\nuses Straight-Through Gumbel-Softmax estimator to decide the parent node among\ncandidates dynamically and to calculate gradients of the discrete decision. We\nevaluate the proposed model on natural language inference and sentiment\nanalysis, and show that our model outperforms or is at least comparable to\nprevious models. We also find that our model converges significantly faster\nthan other models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Graphene quantum dots prevent alpha-synucleinopathy in Parkinson's disease.   While the emerging evidence indicates that the pathogenesis of Parkinson's\ndisease (PD) is strongly correlated to the accumulation of alpha-synuclein\n({\\alpha}-syn) aggregates, there has been no clinical success in\nanti-aggregation agents for the disease to date. Here we show that graphene\nquantum dots (GQDs) exhibit anti-amyloid activity via direct interaction with\n{\\alpha}-syn. Employing biophysical, biochemical, and cell-based assays as well\nas molecular dynamics (MD) simulation, we find that GQDs have notable potency\nin not only inhibiting fibrillization of {\\alpha}-syn but also disaggregating\nmature fibrils in a time-dependent manner. Remarkably, GQDs rescue neuronal\ndeath and synaptic loss, reduce Lewy body (LB)/Lewy neurite (LN) formation,\nameliorate mitochondrial dysfunctions, and prevent neuron-to-neuron\ntransmission of {\\alpha}-syn pathology induced by {\\alpha}-syn preformed\nfibrils (PFFs) in neurons. In addition, in vivo administration of GQDs protects\nagainst {\\alpha}-syn PFFs-induced loss of dopamine neurons, LB/LN pathology,\nand behavioural deficits through the penetration of the blood-brain barrier\n(BBB). The finding that GQDs function as an anti-aggregation agent provides a\npromising novel therapeutic target for the treatment of PD and related\n{\\alpha}-synucleinopathies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Inter-site pair superconductivity: origins and recent validation experiments.   The challenge of understanding high-temperature superconductivity has led to\na plethora of ideas, but 30 years after its discovery in cuprates, very few\nhave achieved convincing experimental validation. While Hubbard and t-J models\nwere given a lot of attention, a number of recent experiments appear to give\ndecisive support to the model of real-space inter-site pairing and percolative\nsuperconductivity in cuprates. Systematic measurements of the doping dependence\nof the superfluid density show a linear dependence on superfluid density -\nrather than doping - over the entire phase diagram, in accordance with the\nmodel's predictions. The doping-dependence of the anomalous lattice dynamics of\nin-plane Cu-O mode vibrations observed by inelastic neutron scattering, gives\nremarkable reciprocal space signature of the inter-site pairing interaction\nwhose doping dependence closely follows the predicted pair density.\nSymmetry-specific time-domain spectroscopy shows carrier localization, polaron\nformation, pairing and superconductivity to be distinct processes occurring on\ndistinct timescales throughout the entire superconducting phase diagram. The\nthree diverse experimental results confirm non-trivial predictions made more\nthan a decade ago by the inter-site pairing model in the cuprates, remarkably\nalso confirming some of the fundamental notions mentioned in the seminal paper\non the discovery of high-temperature superconductivity in cuprates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Cell-to-cell variation sets a tissue-rheology-dependent bound on collective gradient sensing.   When a single cell senses a chemical gradient and chemotaxes, stochastic\nreceptor-ligand binding can be a fundamental limit to the cell's accuracy. For\nclusters of cells responding to gradients, however, there is a critical\ndifference: even genetically identical cells have differing responses to\nchemical signals. With theory and simulation, we show collective chemotaxis is\nlimited by cell-to-cell variation in signaling. We find that when different\ncells cooperate the resulting bias can be much larger than the effects of\nligand-receptor binding. Specifically, when a strongly-responding cell is at\none end of a cell cluster, cluster motion is biased toward that cell. These\nerrors are mitigated if clusters average measurements over times long enough\nfor cells to rearrange. In consequence, fluid clusters are better able to sense\ngradients: we derive a link between cluster accuracy, cell-to-cell variation,\nand the cluster rheology. Because of this connection, increasing the noisiness\nof individual cell motion can actually increase the collective accuracy of a\ncluster by improving fluidity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Machine Learning Approach to RF Transmitter Identification.   With the development and widespread use of wireless devices in recent years\n(mobile phones, Internet of Things, Wi-Fi), the electromagnetic spectrum has\nbecome extremely crowded. In order to counter security threats posed by rogue\nor unknown transmitters, it is important to identify RF transmitters not by the\ndata content of the transmissions but based on the intrinsic physical\ncharacteristics of the transmitters. RF waveforms represent a particular\nchallenge because of the extremely high data rates involved and the potentially\nlarge number of transmitters present in a given location. These factors outline\nthe need for rapid fingerprinting and identification methods that go beyond the\ntraditional hand-engineered approaches. In this study, we investigate the use\nof machine learning (ML) strategies to the classification and identification\nproblems, and the use of wavelets to reduce the amount of data required. Four\ndifferent ML strategies are evaluated: deep neural nets (DNN), convolutional\nneural nets (CNN), support vector machines (SVM), and multi-stage training\n(MST) using accelerated Levenberg-Marquardt (A-LM) updates. The A-LM MST method\npreconditioned by wavelets was by far the most accurate, achieving 100%\nclassification accuracy of transmitters, as tested using data originating from\n12 different transmitters. We discuss strategies for extension of MST to a much\nlarger number of transmitters.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Statistics of turbulence in the energy-containing range of Taylor-Couette compared to canonical wall-bounded flows.   Considering structure functions of the streamwise velocity component in a\nframework akin to the extended self-similarity hypothesis (ESS), de Silva\n\\textit{et al.} (\\textit{J. Fluid Mech.}, vol. 823,2017, pp. 498-510) observed\nthat remarkably the \\textit{large-scale} (energy-containing range) statistics\nin canonical wall bounded flows exhibit universal behaviour. In the present\nstudy, we extend this universality, which was seen to encompass also flows at\nmoderate Reynolds number, to Taylor-Couette flow. In doing so, we find that\nalso the transversal structure function of the spanwise velocity component\nexhibits the same universal behaviour across all flow types considered. We\nfurther demonstrate that these observations are consistent with predictions\ndeveloped based on an attached-eddy hypothesis. These considerations also yield\na possible explanation for the efficacy of the ESS framework by showing that it\nrelaxes the self-similarity assumption for the attached eddy contributions. By\ntaking the effect of streamwise alignment into account, the attached eddy model\npredicts different behaviour for structure functions in the streamwise and in\nthe spanwise directions and that this effect cancels in the ESS-framework ---\nboth consistent with the data. Moreover, it is demonstrated here that also the\nadditive constants, which were previously believed to be flow dependent, are\nindeed universal at least in turbulent boundary layers and pipe flow where\nhigh-Reynolds number data are currently available.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Attention-based Natural Language Person Retrieval.   Following the recent progress in image classification and captioning using\ndeep learning, we develop a novel natural language person retrieval system\nbased on an attention mechanism. More specifically, given the description of a\nperson, the goal is to localize the person in an image. To this end, we first\nconstruct a benchmark dataset for natural language person retrieval. To do so,\nwe generate bounding boxes for persons in a public image dataset from the\nsegmentation masks, which are then annotated with descriptions and attributes\nusing the Amazon Mechanical Turk. We then adopt a region proposal network in\nFaster R-CNN as a candidate region generator. The cropped images based on the\nregion proposals as well as the whole images with attention weights are fed\ninto Convolutional Neural Networks for visual feature extraction, while the\nnatural language expression and attributes are input to Bidirectional Long\nShort- Term Memory (BLSTM) models for text feature extraction. The visual and\ntext features are integrated to score region proposals, and the one with the\nhighest score is retrieved as the output of our system. The experimental\nresults show significant improvement over the state-of-the-art method for\ngeneric object retrieval and this line of research promises to benefit search\nin surveillance video footage.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "When a triangle is isosceles?.   In 1840 Jacob Steiner on Christian Rudolf's request proved that a triangle\nwith two equal bisectors is isosceles. But what about changing the bisectors to\ncevians? Cevian is any line segment in a triangle with one endpoint on a vertex\nof the triangle and other endpoint on the opposite side. Not for any pairs of\nequal cevians the triangle is isosceles. Theorem. If for a triangle ABC there\nare equal cevians issuing from A and B, which intersect on the bisector or on\nthe median of the angle C, then AC=BC (so the triangle ABC is isosceles).\nProposition. Let ABC be an isosceles triangle. Define circle C to be the circle\nsymmetric relative to AB to the circumscribed circle of the triangle ABC. Then\nthe locus of intersection points of pairs of equal cevians is the union of the\nbase AB, the triangle's axis of symmetry, and the circle C.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "How to model fake news.   Over the past three years it has become evident that fake news is a danger to\ndemocracy. However, until now there has been no clear understanding of how to\ndefine fake news, much less how to model it. This paper addresses both these\nissues. A definition of fake news is given, and two approaches for the\nmodelling of fake news and its impact in elections and referendums are\nintroduced. The first approach, based on the idea of a representative voter, is\nshown to be suitable to obtain a qualitative understanding of phenomena\nassociated with fake news at a macroscopic level. The second approach, based on\nthe idea of an election microstructure, describes the collective behaviour of\nthe electorate by modelling the preferences of individual voters. It is shown\nthrough a simulation study that the mere knowledge that pieces of fake news may\nbe in circulation goes a long way towards mitigating the impact of fake news.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Reinforcement Learning for General Video Game AI.   The General Video Game AI (GVGAI) competition and its associated software\nframework provides a way of benchmarking AI algorithms on a large number of\ngames written in a domain-specific description language. While the competition\nhas seen plenty of interest, it has so far focused on online planning,\nproviding a forward model that allows the use of algorithms such as Monte Carlo\nTree Search.\nIn this paper, we describe how we interface GVGAI to the OpenAI Gym\nenvironment, a widely used way of connecting agents to reinforcement learning\nproblems. Using this interface, we characterize how widely used implementations\nof several deep reinforcement learning algorithms fare on a number of GVGAI\ngames. We further analyze the results to provide a first indication of the\nrelative difficulty of these games relative to each other, and relative to\nthose in the Arcade Learning Environment under similar conditions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamics of domain walls in weak ferromagnets.   It is shown that the total set of equations, which determines the dynamics of\nthe domain bounds (DB) in a weak ferromagnet, has the same type of specific\nsolution as the well-known Walker's solution for ferromagnets. We calculated\nthe functional dependence of the velocity of the DB on the magnetic field,\nwhich is described by the obtained solution. This function has a maximum at a\nfinite field and a section of the negative differential mobility of the DB.\nAccording to the calculation, the maximum velocity $ c \\approx 2 \\times 10^6$\ncm/sec in YFeO$_3$ is reached at $H_m \\approx 4 \\times 10^3$ Oe.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "In-gap bound states induced by a single nonmagnetic impurity in sign-preserving s-wave superconductors with incipient bands.   We have investigated the in-gap bound states (IGBS) induced by a single\nnonmagnetic impurity in multiband superconductors with incipient bands.\nContrary to the naive expectation, we found that even if the superconducting\n(SC) order parameter is sign-preserving s-wave on the Fermi surfaces, the\nincipient bands may still affect the appearance and locations of the IGBS,\nalthough the gap between the incipient bands and the Fermi level is much larger\nthan the SC gap. Therefore in scanning tunneling microscopy experiments, the\nIGBS induced by a single nonmagnetic impurity are not the definitive evidences\nfor the sign-changing order parameter on the Fermi surfaces. Our findings have\nspecial implications for the experimental determination of the pairing symmetry\nin the FeSe-based superconductors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the K-theory of C*-algebras for substitution tilings (a pedestrian version).   Under suitable conditions, a substitution tiling gives rise to a Smale space,\nfrom which three equivalence relations can be constructed, namely the stable,\nunstable, and asymptotic equivalence relations. We denote with $S$, $U$, and\n$A$ their corresponding $C^*$-algebras in the sense of Renault. In this article\nwe show that the $K$-theories of $S$ and $U$ can be computed from the\ncohomology and homology of a single cochain complex with connecting maps for\ntilings of the line and of the plane. Moreover, we provide formulas to compute\nthe $K$-theory for these three $C^*$-algebras. Furthermore, we show that the\n$K$-theory groups for tilings of dimension 1 are always torsion free. For\ntilings of dimension 2, only $K_0(U)$ and $K_1(S)$ can contain torsion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Magnetization spin dynamics in a (LuBi)3Fe5O12 (BLIG) epitaxial film.   Bismuth substituted lutetium iron garnet (BLIG) films exhibit larger Faraday\nrotation, and have a higher Curie temperature than yttrium iron garnet. We have\nobserved magnetic stripe domains and measured domain widths of 1.4 {\\mu}{\\mu}m\nusing Fourier domain polarization microscopy, Faraday rotation experiments\nyield a coercive field of 5 Oe. These characterizations form the basis of\nmicromagnetic simulations that allow us to estimate and compare spin wave\nexcitations in BLIG films. We observed that these films support thermal magnons\nwith a precessional frequency of 7 GHz with a line width of 400 MHz. Further,\nwe studied the dependence of precessional frequency on the externally applied\nmagnetic field. Brillouin light scattering experiments and precession\nfrequencies predicted by simulations show similar trend with increasing field.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Angle-resolved photoemission spectroscopy with quantum gas microscopes.   Quantum gas microscopes are a promising tool to study interacting quantum\nmany-body systems and bridge the gap between theoretical models and real\nmaterials. So far they were limited to measurements of instantaneous\ncorrelation functions of the form $\\langle \\hat{O}(t) \\rangle$, even though\nextensions to frequency-resolved response functions $\\langle \\hat{O}(t)\n\\hat{O}(0) \\rangle$ would provide important information about the elementary\nexcitations in a many-body system. For example, single particle spectral\nfunctions, which are usually measured using photoemission experiments in\nelectron systems, contain direct information about fractionalization and the\nquasiparticle excitation spectrum. Here, we propose a measurement scheme to\nexperimentally access the momentum and energy resolved spectral function in a\nquantum gas microscope with currently available techniques. As an example for\npossible applications, we numerically calculate the spectrum of a single hole\nexcitation in one-dimensional $t-J$ models with isotropic and anisotropic\nantiferromagnetic couplings. A sharp asymmetry in the distribution of spectral\nweight appears when a hole is created in an isotropic Heisenberg spin chain.\nThis effect slowly vanishes for anisotropic spin interactions and disappears\ncompletely in the case of pure Ising interactions. The asymmetry strongly\ndepends on the total magnetization of the spin chain, which can be tuned in\nexperiments with quantum gas microscopes. An intuitive picture for the observed\nbehavior is provided by a slave-fermion mean field theory. The key properties\nof the spectra are visible at currently accessible temperatures.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Role of the orbital degree of freedom in iron-based superconductors.   Almost a decade has passed since the serendipitous discovery of the\niron-based high temperature superconductors (FeSCs) in 2008. The question of\nhow much similarity the FeSCs have with the copper oxide high temperature\nsuperconductors emerged since the initial discovery of long-range\nantiferromagnetism in the FeSCs in proximity to superconductivity. Despite the\ngreat resemblance in their phase diagrams, there exist important disparities\nbetween FeSCs and cuprates that need to be considered in order to paint a full\npicture of these two families of high temperature superconductors. One of the\nkey differences lies in the multi-orbital multi-band nature of FeSCs, in\ncontrast to the effective single-band model for cuprates. Due to the complexity\nof multi-orbital band structures, the orbital degree of freedom is often\nneglected in formulating the theoretical models for FeSCs. On the experimental\nside, systematic studies of the orbital related phenomena in FeSCs have been\nlargely lacking. In this review, we summarize angle-resolved photoemission\nspectroscopy (ARPES) measurements across various FeSC families in literature,\nfocusing on the systematic trend of orbital dependent electron correlations and\nthe role of different Fe 3d orbitals in driving the nematic transition, the\nspin-density-wave transition, and implications for superconductivity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Recursive Multikernel Filters Exploiting Nonlinear Temporal Structure.   In kernel methods, temporal information on the data is commonly included by\nusing time-delayed embeddings as inputs. Recently, an alternative formulation\nwas proposed by defining a gamma-filter explicitly in a reproducing kernel\nHilbert space, giving rise to a complex model where multiple kernels operate on\ndifferent temporal combinations of the input signal. In the original\nformulation, the kernels are then simply combined to obtain a single kernel\nmatrix (for instance by averaging), which provides computational benefits but\ndiscards important information on the temporal structure of the signal.\nInspired by works on multiple kernel learning, we overcome this drawback by\nconsidering the different kernels separately. We propose an efficient strategy\nto adaptively combine and select these kernels during the training phase. The\nresulting batch and online algorithms automatically learn to process highly\nnonlinear temporal information extracted from the input signal, which is\nimplicitly encoded in the kernel values. We evaluate our proposal on several\nartificial and real tasks, showing that it can outperform classical approaches\nboth in batch and online settings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Learning from Shallow Dives: Sonar Image Generation and Training for Underwater Object Detection.   Among underwater perceptual sensors, imaging sonar has been highlighted for\nits perceptual robustness underwater. The major challenge of imaging sonar,\nhowever, arises from the difficulty in defining visual features despite limited\nresolution and high noise levels. Recent developments in deep learning provide\na powerful solution for computer-vision researches using optical images.\nUnfortunately, deep learning-based approaches are not well established for\nimaging sonars, mainly due to the scant data in the training phase. Unlike the\nabundant publically available terrestrial images, obtaining underwater images\nis often costly, and securing enough underwater images for training is not\nstraightforward. To tackle this issue, this paper presents a solution to this\nfield's lack of data by introducing a novel end-to-end image-synthesizing\nmethod in the training image preparation phase. The proposed method present\nimage synthesizing scheme to the images captured by an underwater simulator.\nOur synthetic images are based on the sonar imaging models and noisy\ncharacteristics to represent the real data obtained from the sea. We validate\nthe proposed scheme by training using a simulator and by testing the simulated\nimages with real underwater sonar images obtained from a water tank and the\nsea.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rigidity of branching microstructures in shape memory alloys.   We analyze generic sequences for which the geometrically linear energy\n\\[E_\\eta(u,\\chi):= \\eta^{-\\frac{2}{3}}\\int_{B_{0}(1)} \\left| e(u)-\n\\sum_{i=1}^3 \\chi_ie_i\\right|^2 d x+\\eta^\\frac{1}{3} \\sum_{i=1}^3\n|D\\chi_i|(B_{0}(1))\\] remains bounded in the limit $\\eta \\to 0$. Here $ e(u)\n:=1/2(Du + Du^T)$ is the (linearized) strain of the displacement $u$, the\nstrains $e_i$ correspond to the martensite strains of a shape memory alloy\nundergoing cubic-to-tetragonal transformations and $\\chi_i:B_{0}(1) \\to\n\\{0,1\\}$ is the partition into phases. In this regime it is known that in\naddition to simple laminates also branched structures are possible, which if\naustenite was present would enable the alloy to form habit planes.\nIn an ansatz-free manner we prove that the alignment of macroscopic\ninterfaces between martensite twins is as predicted by well-known rank-one\nconditions. Our proof proceeds via the non-convex, non-discrete-valued\ndifferential inclusion \\[e(u) \\in \\bigcup_{1\\leq i\\neq j\\leq 3}\n\\operatorname{conv} \\{e_i,e_j\\}\\] satisfied by the weak limits of bounded\nenergy sequences and of which we classify all solutions. In particular, there\nexist no convex integration solutions of the inclusion with complicated\ngeometric structures.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Period polynomials, derivatives of $L$-functions, and zeros of polynomials.   Period polynomials have long been fruitful tools for the study of values of\n$L$-functions in the context of major outstanding conjectures. In this paper,\nwe survey some facets of this study from the perspective of Eichler cohomology.\nWe discuss ways to incorporate non-cuspidal modular forms and values of\nderivatives of $L$-functions into the same framework. We further review\ninvestigations of the location of zeros of the period polynomial as well as of\nits analogue for $L$-derivatives.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Online Learning for Changing Environments using Coin Betting.   A key challenge in online learning is that classical algorithms can be slow\nto adapt to changing environments. Recent studies have proposed \"meta\"\nalgorithms that convert any online learning algorithm to one that is adaptive\nto changing environments, where the adaptivity is analyzed in a quantity called\nthe strongly-adaptive regret. This paper describes a new meta algorithm that\nhas a strongly-adaptive regret bound that is a factor of $\\sqrt{\\log(T)}$\nbetter than other algorithms with the same time complexity, where $T$ is the\ntime horizon. We also extend our algorithm to achieve a first-order (i.e.,\ndependent on the observed losses) strongly-adaptive regret bound for the first\ntime, to our knowledge. At its heart is a new parameter-free algorithm for the\nlearning with expert advice (LEA) problem in which experts sometimes do not\noutput advice for consecutive time steps (i.e., \\emph{sleeping} experts). This\nalgorithm is derived by a reduction from optimal algorithms for the so-called\ncoin betting problem. Empirical results show that our algorithm outperforms\nstate-of-the-art methods in both learning with expert advice and metric\nlearning scenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Real embedding and equivariant eta forms.   In 1993, Bismut and Zhang establish a mod Z embedding formula of\nAtiyah-Patodi-Singer reduced eta invariants. In this paper, we explain the\nhidden mod Z term as a spectral flow and extend this embedding formula to the\nequivariant family case. In this case, the spectral flow is generalized to the\nequivariant chern character of some equivariant Dai-Zhang higher spectral flow.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Global weak solutions in a three-dimensional Keller-Segel-Navier-Stokes system with nonlinear diffusion.   The coupled quasilinear Keller-Segel-Navier-Stokes system is considered under\nNeumann boundary conditions for $n$ and $c$ and no-slip boundary conditions for\n$u$ in three-dimensional bounded domains $\\Omega\\subseteq \\mathbb{R}^3$ with\nsmooth boundary, where $m>0,\\kappa\\in \\mathbb{R}$ are given constants, $\\phi\\in\nW^{1,\\infty}(\\Omega)$. If $ m> 2$, then for all reasonably regular initial\ndata, a corresponding initial-boundary value problem for $(KSNF)$ possesses a\nglobally defined weak solution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Chiral and Topological Orbital Magnetism of Spin Textures.   Using a semiclassical Green's function formalism, we discover the emergence\nof chiral and topological orbital magnetism in two-dimensional chiral spin\ntextures by explicitly finding the corrections to the orbital magnetization,\nproportional to the powers of the gradients of the texture. We show that in the\nabsence of spin-orbit coupling, the resulting orbital moment can be understood\nas the electronic response to the emergent magnetic field associated with the\nreal-space Berry curvature. By referring to the Rashba model, we demonstrate\nthat by tuning the parameters of surface systems the engineering of emergent\norbital magnetism in spin textures can pave the way to novel concepts in\norbitronics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Personalized Driver Stress Detection with Multi-task Neural Networks using Physiological Signals.   Stress can be seen as a physiological response to everyday emotional, mental\nand physical challenges. A long-term exposure to stressful situations can have\nnegative health consequences, such as increased risk of cardiovascular diseases\nand immune system disorder. Therefore, a timely stress detection can lead to\nsystems for better management and prevention in future circumstances. In this\npaper, we suggest a multi-task learning based neural network approach (with\nhard parameter sharing of mutual representation and task-specific layers) for\npersonalized stress recognition using skin conductance and heart rate from\nwearable devices. The proposed method is tested on multi-modal physiological\nresponses collected during real-world and simulator driving tasks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The co-evolution of emotional well-being with weak and strong friendship ties.   Social ties are strongly related to well-being. But what characterizes this\nrelationship? This study investigates social mechanisms explaining how social\nties affect well-being through social integration and social influence, and how\nwell-being affects social ties through social selection. We hypothesize that\nhighly integrated individuals - those with more extensive and dense friendship\nnetworks - report higher emotional well-being than others. Moreover, emotional\nwell-being should be influenced by the well-being of close friends. Finally,\nwell-being should affect friendship selection when individuals prefer others\nwith higher levels of well-being, and others whose well-being is similar to\ntheirs. We test our hypotheses using longitudinal social network and well-being\ndata of 117 individuals living in a graduate housing community. The application\nof a novel extension of Stochastic Actor-Oriented Models for ordered networks\n(ordered SAOMs) allows us to detail and test our hypotheses for weak- and\nstrong-tied friendship networks simultaneously. Results do not support our\nsocial integration and social influence hypotheses but provide evidence for\nselection: individuals with higher emotional well-being tend to have more\nstrong-tied friends, and there are homophily processes regarding emotional\nwell-being in strong-tied networks. Our study highlights the two-directional\nrelationship between social ties and well-being, and demonstrates the\nimportance of considering different tie strengths for various social processes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exothermicity is not a necessary condition for enhanced diffusion of enzymes.   Recent experiments have revealed that the diffusivity of exothermic and fast\nenzymes is enhanced when they are catalytically active, and different physical\nmechanisms have been explored and quantified to account for this observation.\nWe perform measurements on the endothermic and relatively slow enzyme aldolase,\nwhich also shows substrate-induced enhanced diffusion. We propose a new\nphysical paradigm, which reveals that the diffusion coefficient of a model\nenzyme hydrodynamically coupled to its environment increases significantly when\nundergoing changes in conformational fluctuations in a substrate-dependent\nmanner, and is independent of the overall turnover rate of the underlying\nenzymatic reaction. Our results show that substrate-induced enhanced diffusion\nof enzyme molecules can be explained within an equilibrium picture, and that\nthe exothermicity of the catalyzed reaction is not a necessary condition for\nthe observation of this phenomenon.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "AdaGAN: Boosting Generative Models.   Generative Adversarial Networks (GAN) (Goodfellow et al., 2014) are an\neffective method for training generative models of complex data such as natural\nimages. However, they are notoriously hard to train and can suffer from the\nproblem of missing modes where the model is not able to produce examples in\ncertain regions of the space. We propose an iterative procedure, called AdaGAN,\nwhere at every step we add a new component into a mixture model by running a\nGAN algorithm on a reweighted sample. This is inspired by boosting algorithms,\nwhere many potentially weak individual predictors are greedily aggregated to\nform a strong composite predictor. We prove that such an incremental procedure\nleads to convergence to the true distribution in a finite number of steps if\neach step is optimal, and convergence at an exponential rate otherwise. We also\nillustrate experimentally that this procedure addresses the problem of missing\nmodes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interaction energy between vortices of vector fields on Riemannian surfaces.   We study a variational Ginzburg-Landau type model depending on a small\nparameter $\\epsilon>0$ for (tangent) vector fields on a $2$-dimensional\nRiemannian surface. As $\\epsilon\\to 0$, the vector fields tend to be of unit\nlength and will have singular points of a (non-zero) index, called vortices.\nOur main result determines the interaction energy between these vortices as a\n$\\Gamma$-limit (at the second order) as $\\epsilon\\to 0$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uncertainty principle and geometry of the infinite Grassmann manifold.   We study the pairs of projections $$ P_If=\\chi_If ,\\ \\ Q_Jf= \\left(\\chi_J\n\\hat{f}\\right)\\check{\\ } , \\ \\ f\\in L^2(\\mathbb{R}^n), $$ where $I, J\\subset\n\\mathbb{R}^n$ are sets of finite Lebesgue measure, $\\chi_I, \\chi_J$ denote the\ncorresponding characteristic functions and $\\hat{\\ } , \\check{\\ }$ denote the\nFourier-Plancherel transformation $L^2(\\mathbb{R}^n)\\to L^2(\\mathbb{R}^n)$ and\nits inverse. These pairs of projections have been widely studied by several\nauthors in connection with the mathematical formulation of Heisenberg's\nuncertainty principle. Our study is done from a differential geometric point of\nview. We apply known results on the Finsler geometry of the Grassmann manifold\n${\\cal P}({\\cal H})$ of a Hilbert space ${\\cal H}$ to establish that there\nexists a unique minimal geodesic of ${\\cal P}({\\cal H})$, which is a curve of\nthe form $$ \\delta(t)=e^{itX_{I,J}}P_Ie^{-itX_{I,J}} $$ which joins $P_I$ and\n$Q_J$ and has length $\\pi/2$. As a consequence we obtain that if $H$ is the\nlogarithm of the Fourier-Plancherel map, then $$ \\|[H,P_I]\\|\\ge \\pi/2. $$ The\nspectrum of $X_{I,J}$ is denumerable and symmetric with respect to the origin,\nit has a smallest positive eigenvalue $\\gamma(X_{I,J})$ which satisfies $$\n\\cos(\\gamma(X_{I,J}))=\\|P_IQ_J\\|. $$",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparing anticyclotomic Selmer groups of positive coranks for congruent modular forms.   We study the variation of Iwasawa invariants of the anticyclotomic Selmer\ngroups of congruent modular forms under the Heegner hypothesis. In particular,\nwe show that even if the Selmer groups we study may have positive coranks, the\nmu-invariant vanishes for one modular form if and only if it vanishes for the\nother, and that their lambda-invariants are related by an explicit formula.\nThis generalizes results of Greenberg-Vatsal for the cyclotomic extension, as\nwell as results of Pollack-Weston and Castella-Kim-Longo for the anticyclotomic\nextension when the Selmer groups in question are cotorsion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Arbitrary order 2D virtual elements for polygonal meshes: Part II, inelastic problem.   The present paper is the second part of a twofold work, whose first part is\nreported in [3], concerning a newly developed Virtual Element Method (VEM) for\n2D continuum problems. The first part of the work proposed a study for linear\nelastic problem. The aim of this part is to explore the features of the VEM\nformulation when material nonlinearity is considered, showing that the accuracy\nand easiness of implementation discovered in the analysis inherent to the first\npart of the work are still retained. Three different nonlinear constitutive\nlaws are considered in the VEM formulation. In particular, the generalized\nviscoplastic model, the classical Mises plasticity with isotropic/kinematic\nhardening and a shape memory alloy (SMA) constitutive law are implemented. The\nversatility with respect to all the considered nonlinear material constitutive\nlaws is demonstrated through several numerical examples, also remarking that\nthe proposed 2D VEM formulation can be straightforwardly implemented as in a\nstandard nonlinear structural finite element method (FEM) framework.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Martin David Kruskal: a biographical memoir.   Martin David Kruskal was one of the most versatile theoretical physicists of\nhis generation and is distinguished for his enduring work in several different\nareas, most notably plasma physics, a memorable detour into relativity, and his\npioneering work in nonlinear waves. In the latter, together with Norman\nZabusky, he invented the concept of the soliton and, with others, developed its\napplication to classes of partial differential equations of physical\nsignificance.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Skin Lesion Classification Using Deep Multi-scale Convolutional Neural Networks.   We present a deep learning approach to the ISIC 2017 Skin Lesion\nClassification Challenge using a multi-scale convolutional neural network. Our\napproach utilizes an Inception-v3 network pre-trained on the ImageNet dataset,\nwhich is fine-tuned for skin lesion classification using two different scales\nof input images.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coalescence of Two Impurities in a Trapped One-dimensional Bose Gas.   We study the ground state of a one-dimensional (1D) trapped Bose gas with two\nmobile impurity particles. To investigate this set-up, we develop a variational\nprocedure in which the coordinates of the impurity particles are slow-like\nvariables. We validate our method using the exact results obtained for small\nsystems. Then, we discuss energies and pair densities for systems that contain\nof the order of one hundred atoms. We show that bosonic non-interacting\nimpurities cluster. To explain this clustering, we calculate and discuss\ninduced impurity-impurity potentials in a harmonic trap. Further, we compute\nthe force between static impurities in a ring ({\\it {à} la} the Casimir\nforce), and contrast the two effective potentials: the one obtained from the\nmean-field approximation, and the one due to the one-phonon exchange. Our\nformalism and findings are important for understanding (beyond the polaron\nmodel) the physics of modern 1D cold-atom systems with more than one impurity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Generating Synthetic Data for Real World Detection of DoS Attacks in the IoT.   Denial of service attacks are especially pertinent to the internet of things\nas devices have less computing power, memory and security mechanisms to defend\nagainst them. The task of mitigating these attacks must therefore be redirected\nfrom the device onto a network monitor. Network intrusion detection systems can\nbe used as an effective and efficient technique in internet of things systems\nto offload computation from the devices and detect denial of service attacks\nbefore they can cause harm. However the solution of implementing a network\nintrusion detection system for internet of things networks is not without\nchallenges due to the variability of these systems and specifically the\ndifficulty in collecting data. We propose a model-hybrid approach to model the\nscale of the internet of things system and effectively train network intrusion\ndetection systems. Through bespoke datasets generated by the model, the IDS is\nable to predict a wide spectrum of real-world attacks, and as demonstrated by\nan experiment construct more predictive datasets at a fraction of the time of\nother more standard techniques.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analytic continuation with Padé decomposition.   The ill-posed analytic continuation problem for Green's functions or\nself-energies can be done using the Padé rational polynomial approximation.\nHowever, to extract accurate results from this approximation, high precision\ninput data of the Matsubara Green's function are needed. The calculation of the\nMatsubara Green's function generally involves a Matsubara frequency summation\nwhich cannot be evaluated analytically. Numerical summation is requisite but it\nconverges slowly with the increase of the Matsubara frequency. Here we show\nthat this slow convergence problem can be significantly improved by utilizing\nthe Padé decomposition approach to replace the Matsubara frequency summation\nby a Padé frequency summation, and high precision input data can be obtained\nto successfully perform the Padé analytic continuation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "On Generalized Gibbs Ensembles with an infinite set of conserved charges.   We revisit the question of whether and how the steady states arising after\nnon-equilibrium time evolution in integrable models (and in particular in the\nXXZ spin chain) can be described by the so-called Generalized Gibbs Ensemble\n(GGE). It is known that the micro-canonical ensemble built on a complete set of\ncharges correctly describes the long-time limit of local observables, and\nrecently a canonical ensemble was built by Ilievski et. al. using particle\noccupation number operators. Here we provide an alternative construction by\nconsidering truncated GGE's (tGGE's) that only include a finite number of well\nlocalized conserved operators. It is shown that the tGGE's can approximate the\nsteady states with arbitrary precision, i.e. all physical observables are\nexactly reproduced in the infinite truncation limit. In addition, we show that\na complete canonical ensemble can in fact be built in terms of a new (discrete)\nset of charges built as linear combinations of the standard ones.\nOur general arguments are applied to concrete quench situations in the XXZ\nchain, where the initial states are simple two-site or four-site product\nstates. Depending on the quench we find that numerical results for the local\ncorrelators can be obtained with remarkable precision using truncated GGE's\nwith only 10-100 charges.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Robust MPC for tracking of nonholonomic robots with additive disturbances.   In this paper, two robust model predictive control (MPC) schemes are proposed\nfor tracking control of nonholonomic systems with bounded disturbances:\ntube-MPC and nominal robust MPC (NRMPC). In tube-MPC, the control signal\nconsists of a control action and a nonlinear feedback law based on the\ndeviation of the actual states from the states of a nominal system. It renders\nthe actual trajectory within a tube centered along the optimal trajectory of\nthe nominal system. Recursive feasibility and input-to-state stability are\nestablished and the constraints are ensured by tightening the input domain and\nthe terminal region. While in NRMPC, an optimal control sequence is obtained by\nsolving an optimization problem based on the current state, and the first\nportion of this sequence is applied to the real system in an open-loop manner\nduring each sampling period. The state of nominal system model is updated by\nthe actual state at each step, which provides additional a feedback. By\nintroducing a robust state constraint and tightening the terminal region,\nrecursive feasibility and input-to-state stability are guaranteed. Simulation\nresults demonstrate the effectiveness of both strategies proposed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Candidate exoplanet host HD131399A: a nascent Am star.   Direct imaging suggests that there is a Jovian exoplanet around the primary\nA-star in the triple-star system HD131399. We investigate a high-quality\nspectrum of the primary component HD131399A obtained with FEROS on the ESO/MPG\n2.2m telescope, aiming to characterise the star's atmospheric and fundamental\nparameters, and to determine elemental abundances at high precision and\naccuracy. The aim is to constrain the chemical composition of the birth cloud\nof the system and therefore the bulk composition of the putative planet. A\nhybrid non-local thermal equilibrium (non-LTE) model atmosphere technique is\nadopted for the quantitative spectral analysis. Comparison with the most recent\nstellar evolution models yields the fundamental parameters. The atmospheric and\nfundamental stellar parameters of HD131399A are constrained to Teff=9200+-100\nK, log g=4.37+-0.10, M=1.95+0.08-0.06 Msun, R=1.51+0.13-0.10 Rsun, and log\nL/Lsun=1.17+-0.07, locating the star on the zero-age main sequence. Non-LTE\neffects on the derived metal abundances are often smaller than 0.1dex, but can\nreach up to ~0.8dex for individual lines. The observed lighter elements up to\ncalcium are overall consistent with present-day cosmic abundances, with a C/O\nratio of 0.45$\\pm$0.07 by number, while the heavier elements show mild\noverabundances. We conclude that the birth cloud of the system had a standard\nchemical composition, but we witness the onset of the Am phenomenon in the\nslowly rotating star. We furthermore show that non-LTE analyses have the\npotential to solve the remaining discrepancies between observed abundances and\npredictions by diffusion models for Am stars. Moreover, the present case allows\nmass loss, not turbulent mixing, to be identified as the main transport process\ncompeting with diffusion in very young Am stars.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Progressive Neural Architecture Search.   We propose a new method for learning the structure of convolutional neural\nnetworks (CNNs) that is more efficient than recent state-of-the-art methods\nbased on reinforcement learning and evolutionary algorithms. Our approach uses\na sequential model-based optimization (SMBO) strategy, in which we search for\nstructures in order of increasing complexity, while simultaneously learning a\nsurrogate model to guide the search through structure space. Direct comparison\nunder the same search space shows that our method is up to 5 times more\nefficient than the RL method of Zoph et al. (2018) in terms of number of models\nevaluated, and 8 times faster in terms of total compute. The structures we\ndiscover in this way achieve state of the art classification accuracies on\nCIFAR-10 and ImageNet.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal Weighting for Exam Composition.   A problem faced by many instructors is that of designing exams that\naccurately assess the abilities of the students. Typically these exams are\nprepared several days in advance, and generic question scores are used based on\nrough approximation of the question difficulty and length. For example, for a\nrecent class taught by the author, there were 30 multiple choice questions\nworth 3 points, 15 true/false with explanation questions worth 4 points, and 5\nanalytical exercises worth 10 points. We describe a novel framework where\nalgorithms from machine learning are used to modify the exam question weights\nin order to optimize the exam scores, using the overall class grade as a proxy\nfor a student's true ability. We show that significant error reduction can be\nobtained by our approach over standard weighting schemes, and we make several\nnew observations regarding the properties of the \"good\" and \"bad\" exam\nquestions that can have impact on the design of improved future evaluation\nmethods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Enemy At the Gateways: A Game Theoretic Approach to Proxy Distribution.   A core technique used by popular proxy-based circumvention systems like Tor,\nPsiphon, and Lantern is to secretly share the IP addresses of circumvention\nproxies with the censored clients for them to be able to use such systems. For\ninstance, such secretly shared proxies are known as bridges in Tor. However, a\nkey challenge to this mechanism is the insider attack problem: censoring agents\ncan impersonate as benign censored clients in order to obtain (and then block)\nsuch secretly shared circumvention proxies.\nIn this paper, we perform a fundamental study on the problem of insider\nattack on proxy-based circumvention systems. We model the proxy distribution\nproblem using game theory, based on which we derive the optimal strategies of\nthe parties involved, i.e., the censors and circumvention system operators.\nThat is, we derive the optimal proxy distribution mechanism of a\ncircumvention system like Tor, against the censorship adversary who also takes\nhis optimal censorship strategies.\nThis is unlike previous works that design ad hoc mechanisms for proxy\ndistribution, against non-optimal censors.\nWe perform extensive simulations to evaluate our optimal proxy assignment\nalgorithm under various adversarial and network settings. Comparing with the\nstate-of-the-art prior work, we show that our optimal proxy assignment\nalgorithm has superior performance, i.e., better resistance to censorship even\nagainst the strongest censorship adversary who takes her optimal actions. We\nconclude with lessons and recommendation for the design of proxy-based\ncircumvention systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Sheet Transition Conditions (GSTCs) for a Metascreen -- A Fishnet Metasurface.   We used a multiple-scale homogenization method to derive generalized sheet\ntransition conditions (GSTCs) for electromagnetic fields at the surface of a\nmetascreen---a metasurface with a \"fishnet\" structure. These surfaces are\ncharacterized by periodically-spaced arbitrary-shaped apertures in an otherwise\nrelatively impenetrable surface. The parameters in these GSTCs are interpreted\nas effective surface susceptibilities and surface porosities, which are related\nto the geometry of the apertures that constitute the metascreen. Finally, we\nemphasize the subtle but important difference between the GSTCs required for\nmetascreens and those required for metafilms (a metasurface with a \"cermet\"\nstructure, i.e., an array of isolated (non-touching) scatterers).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Boltzmann Encoded Adversarial Machines.   Restricted Boltzmann Machines (RBMs) are a class of generative neural network\nthat are typically trained to maximize a log-likelihood objective function. We\nargue that likelihood-based training strategies may fail because the objective\ndoes not sufficiently penalize models that place a high probability in regions\nwhere the training data distribution has low probability. To overcome this\nproblem, we introduce Boltzmann Encoded Adversarial Machines (BEAMs). A BEAM is\nan RBM trained against an adversary that uses the hidden layer activations of\nthe RBM to discriminate between the training data and the probability\ndistribution generated by the model. We present experiments demonstrating that\nBEAMs outperform RBMs and GANs on multiple benchmarks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "See the Near Future: A Short-Term Predictive Methodology to Traffic Load in ITS.   The Intelligent Transportation System (ITS) targets to a coordinated traffic\nsystem by applying the advanced wireless communication technologies for road\ntraffic scheduling. Towards an accurate road traffic control, the short-term\ntraffic forecasting to predict the road traffic at the particular site in a\nshort period is often useful and important. In existing works, Seasonal\nAutoregressive Integrated Moving Average (SARIMA) model is a popular approach.\nThe scheme however encounters two challenges: 1) the analysis on related data\nis insufficient whereas some important features of data may be neglected; and\n2) with data presenting different features, it is unlikely to have one\npredictive model that can fit all situations. To tackle above issues, in this\nwork, we develop a hybrid model to improve accuracy of SARIMA. In specific, we\nfirst explore the autocorrelation and distribution features existed in traffic\nflow to revise structure of the time series model. Based on the Gaussian\ndistribution of traffic flow, a hybrid model with a Bayesian learning algorithm\nis developed which can effectively expand the application scenarios of SARIMA.\nWe show the efficiency and accuracy of our proposal using both analysis and\nexperimental studies. Using the real-world trace data, we show that the\nproposed predicting approach can achieve satisfactory performance in practice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved Kernels and Algorithms for Claw and Diamond Free Edge Deletion Based on Refined Observations.   In the {claw, diamond}-free edge deletion problem, we are given a graph $G$\nand an integer $k>0$, the question is whether there are at most $k$ edges whose\ndeletion results in a graph without claws and diamonds as induced graphs. Based\non some refined observations, we propose a kernel of $O(k^3)$ vertices and\n$O(k^4)$ edges, significantly improving the previous kernel of $O(k^{12})$\nvertices and $O(k^{24})$ edges. In addition, we derive an $O^*(3.792^k)$-time\nalgorithm for the {claw, diamond}-free edge deletion problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The singular locus of hypersurface sections containing a closed subscheme over finite fields.   We prove that there exist hypersurfaces that contain a given closed subscheme\n$Z$ of the projective space over a finite field and intersect a given smooth\nscheme $X$ off of $Z$ smoothly, if the intersection $V = Z \\cap X$ is smooth.\nFurthermore, we can give a bound on the dimension of the singular locus of the\nhypersurface section and prescribe finitely many local conditions on the\nhypersurface. This is an analogue of a Bertini theorem of Bloch over finite\nfields and is proved using Poonen's closed point sieve. We also show a similar\ntheorem for the case where $V$ is not smooth.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometric GAN.   Generative Adversarial Nets (GANs) represent an important milestone for\neffective generative models, which has inspired numerous variants seemingly\ndifferent from each other. One of the main contributions of this paper is to\nreveal a unified geometric structure in GAN and its variants. Specifically, we\nshow that the adversarial generative model training can be decomposed into\nthree geometric steps: separating hyperplane search, discriminator parameter\nupdate away from the separating hyperplane, and the generator update along the\nnormal vector direction of the separating hyperplane. This geometric intuition\nreveals the limitations of the existing approaches and leads us to propose a\nnew formulation called geometric GAN using SVM separating hyperplane that\nmaximizes the margin. Our theoretical analysis shows that the geometric GAN\nconverges to a Nash equilibrium between the discriminator and generator. In\naddition, extensive numerical results show that the superior performance of\ngeometric GAN.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Accelerating Kernel Classifiers Through Borders Mapping.   Support vector machines (SVM) and other kernel techniques represent a family\nof powerful statistical classification methods with high accuracy and broad\napplicability. Because they use all or a significant portion of the training\ndata, however, they can be slow, especially for large problems. Piecewise\nlinear classifiers are similarly versatile, yet have the additional advantages\nof simplicity, ease of interpretation and, if the number of component linear\nclassifiers is not too large, speed. Here we show how a simple, piecewise\nlinear classifier can be trained from a kernel-based classifier in order to\nimprove the classification speed. The method works by finding the root of the\ndifference in conditional probabilities between pairs of opposite classes to\nbuild up a representation of the decision boundary. When tested on 17 different\ndatasets, it succeeded in improving the classification speed of a SVM for 9 of\nthem by factors as high as 88 times or more. The method is best suited to\nproblems with continuum features data and smooth probability functions. Because\nthe component linear classifiers are built up individually from an existing\nclassifier, rather than through a simultaneous optimization procedure, the\nclassifier is also fast to train.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inertia-Constrained Pixel-by-Pixel Nonnegative Matrix Factorisation: a Hyperspectral Unmixing Method Dealing with Intra-class Variability.   Blind source separation is a common processing tool to analyse the\nconstitution of pixels of hyperspectral images. Such methods usually suppose\nthat pure pixel spectra (endmembers) are the same in all the image for each\nclass of materials. In the framework of remote sensing, such an assumption is\nno more valid in the presence of intra-class variabilities due to illumination\nconditions, weathering, slight variations of the pure materials, etc... In this\npaper, we first describe the results of investigations highlighting intra-class\nvariability measured in real images. Considering these results, a new\nformulation of the linear mixing model is presented leading to two new methods.\nUnconstrained Pixel-by-pixel NMF (UP-NMF) is a new blind source separation\nmethod based on the assumption of a linear mixing model, which can deal with\nintra-class variability. To overcome UP-NMF limitations an extended method is\nproposed, named Inertia-constrained Pixel-by-pixel NMF (IP-NMF). For each\nsensed spectrum, these extended versions of NMF extract a corresponding set of\nsource spectra. A constraint is set to limit the spreading of each source's\nestimates in IP-NMF. The methods are tested on a semi-synthetic data set built\nwith spectra extracted from a real hyperspectral image and then numerically\nmixed. We thus demonstrate the interest of our methods for realistic source\nvariabilities. Finally, IP-NMF is tested on a real data set and it is shown to\nyield better performance than state of the art methods.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "When Can Neural Networks Learn Connected Decision Regions?.   Previous work has questioned the conditions under which the decision regions\nof a neural network are connected and further showed the implications of the\ncorresponding theory to the problem of adversarial manipulation of classifiers.\nIt has been proven that for a class of activation functions including leaky\nReLU, neural networks having a pyramidal structure, that is no layer has more\nhidden units than the input dimension, produce necessarily connected decision\nregions. In this paper, we advance this important result by further developing\nthe sufficient and necessary conditions under which the decision regions of a\nneural network are connected. We then apply our framework to overcome the\nlimits of existing work and further study the capacity to learn connected\nregions of neural networks for a much wider class of activation functions\nincluding those widely used, namely ReLU, sigmoid, tanh, softlus, and\nexponential linear function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "AspEm: Embedding Learning by Aspects in Heterogeneous Information Networks.   Heterogeneous information networks (HINs) are ubiquitous in real-world\napplications. Due to the heterogeneity in HINs, the typed edges may not fully\nalign with each other. In order to capture the semantic subtlety, we propose\nthe concept of aspects with each aspect being a unit representing one\nunderlying semantic facet. Meanwhile, network embedding has emerged as a\npowerful method for learning network representation, where the learned\nembedding can be used as features in various downstream applications.\nTherefore, we are motivated to propose a novel embedding learning\nframework---AspEm---to preserve the semantic information in HINs based on\nmultiple aspects. Instead of preserving information of the network in one\nsemantic space, AspEm encapsulates information regarding each aspect\nindividually. In order to select aspects for embedding purpose, we further\ndevise a solution for AspEm based on dataset-wide statistics. To corroborate\nthe efficacy of AspEm, we conducted experiments on two real-words datasets with\ntwo types of applications---classification and link prediction. Experiment\nresults demonstrate that AspEm can outperform baseline network embedding\nlearning methods by considering multiple aspects, where the aspects can be\nselected from the given HIN in an unsupervised manner.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scalable Inference for Space-Time Gaussian Cox Processes.   The log-Gaussian Cox process is a flexible and popular class of point pattern\nmodels for capturing spatial and space-time dependence for point patterns.\nModel fitting requires approximation of stochastic integrals which is\nimplemented through discretization over the domain of interest. With fine scale\ndiscretization, inference based on Markov chain Monte Carlo is computationally\nburdensome because of the cost of matrix decompositions and storage, such as\nthe Cholesky, for high dimensional covariance matrices associated with latent\nGaussian variables. This article addresses these computational bottlenecks by\ncombining two recent developments: (i) a data augmentation strategy that has\nbeen proposed for space-time Gaussian Cox processes that is based on exact\nBayesian inference and does not require fine grid approximations for infinite\ndimensional integrals, and (ii) a recently developed family of\nsparsity-inducing Gaussian processes, called nearest-neighbor Gaussian\nprocesses, to avoid expensive matrix computations. Our inference is delivered\nwithin the fully model-based Bayesian paradigm and does not sacrifice the\nrichness of traditional log-Gaussian Cox processes. We apply our method to\ncrime event data in San Francisco and investigate the recovery of the intensity\nsurface.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ALMA Observations of Gas-Rich Galaxies in z~1.6 Galaxy Clusters: Evidence for Higher Gas Fractions in High-Density Environments.   We present ALMA CO (2-1) detections in 11 gas-rich cluster galaxies at z~1.6,\nconstituting the largest sample of molecular gas measurements in z>1.5 clusters\nto date. The observations span three galaxy clusters, derived from the Spitzer\nAdaptation of the Red-sequence Cluster Survey. We augment the >5sigma\ndetections of the CO (2-1) fluxes with multi-band photometry, yielding stellar\nmasses and infrared-derived star formation rates, to place some of the first\nconstraints on molecular gas properties in z~1.6 cluster environments. We\nmeasure sizable gas reservoirs of 0.5-2x10^11 solar masses in these objects,\nwith high gas fractions and long depletion timescales, averaging 62% and 1.4\nGyr, respectively. We compare our cluster galaxies to the scaling relations of\nthe coeval field, in the context of how gas fractions and depletion timescales\nvary with respect to the star-forming main sequence. We find that our cluster\ngalaxies lie systematically off the field scaling relations at z=1.6 toward\nenhanced gas fractions, at a level of ~4sigma, but have consistent depletion\ntimescales. Exploiting CO detections in lower-redshift clusters from the\nliterature, we investigate the evolution of the gas fraction in cluster\ngalaxies, finding it to mimic the strong rise with redshift in the field. We\nemphasize the utility of detecting abundant gas-rich galaxies in high-redshift\nclusters, deeming them as crucial laboratories for future statistical studies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ca II K 1-A Emission Index Composites.   We describe here a procedure to combine measurements in the 393.37 nm Ca II K\nspectral line taken at different observatories. Measurements from the National\nSolar Observatory (NSO) Integrated Sunlight Spectrometer (ISS) on the Synoptic\nOptical Long-term Investigations of the Sun (SOLIS) telescope, the NSO/Sac Peak\nCa II K-Line Monitoring Program, and Ca II K filtergrams from Kodaikanal Solar\nObservatory (KKL) are merged together to create a pair of composites of the Ca\nII K 1-A emission index. These composites are publicly available from the SOLIS\nwebsite at this http URL.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Flow Fields: Dense Correspondence Fields for Highly Accurate Large Displacement Optical Flow Estimation.   Modern large displacement optical flow algorithms usually use an\ninitialization by either sparse descriptor matching techniques or dense\napproximate nearest neighbor fields. While the latter have the advantage of\nbeing dense, they have the major disadvantage of being very outlier-prone as\nthey are not designed to find the optical flow, but the visually most similar\ncorrespondence. In this article we present a dense correspondence field\napproach that is much less outlier-prone and thus much better suited for\noptical flow estimation than approximate nearest neighbor fields. Our approach\ndoes not require explicit regularization, smoothing (like median filtering) or\na new data term. Instead we solely rely on patch matching techniques and a\nnovel multi-scale matching strategy. We also present enhancements for outlier\nfiltering. We show that our approach is better suited for large displacement\noptical flow estimation than modern descriptor matching techniques. We do so by\ninitializing EpicFlow with our approach instead of their originally used\nstate-of-the-art descriptor matching technique. We significantly outperform the\noriginal EpicFlow on MPI-Sintel, KITTI 2012, KITTI 2015 and Middlebury. In this\nextended article of our former conference publication we further improve our\napproach in matching accuracy as well as runtime and present more experiments\nand insights.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using data science as a community advocacy tool to promote equity in urban renewal programs: An analysis of Atlanta's Anti-Displacement Tax Fund.   Cities across the United States are undergoing great transformation and urban\ngrowth. Data and data analysis has become an essential element of urban\nplanning as cities use data to plan land use and development. One great\nchallenge is to use the tools of data science to promote equity along with\ngrowth. The city of Atlanta is an example site of large-scale urban renewal\nthat aims to engage in development without displacement. On the Westside of\ndowntown Atlanta, the construction of the new Mercedes-Benz Stadium and the\nconversion of an underutilized rail-line into a multi-use trail may result in\nincreased property values. In response to community residents' concerns and a\ncommitment to development without displacement, the city and philanthropic\npartners announced an Anti-Displacement Tax Fund to subsidize future property\ntax increases of owner occupants for the next twenty years. To achieve greater\ntransparency, accountability, and impact, residents expressed a desire for a\ntool that would help them determine eligibility and quantify this commitment.\nIn support of this goal, we use machine learning techniques to analyze\nhistorical tax assessment and predict future tax assessments. We then apply\neligibility estimates to our predictions to estimate the total cost for the\nfirst seven years of the program. These forecasts are also incorporated into an\ninteractive tool for community residents to determine their eligibility for the\nfund and the expected increase in their home value over the next seven years.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved Convergence Rates for Distributed Resource Allocation.   In this paper, we develop a class of decentralized algorithms for solving a\nconvex resource allocation problem in a network of $n$ agents, where the agent\nobjectives are decoupled while the resource constraints are coupled. The agents\ncommunicate over a connected undirected graph, and they want to collaboratively\ndetermine a solution to the overall network problem, while each agent only\ncommunicates with its neighbors. We first study the connection between the\ndecentralized resource allocation problem and the decentralized consensus\noptimization problem. Then, using a class of algorithms for solving consensus\noptimization problems, we propose a novel class of decentralized schemes for\nsolving resource allocation problems in a distributed manner. Specifically, we\nfirst propose an algorithm for solving the resource allocation problem with an\n$o(1/k)$ convergence rate guarantee when the agents' objective functions are\ngenerally convex (could be nondifferentiable) and per agent local convex\nconstraints are allowed; We then propose a gradient-based algorithm for solving\nthe resource allocation problem when per agent local constraints are absent and\nshow that such scheme can achieve geometric rate when the objective functions\nare strongly convex and have Lipschitz continuous gradients. We have also\nprovided scalability/network dependency analysis. Based on these two\nalgorithms, we have further proposed a gradient projection-based algorithm\nwhich can handle smooth objective and simple constraints more efficiently.\nNumerical experiments demonstrates the viability and performance of all the\nproposed algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A novel procedure for the identification of chaos in complex biological systems.   We demonstrate the presence of chaos in stochastic simulations that are\nwidely used to study biodiversity in nature. The investigation deals with a set\nof three distinct species that evolve according to the standard rules of\nmobility, reproduction and predation, with predation following the cyclic rules\nof the popular rock, paper and scissors game. The study uncovers the\npossibility to distinguish between time evolutions that start from slightly\ndifferent initial states, guided by the Hamming distance which heuristically\nunveils the chaotic behavior. The finding opens up a quantitative approach that\nrelates the correlation length to the average density of maxima of a typical\nspecies, and an ensemble of stochastic simulations is implemented to support\nthe procedure. The main result of the work shows how a single and simple\nexperimental realization that counts the density of maxima associated with the\nchaotic evolution of the species serves to infer its correlation length. We use\nthe result to investigate others distinct complex systems, one dealing with a\nset of differential equations that can be used to model a diversity of natural\nand artificial chaotic systems, and another one, focusing on the ocean water\nlevel.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "How hard is it to cross the room? -- Training (Recurrent) Neural Networks to steer a UAV.   This work explores the feasibility of steering a drone with a (recurrent)\nneural network, based on input from a forward looking camera, in the context of\na high-level navigation task. We set up a generic framework for training a\nnetwork to perform navigation tasks based on imitation learning. It can be\napplied to both aerial and land vehicles. As a proof of concept we apply it to\na UAV (Unmanned Aerial Vehicle) in a simulated environment, learning to cross a\nroom containing a number of obstacles. So far only feedforward neural networks\n(FNNs) have been used to train UAV control. To cope with more complex tasks, we\npropose the use of recurrent neural networks (RNN) instead and successfully\ntrain an LSTM (Long-Short Term Memory) network for controlling UAVs. Vision\nbased control is a sequential prediction problem, known for its highly\ncorrelated input data. The correlation makes training a network hard,\nespecially an RNN. To overcome this issue, we investigate an alternative\nsampling method during training, namely window-wise truncated backpropagation\nthrough time (WW-TBPTT). Further, end-to-end training requires a lot of data\nwhich often is not available. Therefore, we compare the performance of\nretraining only the Fully Connected (FC) and LSTM control layers with networks\nwhich are trained end-to-end. Performing the relatively simple task of crossing\na room already reveals important guidelines and good practices for training\nneural control networks. Different visualizations help to explain the behavior\nlearned.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strong Functional Representation Lemma and Applications to Coding Theorems.   This paper shows that for any random variables $X$ and $Y$, it is possible to\nrepresent $Y$ as a function of $(X,Z)$ such that $Z$ is independent of $X$ and\n$I(X;Z|Y)\\le\\log(I(X;Y)+1)+4$ bits. We use this strong functional\nrepresentation lemma (SFRL) to establish a bound on the rate needed for\none-shot exact channel simulation for general (discrete or continuous) random\nvariables, strengthening the results by Harsha et al. and Braverman and Garg,\nand to establish new and simple achievability results for one-shot\nvariable-length lossy source coding, multiple description coding and Gray-Wyner\nsystem. We also show that the SFRL can be used to reduce the channel with state\nnoncausally known at the encoder to a point-to-point channel, which provides a\nsimple achievability proof of the Gelfand-Pinsker theorem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Near-Perfect Conversion of a Propagating Plane Wave into a Surface Wave Using Metasurfaces.   In this paper, theoretical and numerical studies of perfect/nearly-perfect\nconversion of a plane wave into a surface wave are presented. The problem of\ndetermining the electromagnetic properties of an inhomogeneous lossless\nboundary which would fully transform an incident plane wave into a surface wave\npropagating along the boundary is considered. An approximate field solution\nwhich produces a slowly growing surface wave and satisfies the energy\nconservation law is discussed and numerically demonstrated. The results of the\nstudy are of great importance for the future development of such devices as\nperfect leaky-wave antennas and can potentially lead to many novel\napplications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Radiomics strategies for risk assessment of tumour failure in head-and-neck cancer.   Quantitative extraction of high-dimensional mineable data from medical images\nis a process known as radiomics. Radiomics is foreseen as an essential\nprognostic tool for cancer risk assessment and the quantification of\nintratumoural heterogeneity. In this work, 1615 radiomic features (quantifying\ntumour image intensity, shape, texture) extracted from pre-treatment FDG-PET\nand CT images of 300 patients from four different cohorts were analyzed for the\nrisk assessment of locoregional recurrences (LR) and distant metastases (DM) in\nhead-and-neck cancer. Prediction models combining radiomic and clinical\nvariables were constructed via random forests and imbalance-adjustment\nstrategies using two of the four cohorts. Independent validation of the\nprediction and prognostic performance of the models was carried out on the\nother two cohorts (LR: AUC = 0.69 and CI = 0.67; DM: AUC = 0.86 and CI = 0.88).\nFurthermore, the results obtained via Kaplan-Meier analysis demonstrated the\npotential of radiomics for assessing the risk of specific tumour outcomes using\nmultiple stratification groups. This could have important clinical impact,\nnotably by allowing for a better personalization of chemo-radiation treatments\nfor head-and-neck cancer patients from different risk groups.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Synergies between Asteroseismology and Exoplanetary Science.   Over the past decade asteroseismology has become a powerful method to\nsystematically characterize host stars and dynamical architectures of exoplanet\nsystems. In this contribution I review current key synergies between\nasteroseismology and exoplanetary science such as the precise determination of\nplanet radii and ages, the measurement of orbital eccentricities, stellar\nobliquities and their impact on hot Jupiter formation theories, and the\nimportance of asteroseismology on spectroscopic analyses of exoplanet hosts. I\nalso give an outlook on future synergies such as the characterization of\nsub-Neptune-size planets orbiting solar-type stars, the study of planet\npopulations orbiting evolved stars, and the determination of ages of\nintermediate-mass stars hosting directly imaged planets.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Expropriations, Property Confiscations and New Offshore Entities: Evidence from the Panama Papers.   Using the Panama Papers, we show that the beginning of media reporting on\nexpropriations and property confiscations in a country increases the\nprobability that offshore entities are incorporated by agents from the same\ncountry in the same month. This result is robust to the use of country-year\nfixed effects and the exclusion of tax havens. Further analysis shows that the\neffect is driven by countries with non-corrupt and effective governments, which\nsupports the notion that offshore entities are incorporated when reasonably\nwell-intended and well-functioning governments become more serious about\nfighting organized crime by confiscating proceeds of crime.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Efficient anchor loss suppression in coupled near-field optomechanical resonators.   Elastic dissipation through radiation towards the substrate is a major loss\nchannel in micro- and nanomechanical resonators. Engineering the coupling of\nthese resonators with optical cavities further complicates and constrains the\ndesign of low-loss optomechanical devices. In this work we rely on the coherent\ncancellation of mechanical radiation to demonstrate material and surface\nabsorption limited silicon near-field optomechanical resonators oscillating at\ntens of MHz. The effectiveness of our dissipation suppression scheme is\ninvestigated at room and cryogenic temperatures. While at room temperature we\ncan reach a maximum quality factor of 7.61k ($fQ$-product of the order of\n$10^{11}$~Hz), at 22~K the quality factor increases to 37k, resulting in a\n$fQ$-product of $2\\times10^{12}$~Hz.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "LAMOST Spectroscopic Survey of the Galactic Anticentre (LSS-GAC): the second release of value-added catalogues.   We present the second release of value-added catalogues of the LAMOST\nSpectroscopic Survey of the Galactic Anticentre (LSS-GAC DR2). The catalogues\npresent values of radial velocity $V_{\\rm r}$, atmospheric parameters ---\neffective temperature $T_{\\rm eff}$, surface gravity log$g$, metallicity\n[Fe/H], $\\alpha$-element to iron (metal) abundance ratio [$\\alpha$/Fe]\n([$\\alpha$/M]), elemental abundances [C/H] and [N/H], and absolute magnitudes\n${\\rm M}_V$ and ${\\rm M}_{K_{\\rm s}}$ deduced from 1.8 million spectra of 1.4\nmillion unique stars targeted by the LSS-GAC since September 2011 until June\n2014. The catalogues also give values of interstellar reddening, distance and\norbital parameters determined with a variety of techniques, as well as proper\nmotions and multi-band photometry from the far-UV to the mid-IR collected from\nthe literature and various surveys. Accuracies of radial velocities reach\n5kms$^{-1}$ for late-type stars, and those of distance estimates range between\n10 -- 30 per cent, depending on the spectral signal-to-noise ratios. Precisions\nof [Fe/H], [C/H] and [N/H] estimates reach 0.1dex, and those of [$\\alpha$/Fe]\nand [$\\alpha$/M] reach 0.05dex. The large number of stars, the contiguous sky\ncoverage, the simple yet non-trivial target selection function and the robust\nestimates of stellar radial velocities and atmospheric parameters, distances\nand elemental abundances, make the catalogues a valuable data set to study the\nstructure and evolution of the Galaxy, especially the solar-neighbourhood and\nthe outer disk.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A New Framework for Synthetic Aperture Sonar Micronavigation.   Synthetic aperture imaging systems achieve constant azimuth resolution by\ncoherently summating the observations acquired along the aperture path. At this\naim, their locations have to be known with subwavelength accuracy. In\nunderwater Synthetic Aperture Sonar (SAS), the nature of propagation and\nnavigation in water makes the retrieval of this information challenging.\nInertial sensors have to be employed in combination with signal processing\ntechniques, which are usually referred to as micronavigation. In this paper we\npropose a novel micronavigation approach based on the minimization of an error\nfunction between two contiguous pings having some mutual information. This\nerror is obtained by comparing the vector space intersections between the pings\northogonal projectors. The effectiveness and generality of the proposed\napproach is demonstrated by means of simulations and by means of an experiment\nperformed in a controlled environment.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Flux-Rope Twist in Eruptive Flares and CMEs: due to Zipper and Main-Phase Reconnection.   The nature of three-dimensional reconnection when a twisted flux tube erupts\nduring an eruptive flare or coronal mass ejection is considered. The\nreconnection has two phases: first of all, 3D \"zipper reconnection\" propagates\nalong the initial coronal arcade, parallel to the polarity inversion line\n(PIL), then subsequent quasi-2D \"main phase reconnection\" in the low corona\naround a flux rope during its eruption produces coronal loops and chromospheric\nribbons that propagate away from the PIL in a direction normal to it.\nOne scenario starts with a sheared arcade: the zipper reconnection creates a\ntwisted flux rope of roughly one turn ($2\\pi$ radians of twist), and then main\nphase reconnection builds up the bulk of the erupting flux rope with a\nrelatively uniform twist of a few turns. A second scenario starts with a\npre-existing flux rope under the arcade. Here the zipper phase can create a\ncore with many turns that depend on the ratio of the magnetic fluxes in the\nnewly formed flare ribbons and the new flux rope. Main phase reconnection then\nadds a layer of roughly uniform twist to the twisted central core. Both phases\nand scenarios are modeled in a simple way that assumes the initial magnetic\nflux is fragmented along the PIL. The model uses conservation of magnetic\nhelicity and flux, together with equipartition of magnetic helicity, to deduce\nthe twist of the erupting flux rope in terms the geometry of the initial\nconfiguration.\nInterplanetary observations show some flux ropes have a fairly uniform twist,\nwhich could be produced when the zipper phase and any pre-existing flux rope\npossess small or moderate twist (up to one or two turns). Other interplanetary\nflux ropes have highly twisted cores (up to five turns), which could be\nproduced when there is a pre-existing flux rope and an active zipper phase that\ncreates substantial extra twist.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Pile-up Reduction, Bayesian Decomposition and Applications of Silicon Drift Detectors at LCLS.   Silicon drift detectors (SDDs) revolutionized spectroscopy in fields as\ndiverse as geology and dentistry. For a subset of experiments at ultra-fast,\nx-ray free-electron lasers (FELs), SDDs can make substantial contributions.\nOften the unknown spectrum is interesting, carrying science data, or the\nbackground measurement is useful to identify unexpected signals. Many\nmeasurements involve only several discrete photon energies known a priori. We\ndesigned a pulse function (a combination of gradual step and exponential decay\nfunction) and demonstrated that for individual pulses the signal amplitude,\npeaking time, and pulse amplitude are interrelated and the signal amplitude and\npeaking time are obtained for each pulse by fitting. Avoiding pulse shaping\nreduced peaking times to tens of nanoseconds, resulting in reduced pulse\npile-up and allowing decomposition of remaining pulse pile-up at photon\nseparation times down to 100~ns while yielding time-of-arrival information with\nprecision of 10~nanoseconds. At pulsed sources or high photon rates, photon\npile-up still occurs. We showed that the area of one photon peaks is not\nsuitable for estimating high photon rates while pile-up spectrum fitting is\nrelatively simple and preferable to pile-up spectrum deconvolution. We\ndeveloped a photon pile-up model for constant intensity sources, extended it to\nvariable intensity sources (typical for FELs) and used it to fit a complex\npile-up spectrum, demonstrating its accuracy. Based on the pile-up model, we\ndeveloped a Bayesian pile-up decomposition method that allows decomposing\npile-up of single events with up to 6 photons from 6 monochromatic lines with\n99% accuracy. The usefulness of SDDs will continue into the x-ray FEL era of\nscience. Their successors, the ePixS hybrid pixel detectors, already offer\nhundreds of pixels, each with similar performance to an SDD, in a compact,\nrobust and affordable package.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Low-shot learning with large-scale diffusion.   This paper considers the problem of inferring image labels from images when\nonly a few annotated examples are available at training time. This setup is\noften referred to as low-shot learning, where a standard approach is to\nre-train the last few layers of a convolutional neural network learned on\nseparate classes for which training examples are abundant. We consider a\nsemi-supervised setting based on a large collection of images to support label\npropagation. This is possible by leveraging the recent advances on large-scale\nsimilarity graph construction.\nWe show that despite its conceptual simplicity, scaling label propagation up\nto hundred millions of images leads to state of the art accuracy in the\nlow-shot learning regime.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ensemble Methods for Personalized E-Commerce Search Challenge at CIKM Cup 2016.   Personalized search has been a hot research topic for many years and has been\nwidely used in e-commerce. This paper describes our solution to tackle the\nchallenge of personalized e-commerce search at CIKM Cup 2016. The goal of this\ncompetition is to predict search relevance and re-rank the result items in SERP\naccording to the personalized search, browsing and purchasing preferences.\nBased on a detailed analysis of the provided data, we extract three different\ntypes of features, i.e., statistic features, query-item features and session\nfeatures. Different models are used on these features, including logistic\nregression, gradient boosted decision trees, rank svm and a novel deep match\nmodel. With the blending of multiple models, a stacking ensemble model is built\nto integrate the output of individual models and produce a more accurate\nprediction result. Based on these efforts, our solution won the champion of the\ncompetition on all the evaluation metrics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Leaf Space Isometries of Singular Riemannian Foliations and Their Spectral Properties.   In this paper, the authors consider leaf spaces of singular Riemannian\nfoliations $\\mathcal{F}$ on compact manifolds $M$ and the associated\n$\\mathcal{F}$-basic spectrum on $M$, $spec_B(M, \\mathcal{F}),$ counted with\nmultiplicities. Recently, a notion of smooth isometry $\\varphi:\nM_1/\\mathcal{F}_1\\rightarrow M_2/\\mathcal{F}_2$ between the leaf spaces of such\nsingular Riemannian foliations $(M_1,\\mathcal{F}_1)$ and $(M_2,\\mathcal{F}_2)$\nhas appeared in the literature. In this paper, the authors provide an example\nto show that the existence a smooth isometry of leaf spaces as above is not\nsufficient to guarantee the equality of $spec_B(M_1,\\mathcal{F}_1)$ and\n$spec_B(M_2,\\mathcal{F}_2).$ The authors then prove that if some additional\nconditions involving the geometry of the leaves are satisfied, then the\nequality of $spec_B(M_1,\\mathcal{F}_1)$ and $spec_B(M_2,\\mathcal{F}_2)$ is\nguaranteed. Consequences and applications to orbifold spectral theory,\nisometric group actions, and their reductions are also explored.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phylogenetic networks that are their own fold-ups.   Phylogenetic networks are becoming of increasing interest to evolutionary\nbiologists due to their ability to capture complex non-treelike evolutionary\nprocesses. From a combinatorial point of view, such networks are certain types\nof rooted directed acyclic graphs whose leaves are labelled by, for example,\nspecies. A number of mathematically interesting classes of phylogenetic\nnetworks are known. These include the biologically relevant class of stable\nphylogenetic networks whose members are defined via certain fold-up and un-fold\noperations that link them with concepts arising within the theory of, for\nexample, graph fibrations. Despite this exciting link, the structural\ncomplexity of stable phylogenetic networks is still relatively poorly\nunderstood. Employing the popular tree-based, reticulation-visible, and\ntree-child properties which allow one to gauge this complexity in one way or\nanother, we provide novel characterizations for when a stable phylogenetic\nnetwork satisfies either one of these three properties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dirichlet's theorem and Jacobsthal's function.   If $a$ and $d$ are relatively prime, we refer to the set of integers\ncongruent to $a$ mod $d$ as an `eligible' arithmetic progression. A theorem of\nDirichlet says that every eligible arithmetic progression contains infinitely\nmany primes; the theorem follows from the assertion that every eligible\narithmetic progression contains at least one prime. The Jacobsthal function\n$g(n)$ is defined as the smallest positive integer such that every sequence of\n$g(n)$ consecutive integers contains an integer relatively prime to $n$. In\nthis paper, we show by a combinatorial argument that every eligible arithmetic\nprogression with $d\\le76$ contains at least one prime, and we show that certain\nplausible bounds on the Jacobsthal function of primorials would imply that\nevery eligible arithmetic progression contains at least one prime. That is,\ncertain plausible bounds on the Jacobsthal function would lead to an elementary\nproof of Dirichlet's theorem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Compactness of the resolvent for the Witten Laplacian.   In this paper we consider the Witten Laplacian on 0-forms and give sufficient\nconditions under which the Witten Laplacian admits a compact resolvent. These\nconditions are imposed on the potential itself, involving the control of high\norder derivatives by lower ones, as well as the control of the positive\neigenvalues of the Hessian matrix. This compactness criterion for resolvent is\ninspired by the one for the Fokker-Planck operator. Our method relies on the\nnilpotent group techniques developed by Helffer-Nourrigat [Hypoellipticité\nmaximale pour des opérateurs polynômes de champs de vecteurs, 1985].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Electric Vehicle Charging Station Placement Method for Urban Areas.   For accommodating more electric vehicles (EVs) to battle against fossil fuel\nemission, the problem of charging station placement is inevitable and could be\ncostly if done improperly. Some researches consider a general setup, using\nconditions such as driving ranges for planning. However, most of the EV growths\nin the next decades will happen in the urban area, where driving ranges is not\nthe biggest concern. For such a need, we consider several practical aspects of\nurban systems, such as voltage regulation cost and protection device upgrade\nresulting from the large integration of EVs. Notably, our diversified objective\ncan reveal the trade-off between different factors in different cities\nworldwide. To understand the global optimum of large-scale analysis, we add\nconstraint one-by-one to see how to preserve the problem convexity. Our\nsensitivity analysis before and after convexification shows that our approach\nis not only universally applicable but also has a small approximation error for\nprioritizing the most urgent constraint in a specific setup. Finally, numerical\nresults demonstrate the trade-off, the relationship between different factors\nand the global objective, and the small approximation error. A unique\nobservation in this study shows the importance of incorporating the protection\ndevice upgrade in urban system planning on charging stations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Formation of coalition structures as a non-cooperative game.   Traditionally social sciences are interested in structuring people in\nmultiple groups based on their individual preferences. This pa- per suggests an\napproach to this problem in the framework of a non- cooperative game theory.\nDefinition of a suggested finite game includes a family of nested simultaneous\nnon-cooperative finite games with intra- and inter-coalition externalities. In\nthis family, games differ by the size of maximum coalition, partitions and by\ncoalition structure formation rules. A result of every game consists of\npartition of players into coalitions and a payoff? profiles for every player.\nEvery game in the family has an equilibrium in mixed strategies with possibly\nmore than one coalition. The results of the game differ from those\nconventionally discussed in cooperative game theory, e.g. the Shapley value,\nstrong Nash, coalition-proof equilibrium, core, kernel, nucleolus. We discuss\nthe following applications of the new game: cooperation as an allocation in one\ncoalition, Bayesian games, stochastic games and construction of a\nnon-cooperative criterion of coalition structure stability for studying focal\npoints.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The QLBS Q-Learner Goes NuQLear: Fitted Q Iteration, Inverse RL, and Option Portfolios.   The QLBS model is a discrete-time option hedging and pricing model that is\nbased on Dynamic Programming (DP) and Reinforcement Learning (RL). It combines\nthe famous Q-Learning method for RL with the Black-Scholes (-Merton) model's\nidea of reducing the problem of option pricing and hedging to the problem of\noptimal rebalancing of a dynamic replicating portfolio for the option, which is\nmade of a stock and cash. Here we expand on several NuQLear (Numerical\nQ-Learning) topics with the QLBS model. First, we investigate the performance\nof Fitted Q Iteration for a RL (data-driven) solution to the model, and\nbenchmark it versus a DP (model-based) solution, as well as versus the BSM\nmodel. Second, we develop an Inverse Reinforcement Learning (IRL) setting for\nthe model, where we only observe prices and actions (re-hedges) taken by a\ntrader, but not rewards. Third, we outline how the QLBS model can be used for\npricing portfolios of options, rather than a single option in isolation, thus\nproviding its own, data-driven and model independent solution to the (in)famous\nvolatility smile problem of the Black-Scholes model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Monte Carlo modified profile likelihood in models for clustered data.   The main focus of the analysts who deal with clustered data is usually not on\nthe clustering variables, and hence the group-specific parameters are treated\nas nuisance. If a fixed effects formulation is preferred and the total number\nof clusters is large relative to the single-group sizes, classical frequentist\ntechniques relying on the profile likelihood are often misleading. The use of\nalternative tools, such as modifications to the profile likelihood or\nintegrated likelihoods, for making accurate inference on a parameter of\ninterest can be complicated by the presence of nonstandard modelling and/or\nsampling assumptions. We show here how to employ Monte Carlo simulation in\norder to approximate the modified profile likelihood in some of these\nunconventional frameworks. The proposed solution is widely applicable and is\nshown to retain the usual properties of the modified profile likelihood. The\napproach is examined in two instances particularly relevant in applications,\ni.e. missing-data models and survival models with unspecified censoring\ndistribution. The effectiveness of the proposed solution is validated via\nsimulation studies and two clinical trial applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparison of methods for early-readmission prediction in a high-dimensional heterogeneous covariates and time-to-event outcome framework.   Background: Choosing the most performing method in terms of outcome\nprediction or variables selection is a recurring problem in prognosis studies,\nleading to many publications on methods comparison. But some aspects have\nreceived little attention. First, most comparison studies treat prediction\nperformance and variable selection aspects separately. Second, methods are\neither compared within a binary outcome setting (based on an arbitrarily chosen\ndelay) or within a survival setting, but not both. In this paper, we propose a\ncomparison methodology to weight up those different settings both in terms of\nprediction and variables selection, while incorporating advanced machine\nlearning strategies. Methods: Using a high-dimensional case study on a\nsickle-cell disease (SCD) cohort, we compare 8 statistical methods. In the\nbinary outcome setting, we consider logistic regression (LR), support vector\nmachine (SVM), random forest (RF), gradient boosting (GB) and neural network\n(NN); while on the survival analysis setting, we consider the Cox Proportional\nHazards (PH), the CURE and the C-mix models. We then compare performances of\nall methods both in terms of risk prediction and variable selection, with a\nfocus on the use of Elastic-Net regularization technique. Results: Among all\nassessed statistical methods assessed, the C-mix model yields the better\nperformances in both the two considered settings, as well as interesting\ninterpretation aspects. There is some consistency in selected covariates across\nmethods within a setting, but not much across the two settings. Conclusions: It\nappears that learning withing the survival setting first, and then going back\nto a binary prediction using the survival estimates significantly enhance\nbinary predictions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asteroid 2017 FZ2 et al.: signs of recent mass-shedding from YORP?.   The first direct detection of the asteroidal YORP effect, a phenomenon that\nchanges the spin states of small bodies due to thermal reemission of sunlight\nfrom their surfaces, was obtained for (54509) YORP 2000 PH5. Such an alteration\ncan slowly increase the rotation rate of asteroids, driving them to reach their\nfission limit and causing their disruption. This process can produce binaries\nand unbound asteroid pairs. Secondary fission opens the door to the eventual\nformation of transient but genetically-related groupings. Here, we show that\nthe small near-Earth asteroid (NEA) 2017 FZ2 was a co-orbital of our planet of\nthe quasi-satellite type prior to their close encounter on 2017 March 23.\nBecause of this flyby with the Earth, 2017 FZ2 has become a non-resonant NEA.\nOur N-body simulations indicate that this object may have experienced\nquasi-satellite engagements with our planet in the past and it may return as a\nco-orbital in the future. We identify a number of NEAs that follow similar\npaths, the largest named being YORP, which is also an Earth's co-orbital. An\napparent excess of NEAs moving in these peculiar orbits is studied within the\nframework of two orbit population models. A possibility that emerges from this\nanalysis is that such an excess, if real, could be the result of mass shedding\nfrom YORP itself or a putative larger object that produced YORP. Future\nspectroscopic observations of 2017 FZ2 during its next visit in 2018 (and of\nrelated objects when feasible) may be able to confirm or reject this\ninterpretation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Generative Model for Exploring Structure Regularities in Attributed Networks.   Many real-world networks known as attributed networks contain two types of\ninformation: topology information and node attributes. It is a challenging task\non how to use these two types of information to explore structural\nregularities. In this paper, by characterizing potential relationship between\nlink communities and node attributes, a principled statistical model named\nPSB_PG that generates link topology and node attributes is proposed. This model\nfor generating links is based on the stochastic blockmodels following a Poisson\ndistribution. Therefore, it is capable of detecting a wide range of network\nstructures including community structures, bipartite structures and other\nmixture structures. The model for generating node attributes assumes that node\nattributes are high dimensional and sparse and also follow a Poisson\ndistribution. This makes the model be uniform and the model parameters can be\ndirectly estimated by expectation-maximization (EM) algorithm. Experimental\nresults on artificial networks and real networks containing various structures\nhave shown that the proposed model PSB_PG is not only competitive with the\nstate-of-the-art models, but also provides good semantic interpretation for\neach community via the learned relationship between the community and its\nrelated attributes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Conversion of Mersenne Twister to double-precision floating-point numbers.   The 32-bit Mersenne Twister generator MT19937 is a widely used random number\ngenerator. To generate numbers with more than 32 bits in bit length, and\nparticularly when converting into 53-bit double-precision floating-point\nnumbers in $[0,1)$ in the IEEE 754 format, the typical implementation\nconcatenates two successive 32-bit integers and divides them by a power of $2$.\nIn this case, the 32-bit MT19937 is optimized in terms of its equidistribution\nproperties (the so-called dimension of equidistribution with $v$-bit accuracy)\nunder the assumption that one will mainly be using 32-bit output values, and\nhence the concatenation sometimes degrades the dimension of equidistribution\ncompared with the simple use of 32-bit outputs. In this paper, we analyze such\nphenomena by investigating hidden $\\mathbb{F}_2$-linear relations among the\nbits of high-dimensional outputs. Accordingly, we report that MT19937 with a\nspecific lag set fails several statistical tests, such as the overlapping\ncollision test, matrix rank test, and Hamming independence test.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hyperplane arrangements associated to symplectic quotient singularities.   We study the hyperplane arrangements associated, via the minimal model\nprogramme, to symplectic quotient singularities. We show that this hyperplane\narrangement equals the arrangement of CM-hyperplanes coming from the\nrepresentation theory of restricted rational Cherednik algebras. We explain\nsome of the interesting consequences of this identification for the\nrepresentation theory of restricted rational Cherednik algebras. We also show\nthat the Calogero-Moser space is smooth if and only if the Calogero-Moser\nfamilies are trivial. We describe the arrangements of CM-hyperplanes associated\nto several exceptional complex reflection groups, some of which are free.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Online control of the false discovery rate with decaying memory.   In the online multiple testing problem, p-values corresponding to different\nnull hypotheses are observed one by one, and the decision of whether or not to\nreject the current hypothesis must be made immediately, after which the next\np-value is observed. Alpha-investing algorithms to control the false discovery\nrate (FDR), formulated by Foster and Stine, have been generalized and applied\nto many settings, including quality-preserving databases in science and\nmultiple A/B or multi-armed bandit tests for internet commerce. This paper\nimproves the class of generalized alpha-investing algorithms (GAI) in four\nways: (a) we show how to uniformly improve the power of the entire class of\nmonotone GAI procedures by awarding more alpha-wealth for each rejection,\ngiving a win-win resolution to a recent dilemma raised by Javanmard and\nMontanari, (b) we demonstrate how to incorporate prior weights to indicate\ndomain knowledge of which hypotheses are likely to be non-null, (c) we allow\nfor differing penalties for false discoveries to indicate that some hypotheses\nmay be more important than others, (d) we define a new quantity called the\ndecaying memory false discovery rate (mem-FDR) that may be more meaningful for\ntruly temporal applications, and which alleviates problems that we describe and\nrefer to as \"piggybacking\" and \"alpha-death\". Our GAI++ algorithms incorporate\nall four generalizations simultaneously, and reduce to more powerful variants\nof earlier algorithms when the weights and decay are all set to unity. Finally,\nwe also describe a simple method to derive new online FDR rules based on an\nestimated false discovery proportion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Maximum Matching Algorithm for Basis Selection in Spectral Learning.   We present a solution to scale spectral algorithms for learning sequence\nfunctions. We are interested in the case where these functions are sparse (that\nis, for most sequences they return 0). Spectral algorithms reduce the learning\nproblem to the task of computing an SVD decomposition over a special type of\nmatrix called the Hankel matrix. This matrix is designed to capture the\nrelevant statistics of the training sequences. What is crucial is that to\ncapture long range dependencies we must consider very large Hankel matrices.\nThus the computation of the SVD becomes a critical bottleneck. Our solution\nfinds a subset of rows and columns of the Hankel that realizes a compact and\ninformative Hankel submatrix. The novelty lies in the way that this subset is\nselected: we exploit a maximal bipartite matching combinatorial algorithm to\nlook for a sub-block with full structural rank, and show how computation of\nthis sub-block can be further improved by exploiting the specific structure of\nHankel matrices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tilings with noncongruent triangles.   We solve a problem of R. Nandakumar by proving that there is no tiling of the\nplane with pairwise noncongruent triangles of equal area and equal perimeter.\nWe also show that no convex polygon with more than three sides can be tiled\nwith finitely many triangles such that no pair of them share a full side.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A bound on partitioning clusters.   Let $X$ be a finite collection of sets (or \"clusters\"). We consider the\nproblem of counting the number of ways a cluster $A \\in X$ can be partitioned\ninto two disjoint clusters $A_1, A_2 \\in X$, thus $A = A_1 \\uplus A_2$ is the\ndisjoint union of $A_1$ and $A_2$; this problem arises in the run time analysis\nof the ASTRAL algorithm in phylogenetic reconstruction. We obtain the bound $$\n| \\{ (A_1,A_2,A) \\in X \\times X \\times X: A = A_1 \\uplus A_2 \\} | \\leq\n|X|^{3/p} $$ where $|X|$ denotes the cardinality of $X$, and $p := \\log_3\n\\frac{27}{4} = 1.73814\\dots$, so that $\\frac{3}{p} = 1.72598\\dots$.\nFurthermore, the exponent $p$ cannot be replaced by any larger quantity. This\nimproves upon the trivial bound of $|X|^2$. The argument relies on establishing\na one-dimensional convolution inequality that can be established by elementary\ncalculus combined with some numerical verification.\nIn a similar vein, we show that for any subset $A$ of a discrete cube\n$\\{0,1\\}^n$, the additive energy of $A$ (the number of quadruples\n$(a_1,a_2,a_3,a_4)$ in $A^4$ with $a_1+a_2=a_3+a_4$) is at most $|A|^{\\log_2\n6}$, and that this exponent is best possible.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Algebraic Bethe ansatz for the trigonometric sl(2) Gaudin model with triangular boundary.   In the derivation of the generating function of the Gaudin Hamiltonians with\nboundary terms, we follow the same approach used previously in the rational\ncase, which in turn was based on Sklyanin's method in the periodic case. Our\nderivation is centered on the quasi-classical expansion of the linear\ncombination of the transfer matrix of the XXZ Heisenberg spin chain and the\ncentral element, the so-called Sklyanin determinant. The corresponding Gaudin\nHamiltonians with boundary terms are obtained as the residues of the generating\nfunction. By defining the appropriate Bethe vectors which yield strikingly\nsimple off-shell action of the generating function, we fully implement the\nalgebraic Bethe ansatz, obtaining the spectrum of the generating function and\nthe corresponding Bethe equations.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Similarity-based Multi-label Learning.   Multi-label classification is an important learning problem with many\napplications. In this work, we propose a principled similarity-based approach\nfor multi-label learning called SML. We also introduce a similarity-based\napproach for predicting the label set size. The experimental results\ndemonstrate the effectiveness of SML for multi-label classification where it is\nshown to compare favorably with a wide variety of existing algorithms across a\nrange of evaluation criterion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Machine learning for graph-based representations of three-dimensional discrete fracture networks.   Structural and topological information play a key role in modeling flow and\ntransport through fractured rock in the subsurface. Discrete fracture network\n(DFN) computational suites such as dfnWorks are designed to simulate flow and\ntransport in such porous media. Flow and transport calculations reveal that a\nsmall backbone of fractures exists, where most flow and transport occurs.\nRestricting the flowing fracture network to this backbone provides a\nsignificant reduction in the network's effective size. However, the particle\ntracking simulations needed to determine the reduction are computationally\nintensive. Such methods may be impractical for large systems or for robust\nuncertainty quantification of fracture networks, where thousands of forward\nsimulations are needed to bound system behavior.\nIn this paper, we develop an alternative network reduction approach to\ncharacterizing transport in DFNs, by combining graph theoretical and machine\nlearning methods. We consider a graph representation where nodes signify\nfractures and edges denote their intersections. Using random forest and support\nvector machines, we rapidly identify a subnetwork that captures the flow\npatterns of the full DFN, based primarily on node centrality features in the\ngraph. Our supervised learning techniques train on particle-tracking backbone\npaths found by dfnWorks, but run in negligible time compared to those\nsimulations. We find that our predictions can reduce the network to\napproximately 20% of its original size, while still generating breakthrough\ncurves consistent with those of the original network.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Phase reduction and synchronization of a network of coupled dynamical elements exhibiting collective oscillations.   A general phase reduction method for a network of coupled dynamical elements\nexhibiting collective oscillations, which is applicable to arbitrary networks\nof heterogeneous dynamical elements, is developed. A set of coupled adjoint\nequations for phase sensitivity functions, which characterize phase response of\nthe collective oscillation to small perturbations applied to individual\nelements, is derived. Using the phase sensitivity functions, collective\noscillation of the network under weak perturbation can be described\napproximately by a one-dimensional phase equation. As an example, mutual\nsynchronization between a pair of collectively oscillating networks of\nexcitable and oscillatory FitzHugh-Nagumo elements with random coupling is\nstudied.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Pachinko Prediction: A Bayesian method for event prediction from social media data.   The combination of large open data sources with machine learning approaches\npresents a potentially powerful way to predict events such as protest or social\nunrest. However, accounting for uncertainty in such models, particularly when\nusing diverse, unstructured datasets such as social media, is essential to\nguarantee the appropriate use of such methods. Here we develop a Bayesian\nmethod for predicting social unrest events in Australia using social media\ndata. This method uses machine learning methods to classify individual postings\nto social media as being relevant, and an empirical Bayesian approach to\ncalculate posterior event probabilities. We use the method to predict events in\nAustralian cities over a period in 2017/18.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Numerical study of the Kadomtsev--Petviashvili equation and dispersive shock waves.   A detailed numerical study of the long time behaviour of dispersive shock\nwaves in solutions to the Kadomtsev-Petviashvili (KP) I equation is presented.\nIt is shown that modulated lump solutions emerge from the dispersive shock\nwaves. For the description of dispersive shock waves, Whitham modulation\nequations for KP are obtained. It is shown that the modulation equations near\nthe soliton line are hyperbolic for the KPII equation while they are elliptic\nfor the KPI equation leading to a focusing effect and the formation of lumps.\nSuch a behaviour is similar to the appearance of breathers for the focusing\nnonlinear Schrodinger equation in the semiclassical limit.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Sensitivity of Love and quasi-Rayleigh waves to model parameters.   We examine the sensitivity of the Love and the quasi-Rayleigh waves to model\nparameters. Both waves are guided waves that propagate in the same model of an\nelastic layer above an elastic halfspace. We study their dispersion curves\nwithout any simplifying assumptions, beyond the standard approach of elasticity\ntheory in isotropic media. We examine the sensitivity of both waves to\nelasticity parameters, frequency and layer thickness, for varying frequency and\ndifferent modes. In the case of Love waves, we derive and plot the absolute\nvalue of a dimensionless sensitivity coefficient in terms of partial\nderivatives, and perform an analysis to find the optimum frequency for\ndetermining the layer thickness. For a coherency of the background information,\nwe briefly review the Love-wave dispersion relation and provide details of the\nless common derivation of the quasi-Rayleigh relation in an appendix. We\ncompare that derivation to past results in the literature, finding certain\ndiscrepancies among them.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A topological lower bound for the energy of a unit vector field on a closed Euclidean hypersurface.   For a unit vector field on a closed immersed Euclidean hypersurface\n$M^{2n+1}$, $n\\geq 1$, we exhibit a nontrivial lower bound for its energy which\ndepends on the degree of the Gauss map of the immersion. When the hypersurface\nis the unit sphere $\\mathbb{S}^{2n+1}$, immersed with degree one, this lower\nbound corresponds to a well established value from the literature. We introduce\na list of functionals $\\mathcal{B}_k$ on a compact Riemannian manifold $M^{m}$,\n$1\\leq k\\leq m$, and show that, when the underlying manifold is a closed\nhypersurface, these functionals possess similar properties regarding the degree\nof the immersion. In addition, we prove that Hopf flows minimize\n$\\mathcal{B}_n$ on $\\mathbb{S}^{2n+1}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Learning of Consumer Preferences for Residential Demand Response.   In coming years residential consumers will face real-time electricity tariffs\nwith energy prices varying day to day, and effective energy saving will require\nautomation - a recommender system, which learns consumer's preferences from her\nactions. A consumer chooses a scenario of home appliance use to balance her\ncomfort level and the energy bill. We propose a Bayesian learning algorithm to\nestimate the comfort level function from the history of appliance use. In\nnumeric experiments with datasets generated from a simulation model of a\nconsumer interacting with small home appliances the algorithm outperforms\npopular regression analysis tools. Our approach can be extended to control an\nair heating and conditioning system, which is responsible for up to half of a\nhousehold's energy bill.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Privacy-Preserving Economic Dispatch in Competitive Electricity Market.   With the emerging of smart grid techniques, cyber attackers may be able to\ngain access to critical energy infrastructure data and strategic market\nparticipants may be able to identify offer prices of their rivals. This paper\ndiscusses a privacy-preserving economic dispatch approach in competitive\nelectricity market, in which individual generation companies (GENCOs) and load\nserving entities (LSEs) can mask their actual bidding information and physical\ndata by multiplying with random numbers before submitting to Independent System\nOperators (ISOs) and Regional Transmission Owners (RTOs). This would avoid\npotential information leakage of critical energy infrastructure and financial\ndata of market participants. The optimal solution to the original ED problem,\nincluding optimal dispatches of generators and loads and locational marginal\nprices (LMPs), can be retrieved from the optimal solution of the proposed\nprivacy-preserving ED approach. Numerical case studies show the effectiveness\nof the proposed approach for protecting private information of individual\nmarket participants while guaranteeing the same optimal ED solution.\nComputation and communication costs of the proposed privacy-preserving ED\napproach and the original ED are also compared in case studies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An influence-based fast preceding questionnaire model for elderly assessments.   To improve the efficiency of elderly assessments, an influence-based fast\npreceding questionnaire model (FPQM) is proposed. Compared with traditional\nassessments, the FPQM optimizes questionnaires by reordering their attributes.\nThe values of low-ranking attributes can be predicted by the values of the\nhigh-ranking attributes. Therefore, the number of attributes can be reduced\nwithout redesigning the questionnaires. A new function for calculating the\ninfluence of the attributes is proposed based on probability theory. Reordering\nand reducing algorithms are given based on the attributes' influences. The\nmodel is verified through a practical application. The practice in an\nelderly-care company shows that the FPQM can reduce the number of attributes by\n90.56% with a prediction accuracy of 98.39%. Compared with other methods, such\nas the Expert Knowledge, Rough Set and C4.5 methods, the FPQM achieves the best\nperformance. In addition, the FPQM can also be applied to other questionnaires.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Homotopy Parametric Simplex Method for Sparse Learning.   High dimensional sparse learning has imposed a great computational challenge\nto large scale data analysis. In this paper, we are interested in a broad class\nof sparse learning approaches formulated as linear programs parametrized by a\n{\\em regularization factor}, and solve them by the parametric simplex method\n(PSM). Our parametric simplex method offers significant advantages over other\ncompeting methods: (1) PSM naturally obtains the complete solution path for all\nvalues of the regularization parameter; (2) PSM provides a high precision dual\ncertificate stopping criterion; (3) PSM yields sparse solutions through very\nfew iterations, and the solution sparsity significantly reduces the\ncomputational cost per iteration. Particularly, we demonstrate the superiority\nof PSM over various sparse learning approaches, including Dantzig selector for\nsparse linear regression, LAD-Lasso for sparse robust linear regression, CLIME\nfor sparse precision matrix estimation, sparse differential network estimation,\nand sparse Linear Programming Discriminant (LPD) analysis. We then provide\nsufficient conditions under which PSM always outputs sparse solutions such that\nits computational performance can be significantly boosted. Thorough numerical\nexperiments are provided to demonstrate the outstanding performance of the PSM\nmethod.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Volumetric Super-Resolution of Multispectral Data.   Most multispectral remote sensors (e.g. QuickBird, IKONOS, and Landsat 7\nETM+) provide low-spatial high-spectral resolution multispectral (MS) or\nhigh-spatial low-spectral resolution panchromatic (PAN) images, separately. In\norder to reconstruct a high-spatial/high-spectral resolution multispectral\nimage volume, either the information in MS and PAN images are fused (i.e.\npansharpening) or super-resolution reconstruction (SRR) is used with only MS\nimages captured on different dates. Existing methods do not utilize temporal\ninformation of MS and high spatial resolution of PAN images together to improve\nthe resolution. In this paper, we propose a multiframe SRR algorithm using\npansharpened MS images, taking advantage of both temporal and spatial\ninformation available in multispectral imagery, in order to exceed spatial\nresolution of given PAN images. We first apply pansharpening to a set of\nmultispectral images and their corresponding PAN images captured on different\ndates. Then, we use the pansharpened multispectral images as input to the\nproposed wavelet-based multiframe SRR method to yield full volumetric SRR. The\nproposed SRR method is obtained by deriving the subband relations between\nmultitemporal MS volumes. We demonstrate the results on Landsat 7 ETM+ images\ncomparing our method to conventional techniques.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Propagation in media as a probe for topological properties.   The central goal of this thesis is to develop methods to experimentally study\ntopological phases. We do so by applying the powerful toolbox of quantum\nsimulation techniques with cold atoms in optical lattices. To this day, a\ncomplete classification of topological phases remains elusive. In this context,\nexperimental studies are key, both for studying the interplay between topology\nand complex effects and for identifying new forms of topological order. It is\ntherefore crucial to find complementary means to measure topological properties\nin order to reach a fundamental understanding of topological phases. In one\ndimensional chiral systems, we suggest a new way to construct and identify\ntopologically protected bound states, which are the smoking gun of these\nmaterials. In two dimensional Hofstadter strips (i.e: systems which are very\nshort along one dimension), we suggest a new way to measure the topological\ninvariant directly from the atomic dynamics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "$\\mathcal{P}$-schemes and Deterministic Polynomial Factoring over Finite Fields.   We introduce a family of mathematical objects called $\\mathcal{P}$-schemes,\nwhere $\\mathcal{P}$ is a poset of subgroups of a finite group $G$. A\n$\\mathcal{P}$-scheme is a collection of partitions of the right coset spaces\n$H\\backslash G$, indexed by $H\\in\\mathcal{P}$, that satisfies a list of axioms.\nThese objects generalize the classical notion of association schemes as well as\nthe notion of $m$-schemes (Ivanyos et al. 2009).\nBased on $\\mathcal{P}$-schemes, we develop a unifying framework for the\nproblem of deterministic factoring of univariate polynomials over finite fields\nunder the generalized Riemann hypothesis (GRH).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Breakthrough revisited: investigating the requirements for growth of dust beyond the bouncing barrier.   For grain growth to proceed effectively and lead to planet formation a number\nof barriers to growth must be overcome. One such barrier, relevant for compact\ngrains in the inner regions of the disc, is the `bouncing barrier' in which\nlarge grains ($\\sim$ mm size) tend to bounce off each other rather than\nsticking. However, by maintaining a population of small grains it has been\nsuggested that cm-size particles may grow rapidly by sweeping up these small\ngrains. We present the first numerically resolved investigation into the\nconditions under which grains may be lucky enough to grow beyond the bouncing\nbarrier by a series of rare collisions leading to growth (so-called\n`breakthrough'). Our models support previous results, and show that in simple\nmodels breakthrough requires the mass ratio at which high velocity collisions\ntransition to growth instead of causing fragmentation to be low, $\\phi \\lesssim\n50$. However, in models that take into account the dependence of the\nfragmentation threshold on mass-ratio, we find breakthrough occurs more\nreadily, even if mass transfer is relatively inefficient. This suggests that\nbouncing may only slow down growth, rather than preventing growth beyond a\nthreshold barrier. However, even when growth beyond the bouncing barrier is\npossible, radial drift will usually prevent growth to arbitrarily large sizes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bayesian uncertainty quantification in linear models for diffusion MRI.   Diffusion MRI (dMRI) is a valuable tool in the assessment of tissue\nmicrostructure. By fitting a model to the dMRI signal it is possible to derive\nvarious quantitative features. Several of the most popular dMRI signal models\nare expansions in an appropriately chosen basis, where the coefficients are\ndetermined using some variation of least-squares. However, such approaches lack\nany notion of uncertainty, which could be valuable in e.g. group analyses. In\nthis work, we use a probabilistic interpretation of linear least-squares\nmethods to recast popular dMRI models as Bayesian ones. This makes it possible\nto quantify the uncertainty of any derived quantity. In particular, for\nquantities that are affine functions of the coefficients, the posterior\ndistribution can be expressed in closed-form. We simulated measurements from\nsingle- and double-tensor models where the correct values of several quantities\nare known, to validate that the theoretically derived quantiles agree with\nthose observed empirically. We included results from residual bootstrap for\ncomparison and found good agreement. The validation employed several different\nmodels: Diffusion Tensor Imaging (DTI), Mean Apparent Propagator MRI (MAP-MRI)\nand Constrained Spherical Deconvolution (CSD). We also used in vivo data to\nvisualize maps of quantitative features and corresponding uncertainties, and to\nshow how our approach can be used in a group analysis to downweight subjects\nwith high uncertainty. In summary, we convert successful linear models for dMRI\nsignal estimation to probabilistic models, capable of accurate uncertainty\nquantification.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Relativistic Spacecraft Propelled by Directed Energy.   Achieving relativistic flight to enable extrasolar exploration is one of the\ndreams of humanity and the long term goal of our NASA Starlight program. We\nderive a fully relativistic solution for the motion of a spacecraft propelled\nby radiation pressure from a directed energy system. Depending on the system\nparameters, low mass spacecraft can achieve relativistic speeds; thereby\nenabling interstellar exploration. The diffraction of the directed energy\nsystem plays an important role and limits the maximum speed of the spacecraft.\nWe consider 'photon recycling' as a possible method to achieving higher speeds.\nWe also discuss recent claims that our previous work on this topic is incorrect\nand show that these claims arise from an improper treatment of causality.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Adaptive Similar Triangles Method: a Stable Alternative to Sinkhorn's Algorithm for Regularized Optimal Transport.   In this paper, we are motivated by two important applications:\nentropy-regularized optimal transport problem and road or IP traffic demand\nmatrix estimation by entropy model. Both of them include solving a special type\nof optimization problem with linear equality constraints and objective given as\na sum of an entropy regularizer and a linear function. It is known that the\nstate-of-the-art solvers for this problem, which are based on Sinkhorn's method\n(also known as RSA or balancing method), can fail to work, when the\nentropy-regularization parameter is small. We consider the above optimization\nproblem as a particular instance of a general strongly convex optimization\nproblem with linear constraints. We propose a new algorithm to solve this\ngeneral class of problems. Our approach is based on the transition to the dual\nproblem. First, we introduce a new accelerated gradient method with adaptive\nchoice of gradient's Lipschitz constant. Then, we apply this method to the dual\nproblem and show, how to reconstruct an approximate solution to the primal\nproblem with provable convergence rate. We prove the rate $O(1/k^2)$, $k$ being\nthe iteration counter, both for the absolute value of the primal objective\nresidual and constraints infeasibility. Our method has similar to Sinkhorn's\nmethod complexity of each iteration, but is faster and more stable numerically,\nwhen the regularization parameter is small. We illustrate the advantage of our\nmethod by numerical experiments for the two mentioned applications. We show\nthat there exists a threshold, such that, when the regularization parameter is\nsmaller than this threshold, our method outperforms the Sinkhorn's method in\nterms of computation time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Automatic Detection of Cyberbullying in Social Media Text.   While social media offer great communication opportunities, they also\nincrease the vulnerability of young people to threatening situations online.\nRecent studies report that cyberbullying constitutes a growing problem among\nyoungsters. Successful prevention depends on the adequate detection of\npotentially harmful messages and the information overload on the Web requires\nintelligent systems to identify potential risks automatically. The focus of\nthis paper is on automatic cyberbullying detection in social media text by\nmodelling posts written by bullies, victims, and bystanders of online bullying.\nWe describe the collection and fine-grained annotation of a training corpus for\nEnglish and Dutch and perform a series of binary classification experiments to\ndetermine the feasibility of automatic cyberbullying detection. We make use of\nlinear support vector machines exploiting a rich feature set and investigate\nwhich information sources contribute the most for this particular task.\nExperiments on a holdout test set reveal promising results for the detection of\ncyberbullying-related posts. After optimisation of the hyperparameters, the\nclassifier yields an F1-score of 64% and 61% for English and Dutch\nrespectively, and considerably outperforms baseline systems based on keywords\nand word unigrams.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Personalized and Private Peer-to-Peer Machine Learning.   The rise of connected personal devices together with privacy concerns call\nfor machine learning algorithms capable of leveraging the data of a large\nnumber of agents to learn personalized models under strong privacy\nrequirements. In this paper, we introduce an efficient algorithm to address the\nabove problem in a fully decentralized (peer-to-peer) and asynchronous fashion,\nwith provable convergence rate. We show how to make the algorithm\ndifferentially private to protect against the disclosure of information about\nthe personal datasets, and formally analyze the trade-off between utility and\nprivacy. Our experiments show that our approach dramatically outperforms\nprevious work in the non-private case, and that under privacy constraints, we\ncan significantly improve over models learned in isolation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Efficiently Detecting Overlapping Communities over Distributed Dynamic Graphs.   Modern networks are of huge sizes as well as high dynamics, which challenges\nthe efficiency of community detection algorithms. In this paper, we study the\nproblem of overlapping community detection on distributed and dynamic graphs.\nGiven a distributed, undirected and unweighted graph, the goal is to detect\noverlapping communities incrementally as the graph is dynamically changing. We\npropose an efficient algorithm, called \\textit{randomized Speaker-Listener\nLabel Propagation Algorithm} (rSLPA), based on the \\textit{Speaker-Listener\nLabel Propagation Algorithm} (SLPA) by relaxing the probability distribution of\nlabel propagation. Besides detecting high-quality communities, rSLPA can\nincrementally update the detected communities after a batch of edge insertion\nand deletion operations. To the best of our knowledge, rSLPA is the first\nalgorithm that can incrementally capture the same communities as those obtained\nby applying the detection algorithm from the scratch on the updated graph.\nExtensive experiments are conducted on both synthetic and real-world datasets,\nand the results show that our algorithm can achieve high accuracy and\nefficiency at the same time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Excited states of defect lines in silicon: A first-principles study based on hydrogen cluster analogues.   Excited states of a single donor in bulk silicon have previously been studied\nextensively based on effective mass theory. However, a proper theoretical\ndescription of the excited states of a donor cluster is still scarce. Here we\nstudy the excitations of lines of defects within a single-valley spherical band\napproximation, thus mapping the problem to a scaled hydrogen atom array. A\nseries of detailed full configuration-interaction and time-dependent hybrid\ndensity-functional theory calculations have been performed to understand linear\nclusters of up to 10 donors. Our studies illustrate the generic features of\ntheir excited states, addressing the competition between formation of\ninter-donor ionic states and intra-donor atomic excited states. At short\ninter-donor distances, excited states of donor molecules are dominant, at\nintermediate distances ionic states play an important role, and at long\ndistances the intra-donor excitations are predominant as expected. The\ncalculations presented here emphasise the importance of correlations between\ndonor electrons, and are thus complementary to other recent approaches that\ninclude effective mass anisotropy and multi-valley effects. The exchange\nsplittings between relevant excited states have also been estimated for a donor\npair and for a three-donor arrays; the splittings are much larger than those in\nthe ground state in the range of donor separations between 10 and 20 nm. This\nestablishes a solid theoretical basis for the use of excited-state exchange\ninteractions for controllable quantum gate operations in silicon.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Validation of small Kepler transiting planet candidates in or near the habitable zone.   A main goal of NASA's Kepler Mission is to establish the frequency of\npotentially habitable Earth-size planets (eta Earth). Relatively few such\ncandidates identified by the mission can be confirmed to be rocky via dynamical\nmeasurement of their mass. Here we report an effort to validate 18 of them\nstatistically using the BLENDER technique, by showing that the likelihood they\nare true planets is far greater than that of a false positive. Our analysis\nincorporates follow-up observations including high-resolution optical and\nnear-infrared spectroscopy, high-resolution imaging, and information from the\nanalysis of the flux centroids of the Kepler observations themselves. While\nmany of these candidates have been previously validated by others, the\nconfidence levels reported typically ignore the possibility that the planet may\ntransit a different star than the target along the same line of sight. If that\nwere the case, a planet that appears small enough to be rocky may actually be\nconsiderably larger and therefore less interesting from the point of view of\nhabitability. We take this into consideration here, and are able to validate 15\nof our candidates at a 99.73% (3 sigma) significance level or higher, and the\nother three at slightly lower confidence. We characterize the GKM host stars\nusing available ground-based observations and provide updated parameters for\nthe planets, with sizes between 0.8 and 2.9 Earth radii. Seven of them\n(KOI-0438.02, 0463.01, 2418.01, 2626.01, 3282.01, 4036.01, and 5856.01) have a\nbetter than 50% chance of being smaller than 2 Earth radii and being in the\nhabitable zone of their host stars.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Revisiting the quest for a universal log-law and the role of pressure gradient in \"canonical\" wall-bounded turbulent flows.   The trinity of so-called \"canonical\" wall-bounded turbulent flows, comprising\nthe zero pressure gradient turbulent boundary layer, abbreviated ZPG TBL,\nturbulent pipe flow and channel/duct flows has continued to receive intense\nattention as new and more reliable experimental data have become available.\nNevertheless, the debate on whether the logarithmic part of the mean velocity\nprofile, in particular the Kármán constant $\\kappa$, is identical for these\nthree canonical flows or flow-dependent is still ongoing. In this paper, which\nexpands upon Monkewitz and Nagib (24th ICTAM Conf., Montreal, 2016), the\nasymptotic matching requirement of equal $\\kappa$ in the log-law and in the\nexpression for the centerline/free-stream velocity is reiterated and shown to\npreclude a single universal log-law in the three canonical flows or at least\nmake it very unlikely. The current re-analysis of high quality mean velocity\nprofiles in ZPG TBL's, the Princeton \"Superpipe\" and in channels and ducts\nleads to a coherent description of (almost) all seemingly contradictory data\ninterpretations in terms of TWO logarithmic regions in pipes and channels: A\nuniversal interior, near-wall logarithmic region with the same parameters as in\nthe ZPG TBL, in particular $\\kappa_{\\mathrm{wall}} \\cong 0.384$, but only\nextending from around $150$ to around $10^3$ wall units, and shrinking with\nincreasing pressure gradient, followed by an exterior logarithmic region with a\nflow specific $\\kappa$ matching the logarithmic slope of the respective\nfree-stream or centerline velocity. The log-law parameters of the exterior\nlogarithmic region in channels and pipes are shown to depend monotonically on\nthe pressure gradient.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Deformations of coisotropic submanifolds in Jacobi manifolds.   In this thesis, we study the deformation problem of coisotropic submanifolds\nin Jacobi manifolds. In particular we attach two algebraic invariants to any\ncoisotropic submanifold $S$ in a Jacobi manifold, namely the\n$L_\\infty[1]$-algebra and the BFV-complex of $S$. Our construction generalizes\nand unifies analogous constructions in symplectic, Poisson, and locally\nconformal symplectic geometry. As a new special case we also attach an\n$L_\\infty[1]$-algebra and a BFV-complex to any coisotropic submanifold in a\ncontact manifold. The $L_\\infty[1]$-algebra of $S$ controls the formal\ncoisotropic deformation problem of $S$, even under Hamiltonian equivalence. The\nBFV-complex of $S$ controls the non-formal coisotropic deformation problem of\n$S$, even under both Hamiltonian and Jacobi equivalence. In view of these\nresults, we exhibit, in the contact setting, two examples of coisotropic\nsubmanifolds whose coisotropic deformation problem is obstructed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "San Pedro Meeting on Wide Field Variability Surveys: Some Concluding Comments.   This is a written version of the closing talk at the 22nd Los Alamos Stellar\npulsation conference on wide field variability surveys. It comments on some of\nthe issues which arise from the meeting. These include the need for attention\nto photometric standardization (especially in the infrared) and the somewhat\ncontroversial problem of statistical bias in the use of parallaxes (and other\nmethods of distance determination). Some major advances in the use of pulsating\nvariables to study Galactic structure are mentioned. The paper includes a\nclarification of apparently conflicting results from classical Cepheids and RR\nLyrae stars in the inner Galaxy and bulge. The importance of understanding\nnon-periodic phenomena in variable stars,particularly AGB variables and RCB\nstars is stressed, especially for its relevance to mass-loss, in which\npulsation may only play a minor role.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Vague Computers.   Vagueness is something everyone is familiar with. In fact, most people think\nthat vagueness is closely related to language and exists only there. However,\nvagueness is a property of the physical world. Quantum computers harness\nsuperposition and entanglement to perform their computational tasks. Both\nsuperposition and entanglement are vague processes. Thus quantum computers,\nwhich process exact data without \"exploiting\" vagueness, are actually vague\ncomputers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Global aspects of polarization optics and coset space geometry.   We use group theoretic ideas and coset space methods to deal with problems in\npolarization optics of a global nature. These include the possibility of a\nglobally smooth phase convention for electric fields for all points on the\nPoincaré sphere, and a similar possibility of real or complex bases of\ntransverse electric vectors for all possible propagation directions. It is\nshown that these methods help in understanding some known results in an\neffective manner, and in answering new questions as well. We find that apart\nfrom the groups $SU(2)$ and $SO(3)$ which occur naturally in these problems,\nthe group $SU(3)$ also plays an important role.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Safety-Aware Apprenticeship Learning.   Apprenticeship learning (AL) is a kind of Learning from Demonstration\ntechniques where the reward function of a Markov Decision Process (MDP) is\nunknown to the learning agent and the agent has to derive a good policy by\nobserving an expert's demonstrations. In this paper, we study the problem of\nhow to make AL algorithms inherently safe while still meeting its learning\nobjective. We consider a setting where the unknown reward function is assumed\nto be a linear combination of a set of state features, and the safety property\nis specified in Probabilistic Computation Tree Logic (PCTL). By embedding\nprobabilistic model checking inside AL, we propose a novel\ncounterexample-guided approach that can ensure safety while retaining\nperformance of the learnt policy. We demonstrate the effectiveness of our\napproach on several challenging AL scenarios where safety is essential.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression.   Deep neural networks (DNNs) have achieved great success in solving a variety\nof machine learning (ML) problems, especially in the domain of image\nrecognition. However, recent research showed that DNNs can be highly vulnerable\nto adversarially generated instances, which look seemingly normal to human\nobservers, but completely confuse DNNs. These adversarial samples are crafted\nby adding small perturbations to normal, benign images. Such perturbations,\nwhile imperceptible to the human eye, are picked up by DNNs and cause them to\nmisclassify the manipulated instances with high confidence. In this work, we\nexplore and demonstrate how systematic JPEG compression can work as an\neffective pre-processing step in the classification pipeline to counter\nadversarial attacks and dramatically reduce their effects (e.g., Fast Gradient\nSign Method, DeepFool). An important component of JPEG compression is its\nability to remove high frequency signal components, inside square blocks of an\nimage. Such an operation is equivalent to selective blurring of the image,\nhelping remove additive perturbations. Further, we propose an ensemble-based\ntechnique that can be constructed quickly from a given well-performing DNN, and\nempirically show how such an ensemble that leverages JPEG compression can\nprotect a model from multiple types of adversarial attacks, without requiring\nknowledge about the model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Capacity of Some Classes of Polyhedra.   K. Borsuk in 1979, in the Topological Conference in Moscow, introduced the\nconcept of the capacity of a compactum. In this paper, we compute the capacity\nof the product of two spheres of the same or different dimensions and the\ncapacity of lense spaces. Also, we present an upper bound for the capacity of a\n$\\mathbb{Z}_n$-complex, i.e., a connected finite 2-dimensional CW-complex with\nfinite cyclic fundamental group $\\mathbb{Z}_n$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Collective decision for open set recognition.   In open set recognition (OSR), almost all existing methods are designed\nspecially for recognizing individual instances, even these instances are\ncollectively coming in batch. Recognizers in decision either reject or\ncategorize them to some known class using empirically-set threshold. Thus the\nthreshold plays a key role, however, the selection for it usually depends on\nthe knowledge of known classes, inevitably incurring risks due to lacking\navailable information from unknown classes. On the other hand, a more realistic\nOSR system should NOT just rest on a reject decision but should go further,\nespecially for discovering the hidden unknown classes among the reject\ninstances, whereas existing OSR methods do not pay special attention. In this\npaper, we introduce a novel collective/batch decision strategy with an aim to\nextend existing OSR for new class discovery while considering correlations\namong the testing instances. Specifically, a collective decision-based OSR\nframework (CD-OSR) is proposed by slightly modifying the Hierarchical Dirichlet\nprocess (HDP). Thanks to the HDP, our CD-OSR does not need to define the\nspecific threshold and can automatically reserve space for unknown classes in\ntesting, naturally resulting in a new class discovery function. Finally,\nextensive experiments on benchmark datasets indicate the validity of CD-OSR.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Local equilibrium in the Bak-Sneppen model.   The Bak Sneppen (BS) model is a very simple model that exhibits all the\nrichness of self-organized criticality theory. At the thermodynamic limit, the\nBS model converges to a situation where all particles have a fitness that is\nuniformly distributed between a critical value $p_c$ and 1. The $p_c$ value is\nunknown, as are the variables that influence and determine this value. Here, we\nstudy the Bak Sneppen model in the case in which the lowest fitness particle\ninteracts with an arbitrary even number of $m$ nearest neighbors. We show that\n$p_{c,m}$ verifies a simple local equilibrium relationship. Based on this\nrelationship, we can determine bounds for $p_{c,m}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Scientific Value of Large-scale Testbeds for Wireless Multi-hop Networks.   Large-scale wireless testbeds have been setup in the last years with the goal\nto study wireless multi-hop networks in more realistic environments. Since the\nsetup and operation of such a testbed is expensive in terms of money, time, and\nlabor, the crucial question rises whether this effort is justified with the\nscientific results the testbed generates.\nIn this paper, we give an answer to this question based on our experience\nwith the DES-Testbed, a large-scale wireless sensor network and wireless mesh\nnetwork testbed. The DES-Testbed has been operated for almost 5 years. Our\nanalysis comprises more than 1000 experiments that have been run on the testbed\nin the years 2010 and 2011. We discuss the scientific value in respect to the\neffort of experimentation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Infinite Mixture of Inverted Dirichlet Distributions.   In this work, we develop a novel Bayesian estimation method for the Dirichlet\nprocess (DP) mixture of the inverted Dirichlet distributions, which has been\nshown to be very flexible for modeling vectors with positive elements. The\nrecently proposed extended variational inference (EVI) framework is adopted to\nderive an analytically tractable solution. The convergency of the proposed\nalgorithm is theoretically guaranteed by introducing single lower bound\napproximation to the original objective function in the VI framework. In\nprinciple, the proposed model can be viewed as an infinite inverted Dirichelt\nmixture model (InIDMM) that allows the automatic determination of the number of\nmixture components from data. Therefore, the problem of pre-determining the\noptimal number of mixing components has been overcome. Moreover, the problems\nof over-fitting and under-fitting are avoided by the Bayesian estimation\napproach. Comparing with several recently proposed DP-related methods, the good\nperformance and effectiveness of the proposed method have been demonstrated\nwith both synthesized data and real data evaluations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient conversion from rotating matrix to rotation axis and angle by extending Rodrigues' formula.   In computational 3D geometric problems involving rotations, it is often that\npeople have to convert back and forth between a rotational matrix and a\nrotation described by an axis and a corresponding angle. For this purpose,\nRodrigues' rotation formula is a very popular expression to use because of its\nsimplicity and efficiency. Nevertheless, while converting a rotation matrix to\nan axis of rotation and the rotation angle, there exists ambiguity. Further\njudgement or even manual interference may be necessary in some situations. An\nextension of the Rodrigues' formula helps to find the sine and cosine values of\nthe rotation angle with respect to a given rotation axis is found and this\nsimple extension may help to accelerate many applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Phase Variable Approach for Improved Volitional and Rhythmic Control of a Powered Knee-Ankle Prosthesis.   Although there has been recent progress in control of multi-joint prosthetic\nlegs for periodic tasks such as walking, volitional control of these systems\nfor non-periodic maneuvers is still an open problem. In this paper, we develop\na new controller that is capable of both periodic walking and common volitional\nleg motions based on a piecewise holonomic phase variable through a finite\nstate machine. The phase variable is constructed by measuring the thigh angle,\nand the transitions in the finite state machine are formulated through sensing\nfoot contact along with attributes of a nominal reference gait trajectory. The\ncontroller was implemented on a powered knee-ankle prosthesis and tested with a\ntransfemoral amputee subject, who successfully performed a wide range of\nperiodic and non-periodic tasks, including low- and high-speed walking, quick\nstart and stop, backward walking, walking over obstacles, and kicking a soccer\nball. Use of the powered leg resulted in significant reductions in amputee\ncompensations including vaulting and hip circumduction when compared to use of\nthe take-home passive leg. The proposed approach is expected to provide better\nunderstanding of volitional motions and lead to more reliable control of\nmulti-joint prostheses for a wider range of tasks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The sharp for the Chang model is small.   Woodin has shown that if there is a measurable Woodin cardinal then there is,\nin an appropriate sense, a sharp for the Chang model. We produce, in a weaker\nsense, a sharp for the Chang model using only the existence of a cardinal\n$\\kappa$ having an extender of length $\\kappa^{+\\omega_1}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Response to \"Counterexample to global convergence of DSOS and SDSOS hierarchies\".   In a recent note [8], the author provides a counterexample to the global\nconvergence of what his work refers to as \"the DSOS and SDSOS hierarchies\" for\npolynomial optimization problems (POPs) and purports that this refutes claims\nin our extended abstract [4] and slides in [3]. The goal of this paper is to\nclarify that neither [4], nor [3], and certainly not our full paper [5], ever\ndefined DSOS or SDSOS hierarchies as it is done in [8]. It goes without saying\nthat no claims about convergence properties of the hierarchies in [8] were ever\nmade as a consequence. What was stated in [4,3] was completely different: we\nstated that there exist hierarchies based on DSOS and SDSOS optimization that\nconverge. This is indeed true as we discuss in this response. We also emphasize\nthat we were well aware that some (S)DSOS hierarchies do not converge even if\ntheir natural SOS counterparts do. This is readily implied by an example in our\nprior work [5], which makes the counterexample in [8] superfluous. Finally, we\nprovide concrete counterarguments to claims made in [8] that aim to challenge\nthe scalability improvements obtained by DSOS and SDSOS optimization as\ncompared to sum of squares (SOS) optimization.\n[3] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS: More tractable alternatives\nto SOS. Slides at the meeting on Geometry and Algebra of Linear Matrix\nInequalities, CIRM, Marseille, 2013. [4] A. A. Ahmadi and A. Majumdar. DSOS and\nSDSOS optimization: LP and SOCP-based alternatives to sum of squares\noptimization. In proceedings of the 48th annual IEEE Conference on Information\nSciences and Systems, 2014. [5] A. A. Ahmadi and A. Majumdar. DSOS and SDSOS\noptimization: more tractable alternatives to sum of squares and semidefinite\noptimization. arXiv:1706.02586, 2017. [8] C. Josz. Counterexample to global\nconvergence of DSOS and SDSOS hierarchies. arXiv:1707.02964, 2017.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a population synthesis model of self-gravitating disc fragmentation and tidal downsizing II: The effect of fragment-fragment interactions.   It is likely that most protostellar systems undergo a brief phase where the\nprotostellar disc is self-gravitating. If these discs are prone to\nfragmentation, then they are able to rapidly form objects that are initially of\nseveral Jupiter masses and larger. The fate of these disc fragments (and the\nfate of planetary bodies formed afterwards via core accretion) depends\nsensitively not only on the fragment's interaction with the disc, but with its\nneighbouring fragments.\nWe return to and revise our population synthesis model of self-gravitating\ndisc fragmentation and tidal downsizing. Amongst other improvements, the model\nnow directly incorporates fragment-fragment interactions while the disc is\nstill present. We find that fragment-fragment scattering dominates the orbital\nevolution, even when we enforce rapid migration and inefficient gap formation.\nCompared to our previous model, we see a small increase in the number of\nterrestrial-type objects being formed, although their survival under tidal\nevolution is at best unclear. We also see evidence for disrupted fragments with\nevolved grain populations - this is circumstantial evidence for the formation\nof planetesimal belts, a phenomenon not seen in runs where fragment-fragment\ninteractions are ignored.\nIn spite of intense dynamical evolution, our population is dominated by\nmassive giant planets and brown dwarfs at large semimajor axis, which direct\nimaging surveys should, but only rarely, detect. Finally, disc fragmentation is\nshown to be an efficient manufacturer of free floating planetary mass objects,\nand the typical multiplicity of systems formed via gravitational instability\nwill be low.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Popov's formula involving the Von Mangoldt function.   We offer a generalization of a formula of Popov involving the Von Mangoldt\nfunction. Some commentary on its relation to other results in analytic number\ntheory is mentioned as well as an analogue involving the m$\\ddot{o}$bius\nfunction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reduced-Order Modeling through Machine Learning Approaches for Brittle Fracture Applications.   In this paper, five different approaches for reduced-order modeling of\nbrittle fracture in geomaterials, specifically concrete, are presented and\ncompared. Four of the five methods rely on machine learning (ML) algorithms to\napproximate important aspects of the brittle fracture problem. In addition to\nthe ML algorithms, each method incorporates different physics-based assumptions\nin order to reduce the computational complexity while maintaining the physics\nas much as possible. This work specifically focuses on using the ML approaches\nto model a 2D concrete sample under low strain rate pure tensile loading\nconditions with 20 preexisting cracks present. A high-fidelity finite\nelement-discrete element model is used to both produce a training dataset of\n150 simulations and an additional 35 simulations for validation. Results from\nthe ML approaches are directly compared against the results from the\nhigh-fidelity model. Strengths and weaknesses of each approach are discussed\nand the most important conclusion is that a combination of physics-informed and\ndata-driven features are necessary for emulating the physics of crack\npropagation, interaction and coalescence. All of the models presented here have\nruntimes that are orders of magnitude faster than the original high-fidelity\nmodel and pave the path for developing accurate reduced order models that could\nbe used to inform larger length-scale models with important sub-scale physics\nthat often cannot be accounted for due to computational cost.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Transfer Learning by Asymmetric Image Weighting for Segmentation across Scanners.   Supervised learning has been very successful for automatic segmentation of\nimages from a single scanner. However, several papers report deteriorated\nperformances when using classifiers trained on images from one scanner to\nsegment images from other scanners. We propose a transfer learning classifier\nthat adapts to differences between training and test images. This method uses a\nweighted ensemble of classifiers trained on individual images. The weight of\neach classifier is determined by the similarity between its training image and\nthe test image.\nWe examine three unsupervised similarity measures, which can be used in\nscenarios where no labeled data from a newly introduced scanner or scanning\nprotocol is available. The measures are based on a divergence, a bag distance,\nand on estimating the labels with a clustering procedure. These measures are\nasymmetric. We study whether the asymmetry can improve classification. Out of\nthe three similarity measures, the bag similarity measure is the most robust\nacross different studies and achieves excellent results on four brain tissue\nsegmentation datasets and three white matter lesion segmentation datasets,\nacquired at different centers and with different scanners and scanning\nprotocols. We show that the asymmetry can indeed be informative, and that\ncomputing the similarity from the test image to the training images is more\nappropriate than the opposite direction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear stability for the Maxwell--Born--Infeld system on a Schwarzschild background.   In this paper we prove small data global existence for solutions to the\nMaxwell--Born--Infeld (MBI) system on a fixed Schwarzschild background. This\nsystem has appeared in the context of string theory and can be seen as a\nnonlinear model problem for the stability of the background metric itself, due\nto its tensorial and quasilinear nature. The MBI system models nonlinear\nelectromagnetism and does not display birefringence. The key element in our\nproof lies in the observation that there exists a first-order differential\ntransformation which brings solutions of the spin $\\pm 1$ Teukolsky equations,\nsatisfied by the extreme components of the field, into solutions of a \"good\"\nequation (the Fackerell--Ipser Equation). This strategy was established in [F.\nPasqualotto, The spin $\\pm 1$ Teukolsky equations and the Maxwell system on\nSchwarzschild, Preprint 2016, arXiv:1612.07244] for the linear Maxwell field on\nSchwarzschild. We show that analogous Fackerell--Ipser equations hold for the\nMBI system on a fixed Schwarzschild background, which are however nonlinearly\ncoupled. To essentially decouple these right hand sides, we setup a bootstrap\nargument. We use the $r^p$ method of Dafermos and Rodnianski in [M. Dafermos\nand I. Rodnianski, A new physical-space approach to decay for the wave equation\nwith applications to black hole spacetimes, in XVIth International Congress on\nMathematical Physics, Pavel Exner ed., Prague 2009 pp. 421-433, 2009,\narXiv:0910.4957] in order to deduce decay of some null components, and we infer\ndecay for the remaining quantities by integrating the MBI system as transport\nequations.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Addressing Class Imbalance in Classification Problems of Noisy Signals by using Fourier Transform Surrogates.   Randomizing the Fourier-transform (FT) phases of temporal-spatial data\ngenerates surrogates that approximate examples from the data-generating\ndistribution. We propose such FT surrogates as a novel tool to augment and\nanalyze training of neural networks and explore the approach in the example of\nsleep-stage classification. By computing FT surrogates of raw EEG, EOG, and EMG\nsignals of under-represented sleep stages, we balanced the CAPSLPDB sleep\ndatabase. We then trained and tested a convolutional neural network for sleep\nstage classification, and found that our surrogate-based augmentation improved\nthe mean F1-score by 7%. As another application of FT surrogates, we formulated\nan approach to compute saliency maps for individual sleep epochs. The\nvisualization is based on the response of inferred class probabilities under\nreplacement of short data segments by partial surrogates. To quantify how well\nthe distributions of the surrogates and the original data match, we evaluated a\ntrained classifier on surrogates of correctly classified examples, and\nsummarized these conditional predictions in a confusion matrix. We show how\nsuch conditional confusion matrices can qualitatively explain the performance\nof surrogates in class balancing. The FT-surrogate augmentation approach may\nimprove classification on noisy signals if carefully adapted to the data\ndistribution under analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Testing convexity of a discrete distribution.   Based on the convex least-squares estimator, we propose two different\nprocedures for testing convexity of a probability mass function supported on N\nwith an unknown finite support. The procedures are shown to be asymptotically\ncalibrated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimizing Long Short-Term Memory Recurrent Neural Networks Using Ant Colony Optimization to Predict Turbine Engine Vibration.   This article expands on research that has been done to develop a recurrent\nneural network (RNN) capable of predicting aircraft engine vibrations using\nlong short-term memory (LSTM) neurons. LSTM RNNs can provide a more\ngeneralizable and robust method for prediction over analytical calculations of\nengine vibration, as analytical calculations must be solved iteratively based\non specific empirical engine parameters, making this approach ungeneralizable\nacross multiple engines. In initial work, multiple LSTM RNN architectures were\nproposed, evaluated and compared. This research improves the performance of the\nmost effective LSTM network design proposed in the previous work by using a\npromising neuroevolution method based on ant colony optimization (ACO) to\ndevelop and enhance the LSTM cell structure of the network. A parallelized\nversion of the ACO neuroevolution algorithm has been developed and the evolved\nLSTM RNNs were compared to the previously used fixed topology. The evolved\nnetworks were trained on a large database of flight data records obtained from\nan airline containing flights that suffered from excessive vibration. Results\nwere obtained using MPI (Message Passing Interface) on a high performance\ncomputing (HPC) cluster, evolving 1000 different LSTM cell structures using 168\ncores over 4 days. The new evolved LSTM cells showed an improvement of 1.35%,\nreducing prediction error from 5.51% to 4.17% when predicting excessive engine\nvibrations 10 seconds in the future, while at the same time dramatically\nreducing the number of weights from 21,170 to 11,810.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum machine learning: a classical perspective.   Recently, increased computational power and data availability, as well as\nalgorithmic advances, have led machine learning techniques to impressive\nresults in regression, classification, data-generation and reinforcement\nlearning tasks. Despite these successes, the proximity to the physical limits\nof chip fabrication alongside the increasing size of datasets are motivating a\ngrowing number of researchers to explore the possibility of harnessing the\npower of quantum computation to speed-up classical machine learning algorithms.\nHere we review the literature in quantum machine learning and discuss\nperspectives for a mixed readership of classical machine learning and quantum\ncomputation experts. Particular emphasis will be placed on clarifying the\nlimitations of quantum algorithms, how they compare with their best classical\ncounterparts and why quantum resources are expected to provide advantages for\nlearning problems. Learning in the presence of noise and certain\ncomputationally hard problems in machine learning are identified as promising\ndirections for the field. Practical questions, like how to upload classical\ndata into quantum form, will also be addressed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Formal Synthesis of Control Strategies for Positive Monotone Systems.   We design controllers from formal specifications for positive discrete-time\nmonotone systems that are subject to bounded disturbances. Such systems are\nwidely used to model the dynamics of transportation and biological networks.\nThe specifications are described using signal temporal logic (STL), which can\nexpress a broad range of temporal properties. We formulate the problem as a\nmixed-integer linear program (MILP) and show that under the assumptions made in\nthis paper, which are not restrictive for traffic applications, the existence\nof open-loop control policies is sufficient and almost necessary to ensure the\nsatisfaction of STL formulas. We establish a relation between satisfaction of\nSTL formulas in infinite time and set-invariance theories and provide an\nefficient method to compute robust control invariant sets in high dimensions.\nWe also develop a robust model predictive framework to plan controls optimally\nwhile ensuring the satisfaction of the specification. Illustrative examples and\na traffic management case study are included.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Solving Graph Isomorphism Problem for a Special case.   Graph isomorphism is an important computer science problem. The problem for\nthe general case is unknown to be in polynomial time. The base algorithm for\nthe general case works in quasi-polynomial time. The solutions in polynomial\ntime for some special type of classes are known. In this work, we have worked\nwith a special type of graphs. We have proposed a method to represent these\ngraphs and finding isomorphism between these graphs. The method uses a modified\nversion of the degree list of a graph and neighbourhood degree list. These\nspecial type of graphs have a property that neighbourhood degree list of any\ntwo immediate neighbours is different for every vertex.The representation\nbecomes invariant to the order in which the node was selected for giving the\nrepresentation making the isomorphism problem trivial for this case. The\nalgorithm works in $O(n^4)$ time, where n is the number of vertices present in\nthe graph. The proposed algorithm runs faster than quasi-polynomial time for\nthe graphs used in the study.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Benefits from Superposed Hawkes Processes.   The superposition of temporal point processes has been studied for many\nyears, although the usefulness of such models for practical applications has\nnot be fully developed. We investigate superposed Hawkes process as an\nimportant class of such models, with properties studied in the framework of\nleast squares estimation. The superposition of Hawkes processes is demonstrated\nto be beneficial for tightening the upper bound of excess risk under certain\nconditions, and we show the feasibility of the benefit in typical situations.\nThe usefulness of superposed Hawkes processes is verified on synthetic data,\nand its potential to solve the cold-start problem of recommendation systems is\ndemonstrated on real-world data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Einstein's 1935 papers: EPR=ER?.   In May of 1935, Einstein published with two co-authors the famous EPR-paper\nabout entangled particles, which questioned the completeness of Quantum\nMechanics by means of a gedankenexperiment. Only one month later, he published\na work that seems unconnected to the EPR-paper at first, the so called\nEinstein-Rosen-paper, that presented a solution of the field equations for\nparticles in the framework of general relativity. Both papers ask for the\nconception of completeness in a theory and, from a modern perspective, it is\neasy to believe that there is a connection between these topics. We question\nwhether Einstein might have considered that a correlation between nonlocal\nfeatures of Quantum Mechanics and the Einstein-Rosen bridge can be used to\nexplain entanglement. We analyse this question by discussing the used\nconceptions of \"completeness,\" \"atomistic structure of matter,\" and \"quantum\nphenomena.\" We discuss the historical embedding of the two works and the\ncontext to modern research. Recent approaches are presented that formulate an\nEPR=ER principle and claim an equivalence of the basic principles of these two\npapers.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Fractal dimension and lower bounds for geometric problems.   We study the complexity of geometric problems on spaces of low fractal\ndimension. It was recently shown by [Sidiropoulos & Sridhar, SoCG 2017] that\nseveral problems admit improved solutions when the input is a pointset in\nEuclidean space with fractal dimension smaller than the ambient dimension. In\nthis paper we prove nearly-matching lower bounds, thus establishing\nnearly-optimal bounds for various problems as a function of the fractal\ndimension.\nMore specifically, we show that for any set of $n$ points in $d$-dimensional\nEuclidean space, of fractal dimension $\\delta\\in (1,d)$, for any $\\epsilon >0$\nand $c\\geq 1$, any $c$-spanner must have treewidth at least $\\Omega \\left(\n\\frac{n^{1-1/(\\delta - \\epsilon)}}{c^{d-1}} \\right)$, matching the previous\nupper bound. The construction used to prove this lower bound on the treewidth\nof spanners can also be used to derive lower bounds on the running time of\nalgorithms for various problems, assuming the Exponential Time Hypothesis. We\nprovide two prototypical results of this type. For any $\\delta \\in (1,d)$ and\nany $\\epsilon >0$ we show that:\n1) $d$-dimensional Euclidean TSP on $n$ points with fractal dimension at most\n$\\delta$ cannot be solved in time $2^{O\\left(n^{1-1/(\\delta - \\epsilon)}\n\\right)}$. The best-known upper bound is $2^{O(n^{1-1/\\delta} \\log n)}$.\n2) The problem of finding $k$-pairwise non-intersecting $d$-dimensional unit\nballs/axis parallel unit cubes with centers having fractal dimension at most\n$\\delta$ cannot be solved in time $f(k)n^{O \\left(k^{1-1/(\\delta -\n\\epsilon)}\\right)}$ for any computable function $f$. The best-known upper bound\nis $n^{O(k^{1-1/\\delta} \\log n)}$.\nThe above results nearly match previously known upper bounds from\n[Sidiropoulos & Sridhar, SoCG 2017], and generalize analogous lower bounds for\nthe case of ambient dimension due to [Marx & Sidiropoulos, SoCG 2014].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved approximation algorithm for the Dense-3-Subhypergraph Problem.   The study of Dense-$3$-Subhypergraph problem was initiated in Chlamt{á}c\net al. [Approx'16]. The input is a universe $U$ and collection ${\\cal S}$ of\nsubsets of $U$, each of size $3$, and a number $k$. The goal is to choose a set\n$W$ of $k$ elements from the universe, and maximize the number of sets, $S\\in\n{\\cal S}$ so that $S\\subseteq W$. The members in $U$ are called {\\em vertices}\nand the sets of ${\\cal S}$ are called the {\\em hyperedges}. This is the\nsimplest extension into hyperedges of the case of sets of size $2$ which is the\nwell known Dense $k$-subgraph problem.\nThe best known ratio for the Dense-$3$-Subhypergraph is $O(n^{0.69783..})$ by\nChlamt{á}c et al. We improve this ratio to $n^{0.61802..}$. More\nimportantly, we give a new algorithm that approximates Dense-$3$-Subhypergraph\nwithin a ratio of $\\tilde O(n/k)$, which improves the ratio of $O(n^2/k^2)$ of\nChlamt{á}c et al.\nWe prove that under the {\\em log density conjecture} (see Bhaskara et al.\n[STOC'10]) the ratio cannot be better than $\\Omega(\\sqrt{n})$ and demonstrate\nsome cases in which this optimum can be attained.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Almost complex structures on connected sums of complex projective spaces.   We show that the m-fold connected sum $m\\#\\mathbb{C}\\mathbb{P}^{2n}$ admits\nan almost complex structure if and only if m is odd.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Kustaanheimo-Stiefel transformation with an arbitrary defining vector.   Kustaanheimo-Stiefel (KS) transformation depends on the choice of some\npreferred direction in the Cartesian 3D space. This choice, seldom explicitly\nmentioned, amounts typically to the direction of the first or the third\ncoordinate axis in celestial mechanics and atomic physics, respectively. The\npresent work develops a canonical KS transformation with an arbitrary preferred\ndirection, indicated by what we call a defining vector. Using a mix of vector\nand quaternion algebra, we formulate the transformation in a reference frame\nindependent manner. The link between the oscillator and Keplerian first\nintegrals is given. As an example of the present formulation, the Keplerian\nmotion in a rotating frame is re-investigated.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Large Scale Graph Learning from Smooth Signals.   Graphs are a prevalent tool in data science, as they model the inherent\nstructure of the data. They have been used successfully in unsupervised and\nsemi-supervised learning. Typically they are constructed either by connecting\nnearest samples, or by learning them from data, solving an optimization\nproblem. While graph learning does achieve a better quality, it also comes with\na higher computational cost. In particular, the current state-of-the-art model\ncost is $\\mathcal{O}(n^2)$ for $n$ samples. In this paper, we show how to scale\nit, obtaining an approximation with leading cost of $\\mathcal{O}(n\\log(n))$,\nwith quality that approaches the exact graph learning model. Our algorithm uses\nknown approximate nearest neighbor techniques to reduce the number of\nvariables, and automatically selects the correct parameters of the model,\nrequiring a single intuitive input: the desired edge density.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sports stars: analyzing the performance of astronomers at visualization-based discovery.   In this data-rich era of astronomy, there is a growing reliance on automated\ntechniques to discover new knowledge. The role of the astronomer may change\nfrom being a discoverer to being a confirmer. But what do astronomers actually\nlook at when they distinguish between \"sources\" and \"noise?\" What are the\ndifferences between novice and expert astronomers when it comes to visual-based\ndiscovery? Can we identify elite talent or coach astronomers to maximize their\npotential for discovery? By looking to the field of sports performance\nanalysis, we consider an established, domain-wide approach, where the expertise\nof the viewer (i.e. a member of the coaching team) plays a crucial role in\nidentifying and determining the subtle features of gameplay that provide a\nwinning advantage. As an initial case study, we investigate whether the\nSportsCode performance analysis software can be used to understand and document\nhow an experienced HI astronomer makes discoveries in spectral data cubes. We\nfind that the process of timeline-based coding can be applied to spectral cube\ndata by mapping spectral channels to frames within a movie. SportsCode provides\na range of easy to use methods for annotation, including feature-based codes\nand labels, text annotations associated with codes, and image-based drawing.\nThe outputs, including instance movies that are uniquely associated with coded\nevents, provide the basis for a training program or team-based analysis that\ncould be used in unison with discipline specific analysis software. In this\ncoordinated approach to visualization and analysis, SportsCode can act as a\nvisual notebook, recording the insight and decisions in partnership with\nestablished analysis methods. Alternatively, in situ annotation and coding of\nfeatures would be a valuable addition to existing and future visualisation and\nanalysis packages.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Uniqueness of planar vortex patch in incompressible steady flow.   We investigate a steady planar flow of an ideal fluid in a bounded simple\nconnected domain and focus on the vortex patch problem with prescribed\nvorticity strength. There are two methods to deal with the existence of\nsolutions for this problem: the vorticity method and the stream function\nmethod. A long standing open problem is whether these two entirely different\nmethods result in the same solution. In this paper, we will give a positive\nanswer to this problem by studying the local uniqueness of the solutions.\nAnother result obtained in this paper is that if the domain is convex, then the\nvortex patch problem has a unique solution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exact partial information decompositions for Gaussian systems based on dependency constraints.   The Partial Information Decomposition (PID) [arXiv:1004.2515] provides a\ntheoretical framework to characterize and quantify the structure of\nmultivariate information sharing. A new method (Idep) has recently been\nproposed for computing a two-predictor PID over discrete spaces.\n[arXiv:1709.06653] A lattice of maximum entropy probability models is\nconstructed based on marginal dependency constraints, and the unique\ninformation that a particular predictor has about the target is defined as the\nminimum increase in joint predictor-target mutual information when that\nparticular predictor-target marginal dependency is constrained. Here, we apply\nthe Idep approach to Gaussian systems, for which the marginally constrained\nmaximum entropy models are Gaussian graphical models. Closed form solutions for\nthe Idep PID are derived for both univariate and multivariate Gaussian systems.\nNumerical and graphical illustrations are provided, together with practical and\ntheoretical comparisons of the Idep PID with the minimum mutual information PID\n(Immi). [arXiv:1411.2832] In particular, it is proved that the Immi method\ngenerally produces larger estimates of redundancy and synergy than does the\nIdep method. In discussion of the practical examples, the PIDs are complemented\nby the use of deviance tests for the comparison of Gaussian graphical models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On convergence for graphexes.   We study four different notions of convergence for graphexes, recently\nintroduced by Borgs, Chayes, Cohn and Holden, and by Veitch and Roy. We give\nsome properties of them and some relations between them. We also extend results\nby Veitch and Roy on convergence of empirical graphons.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Local and global existence of solutions to a strongly damped wave equation of the $p$-Laplacian type.   This article focuses on a quasilinear wave equation of $p$-Laplacian type: $$\nu_{tt} - \\Delta_p u - \\Delta u_t=0$$ in a bounded domain\n$\\Omega\\subset\\mathbb{R}^3$ with a sufficiently smooth boundary\n$\\Gamma=\\partial\\Omega$ subject to a generalized Robin boundary condition\nfeaturing boundary damping and a nonlinear source term. The operator\n$\\Delta_p$, $2 < p < 3$, denotes the classical $p$-Laplacian. The nonlinear\nboundary term $f (u)$ is a source feedback that is allowed to have a\nsupercritical exponent, in the sense that the associated Nemytskii operator is\nnot locally Lipschitz from $W^{1,p}(\\Omega)$ into $L^2(\\Gamma)$. Under suitable\nassumptions on the parameters we provide a rigorous proof of existence of a\nlocal weak solution which can be extended globally in time provided the source\nterm satisfies an appropriate growth condition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectral Graph Convolutions for Population-based Disease Prediction.   Exploiting the wealth of imaging and non-imaging information for disease\nprediction tasks requires models capable of representing, at the same time,\nindividual features as well as data associations between subjects from\npotentially large populations. Graphs provide a natural framework for such\ntasks, yet previous graph-based approaches focus on pairwise similarities\nwithout modelling the subjects' individual characteristics and features. On the\nother hand, relying solely on subject-specific imaging feature vectors fails to\nmodel the interaction and similarity between subjects, which can reduce\nperformance. In this paper, we introduce the novel concept of Graph\nConvolutional Networks (GCN) for brain analysis in populations, combining\nimaging and non-imaging data. We represent populations as a sparse graph where\nits vertices are associated with image-based feature vectors and the edges\nencode phenotypic information. This structure was used to train a GCN model on\npartially labelled graphs, aiming to infer the classes of unlabelled nodes from\nthe node features and pairwise associations between subjects. We demonstrate\nthe potential of the method on the challenging ADNI and ABIDE databases, as a\nproof of concept of the benefit from integrating contextual information in\nclassification tasks. This has a clear impact on the quality of the\npredictions, leading to 69.5% accuracy for ABIDE (outperforming the current\nstate of the art of 66.8%) and 77% for ADNI for prediction of MCI conversion,\nsignificantly outperforming standard linear classifiers where only individual\nfeatures are considered.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Second order structural phase transitions, free energy curvature, and temperature-dependent anharmonic phonons in the self-consistent harmonic approximation: theory and stochastic implementation.   The self-consistent harmonic approximation is an effective harmonic theory to\ncalculate the free energy of systems with strongly anharmonic atomic\nvibrations, and its stochastic implementation has proved to be an efficient\nmethod to study, from first-principles, the anharmonic properties of solids.\nThe free energy as a function of average atomic positions (centroids) can be\nused to study quantum or thermal lattice instability. In particular the\ncentroids are order parameters in second-order structural phase transitions\nsuch as, e.g., charge-density-waves or ferroelectric instabilities. According\nto Landau's theory, the knowledge of the second derivative of the free energy\n(i.e. the curvature) with respect to the centroids in a high-symmetry\nconfiguration allows the identification of the phase-transition and of the\ninstability modes. In this work we derive the exact analytic formula for the\nsecond derivative of the free energy in the self-consistent harmonic\napproximation for a generic atomic configuration. The analytic derivative is\nexpressed in terms of the atomic displacements and forces in a form that can be\nevaluated by a stochastic technique using importance sampling. Our approach is\nparticularly suitable for applications based on first-principles\ndensity-functional-theory calculations, where the forces on atoms can be\nobtained with a negligible computational effort compared to total energy\ndetermination. Finally we propose a dynamical extension of the theory to\ncalculate spectral properties of strongly anharmonic phonons, as probed by\ninelastic scattering processes. We illustrate our method with a numerical\napplication on a toy model that mimics the ferroelectric transition in\nrock-salt crystals such as SnTe or GeTe.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Diffraction-limited plenoptic imaging with correlated light.   Traditional optical imaging faces an unavoidable trade-off between resolution\nand depth of field (DOF). To increase resolution, high numerical apertures (NA)\nare needed, but the associated large angular uncertainty results in a limited\nrange of depths that can be put in sharp focus. Plenoptic imaging was\nintroduced a few years ago to remedy this trade off. To this aim, plenoptic\nimaging reconstructs the path of light rays from the lens to the sensor.\nHowever, the improvement offered by standard plenoptic imaging is practical and\nnot fundamental: the increased DOF leads to a proportional reduction of the\nresolution well above the diffraction limit imposed by the lens NA. In this\npaper, we demonstrate that correlation measurements enable pushing plenoptic\nimaging to its fundamental limits of both resolution and DOF. Namely, we\ndemonstrate to maintain the imaging resolution at the diffraction limit while\nincreasing the depth of field by a factor of 7. Our results represent the\ntheoretical and experimental basis for the effective development of the\npromising applications of plenoptic imaging.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "DeepFense: Online Accelerated Defense Against Adversarial Deep Learning.   Recent advances in adversarial Deep Learning (DL) have opened up a largely\nunexplored surface for malicious attacks jeopardizing the integrity of\nautonomous DL systems. With the wide-spread usage of DL in critical and\ntime-sensitive applications, including unmanned vehicles, drones, and video\nsurveillance systems, online detection of malicious inputs is of utmost\nimportance. We propose DeepFense, the first end-to-end automated framework that\nsimultaneously enables efficient and safe execution of DL models. DeepFense\nformalizes the goal of thwarting adversarial attacks as an optimization problem\nthat minimizes the rarely observed regions in the latent feature space spanned\nby a DL network. To solve the aforementioned minimization problem, a set of\ncomplementary but disjoint modular redundancies are trained to validate the\nlegitimacy of the input samples in parallel with the victim DL model. DeepFense\nleverages hardware/software/algorithm co-design and customized acceleration to\nachieve just-in-time performance in resource-constrained settings. The proposed\ncountermeasure is unsupervised, meaning that no adversarial sample is leveraged\nto train modular redundancies. We further provide an accompanying API to reduce\nthe non-recurring engineering cost and ensure automated adaptation to various\nplatforms. Extensive evaluations on FPGAs and GPUs demonstrate up to two orders\nof magnitude performance improvement while enabling online adversarial sample\ndetection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Resilient Non-Submodular Maximization over Matroid Constraints.   The control and sensing of large-scale systems results in combinatorial\nproblems not only for sensor and actuator placement but also for scheduling or\nobservability/controllability. Such combinatorial constraints in system design\nand implementation can be captured using a structure known as matroids. In\nparticular, the algebraic structure of matroids can be exploited to develop\nscalable algorithms for sensor and actuator selection, along with quantifiable\napproximation bounds. However, in large-scale systems, sensors and actuators\nmay fail or may be (cyber-)attacked. The objective of this paper is to focus on\nresilient matroid-constrained problems arising in control and sensing but in\nthe presence of sensor and actuator failures. In general, resilient\nmatroid-constrained problems are computationally hard. Contrary to the\nnon-resilient case (with no failures), even though they often involve objective\nfunctions that are monotone or submodular, no scalable approximation algorithms\nare known for their solution. In this paper, we provide the first algorithm,\nthat also has the following properties: First, it achieves system-wide\nresiliency, i.e., the algorithm is valid for any number of denial-of-service\nattacks or failures. Second, it is scalable, as our algorithm terminates with\nthe same running time as state-of-the-art algorithms for (non-resilient)\nmatroid-constrained optimization. Third, it provides provable approximation\nbounds on the system performance, since for monotone objective functions our\nalgorithm guarantees a solution close to the optimal. We quantify our\nalgorithm's approximation performance using a notion of curvature for monotone\n(not necessarily submodular) set functions. Finally, we support our theoretical\nanalyses with numerical experiments, by considering a control-aware sensor\nselection scenario, namely, sensing-constrained robot navigation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Design, Engineering and Optimization of a Grid-Tie Multicell Inverter for Energy Storage Applications.   Multilevel converters have found many applications within renewable energy\nsystems thanks to their unique capability of generating multiple voltage\nlevels. However, these converters need multiple DC sources and the voltage\nbalancing over capacitors for these systems is cumbersome. In this work, a new\ngrid-tie multicell inverter with high level of safety has been designed,\nengineered and optimized for integrating energy storage devices to the electric\ngrid. The multilevel converter proposed in this work is capable of maintaining\nthe flying capacitors voltage in the desired value. The solar cells are the\nprimary energy sources for proposed inverter where the maximum power density is\nobtained. Finally, the performance of the inverter and its control method\nsimulated using PSCAD/EMTDC software package and good agreement achieved with\nexperimental data.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Price of Diversity in Assignment Problems.   We introduce and analyze an extension to the matching problem on a weighted\nbipartite graph: Assignment with Type Constraints. The two parts of the graph\nare partitioned into subsets called types and blocks; we seek a matching with\nthe largest sum of weights under the constraint that there is a pre-specified\ncap on the number of vertices matched in every type-block pair. Our primary\nmotivation stems from the public housing program of Singapore, accounting for\nover 70% of its residential real estate. To promote ethnic diversity within its\nhousing projects, Singapore imposes ethnicity quotas: each new housing\ndevelopment comprises blocks of flats and each ethnicity-based group in the\npopulation must not own more than a certain percentage of flats in a block.\nOther domains using similar hard capacity constraints include matching\nprospective students to schools or medical residents to hospitals. Limiting\nagents' choices for ensuring diversity in this manner naturally entails some\nwelfare loss. One of our goals is to study the trade-off between diversity and\nsocial welfare in such settings. We first show that, while the classic\nassignment program is polynomial-time computable, adding diversity constraints\nmakes it computationally intractable; however, we identify a\n$\\tfrac{1}{2}$-approximation algorithm, as well as reasonable assumptions on\nthe weights that permit poly-time algorithms. Next, we provide two upper bounds\non the price of diversity -- a measure of the loss in welfare incurred by\nimposing diversity constraints -- as functions of natural problem parameters.\nWe conclude the paper with simulations based on publicly available data from\ntwo diversity-constrained allocation problems -- Singapore Public Housing and\nChicago School Choice -- which shed light on how the constrained maximization\nas well as lottery-based variants perform in practice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "\\textit{Ab Initio} Study of the Magnetic Behavior of Metal Hydrides: A Comparison with the Slater-Pauling Curve.   We investigated the magnetic behavior of metal hydrides FeH$_{x}$, CoH$_{x}$\nand NiH$_{x}$ for several concentrations of hydrogen ($x$) by using Density\nFunctional Theory calculations. Several structural phases of the metallic host:\nbcc ($\\alpha$), fcc ($\\gamma$), hcp ($\\varepsilon$), dhcp ($\\varepsilon'$),\ntetragonal structure for FeH$_{x}$ and $\\varepsilon$-$\\gamma$ phases for\nCoH$_{x}$, were studied. We found that for CoH$_{x}$ and NiH$_{x}$ the magnetic\nmoment ($m$) decreases regardless the concentration $x$. However, for FeH$_{x}$\nsystems, $m$ increases or decreases depending on the variation in $x$. In order\nto find a general trend for these changes of $m$ in magnetic metal hydrides, we\ncompare our results with the Slater-Pauling curve for ferromagnetic metallic\nbinary alloys. It is found that the $m$ of metal hydrides made of Fe, Co and Ni\nfits the shape of the Slater-Pauling curve as a function of $x$. Our results\nindicate that there are two main effects that determine the $m$ value due to\nhydrogenation: an increase of volume causes $m$ to increase, and the addition\nof an extra electron to the metal always causes it to decrease. We discuss\nthese behaviors in detail.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Floquet prethermalization in the resonantly driven Hubbard model.   We demonstrate the existence of long-lived prethermalized states in the Mott\ninsulating Hubbard model driven by periodic electric fields. These states,\nwhich also exist in the resonantly driven case with a large density of\nphoto-induced doublons and holons, are characterized by a nonzero current and\nan effective temperature of the doublons and holons which depends sensitively\non the driving condition. Focusing on the specific case of resonantly driven\nmodels whose effective time-independent Hamiltonian in the high-frequency\ndriving limit corresponds to noninteracting fermions, we show that the time\nevolution of the double occupation can be reproduced by the effective\nHamiltonian, and that the prethermalization plateaus at finite driving\nfrequency are controlled by the next-to-leading order correction in the\nhigh-frequency expansion of the effective Hamiltonian. We propose a numerical\nprocedure to determine an effective Hubbard interaction that mimics the\ncorrelation effects induced by these higher order terms.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Synthesizing Neural Network Controllers with Probabilistic Model based Reinforcement Learning.   We present an algorithm for rapidly learning controllers for robotics\nsystems. The algorithm follows the model-based reinforcement learning paradigm,\nand improves upon existing algorithms; namely Probabilistic learning in Control\n(PILCO) and a sample-based version of PILCO with neural network dynamics\n(Deep-PILCO). We propose training a neural network dynamics model using\nvariational dropout with truncated Log-Normal noise. This allows us to obtain a\ndynamics model with calibrated uncertainty, which can be used to simulate\ncontroller executions via rollouts. We also describe set of techniques,\ninspired by viewing PILCO as a recurrent neural network model, that are crucial\nto improve the convergence of the method. We test our method on a variety of\nbenchmark tasks, demonstrating data-efficiency that is competitive with PILCO,\nwhile being able to optimize complex neural network controllers. Finally, we\nassess the performance of the algorithm for learning motor controllers for a\nsix legged autonomous underwater vehicle. This demonstrates the potential of\nthe algorithm for scaling up the dimensionality and dataset sizes, in more\ncomplex control tasks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bridging Semantic Gaps between Natural Languages and APIs with Word Embedding.   Developers increasingly rely on text matching tools to analyze the relation\nbetween natural language words and APIs. However, semantic gaps, namely textual\nmismatches between words and APIs, negatively affect these tools. Previous\nstudies have transformed words or APIs into low-dimensional vectors for\nmatching; however, inaccurate results were obtained due to the failure of\nmodeling words and APIs simultaneously. To resolve this problem, two main\nchallenges are to be addressed: the acquisition of massive words and APIs for\nmining and the alignment of words and APIs for modeling. Therefore, this study\nproposes Word2API to effectively estimate relatedness of words and APIs.\nWord2API collects millions of commonly used words and APIs from code\nrepositories to address the acquisition challenge. Then, a shuffling strategy\nis used to transform related words and APIs into tuples to address the\nalignment challenge. Using these tuples, Word2API models words and APIs\nsimultaneously. Word2API outperforms baselines by 10%-49.6% of relatedness\nestimation in terms of precision and NDCG. Word2API is also effective on\nsolving typical software tasks, e.g., query expansion and API documents\nlinking. A simple system with Word2API-expanded queries recommends up to 21.4%\nmore related APIs for developers. Meanwhile, Word2API improves comparison\nalgorithms by 7.9%-17.4% in linking questions in Question&Answer communities to\nAPI documents.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scattering dominated high-temperature phase of 1T-TiSe2: an optical conductivity study.   The controversy regarding the precise nature of the high-temperature phase of\n1T-TiSe2 lasts for decades. It has intensified in recent times when new\nevidence for the excitonic origin of the low-temperature charge-density wave\nstate started to unveil. Here we address the problem of the high-temperature\nphase through precise measurements and detailed analysis of the optical\nresponse of 1T-TiSe2 single crystals. The separate responses of electron and\nhole subsystems are identified and followed in temperature. We show that\nneither semiconductor nor semimetal pictures can be applied in their generic\nforms as the scattering for both types of carriers is in the vicinity of the\nIoffe-Regel limit with decay rates being comparable to or larger than the\noffsets of band extrema. The nonmetallic temperature dependence of transport\nproperties comes from the anomalous temperature dependence of scattering rates.\nNear the transition temperature the heavy electrons and the light holes\ncontribute equally to the conductivity. This surprising coincidence is regarded\nas the consequence of dominant intervalley scattering that precedes the\ntransition. The low-frequency peak in the optical spectra is identified and\nattributed to the critical softening of the L-point collective mode.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Backward-emitted sub-Doppler fluorescence from an optically thick atomic vapor.   Literature mentions only incidentally a sub-Doppler contribution in the\nexcitation spectrum of the backward fluorescence of a dense vapor. This\ncontribution is here investigated on Cs vapor, both on the first resonance line\n(894 nm) and on the weaker second resonance line (459 nm). We show that in a\nstrongly absorbing medium, the quenching of excited atoms moving towards a\nwindow irradiated under near normal incidence reduces the fluorescence on the\nred side of the excitation spectrum. Atoms moving slowly towards the window\nproduce a sub- Doppler velocity-selective contribution, whose visibility is\nhere improved by applying a frequency-modulation technique. This sub-Doppler\nfeature, induced by a surface quenching combined with a short absorption length\nfor the incident irradiation, exhibits close analogies with the narrow spectra\nappearing with thin vapor cells. We also show that a normal incidence\nirradiation is essential for the sub-Doppler feature to be observed, while it\nshould be independent of the detection geometry",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Planning with Verbal Communication for Human-Robot Collaboration.   Human collaborators coordinate effectively their actions through both verbal\nand non-verbal communication. We believe that the the same should hold for\nhuman-robot teams. We propose a formalism that enables a robot to decide\noptimally between doing a task and issuing an utterance. We focus on two types\nof utterances: verbal commands, where the robot expresses how it wants its\nhuman teammate to behave, and state-conveying actions, where the robot explains\nwhy it is behaving this way. Human subject experiments show that enabling the\nrobot to issue verbal commands is the most effective form of communicating\nobjectives, while retaining user trust in the robot. Communicating why\ninformation should be done judiciously, since many participants questioned the\ntruthfulness of the robot statements.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Superconductivity in ultra-thin carbon nanotubes and carbyne-nanotube composites: an ab-initio approach.   The superconductivity of the 4-angstrom single-walled carbon nanotubes\n(SWCNTs) was discovered more than a decade ago, and marked the breakthrough of\nfinding superconductivity in pure elemental undoped carbon compounds. The van\nHove singularities in the electronic density of states at the Fermi level in\ncombination with a large Debye temperature of the SWCNTs are expected to cause\nan impressively large superconducting gap. We have developed an innovative\ncomputational algorithm specially tailored for the investigation of\nsuperconductivity in ultrathin SWCNTs. We predict the superconducting\ntransition temperature of various thin carbon nanotubes resulting from\nelectron-phonon coupling by an ab-initio method, taking into account the effect\nof radial pressure, symmetry, chirality (N,M) and bond lengths. By optimizing\nthe geometry of the carbon nanotubes, a maximum Tc of 60K is found. We also use\nour method to calculate the Tc of a linear carbon chain embedded in the center\nof (5,0) SWCNTs. The strong curvature in the (5,0) carbon nanotubes in the\npresence of the inner carbon chain provides an alternative path to increase the\nTc of this carbon composite by a factor of 2.2 with respect to the empty (5,0)\nSWCNTs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Actively Learning what makes a Discrete Sequence Valid.   Deep learning techniques have been hugely successful for traditional\nsupervised and unsupervised machine learning problems. In large part, these\ntechniques solve continuous optimization problems. Recently however, discrete\ngenerative deep learning models have been successfully used to efficiently\nsearch high-dimensional discrete spaces. These methods work by representing\ndiscrete objects as sequences, for which powerful sequence-based deep models\ncan be employed. Unfortunately, these techniques are significantly hindered by\nthe fact that these generative models often produce invalid sequences. As a\nstep towards solving this problem, we propose to learn a deep recurrent\nvalidator model. Given a partial sequence, our model learns the probability of\nthat sequence occurring as the beginning of a full valid sequence. Thus this\nidentifies valid versus invalid sequences and crucially it also provides\ninsight about how individual sequence elements influence the validity of\ndiscrete objects. To learn this model we propose an approach inspired by\nseminal work in Bayesian active learning. On a synthetic dataset, we\ndemonstrate the ability of our model to distinguish valid and invalid\nsequences. We believe this is a key step toward learning generative models that\nfaithfully produce valid discrete objects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On stably trivial spin torsors over low-dimensional schemes.   The paper discusses stably trivial torsors for spin and orthogonal groups\nover smooth affine schemes over infinite perfect fields of characteristic\nunequal to 2. We give a complete description of all the invariants relevant for\nthe classification of such objects over schemes of dimension at most $3$, along\nwith many examples. The results are based on the\n$\\mathbb{A}^1$-representability theorem for torsors and transfer of known\ncomputations of $\\mathbb{A}^1$-homotopy sheaves along the sporadic isomorphisms\nto spin groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a Deep Improviser: a prototype deep learning post-tonal free music generator.   Two modest-sized symbolic corpora of post-tonal and post-metric keyboard\nmusic have been constructed, one algorithmic, the other improvised. Deep\nlearning models of each have been trained and largely optimised. Our purpose is\nto obtain a model with sufficient generalisation capacity that in response to a\nsmall quantity of separate fresh input seed material, it can generate outputs\nthat are distinctive, rather than recreative of the learned corpora or the seed\nmaterial. This objective has been first assessed statistically, and as judged\nby k-sample Anderson-Darling and Cramer tests, has been achieved. Music has\nbeen generated using the approach, and informal judgements place it roughly on\na par with algorithmic and composed music in related forms. Future work will\naim to enhance the model such that it can be evaluated in relation to\nexpression, meaning and utility in real-time performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Levels of distribution for sieve problems in prehomogeneous vector spaces.   In a companion paper, we developed an efficient algebraic method for\ncomputing the Fourier transforms of certain functions defined on prehomogeneous\nvector spaces over finite fields, and we carried out these computations in a\nvariety of cases.\nHere we develop a method, based on Fourier analysis and algebraic geometry,\nwhich exploits these Fourier transform formulas to yield level of distribution\nresults, in the sense of analytic number theory. Such results are of the shape\ntypically required for a variety of sieve methods. As an example of such an\napplication we prove that there are $\\gg$ X/log(X) quartic fields whose\ndiscriminant is squarefree, bounded above by X, and has at most eight prime\nfactors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Equilibria, information and frustration in heterogeneous network games with conflicting preferences.   Interactions between people are the basis on which the structure of our\nsociety arises as a complex system and, at the same time, are the starting\npoint of any physical description of it. In the last few years, much\ntheoretical research has addressed this issue by combining the physics of\ncomplex networks with a description of interactions in terms of evolutionary\ngame theory. We here take this research a step further by introducing a most\nsalient societal factor such as the individuals' preferences, a characteristic\nthat is key to understand much of the social phenomenology these days. We\nconsider a heterogeneous, agent-based model in which agents interact\nstrategically with their neighbors but their preferences and payoffs for the\npossible actions differ. We study how such a heterogeneous network behaves\nunder evolutionary dynamics and different strategic interactions, namely\ncoordination games and best shot games. With this model we study the emergence\nof the equilibria predicted analytically in random graphs under best response\ndynamics, and we extend this test to unexplored contexts like proportional\nimitation and scale free networks. We show that some theoretically predicted\nequilibria do not arise in simulations with incomplete Information, and we\ndemonstrate the importance of the graph topology and the payoff function\nparameters for some games. Finally, we discuss our results with available\nexperimental evidence on coordination games, showing that our model agrees\nbetter with the experiment that standard economic theories, and draw hints as\nto how to maximize social efficiency in situations of conflicting preferences.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Multivariate stable distributions and their applications for modelling cryptocurrency-returns.   In this paper we extend the known methodology for fitting stable\ndistributions to the multivariate case and apply the suggested method to the\nmodelling of daily cryptocurrency-return data. The investigated time period is\ncut into 10 non-overlapping sections, thus the changes can also be observed. We\napply bootstrap tests for checking the models and compare our approach to the\nmore traditional extreme-value and copula models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simultaneous Confidence Band for Partially Linear Panel Data Models with Fixed Effects.   In this paper, we construct the simultaneous confidence band (SCB) for the\nnonparametric component in partially linear panel data models with fixed\neffects. We remove the fixed effects, and further obtain the estimators of\nparametric and nonparametric components, which do not depend on the fixed\neffects. We establish the asymptotic distribution of their maximum absolute\ndeviation between the estimated nonparametric component and the true\nnonparametric component under some suitable conditions, and hence the result\ncan be used to construct the simultaneous confidence band of the nonparametric\ncomponent. Based on the asymptotic distribution, it becomes difficult for the\nconstruction of the simultaneous confidence band. The reason is that the\nasymptotic distribution involves the estimators of the asymptotic bias and\nconditional variance, and the choice of the bandwidth for estimating the second\nderivative of nonparametric function. Clearly, these will cause computational\nburden and accumulative errors. To overcome these problems, we propose a\nBootstrap method to construct simultaneous confidence band. Simulation studies\nindicate that the proposed Bootstrap method exhibits better performance under\nthe limited samples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Statistical Speech Enhancement Based on Probabilistic Integration of Variational Autoencoder and Non-Negative Matrix Factorization.   This paper presents a statistical method of single-channel speech enhancement\nthat uses a variational autoencoder (VAE) as a prior distribution on clean\nspeech. A standard approach to speech enhancement is to train a deep neural\nnetwork (DNN) to take noisy speech as input and output clean speech. Although\nthis supervised approach requires a very large amount of pair data for\ntraining, it is not robust against unknown environments. Another approach is to\nuse non-negative matrix factorization (NMF) based on basis spectra trained on\nclean speech in advance and those adapted to noise on the fly. This\nsemi-supervised approach, however, causes considerable signal distortion in\nenhanced speech due to the unrealistic assumption that speech spectrograms are\nlinear combinations of the basis spectra. Replacing the poor linear generative\nmodel of clean speech in NMF with a VAE---a powerful nonlinear deep generative\nmodel---trained on clean speech, we formulate a unified probabilistic\ngenerative model of noisy speech. Given noisy speech as observed data, we can\nsample clean speech from its posterior distribution. The proposed method\noutperformed the conventional DNN-based method in unseen noisy environments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SOLAR: Deep Structured Latent Representations for Model-Based Reinforcement Learning.   Model-based reinforcement learning (RL) methods can be broadly categorized as\nglobal model methods, which depend on learning models that provide sensible\npredictions in a wide range of states, or local model methods, which\niteratively refit simple models that are used for policy improvement. While\npredicting future states that will result from the current actions is\ndifficult, local model methods only attempt to understand system dynamics in\nthe neighborhood of the current policy, making it possible to produce local\nimprovements without ever learning to predict accurately far into the future.\nThe main idea in this paper is that we can learn representations that make it\neasy to retrospectively infer simple dynamics given the data from the current\npolicy, thus enabling local models to be used for policy learning in complex\nsystems. To that end, we focus on learning representations with probabilistic\ngraphical model (PGM) structure, which allows us to devise an efficient local\nmodel method that infers dynamics from real-world rollouts with the PGM as a\nglobal prior. We compare our method to other model-based and model-free RL\nmethods on a suite of robotics tasks, including manipulation tasks on a real\nSawyer robotic arm directly from camera images. Videos of our results are\navailable at this https URL",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "It Takes Two to Tango: Towards Theory of AI's Mind.   Theory of Mind is the ability to attribute mental states (beliefs, intents,\nknowledge, perspectives, etc.) to others and recognize that these mental states\nmay differ from one's own. Theory of Mind is critical to effective\ncommunication and to teams demonstrating higher collective performance. To\neffectively leverage the progress in Artificial Intelligence (AI) to make our\nlives more productive, it is important for humans and AI to work well together\nin a team. Traditionally, there has been much emphasis on research to make AI\nmore accurate, and (to a lesser extent) on having it better understand human\nintentions, tendencies, beliefs, and contexts. The latter involves making AI\nmore human-like and having it develop a theory of our minds. In this work, we\nargue that for human-AI teams to be effective, humans must also develop a\ntheory of AI's mind (ToAIM) - get to know its strengths, weaknesses, beliefs,\nand quirks. We instantiate these ideas within the domain of Visual Question\nAnswering (VQA). We find that using just a few examples (50), lay people can be\ntrained to better predict responses and oncoming failures of a complex VQA\nmodel. We further evaluate the role existing explanation (or interpretability)\nmodalities play in helping humans build ToAIM. Explainable AI has received\nconsiderable scientific and popular attention in recent times. Surprisingly, we\nfind that having access to the model's internal states - its confidence in its\ntop-k predictions, explicit or implicit attention maps which highlight regions\nin the image (and words in the question) the model is looking at (and listening\nto) while answering a question about an image - do not help people better\npredict its behavior.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "New low-mass eclipsing binary systems in Praesepe discovered by K2.   We present the discovery of four low-mass ($M<0.6$ $M_\\odot$) eclipsing\nbinary (EB) systems in the sub-Gyr old Praesepe open cluster using Kepler/K2\ntime-series photometry and Keck/HIRES spectroscopy. We present a new Gaussian\nprocess eclipsing binary model, GP-EBOP, as well as a method of simultaneously\ndetermining effective temperatures and distances for EBs. Three of the reported\nsystems (AD 3814, AD 2615 and AD 1508) are detached and double-lined, and\nprecise solutions are presented for the first two. We determine masses and\nradii to 1-3% precision for AD 3814 and to 5-6% for AD 2615. Together with\neffective temperatures determined to $\\sim$50 K precision, we test the PARSEC\nv1.2 and BHAC15 stellar evolution models. Our EB parameters are more consistent\nwith the PARSEC models, primarily because the BHAC15 temperature scale is\nhotter than our data over the mid M-dwarf mass range probed. Both ADs 3814 and\n2615, which have orbital periods of 6.0 and 11.6 days, are circularized but not\nsynchronized. This suggests that either synchronization proceeds more slowly in\nfully convective stars than the theory of equilibrium tides predicts or\nmagnetic braking is currently playing a more important role than tidal forces\nin the spin evolution of these binaries. The fourth system (AD 3116) comprises\na brown dwarf transiting a mid M-dwarf, which is the first such system\ndiscovered in a sub-Gyr open cluster. Finally, these new discoveries increase\nthe number of characterized EBs in sub-Gyr open clusters by 20% (40%) below\n$M<1.5$ $M_{\\odot}$ ($M<0.6$ $M_{\\odot}$).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Preserving Differential Privacy in Convolutional Deep Belief Networks.   The remarkable development of deep learning in medicine and healthcare domain\npresents obvious privacy issues, when deep neural networks are built on users'\npersonal and highly sensitive data, e.g., clinical records, user profiles,\nbiomedical images, etc. However, only a few scientific studies on preserving\nprivacy in deep learning have been conducted. In this paper, we focus on\ndeveloping a private convolutional deep belief network (pCDBN), which\nessentially is a convolutional deep belief network (CDBN) under differential\nprivacy. Our main idea of enforcing epsilon-differential privacy is to leverage\nthe functional mechanism to perturb the energy-based objective functions of\ntraditional CDBNs, rather than their results. One key contribution of this work\nis that we propose the use of Chebyshev expansion to derive the approximate\npolynomial representation of objective functions. Our theoretical analysis\nshows that we can further derive the sensitivity and error bounds of the\napproximate polynomial representation. As a result, preserving differential\nprivacy in CDBNs is feasible. We applied our model in a health social network,\ni.e., YesiWell data, and in a handwriting digit dataset, i.e., MNIST data, for\nhuman behavior prediction, human behavior classification, and handwriting digit\nrecognition tasks. Theoretical analysis and rigorous experimental evaluations\nshow that the pCDBN is highly effective. It significantly outperforms existing\nsolutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Decay Estimates and Strichartz Estimates of Fourth-order Schrödinger Operator.   We study time decay estimates of the fourth-order Schrödinger operator\n$H=(-\\Delta)^{2}+V(x)$ in $\\mathbb{R}^{d}$ for $d=3$ and $d\\geq5$. We analyze\nthe low energy and high energy behaviour of resolvent $R(H; z)$, and then\nderive the Jensen-Kato dispersion decay estimate and local decay estimate for\n$e^{-itH}P_{ac}$ under suitable spectrum assumptions of $H$. Based on\nJensen-Kato decay estimate and local decay estimate, we obtain the\n$L^1\\rightarrow L^{\\infty}$ estimate of $e^{-itH}P_{ac}$ in $3$-dimension by\nGinibre argument, and also establish the endpoint global Strichartz estimates\nof $e^{-itH}P_{ac}$ for $d\\geq5$. Furthermore, using the local decay estimate\nand the Georgescu-Larenas-Soffer conjugate operator method, we prove the\nJensen-Kato type decay estimates for some functions of $H$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Risk Bounds in Univariate Total Variation Denoising and Trend Filtering.   We study trend filtering, a relatively recent method for univariate\nnonparametric regression. For a given positive integer $r$, the $r$-th order\ntrend filtering estimator is defined as the minimizer of the sum of squared\nerrors when we constrain (or penalize) the sum of the absolute $r$-th order\ndiscrete derivatives of the fitted function at the design points. For $r=1$,\nthe estimator reduces to total variation regularization which has received much\nattention in the statistics and image processing literature. In this paper, we\nstudy the performance of the trend filtering estimator for every positive\ninteger $r$, both in the constrained and penalized forms. Our main results show\nthat in the strong sparsity setting when the underlying function is a\n(discrete) spline with few \"knots\", the risk (under the global squared error\nloss) of the trend filtering estimator (with an appropriate choice of the\ntuning parameter) achieves the parametric $n^{-1}$ rate, up to a logarithmic\n(multiplicative) factor. Our results therefore provide support for the use of\ntrend filtering, for every $r$, in the strong sparsity setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On periodic solutions of nonlinear wave equations, including Einstein equations with a negative cosmological constant.   We construct periodic solutions of nonlinear wave equations using analytic\ncontinuation. The construction applies in particular to Einstein equations,\nleading to infinite-dimensional families of time-periodic solutions of the\nvacuum, or of the Einstein-Maxwell-dilaton-scalar\nfields-Yang-Mills-Higgs-Chern-Simons-$f(R)$ equations, with a negative\ncosmological constant.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Blind Gain and Phase Calibration via Sparse Spectral Methods.   Blind gain and phase calibration (BGPC) is a bilinear inverse problem\ninvolving the determination of unknown gains and phases of the sensing system,\nand the unknown signal, jointly. BGPC arises in numerous applications, e.g.,\nblind albedo estimation in inverse rendering, synthetic aperture radar\nautofocus, and sensor array auto-calibration. In some cases, sparse structure\nin the unknown signal alleviates the ill-posedness of BGPC. Recently there has\nbeen renewed interest in solutions to BGPC with careful analysis of error\nbounds. In this paper, we formulate BGPC as an eigenvalue/eigenvector problem,\nand propose to solve it via power iteration, or in the sparsity or joint\nsparsity case, via truncated power iteration. Under certain assumptions, the\nunknown gains, phases, and the unknown signal can be recovered simultaneously.\nNumerical experiments show that power iteration algorithms work not only in the\nregime predicted by our main results, but also in regimes where theoretical\nanalysis is limited. We also show that our power iteration algorithms for BGPC\ncompare favorably with competing algorithms in adversarial conditions, e.g.,\nwith noisy measurement or with a bad initial estimate.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Humphreys conjecture on support varieties of tilting modules.   Let $G$ be a simply-connected semisimple algebraic group over an\nalgebraically closed field of characteristic $p$, assumed to be larger than the\nCoxeter number. The \"support variety\" of a $G$-module $M$ is a certain closed\nsubvariety of the nilpotent cone of $G$, defined in terms of cohomology for the\nfirst Frobenius kernel $G_1$. In the 1990s, Humphreys proposed a conjectural\ndescription of the support varieties of tilting modules; this conjecture has\nbeen proved for $G = \\mathrm{SL}_n$ in earlier work of the second author.\nIn this paper, we show that for any $G$, the support variety of a tilting\nmodule always contains the variety predicted by Humphreys, and that they\ncoincide (i.e., the Humphreys conjecture is true) when $p$ is sufficiently\nlarge. We also prove variants of these statements involving \"relative support\nvarieties.\"",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unified theory for finite Markov chains.   We provide a unified framework to compute the stationary distribution of any\nfinite irreducible Markov chain or equivalently of any irreducible random walk\non a finite semigroup $S$. Our methods use geometric finite semigroup theory\nvia the Karnofsky-Rhodes and the McCammond expansions of finite semigroups with\nspecified generators; this does not involve any linear algebra. The original\nTsetlin library is obtained by applying the expansions to $P(n)$, the set of\nall subsets of an $n$ element set. Our set-up generalizes previous\ngroundbreaking work involving left-regular bands (or $\\mathscr{R}$-trivial\nbands) by Brown and Diaconis, extensions to $\\mathscr{R}$-trivial semigroups by\nAyyer, Steinberg, Thiéry and the second author, and important recent work by\nChung and Graham. The Karnofsky-Rhodes expansion of the right Cayley graph of\n$S$ in terms of generators yields again a right Cayley graph. The McCammond\nexpansion provides normal forms for elements in the expanded $S$. Using our\nprevious results with Silva based on work by Berstel, Perrin, Reutenauer, we\nconstruct (infinite) semaphore codes on which we can define Markov chains.\nThese semaphore codes can be lumped using geometric semigroup theory. Using\nnormal forms and associated Kleene expressions, they yield formulas for the\nstationary distribution of the finite Markov chain of the expanded $S$ and the\noriginal $S$. Analyzing the normal forms also provides an estimate on the\nmixing time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling and Reasoning About Wireless Networks: A Graph-based Calculus Approach.   We propose a graph-based process calculus for modeling and reasoning about\nwireless networks with local broadcasts. Graphs are used at syntactical level\nto describe the topological structures of networks. This calculus is equipped\nwith a reduction semantics and a labelled transition semantics. The former is\nused to define weak barbed congruence. The latter is used to define a\nparameterized weak bisimulation emphasizing locations and local broadcasts. We\nprove that weak bisimilarity implies weak barbed congruence. The potential\napplications are illustrated by some examples and two case studies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Transmission spectra and valley processing of graphene and carbon nanotube superlattices with inter-valley coupling.   We numerically investigate the electronic transport properties of graphene\nnanoribbons and carbon nanotubes with inter-valley coupling, e.g., in \\sqrt{3}N\n\\times \\sqrt{3}N and 3N \\times 3N superlattices. By taking the \\sqrt{3} \\times\n\\sqrt{3} graphene superlattice as an example, we show that tailoring the bulk\ngraphene superlattice results in rich structural configurations of nanoribbons\nand nanotubes. After studying the electronic characteristics of the\ncorresponding armchair and zigzag nanoribbon geometries, we find that the\nlinear bands of carbon nanotubes can lead to the Klein tunnelling-like\nphenomenon, i.e., electrons propagate along tubes without backscattering even\nin the presence of a barrier. Due to the coupling between K and K' valleys of\npristine graphene by \\sqrt{3} \\times \\sqrt{3} supercells,we propose a\nvalley-field-effect transistor based on the armchair carbon nanotube, where the\nvalley polarization of the current can be tuned by applying a gate voltage or\nvarying the length of the armchair carbon nanotubes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Privacy of the Opal Data Release: A Response.   This document is a response to a report from the University of Melbourne on\nthe privacy of the Opal dataset release. The Opal dataset was released by\nData61 (CSIRO) in conjunction with the Transport for New South Wales (TfNSW).\nThe data consists of two separate weeks of \"tap-on/tap-off\" data of individuals\nwho used any of the four different modes of public transport from TfNSW: buses,\nlight rail, train and ferries. These taps are recorded through the smart\nticketing system, known as Opal, available in the state of New South Wales,\nAustralia.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A remark on the disorienting of species due to the fluctuating environment.   In this article we study the stabilizing of a primitive pattern of behaviour\nfor the two-species community with chemotaxis due to the short-wavelength\nexternal signal. We use a system of Patlak-Keller-Segel type as a model of the\ncommunity. It is well-known that such systems can produce complex unsteady\npatterns of behaviour which are usually explained mathematically by\nbifurcations of some basic solutions that describe simpler patterns. As far as\nwe aware, all such bifurcations in the models of the Patlak-Keller-Segel type\nhad been found for homogeneous (i.e. translationally invariant) systems where\nthe basic solutions are equilibria with homogeneous distributions of all\nspecies. The model considered in the present paper does not possess the\ntranslational invariance: one of species (the predators) is assumed to be\ncapable of moving in response to a signal produced externally in addition to\nthe signal emitted by another species (the prey). For instance, the external\nsignal may arise from the inhomogeneity of the distribution of an environmental\ncharacteristic such as temperature, salinity, terrain relief, etc. Our goal is\nto examine the effect of short-wavelength inhomogeneity. To do this, we employ\na certain homogenization procedure. We separate the short-wavelength and smooth\ncomponents of the system response and derive a slow system governing the latter\none. Analysing the slow system and comparing it with the case of homogeneous\nenvironment shows that, generically, a short-wavelength inhomogeneity results\nin an exponential decrease in the motility of the predators. The loss of\nmotility prevents, to a great extent, the occurrence of complex unsteady\npatterns and dramatically stabilizes the primitive basic solution. In some\nsense, the necessity of dealing with intensive small-scale changes of the\nenvironment makes the system unable to respond to other challenges.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "ADN: An Information-Centric Networking Architecture for the Internet of Things.   Forwarding data by name has been assumed to be a necessary aspect of an\ninformation-centric redesign of the current Internet architecture that makes\ncontent access, dissemination, and storage more efficient. The Named Data\nNetworking (NDN) and Content-Centric Networking (CCNx) architectures are the\nleading examples of such an approach. However, forwarding data by name incurs\nstorage and communication complexities that are orders of magnitude larger than\nsolutions based on forwarding data using addresses. Furthermore, the specific\nalgorithms used in NDN and CCNx have been shown to have a number of\nlimitations. The Addressable Data Networking (ADN) architecture is introduced\nas an alternative to NDN and CCNx. ADN is particularly attractive for\nlarge-scale deployments of the Internet of Things (IoT), because it requires\nfar less storage and processing in relaying nodes than NDN. ADN allows things\nand data to be denoted by names, just like NDN and CCNx do. However, instead of\nreplacing the waist of the Internet with named-data forwarding, ADN uses an\naddress-based forwarding plane and introduces an information plane that\nseamlessly maps names to addresses without the involvement of end-user\napplications. Simulation results illustrate the order of magnitude savings in\ncomplexity that can be attained with ADN compared to NDN.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Problems on Matchings and Independent Sets of a Graph.   Let $G$ be a finite simple graph. For $X \\subset V(G)$, the difference of\n$X$, $d(X) := |X| - |N (X)|$ where $N(X)$ is the neighborhood of $X$ and $\\max\n\\, \\{d(X):X\\subset V(G)\\}$ is called the critical difference of $G$. $X$ is\ncalled a critical set if $d(X)$ equals the critical difference and ker$(G)$ is\nthe intersection of all critical sets. It is known that ker$(G)$ is an\nindependent (vertex) set of $G$. diadem$(G)$ is the union of all critical\nindependent sets. An independent set $S$ is an inclusion minimal set with $d(S)\n> 0$ if no proper subset of $S$ has positive difference.\nA graph $G$ is called König-Egerváry if the sum of its independence\nnumber ($\\alpha (G)$) and matching number ($\\mu (G)$) equals $|V(G)|$. It is\nknown that bipartite graphs are König-Egerváry.\nIn this paper, we study independent sets with positive difference for which\nevery proper subset has a smaller difference and prove a result conjectured by\nLevit and Mandrescu in 2013. The conjecture states that for any graph, the\nnumber of inclusion minimal sets $S$ with $d(S) > 0$ is at least the critical\ndifference of the graph. We also give a short proof of the inequality\n$|$ker$(G)| + |$diadem$(G)| \\le 2\\alpha (G)$ (proved by Short in 2016).\nA characterization of unicyclic non-König-Egerváry graphs is also\npresented and a conjecture which states that for such a graph $G$, the critical\ndifference equals $\\alpha (G) - \\mu (G)$, is proved.\nWe also make an observation about ker$G)$ using Edmonds-Gallai Structure\nTheorem as a concluding remark.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "DeepSD: Generating High Resolution Climate Change Projections through Single Image Super-Resolution.   The impacts of climate change are felt by most critical systems, such as\ninfrastructure, ecological systems, and power-plants. However, contemporary\nEarth System Models (ESM) are run at spatial resolutions too coarse for\nassessing effects this localized. Local scale projections can be obtained using\nstatistical downscaling, a technique which uses historical climate observations\nto learn a low-resolution to high-resolution mapping. Depending on statistical\nmodeling choices, downscaled projections have been shown to vary significantly\nterms of accuracy and reliability. The spatio-temporal nature of the climate\nsystem motivates the adaptation of super-resolution image processing techniques\nto statistical downscaling. In our work, we present DeepSD, a generalized\nstacked super resolution convolutional neural network (SRCNN) framework for\nstatistical downscaling of climate variables. DeepSD augments SRCNN with\nmulti-scale input channels to maximize predictability in statistical\ndownscaling. We provide a comparison with Bias Correction Spatial\nDisaggregation as well as three Automated-Statistical Downscaling approaches in\ndownscaling daily precipitation from 1 degree (~100km) to 1/8 degrees (~12.5km)\nover the Continental United States. Furthermore, a framework using the NASA\nEarth Exchange (NEX) platform is discussed for downscaling more than 20 ESM\nmodels with multiple emission scenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the stability and applications of distance-based flexible formations.   This paper investigates the stability of distance-based \\textit{flexible}\nundirected formations in the plane. Without rigidity, there exists a set of\nconnected shapes for given distance constraints, which is called the ambit. We\nshow that a flexible formation can lose its flexibility, or equivalently may\nreduce the degrees of freedom of its ambit, if a small disturbance is\nintroduced in the range sensor of the agents. The stability of the disturbed\nequilibrium can be characterized by analyzing the eigenvalues of the linearized\naugmented error system. Unlike infinitesimally rigid formations, the disturbed\ndesired equilibrium can be turned unstable regardless of how small the\ndisturbance is. We finally present two examples of how to exploit these\ndisturbances as design parameters. The first example shows how to combine rigid\nand flexible formations such that some of the agents can move freely in the\ndesired and locally stable ambit. The second example shows how to achieve a\nspecific shape with fewer edges than the necessary for the standard controller\nin rigid formations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Equivalence of Fully Connected Layer and Convolutional Layer.   This article demonstrates that convolutional operation can be converted to\nmatrix multiplication, which has the same calculation way with fully connected\nlayer. The article is helpful for the beginners of the neural network to\nunderstand how fully connected layer and the convolutional layer work in the\nbackend. To be concise and to make the article more readable, we only consider\nthe linear case. It can be extended to the non-linear case easily through\nplugging in a non-linear encapsulation to the values like this $\\sigma(x)$\ndenoted as $x^{\\prime}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cooperation and Environment Characterize the Low-Lying Optical Spectrum of Liquid Water.   The optical spectrum of liquid water is analyzed by subsystem time-dependent\ndensity functional theory. We provide simple explanations for several important\n(and so far elusive) features. Due to the disordered environment surrounding\neach water molecule, the joint density of states of the liquid is much broader\nthan that of the vapor. This results in a red shifted Urbach tail. Confinement\neffects provided by the first solvation shell are responsible for the blue\nshift of the first absorption peak compared to the vapor. In addition, we also\ncharacterize many-body excitonic effects. These dramatically affect the\nspectral weights at low frequencies, contributing to the refractive index by a\nsmall but significant amount.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Extended quantum field theory, index theory and the parity anomaly.   We use techniques from functorial quantum field theory to provide a geometric\ndescription of the parity anomaly in fermionic systems coupled to background\ngauge and gravitational fields on odd-dimensional spacetimes. We give an\nexplicit construction of a geometric cobordism bicategory which incorporates\ngeneral background fields in a stack, and together with the theory of symmetric\nmonoidal bicategories we use it to provide the concrete forms of invertible\nextended quantum field theories which capture anomalies in both the path\nintegral and Hamiltonian frameworks. Specialising this situation by using the\nextension of the Atiyah-Patodi-Singer index theorem to manifolds with corners\ndue to Loya and Melrose, we obtain a new Hamiltonian perspective on the parity\nanomaly. We compute explicitly the 2-cocycle of the projective representation\nof the gauge symmetry on the quantum state space, which is defined in a\nparity-symmetric way by suitably augmenting the standard chiral fermionic Fock\nspaces with Lagrangian subspaces of zero modes of the Dirac Hamiltonian that\nnaturally appear in the index theorem. We describe the significance of our\nconstructions for the bulk-boundary correspondence in a large class of\ntime-reversal invariant gauge-gravity symmetry-protected topological phases of\nquantum matter with gapless charged boundary fermions, including the standard\ntopological insulator in 3+1 dimensions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Filamentary superconductivity in semiconducting policrystalline ZrSe2 compound with Zr vacancies.   ZrSe2 is a band semiconductor studied long time ago. It has interesting\nelectronic properties, and because its layers structure can be intercalated\nwith different atoms to change some of the physical properties. In this\ninvestigation we found that Zr deficiencies alter the semiconducting behavior\nand the compound can be turned into a superconductor. In this paper we report\nour studies related to this discovery. The decreasing of the number of Zr atoms\nin small proportion according to the formula ZrxSe2, where x is varied from\nabout 8.1 to 8.6 K, changing the semiconducting behavior to a superconductor\nwith transition temperatures ranging between 7.8 to 8.5 K, it depending of the\ndeficiencies. Outside of those ranges the compound behaves as semiconducting\nwith the properties already known. In our experiments we found that this new\nsuperconductor has only a very small fraction of superconducting material\ndetermined by magnetic measurements with applied magnetic field of 10 Oe. Our\nconclusions is that superconductivity is filamentary. However, in one studied\nsample the fraction was about 10.2 %, whereas in others is only about 1 % or\nless. We determined the superconducting characteristics; the critical fields\nthat indicate a type two superonductor with Ginzburg-Landau ? parameter of the\norder about 2.7. The synthesis procedure is quite normal fol- lowing the\nconventional solid state reaction. In this paper are included, the electronic\ncharacteristics, transition temperature, and evolution with temperature of the\ncritical fields.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Theoretical limitations of Encoder-Decoder GAN architectures.   Encoder-decoder GANs architectures (e.g., BiGAN and ALI) seek to add an\ninference mechanism to the GANs setup, consisting of a small encoder deep net\nthat maps data-points to their succinct encodings. The intuition is that being\nforced to train an encoder alongside the usual generator forces the system to\nlearn meaningful mappings from the code to the data-point and vice-versa, which\nshould improve the learning of the target distribution and ameliorate\nmode-collapse. It should also yield meaningful codes that are useful as\nfeatures for downstream tasks. The current paper shows rigorously that even on\nreal-life distributions of images, the encode-decoder GAN training objectives\n(a) cannot prevent mode collapse; i.e. the objective can be near-optimal even\nwhen the generated distribution has low and finite support (b) cannot prevent\nlearning meaningless codes for data -- essentially white noise. Thus if\nencoder-decoder GANs do indeed work then it must be due to reasons as yet not\nunderstood, since the training objective can be low even for meaningless\nsolutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Calculus with respect to Gaussian Processes: Part I.   Stochastic integration \\textit{wrt} Gaussian processes has raised strong\ninterest in recent years, motivated in particular by its applications in\nInternet traffic modeling, biomedicine and finance. The aim of this work is to\ndefine and develop a White Noise Theory-based anticipative stochastic calculus\nwith respect to all Gaussian processes that have an integral representation\nover a real (maybe infinite) interval. Very rich, this class of Gaussian\nprocesses contains, among many others, Volterra processes (and thus fractional\nBrownian motion) as well as processes the regularity of which varies along the\ntime (such as multifractional Brownian motion).A systematic comparison of the\nstochastic calculus (including It{ô} formula) we provide here, to the ones\ngiven by Malliavin calculus in\n\\cite{nualart,MV05,NuTa06,KRT07,KrRu10,LN12,SoVi14,LN12}, and by It{ô}\nstochastic calculus is also made. Not only our stochastic calculus fully\ngeneralizes and extends the ones originally proposed in \\cite{MV05} and in\n\\cite{NuTa06} for Gaussian processes, but also the ones proposed in\n\\cite{ell,bosw,ben1} for fractional Brownian motion (\\textit{resp.} in\n\\cite{JLJLV1,JL13,LLVH} for multifractional Brownian motion).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Von Neumann Regular Cellular Automata.   For any group $G$ and any set $A$, a cellular automaton (CA) is a\ntransformation of the configuration space $A^G$ defined via a finite memory set\nand a local function. Let $\\text{CA}(G;A)$ be the monoid of all CA over $A^G$.\nIn this paper, we investigate a generalisation of the inverse of a CA from the\nsemigroup-theoretic perspective. An element $\\tau \\in \\text{CA}(G;A)$ is von\nNeumann regular (or simply regular) if there exists $\\sigma \\in \\text{CA}(G;A)$\nsuch that $\\tau \\circ \\sigma \\circ \\tau = \\tau$ and $\\sigma \\circ \\tau \\circ\n\\sigma = \\sigma$, where $\\circ$ is the composition of functions. Such an\nelement $\\sigma$ is called a generalised inverse of $\\tau$. The monoid\n$\\text{CA}(G;A)$ itself is regular if all its elements are regular. We\nestablish that $\\text{CA}(G;A)$ is regular if and only if $\\vert G \\vert = 1$\nor $\\vert A \\vert = 1$, and we characterise all regular elements in\n$\\text{CA}(G;A)$ when $G$ and $A$ are both finite. Furthermore, we study\nregular linear CA when $A= V$ is a vector space over a field $\\mathbb{F}$; in\nparticular, we show that every regular linear CA is invertible when $G$ is\ntorsion-free elementary amenable (e.g. when $G=\\mathbb{Z}^d, \\ d \\in\n\\mathbb{N}$) and $V=\\mathbb{F}$, and that every linear CA is regular when $V$\nis finite-dimensional and $G$ is locally finite with $\\text{Char}(\\mathbb{F})\n\\nmid o(g)$ for all $g \\in G$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Average sampling and average splines on combinatorial graphs.   In the setting of a weighted combinatorial finite or infinite countable graph\n$G$ we introduce functional Paley-Wiener spaces $PW_{\\omega}(L),\\>\\omega>0,$\ndefined in terms of the spectral resolution of the combinatorial Laplace\noperator $L$ in the space $L_{2}(G)$. It is shown that functions in certain\n$PW_{\\omega}(L),\\>\\omega>0,$ are uniquely defined by their averages over some\nfamilies of \"small\" subgraphs which form a cover of $G$. Reconstruction methods\nfor reconstruction of an $f\\in PW_{\\omega}(L)$ from appropriate set of its\naverages are introduced. One method is using language of Hilbert frames.\nAnother one is using average variational interpolating splines which are\nconstructed in the setting of combinatorial graphs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Path integral molecular dynamics with surface hopping for thermal equilibrium sampling of nonadiabatic systems.   In this work, a novel ring polymer representation for multi-level quantum\nsystem is proposed for thermal average calculations. The proposed presentation\nkeeps the discreteness of the electronic states: besides position and momentum,\neach bead in the ring polymer is also characterized by a surface index\nindicating the electronic energy surface. A path integral molecular dynamics\nwith surface hopping (PIMD-SH) dynamics is also developed to sample the\nequilibrium distribution of ring polymer configurational space. The PIMD-SH\nsampling method is validated theoretically and by numerical examples.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the normal centrosymmetric Nonnegative inverse eigenvalue problem.   We give sufficient conditions of the nonnegative inverse eigenvalue problem\n(NIEP) for normal centrosymmetric matrices. These sufficient conditions are\nanalogous to the sufficient conditions of the NIEP for normal matrices given by\nXu [16] and Julio, Manzaneda and Soto [2].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Nonlinear Kernel Support Matrix Machine for Matrix Learning.   In many problems of supervised tensor learning (STL), real world data such as\nface images or MRI scans are naturally represented as matrices, which are also\ncalled as second order tensors. Most existing classifiers based on tensor\nrepresentation, such as support tensor machine (STM) need to solve iteratively\nwhich occupy much time and may suffer from local minima. In this paper, we\npresent a kernel support matrix machine (KSMM) to perform supervised learning\nwhen data are represented as matrices. KSMM is a general framework for the\nconstruction of matrix-based hyperplane to exploit structural information. We\nanalyze a unifying optimization problem for which we propose an asymptotically\nconvergent algorithm. Theoretical analysis for the generalization bounds is\nderived based on Rademacher complexity with respect to a probability\ndistribution. We demonstrate the merits of the proposed method by exhaustive\nexperiments on both simulation study and a number of real-word datasets from a\nvariety of application domains.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Combined MEG and fMRI Exponential Random Graph Modeling for inferring functional Brain Connectivity.   Estimated connectomes by the means of neuroimaging techniques have enriched\nour knowledge of the organizational properties of the brain leading to the\ndevelopment of network-based clinical diagnostics. Unfortunately, to date, many\nof those network-based clinical diagnostics tools, based on the mere\ndescription of isolated instances of observed connectomes are noisy estimates\nof the true connectivity network. Modeling brain connectivity networks is\ntherefore important to better explain the functional organization of the brain\nand allow inference of specific brain properties. In this report, we present\npilot results on the modeling of combined MEG and fMRI neuroimaging data\nacquired during an n-back memory task experiment. We adopted a pooled\nExponential Random Graph Model (ERGM) as a network statistical model to capture\nthe underlying process in functional brain networks of 9 subjects MEG and fMRI\ndata out of 32 during a 0-back vs 2-back memory task experiment. Our results\nsuggested strong evidence that all the functional connectomes of the 9 subjects\nhave small world properties. A group level comparison using comparing the\nconditions pairwise showed no significant difference in the functional\nconnectomes across the subjects. Our pooled ERGMs successfully reproduced\nimportant brain properties such as functional segregation and functional\nintegration. However, the ERGMs reproducing the functional segregation of the\nbrain networks discriminated between the 0-back and 2-back conditions while the\nmodels reproducing both properties failed to successfully discriminate between\nboth conditions. Our results are promising and would improve in robustness with\na larger sample size. Nevertheless, our pilot results tend to support previous\nfindings that functional segregation and integration are sufficient to\nstatistically reproduce the main properties of brain network.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A numerical scheme for an improved Green-Naghdi model in the Camassa-Holm regime for the propagation of internal waves.   In this paper we introduce a new reformulation of the Green-Naghdi model in\nthe Camassa-Holm regime for the propagation of internal waves over a flat\ntopography derived by Duchêne, Israwi and Talhouk. These new Green-Naghdi\nsystems are adapted to improve the frequency dispersion of the original model,\nthey share the same order of precision as the standard one but have an\nappropriate structure which makes them much more suitable for the numerical\nresolution. We develop a second order splitting scheme where the hyperbolic\npart of the system is treated with a high-order finite volume scheme and the\ndispersive part is treated with a finite difference approach. Numerical\nsimulations are then performed to validate the model and the numerical methods.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Cosmological Simulations in Exascale Era.   The architecture of Exascale computing facilities, which involves millions of\nheterogeneous processing units, will deeply impact on scientific applications.\nFuture astrophysical HPC applications must be designed to make such computing\nsystems exploitable. The ExaNeSt H2020 EU-funded project aims to design and\ndevelop an exascale ready prototype based on low-energy-consumption ARM64 cores\nand FPGA accelerators. We participate to the design of the platform and to the\nvalidation of the prototype with cosmological N-body and hydrodynamical codes\nsuited to perform large-scale, high-resolution numerical simulations of cosmic\nstructures formation and evolution. We discuss our activities on astrophysical\napplications to take advantage of the underlying architecture.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "New Derivatives for the Functions with the Fractal Tartan Support.   In this manuscript, we generalize F-calculus to apply it on fractal Tartan\nspaces. The generalized standard F-calculus is used to obtain the integral and\nderivative of the functions on the fractal Tartan with different dimensions.\nThe generalized fractional derivatives have local properties that make it more\nuseful in modelling physical problems. The illustrative examples are used to\npresent the details.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A null test of General Relativity: New limits on Local Position Invariance and the variation of fundamental constants.   We compare the long-term fractional frequency variation of four hydrogen\nmasers that are part of an ensemble of clocks comprising the National Institute\nof Standards and Technology,(NIST), Boulder, timescale with the fractional\nfrequencies of primary frequency standards operated by leading metrology\nlaboratories in the United States, France, Germany, Italy and the United\nKingdom for a period extending more than 14 years. The measure of the assumed\nvariation of non-gravitational interaction,(LPI parameter, $\\beta$)---within\nthe atoms of H and Cs---over time as the earth orbits the sun, has been\nconstrained to $\\beta=(2.2 \\pm 2.5)\\times 10^{-7}$, a factor of two improvement\nover previous estimates. Using our results together with the previous best\nestimates of $\\beta$ based on Rb vs. Cs, and Rb vs. H comparisons, we impose\nthe most stringent limits to date on the dimensionless coupling constants that\nrelate the variation of fundamental constants such as the fine-structure\nconstant and the scaled quark mass with strong(QCD) interaction to the\nvariation in the local gravitational potential. For any metric theory of\ngravity $\\beta=0$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "OpenML Benchmarking Suites and the OpenML100.   We advocate the use of curated, comprehensive benchmark suites of machine\nlearning datasets, backed by standardized OpenML-based interfaces and\ncomplementary software toolkits written in Python, Java and R. Major\ndistinguishing features of OpenML benchmark suites are (a) ease of use through\nstandardized data formats, APIs, and existing client libraries; (b)\nmachine-readable meta-information regarding the contents of the suite; and (c)\nonline sharing of results, enabling large scale comparisons. As a first such\nsuite, we propose the OpenML100, a machine learning benchmark suite of\n100~classification datasets carefully curated from the thousands of datasets\navailable on OpenML.org.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analyzing Cloud Optical Properties Using Sky Cameras.   Clouds play a significant role in the fluctuation of solar radiation received\nby the earth's surface. It is important to study the various cloud properties,\nas it impacts the total solar irradiance falling on the earth's surface. One of\nsuch important optical properties of the cloud is the Cloud Optical Thickness\n(COT). It is defined with the amount of light that can pass through the clouds.\nThe COT values are generally obtained from satellite images. However, satellite\nimages have a low temporal- and spatial- resolutions; and are not suitable for\nstudy in applications as solar energy generation and forecasting. Therefore,\nground-based sky cameras are now getting popular in such fields. In this paper,\nwe analyze the cloud optical thickness value, from the ground-based sky\ncameras, and provide future research directions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An adaptive Newton algorithm for optimal control problems with application to optimal electrode design.   In this work we present an adaptive Newton-type method to solve nonlinear\nconstrained optimization problems in which the constraint is a system of\npartial differential equations discretized by the finite element method. The\nadaptive strategy is based on a goal-oriented a posteriori error estimation for\nthe discretization and for the iteration error. The iteration error stems from\nan inexact solution of the nonlinear system of first order optimality\nconditions by the Newton-type method. This strategy allows to balance the two\nerrors and to derive effective stopping criteria for the Newton-iterations. The\nalgorithm proceeds with the search of the optimal point on coarse grids which\nare refined only if the discretization error becomes dominant. Using computable\nerror indicators the mesh is refined locally leading to a highly efficient\nsolution process. The performance of the algorithm is shown with several\nexamples and in particular with an application in the neurosciences: the\noptimal electrode design for the study of neuronal networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Delving into adversarial attacks on deep policies.   Adversarial examples have been shown to exist for a variety of deep learning\narchitectures. Deep reinforcement learning has shown promising results on\ntraining agent policies directly on raw inputs such as image pixels. In this\npaper we present a novel study into adversarial attacks on deep reinforcement\nlearning polices. We compare the effectiveness of the attacks using adversarial\nexamples vs. random noise. We present a novel method for reducing the number of\ntimes adversarial examples need to be injected for a successful attack, based\non the value function. We further explore how re-training on random noise and\nFGSM perturbations affects the resilience against adversarial examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast construction of efficient composite likelihood equations.   Growth in both size and complexity of modern data challenges the\napplicability of traditional likelihood-based inference. Composite likelihood\n(CL) methods address the difficulties related to model selection and\ncomputational intractability of the full likelihood by combining a number of\nlow-dimensional likelihood objects into a single objective function used for\ninference. This paper introduces a procedure to combine partial likelihood\nobjects from a large set of feasible candidates and simultaneously carry out\nparameter estimation. The new method constructs estimating equations balancing\nstatistical efficiency and computing cost by minimizing an approximate distance\nfrom the full likelihood score subject to a L1-norm penalty representing the\navailable computing resources. This results in truncated CL equations\ncontaining only the most informative partial likelihood score terms. An\nasymptotic theory within a framework where both sample size and data dimension\ngrow is developed and finite-sample properties are illustrated through\nnumerical examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lower Bounds for Maximum Gap in (Inverse) Cyclotomic Polynomials.   The maximum gap $g(f)$ of a polynomial $f$ is the maximum of the differences\n(gaps) between two consecutive exponents that appear in $f$. Let $\\Phi_{n}$ and\n$\\Psi_{n}$ denote the $n$-th cyclotomic and $n$-th inverse cyclotomic\npolynomial, respectively. In this paper, we give several lower bounds for\n$g(\\Phi_{n})$ and $g(\\Psi_{n})$, where $n$ is the product of odd primes. We\nobserve that they are very often exact. We also give an exact expression for\n$g(\\Psi_{n})$ under a certain condition. Finally we conjecture an exact\nexpression for $g(\\Phi_{n})$ under a certain condition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Robust Utility Learning Framework via Inverse Optimization.   In many smart infrastructure applications flexibility in achieving\nsustainability goals can be gained by engaging end-users. However, these users\noften have heterogeneous preferences that are unknown to the decision-maker\ntasked with improving operational efficiency. Modeling user interaction as a\ncontinuous game between non-cooperative players, we propose a robust parametric\nutility learning framework that employs constrained feasible generalized least\nsquares estimation with heteroskedastic inference. To improve forecasting\nperformance, we extend the robust utility learning scheme by employing\nbootstrapping with bagging, bumping, and gradient boosting ensemble methods.\nMoreover, we estimate the noise covariance which provides approximated\ncorrelations between players which we leverage to develop a novel correlated\nutility learning framework. We apply the proposed methods both to a toy example\narising from Bertrand-Nash competition between two firms as well as to data\nfrom a social game experiment designed to encourage energy efficient behavior\namongst smart building occupants. Using occupant voting data for shared\nresources such as lighting, we simulate the game defined by the estimated\nutility functions to demonstrate the performance of the proposed methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Quitting: Performance and Practice in Online Game Play.   We study the relationship between performance and practice by analyzing the\nactivity of many players of a casual online game. We find significant\nheterogeneity in the improvement of player performance, given by score, and\naddress this by dividing players into similar skill levels and segmenting each\nplayer's activity into sessions, i.e., sequence of game rounds without an\nextended break. After disaggregating data, we find that performance improves\nwith practice across all skill levels. More interestingly, players are more\nlikely to end their session after an especially large improvement, leading to a\npeak score in their very last game of a session. In addition, success is\nstrongly correlated with a lower quitting rate when the score drops, and only\nweakly correlated with skill, in line with psychological findings about the\nvalue of persistence and \"grit\": successful players are those who persist in\ntheir practice despite lower scores. Finally, we train an epsilon-machine, a\ntype of hidden Markov model, and find a plausible mechanism of game play that\ncan predict player performance and quitting the game. Our work raises the\npossibility of real-time assessment and behavior prediction that can be used to\noptimize human performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stability analysis of a system coupled to a heat equation.   As a first approach to the study of systems coupling finite and infinite\ndimensional natures, this article addresses the stability of a system of\nordinary differential equations coupled with a classic heat equation using a\nLyapunov functional technique. Inspired from recent developments in the area of\ntime delay systems, a new methodology to study the stability of such a class of\ndistributed parameter systems is presented here. The idea is to use a\npolynomial approximation of the infinite dimensional state of the heat equation\nin order to build an enriched energy functional. A well known efficient\nintegral inequality (Bessel inequality) will allow to obtain stability\nconditions expressed in terms of linear matrix inequalities. We will eventually\ntest our approach on academic examples in order to illustrate the efficiency of\nour theoretical results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectral properties and breathing dynamics of a few-body Bose-Bose mixture in a 1D harmonic trap.   We investigate a few-body mixture of two bosonic components, each consisting\nof two particles confined in a quasi one-dimensional harmonic trap. By means of\nexact diagonalization with a correlated basis approach we obtain the low-energy\nspectrum and eigenstates for the whole range of repulsive intra- and\ninter-component interaction strengths. We analyse the eigenvalues as a function\nof the inter-component coupling, covering hereby all the limiting regimes, and\ncharacterize the behaviour in-between these regimes by exploiting the\nsymmetries of the Hamiltonian. Provided with this knowledge we study the\nbreathing dynamics in the linear-response regime by slightly quenching the trap\nfrequency symmetrically for both components. Depending on the choice of\ninteractions strengths, we identify 1 to 3 monopole modes besides the breathing\nmode of the center of mass coordinate. For the uncoupled mixture each monopole\nmode corresponds to the breathing oscillation of a specific relative\ncoordinate. Increasing the inter-component coupling first leads to multi-mode\noscillations in each relative coordinate, which turn into single-mode\noscillations of the same frequency in the composite-fermionization regime.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Traveling dark-bright solitons in a reduced spin-orbit coupled system: application to Bose-Einstein condensates.   In the present work, we explore the potential of spin-orbit (SO) coupled\nBose-Einstein condensates to support multi-component solitonic states in the\nform of dark-bright (DB) solitons. In the case where Raman linear coupling\nbetween components is absent, we use a multiscale expansion method to reduce\nthe model to the integrable Mel'nikov system. The soliton solutions of the\nlatter allow us to reconstruct approximate traveling DB solitons for the\nreduced SO coupled system. For small values of the formal perturbation\nparameter, the resulting waveforms propagate undistorted, while for large\nvalues thereof, they shed some dispersive radiation, and subsequently distill\ninto a robust propagating structure. After quantifying the relevant radiation\neffect, we also study the dynamics of DB solitons in a parabolic trap,\nexploring how their oscillation frequency varies as a function of the bright\ncomponent mass and the Raman laser wavenumber.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Geometric tracking control of thrust vectoring UAVs.   In this paper a geometric approach to the trajectory tracking control of\nUnmanned Aerial Vehicles with thrust vectoring capabilities is proposed. The\ncontrol design is suitable for aerial systems that allow to effectively\ndecouple position and orientation tracking tasks. The control problem is\ndeveloped within the framework of geometric control theory on the group of\nrigid displacements SE(3), yielding a control law that is independent of any\nparametrization of the configuration space. The proposed design works seamlessy\nwhen the thrust vectoring capability is limited, by prioritizing position over\norientation tracking. A characterization of the region of attraction and of the\nconvergence properties is explicitly derived. Finally, a numerical example is\npresented to test the proposed control law. The generality of the control\nscheme can be exploited for a broad class of aerial vehicles.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Moon Illusion explained by the Projective Consciousness Model.   The Moon often appears larger near the perceptual horizon and smaller high in\nthe sky though the visual angle subtended is invariant. We show how this\nillusion results from the optimization of a projective geometrical frame for\nconscious perception through free energy minimization, as articulated in the\nProjective Consciousness Model. The model accounts for all documented\nmodulations of the illusion without anomalies (e.g., the size-distance\nparadox), surpasses other theories in explanatory power, makes sense of inter-\nand intra-subjective variability vis-a-vis the illusion, and yields new\nquantitative and qualitative predictions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Disorder robustness and protection of Majorana bound states in ferromagnetic chains on conventional superconductors.   Majorana bound states (MBS) are well-established in the clean limit in chains\nof ferromagnetically aligned impurities deposited on conventional\nsuperconductors with finite spin-orbit coupling. Here we show that these MBS\nare very robust against disorder. By performing self-consistent calculations we\nfind that the MBS are protected as long as the surrounding superconductor show\nno large signs of inhomogeneity. We find that longer chains offer more\nstability against disorder for the MBS, albeit the minigap decreases, as do\nincreasing strengths of spin-orbit coupling and superconductivity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A System of Three Super Earths Transiting the Late K-Dwarf GJ 9827 at Thirty Parsecs.   We report the discovery of three small transiting planets orbiting GJ 9827, a\nbright (K = 7.2) nearby late K-type dwarf star. GJ 9827 hosts a $1.62\\pm0.11$\n$R_{\\rm \\oplus}$ super Earth on a 1.2 day period, a $1.269^{+0.087}_{-0.089}$\n$R_{\\rm \\oplus}$ super Earth on a 3.6 day period, and a $2.07\\pm0.14$ $R_{\\rm\n\\oplus}$ super Earth on a 6.2 day period. The radii of the planets transiting\nGJ 9827 span the transition between predominantly rocky and gaseous planets,\nand GJ 9827 b and c fall in or close to the known gap in the radius\ndistribution of small planets between these populations. At a distance of 30\nparsecs, GJ 9827 is the closest exoplanet host discovered by K2 to date, making\nthese planets well-suited for atmospheric studies with the upcoming James Webb\nSpace Telescope. The GJ 9827 system provides a valuable opportunity to\ncharacterize interior structure and atmospheric properties of coeval planets\nspanning the rocky to gaseous transition.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "DyNet: The Dynamic Neural Network Toolkit.   We describe DyNet, a toolkit for implementing neural network models based on\ndynamic declaration of network structure. In the static declaration strategy\nthat is used in toolkits like Theano, CNTK, and TensorFlow, the user first\ndefines a computation graph (a symbolic representation of the computation), and\nthen examples are fed into an engine that executes this computation and\ncomputes its derivatives. In DyNet's dynamic declaration strategy, computation\ngraph construction is mostly transparent, being implicitly constructed by\nexecuting procedural code that computes the network outputs, and the user is\nfree to use different network structures for each input. Dynamic declaration\nthus facilitates the implementation of more complicated network architectures,\nand DyNet is specifically designed to allow users to implement their models in\na way that is idiomatic in their preferred programming language (C++ or\nPython). One challenge with dynamic declaration is that because the symbolic\ncomputation graph is defined anew for every training example, its construction\nmust have low overhead. To achieve this, DyNet has an optimized C++ backend and\nlightweight graph representation. Experiments show that DyNet's speeds are\nfaster than or comparable with static declaration toolkits, and significantly\nfaster than Chainer, another dynamic declaration toolkit. DyNet is released\nopen-source under the Apache 2.0 license and available at\nthis http URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "What Happens - After the First Race? Enhancing the Predictive Power of Happens - Before Based Dynamic Race Detection.   Dynamic race detection is the problem of determining if an observed program\nexecution reveals the presence of a data race in a program. The classical\napproach to solving this problem is to detect if there is a pair of conflicting\nmemory accesses that are unordered by Lamport's happens-before (HB) relation.\nHB based race detection is known to not report false positives, i.e., it is\nsound. However, the soundness guarantee of HB only promises that the first pair\nof unordered, conflicting events is a schedulable data race. That is, there can\nbe pairs of HB-unordered conflicting data accesses that are not schedulable\nraces because there is no reordering of the events of the execution, where the\nevents in race can be executed immediately after each other. We introduce a new\npartial order, called schedulable happens-before (SHB) that exactly\ncharacterizes the pairs of schedulable data races --- every pair of conflicting\ndata accesses that are identified by SHB can be scheduled, and every HB-race\nthat can be scheduled is identified by SHB. Thus, the SHB partial order is\ntruly sound. We present a linear time, vector clock algorithm to detect\nschedulable races using SHB. Our experiments demonstrate the value of our\nalgorithm for dynamic race detection --- SHB incurs only little performance\noverhead and can scale to executions from real-world software applications\nwithout compromising soundness.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Understanding System Characteristics of Online Erasure Coding on Scalable, Distributed and Large-Scale SSD Array Systems.   Large-scale systems with arrays of solid state disks (SSDs) have become\nincreasingly common in many computing segments. To make such systems resilient,\nwe can adopt erasure coding such as Reed-Solomon (RS) code as an alternative to\nreplication because erasure coding can offer a significantly lower storage cost\nthan replication. To understand the impact of using erasure coding on system\nperformance and other system aspects such as CPU utilization and network\ntraffic, we build a storage cluster consisting of approximately one hundred\nprocessor cores with more than fifty high-performance SSDs, and evaluate the\ncluster with a popular open-source distributed parallel file system, Ceph. Then\nwe analyze behaviors of systems adopting erasure coding from the following five\nviewpoints, compared with those of systems using replication: (1) storage\nsystem I/O performance; (2) computing and software overheads; (3) I/O\namplification; (4) network traffic among storage nodes; (5) the impact of\nphysical data layout on performance of RS-coded SSD arrays. For all these\nanalyses, we examine two representative RS configurations, which are used by\nGoogle and Facebook file systems, and compare them with triple replication that\na typical parallel file system employs as a default fault tolerance mechanism.\nLastly, we collect 54 block-level traces from the cluster and make them\navailable for other researchers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unsupervised and Semi-supervised Anomaly Detection with LSTM Neural Networks.   We investigate anomaly detection in an unsupervised framework and introduce\nLong Short Term Memory (LSTM) neural network based algorithms. In particular,\ngiven variable length data sequences, we first pass these sequences through our\nLSTM based structure and obtain fixed length sequences. We then find a decision\nfunction for our anomaly detectors based on the One Class Support Vector\nMachines (OC-SVM) and Support Vector Data Description (SVDD) algorithms. As the\nfirst time in the literature, we jointly train and optimize the parameters of\nthe LSTM architecture and the OC-SVM (or SVDD) algorithm using highly effective\ngradient and quadratic programming based training methods. To apply the\ngradient based training method, we modify the original objective criteria of\nthe OC-SVM and SVDD algorithms, where we prove the convergence of the modified\nobjective criteria to the original criteria. We also provide extensions of our\nunsupervised formulation to the semi-supervised and fully supervised\nframeworks. Thus, we obtain anomaly detection algorithms that can process\nvariable length data sequences while providing high performance, especially for\ntime series data. Our approach is generic so that we also apply this approach\nto the Gated Recurrent Unit (GRU) architecture by directly replacing our LSTM\nbased structure with the GRU based structure. In our experiments, we illustrate\nsignificant performance gains achieved by our algorithms with respect to the\nconventional methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A split step Fourier/discontinuous Galerkin scheme for the Kadomtsev--Petviashvili equation.   In this paper we propose a method to solve the Kadomtsev--Petviashvili\nequation based on splitting the linear part of the equation from the nonlinear\npart. The linear part is treated using FFTs, while the nonlinear part is\napproximated using a semi-Lagrangian discontinuous Galerkin approach of\narbitrary order.\nWe demonstrate the efficiency and accuracy of the numerical method by\nproviding a range of numerical simulations. In particular, we find that our\napproach can outperform the numerical methods considered in the literature by\nup to a factor of five. Although we focus on the Kadomtsev--Petviashvili\nequation in this paper, the proposed numerical scheme can be extended to a\nrange of related models as well.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "The Forgettable-Watcher Model for Video Question Answering.   A number of visual question answering approaches have been proposed recently,\naiming at understanding the visual scenes by answering the natural language\nquestions. While the image question answering has drawn significant attention,\nvideo question answering is largely unexplored.\nVideo-QA is different from Image-QA since the information and the events are\nscattered among multiple frames. In order to better utilize the temporal\nstructure of the videos and the phrasal structures of the answers, we propose\ntwo mechanisms: the re-watching and the re-reading mechanisms and combine them\ninto the forgettable-watcher model. Then we propose a TGIF-QA dataset for video\nquestion answering with the help of automatic question generation. Finally, we\nevaluate the models on our dataset. The experimental results show the\neffectiveness of our proposed models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Frame Tracking Model for Memory-Enhanced Dialogue Systems.   Recently, resources and tasks were proposed to go beyond state tracking in\ndialogue systems. An example is the frame tracking task, which requires\nrecording multiple frames, one for each user goal set during the dialogue. This\nallows a user, for instance, to compare items corresponding to different goals.\nThis paper proposes a model which takes as input the list of frames created so\nfar during the dialogue, the current user utterance as well as the dialogue\nacts, slot types, and slot values associated with this utterance. The model\nthen outputs the frame being referenced by each triple of dialogue act, slot\ntype, and slot value. We show that on the recently published Frames dataset,\nthis model significantly outperforms a previously proposed rule-based baseline.\nIn addition, we propose an extensive analysis of the frame tracking task by\ndividing it into sub-tasks and assessing their difficulty with respect to our\nmodel.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A tale of seven narrow spikes and a long trough: constraining the timing of the percolation of HII bubbles at the tail-end of reionization with ULAS J1120+0641.   High-signal to noise observations of the Ly$\\alpha$ forest transmissivity in\nthe z = 7.085 QSO ULAS J1120+0641 show seven narrow transmission spikes\nfollowed by a long 240 cMpc/h trough. Here we use radiative transfer\nsimulations of cosmic reionization previously calibrated to match a wider range\nof Ly$\\alpha$ forest data to show that the occurrence of seven transmission\nspikes in the narrow redshift range z = 5.85 - 6.1 is very sensitive to the\nexact timing of reionization. Occurrence of the spikes requires the most under\ndense regions of the IGM to be already fully ionised. The rapid onset of a long\ntrough at z = 6.12 requires a strong decrease of the photo-ionisation rate at\nz$\\sim$6.1 in this line-of-sight, consistent with the end of percolation at\nthis redshift. The narrow range of reionisation histories that we previously\nfound to be consistent with a wider range of Ly$\\alpha$ forest data have a\nreasonable probability of showing seven spikes and the mock absorption spectra\nprovide an excellent match to the spikes and the trough in the observed\nspectrum of ULAS J1120+0641. Despite the large overall opacity of Ly$\\alpha$ at\nz > 5.8, larger samples of high signal-to-noise observations of rare\ntransmission spikes should therefore provide important further insights into\nthe exact timing of the percolation of HII bubbles at the tail-end of\nreionization",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning to Represent Edits.   We introduce the problem of learning distributed representations of edits. By\ncombining a \"neural editor\" with an \"edit encoder\", our models learn to\nrepresent the salient information of an edit and can be used to apply edits to\nnew inputs. We experiment on natural language and source code edit data. Our\nevaluation yields promising results that suggest that our neural network models\nlearn to capture the structure and semantics of edits. We hope that this\ninteresting task and data source will inspire other researchers to work further\non this problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sampling Errors in Nested Sampling Parameter Estimation.   Sampling errors in nested sampling parameter estimation differ from those in\nBayesian evidence calculation, but have been little studied in the literature.\nThis paper provides the first explanation of the two main sources of sampling\nerrors in nested sampling parameter estimation, and presents a new diagrammatic\nrepresentation for the process. We find no current method can accurately\nmeasure the parameter estimation errors of a single nested sampling run, and\npropose a method for doing so using a new algorithm for dividing nested\nsampling runs. We empirically verify our conclusions and the accuracy of our\nnew method.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Anderson localization in the Non-Hermitian Aubry-André-Harper model with physical gain and loss.   We investigate the Anderson localization in non-Hermitian\nAubry-André-Harper (AAH) models with imaginary potentials added to lattice\nsites to represent the physical gain and loss during the interacting processes\nbetween the system and environment. By checking the mean inverse participation\nratio (MIPR) of the system, we find that different configurations of physical\ngain and loss have very different impacts on the localization phase transition\nin the system. In the case with balanced physical gain and loss added in an\nalternate way to the lattice sites, the critical region (in the case with\np-wave superconducting pairing) and the critical value (both in the situations\nwith and without p-wave pairing) for the Anderson localization phase transition\nwill be significantly reduced, which implies an enhancement of the localization\nprocess. However, if the system is divided into two parts with one of them\ncoupled to physical gain and the other coupled to the corresponding physical\nloss, the transition process will be impacted only in a very mild way. Besides,\nwe also discuss the situations with imbalanced physical gain and loss and find\nthat the existence of random imaginary potentials in the system will also\naffect the localization process while constant imaginary potentials will not.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Geometric Enclosing Networks.   Training model to generate data has increasingly attracted research attention\nand become important in modern world applications. We propose in this paper a\nnew geometry-based optimization approach to address this problem. Orthogonal to\ncurrent state-of-the-art density-based approaches, most notably VAE and GAN, we\npresent a fresh new idea that borrows the principle of minimal enclosing ball\nto train a generator G\\left(\\bz\\right) in such a way that both training and\ngenerated data, after being mapped to the feature space, are enclosed in the\nsame sphere. We develop theory to guarantee that the mapping is bijective so\nthat its inverse from feature space to data space results in expressive\nnonlinear contours to describe the data manifold, hence ensuring data generated\nare also lying on the data manifold learned from training data. Our model\nenjoys a nice geometric interpretation, hence termed Geometric Enclosing\nNetworks (GEN), and possesses some key advantages over its rivals, namely\nsimple and easy-to-control optimization formulation, avoidance of mode\ncollapsing and efficiently learn data manifold representation in a completely\nunsupervised manner. We conducted extensive experiments on synthesis and\nreal-world datasets to illustrate the behaviors, strength and weakness of our\nproposed GEN, in particular its ability to handle multi-modal data and quality\nof generated data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Portfolio Optimization in Fractional and Rough Heston Models.   We consider a fractional version of the Heston volatility model which is\ninspired by [16]. Within this model we treat portfolio optimization problems\nfor power utility functions. Using a suitable representation of the fractional\npart, followed by a reasonable approximation we show that it is possible to\ncast the problem into the classical stochastic control framework. This approach\nis generic for fractional processes. We derive explicit solutions and obtain as\na by-product the Laplace transform of the integrated volatility. In order to\nget rid of some undesirable features we introduce a new model for the rough\npath scenario which is based on the Marchaud fractional derivative. We provide\na numerical study to underline our results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Understanding Black-box Predictions via Influence Functions.   How can we explain the predictions of a black-box model? In this paper, we\nuse influence functions -- a classic technique from robust statistics -- to\ntrace a model's prediction through the learning algorithm and back to its\ntraining data, thereby identifying training points most responsible for a given\nprediction. To scale up influence functions to modern machine learning\nsettings, we develop a simple, efficient implementation that requires only\noracle access to gradients and Hessian-vector products. We show that even on\nnon-convex and non-differentiable models where the theory breaks down,\napproximations to influence functions can still provide valuable information.\nOn linear models and convolutional neural networks, we demonstrate that\ninfluence functions are useful for multiple purposes: understanding model\nbehavior, debugging models, detecting dataset errors, and even creating\nvisually-indistinguishable training-set attacks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simulating Linear Logic in 1-Only Linear Logic.   Linear Logic was introduced by Girard as a resource-sensitive refinement of\nclassical logic. It turned out that full propositional Linear Logic is\nundecidable (Lincoln, Mitchell, Scedrov, and Shankar) and, hence, it is more\nexpressive than (modalized) classical or intuitionistic logic. In this paper we\nfocus on the study of the simplest fragments of Linear Logic, such as the\none-literal and constant-only fragments (the latter contains no literals at\nall). Here we demonstrate that all these extremely simple fragments of Linear\nLogic (one-literal, $\\bot$-only, and even unit-only) are exactly of the same\nexpressive power as the corresponding full versions. We present also a complete\ncomputational interpretation (in terms of acyclic programs with stack) for\nbottom-free Intuitionistic Linear Logic. Based on this interpretation, we prove\nthe fairness of our encodings and establish the foregoing complexity results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Remarks on defective Fano manifolds.   This note continues our previous work on special secant defective\n(specifically, conic connected and local quadratic entry locus) and dual\ndefective manifolds. These are now well understood, except for the prime Fano\nones. Here we add a few remarks on this case, completing the results in our\npapers \\cite{LQEL I}, \\cite{LQEL II}, \\cite{CC}, \\cite{HC} and \\cite{DD}; see\nalso the recent book \\cite{Russo}",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spin-resolved electronic structure of ferroelectric α-GeTe and multiferroic Ge1-xMnxTe.   Germanium telluride features special spin-electric effects originating from\nspin-orbit coupling and symmetry breaking by the ferroelectric lattice\npolarization, which opens up many prospectives for electrically tunable and\nswitchable spin electronic devices. By Mn doping of the {\\alpha}-GeTe host\nlattice, the system becomes a multiferroic semiconductor possessing\nmagnetoelectric properties in which the electric polarization, magnetization\nand spin texture are coupled to each other. Employing spin- and angle-resolved\nphotoemission spectroscopy in bulk- and surface-sensitive energy ranges and by\nvarying dipole transition matrix elements, we disentangle the bulk, surface and\nsurface-resonance states of the electronic structure and determine the spin\ntextures for selected parameters. From our results, we derive a comprehensive\nmodel of the {\\alpha}-GeTe surface electronic structure which fits experimental\ndata and first principle theoretical predictions and we discuss the\nunconventional evolution of the Rashba-type spin splitting upon manipulation by\nexternal B- and E-fields.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An initial-boundary value problem of the general three-component nonlinear Schrodinger equation with a 4x4 Lax pair on a finite interval.   We investigate the initial-boundary value problem for the general\nthree-component nonlinear Schrodinger (gtc-NLS) equation with a 4x4 Lax pair on\na finite interval by extending the Fokas unified approach. The solutions of the\ngtc-NLS equation can be expressed in terms of the solutions of a 4x4 matrix\nRiemann-Hilbert (RH) problem formulated in the complex k-plane. Moreover, the\nrelevant jump matrices of the RH problem can be explicitly found via the three\nspectral functions arising from the initial data, the Dirichlet-Neumann\nboundary data. The global relation is also established to deduce two distinct\nbut equivalent types of representations (i.e., one by using the large k of\nasymptotics of the eigenfunctions and another one in terms of the\nGelfand-Levitan-Marchenko (GLM) method) for the Dirichlet and Neumann boundary\nvalue problems. Moreover, the relevant formulae for boundary value problems on\nthe finite interval can reduce to ones on the half-line as the length of the\ninterval approaches to infinity. Finally, we also give the linearizable\nboundary conditions for the GLM representation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Hazard Analysis and Risk Assessment for an Automated Unmanned Protective Vehicle.   For future application of automated vehicles in public traffic, ensuring\nfunctional safety is essential. In this context, a hazard analysis and risk\nassessment is an important input for designing functionally vehicle automation\nsystems. In this contribution, we present a detailed hazard analysis and risk\nassessment (HARA) according to the ISO 26262 standard for a specific Level 4\napplication, namely an unmanned protective vehicle operated without human\nsupervision for motorway hard shoulder roadworks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comment on the Equality Condition for the I-MMSE Proof of Entropy Power Inequality.   The paper establishes the equality condition in the I-MMSE proof of the\nentropy power inequality (EPI). This is done by establishing an exact\nexpression for the deficit between the two sides of the EPI. Interestingly, a\nnecessary condition for the equality is established by making a connection to\nthe famous Cauchy functional equation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interferometric confirmation of \"water fountain\" candidates.   Water fountain stars (WFs) are evolved objects with water masers tracing\nhigh-velocity jets (up to several hundreds of km s$^{-1}$). They could\nrepresent one of the first manifestations of collimated mass-loss in evolved\nobjects and thus, be a key to understanding the shaping mechanisms of planetary\nnebulae. Only 13 objects had been confirmed so far as WFs with interferometer\nobservations. We present new observations with the Australia Telescope Compact\nArray and archival observations with the Very Large Array of four objects that\nare considered to be WF candidates, mainly based on single-dish observations.\nWe confirm IRAS 17291-2147 and IRAS 18596+0315 (OH 37.1-0.8) as bona fide\nmembers of the WF class, with high-velocity water maser emission consistent\nwith tracing bipolar jets. We argue that IRAS 15544-5332 has been wrongly\nconsidered as a WF in previous works, since we see no evidence in our data nor\nin the literature that this object harbours high-velocity water maser emission.\nIn the case of IRAS 19067+0811, we did not detect any water maser emission, so\nits confirmation as a WF is still pending. With the result of this work, there\nare 15 objects that can be considered confirmed WFs. We speculate that there is\nno significant physical difference between WFs and obscured post-AGB stars in\ngeneral. The absence of high-velocity water maser emission in some obscured\npost-AGB stars could be attributed to a variability or orientation effect.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Surface energy of strained amorphous solids.   Surface stress and surface energy are fundamental quantities which\ncharacterize the interface between two materials. Although these quantities are\nidentical for interfaces involving only fluids, the Shuttleworth effect\ndemonstrates that this is not the case for most interfaces involving solids,\nsince their surface energies change with strain. Crystalline materials are\nknown to have strain dependent surface energies, but in amorphous materials,\nsuch as polymeric glasses and elastomers, the strain dependence is debated due\nto a dearth of direct measurements. Here, we utilize contact angle measurements\non strained glassy and elastomeric solids to address this matter. We show\nconclusively that interfaces involving polymeric glasses exhibit strain\ndependent surface energies, and give strong evidence for the absence of such a\ndependence for incompressible elastomers. The results provide fundamental\ninsight into our understanding of the interfaces of amorphous solids and their\ninteraction with contacting liquids.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Singlet ground state in the spin-$1/2$ weakly coupled dimer compound NH$_4$[(V$_2$O$_3$)$_2$(4,4$^\\prime$-$bpy$)$_2$(H$_2$PO$_4$)(PO$_4$)$_2$]$\\cdot$0.5H$_2$O.   We present the synthesis and a detailed investigation of structural and\nmagnetic properties of polycrystalline\nNH$_4$[(V$_2$O$_3$)$_2$(4,4$^\\prime$-$bpy$)$_2$(H$_2$PO$_4$)(PO$_4$)$_2$]$\\cdot$0.5H$_2$O\nby means of x-ray diffraction, magnetic susceptibility, electron spin\nresonance, and $^{31}$P nuclear magnetic resonance measurements. Temperature\ndependent magnetic susceptibility could be described well using a weakly\ncoupled spin-$1/2$ dimer model with an excitation gap $\\Delta/k_{\\rm B}\\simeq\n26.1$ K between the singlet ground state and triplet excited states and a weak\ninter-dimer exchange coupling $J^\\prime/k_{\\rm B} \\simeq 4.6$ K. A gapped chain\nmodel also describes the data well with a gap of about 20 K. The ESR intensity\nas a function of temperature traces the bulk susceptibility nicely. The\nisotropic Land$\\acute{\\rm e}$ $g$-factor is estimated to be about $g \\simeq\n1.97$, at room temperature. We are able to resolve the $^{31}$P NMR signal as\ncoming from two inequivalent P-sites in the crystal structure. The hyperfine\ncoupling constant between $^{31}$P nucleus and V$^{4+}$ spins is calculated to\nbe $A_{\\rm hf}(1) \\simeq 2963$ Oe/$\\mu_{\\rm B}$ and $A_{\\rm hf}(2) \\simeq 1466$\nOe/$\\mu_{\\rm B}$ for the P(1) and P(2) sites, respectively. Our NMR shift and\nspin-lattice relaxation rate for both the $^{31}$P sites show an activated\nbehaviour at low temperatures, further confirming the singlet ground state. The\nestimated value of the spin gap from the NMR data measured in an applied field\nof $H = 9.394$ T is consistent with the gap obtained from the magnetic\nsusceptibility analysis using the dimer model. Because of a relatively small\nspin gap,\nNH$_4$[(V$_2$O$_3$)$_2$(4,4$^\\prime$-$bpy$)$_2$(H$_2$PO$_4$)(PO$_4$)$_2$]$\\cdot$0.5H$_2$O\nis a promising compound for further experimental studies under high magnetic\nfields.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Zeros of real random polynomials spanned by OPUC.   Let \\( \\{\\varphi_i\\}_{i=0}^\\infty \\) be a sequence of orthonormal polynomials\non the unit circle with respect to a probability measure \\( \\mu \\). We study\nzero distribution of random linear combinations of the form \\[\nP_n(z)=\\sum_{i=0}^{n-1}\\eta_i\\varphi_i(z), \\] where \\( \\eta_0,\\dots,\\eta_{n-1}\n\\) are i.i.d. standard Gaussian variables. We use the Christoffel-Darboux\nformula to simplify the density functions provided by Vanderbei for the\nexpected number real and complex of zeros of \\( P_n \\). From these expressions,\nunder the assumption that \\( \\mu \\) is in the Nevai class, we deduce the\nlimiting value of these density functions away from the unit circle. Under the\nmere assumption that \\( \\mu \\) is doubling on subarcs of \\( \\T \\) centered at\n\\( 1 \\) and \\( -1 \\), we show that the expected number of real zeros of \\( P_n\n\\) is at most \\[ (2/\\pi) \\log n +O(1), \\] and that the asymptotic equality\nholds when the corresponding recurrence coefficients decay no slower than \\(\nn^{-(3+\\epsilon)/2} \\), \\( \\epsilon>0 \\). We conclude with providing results\nthat estimate the expected number of complex zeros of \\( P_n \\) in shrinking\nneighborhoods of compact subsets of \\( \\T \\).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Hand Combining Two Simple Grippers to Pick up and Arrange Objects for Assembly.   This paper proposes a novel robotic hand design for assembly tasks. The idea\nis to combine two simple grippers -- an inner gripper which is used for precise\nalignment, and an outer gripper which is used for stable holding. Conventional\nrobotic hands require complicated compliant mechanisms or complicated control\nstrategy and force sensing to conduct assemble tasks, which makes them costly\nand difficult to pick and arrange small objects like screws or washers.\nCompared to the conventional hands, the proposed design provides a low-cost\nsolution for aligning, picking up, and arranging various objects by taking\nadvantages of the geometric constraints of the positioning fingers and gravity.\nIt is able to deal with small screws and washers, and eliminate the position\nerrors of cylindrical objects or objects with cylindrical holes. In the\nexperiments, both real-world tasks and quantitative analysis are performed to\nvalidate the aligning, picking, and arrangements abilities of the design.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Large time behavior of solution to nonlinear Dirac equation in $1+1$ dimensions.   This paper studies the large time behavior of solution for a class of\nnonlinear massless Dirac equations in $R^{1+1}$. It is shown that the solution\nwill tend to travelling wave solution when time tends to infinity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Positive semi-definite embedding for dimensionality reduction and out-of-sample extensions.   In machine learning or statistics, it is often desirable to reduce the\ndimensionality of high dimensional data. We propose to obtain the low\ndimensional embedding coordinates as the eigenvectors of a positive\nsemi-definite kernel matrix. This kernel matrix is the solution of a\nsemi-definite program promoting a low rank solution and defined with the help\nof a diffusion kernel. Besides, we also discuss an infinite dimensional\nanalogue of the same semi-definite program. From a practical perspective, a\nmain feature of our approach is the existence of a non-linear out-of-sample\nextension formula of the embedding coordinates that we call a projected\nNyström approximation. This extension formula yields an extension of the\nkernel matrix to a data-dependent Mercer kernel function. Although the\nsemi-definite program may be solved directly, we propose another strategy based\non a rank constrained formulation solved thanks to a projected power method\nalgorithm followed by a singular value decomposition. This strategy allows for\na reduced computational time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Drawing Planar Graphs with Few Geometric Primitives.   We define the \\emph{visual complexity} of a plane graph drawing to be the\nnumber of basic geometric objects needed to represent all its edges. In\nparticular, one object may represent multiple edges (e.g., one needs only one\nline segment to draw a path with an arbitrary number of edges). Let $n$ denote\nthe number of vertices of a graph. We show that trees can be drawn with $3n/4$\nstraight-line segments on a polynomial grid, and with $n/2$ straight-line\nsegments on a quasi-polynomial grid. Further, we present an algorithm for\ndrawing planar 3-trees with $(8n-17)/3$ segments on an $O(n)\\times O(n^2)$\ngrid. This algorithm can also be used with a small modification to draw maximal\nouterplanar graphs with $3n/2$ edges on an $O(n)\\times O(n^2)$ grid. We also\nstudy the problem of drawing maximal planar graphs with circular arcs and\nprovide an algorithm to draw such graphs using only $(5n - 11)/3$ arcs. This is\nsignificantly smaller than the lower bound of $2n$ for line segments for a\nnontrivial graph class.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Promise and Peril of Human Evaluation for Model Interpretability.   Transparency, user trust, and human comprehension are popular ethical\nmotivations for interpretable machine learning. In support of these goals,\nresearchers evaluate model explanation performance using humans and real world\napplications. This alone presents a challenge in many areas of artificial\nintelligence. In this position paper, we propose a distinction between\ndescriptive and persuasive explanations. We discuss reasoning suggesting that\nfunctional interpretability may be correlated with cognitive function and user\npreferences. If this is indeed the case, evaluation and optimization using\nfunctional metrics could perpetuate implicit cognitive bias in explanations\nthat threaten transparency. Finally, we propose two potential research\ndirections to disambiguate cognitive function and explanation models, retaining\ncontrol over the tradeoff between accuracy and interpretability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamic density structure factor of a unitary Fermi gas at finite temperature.   We present a theoretical investigation of the dynamic density structure\nfactor of a strongly interacting Fermi gas near a Feshbach resonance at finite\ntemperature. The study is based on a gauge invariant linear response theory.\nThe theory is consistent with a diagrammatic approach for the equilibrium state\ntaking into account the pair fluctuation effects and respects some important\nrestrictions like the $f$-sum rule. Our numerical results show that the dynamic\ndensity structure factor at large incoming momentum and at half recoil\nfrequency has a qualitatively similar behavior as the order parameter, which\ncan signify the appearance of the condensate. This qualitatively agrees with\nthe recent Bragg spectroscopy experiment results. We also present the results\nat small incoming momentum.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Alliance formation with exclusion in the spatial public goods game.   Detecting defection and alarming partners about the possible danger could be\nessential to avoid being exploited. This act, however, may require a huge\nindividual effort from those who take this job, hence such a strategy seems to\nbe unfavorable. But structured populations can provide an opportunity where a\nlargely unselfish excluder strategy can form an effective alliance with other\ncooperative strategies, hence they can sweep out defection. Interestingly, this\nalliance is functioning even at the extremely high cost of exclusion where the\nsole application of an exclusion strategy would be harmful otherwise. These\nresults may explain why the emergence of extreme selfless behavior is not\nnecessarily against individual selection but could be the result of an\nevolutionary process.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Automatic Detection of Knee Joints and Quantification of Knee Osteoarthritis Severity using Convolutional Neural Networks.   This paper introduces a new approach to automatically quantify the severity\nof knee OA using X-ray images. Automatically quantifying knee OA severity\ninvolves two steps: first, automatically localizing the knee joints; next,\nclassifying the localized knee joint images. We introduce a new approach to\nautomatically detect the knee joints using a fully convolutional neural network\n(FCN). We train convolutional neural networks (CNN) from scratch to\nautomatically quantify the knee OA severity optimizing a weighted ratio of two\nloss functions: categorical cross-entropy and mean-squared loss. This joint\ntraining further improves the overall quantification of knee OA severity, with\nthe added benefit of naturally producing simultaneous multi-class\nclassification and regression outputs. Two public datasets are used to evaluate\nour approach, the Osteoarthritis Initiative (OAI) and the Multicenter\nOsteoarthritis Study (MOST), with extremely promising results that outperform\nexisting approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Direct Optimization through $\\arg \\max$ for Discrete Variational Auto-Encoder.   Reparameterization of variational auto-encoders with continuous latent spaces\nis an effective method for reducing the variance of their gradient estimates.\nHowever, using the same approach when latent variables are discrete is\nproblematic, due to the resulting non-differentiable objective. In this work,\nwe present a direct optimization method that propagates gradients through a\nnon-differentiable $\\arg \\max$ prediction operation. We apply this method to\ndiscrete variational auto-encoders, by modeling a discrete random variable by\nthe $\\arg \\max$ function of the Gumbel-Max perturbation model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-robot motion-formation distributed control with sensor self-calibration: experimental validation.   In this paper, we present the design and implementation of a robust motion\nformation distributed control algorithm for a team of mobile robots. The\nprimary task for the team is to form a geometric shape, which can be freely\ntranslated and rotated at the same time. This approach makes the robots to\nbehave as a cohesive whole, which can be useful in tasks such as collaborative\ntransportation. The robustness of the algorithm relies on the fact that each\nrobot employs only local measurements from a laser sensor which does not need\nto be off-line calibrated. Furthermore, robots do not need to exchange any\ninformation with each other. Being free of sensor calibration and not requiring\na communication channel helps the scaling of the overall system to a large\nnumber of robots. In addition, since the robots do not need any off-board\nlocalization system, but require only relative positions with respect to their\nneighbors, it can be aimed to have a full autonomous team that operates in\nenvironments where such localization systems are not available. The\ncomputational cost of the algorithm is inexpensive and the resources from a\nstandard microcontroller will suffice. This fact makes the usage of our\napproach appealing as a support for other more demanding algorithms, e.g.,\nprocessing images from onboard cameras. We validate the performance of the\nalgorithm with a team of four mobile robots equipped with low-cost commercially\navailable laser scanners.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Optimal Generalizability in Parametric Learning.   We consider the parametric learning problem, where the objective of the\nlearner is determined by a parametric loss function. Employing empirical risk\nminimization with possibly regularization, the inferred parameter vector will\nbe biased toward the training samples. Such bias is measured by the cross\nvalidation procedure in practice where the data set is partitioned into a\ntraining set used for training and a validation set, which is not used in\ntraining and is left to measure the out-of-sample performance. A classical\ncross validation strategy is the leave-one-out cross validation (LOOCV) where\none sample is left out for validation and training is done on the rest of the\nsamples that are presented to the learner, and this process is repeated on all\nof the samples. LOOCV is rarely used in practice due to the high computational\ncomplexity. In this paper, we first develop a computationally efficient\napproximate LOOCV (ALOOCV) and provide theoretical guarantees for its\nperformance. Then we use ALOOCV to provide an optimization algorithm for\nfinding the regularizer in the empirical risk minimization framework. In our\nnumerical experiments, we illustrate the accuracy and efficiency of ALOOCV as\nwell as our proposed framework for the optimization of the regularizer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Laser annealing heals radiation damage in avalanche photodiodes.   Avalanche photodiodes (APDs) are a practical option for space-based quantum\ncommunications requiring single-photon detection. However, radiation damage to\nAPDs significantly increases their dark count rates and reduces their useful\nlifetimes in orbit. We show that high-power laser annealing of irradiated APDs\nof three different models (Excelitas C30902SH, Excelitas SLiK, and Laser\nComponents SAP500S2) heals the radiation damage and substantially restores low\ndark count rates. Of nine samples, the maximum dark count rate reduction factor\nvaries between 5.3 and 758 when operating at minus 80 degrees Celsius. The\nillumination power to reach these reduction factors ranges from 0.8 to 1.6 W.\nOther photon detection characteristics, such as photon detection efficiency,\ntiming jitter, and afterpulsing probability, remain mostly unaffected. These\nresults herald a promising method to extend the lifetime of a quantum satellite\nequipped with APDs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "ParaGraphE: A Library for Parallel Knowledge Graph Embedding.   Knowledge graph embedding aims at translating the knowledge graph into\nnumerical representations by transforming the entities and relations into\ncontinuous low-dimensional vectors. Recently, many methods [1, 5, 3, 2, 6] have\nbeen proposed to deal with this problem, but existing single-thread\nimplementations of them are time-consuming for large-scale knowledge graphs.\nHere, we design a unified parallel framework to parallelize these methods,\nwhich achieves a significant time reduction without influencing the accuracy.\nWe name our framework as ParaGraphE, which provides a library for parallel\nknowledge graph embedding. The source code can be downloaded from\nthis https URL .",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strong and Weak Equilibria for Time-Inconsistent Stochastic Control in Continuous Time.   A new definition of continuous-time equilibrium controls is introduced. As\nopposed to the standard definition, which involves a derivative-type operation,\nthe new definition parallels how a discrete-time equilibrium is defined, and\nallows for unambiguous economic interpretation. The terms \"strong equilibria\"\nand \"weak equilibria\" are coined for controls under the new and the standard\ndefinitions, respectively. When the state process is a time-homogeneous\ncontinuous-time Markov chain, a careful asymptotic analysis gives complete\ncharacterizations of weak and strong equilibria. Thanks to Kakutani-Fan's\nfixed-point theorem, general existence of weak and strong equilibria is also\nestablished, under additional compactness assumption. Our theoretic results are\napplied to a two-state model under non-exponential discounting. In particular,\nwe demonstrate explicitly that there can be incentive to deviate from a weak\nequilibrium, which justifies the need for strong equilibria. Our analysis also\nprovides new results for the existence and characterization of discrete-time\nequilibria under infinite horizon.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Mixed-Effect Modeling for Longitudinal Prediction of Cancer Tumor.   In this paper, a mixed-effect modeling scheme is proposed to construct a\npredictor for different features of cancer tumor. For this purpose, a set of\nfeatures is extracted from two groups of patients with the same type of cancer\nbut with two medical outcome: 1) survived and 2) passed away. The goal is to\nbuild different models for the two groups, where in each group,\npatient-specified behavior of individuals can be characterized. These models\nare then used as predictors to forecast future state of patients with a given\nhistory or initial state. To this end, a leave-on-out cross validation method\nis used to measure the prediction accuracy of each patient-specified model.\nExperiments show that compared to fixed-effect modeling (regression),\nmixed-effect modeling has a superior performance on some of the extracted\nfeatures and similar or worse performance on the others.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparative study of Discrete Wavelet Transforms and Wavelet Tensor Train decomposition to feature extraction of FTIR data of medicinal plants.   Fourier-transform infra-red (FTIR) spectra of samples from 7 plant species\nwere used to explore the influence of preprocessing and feature extraction on\nefficiency of machine learning algorithms. Wavelet Tensor Train (WTT) and\nDiscrete Wavelet Transforms (DWT) were compared as feature extraction\ntechniques for FTIR data of medicinal plants. Various combinations of signal\nprocessing steps showed different behavior when applied to classification and\nclustering tasks. Best results for WTT and DWT found through grid search were\nsimilar, significantly improving quality of clustering as well as\nclassification accuracy for tuned logistic regression in comparison to original\nspectra. Unlike DWT, WTT has only one parameter to be tuned (rank), making it a\nmore versatile and easier to use as a data processing tool in various signal\nprocessing applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Large Term Rewrite System Modelling a Pioneering Cryptographic Algorithm.   We present a term rewrite system that formally models the Message\nAuthenticator Algorithm (MAA), which was one of the first cryptographic\nfunctions for computing a Message Authentication Code and was adopted, between\n1987 and 2001, in international standards (ISO 8730 and ISO 8731-2) to ensure\nthe authenticity and integrity of banking transactions. Our term rewrite system\nis large (13 sorts, 18 constructors, 644 non-constructors, and 684 rewrite\nrules), confluent, and terminating. Implementations in thirteen different\nlanguages have been automatically derived from this model and used to validate\n200 official test vectors for the MAA.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum Annealing Applied to De-Conflicting Optimal Trajectories for Air Traffic Management.   We present the mapping of a class of simplified air traffic management (ATM)\nproblems (strategic conflict resolution) to quadratic unconstrained boolean\noptimization (QUBO) problems. The mapping is performed through an original\nrepresentation of the conflict-resolution problem in terms of a conflict graph,\nwhere nodes of the graph represent flights and edges represent a potential\nconflict between flights. The representation allows a natural decomposition of\na real world instance related to wind- optimal trajectories over the Atlantic\nocean into smaller subproblems, that can be discretized and are amenable to be\nprogrammed in quantum annealers. In the study, we tested the new programming\ntechniques and we benchmark the hardness of the instances using both classical\nsolvers and the D-Wave 2X and D-Wave 2000Q quantum chip. The preliminary\nresults show that for reasonable modeling choices the most challenging\nsubproblems which are programmable in the current devices are solved to\noptimality with 99% of probability within a second of annealing time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stronger selection can slow down evolution driven by recombination on a smooth fitness landscape.   Stronger selection implies faster evolution---that is, the greater the force,\nthe faster the change. This apparently self-evident proposition, however, is\nderived under the assumption that genetic variation within a population is\nprimarily supplied by mutation (i.e.\\ mutation-driven evolution). Here, we show\nthat this proposition does not actually hold for recombination-driven\nevolution, i.e.\\ evolution in which genetic variation is primarily created by\nrecombination rather than mutation. By numerically investigating population\ngenetics models of recombination, migration and selection, we demonstrate that\nstronger selection can slow down evolution on a perfectly smooth fitness\nlandscape. Through simple analytical calculation, this apparently\ncounter-intuitive result is shown to stem from two opposing effects of natural\nselection on the rate of evolution. On the one hand, natural selection tends to\nincrease the rate of evolution by increasing the fixation probability of fitter\ngenotypes. On the other hand, natural selection tends to decrease the rate of\nevolution by decreasing the chance of recombination between immigrants and\nresident individuals. As a consequence of these opposing effects, there is a\nfinite selection pressure maximizing the rate of evolution. Hence, stronger\nselection can imply slower evolution if genetic variation is primarily supplied\nby recombination.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Two-Dimensional Systolic Complexes Satisfy Property A.   We show that 2-dimensional systolic complexes are quasi-isometric to quadric\ncomplexes with flat intervals. We use this fact along with the weight function\nof Brodzki, Campbell, Guentner, Niblo and Wright to prove that 2-dimensional\nsystolic complexes satisfy Property A.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "CT Image Reconstruction in a Low Dimensional Manifold.   Regularization methods are commonly used in X-ray CT image reconstruction.\nDifferent regularization methods reflect the characterization of different\nprior knowledge of images. In a recent work, a new regularization method called\na low-dimensional manifold model (LDMM) is investigated to characterize the\nlow-dimensional patch manifold structure of natural images, where the manifold\ndimensionality characterizes structural information of an image. In this paper,\nwe propose a CT image reconstruction method based on the prior knowledge of the\nlow-dimensional manifold of CT image. Using the clinical raw projection data\nfrom GE clinic, we conduct comparisons for the CT image reconstruction among\nthe proposed method, the simultaneous algebraic reconstruction technique (SART)\nwith the total variation (TV) regularization, and the filtered back projection\n(FBP) method. Results show that the proposed method can successfully recover\nstructural details of an imaging object, and achieve higher spatial and\ncontrast resolution of the reconstructed image than counterparts of FBP and\nSART with TV.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Binary Matrix Factorization via Dictionary Learning.   Matrix factorization is a key tool in data analysis; its applications include\nrecommender systems, correlation analysis, signal processing, among others.\nBinary matrices are a particular case which has received significant attention\nfor over thirty years, especially within the field of data mining. Dictionary\nlearning refers to a family of methods for learning overcomplete basis (also\ncalled frames) in order to efficiently encode samples of a given type; this\narea, now also about twenty years old, was mostly developed within the signal\nprocessing field. In this work we propose two binary matrix factorization\nmethods based on a binary adaptation of the dictionary learning paradigm to\nbinary matrices. The proposed algorithms focus on speed and scalability; they\nwork with binary factors combined with bit-wise operations and a few auxiliary\ninteger ones. Furthermore, the methods are readily applicable to online binary\nmatrix factorization. Another important issue in matrix factorization is the\nchoice of rank for the factors; we address this model selection problem with an\nefficient method based on the Minimum Description Length principle. Our\npreliminary results show that the proposed methods are effective at producing\ninterpretable factorizations of various data types of different nature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Computing maximum cliques in $B_2$-EPG graphs.   EPG graphs, introduced by Golumbic et al. in 2009, are edge-intersection\ngraphs of paths on an orthogonal grid. The class $B_k$-EPG is the subclass of\nEPG graphs where the path on the grid associated to each vertex has at most $k$\nbends. Epstein et al. showed in 2013 that computing a maximum clique in\n$B_1$-EPG graphs is polynomial. As remarked in [Heldt et al., 2014], when the\nnumber of bends is at least $4$, the class contains $2$-interval graphs for\nwhich computing a maximum clique is an NP-hard problem. The complexity status\nof the Maximum Clique problem remains open for $B_2$ and $B_3$-EPG graphs. In\nthis paper, we show that we can compute a maximum clique in polynomial time in\n$B_2$-EPG graphs given a representation of the graph.\nMoreover, we show that a simple counting argument provides a\n${2(k+1)}$-approximation for the coloring problem on $B_k$-EPG graphs without\nknowing the representation of the graph. It generalizes a result of [Epstein et\nal, 2013] on $B_1$-EPG graphs (where the representation was needed).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Survey of Visual Question Answering: Datasets and Techniques.   Visual question answering (or VQA) is a new and exciting problem that\ncombines natural language processing and computer vision techniques. We present\na survey of the various datasets and models that have been used to tackle this\ntask. The first part of the survey details the various datasets for VQA and\ncompares them along some common factors. The second part of this survey details\nthe different approaches for VQA, classified into four types: non-deep learning\nmodels, deep learning models without attention, deep learning models with\nattention, and other models which do not fit into the first three. Finally, we\ncompare the performances of these approaches and provide some directions for\nfuture work.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analysis of the Polya-Gamma block Gibbs sampler for Bayesian logistic linear mixed models.   In this article, we construct a two-block Gibbs sampler using Polson et al.\n(2013) data augmentation technique with Polya-Gamma latent variables for\nBayesian logistic linear mixed models under proper priors. Furthermore, we\nprove the uniform ergodicity of this Gibbs sampler, which guarantees the\nexistence of the central limit theorems for MCMC based estimators.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Achieving rental harmony with a secretive roommate.   Given the subjective preferences of n roommates in an n-bedroom apartment,\none can use Sperner's lemma to find a division of the rent such that each\nroommate is content with a distinct room. At the given price distribution, no\nroommate has a strictly stronger preference for a different room. We give a new\nelementary proof that the subjective preferences of only n-1 of the roommates\nactually suffice to achieve this envy-free rent division. Our proof, in\nparticular, yields an algorithm to find such a fair division of rent. The\ntechniques also give generalizations of Sperner's lemma including a new proof\nof a conjecture of the third author.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Automaton Semigroups and Groups: on the Undecidability of Problems Related to Freeness and Finiteness.   In this paper, we study algorithmic problems for automaton semigroups and\nautomaton groups related to freeness and finiteness. In the course of this\nstudy, we also exhibit some connections between the algebraic structure of\nautomaton (semi)groups and their dynamics on the boundary.\nFirst, we show that it is undecidable to check whether the group generated by\na given invertible automaton has a positive relation, i. e. a relation p = 1\nsuch that p only contains positive generators. Besides its obvious relation to\nthe freeness of the group, the absence of positive relations has previously\nbeen studied and is connected to the triviality of some stabilizers of the\nboundary. We show that the emptiness of the set of positive relations is\nequivalent to the dynamical property that all (directed positive) orbital\ngraphs centered at non-singular points are acyclic. Our approach also works to\nshow undecidability of the freeness problem for automaton semigroups; in fact,\nit shows undecidability of a strengthened version where the input automaton is\ncomplete and invertible.\nGillibert showed that the finiteness problem for automaton semigroups is\nundecidable. In the second part of the paper, we show that this undecidability\nresult also holds if the input is restricted to be bi-reversible and invertible\n(but, in general, not complete). As an immediate consequence, we obtain that\nthe finiteness problem for automaton subsemigroups of semigroups generated by\ninvertible, yet partial automata, so called automaton-inverse semigroups, is\nalso undecidable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Anticipation: an effective evolutionary strategy for a sub-optimal population in a cyclic environment.   We built a two-state model of an asexually reproducing organism in a periodic\nenvironment endowed with the capability to anticipate an upcoming environmental\nchange and undergo pre-emptive switching. By virtue of these anticipatory\ntransitions, the organism oscillates between its two states that is a time\n$\\theta$ out of sync with the environmental oscillation. We show that an\nanticipation-capable organism increases its long-term fitness over an organism\nthat oscillates in-sync with the environment, provided $\\theta$ does not exceed\na threshold. We also show that the long-term fitness is maximized for an\noptimal anticipation time that decreases approximately as $1/n$, $n$ being the\nnumber of cell divisions in time $T$. Furthermore, we demonstrate that optimal\n\"anticipators\" outperforms \"bet-hedgers\" in the range of parameters considered.\nFor a sub-optimal ensemble of anticipators, anticipation performs better to\nbet-hedging only when the variance in anticipation is small compared to the\nmean and the rate of pre-emptive transition is high. Taken together, our work\nsuggests that anticipation increases overall fitness of an organism in a\nperiodic environment and it is a viable alternative to bet-hedging provided the\nerror in anticipation is small.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Finite-sample bounds for the multivariate Behrens-Fisher distribution with proportional covariances.   The Behrens-Fisher problem is a well-known hypothesis testing problem in\nstatistics concerning two-sample mean comparison. In this article, we confirm\none conjecture in Eaton and Olshen (1972), which provides stochastic bounds for\nthe multivariate Behrens-Fisher test statistic under the null hypothesis. We\nalso extend their results on the stochastic ordering of random quotients to the\narbitrary finite dimensional case. This work can also be seen as a\ngeneralization of Hsu (1938) that provided the bounds for the univariate\nBehrens-Fisher problem. The results obtained in this article can be used to\nderive a testing procedure for the multivariate Behrens-Fisher problem that\nstrongly controls the Type I error.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Controlling plasmon modes and damping in buckled two-dimensional material open systems.   Full ranges of both hybrid plasmon-mode dispersions and their damping are\nstudied systematically by our recently developed mean-field theory in open\nsystems involving a conducting substrate and a two-dimensional (2D) material\nwith a buckled honeycomb lattice, such as silicene, germanene, and a group\n\\rom{4} dichalcogenide as well. In this hybrid system, the single plasmon mode\nfor a free-standing 2D layer is split into one acoustic-like and one\noptical-like mode, leading to a dramatic change in the damping of plasmon\nmodes. In comparison with gapped graphene, critical features associated with\nplasmon modes and damping in silicene and molybdenum disulfide are found with\nvarious spin-orbit and lattice asymmetry energy bandgaps, doping types and\nlevels, and coupling strengths between 2D materials and the conducting\nsubstrate. The obtained damping dependence on both spin and valley degrees of\nfreedom is expected to facilitate measuring the open-system dielectric property\nand the spin-orbit coupling strength of individual 2D materials. The unique\nlinear dispersion of the acoustic-like plasmon mode introduces additional\ndamping from the intraband particle-hole modes which is absent for a\nfree-standing 2D material layer, and the use of molybdenum disulfide with a\nlarge bandgap simultaneously suppresses the strong damping from the interband\nparticle-hole modes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Data-driven Advice for Applying Machine Learning to Bioinformatics Problems.   As the bioinformatics field grows, it must keep pace not only with new data\nbut with new algorithms. Here we contribute a thorough analysis of 13\nstate-of-the-art, commonly used machine learning algorithms on a set of 165\npublicly available classification problems in order to provide data-driven\nalgorithm recommendations to current researchers. We present a number of\nstatistical and visual comparisons of algorithm performance and quantify the\neffect of model selection and algorithm tuning for each algorithm and dataset.\nThe analysis culminates in the recommendation of five algorithms with\nhyperparameters that maximize classifier performance across the tested\nproblems, as well as general guidelines for applying machine learning to\nsupervised classification problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "HATS-43b, HATS-44b, HATS-45b, and HATS-46b: Four Short Period Transiting Giant Planets in the Neptune-Jupiter Mass Range.   We report the discovery of four short period extrasolar planets transiting\nmoderately bright stars from photometric measurements of the HATSouth network\ncoupled to additional spectroscopic and photometric follow-up observations.\nWhile the planet masses range from 0.26 to 0.90 M$_J$, the radii are all\napproximately a Jupiter radii, resulting in a wide range of bulk densities. The\norbital period of the planets range from 2.7d to 4.7d, with HATS-43b having an\norbit that appears to be marginally non-circular (e= 0.173$\\pm$0.089). HATS-44\nis notable for a high metallicity ([Fe/H]= 0.320$\\pm$0.071). The host stars\nspectral types range from late F to early K, and all of them are moderately\nbright (13.3<V<14.4), allowing the execution of future detailed follow-up\nobservations. HATS-43b and HATS-46b, with expected transmission signals of 2350\nppm and 1500 ppm, respectively, are particularly well suited targets for\natmospheric characterisation via transmission spectroscopy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Radon background in liquid xenon detectors.   The radioactive daughters isotope of 222Rn are one of the highest risk\ncontaminants in liquid xenon detectors aiming for a small signal rate. The\nnoble gas is permanently emanated from the detector surfaces and mixed with the\nxenon target. Because of its long half-life 222Rn is homogeneously distributed\nin the target and its subsequent decays can mimic signal events. Since no\nshielding is possible this background source can be the dominant one in future\nlarge scale experiments. This article provides an overview of strategies used\nto mitigate this source of background by means of material selection and\non-line radon removal techniques.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Faraday room of the CUORE Experiment.   The paper describes the Faraday room that shields the CUORE experiment\nagainst electromagnetic fields, from 50 Hz up to high frequency. Practical\ncontraints led to choose panels made of light shielding materials. The seams\nbetween panels were optimized with simulations to minimize leakage.\nMeasurements of shielding performance show attenuation of a factor 15 at 50 Hz,\nand a factor 1000 above 1 KHz up to about 100 MHz.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Baby MIND: A magnetized segmented neutrino detector for the WAGASCI experiment.   T2K (Tokai-to-Kamioka) is a long-baseline neutrino experiment in Japan\ndesigned to study various parameters of neutrino oscillations. A near detector\ncomplex (ND280) is located 280~m downstream of the production target and\nmeasures neutrino beam parameters before any oscillations occur. ND280's\nmeasurements are used to predict the number and spectra of neutrinos in the\nSuper-Kamiokande detector at the distance of 295~km. The difference in the\ntarget material between the far (water) and near (scintillator, hydrocarbon)\ndetectors leads to the main non-cancelling systematic uncertainty for the\noscillation analysis. In order to reduce this uncertainty a new\nWAter-Grid-And-SCintillator detector (WAGASCI) has been developed. A magnetized\niron neutrino detector (Baby MIND) will be used to measure momentum and charge\nidentification of the outgoing muons from charged current interactions. The\nBaby MIND modules are composed of magnetized iron plates and long plastic\nscintillator bars read out at the both ends with wavelength shifting fibers and\nsilicon photomultipliers. The front-end electronics board has been developed to\nperform the readout and digitization of the signals from the scintillator bars.\nDetector elements were tested with cosmic rays and in the PS beam at CERN. The\nobtained results are presented in this paper.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Inflationary magneto-(non)genesis, increasing kinetic couplings, and the strong coupling problem.   We study the generation of magnetic fields during inflation making use of a\ncoupling of the inflaton and moduli fields to electromagnetism via the photon\nkinetic term, and assuming that the coupling is an increasing function of time.\nWe demonstrate that the strong coupling problem of inflationary magnetogenesis\ncan be avoided by incorporating the destabilization of moduli fields after\ninflation. The magnetic field always dominates over the electric one, and thus\nthe severe constraints on the latter from backreaction, which are the demanding\nobstacles in the case of a decreasing coupling function, do not apply to the\ncurrent scenario. However, we show that this loophole to the strong coupling\nproblem comes at a price: the normalization of the amplitude of magnetic fields\nis determined by this coupling term and is therefore suppressed by a large\nfactor after the moduli destabilization completes. From this we conclude that\nthere is no self-consistent and generic realization of primordial\nmagnetogenesis producing scale-invariant fields in the case of an increasing\nkinetic coupling.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Exhaled breath barbotage: a new method for pulmonary surfactant dysfunction assessment.   Exhaled air contains aerosol of submicron droplets of the alveolar lining\nfluid (ALF), which are generated in the small airways of a human lung. Since\nthe exhaled particles are micro-samples of the ALF, their trapping opens up an\nopportunity to collect non-invasively a native material from respiratory tract.\nRecent studies of the particle characteristics (such as size distribution,\nconcentration and composition) in healthy and diseased subjects performed under\nvarious conditions have demonstrated a high potential of the analysis of\nexhaled aerosol droplets for identifying and monitoring pathological processes\nin the ALF. In this paper we present a new method for sampling of aerosol\nparticles during the exhaled breath barbotage (EBB) through liquid. The\nbarbotage procedure results in accumulation of the pulmonary surfactant, being\nthe main component of ALF, on the liquid surface, which makes possible the\nstudy its surface properties. We also propose a data processing algorithm to\nevaluate the surface pressure ($\\pi$) -- surface concentration ($\\Gamma$)\nisotherm from the raw data measured in a Langmuir trough. Finally, we analyze\nthe $(\\pi-\\Gamma)$ isotherms obtained for the samples collected in the groups\nof healthy volunteers and patients with pulmonary tuberculosis and compare them\nwith the isotherm measured for the artificial pulmonary surfactant.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The adaptive zero-error capacity for a class of channels with noisy feedback.   The adaptive zero-error capacity of discrete memoryless channels (DMC) with\nnoiseless feedback has been shown to be positive whenever there exists at least\none channel output \"disprover\", i.e. a channel output that cannot be reached\nfrom at least one of the inputs. Furthermore, whenever there exists a\ndisprover, the adaptive zero-error capacity attains the Shannon (small-error)\ncapacity. Here, we study the zero-error capacity of a DMC when the channel\nfeedback is noisy rather than perfect. We show that the adaptive zero-error\ncapacity with noisy feedback is lower bounded by the forward channel's\nzero-undetected error capacity, and show that under certain conditions this is\ntight.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SimProp v2r4: Monte Carlo simulation code for UHECR propagation.   We introduce the new version of SimProp, a Monte Carlo code for simulating\nthe propagation of ultra-high energy cosmic rays in intergalactic space. This\nversion, SimProp v2r4, together with an overall improvement of the code\ncapabilities with a substantial reduction in the computation time, also\ncomputes secondary cosmogenic particles such as electron-positron pairs and\ngamma rays produced during the propagation of ultra-high energy cosmic rays. As\nrecently pointed out by several authors, the flux of this secondary radiation\nand its products, within reach of the current observatories, provides useful\ninformation about models of ultra-high energy cosmic ray sources which would be\nhard to discriminate otherwise.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "X-Cube Fracton Model on Generic Lattices: Phases and Geometric Order.   Fracton order is a new kind of quantum order characterized by topological\nexcitations that exhibit remarkable mobility restrictions and a robust ground\nstate degeneracy (GSD) which can increase exponentially with system size. In\nthis paper, we present a generic lattice construction (in three dimensions) for\na generalized X-cube model of fracton order, where the mobility restrictions of\nthe subdimensional particles inherit the geometry of the lattice. This helps\nexplain a previous result that lattice curvature can produce a robust GSD, even\non a manifold with trivial topology. We provide explicit examples to show that\nthe (zero temperature) phase of matter is sensitive to the lattice geometry. In\none example, the lattice geometry confines the dimension-1 particles to small\nloops, which allows the fractons to be fully mobile charges, and the resulting\nphase is equivalent to (3+1)-dimensional toric code. However, the phase is\nsensitive to more than just lattice curvature; different lattices without\ncurvature (e.g. cubic or stacked kagome lattices) also result in different\nphases of matter, which are separated by phase transitions. Unintuitively\nhowever, according to a previous definition of phase [Chen, Gu, Wen 2010], even\njust a rotated or rescaled cubic lattice results in different phases of matter,\nwhich motivates us to propose a new and coarser definition of phase for gapped\nground states and fracton order. The new equivalence relation between ground\nstates is given by the composition of a local unitary transformation and a\nquasi-isometry (which can rotate and rescale the lattice); equivalently, ground\nstates are in the same phase if they can be adiabatically connected by varying\nboth the Hamiltonian and the positions of the degrees of freedom (via a\nquasi-isometry). In light of the importance of geometry, we further propose\nthat fracton orders should be regarded as a geometric order.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multifractal analysis of the time series of daily means of wind speed in complex regions.   In this paper, we applied the multifractal detrended fluctuation analysis to\nthe daily means of wind speed measured by 119 weather stations distributed over\nthe territory of Switzerland. The analysis was focused on the inner time\nfluctuations of wind speed, which could be more linked with the local\nconditions of the highly varying topography of Switzerland. Our findings point\nout to a persistent behaviour of all the measured wind speed series (indicated\nby a Hurst exponent significantly larger than 0.5), and to a high\nmultifractality degree indicating a relative dominance of the large\nfluctuations in the dynamics of wind speed, especially in the Swiss plateau,\nwhich is comprised between the Jura and Alp mountain ranges. The study\nrepresents a contribution to the understanding of the dynamical mechanisms of\nwind speed variability in mountainous regions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Causal Effect Inference with Deep Latent-Variable Models.   Learning individual-level causal effects from observational data, such as\ninferring the most effective medication for a specific patient, is a problem of\ngrowing importance for policy makers. The most important aspect of inferring\ncausal effects from observational data is the handling of confounders, factors\nthat affect both an intervention and its outcome. A carefully designed\nobservational study attempts to measure all important confounders. However,\neven if one does not have direct access to all confounders, there may exist\nnoisy and uncertain measurement of proxies for confounders. We build on recent\nadvances in latent variable modeling to simultaneously estimate the unknown\nlatent space summarizing the confounders and the causal effect. Our method is\nbased on Variational Autoencoders (VAE) which follow the causal structure of\ninference with proxies. We show our method is significantly more robust than\nexisting methods, and matches the state-of-the-art on previous benchmarks\nfocused on individual treatment effects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Low-cost Autonomous Navigation System Based on Optical Flow Classification.   This work presents a low-cost robot, controlled by a Raspberry Pi, whose\nnavigation system is based on vision. The strategy used consisted of\nidentifying obstacles via optical flow pattern recognition. Its estimation was\ndone using the Lucas-Kanade algorithm, which can be executed by the Raspberry\nPi without harming its performance. Finally, an SVM-based classifier was used\nto identify patterns of this signal associated with obstacles movement. The\ndeveloped system was evaluated considering its execution over an optical flow\npattern dataset extracted from a real navigation environment. In the end, it\nwas verified that the acquisition cost of the system was inferior to that\npresented by most of the cited works, while its performance was similar to\ntheirs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Euler characteristics of cominuscule quantum K-theory.   We prove an identity relating the product of two opposite Schubert varieties\nin the (equivariant) quantum K-theory ring of a cominuscule flag variety to the\nminimal degree of a rational curve connecting the Schubert varieties. We deduce\nthat the sum of the structure constants associated to any product of Schubert\nclasses is equal to one. Equivalently, the sheaf Euler characteristic map\nextends to a ring homomorphism defined on the quantum K-theory ring.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Big Data Regression Using Tree Based Segmentation.   Scaling regression to large datasets is a common problem in many application\nareas. We propose a two step approach to scaling regression to large datasets.\nUsing a regression tree (CART) to segment the large dataset constitutes the\nfirst step of this approach. The second step of this approach is to develop a\nsuitable regression model for each segment. Since segment sizes are not very\nlarge, we have the ability to apply sophisticated regression techniques if\nrequired. A nice feature of this two step approach is that it can yield models\nthat have good explanatory power as well as good predictive performance.\nEnsemble methods like Gradient Boosted Trees can offer excellent predictive\nperformance but may not provide interpretable models. In the experiments\nreported in this study, we found that the predictive performance of the\nproposed approach matched the predictive performance of Gradient Boosted Trees.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Galactic Dark Matter Halos and Globular Cluster Populations. III: Extension to Extreme Environments.   The total mass M_GCS in the globular cluster (GC) system of a galaxy is\nempirically a near-constant fraction of the total mass M_h = M_bary + M_dark of\nthe galaxy, across a range of 10^5 in galaxy mass. This trend is radically\nunlike the strongly nonlinear behavior of total stellar mass M_star versus M_h.\nWe discuss extensions of this trend to two more extreme situations: (a) entire\nclusters of galaxies, and (b) the Ultra-Diffuse Galaxies (UDGs) recently\ndiscovered in Coma and elsewhere. Our calibration of the ratio \\eta_M = M_GCS /\nM_h from normal galaxies, accounting for new revisions in the adopted\nmass-to-light ratio for GCs, now gives \\eta_M = 2.9 \\times 10^{-5} as the mean\nabsolute mass fraction. We find that the same ratio appears valid for galaxy\nclusters and UDGs. Estimates of \\eta_M in the four clusters we examine tend to\nbe slightly higher than for individual galaxies, butmore data and better\nconstraints on the mean GC mass in such systems are needed to determine if this\ndifference is significant. We use the constancy of \\eta_M to estimate total\nmasses for several individual cases; for example, the total mass of the Milky\nWay is calculated to be M_h = 1.1 \\times 10^{12} M_sun. Physical explanations\nfor the uniformity of \\eta_M are still descriptive, but point to a picture in\nwhich massive, dense star clusters in their formation stages were relatively\nimmune to the feedback that more strongly influenced lower-density regions\nwhere most stars form.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reversing Parallel Programs with Blocks and Procedures.   We show how to reverse a while language extended with blocks, local\nvariables, procedures and the interleaving parallel composition. Annotation is\ndefined along with a set of operational semantics capable of storing necessary\nreversal information, and identifiers are introduced to capture the\ninterleaving order of an execution. Inversion is defined with a set of\noperational semantics that use saved information to undo an execution. We prove\nthat annotation does not alter the behaviour of the original program, and that\ninversion correctly restores the initial program state.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The effect of prior probabilities on quantification and propagation of imprecise probabilities resulting from small datasets.   This paper outlines a methodology for Bayesian multimodel uncertainty\nquantification (UQ) and propagation and presents an investigation into the\neffect of prior probabilities on the resulting uncertainties. The UQ\nmethodology is adapted from the information-theoretic method previously\npresented by the authors (Zhang and Shields, 2018) to a fully Bayesian\nconstruction that enables greater flexibility in quantifying uncertainty in\nprobability model form. Being Bayesian in nature and rooted in UQ from small\ndatasets, prior probabilities in both probability model form and model\nparameters are shown to have a significant impact on quantified uncertainties\nand, consequently, on the uncertainties propagated through a physics-based\nmodel. These effects are specifically investigated for a simplified plate\nbuckling problem with uncertainties in material properties derived from a small\nnumber of experiments using noninformative priors and priors derived from past\nstudies of varying appropriateness. It is illustrated that prior probabilities\ncan have a significant impact on multimodel UQ for small datasets and\ninappropriate (but seemingly reasonable) priors may even have lingering effects\nthat bias probabilities even for large datasets. When applied to uncertainty\npropagation, this may result in probability bounds on response quantities that\ndo not include the true probabilities.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Barnacles and Gravity.   Theories with more than one vacuum allow quantum transitions between them,\nwhich may proceed via bubble nucleation; theories with more than two vacua\nposses additional decay modes in which the wall of a bubble may further decay.\nThe instantons which mediate such a process have $O(3)$ symmetry (in four\ndimensions, rather than the usual $O(4)$ symmetry of homogeneous vacuum decay),\nand have been called `barnacles'; previously they have been studied in flat\nspace, in the thin wall limit, and this paper extends the analysis to include\ngravity. It is found that there are regions of parameter space in which, given\nan initial bubble, barnacles are the favoured subsequent decay process, and\nthat the inclusion of gravity can enlarge this region. The relation to other\nheterogeneous vacuum decay scenarios, as well as some of the phenomenological\nimplications of barnacles are briefly discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning Deep Visual Object Models From Noisy Web Data: How to Make it Work.   Deep networks thrive when trained on large scale data collections. This has\ngiven ImageNet a central role in the development of deep architectures for\nvisual object classification. However, ImageNet was created during a specific\nperiod in time, and as such it is prone to aging, as well as dataset bias\nissues. Moving beyond fixed training datasets will lead to more robust visual\nsystems, especially when deployed on robots in new environments which must\ntrain on the objects they encounter there. To make this possible, it is\nimportant to break free from the need for manual annotators. Recent work has\nbegun to investigate how to use the massive amount of images available on the\nWeb in place of manual image annotations. We contribute to this research thread\nwith two findings: (1) a study correlating a given level of noisily labels to\nthe expected drop in accuracy, for two deep architectures, on two different\ntypes of noise, that clearly identifies GoogLeNet as a suitable architecture\nfor learning from Web data; (2) a recipe for the creation of Web datasets with\nminimal noise and maximum visual variability, based on a visual and natural\nlanguage processing concept expansion strategy. By combining these two results,\nwe obtain a method for learning powerful deep object models automatically from\nthe Web. We confirm the effectiveness of our approach through object\ncategorization experiments using our Web-derived version of ImageNet on a\npopular robot vision benchmark database, and on a lifelong object discovery\ntask on a mobile robot.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Driver Distraction Identification with an Ensemble of Convolutional Neural Networks.   The World Health Organization (WHO) reported 1.25 million deaths yearly due\nto road traffic accidents worldwide and the number has been continuously\nincreasing over the last few years. Nearly fifth of these accidents are caused\nby distracted drivers. Existing work of distracted driver detection is\nconcerned with a small set of distractions (mostly, cell phone usage).\nUnreliable ad-hoc methods are often used.In this paper, we present the first\npublicly available dataset for driver distraction identification with more\ndistraction postures than existing alternatives. In addition, we propose a\nreliable deep learning-based solution that achieves a 90% accuracy. The system\nconsists of a genetically-weighted ensemble of convolutional neural networks,\nwe show that a weighted ensemble of classifiers using a genetic algorithm\nyields in a better classification confidence. We also study the effect of\ndifferent visual elements in distraction detection by means of face and hand\nlocalizations, and skin segmentation. Finally, we present a thinned version of\nour ensemble that could achieve 84.64% classification accuracy and operate in a\nreal-time environment.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust Optimal Design of Energy Efficient Series Elastic Actuators: Application to a Powered Prosthetic Ankle.   Design of robotic systems that safely and efficiently operate in uncertain\noperational conditions, such as rehabilitation and physical assistance robots,\nremains an important challenge in the field. Current methods for the design of\nenergy efficient series elastic actuators use an optimization formulation that\ntypically assumes known operational conditions. This approach could lead to\nactuators that cannot perform in uncertain environments because elongation,\nspeed, or torque requirements may be beyond actuator specifications when the\noperation deviates from its nominal conditions. Addressing this gap, we propose\na convex optimization formulation to design the stiffness of series elastic\nactuators to minimize energy consumption and satisfy actuator constraints\ndespite uncertainty due to manufacturing of the spring, unmodeled dynamics,\nefficiency of the transmission, and the kinematics and kinetics of the load. In\nour formulation, we express energy consumption as a scalar convex-quadratic\nfunction of compliance. In the unconstrained case, this quadratic equation\nprovides an analytical solution to the optimal value of stiffness that\nminimizes energy consumption for arbitrary periodic reference trajectories. As\nactuator constraints, we consider peak motor torque, peak motor velocity,\nlimitations due to the speed-torque relationship of DC motors, and peak\nelongation of the spring. As a simulation case study, we apply our formulation\nto the robust design of a series elastic actuator for a powered prosthetic\nankle. Our simulation results indicate that a small trade-off between energy\nefficiency and robustness is justified to design actuators that can operate\nwith uncertainty.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Parameterized Approach to Personalized Variable Length Summarization of Soccer Matches.   We present a parameterized approach to produce personalized variable length\nsummaries of soccer matches. Our approach is based on temporally segmenting the\nsoccer video into 'plays', associating a user-specifiable 'utility' for each\ntype of play and using 'bin-packing' to select a subset of the plays that add\nup to the desired length while maximizing the overall utility (volume in\nbin-packing terms). Our approach systematically allows a user to override the\ndefault weights assigned to each type of play with individual preferences and\nthus see a highly personalized variable length summarization of soccer matches.\nWe demonstrate our approach based on the output of an end-to-end pipeline that\nwe are building to produce such summaries. Though aspects of the overall\nend-to-end pipeline are human assisted at present, the results clearly show\nthat the proposed approach is capable of producing semantically meaningful and\ncompelling summaries. Besides the obvious use of producing summaries of\nsuperior league matches for news broadcasts, we anticipate our work to promote\ngreater awareness of the local matches and junior leagues by producing\nconsumable summaries of them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gradient-based Filter Design for the Dual-tree Wavelet Transform.   The wavelet transform has seen success when incorporated into neural network\narchitectures, such as in wavelet scattering networks. More recently, it has\nbeen shown that the dual-tree complex wavelet transform can provide better\nrepresentations than the standard transform. With this in mind, we extend our\nprevious method for learning filters for the 1D and 2D wavelet transforms into\nthe dual-tree domain. We show that with few modifications to our original\nmodel, we can learn directional filters that leverage the properties of the\ndual-tree wavelet transform.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From rate distortion theory to metric mean dimension: variational principle.   The purpose of this paper is to point out a new connection between\ninformation theory and dynamical systems. In the information theory side, we\nconsider rate distortion theory, which studies lossy data compression of\nstochastic processes under distortion constraints. In the dynamical systems\nside, we consider mean dimension theory, which studies how many parameters per\nsecond we need to describe a dynamical system. The main results are new\nvariational principles connecting rate distortion function to metric mean\ndimension.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Five-dimensional Perfect Simplices.   Let $Q_n=[0,1]^n$ be the unit cube in ${\\mathbb R}^n$, $n \\in {\\mathbb N}$.\nFor a nondegenerate simplex $S\\subset{\\mathbb R}^n$, consider the value\n$\\xi(S)=\\min \\{\\sigma>0: Q_n\\subset \\sigma S\\}$. Here $\\sigma S$ is a\nhomothetic image of $S$ with homothety center at the center of gravity of $S$\nand coefficient of homothety $\\sigma$. Let us introduce the value $\\xi_n=\\min\n\\{\\xi(S): S\\subset Q_n\\}$. We call $S$ a perfect simplex if $S\\subset Q_n$ and\n$Q_n$ is inscribed into the simplex $\\xi_n S$. It is known that such simplices\nexist for $n=1$ and $n=3$. The exact values of $\\xi_n$ are known for $n=2$ and\nin the case when there exist an Hadamard matrix of order $n+1$, in the latter\nsituation $\\xi_n=n$. In this paper we show that $\\xi_5=5$ and $\\xi_9=9$. We\nalso describe infinite families of simplices $S\\subset Q_n$ such that\n$\\xi(S)=\\xi_n$ for $n=5,7,9$. The main result of the paper is the existence of\nperfect simplices in ${\\mathbb R}^5$.\nKeywords: simplex, cube, homothety, axial diameter, Hadamard matrix",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Polarization, plasmon, and Debye screening in doped 3D ani-Weyl semimetal.   We compute the polarization function in a doped three-dimensional\nanisotropic-Weyl semimetal, in which the fermion energy dispersion is linear in\ntwo components of the momenta and quadratic in the third. Through detailed\ncalculations, we find that the long wavelength plasmon mode depends on the\nfermion density $n_e$ in the form $\\Omega_{p}^{\\bot}\\propto n_{e}^{3/10}$\nwithin the basal plane and behaves as $\\Omega_{p}^{z}\\propto n_{e}^{1/2}$ along\nthe third direction. This unique characteristic of the plasmon mode can be\nprobed by various experimental techniques, such as electron energy-loss\nspectroscopy. The Debye screening at finite chemical potential and finite\ntemperature is also analyzed based on the polarization function.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Dose finding for new vaccines: the role for immunostimulation/immunodynamic modelling.   Current methods to optimize vaccine dose are purely empirically based,\nwhereas in the drug development field, dosing determinations use far more\nadvanced quantitative methodology to accelerate decision-making. Applying these\nestablished methods in the field of vaccine development may reduce the\ncurrently large clinical trial sample sizes, long time frames, high costs, and\nultimately have a better potential to save lives. We propose the field of\nimmunostimulation/immunodynamic (IS/ID) modelling, which aims to translate\nmathematical frameworks used for drug dosing towards optimizing vaccine dose\ndecision-making. Analogous to PK/PD modelling, IS/ID modelling approaches apply\nmathematical models to describe the underlying mechanisms by which the immune\nresponse is stimulated by vaccination (IS) and the resulting measured immune\nresponse dynamics (ID). To move IS/ID modelling forward, existing datasets and\nfurther data on vaccine allometry and dose-dependent dynamics need to be\ngenerated and collate, requiring a collaborative environment with input from\nacademia, industry, regulators, governmental and non-governmental agencies to\nshare modelling expertise, and connect modellers to vaccine data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting how and when hidden neurons skew measured synaptic interactions.   A major obstacle to understanding neural coding and computation is the fact\nthat experimental recordings typically sample only a small fraction of the\nneurons in a circuit. Measured neural properties are skewed by interactions\nbetween recorded neurons and the \"hidden\" portion of the network. To properly\ninterpret neural data and determine how biological structure gives rise to\nneural circuit function, we thus need a better understanding of the\nrelationships between measured effective neural properties and the true\nunderlying physiological properties. Here, we focus on how the effective\nspatiotemporal dynamics of the synaptic interactions between neurons are\nreshaped by coupling to unobserved neurons. We find that the effective\ninteractions from a pre-synaptic neuron $r'$ to a post-synaptic neuron $r$ can\nbe decomposed into a sum of the true interaction from $r'$ to $r$ plus\ncorrections from every directed path from $r'$ to $r$ through unobserved\nneurons. Importantly, the resulting formula reveals when the hidden units\nhave---or do not have---major effects on reshaping the interactions among\nobserved neurons. As a particular example of interest, we derive a formula for\nthe impact of hidden units in random networks with \"strong\"\ncoupling---connection weights that scale with $1/\\sqrt{N}$, where $N$ is the\nnetwork size, precisely the scaling observed in recent experiments. With this\nquantitative relationship between measured and true interactions, we can study\nhow network properties shape effective interactions, which properties are\nrelevant for neural computations, and how to manipulate effective interactions.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Image Registration for the Alignment of Digitized Historical Documents.   In this work, we conducted a survey on different registration algorithms and\ninvestigated their suitability for hyperspectral historical image registration\napplications. After the evaluation of different algorithms, we choose an\nintensity based registration algorithm with a curved transformation model. For\nthe transformation model, we select cubic B-splines since they should be\ncapable to cope with all non-rigid deformations in our hyperspectral images.\nFrom a number of similarity measures, we found that residual complexity and\nlocalized mutual information are well suited for the task at hand. In our\nevaluation, both measures show an acceptable performance in handling all\ndifficulties, e.g., capture range, non-stationary and spatially varying\nintensity distortions or multi-modality that occur in our application.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Control Interpretations for First-Order Optimization Methods.   First-order iterative optimization methods play a fundamental role in large\nscale optimization and machine learning. This paper presents control\ninterpretations for such optimization methods. First, we give loop-shaping\ninterpretations for several existing optimization methods and show that they\nare composed of basic control elements such as PID and lag compensators. Next,\nwe apply the small gain theorem to draw a connection between the convergence\nrate analysis of optimization methods and the input-output gain computations of\ncertain complementary sensitivity functions. These connections suggest that\nstandard classical control synthesis tools may be brought to bear on the design\nof optimization algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian adaptive bandit-based designs using the Gittins index for multi-armed trials with normally distributed endpoints.   Adaptive designs for multi-armed clinical trials have become increasingly\npopular recently in many areas of medical research because of their potential\nto shorten development times and to increase patient response. However,\ndeveloping response-adaptive trial designs that offer patient benefit while\nensuring the resulting trial avoids bias and provides a statistically rigorous\ncomparison of the different treatments included is highly challenging. In this\npaper, the theory of Multi-Armed Bandit Problems is used to define a family of\nnear optimal adaptive designs in the context of a clinical trial with a\nnormally distributed endpoint with known variance. Through simulation studies\nbased on an ongoing trial as a motivation we report the operating\ncharacteristics (type I error, power, bias) and patient benefit of these\napproaches and compare them to traditional and existing alternative designs.\nThese results are then compared to those recently published in the context of\nBernoulli endpoints. Many limitations and advantages are similar in both cases\nbut there are also important differences, specially with respect to type I\nerror control. This paper proposes a simulation-based testing procedure to\ncorrect for the observed type I error inflation that bandit-based and adaptive\nrules can induce. Results presented extend recent work by considering a\nnormally distributed endpoint, a very common case in clinical practice yet\nmostly ignored in the response-adaptive theoretical literature, and illustrate\nthe potential advantages of using these methods in a rare disease context. We\nalso recommend a suitable modified implementation of the bandit-based adaptive\ndesigns for the case of common diseases.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-rendezvous Spacecraft Trajectory Optimization with Beam P-ACO.   The design of spacecraft trajectories for missions visiting multiple\ncelestial bodies is here framed as a multi-objective bilevel optimization\nproblem. A comparative study is performed to assess the performance of\ndifferent Beam Search algorithms at tackling the combinatorial problem of\nfinding the ideal sequence of bodies. Special focus is placed on the\ndevelopment of a new hybridization between Beam Search and the Population-based\nAnt Colony Optimization algorithm. An experimental evaluation shows all\nalgorithms achieving exceptional performance on a hard benchmark problem. It is\nfound that a properly tuned deterministic Beam Search always outperforms the\nremaining variants. Beam P-ACO, however, demonstrates lower parameter\nsensitivity, while offering superior worst-case performance. Being an anytime\nalgorithm, it is then found to be the preferable choice for certain practical\napplications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Parameter Learning and Change Detection Using a Particle Filter With Accelerated Adaptation.   This paper presents the construction of a particle filter, which incorporates\nelements inspired by genetic algorithms, in order to achieve accelerated\nadaptation of the estimated posterior distribution to changes in model\nparameters. Specifically, the filter is designed for the situation where the\nsubsequent data in online sequential filtering does not match the model\nposterior filtered based on data up to a current point in time. The examples\nconsidered encompass parameter regime shifts and stochastic volatility. The\nfilter adapts to regime shifts extremely rapidly and delivers a clear heuristic\nfor distinguishing between regime shifts and stochastic volatility, even though\nthe model dynamics assumed by the filter exhibit neither of those features.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Training Group Orthogonal Neural Networks with Privileged Information.   Learning rich and diverse representations is critical for the performance of\ndeep convolutional neural networks (CNNs). In this paper, we consider how to\nuse privileged information to promote inherent diversity of a single CNN model\nsuch that the model can learn better representations and offer stronger\ngeneralization ability. To this end, we propose a novel group orthogonal\nconvolutional neural network (GoCNN) that learns untangled representations\nwithin each layer by exploiting provided privileged information and enhances\nrepresentation diversity effectively. We take image classification as an\nexample where image segmentation annotations are used as privileged information\nduring the training process. Experiments on two benchmark datasets -- ImageNet\nand PASCAL VOC -- clearly demonstrate the strong generalization ability of our\nproposed GoCNN model. On the ImageNet dataset, GoCNN improves the performance\nof state-of-the-art ResNet-152 model by absolute value of 1.2% while only uses\nprivileged information of 10% of the training images, confirming effectiveness\nof GoCNN on utilizing available privileged knowledge to train better CNNs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Trail-Mediated Self-Interaction.   A number of microorganisms leave persistent trails while moving along\nsurfaces. For single-cell organisms, the trail-mediated self-interaction will\ninfluence its dynamics. It has been discussed recently [Kranz \\textit{et al.}\nPhys. Rev. Lett. \\textbf{117}, 8101 (2016)] that the self-interaction may\nlocalize the organism above a critical coupling $\\chi_c$ to the trail. Here we\nwill derive a generalized active particle model capturing the key features of\nthe self-interaction and analyze its behavior for smaller couplings $\\chi <\n\\chi_c$. We find that fluctuations in propulsion speed shift the localization\ntransition to stronger couplings.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "V2X Meets NOMA: Non-Orthogonal Multiple Access for 5G Enabled Vehicular Networks.   Benefited from the widely deployed infrastructure, the LTE network has\nrecently been considered as a promising candidate to support the\nvehicle-to-everything (V2X) services. However, with a massive number of devices\naccessing the V2X network in the future, the conventional OFDM-based LTE\nnetwork faces the congestion issues due to its low efficiency of orthogonal\naccess, resulting in significant access delay and posing a great challenge\nespecially to safety-critical applications. The non-orthogonal multiple access\n(NOMA) technique has been well recognized as an effective solution for the\nfuture 5G cellular networks to provide broadband communications and massive\nconnectivity. In this article, we investigate the applicability of NOMA in\nsupporting cellular V2X services to achieve low latency and high reliability.\nStarting with a basic V2X unicast system, a novel NOMA-based scheme is proposed\nto tackle the technical hurdles in designing high spectral efficient scheduling\nand resource allocation schemes in the ultra dense topology. We then extend it\nto a more general V2X broadcasting system. Other NOMA-based extended V2X\napplications and some open issues are also discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal rate list decoding over bounded alphabets using algebraic-geometric codes.   We give new constructions of two classes of algebraic code families which are\nefficiently list decodable with small output list size from a fraction\n$1-R-\\epsilon$ of adversarial errors where $R$ is the rate of the code, for any\ndesired positive constant $\\epsilon$. The alphabet size depends only $\\epsilon$\nand is nearly-optimal.\nThe first class of codes are obtained by folding algebraic-geometric codes\nusing automorphisms of the underlying function field. The list decoding\nalgorithm is based on a linear-algebraic approach, which pins down the\ncandidate messages to a subspace with a nice \"periodic\" structure. The list is\npruned by precoding into a special form of \"subspace-evasive\" sets, which are\nconstructed pseudorandomly. Instantiating this construction with the\nGarcia-Stichtenoth function field tower yields codes list-decodable up to a\n$1-R-\\epsilon$ error fraction with list size bounded by $O(1/\\epsilon)$,\nmatching the existential bound up to constant factors. The parameters we\nachieve are thus quite close to the existential bounds in all three aspects:\nerror-correction radius, alphabet size, and list-size.\nThe second class of codes are obtained by restricting evaluation points of an\nalgebraic-geometric code to rational points from a subfield. Once again, the\nlinear-algebraic approach to list decoding to pin down candidate messages to a\nperiodic subspace. We develop an alternate approach based on \"subspace designs\"\nto precode messages. Together with the subsequent explicit constructions of\nsubspace designs, this yields a deterministic construction of an algebraic code\nfamily of rate $R$ with efficient list decoding from $1-R-\\epsilon$ fraction of\nerrors over a constant-sized alphabet. The list size is bounded by a very\nslowly growing function of the block length $N$; in particular, it is at most\n$O(\\log^{(r)} N)$ (the $r$'th iterated logarithm) for any fixed integer $r$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Resilience: A Criterion for Learning in the Presence of Arbitrary Outliers.   We introduce a criterion, resilience, which allows properties of a dataset\n(such as its mean or best low rank approximation) to be robustly computed, even\nin the presence of a large fraction of arbitrary additional data. Resilience is\na weaker condition than most other properties considered so far in the\nliterature, and yet enables robust estimation in a broader variety of settings.\nWe provide new information-theoretic results on robust distribution learning,\nrobust estimation of stochastic block models, and robust mean estimation under\nbounded $k$th moments. We also provide new algorithmic results on robust\ndistribution learning, as well as robust mean estimation in $\\ell_p$-norms.\nAmong our proof techniques is a method for pruning a high-dimensional\ndistribution with bounded $1$st moments to a stable \"core\" with bounded $2$nd\nmoments, which may be of independent interest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Causal Mediation Analysis Leveraging Multiple Types of Summary Statistics Data.   Summary statistics of genome-wide association studies (GWAS) teach causal\nrelationship between millions of genetic markers and tens and thousands of\nphenotypes. However, underlying biological mechanisms are yet to be elucidated.\nWe can achieve necessary interpretation of GWAS in a causal mediation\nframework, looking to establish a sparse set of mediators between genetic and\ndownstream variables, but there are several challenges. Unlike existing methods\nrely on strong and unrealistic assumptions, we tackle practical challenges\nwithin a principled summary-based causal inference framework. We analyzed the\nproposed methods in extensive simulations generated from real-world genetic\ndata. We demonstrated only our approach can accurately redeem causal genes,\neven without knowing actual individual-level data, despite the presence of\ncompeting non-causal trails.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ballistic magnon heat conduction and possible Poiseuille flow in the helimagnetic insulator Cu$_2$OSeO$_3$.   We report on the observation of magnon thermal conductivity $\\kappa_m\\sim$ 70\nW/mK near 5 K in the helimagnetic insulator Cu$_2$OSeO$_3$, exceeding that\nmeasured in any other ferromagnet by almost two orders of magnitude. Ballistic,\nboundary-limited transport for both magnons and phonons is established below 1\nK, and Poiseuille flow of magnons is proposed to explain a magnon mean-free\npath substantially exceeding the specimen width for the least defective\nspecimens in the range 2 K $<T<$ 10 K. These observations establish\nCu$_2$OSeO$_3$ as a model system for studying long-wavelength magnon dynamics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Entanglement spectroscopy on a quantum computer.   We present a quantum algorithm to compute the entanglement spectrum of\narbitrary quantum states. The interesting universal part of the entanglement\nspectrum is typically contained in the largest eigenvalues of the density\nmatrix which can be obtained from the lower Renyi entropies through the\nNewton-Girard method. Obtaining the $p$ largest eigenvalues\n($\\lambda_1>\\lambda_2\\ldots>\\lambda_p$) requires a parallel circuit depth of\n$\\mathcal{O}(p(\\lambda_1/\\lambda_p)^p)$ and $\\mathcal{O}(p\\log(N))$ qubits\nwhere up to $p$ copies of the quantum state defined on a Hilbert space of size\n$N$ are needed as the input. We validate this procedure for the entanglement\nspectrum of the topologically-ordered Laughlin wave function corresponding to\nthe quantum Hall state at filling factor $\\nu=1/3$. Our scaling analysis\nexposes the tradeoffs between time and number of qubits for obtaining the\nentanglement spectrum in the thermodynamic limit using finite-size digital\nquantum computers. We also illustrate the utility of the second Renyi entropy\nin predicting a topological phase transition and in extracting the localization\nlength in a many-body localized system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Image-derived generative modeling of pseudo-macromolecular structures - towards the statistical assessment of Electron CryoTomography template matching.   Cellular Electron CryoTomography (CECT) is a 3D imaging technique that\ncaptures information about the structure and spatial organization of\nmacromolecular complexes within single cells, in near-native state and at\nsub-molecular resolution. Although template matching is often used to locate\nmacromolecules in a CECT image, it is insufficient as it only measures the\nrelative structural similarity. Therefore, it is preferable to assess the\nstatistical credibility of the decision through hypothesis testing, requiring\nmany templates derived from a diverse population of macromolecular structures.\nDue to the very limited number of known structures, we need a generative model\nto efficiently and reliably sample pseudo-structures from the complex\ndistribution of macromolecular structures. To address this challenge, we\npropose a novel image-derived approach for performing hypothesis testing for\ntemplate matching by constructing generative models using the generative\nadversarial network. Finally, we conducted hypothesis testing experiments for\ntemplate matching on both simulated and experimental subtomograms, allowing us\nto conclude the identity of subtomograms with high statistical credibility and\nsignificantly reducing false positives.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Casimir free energy of dielectric films: Classical limit, low-temperature behavior and control.   The Casimir free energy of dielectric films, both free-standing in vacuum and\ndeposited on metallic or dielectric plates, is investigated. It is shown that\nthe values of the free energy depend considerably on whether the calculation\napproach used neglects or takes into account the dc conductivity of film\nmaterial. We demonstrate that there are the material-dependent and universal\nclassical limits in the former and latter cases, respectively. The analytic\nbehavior of the Casimir free energy and entropy for a free-standing dielectric\nfilm at low temperature in found. According to our results, the Casimir entropy\ngoes to zero when the temperature vanishes if the calculation approach with\nneglected dc conductivity of a film is employed. If the dc conductivity is\ntaken into account, the Casimir entropy takes the positive value at zero\ntemperature, depending on the parameters of a film, i.e., the Nernst heat\ntheorem is violated. By considering the Casimir free energy of silica and\nsapphire films deposited on a Au plate in the framework of two calculation\napproaches, we argue that physically correct values are obtained by\ndisregarding the role of dc conductivity. A comparison with the well known\nresults for the configuration of two parallel plates is made. Finally, we\ncompute the Casimir free energy of silica, sapphire and Ge films deposited on\nhigh-resistivity Si plates of different thicknesses and demonstrate that it can\nbe positive, negative and equal to zero. Possible applications of the obtained\nresults to thin films used in microelectronics are discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Scalable Magnetic Field SLAM in 3D Using Gaussian Process Maps.   We present a method for scalable and fully 3D magnetic field simultaneous\nlocalisation and mapping (SLAM) using local anomalies in the magnetic field as\na source of position information. These anomalies are due to the presence of\nferromagnetic material in the structure of buildings and in objects such as\nfurniture. We represent the magnetic field map using a Gaussian process model\nand take well-known physical properties of the magnetic field into account. We\nbuild local maps using three-dimensional hexagonal block tiling. To make our\napproach computationally tractable we use reduced-rank Gaussian process\nregression in combination with a Rao-Blackwellised particle filter. We show\nthat it is possible to obtain accurate position and orientation estimates using\nmeasurements from a smartphone, and that our approach provides a scalable\nmagnetic field SLAM algorithm in terms of both computational complexity and map\nstorage.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On the link between column density distribution and density scaling relation in star formation regions.   We present a method to derive the density scaling relation $\\langle n\\rangle\n\\propto L^{-\\alpha}$ in regions of star formation or in their turbulent\nvicinities from straightforward binning of the column-density distribution\n($N$-pdf). The outcome of the method is studied for three types of $N$-pdf:\npower law ($7/5\\le\\alpha\\le5/3$), lognormal ($0.7\\lesssim\\alpha\\lesssim1.4$)\nand combination of lognormals. In the last case, the method of Stanchev et al.\n(2015) was also applied for comparison and a very weak (or close to zero)\ncorrelation was found. We conclude that the considered `binning approach'\nreflects rather the local morphology of the $N$-pdf with no reference to the\nphysical conditions in a considered region. The rough consistency of the\nderived slopes with the widely adopted Larson's (1981) value $\\alpha\\sim1.1$ is\nsuggested to support claims that the density-size relation in molecular clouds\nis indeed an artifact of the observed $N$-pdf.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Infinite ergodic index of the ehrenfest wind-tree model.   The set of all possible configurations of the Ehrenfest wind-tree model\nendowed with the Hausdorff topology is a compact metric space. For a typical\nconfiguration we show that the wind-tree dynamics has infinite ergodic index in\nalmost every direction. In particular some ergodic theorems can be applied to\nshow that if we start with a large number of initially parallel particles their\ndirections decorrelate as the dynamics evolve answering the question posed by\nthe Ehrenfests.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Low-dose cryo electron ptychography via non-convex Bayesian optimization.   Electron ptychography has seen a recent surge of interest for phase sensitive\nimaging at atomic or near-atomic resolution. However, applications are so far\nmainly limited to radiation-hard samples because the required doses are too\nhigh for imaging biological samples at high resolution. We propose the use of\nnon-convex, Bayesian optimization to overcome this problem and reduce the dose\nrequired for successful reconstruction by two orders of magnitude compared to\nprevious experiments. We suggest to use this method for imaging single\nbiological macromolecules at cryogenic temperatures and demonstrate 2D\nsingle-particle reconstructions from simulated data with a resolution of 7.9\n\\AA$\\,$ at a dose of 20 $e^- / \\AA^2$. When averaging over only 15 low-dose\ndatasets, a resolution of 4 \\AA$\\,$ is possible for large macromolecular\ncomplexes. With its independence from microscope transfer function, direct\nrecovery of phase contrast and better scaling of signal-to-noise ratio,\ncryo-electron ptychography may become a promising alternative to Zernike\nphase-contrast microscopy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the structure of join tensors with applications to tensor eigenvalue problems.   We investigate the structure of join tensors, which may be regarded as the\nmultivariable extension of lattice-theoretic join matrices. Explicit formulae\nfor a polyadic decomposition (i.e., a linear combination of rank-1 tensors) and\na tensor-train decomposition of join tensors are derived on general join\nsemilattices. We discuss conditions under which the obtained decompositions are\noptimal in rank, and examine numerically the storage complexity of the obtained\ndecompositions for a class of LCM tensors as a special case of join tensors. In\naddition, we investigate numerically the sharpness of a theoretical upper bound\non the tensor eigenvalues of LCM tensors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Comparison of Spatial-based Targeted Disease Containment Strategies using Mobile Phone Data.   Epidemic outbreaks are an important healthcare challenge, especially in\ndeveloping countries where they represent one of the major causes of mortality.\nApproaches that can rapidly target subpopulations for surveillance and control\nare critical for enhancing containment processes during epidemics.\nUsing a real-world dataset from Ivory Coast, this work presents an attempt to\nunveil the socio-geographical heterogeneity of disease transmission dynamics.\nBy employing a spatially explicit meta-population epidemic model derived from\nmobile phone Call Detail Records (CDRs), we investigate how the differences in\nmobility patterns may affect the course of a realistic infectious disease\noutbreak. We consider different existing measures of the spatial dimension of\nhuman mobility and interactions, and we analyse their relevance in identifying\nthe highest risk sub-population of individuals, as the best candidates for\nisolation countermeasures. The approaches presented in this paper provide\nfurther evidence that mobile phone data can be effectively exploited to\nfacilitate our understanding of individuals' spatial behaviour and its\nrelationship with the risk of infectious diseases' contagion. In particular, we\nshow that CDRs-based indicators of individuals' spatial activities and\ninteractions hold promise for gaining insight of contagion heterogeneity and\nthus for developing containment strategies to support decision-making during\ncountry-level pandemics.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Bit Complexity of Computing Solutions for Symmetric Hyperbolic Systems of PDEs with Guaranteed Precision.   We establish upper bounds of bit complexity of computing solution operators\nfor symmetric hyperbolic systems of PDEs. Here we continue the research started\nin in our revious publications where computability, in the rigorous sense of\ncomputable analysis, has been established for solution operators of Cauchy and\ndissipative boundary-value problems for such systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Noise2Noise: Learning Image Restoration without Clean Data.   We apply basic statistical reasoning to signal reconstruction by machine\nlearning -- learning to map corrupted observations to clean signals -- with a\nsimple and powerful conclusion: it is possible to learn to restore images by\nonly looking at corrupted examples, at performance at and sometimes exceeding\ntraining using clean data, without explicit image priors or likelihood models\nof the corruption. In practice, we show that a single model learns photographic\nnoise removal, denoising synthetic Monte Carlo images, and reconstruction of\nundersampled MRI scans -- all corrupted by different processes -- based on\nnoisy data only.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network (RED-CNN).   Given the potential X-ray radiation risk to the patient, low-dose CT has\nattracted a considerable interest in the medical imaging field. The current\nmain stream low-dose CT methods include vendor-specific sinogram domain\nfiltration and iterative reconstruction, but they need to access original raw\ndata whose formats are not transparent to most users. Due to the difficulty of\nmodeling the statistical characteristics in the image domain, the existing\nmethods for directly processing reconstructed images cannot eliminate image\nnoise very well while keeping structural details. Inspired by the idea of deep\nlearning, here we combine the autoencoder, the deconvolution network, and\nshortcut connections into the residual encoder-decoder convolutional neural\nnetwork (RED-CNN) for low-dose CT imaging. After patch-based training, the\nproposed RED-CNN achieves a competitive performance relative to\nthe-state-of-art methods in both simulated and clinical cases. Especially, our\nmethod has been favorably evaluated in terms of noise suppression, structural\npreservation and lesion detection.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Accelerating Innovation Through Analogy Mining.   The availability of large idea repositories (e.g., the U.S. patent database)\ncould significantly accelerate innovation and discovery by providing people\nwith inspiration from solutions to analogous problems. However, finding useful\nanalogies in these large, messy, real-world repositories remains a persistent\nchallenge for either human or automated methods. Previous approaches include\ncostly hand-created databases that have high relational structure (e.g.,\npredicate calculus representations) but are very sparse. Simpler\nmachine-learning/information-retrieval similarity metrics can scale to large,\nnatural-language datasets, but struggle to account for structural similarity,\nwhich is central to analogy. In this paper we explore the viability and value\nof learning simpler structural representations, specifically, \"problem\nschemas\", which specify the purpose of a product and the mechanisms by which it\nachieves that purpose. Our approach combines crowdsourcing and recurrent neural\nnetworks to extract purpose and mechanism vector representations from product\ndescriptions. We demonstrate that these learned vectors allow us to find\nanalogies with higher precision and recall than traditional\ninformation-retrieval methods. In an ideation experiment, analogies retrieved\nby our models significantly increased people's likelihood of generating\ncreative ideas compared to analogies retrieved by traditional methods. Our\nresults suggest a promising approach to enabling computational analogy at scale\nis to learn and leverage weaker structural representations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Right for the Right Reasons: Training Differentiable Models by Constraining their Explanations.   Neural networks are among the most accurate supervised learning methods in\nuse today, but their opacity makes them difficult to trust in critical\napplications, especially when conditions in training differ from those in test.\nRecent work on explanations for black-box models has produced tools (e.g. LIME)\nto show the implicit rules behind predictions, which can help us identify when\nmodels are right for the wrong reasons. However, these methods do not scale to\nexplaining entire datasets and cannot correct the problems they reveal. We\nintroduce a method for efficiently explaining and regularizing differentiable\nmodels by examining and selectively penalizing their input gradients, which\nprovide a normal to the decision boundary. We apply these penalties both based\non expert annotation and in an unsupervised fashion that encourages diverse\nmodels with qualitatively different decision boundaries for the same\nclassification problem. On multiple datasets, we show our approach generates\nfaithful explanations and models that generalize much better when conditions\ndiffer between training and test.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The hypotensive effect of activated apelin receptor is correlated with \\b{eta}-arrestin recruitment.   The apelinergic system is an important player in the regulation of both\nvascular tone and cardiovascular function, making this physiological system an\nattractive target for drug development for hypertension, heart failure and\nischemic heart disease. Indeed, apelin exerts a positive inotropic effect in\nhumans whilst reducing peripheral vascular resistance. In this study, we\ninvestigated the signaling pathways through which apelin exerts its hypotensive\naction. We synthesized a series of apelin-13 analogs whereby the C-terminal\nPhe13 residue was replaced by natural or unnatural amino acids. In HEK293 cells\nexpressing APJ, we evaluated the relative efficacy of these compounds to\nactivate G{\\alpha}i1 and G{\\alpha}oA G-proteins, recruit \\b{eta}-arrestins 1\nand 2 (\\b{eta}arrs), and inhibit cAMP production. Calculating the transduction\nratio for each pathway allowed us to identify several analogs with distinct\nsignaling profiles. Furthermore, we found that these analogs delivered i.v. to\nSprague-Dawley rats exerted a wide range of hypotensive responses. Indeed, two\ncompounds lost their ability to lower blood pressure, while other analogs\nsignificantly reduced blood pressure as apelin-13. Interestingly, analogs that\ndid not lower blood pressure were less effective at recruiting \\b{eta}arrs.\nFinally, using Spearman correlations, we established that the hypotensive\nresponse was significantly correlated with \\b{eta}arr recruitment but not with\nG protein- dependent signaling. In conclusion, our results demonstrated that\nthe \\b{eta}arr recruitment potency is involved in the hypotensive efficacy of\nactivated APJ.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "CN rings in full protoplanetary disks around young stars as probes of disk structure.   Bright ring-like structure emission of the CN molecule has been observed in\nprotoplanetary disks. We investigate whether such structures are due to the\nmorphology of the disk itself or if they are instead an intrinsic feature of CN\nemission. With the intention of using CN as a diagnostic, we also address to\nwhich physical and chemical parameters CN is most sensitive. A set of disk\nmodels were run for different stellar spectra, masses, and physical structures\nvia the 2D thermochemical code DALI. An updated chemical network that accounts\nfor the most relevant CN reactions was adopted. Ring-shaped emission is found\nto be a common feature of all adopted models; the highest abundance is found in\nthe upper outer regions of the disk, and the column density peaks at 30-100 AU\nfor T Tauri stars with standard accretion rates. Higher mass disks generally\nshow brighter CN. Higher UV fields, such as those appropriate for T Tauri stars\nwith high accretion rates or for Herbig Ae stars or for higher disk flaring,\ngenerally result in brighter and larger rings. These trends are due to the main\nformation paths of CN, which all start with vibrationally excited H2*\nmolecules, that are produced through far ultraviolet (FUV) pumping of H2. The\nmodel results compare well with observed disk-integrated CN fluxes and the\nobserved location of the CN ring for the TW Hya disk. CN rings are produced\nnaturally in protoplanetary disks and do not require a specific underlying disk\nstructure such as a dust cavity or gap. The strong link between FUV flux and CN\nemission can provide critical information regarding the vertical structure of\nthe disk and the distribution of dust grains which affects the UV penetration,\nand could help to break some degeneracies in the SED fitting. In contrast with\nC2H or c-C3H2, the CN flux is not very sensitive to carbon and oxygen\ndepletion.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Universality in numerical computation with random data. Case studies, analytic results and some speculations.   We discuss various universality aspects of numerical computations using\nstandard algorithms. These aspects include empirical observations and rigorous\nresults. We also make various speculations about computation in a broader\nsense.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Modelling thermo-electro-mechanical effects in orthotropic cardiac tissue.   In this paper we introduce a new mathematical model for the active\ncontraction of cardiac muscle, featuring different thermo-electric and\nnonlinear conductivity properties. The passive hyperelastic response of the\ntissue is described by an orthotropic exponential model, whereas the ionic\nactivity dictates active contraction incorporated through the concept of\northotropic active strain. We use a fully incompressible formulation, and the\ngenerated strain modifies directly the conductivity mechanisms in the medium\nthrough the pull-back transformation. We also investigate the influence of\nthermo-electric effects in the onset of multiphysics emergent spatiotemporal\ndynamics, using nonlinear diffusion. It turns out that these ingredients have a\nkey role in reproducing pathological chaotic dynamics such as ventricular\nfibrillation during inflammatory events, for instance. The specific structure\nof the governing equations suggests to cast the problem in mixed-primal form\nand we write it in terms of Kirchhoff stress, displacements, solid pressure,\nelectric potential, activation generation, and ionic variables. We also propose\na new mixed-primal finite element method for its numerical approximation, and\nwe use it to explore the properties of the model and to assess the importance\nof coupling terms, by means of a few computational experiments in 3D.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Fast learning rate of deep learning via a kernel perspective.   We develop a new theoretical framework to analyze the generalization error of\ndeep learning, and derive a new fast learning rate for two representative\nalgorithms: empirical risk minimization and Bayesian deep learning. The series\nof theoretical analyses of deep learning has revealed its high expressive power\nand universal approximation capability. Although these analyses are highly\nnonparametric, existing generalization error analyses have been developed\nmainly in a fixed dimensional parametric model. To compensate this gap, we\ndevelop an infinite dimensional model that is based on an integral form as\nperformed in the analysis of the universal approximation capability. This\nallows us to define a reproducing kernel Hilbert space corresponding to each\nlayer. Our point of view is to deal with the ordinary finite dimensional deep\nneural network as a finite approximation of the infinite dimensional one. The\napproximation error is evaluated by the degree of freedom of the reproducing\nkernel Hilbert space in each layer. To estimate a good finite dimensional\nmodel, we consider both of empirical risk minimization and Bayesian deep\nlearning. We derive its generalization error bound and it is shown that there\nappears bias-variance trade-off in terms of the number of parameters of the\nfinite dimensional approximation. We show that the optimal width of the\ninternal layers can be determined through the degree of freedom and the\nconvergence rate can be faster than $O(1/\\sqrt{n})$ rate which has been shown\nin the existing studies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improving SIEM capabilities through an enhanced probe for encrypted Skype traffic detection.   Nowadays, the Security Information and Event Management (SIEM) systems take\non great relevance in handling security issues for critical infrastructures as\nInternet Service Providers. Basically, a SIEM has two main functions: i) the\ncollection and the aggregation of log data and security information from\ndisparate network devices (routers, firewalls, intrusion detection systems, ad\nhoc probes and others) and ii) the analysis of the gathered data by\nimplementing a set of correlation rules aimed at detecting potential suspicious\nevents as the presence of encrypted real-time traffic. In the present work, the\nauthors propose an enhanced implementation of a SIEM where a particular focus\nis given to the detection of encrypted Skype traffic by using an ad-hoc\ndeveloped enhanced probe (ESkyPRO) conveniently governed by the SIEM itself.\nSuch enhanced probe, able to interact with an agent counterpart deployed into\nthe SIEM platform, is designed by exploiting some machine learning concepts.\nThe main purpose of the proposed ad-hoc SIEM is to correlate the information\nreceived by ESkyPRO and other types of data obtained by an Intrusion Detection\nSystem (IDS) probe in order to make the encrypted Skype traffic detection as\naccurate as possible.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gate-Variants of Gated Recurrent Unit (GRU) Neural Networks.   The paper evaluates three variants of the Gated Recurrent Unit (GRU) in\nrecurrent neural networks (RNN) by reducing parameters in the update and reset\ngates. We evaluate the three variant GRU models on MNIST and IMDB datasets and\nshow that these GRU-RNN variant models perform as well as the original GRU RNN\nmodel while reducing the computational expense.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adversarial Variational Inference and Learning in Markov Random Fields.   Markov random fields (MRFs) find applications in a variety of machine\nlearning areas, while the inference and learning of such models are challenging\nin general. In this paper, we propose the Adversarial Variational Inference and\nLearning (AVIL) algorithm to solve the problems with a minimal assumption about\nthe model structure of an MRF. AVIL employs two variational distributions to\napproximately infer the latent variables and estimate the partition function,\nrespectively. The variational distributions, which are parameterized as neural\nnetworks, provide an estimate of the negative log likelihood of the MRF. On one\nhand, the estimate is in an intuitive form of approximate contrastive free\nenergy. On the other hand, the estimate is a minimax optimization problem,\nwhich is solved by stochastic gradient descent in an alternating manner. We\napply AVIL to various undirected generative models in a fully black-box manner\nand obtain better results than existing competitors on several real datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Infinitesimal perturbation analysis for risk measures based on the Smith max-stable random field.   When using risk or dependence measures based on a given underlying model, it\nis essential to be able to quantify the sensitivity or robustness of these\nmeasures with respect to the model parameters. In this paper, we consider an\nunderlying model which is very popular in spatial extremes, the Smith\nmax-stable random field. We study the sensitivity properties of risk or\ndependence measures based on the values of this field at a finite number of\nlocations. Max-stable fields play a key role, e.g., in the modelling of natural\ndisasters. As their multivariate density is generally not available for more\nthan three locations, the Likelihood Ratio Method cannot be used to estimate\nthe derivatives of the risk measures with respect to the model parameters.\nThus, we focus on a pathwise method, the Infinitesimal Perturbation Analysis\n(IPA). We provide a convenient and tractable sufficient condition for\nperforming IPA, which is intricate to obtain because of the very structure of\nmax-stable fields involving pointwise maxima over an infinite number of random\nfunctions. IPA enables the consistent estimation of the considered measures'\nderivatives with respect to the parameters characterizing the spatial\ndependence. We carry out a simulation study which shows that the approach\nperforms well in various configurations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Protonation induced high-Tc phases in iron-based superconductors evidenced by NMR and magnetization measurements.   Chemical substitution during growth is a well-established method to\nmanipulate electronic states of quantum materials, and leads to rich spectra of\nphase diagrams in cuprate and iron-based superconductors. Here we report a\nnovel and generic strategy to achieve nonvolatile electron doping in series of\n(i.e. 11 and 122 structures) Fe-based superconductors by ionic liquid gating\ninduced protonation at room temperature. Accumulation of protons in bulk\ncompounds induces superconductivity in the parent compounds, and enhances the\nTc largely in some superconducting ones. Furthermore, the existence of proton\nin the lattice enables the first proton nuclear magnetic resonance (NMR) study\nto probe directly superconductivity. Using FeS as a model system, our NMR study\nreveals an emergent high-Tc phase with no coherence peak which is hard to\nmeasure by NMR with other isotopes. This novel electric-field-induced proton\nevolution opens up an avenue for manipulation of competing electronic states\n(e.g. Mott insulators), and may provide an innovative way for a broad\nperspective of NMR measurements with greatly enhanced detecting resolution.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Report: Dynamic Eye Movement Matching and Visualization Tool in Neuro Gesture.   In the research of the impact of gestures using by a lecturer, one\nchallenging task is to infer the attention of a group of audiences. Two\nimportant measurements that can help infer the level of attention are eye\nmovement data and Electroencephalography (EEG) data. Under the fundamental\nassumption that a group of people would look at the same place if they all pay\nattention at the same time, we apply a method, \"Time Warp Edit Distance\", to\ncalculate the similarity of their eye movement trajectories. Moreover, we also\ncluster eye movement pattern of audiences based on these pair-wised similarity\nmetrics. Besides, since we don't have a direct metric for the \"attention\"\nground truth, a visual assessment would be beneficial to evaluate the\ngesture-attention relationship. Thus we also implement a visualization tool.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fuzzy logic based approaches for gene regulatory network inference.   The rapid advancement in high-throughput techniques has fueled the generation\nof large volume of biological data rapidly with low cost. Some of these\ntechniques are microarray and next generation sequencing which provides genome\nlevel insight of living cells. As a result, the size of most of the biological\ndatabases, such as NCBI-GEO, NCBI-SRA, is exponentially growing. These\nbiological data are analyzed using computational techniques for knowledge\ndiscovery - which is one of the objectives of bioinformatics research. Gene\nregulatory network (GRN) is a gene-gene interaction network which plays pivotal\nrole in understanding gene regulation process and disease studies. From the\nlast couple of decades, the researchers are interested in developing\ncomputational algorithms for GRN inference (GRNI) using high-throughput\nexperimental data. Several computational approaches have been applied for\ninferring GRN from gene expression data including statistical techniques\n(correlation coefficient), information theory (mutual information), regression\nbased approaches, probabilistic approaches (Bayesian networks, naive byes),\nartificial neural networks, and fuzzy logic. The fuzzy logic, along with its\nhybridization with other intelligent approach, is well studied in GRNI due to\nits several advantages. In this paper, we present a consolidated review on\nfuzzy logic and its hybrid approaches for GRNI developed during last two\ndecades.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Prediction-Constrained Topic Models for Antidepressant Recommendation.   Supervisory signals can help topic models discover low-dimensional data\nrepresentations that are more interpretable for clinical tasks. We propose a\nframework for training supervised latent Dirichlet allocation that balances two\ngoals: faithful generative explanations of high-dimensional data and accurate\nprediction of associated class labels. Existing approaches fail to balance\nthese goals by not properly handling a fundamental asymmetry: the intended task\nis always predicting labels from data, not data from labels. Our new\nprediction-constrained objective trains models that predict labels from heldout\ndata well while also producing good generative likelihoods and interpretable\ntopic-word parameters. In a case study on predicting depression medications\nfrom electronic health records, we demonstrate improved recommendations\ncompared to previous supervised topic models and high- dimensional logistic\nregression from words alone.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the geometry of the moduli space of sheaves supported on curves of genus two in a quadric surface.   We study the moduli space of stable sheaves of Euler characteristic 2,\nsupported on curves of arithmetic genus 2 contained in a smooth quadric\nsurface. We show that this moduli space is rational. We compute its Betti\nnumbers and we give a classification of the stable sheaves involving locally\nfree resolutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emergence of Topological Nodal Lines and Type II Weyl Nodes in Strong Spin--Orbit Coupling System InNbX2(X=S,Se).   Using first--principles density functional calculations, we systematically\ninvestigate electronic structures and topological properties of InNbX2 (X=S,\nSe). In the absence of spin--orbit coupling (SOC), both compounds show nodal\nlines protected by mirror symmetry. Including SOC, the Dirac rings in InNbS2\nsplit into two Weyl rings. This unique property is distinguished from other\ndicovered nodal line materials which normally requires the absence of SOC. On\nthe other hand, SOC breaks the nodal lines in InNbSe2 and the compound becomes\na type II Weyl semimetal with 12 Weyl points in the Brillouin Zone. Using a\nsupercell slab calculation we study the dispersion of Fermi arcs surface states\nin InNbSe2, we also utilize a coherent potential approximation to probe their\ntolernace to the surface disorder effects. The quasi two--dimensionality and\nthe absence of toxic elements makes these two compounds an ideal experimental\nplatform for investigating novel properties of topological semimetals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "YUI and HANA: Control and Visualization Programs for HRC in J-PARC.   We developed control and visualization programs, YUI and HANA, for High-\nResolution Chopper spectrometer (HRC) installed at BL12 in MLF, J-PARC. YUI is\na comprehensive program to control DAQ-middleware, the accessories, and sample\nenvironment devices. HANA is a program for the data transformation and\nvisualization of inelastic neutron scattering spectra. In this paper, we\ndescribe the basic system structures and unique functions of these programs\nfrom the viewpoint of users.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Novel Model of Cancer-Induced Peripheral Neuropathy and the Role of TRPA1 in Pain Transduction.   Background. Models of cancer-induced neuropathy are designed by injecting\ncancer cells near the peripheral nerves. The interference of tissue-resident\nimmune cells does not allow a direct contact with nerve fibres which affects\nthe tumor microenvironment and the invasion process. Methods. Anaplastic\ntumor-1 (AT-1) cells were inoculated within the sciatic nerves (SNs) of male\nCopenhagen rats. Lumbar dorsal root ganglia (DRGs) and the SNs were collected\non days 3, 7, 14, and 21. SN tissues were examined for morphological changes\nand DRG tissues for immunofluorescence, electrophoretic tendency, and mRNA\nquantification. Hypersensitivities to cold, mechanical, and thermal stimuli\nwere determined. HC-030031, a selective TRPA1 antagonist, was used to treat\ncold allodynia. Results. Nociception thresholds were identified on day 6.\nImmunofluorescent micrographs showed overexpression of TRPA1 on days 7 and 14\nand of CGRP on day 14 until day 21. Both TRPA1 and CGRP were coexpressed on the\nsame cells. Immunoblots exhibited an increase in TRPA1 expression on day 14.\nTRPA1 mRNA underwent an increase on day 7 (normalized to 18S). Injection of\nHC-030031 transiently reversed the cold allodynia. Conclusion. A novel and a\npromising model of cancer-induced neuropathy was established, and the role of\nTRPA1 and CGRP in pain transduction was examined.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "An evaluation of cosmological models from expansion and growth of structure measurements.   We compare a large suite of theoretical cosmological models to observational\ndata from the cosmic microwave background, baryon acoustic oscillation\nmeasurements of expansion, Type Ia SNe measurements of expansion, redshift\nspace distortion measurements of the growth of structure, and the local Hubble\nconstant. Our theoretical models include parametrizations of dark energy as\nwell as physical models of dark energy and modified gravity. We determine the\nconstraints on the model parameters, incorporating the redshift space\ndistortion data directly in the analysis. To determine whether models can be\nruled out, we evaluate the $p$ value (the probability under the model of\nobtaining data as bad or worse than the observed data). In our comparison, we\nfind the well known tension of H$_0$ with the other data; no model resolves\nthis tension successfully. Among the models we consider, the large scale growth\nof structure data does not affect the modified gravity models as a category\nparticularly differently than dark energy models; it matters for some modified\ngravity models but not others, and the same is true for dark energy models. We\ncompute predicted observables for each model under current observational\nconstraints, and identify models for which future observational constraints\nwill be particularly informative.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Persistent Currents in Ferromagnetic Condensates.   Persistent currents in Bose condensates with a scalar order parameter are\nstabilized by the topology of the order parameter manifold. In condensates with\nmulticomponent order parameters it is topologically possible for supercurrents\nto `unwind' without leaving the manifold. We study the energetics of this\nprocess in the case of ferromagnetic condensates using a long wavelength energy\nfunctional that includes both the superfluid and spin stiffnesses. Exploiting\nanalogies to an elastic rod and rigid body motion, we show that the current\ncarrying state in a 1D ring geometry transitions between a spin helix in the\nenergy minima and a soliton-like configuration at the maxima. The relevance to\nrecent experiments in ultracold atoms is briefly discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Leveraging the Path Signature for Skeleton-based Human Action Recognition.   Human action recognition in videos is one of the most challenging tasks in\ncomputer vision. One important issue is how to design discriminative features\nfor representing spatial context and temporal dynamics. Here, we introduce a\npath signature feature to encode information from intra-frame and inter-frame\ncontexts. A key step towards leveraging this feature is to construct the proper\ntrajectories (paths) for the data steam. In each frame, the correlated\nconstraints of human joints are treated as small paths, then the spatial path\nsignature features are extracted from them. In video data, the evolution of\nthese spatial features over time can also be regarded as paths from which the\ntemporal path signature features are extracted. Eventually, all these features\nare concatenated to constitute the input vector of a fully connected neural\nnetwork for action classification. Experimental results on four standard\nbenchmark action datasets, J-HMDB, SBU Dataset, Berkeley MHAD, and NTURGB+D\ndemonstrate that the proposed approach achieves state-of-the-art accuracy even\nin comparison with recent deep learning based models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Query Complexity of Cake Cutting.   We study the query complexity of cake cutting and give lower and upper bounds\nfor computing approximately envy-free, perfect, and equitable allocations with\nthe minimum number of cuts. The lower bounds are tight for computing connected\nenvy-free allocations among n=3 players and for computing perfect and equitable\nallocations with minimum number of cuts between n=2 players.\nWe also formalize moving knife procedures and show that a large subclass of\nthis family, which captures all the known moving knife procedures, can be\nsimulated efficiently with arbitrarily small error in the Robertson-Webb query\nmodel.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Supercongruences related to ${}_3F_2(1)$ involving harmonic numbers.   We show various supercongruences for truncated series which involve central\nbinomial coefficients and harmonic numbers. The corresponding infinite series\nare also evaluated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Zero-Delay Source-Channel Coding with a One-Bit ADC Front End and Correlated Side Information at the Receiver.   Zero-delay transmission of a Gaussian source over an additive white Gaussian\nnoise (AWGN) channel is considered with a one-bit analog-to-digital converter\n(ADC) front end and a correlated side information at the receiver. The design\nof the optimal encoder and decoder is studied for two performance criteria,\nnamely, the mean squared error (MSE) distortion and the distortion outage\nprobability (DOP), under an average power constraint on the channel input. For\nboth criteria, necessary optimality conditions for the encoder and the decoder\nare derived. Using these conditions, it is observed that the numerically\noptimized encoder (NOE) under the MSE distortion criterion is periodic, and its\nperiod increases with the correlation between the source and the receiver side\ninformation. For the DOP, it is instead seen that the NOE mappings periodically\nacquire positive and negative values, which decay to zero with increasing\nsource magnitude, and the interval over which the mapping takes non-zero\nvalues, becomes wider with the correlation between the source and the side\ninformation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Shared urbanism: Big data on accommodation sharing in urban Australia.   As affordability pressures and tight rental markets in global cities mount,\nonline shared accommodation sites proliferate. Home sharing arrangements\npresent dilemmas for planning that aims to improve health and safety standards,\nwhile supporting positives such as the usage of dormant stock and the relieving\nof rental pressures on middle/lower income earners. Currently, no formal data\nexists on this internationally growing trend. Here, we present a first\nquantitative glance on shared accommodation practices across all major urban\ncenters of Australia enabled via collection and analysis of thousands of online\nlistings. We examine, countrywide, the spatial and short time scale temporal\ncharacteristics of this market, along with preliminary analysis on rents,\ndwelling types and other characteristics. Findings have implications for\nhousing policy makers and planning practitioners seeking to monitor and respond\nto housing policy and affordability pressures in formal and informal housing\nmarkets.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Bio-Inspired Multi-Layer Spiking Neural Network Extracts Discriminative Features from Speech Signals.   Spiking neural networks (SNNs) enable power-efficient implementations due to\ntheir sparse, spike-based coding scheme. This paper develops a bio-inspired SNN\nthat uses unsupervised learning to extract discriminative features from speech\nsignals, which can subsequently be used in a classifier. The architecture\nconsists of a spiking convolutional/pooling layer followed by a fully connected\nspiking layer for feature discovery. The convolutional layer of leaky,\nintegrate-and-fire (LIF) neurons represents primary acoustic features. The\nfully connected layer is equipped with a probabilistic spike-timing-dependent\nplasticity learning rule. This layer represents the discriminative features\nthrough probabilistic, LIF neurons. To assess the discriminative power of the\nlearned features, they are used in a hidden Markov model (HMM) for spoken digit\nrecognition. The experimental results show performance above 96% that compares\nfavorably with popular statistical feature extraction methods. Our results\nprovide a novel demonstration of unsupervised feature acquisition in an SNN.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accurate Multi-physics Numerical Analysis of Particle Preconcentration Based on Ion Concentration Polarization.   This paper studies mechanism of preconcentration of charged particles in a\nstraight micro-channel embedded with permselective membranes, by numerically\nsolving coupled transport equations of ions, charged particles and solvent\nfluid without any simplifying assumptions. It is demonstrated that trapping and\npreconcentration of charged particles are determined by the interplay between\ndrag force from the electroosmotic fluid flow and the electrophoretic force\napplied trough the electric field. Several insightful characteristics are\nrevealed, including the diverse dynamics of co-ions and counter ions,\nreplacement of co-ions by focused particles, lowered ion concentrations in\nparticle enriched zone, and enhanced electroosmotic pumping effect etc.\nConditions for particles that may be concentrated are identified in terms of\ncharges, sizes and electrophoretic mobilities of particles and co-ions.\nDependences of enrichment factor on cross-membrane voltage, initial particle\nconcentration and buffer ion concentrations are analyzed and the underlying\nreasons are elaborated. Finally, post priori a condition for validity of\ndecoupled simulation model is given based on charges carried by focused charge\nparticles and that by buffer co-ions. These results provide important guidance\nin the design and optimization of nanofluidic preconcentration and other\nrelated devices.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A fast numerical method for ideal fluid flow in domains with multiple stirrers.   A collection of arbitrarily-shaped solid objects, each moving at a constant\nspeed, can be used to mix or stir ideal fluid, and can give rise to interesting\nflow patterns. Assuming these systems of fluid stirrers are two-dimensional,\nthe mathematical problem of resolving the flow field - given a particular\ndistribution of any finite number of stirrers of specified shape and speed -\ncan be formulated as a Riemann-Hilbert problem. We show that this\nRiemann-Hilbert problem can be solved numerically using a fast and accurate\nalgorithm for any finite number of stirrers based around a boundary integral\nequation with the generalized Neumann kernel. Various systems of fluid stirrers\nare considered, and our numerical scheme is shown to handle highly multiply\nconnected domains (i.e. systems of many fluid stirrers) with minimal\ncomputational expense.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Distance-based Protein Folding Powered by Deep Learning.   Contact-assisted protein folding has made very good progress, but two\nchallenges remain. One is accurate contact prediction for proteins lack of many\nsequence homologs and the other is that time-consuming folding simulation is\noften needed to predict good 3D models from predicted contacts. We show that\nprotein distance matrix can be predicted well by deep learning and then\ndirectly used to construct 3D models without folding simulation at all. Using\ndistance geometry to construct 3D models from our predicted distance matrices,\nwe successfully folded 21 of the 37 CASP12 hard targets with a median family\nsize of 58 effective sequence homologs within 4 hours on a Linux computer of 20\nCPUs. In contrast, contacts predicted by direct coupling analysis (DCA) cannot\nfold any of them in the absence of folding simulation and the best CASP12 group\nfolded 11 of them by integrating predicted contacts into complex,\nfragment-based folding simulation. The rigorous experimental validation on 15\nCASP13 targets show that among the 3 hardest targets of new fold our\ndistance-based folding servers successfully folded 2 large ones with <150\nsequence homologs while the other servers failed on all three, and that our ab\ninitio folding server also predicted the best, high-quality 3D model for a\nlarge homology modeling target. Further experimental validation in CAMEO shows\nthat our ab initio folding server predicted correct fold for a membrane protein\nof new fold with 200 residues and 229 sequence homologs while all the other\nservers failed. These results imply that deep learning offers an efficient and\naccurate solution for ab initio folding on a personal computer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Playing a true Parrondo's game with a three state coin on a quantum walk.   Playing a Parrondo's game with a qutrit is the subject of this paper. We show\nthat a true quantum Parrondo's game can be played with a 3 state coin(qutrit)\nin a 1D quantum walk in contrast to the fact that playing a true Parrondo's\ngame with a 2 state coin(qubit) in 1D quantum walk fails in the asymptotic\nlimits.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards Audio to Scene Image Synthesis using Generative Adversarial Network.   Humans can imagine a scene from a sound. We want machines to do so by using\nconditional generative adversarial networks (GANs). By applying the techniques\nincluding spectral norm, projection discriminator and auxiliary classifier,\ncompared with naive conditional GAN, the model can generate images with better\nquality in terms of both subjective and objective evaluations. Almost\nthree-fourth of people agree that our model have the ability to generate images\nrelated to sounds. By inputting different volumes of the same sound, our model\noutput different scales of changes based on the volumes, showing that our model\ntruly knows the relationship between sounds and images to some extent.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast, Better Training Trick -- Random Gradient.   In this paper, we will show an unprecedented method to accelerate training\nand improve performance, which called random gradient (RG). This method can be\neasier to the training of any model without extra calculation cost, we use\nImage classification, Semantic segmentation, and GANs to confirm this method\ncan improve speed which is training model in computer vision. The central idea\nis using the loss multiplied by a random number to random reduce the\nback-propagation gradient. We can use this method to produce a better result in\nPascal VOC, Cifar, Cityscapes datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Logics for Word Transductions with Synthesis.   We introduce a logic, called LT, to express properties of transductions, i.e.\nbinary relations from input to output (finite) words. In LT, the input/output\ndependencies are modelled via an origin function which associates to any\nposition of the output word, the input position from which it originates. LT is\nwell-suited to express relations (which are not necessarily functional), and\ncan express all regular functional transductions, i.e. transductions definable\nfor instance by deterministic two-way transducers. Despite its high expressive\npower, LT has decidable satisfiability and equivalence problems, with tight\nnon-elementary and elementary complexities, depending on specific\nrepresentation of LT-formulas. Our main contribution is a synthesis result:\nfrom any transduction R defined in LT , it is possible to synthesise a regular\nfunctional transduction f such that for all input words u in the domain of R, f\nis defined and (u,f(u)) belongs to R. As a consequence, we obtain that any\nfunctional transduction is regular iff it is LT-definable. We also investigate\nthe algorithmic and expressiveness properties of several extensions of LT, and\nexplicit a correspondence between transductions and data words. As a\nside-result, we obtain a new decidable logic for data words.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Probabilistic Combination of Noisy Points and Planes for RGB-D Odometry.   This work proposes a visual odometry method that combines points and plane\nprimitives, extracted from a noisy depth camera. Depth measurement uncertainty\nis modelled and propagated through the extraction of geometric primitives to\nthe frame-to-frame motion estimation, where pose is optimized by weighting the\nresiduals of 3D point and planes matches, according to their uncertainties.\nResults on an RGB-D dataset show that the combination of points and planes,\nthrough the proposed method, is able to perform well in poorly textured\nenvironments, where point-based odometry is bound to fail.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Active Community Detection: A Maximum Likelihood Approach.   We propose novel semi-supervised and active learning algorithms for the\nproblem of community detection on networks. The algorithms are based on\noptimizing the likelihood function of the community assignments given a graph\nand an estimate of the statistical model that generated it. The optimization\nframework is inspired by prior work on the unsupervised community detection\nproblem in Stochastic Block Models (SBM) using Semi-Definite Programming (SDP).\nIn this paper we provide the next steps in the evolution of learning\ncommunities in this context which involves a constrained semi-definite\nprogramming algorithm, and a newly presented active learning algorithm. The\nactive learner intelligently queries nodes that are expected to maximize the\nchange in the model likelihood. Experimental results show that this active\nlearning algorithm outperforms the random-selection semi-supervised version of\nthe same algorithm as well as other state-of-the-art active learning\nalgorithms. Our algorithms significantly improved performance is demonstrated\non both real-world and SBM-generated networks even when the SBM has a signal to\nnoise ratio (SNR) below the known unsupervised detectability threshold.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Meridian Surfaces on Rotational Hypersurfaces with Lightlike Axis in ${\\mathbb E}^4_2$.   We construct a special class of Lorentz surfaces in the pseudo-Euclidean\n4-space with neutral metric which are one-parameter systems of meridians of\nrotational hypersurfaces with lightlike axis and call them meridian surfaces.\nWe give the complete classification of the meridian surfaces with constant\nGauss curvature and prove that there are no meridian surfaces with parallel\nmean curvature vector field other than CMC surfaces lying in a hyperplane. We\nalso classify the meridian surfaces with parallel normalized mean curvature\nvector field. We show that in the family of the meridian surfaces there exist\nLorentz surfaces which have parallel normalized mean curvature vector field but\nnot parallel mean curvature vector.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Learning for Real-time Gravitational Wave Detection and Parameter Estimation: Results with Advanced LIGO Data.   The recent Nobel-prize-winning detections of gravitational waves from merging\nblack holes and the subsequent detection of the collision of two neutron stars\nin coincidence with electromagnetic observations have inaugurated a new era of\nmultimessenger astrophysics. To enhance the scope of this emergent field of\nscience, we pioneered the use of deep learning with convolutional neural\nnetworks, that take time-series inputs, for rapid detection and\ncharacterization of gravitational wave signals. This approach, Deep Filtering,\nwas initially demonstrated using simulated LIGO noise. In this article, we\npresent the extension of Deep Filtering using real data from LIGO, for both\ndetection and parameter estimation of gravitational waves from binary black\nhole mergers using continuous data streams from multiple LIGO detectors. We\ndemonstrate for the first time that machine learning can detect and estimate\nthe true parameters of real events observed by LIGO. Our results show that Deep\nFiltering achieves similar sensitivities and lower errors compared to\nmatched-filtering while being far more computationally efficient and more\nresilient to glitches, allowing real-time processing of weak time-series\nsignals in non-stationary non-Gaussian noise with minimal resources, and also\nenables the detection of new classes of gravitational wave sources that may go\nunnoticed with existing detection algorithms. This unified framework for data\nanalysis is ideally suited to enable coincident detection campaigns of\ngravitational waves and their multimessenger counterparts in real-time.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Miraculous cancellations for quantum $SL_2$.   In earlier work, Helen Wong and the author discovered certain \"miraculous\ncancellations\" for the quantum trace map connecting the Kauffman bracket skein\nalgebra of a surface to its quantum Teichmueller space, occurring when the\nquantum parameter $q$ is a root of unity. The current paper is devoted to\ngiving a more representation theoretic interpretation of this phenomenon, in\nterms of the quantum group $U_q(sl_2)$ and its dual Hopf algebra $SL_2^q$.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Curious Minds Wonder Alike: Studying Multimodal Behavioral Dynamics to Design Social Scaffolding of Curiosity.   Curiosity is the strong desire to learn or know more about something or\nsomeone. Since learning is often a social endeavor, social dynamics in\ncollaborative learning may inevitably influence curiosity. There is a scarcity\nof research, however, focusing on how curiosity can be evoked in group learning\ncontexts. Inspired by a recently proposed theoretical framework that\narticulates an integrated socio-cognitive infrastructure of curiosity, in this\nwork, we use data-driven approaches to identify fine-grained social scaffolding\nof curiosity in child-child interaction, and propose how they can be used to\nelicit and maintain curiosity in technology-enhanced learning environments. For\nexample, we discovered sequential patterns of multimodal behaviors across group\nmembers and we describe those that maximize an individual's utility, or\nlikelihood, of demonstrating curiosity during open-ended problem-solving in\ngroup work. We also discovered, and describe here, behaviors that directly or\nin a mediated manner cause curiosity related conversational behaviors in the\ninteraction, with twice as many interpersonal causal influences compared to\nintrapersonal ones. We explain how these findings form a solid foundation for\ndeveloping curiosity-increasing learning technologies or even assisting a human\ncoach to induce curiosity among learners.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Weak multiplier Hopf algebras III. Integrals and duality.   Let $(A,\\Delta)$ be a weak multiplier Hopf algebra. It is a pair of a\nnon-degenerate algebra $A$, with or without identity, and a coproduct $\\Delta$\non $A$, satisfying certain properties. The main difference with multiplier Hopf\nalgebras is that now, the canonical maps $T_1$ and $T_2$ on $A\\otimes A$,\ndefined by $$T_1(a\\otimes b)=\\Delta(a)(1\\otimes b)\n\\qquad\\quad\\text{and}\\qquad\\quad T_2(c\\otimes a)=(c\\otimes 1)\\Delta(a),$$ are\nno longer assumed to be bijective. Also recall that a weak multiplier Hopf\nalgebra is called regular if its antipode is a bijective map from $A$ to\nitself.\nIn this paper, we introduce and study the notion of integrals on such regular\nweak multiplier Hopf algebras. A left integral is a non-zero linear functional\non $A$ that is left invariant (in an appropriate sense). Similarly for a right\nintegral. For a regular weak multiplier Hopf algebra $(A,\\Delta)$ with\n(sufficiently many) integrals, we construct the dual $(\\widehat\nA,\\widehat\\Delta)$. It is again a regular weak multiplier Hopf algebra with\n(sufficiently many) integrals. This duality extends the known duality of\nfinite-dimensional weak Hopf algebras to this more general case. It also\nextends the duality of multiplier Hopf algebras with integrals, the so-called\nalgebraic quantum groups. For this reason, we will sometimes call a regular\nweak multiplier Hopf algebra with enough integrals an algebraic quantum\ngroupoid.\nWe discuss the relation of our work with the work on duality for algebraic\nquantum groupoids by Timmermann.\nWe also illustrate this duality with a particular example in a separate\npaper. In this paper, we only mention the main definitions and results for this\nexample. However, we do consider the two natural weak multiplier Hopf algebras\nassociated with a groupoid in detail and show that they are dual to each other\nin the sense of the above duality.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparing the dark matter models, modified Newtonian dynamics and modified gravity in accounting for the galaxy rotation curves.   We compare six models (including the baryonic model, two dark matter models,\ntwo modified Newtonian dynamics models and one modified gravity model) in\naccounting for the galaxy rotation curves. For the dark matter models, we\nassume NFW profile and core-modified profile for the dark halo, respectively.\nFor the modified Newtonian dynamics models, we discuss Milgrom's MOND theory\nwith two different interpolation functions, i.e. the standard and the simple\ninterpolation functions. As for the modified gravity, we focus on Moffat's MSTG\ntheory. We fit these models to the observed rotation curves of 9 high-surface\nbrightness and 9 low-surface brightness galaxies. We apply the Bayesian\nInformation Criterion and the Akaike Information Criterion to test the\ngoodness-of-fit of each model. It is found that non of the six models can well\nfit all the galaxy rotation curves. Two galaxies can be best fitted by the\nbaryonic model without involving the nonluminous dark matter. MOND can fit the\nlargest number of galaxies, and only one galaxy can be best fitted by MSTG\nmodel. Core-modified model can well fit about one half LSB galaxies but no HSB\ngalaxy, while NFW model can fit only a small fraction of HSB galaxies but no\nLSB galaxy. This may imply that the oversimplified NFW and Core-modified\nprofiles couldn't well mimic the postulated dark matter halo.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Interior transmission eigenvalue problems on compact manifolds with boundary conductivity parameters.   In this paper, we consider an interior transmission eigenvalue (ITE) problem\non some compact $C^{\\infty }$-Riemannian manifolds with a common smooth\nboundary. In particular, these manifolds may have different topologies, but we\nimpose some conditions of Riemannian metrics, indices of refraction and\nboundary conductivity parameters on the boundary. Then we prove the\ndiscreteness of the set of ITEs, the existence of infinitely many ITEs, and its\nWeyl type lower bound. For our settings, we can adopt the argument by\nLakshtanov and Vainberg, considering the Dirichlet-to-Neumann map. As an\napplication, we derive the existence of non-scattering energies for\ntime-harmonic acoustic equations. For the sake of simplicity, we consider the\nscattering theory on the Euclidean space. However, the argument is applicable\nfor certain kinds of non-compact manifolds with ends on which we can define the\nscattering matrix.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cubic Fields: A Primer.   We classify all cubic extensions of any field of arbitrary characteristic, up\nto isomorphism, via an explicit construction involving three fundamental types\nof cubic forms. We deduce a classification of any Galois cubic extension of a\nfield. The splitting and ramification of places in a separable cubic extension\nof any global function field are completely determined, and precise\nRiemann-Hurwitz formulae are given. In doing so, we determine the decomposition\nof any cubic polynomial over a finite field.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A cross-vendor and cross-state analysis of the GPS-probe data latency.   Crowdsourced GPS probe data has become a major source of real-time traffic\ninformation applications. In addition to traditional traveler advisory systems\nsuch as dynamic message signs (DMS) and 511 systems, probe data is being used\nfor automatic incident detection, Integrated Corridor Management (ICM), end of\nqueue warning systems, and mobility-related smartphone applications. Several\nprivate sector vendors offer minute by minute network-wide travel time and\nspeed probe data. The quality of such data in terms of deviation of the\nreported travel time and speeds from ground-truth has been extensively studied\nin recent years, and as a result concerns over the accuracy of probe data has\nmostly faded away. However, the latency of probe data, defined as the lag\nbetween the time that disturbance in traffic speed is reported in the\noutsourced data feed, and the time that the traffic is perturbed, has become a\nsubject of interest. The extent of latency of probe data for real-time\napplications is critical, so it is important to have a good understanding of\nthe amount of latency and its influencing factors. This paper uses high-quality\nindependent Bluetooth/Wi-Fi re-identification data collected on multiple\nfreeway segments in three different states, to measure the latency of the\nvehicle probe data provided by three major vendors. The statistical\ndistribution of the latency and its sensitivity to speed slowdown and recovery\nperiods are discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Diversification-Based Learning in Computing and Optimization.   Diversification-Based Learning (DBL) derives from a collection of principles\nand methods introduced in the field of metaheuristics that have broad\napplications in computing and optimization. We show that the DBL framework goes\nsignificantly beyond that of the more recent Opposition-based learning (OBL)\nframework introduced in Tizhoosh (2005), which has become the focus of numerous\nresearch initiatives in machine learning and metaheuristic optimization. We\nunify and extend earlier proposals in metaheuristic search (Glover, 1997,\nGlover and Laguna, 1997) to give a collection of approaches that are more\nflexible and comprehensive than OBL for creating intensification and\ndiversification strategies in metaheuristic search. We also describe potential\napplications of DBL to various subfields of machine learning and optimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear dynamics on branched structures and networks.   Nonlinear dynamics on graphs has rapidly become a topical issue with many\nphysical applications, ranging from nonlinear optics to Bose-Einstein\ncondensation. Whenever in a physical experiment a ramified structure is\ninvolved, it can prove useful to approximate such a structure by a metric\ngraph, or network. For the Schroedinger equation it turns out that the sixth\npower in the nonlinear term of the energy is critical in the sense that below\nthat power the constrained energy is lower bounded irrespectively of the value\nof the mass (subcritical case). On the other hand, if the nonlinearity power\nequals six, then the lower boundedness depends on the value of the mass: below\na critical mass, the constrained energy is lower bounded, beyond it, it is not.\nFor powers larger than six the constrained energy functional is never lower\nbounded, so that it is meaningless to speak about ground states (supercritical\ncase). These results are the same as in the case of the nonlinear Schrodinger\nequation on the real line. In fact, as regards the existence of ground states,\nthe results for systems on graphs differ, in general, from the ones for systems\non the line even in the subcritical case: in the latter case, whenever the\nconstrained energy is lower bounded there always exist ground states (the\nsolitons, whose shape is explicitly known), whereas for graphs the existence of\na ground state is not guaranteed. For the critical case, our results show a\nphenomenology much richer than the analogous on the line.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Integrable modules over affine Lie superalgebras sl(1|n)^.   We describe the category of integrable sl(1|n)^ -modules with the positive\ncentral charge and show that the irreducible modules provide the full set of\nirreducible representations for the corresponding simple vertex algebra.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Permutation complexity of images of Sturmian words by marked morphisms.   We show that the permutation complexity of the image of a Sturmian word by a\nbinary marked morphism is $n+k$ for some constant $k$ and all lengths $n$\nsufficiently large.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A GPU Poisson-Fermi Solver for Ion Channel Simulations.   The Poisson-Fermi model is an extension of the classical Poisson-Boltzmann\nmodel to include the steric and correlation effects of ions and water treated\nas nonuniform spheres in aqueous solutions. Poisson-Boltzmann electrostatic\ncalculations are essential but computationally very demanding for molecular\ndynamics or continuum simulations of complex systems in molecular biophysics\nand electrochemistry. The graphic processing unit (GPU) with enormous\narithmetic capability and streaming memory bandwidth is now a powerful engine\nfor scientific as well as industrial computing. We propose two parallel GPU\nalgorithms, one for linear solver and the other for nonlinear solver, for\nsolving the Poisson-Fermi equation approximated by the standard finite\ndifference method in 3D to study biological ion channels with crystallized\nstructures from the Protein Data Bank, for example. Numerical methods for both\nlinear and nonlinear solvers in the parallel algorithms are given in detail to\nillustrate the salient features of the CUDA (compute unified device\narchitecture) software platform of GPU in implementation. It is shown that the\nparallel algorithms on GPU over the sequential algorithms on CPU (central\nprocessing unit) can achieve 22.8x and 16.9x speedups for the linear solver\ntime and total runtime, respectively.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Transkernel: An Executor for Commodity Kernels on Peripheral Cores.   Modern mobile and embedded platforms see a large number of ephemeral tasks\ndriven by background activities. In order to execute such a task, the OS kernel\nwakes up the platform beforehand and puts it back to sleep afterwards. In doing\nso, the kernel operates various IO devices and orchestrates their power state\ntransitions. Such kernel execution phases are lengthy, having high energy cost,\nand yet difficult to optimize. We advocate for relieving the CPU from these\nkernel phases by executing them on a low-power, microcontroller-like core,\ndubbed peripheral core, hence leaving the CPU off. Yet, for a peripheral core\nto execute phases in a complex commodity kernel (e.g. Linux), existing\napproaches either incur high engineering effort or high runtime overhead. We\ntake a radical approach with a new executor model called transkernel. Running\non a peripheral core, a transkernel executes the binary of the commodity kernel\nthrough cross-ISA, dynamic binary translation (DBT). The transkernel translates\nstateful kernel code while emulating a small set of stateless kernel services;\nit sets a narrow, stable binary interface for emulated services; it specializes\nfor kernel's beaten paths; it exploits ISA similarities for low DBT cost. With\na concrete implementation on a heterogeneous ARM SoC, we demonstrate the\nfeasibility and benefit of transkernel. Our result contributes a new OS\nstructure that combines cross-ISA DBT and emulation for harnessing a\nheterogeneous SoC. Our result demonstrates that while cross-ISA DBT is\ntypically used under the assumption of efficiency loss, it can be used for\nefficiency gain, even atop off-the-shelf hardware.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Smooth Pinball Neural Network for Probabilistic Forecasting of Wind Power.   Uncertainty analysis in the form of probabilistic forecasting can\nsignificantly improve decision making processes in the smart power grid for\nbetter integrating renewable energy sources such as wind. Whereas point\nforecasting provides a single expected value, probabilistic forecasts provide\nmore information in the form of quantiles, prediction intervals, or full\npredictive densities. This paper analyzes the effectiveness of a novel approach\nfor nonparametric probabilistic forecasting of wind power that combines a\nsmooth approximation of the pinball loss function with a neural network\narchitecture and a weighting initialization scheme to prevent the quantile\ncross over problem. A numerical case study is conducted using publicly\navailable wind data from the Global Energy Forecasting Competition 2014.\nMultiple quantiles are estimated to form 10%, to 90% prediction intervals which\nare evaluated using a quantile score and reliability measures. Benchmark models\nsuch as the persistence and climatology distributions, multiple quantile\nregression, and support vector quantile regression are used for comparison\nwhere results demonstrate the proposed approach leads to improved performance\nwhile preventing the problem of overlapping quantile estimates.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tamed to compatible when b^(2+) = 1 and b^1 = 2.   Weiyi Zhang noticed recently a gap in the proof of the main theorem of the\nauthors article \"Tamed to compatible: Symplectic forms via moduli space\nintegration\" [T] for the case when the symplectic 4-manifold in question has\nfirst Betti number 2 (and necessarily self-dual second Betti number 1). This\nnote explains how to fill this gap.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Critical fields and fluctuations determined from specific heat and magnetoresistance in the same nanogram SmFeAs(O,F) single crystal.   Through a direct comparison of specific heat and magneto-resistance we\ncritically asses the nature of superconducting fluctuations in the same\nnano-gram crystal of SmFeAs(O, F). We show that although the superconducting\nfluctuation contribution to conductivity scales well within the 2D-LLL scheme\nits predictions contrast the inherently 3D nature of SmFeAs(O, F) in the\nvicinity T_{c}. Furthermore the transition seen in specific heat cannot be\nsatisfactory described either by the LLL or the XY scaling. Additionally we\nhave validated, through comparing Hc2 values obtained from the entropy\nconservation construction (Hab=-19.5 T/K and Hab=-2.9 T/K), the analysis of\nfluctuation contribution to conductivity as a reasonable method for estimating\nthe Hc2 slope.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weighted Contrastive Divergence.   Learning algorithms for energy based Boltzmann architectures that rely on\ngradient descent are in general computationally prohibitive, typically due to\nthe exponential number of terms involved in computing the partition function.\nIn this way one has to resort to approximation schemes for the evaluation of\nthe gradient. This is the case of Restricted Boltzmann Machines (RBM) and its\nlearning algorithm Contrastive Divergence (CD). It is well-known that CD has a\nnumber of shortcomings, and its approximation to the gradient has several\ndrawbacks. Overcoming these defects has been the basis of much research and new\nalgorithms have been devised, such as persistent CD. In this manuscript we\npropose a new algorithm that we call Weighted CD (WCD), built from small\nmodifications of the negative phase in standard CD. However small these\nmodifications may be, experimental work reported in this paper suggest that WCD\nprovides a significant improvement over standard CD and persistent CD at a\nsmall additional computational cost.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hydrodynamic signatures of stationary Marangoni-driven surfactant transport.   We experimentally study steady Marangoni-driven surfactant transport on the\ninterface of a deep water layer. Using hydrodynamic measurements, and without\nusing any knowledge of the surfactant physico-chemical properties, we show that\nsodium dodecyl sulphate and Tergitol 15-S-9 introduced in low concentrations\nresult in a flow driven by adsorbed surfactant. At higher surfactant\nconcentration, the flow is dominated by the dissolved surfactant. Using\nCamphoric acid, whose properties are {\\it a priori} unknown, we demonstrate\nthis method's efficacy by showing its spreading is adsorption dominated.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Continuum of classical-field ensembles from canonical to grand canonical and the onset of their equivalence.   The canonical and grand-canonical ensembles are two usual marginal cases for\nultracold Bose gases, but real collections of experimental runs commonly have\nintermediate properties. Here we study the continuum of intermediate cases, and\nlook into the appearance of ensemble equivalence as interaction rises for\nmesoscopic 1d systems. We demonstrate how at sufficient interaction strength\nthe distributions of condensate and excited atoms become practically identical\nregardless of the ensemble used. Importantly, we find that features that are\nfragile in the ideal gas and appear only in a strict canonical ensemble can\nbecome robust in all ensembles when interactions become strong. As evidence,\nthe steep cliff in the distribution of the number of excited atoms is\npreserved. To make this study, a straightforward approach for generating\ncanonical and intermediate classical field ensembles using a modified\nstochastic Gross-Pitaevskii equation (SGPE) is developed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Joint Syntacto-Discourse Parsing and the Syntacto-Discourse Treebank.   Discourse parsing has long been treated as a stand-alone problem independent\nfrom constituency or dependency parsing. Most attempts at this problem are\npipelined rather than end-to-end, sophisticated, and not self-contained: they\nassume gold-standard text segmentations (Elementary Discourse Units), and use\nexternal parsers for syntactic features. In this paper we propose the first\nend-to-end discourse parser that jointly parses in both syntax and discourse\nlevels, as well as the first syntacto-discourse treebank by integrating the\nPenn Treebank with the RST Treebank. Built upon our recent span-based\nconstituency parser, this joint syntacto-discourse parser requires no\npreprocessing whatsoever (such as segmentation or feature extraction), achieves\nthe state-of-the-art end-to-end discourse parsing accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Motivic infinite loop spaces.   We prove a recognition principle for motivic infinite P1-loop spaces over a\nperfect field. This is achieved by developing a theory of framed motivic\nspaces, which is a motivic analogue of the theory of E-infinity-spaces. A\nframed motivic space is a motivic space equipped with transfers along finite\nsyntomic morphisms with trivialized cotangent complex in K-theory. Our main\nresult is that grouplike framed motivic spaces are equivalent to the full\nsubcategory of motivic spectra generated under colimits by suspension spectra.\nAs a consequence, we deduce some representability results for suspension\nspectra of smooth varieties, and in particular for the motivic sphere spectrum,\nin terms of Hilbert schemes of points in affine spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Toward Incorporation of Relevant Documents in word2vec.   Recent advances in neural word embedding provide significant benefit to\nvarious information retrieval tasks. However as shown by recent studies,\nadapting the embedding models for the needs of IR tasks can bring considerable\nfurther improvements. The embedding models in general define the term\nrelatedness by exploiting the terms' co-occurrences in short-window contexts.\nAn alternative (and well-studied) approach in IR for related terms to a query\nis using local information i.e. a set of top-retrieved documents. In view of\nthese two methods of term relatedness, in this work, we report our study on\nincorporating the local information of the query in the word embeddings. One\nmain challenge in this direction is that the dense vectors of word embeddings\nand their estimation of term-to-term relatedness remain difficult to interpret\nand hard to analyze. As an alternative, explicit word representations propose\nvectors whose dimensions are easily interpretable, and recent methods show\ncompetitive performance to the dense vectors. We introduce a neural-based\nexplicit representation, rooted in the conceptual ideas of the word2vec\nSkip-Gram model. The method provides interpretable explicit vectors while\nkeeping the effectiveness of the Skip-Gram model. The evaluation of various\nexplicit representations on word association collections shows that the newly\nproposed method out- performs the state-of-the-art explicit representations\nwhen tasked with ranking highly similar terms. Based on the introduced ex-\nplicit representation, we discuss our approaches on integrating local documents\nin globally-trained embedding models and discuss the preliminary results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Game-Theoretic Design of Secure and Resilient Distributed Support Vector Machines with Adversaries.   With a large number of sensors and control units in networked systems,\ndistributed support vector machines (DSVMs) play a fundamental role in scalable\nand efficient multi-sensor classification and prediction tasks. However, DSVMs\nare vulnerable to adversaries who can modify and generate data to deceive the\nsystem to misclassification and misprediction. This work aims to design defense\nstrategies for DSVM learner against a potential adversary. We establish a\ngame-theoretic framework to capture the conflicting interests between the DSVM\nlearner and the attacker. The Nash equilibrium of the game allows predicting\nthe outcome of learning algorithms in adversarial environments, and enhancing\nthe resilience of the machine learning through dynamic distributed learning\nalgorithms. We show that the DSVM learner is less vulnerable when he uses a\nbalanced network with fewer nodes and higher degree. We also show that adding\nmore training samples is an efficient defense strategy against an attacker. We\npresent secure and resilient DSVM algorithms with verification method and\nrejection method, and show their resiliency against adversary with numerical\nexperiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Debris Backwards Flow Simulation System for Malaysia Airlines Flight 370.   This paper presents a system based on a Two-Way Particle-Tracking Model to\nanalyze possible crash positions of flight MH370. The particle simulator\nincludes a simple flow simulation of the debris based on a Lagrangian approach\nand a module to extract appropriated ocean current data from netCDF files. The\ninfluence of wind, waves, immersion depth and hydrodynamic behavior are not\nconsidered in the simulation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Discrete configuration spaces of squares and hexagons.   We consider generalizations of the familiar fifteen-piece sliding puzzle on\nthe 4 by 4 square grid. On larger grids with more pieces and more holes,\nasymptotically how fast can we move the puzzle into the solved state? We also\ngive a variation with sliding hexagons. The square puzzles and the hexagon\npuzzles are both discrete versions of configuration spaces of disks, which are\nof interest in statistical mechanics and topological robotics. The\ncombinatorial theorems and proofs in this paper suggest followup questions in\nboth combinatorics and topology, and may turn out to be useful for proving\ntopological statements about configuration spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "HARPO: 1.7 - 74 MeV gamma-ray beam validation of a high angular resolutio n, high linear polarisation dilution, gas time projection chamber telescope and polarimeter.   A presentation at the SciNeGHE conference of the past achievements, of the\npresent activities and of the perspectives for the future of the HARPO project,\nthe development of a time projection chamber as a high-performance gamma-ray\ntelescope and linear polarimeter in the e+e- pair creation regime.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On certain families of planar patterns and fractals.   This survey article is dedicated to some families of fractals that were\nintroduced and studied during the last decade, more precisely, families of\nSierpiński carpets: limit net sets, generalised Sierpiński carpets and\nlabyrinth fractals. We give a unifying approach of these fractals and several\nof their topological and geometrical properties, by using the framework of\nplanar patterns.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "L1188: a promising candidate of cloud-cloud collision triggering the formation of the low- and intermediate-mass stars.   We present a new large-scale (4 square degrees) simultaneous $^{12}$CO,\n$^{13}$CO, and C$^{18}$O ($J$=1$-$0) mapping of L1188 with the PMO 13.7-m\ntelescope. Our observations have revealed that L1188 consists of two nearly\northogonal filamentary molecular clouds at two clearly separated velocities.\nToward the intersection showing large velocity spreads, we find several\nbridging features connecting the two clouds in velocity, and an open arc\nstructure which exhibits high excitation temperatures, enhanced $^{12}$CO and\n$^{13}$CO emission, and broad $^{12}$CO line wings. This agrees with the\nscenario that the two clouds are colliding with each other. The distribution of\nyoung stellar object (YSO) candidates implies an enhancement of star formation\nin the intersection of the two clouds. We suggest that a cloud-cloud collision\nhappened in L1188 about 1~Myr ago, possibly triggering the formation of low-\nand intermediate-mass YSOs in the intersection.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Observation of a Lamb band gap in a polymer waveguide with periodic cross-like cavities.   The quest for large and low frequency band gaps is one of the principal\nobjectives pursued in a number of engineering applications, ranging from noise\nabsorption to vibration control, to seismic wave abatement. For this purpose, a\nplethora of complex architectures (including multi-phase materials) and\nmulti-physics approaches have been proposed in the past, often involving\ndifficulties in their practical realization.\nTo address this issue, in this work we propose an easy-to-manufacture design\nable to open large, low frequency complete Lamb band gaps exploiting a suitable\narrangement of masses and stiffnesses produced by cavities in a monolithic\nmaterial. The performance of the designed structure is evaluated by numerical\nsimulations and confirmed by Scanning Laser Doppler Vibrometer (SLDV)\nmeasurements on an isotropic polyvinyl chloride plate in which a square ring\nregion of cross-like cavities is fabricated. The full wave field reconstruction\nclearly confirms the ability of even a limited number of unit cell rows of the\nproposed design to efficiently attenuate Lamb waves. In addition, numerical\nsimulations show that the structure allows to shift of the central frequency of\nthe BG through geometrical modifications. The design may be of interest for\napplications in which large BGs at low frequencies are required.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Model comparison for Gibbs random fields using noisy reversible jump Markov chain Monte Carlo.   The reversible jump Markov chain Monte Carlo (RJMCMC) method offers an\nacross-model simulation approach for Bayesian estimation and model comparison,\nby exploring the sampling space that consists of several models of possibly\nvarying dimensions. A naive implementation of RJMCMC to models like Gibbs\nrandom fields suffers from computational difficulties: the posterior\ndistribution for each model is termed doubly-intractable since computation of\nthe likelihood function is rarely available. Consequently, it is simply\nimpossible to simulate a transition of the Markov chain in the presence of\nlikelihood intractability. A variant of RJMCMC is presented, called noisy\nRJMCMC, where the underlying transition kernel is replaced with an\napproximation based on unbiased estimators. Based on previous theoretical\ndevelopments, convergence guarantees for the noisy RJMCMC algorithm are\nprovided. The experiments show that the noisy RJMCMC algorithm can be much more\nefficient than other exact methods, provided that an estimator with controlled\nMonte Carlo variance is used, a fact which is in agreement with the theoretical\nanalysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Artificial Intelligence Assisted Power Grid Hardening in Response to Extreme Weather Events.   In this paper, an artificial intelligence based grid hardening model is\nproposed with the objective of improving power grid resilience in response to\nextreme weather events. At first, a machine learning model is proposed to\npredict the component states (either operational or outage) in response to the\nextreme event. Then, these predictions are fed into a hardening model, which\ndetermines strategic locations for placement of distributed generation (DG)\nunits. In contrast to existing literature in hardening and resilience\nenhancement, this paper co-optimizes grid economic and resilience objectives by\nconsidering the intricate dependencies of the two. The numerical simulations on\nthe standard IEEE 118-bus test system illustrate the merits and applicability\nof the proposed hardening model. The results indicate that the proposed\nhardening model through decentralized and distributed local energy resources\ncan produce a more robust solution that can protect the system significantly\nagainst multiple component outages due to an extreme event.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Differentiable Compositional Kernel Learning for Gaussian Processes.   The generalization properties of Gaussian processes depend heavily on the\nchoice of kernel, and this choice remains a dark art. We present the Neural\nKernel Network (NKN), a flexible family of kernels represented by a neural\nnetwork. The NKN architecture is based on the composition rules for kernels, so\nthat each unit of the network corresponds to a valid kernel. It can compactly\napproximate compositional kernel structures such as those used by the Automatic\nStatistician (Lloyd et al., 2014), but because the architecture is\ndifferentiable, it is end-to-end trainable with gradient-based optimization. We\nshow that the NKN is universal for the class of stationary kernels. Empirically\nwe demonstrate pattern discovery and extrapolation abilities of NKN on several\ntasks that depend crucially on identifying the underlying structure, including\ntime series and texture extrapolation, as well as Bayesian optimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ultra-light and strong: the massless harmonic oscillator and its singular path integral.   In classical mechanics, a light particle bound by a strong elastic force just\noscillates at high frequency in the region allowed by its initial position and\nvelocity. In quantum mechanics, instead, the ground state of the particle\nbecomes completely de-localized in the limit $m \\to 0$. The harmonic oscillator\nthus ceases to be a useful microscopic physical model in the limit $m \\to 0$,\nbut its Feynman path integral has interesting singularities which make it a\nprototype of other systems exhibiting a \"quantum runaway\" from the classical\nconfigurations near the minimum of the action. The probability density of the\ncoherent runaway modes can be obtained as the solution of a Fokker-Planck\nequation associated to the condition $S=S_{min}$. This technique can be applied\nalso to other systems, notably to a dimensional reduction of the\nEinstein-Hilbert action.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning Distributions of Meant Color.   When a speaker says the name of a color, the color that they picture is not\nnecessarily the same as the listener imagines. Color is a grounded semantic\ntask, but that grounding is not a mapping of a single word (or phrase) to a\nsingle point in color-space. Proper understanding of color language requires\nthe capacity to map a sequence of words to a probability distribution in\ncolor-space. A distribution is required as there is no clear agreement between\npeople as to what a particular color describes -- different people have a\ndifferent idea of what it means to be `very dark orange'. We propose a novel\nGRU-based model to handle this case. Learning how each word in a color name\ncontributes to the color described, allows for knowledge sharing between uses\nof the words in different color names. This knowledge sharing significantly\nimproves predicative capacity for color names with sparse training data. The\nextreme case of this challenge in data sparsity is for color names without any\ndirect training data. Our model is able to predict reasonable distributions for\nthese cases, as evaluated on a held-out dataset consisting only of such terms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Search for Laser Emission with Megawatt Thresholds from 5600 FGKM Stars.   We searched high resolution spectra of 5600 nearby stars for emission lines\nthat are both inconsistent with a natural origin and unresolved spatially, as\nwould be expected from extraterrestrial optical lasers. The spectra were\nobtained with the Keck 10-meter telescope, including light coming from within\n0.5 arcsec of the star, corresponding typically to within a few to tens of au\nof the star, and covering nearly the entire visible wavelength range from 3640\nto 7890 angstroms. We establish detection thresholds by injecting synthetic\nlaser emission lines into our spectra and blindly analyzing them for\ndetections. We compute flux density detection thresholds for all wavelengths\nand spectral types sampled. Our detection thresholds for the power of the\nlasers themselves range from 3 kW to 13 MW, independent of distance to the star\nbut dependent on the competing \"glare\" of the spectral energy distribution of\nthe star and on the wavelength of the laser light, launched from a benchmark,\ndiffraction-limited 10-meter class telescope. We found no such laser emission\ncoming from the planetary region around any of the 5600 stars. As they contain\nroughly 2000 lukewarm, Earth-size planets, we rule out models of the Milky Way\nin which over 0.1 percent of warm, Earth-size planets harbor technological\ncivilizations that, intentionally or not, are beaming optical lasers toward us.\nA next generation spectroscopic laser search will be done by the Breakthrough\nListen initiative, targeting more stars, especially stellar types overlooked\nhere including spectral types O, B, A, early F, late M, and brown dwarfs, and\nastrophysical exotica.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reminiscences of Julian Schwinger: Late Harvard, Early UCLA Years (1968-1981).   These are reminiscences of my interactions with Julian Schwinger from 1968\nthrough 1981 and beyond.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Predictability of escape for a stochastic saddle-node bifurcation: when rare events are typical.   Transitions between multiple stable states of nonlinear systems are\nubiquitous in physics, chemistry, and beyond. Two types of behaviors are\nusually seen as mutually exclusive: unpredictable noise-induced transitions and\npredictable bifurcations of the underlying vector field. Here, we report a new\nsituation, corresponding to a fluctuating system approaching a bifurcation,\nwhere both effects collaborate. We show that the problem can be reduced to a\nsingle control parameter governing the competition between deterministic and\nstochastic effects. Two asymptotic regimes are identified: when the control\nparameter is small (e.g. small noise), deviations from the deterministic case\nare well described by the Freidlin-Wentzell theory. In particular, escapes over\nthe potential barrier are very rare events. When the parameter is large (e.g.\nlarge noise), such events become typical. Unlike pure noise-induced\ntransitions, the distribution of the escape time is peaked around a value which\nis asymptotically predicted by an adiabatic approximation. We show that the two\nregimes are characterized by qualitatively different reacting trajectories,\nwith algebraic and exponential divergence, respectively.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Improvement in the UAV position estimation with low-cost GPS, INS and vision-based system: Application to a quadrotor UAV.   In this paper, we develop a position estimation system for Unmanned Aerial\nVehicles formed by hardware and software. It is based on low-cost devices: GPS,\ncommercial autopilot sensors and dense optical flow algorithm implemented in an\nonboard microcomputer. Comparative tests were conducted using our approach and\nthe conventional one, where only fusion of GPS and inertial sensors are used.\nExperiments were conducted using a quadrotor in two flying modes: hovering and\ntrajectory tracking in outdoor environments. Results demonstrate the\neffectiveness of the proposed approach in comparison with the conventional\napproaches presented in the vast majority of commercial drones.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Invariance of Ideal Limit Points.   Let $\\mathcal{I}$ be an analytic P-ideal [respectively, a summable ideal] on\nthe positive integers and let $(x_n)$ be a sequence taking values in a metric\nspace $X$. First, it is shown that the set of ideal limit points of $(x_n)$ is\nan $F_\\sigma$-set [resp., a closet set]. Let us assume that $X$ is also\nseparable and the ideal $\\mathcal{I}$ satisfies certain additional assumptions,\nwhich however includes several well-known examples, e.g., the collection of\nsets with zero asymptotic density, sets with zero logarithmic density, and some\nsummable ideals. Then, it is shown that the set of ideal limit points of\n$(x_n)$ is equal to the set of ideal limit points of almost all its\nsubsequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiple Source Domain Adaptation with Adversarial Training of Neural Networks.   While domain adaptation has been actively researched in recent years, most\ntheoretical results and algorithms focus on the single-source-single-target\nadaptation setting. Naive application of such algorithms on multiple source\ndomain adaptation problem may lead to suboptimal solutions. As a step toward\nbridging the gap, we propose a new generalization bound for domain adaptation\nwhen there are multiple source domains with labeled instances and one target\ndomain with unlabeled instances. Compared with existing bounds, the new bound\ndoes not require expert knowledge about the target distribution, nor the\noptimal combination rule for multisource domains. Interestingly, our theory\nalso leads to an efficient learning strategy using adversarial neural networks:\nwe show how to interpret it as learning feature representations that are\ninvariant to the multiple domain shifts while still being discriminative for\nthe learning task. To this end, we propose two models, both of which we call\nmultisource domain adversarial networks (MDANs): the first model optimizes\ndirectly our bound, while the second model is a smoothed approximation of the\nfirst one, leading to a more data-efficient and task-adaptive model. The\noptimization tasks of both models are minimax saddle point problems that can be\noptimized by adversarial training. To demonstrate the effectiveness of MDANs,\nwe conduct extensive experiments showing superior adaptation performance on\nthree real-world datasets: sentiment analysis, digit classification, and\nvehicle counting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On a Possible Giant Impact Origin for the Colorado Plateau.   It is proposed and substantiated that an extraterrestrial object of the\napproximate size and mass of Planet Mars, impacting the Earth in an oblique\nangle along an approximately NE-SW route (with respect to the current\norientation of the North America continent) around 750 million years ago (750\nMa), is likely to be the direct cause of a chain of events which led to the\nrifting of the Rodinia supercontinent and the severing of the foundation of the\nColorado Plateau from its surrounding craton.\nIt is further argued that the impactor most likely originated as a rouge\nexoplanet produced during one of the past crossings of our Solar System through\nthe Galactic spiral arms in its orbital motion around the center of the Milky\nWay Galaxy. Recent work has shown that the sites of galactic spiral arms are\nlocations of density-wave collisionless shocks. The perturbations from such\nshock are known lead to the formation of massive stars, which evolve quickly\nand die as supernovae. The blastwaves from supernova explosions, in addition to\nthe collisionless shocks at the spiral arms, can perturb the orbits of the\nstreaming disk matter, occasionally producing rogue exoplanets that can reach\nthe inner confines of our Solar System. The similarity between the period of\nspiral-arm crossings of our Solar System to the period of major extinction\nevents in the Phanerozoic Eon of the Earth's history, as well as to the period\nof the supercontinent cycle (the so-called Wilson Cycle), indicates that the\nglobal environment of the Milky Way Galaxy may have played a major role in\ninitiating Earth's past tectonic activities.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Highly accurate model for prediction of lung nodule malignancy with CT scans.   Computed tomography (CT) examinations are commonly used to predict lung\nnodule malignancy in patients, which are shown to improve noninvasive early\ndiagnosis of lung cancer. It remains challenging for computational approaches\nto achieve performance comparable to experienced radiologists. Here we present\nNoduleX, a systematic approach to predict lung nodule malignancy from CT data,\nbased on deep learning convolutional neural networks (CNN). For training and\nvalidation, we analyze >1000 lung nodules in images from the LIDC/IDRI cohort.\nAll nodules were identified and classified by four experienced thoracic\nradiologists who participated in the LIDC project. NoduleX achieves high\naccuracy for nodule malignancy classification, with an AUC of ~0.99. This is\ncommensurate with the analysis of the dataset by experienced radiologists. Our\napproach, NoduleX, provides an effective framework for highly accurate nodule\nmalignancy prediction with the model trained on a large patient population. Our\nresults are replicable with software available at\nthis http URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "How to place an obstacle having a dihedral symmetry centered at a given point inside a disk so as to optimize the fundamental Dirichlet eigenvalue.   A generic model for the shape optimization problems we consider in this paper\nis the optimization of the Dirichlet eigenvalues of the Laplace operator with a\nvolume constraint. We deal with an obstacle placement problem which can be\nformulated as the following eigenvalue optimization problem: Fix two positive\nreal numbers $r_1$ and $A$. We consider a disk $B\\subset \\mathbb{R}^2$ having\nradius $r_1$. We want to place an obstacle $P$ of area $A$ within $B$ so as to\nmaximize or minimize the fundamental Dirichlet eigenvalue $\\lambda_1$ for the\nLaplacian on $B\\setminus P$. That is, we want to study the behavior of the\nfunction $\\rho \\mapsto \\lambda_1(B\\setminus\\rho(P))$, where $\\rho$ runs over\nthe set of all rigid motions of the plane fixing the center of mass for $P$\nsuch that $\\rho(P)\\subset B$. In this paper, we consider a non-concentric\nobstacle placement problem. The extremal configurations correspond to the cases\nwhere an axis of symmetry of $P$ coincide with an axis of symmetry of $B$. We\nalso characterize the maximizing and the minimizing configurations in our main\nresult, viz., Theorem 4.1. Equation (6), Propositions 5.1 and 5.2 imply Theorem\n4.1. We give many different generalizations of our result. At the end, we\nprovide some numerical evidence to validate our main theorem for the case where\nthe obstacle $P$ has $\\mathbb{D}_4$ symmetry. For the $n$ odd case, we identify\nsome of the extremal configuration for $\\lambda_1$. We prove that equation (6)\nand Proposition 5.1 hold true for $n$ odd too. We highlight some of the\ndifficulties faced in proving Proposition 5.2 for this case. We provide\nnumerical evidence for $n=5$ and conjecture that Theorem 4.1 holds true for $n$\nodd too.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Catalyzed bimolecular reactions in responsive nanoreactors.   We describe a general theory for surface-catalyzed bimolecular reactions in\nresponsive nanoreactors, catalytically active nanoparticles coated by a\nstimuli-responsive 'gating' shell, whose permeability controls the activity of\nthe process. We address two archetypal scenarios encountered in this system:\nThe first, where two species diffusing from a bulk solution react at the\ncatalyst's surface; the second where only one of the reactants diffuses from\nthe bulk while the other one is produced at the nanoparticle surface, e.g., by\nlight conversion. We find that in both scenarios the total catalytic rate has\nthe same mathematical structure, once diffusion rates are properly redefined.\nMoreover, the diffusional fluxes of the different reactants are strongly\ncoupled, providing a richer behavior than that arising in unimolecular\nreactions. We also show that in stark contrast to bulk reactions, the\nidentification of a limiting reactant is not simply determined by the relative\nbulk concentrations but controlled by the nanoreactor shell permeability.\nFinally, we describe an application of our theory by analyzing experimental\ndata on the reaction between hexacyanoferrate (III) and borohydride ions in\nresponsive hydrogel-based core-shell nanoreactors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "TADPOLE Challenge: Prediction of Longitudinal Evolution in Alzheimer's Disease.   The Alzheimer's Disease Prediction Of Longitudinal Evolution (TADPOLE)\nChallenge compares the performance of algorithms at predicting future evolution\nof individuals at risk of Alzheimer's disease. TADPOLE Challenge participants\ntrain their models and algorithms on historical data from the Alzheimer's\nDisease Neuroimaging Initiative (ADNI) study or any other datasets to which\nthey have access. Participants are then required to make monthly forecasts over\na period of 5 years from January 2018, of three key outcomes for ADNI-3\nrollover participants: clinical diagnosis, Alzheimer's Disease Assessment Scale\nCognitive Subdomain (ADAS-Cog13), and total volume of the ventricles. These\nindividual forecasts are later compared with the corresponding future\nmeasurements in ADNI-3 (obtained after the TADPOLE submission deadline). The\nfirst submission phase of TADPOLE was open for prize-eligible submissions\nbetween 15 June and 15 November 2017. The submission system remains open via\nthe website: this https URL, although since 15 November\n2017 submissions are not eligible for the first round of prizes. This paper\ndescribes the design of the TADPOLE Challenge.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling Temporally Evolving and Spatially Globally Dependent Data.   The last decades have seen an unprecedented increase in the availability of\ndata sets that are inherently global and temporally evolving, from remotely\nsensed networks to climate model ensembles. This paper provides a view of\nstatistical modeling techniques for space-time processes, where space is the\nsphere representing our planet. In particular, we make a distintion between (a)\nsecond order-based, and (b) practical approaches to model temporally evolving\nglobal processes. The former are based on the specification of a class of\nspace-time covariance functions, with space being the two-dimensional sphere.\nThe latter are based on explicit description of the dynamics of the space-time\nprocess, i.e., by specifying its evolution as a function of its past history\nwith added spatially dependent noise.\nWe especially focus on approach (a), where the literature has been sparse. We\nprovide new models of space-time covariance functions for random fields defined\non spheres cross time. Practical approaches, (b), are also discussed, with\nspecial emphasis on models built directly on the sphere, without projecting the\nspherical coordinate on the plane.\nWe present a case study focused on the analysis of air pollution from the\n2015 wildfires in Equatorial Asia, an event which was classified as the year's\nworst environmental disaster. The paper finishes with a list of the main\ntheoretical and applied research problems in the area, where we expect the\nstatistical community to engage over the next decade.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Trace Properties from Separation Logic Specifications.   We propose a formal approach for relating abstract separation logic library\nspecifications with the trace properties they enforce on interactions between a\nclient and a library. Separation logic with abstract predicates enforces a\nresource discipline that constrains when and how calls may be made between a\nclient and a library. Intuitively, this can enforce a protocol on the\ninteraction trace. This intuition is broadly used in the separation logic\ncommunity but has not previously been formalised. We provide just such a\nformalisation. Our approach is based on using wrappers which instrument library\ncode to induce execution traces for the properties under examination. By\nconsidering a separation logic extended with trace resources, we prove that\nwhen a library satisfies its separation logic specification then its wrapped\nversion satisfies the same specification and, moreover, maintains the trace\nproperties as an invariant. Consequently, any client and library implementation\nthat are correct with respect to the separation logic specification will\nsatisfy the trace properties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scalable methods for Bayesian selective inference.   Modeled along the truncated approach in Panigrahi (2016), selection-adjusted\ninference in a Bayesian regime is based on a selective posterior. Such a\nposterior is determined together by a generative model imposed on data and the\nselection event that enforces a truncation on the assumed law. The effective\ndifference between the selective posterior and the usual Bayesian framework is\nreflected in the use of a truncated likelihood. The normalizer of the truncated\nlaw in the adjusted framework is the probability of the selection event; this\nis typically intractable and it leads to the computational bottleneck in\nsampling from such a posterior. The current work lays out a primal-dual\napproach of solving an approximating optimization problem to provide valid\npost-selective Bayesian inference. The selection procedures are posed as\ndata-queries that solve a randomized version of a convex learning program which\nhave the advantage of preserving more left-over information for inference. We\npropose a randomization scheme under which the optimization has separable\nconstraints that result in a partially separable objective in lower dimensions\nfor many commonly used selective queries to approximate the otherwise\nintractable selective posterior. We show that the approximating optimization\nunder a Gaussian randomization gives a valid exponential rate of decay for the\nselection probability on a large deviation scale. We offer a primal-dual method\nto solve the optimization problem leading to an approximate posterior; this\nallows us to exploit the usual merits of a Bayesian machinery in both low and\nhigh dimensional regimes where the underlying signal is effectively sparse. We\nshow that the adjusted estimates empirically demonstrate better frequentist\nproperties in comparison to the unadjusted estimates based on the usual\nposterior, when applied to a wide range of constrained, convex data queries.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ROPPERI - A TPC readout with GEMs, pads and Timepix.   The concept of a hybrid readout of a time projection chamber is presented. It\ncombines a GEM-based amplification and a pad-based anode plane with a pixel\nchip as readout electronics. This way, a high granularity enabling to identify\nelectron clusters from the primary ionisation is achieved as well as\nflexibility and large anode coverage. The benefits of this high granularity, in\nparticular for dE/dx measurements, are outlined and the current software and\nhardware development status towards a proof-of-principle is given.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Predicate Specialization for Definitional Higher-order Logic Programs.   Higher-order logic programming is an interesting extension of traditional\nlogic programming that allows predicates to appear as arguments and variables\nto be used where predicates typically occur. Higher-order characteristics are\nindeed desirable but on the other hand they are also usually more expensive to\nsupport. In this paper we propose a program specialization technique based on\npartial evaluation that can be applied to a modest but useful class of\nhigher-order logic programs and can transform them into first-order programs\nwithout introducing additional data structures. The resulting first-order\nprograms can be executed by conventional logic programming interpreters and\nbenefit from other optimizations that might be available. We provide an\nimplementation and experimental results that suggest the efficiency of the\ntransformation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust Bayesian Model Selection for Variable Clustering with the Gaussian Graphical Model.   Variable clustering is important for explanatory analysis. However, only few\ndedicated methods for variable clustering with the Gaussian graphical model\nhave been proposed. Even more severe, small insignificant partial correlations\ndue to noise can dramatically change the clustering result when evaluating for\nexample with the Bayesian Information Criteria (BIC). In this work, we try to\naddress this issue by proposing a Bayesian model that accounts for negligible\nsmall, but not necessarily zero, partial correlations. Based on our model, we\npropose to evaluate a variable clustering result using the marginal likelihood.\nTo address the intractable calculation of the marginal likelihood, we propose\ntwo solutions: one based on a variational approximation, and another based on\nMCMC. Experiments on simulated data shows that the proposed method is similarly\naccurate as BIC in the no noise setting, but considerably more accurate when\nthere are noisy partial correlations. Furthermore, on real data the proposed\nmethod provides clustering results that are intuitively sensible, which is not\nalways the case when using BIC or its extensions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparing Graph Clusterings: Set partition measures vs. Graph-aware measures.   In this paper, we propose a family of graph partition similarity measures\nthat take the topology of the graph into account. These graph-aware measures\nare alternatives to using set partition similarity measures that are not\nspecifically designed for graph partitions. The two types of measures,\ngraph-aware and set partition measures, are shown to have opposite behaviors\nwith respect to resolution issues and provide complementary information\nnecessary to assess that two graph partitions are similar.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a Science of Mind.   The ancient mind/body problem continues to be one of deepest mysteries of\nscience and of the human spirit. Despite major advances in many fields, there\nis still no plausible link between subjective experience (qualia) and its\nrealization in the body. This paper outlines some of the elements of a rigorous\nscience of mind (SoM) - key ideas include scientific realism of mind, agnostic\nmysterianism, careful attention to language, and a focus on concrete\n(touchstone) questions and results.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Raman LIDARs and atmospheric calibration for the Cherenkov Telescope Array.   The Cherenkov Telescope Array (CTA) is the next generation of Imaging\nAtmospheric Cherenkov Telescopes. It will reach a sensitivity and energy\nresolution never obtained until now by any other high energy gamma-ray\nexperiment. Understanding the systematic uncertainties in general will be a\ncrucial issue for the performance of CTA. It is well known that atmospheric\nconditions contribute particularly in this aspect.Within the CTA consortium\nseveral groups are currently building Raman LIDARs to be installed on the two\nsites. Raman LIDARs are devices composed of a powerful laser that shoots into\nthe atmosphere, a collector that gathers the backscattered light from molecules\nand aerosols, a photo-sensor, an optical module that spectrally selects\nwavelengths of interest, and a read--out system.Unlike currently used elastic\nLIDARs, they can help reduce the systematic uncertainties of the molecular and\naerosol components of the atmosphere to <5% so that CTA can achieve its energy\nresolution requirements of<10% uncertainty at 1 TeV.All the Raman LIDARs in\nthis work have design features that make them different than typical Raman\nLIDARs used in atmospheric science and are characterized by large collecting\nmirrors (2.5m2) and reduced acquisition time.They provide both multiple elastic\nand Raman read-out channels and custom made optics design.In this paper, the\nmotivation for Raman LIDARs, the design and the status of advance of these\ntechnologies are described.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ground state properties of 3d metals from self-consistent GW approach.   Self consistent GW approach (scGW) has been applied to calculate the ground\nstate properties (equilibrium Wigner-Seitz radius $S_{WZ}$ and bulk modulus\n$B$) of 3d transition metals Sc, Ti, V, Fe, Co, Ni, and Cu. The approach\nsystematically underestimates $S_{WZ}$ with average relative deviation from the\nexperimental data about 1% and it overestimates the calculated bulk modulus\nwith relative error about 25%. It is shown that scGW is superior in accuracy as\ncompared to the local density approximation (LDA) but it is less accurate than\nthe generalized gradient approach (GGA) for the materials studied. If compared\nto the random phase approximation (RPA), scGW is slightly less accurate, but\nits error for the 3d metals looks more systematic. The systematic nature of the\ndeviation from the experimental data suggests that the next order of the\nperturbation theory should allow one to reduce the error.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Magnetic Flux Tailoring through Lenz Lenses in Toroidal Diamond Indenter Cells: A New Pathway to High Pressure Nuclear Magnetic Resonance.   A new pathway to nuclear magnetic resonance spectroscopy in high pressure\ndiamond anvil cells is introduced, using inductively coupled broadband passive\nelectro-magnetic lenses to locally amplify the magnetic flux at the isolated\nsample, leading to an increase in sensitivity. The lenses are adopted for the\ngeometrical restrictions imposed by a toroidal diamond indenter cell, and yield\nhigh signal-to-noise ratios at pressures as high as 72 GPa, at initial sample\nvolumes of only 230 pl. The corresponding levels of detection, LODt, are found\nto be up to four orders of magnitude lower compared to formerly used solenoidal\nmicro-coils in diamond anvil cells, as shown by Proton-NMR measurements on\nparaffin oil. This approach opens up the field of ultra-high pressure sciences\nfor one of the most versatile spectroscopic methods available in a pressure\nrange unprecedended up to now.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stability and performance analysis of linear positive systems with delays using input-output methods.   It is known that input-output approaches based on scaled small-gain theorems\nwith constant $D$-scalings and integral linear constraints are non-conservative\nfor the analysis of some classes of linear positive systems interconnected with\nuncertain linear operators. This dramatically contrasts with the case of\ngeneral linear systems with delays where input-output approaches provide, in\ngeneral, sufficient conditions only. Using these results we provide simple\nalternative proofs for many of the existing results on the stability of linear\npositive systems with discrete/distributed/neutral time-invariant/-varying\ndelays and linear difference equations. In particular, we give a simple proof\nfor the characterization of diagonal Riccati stability for systems with\ndiscrete-delays and generalize this equation to other types of delay systems.\nThe fact that all those results can be reproved in a very simple way\ndemonstrates the importance and the efficiency of the input-output framework\nfor the analysis of linear positive systems. The approach is also used to\nderive performance results evaluated in terms of the $L_1$-, $L_2$- and\n$L_\\infty$-gains. It is also flexible enough to be used for design purposes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robot human interface for housekepeer with wireless capabilities.   This paper presents the design and implementation of a Human Interface for a\nhousekeeper robot. It bases on the idea of making the robot understand the\nhuman needs without making the human go through the details of robots work, for\nexample, the way that the robot implements the work or the method that the\nrobot uses to plan the path in order to reach the work area. The interface\ncommands based on idioms of the natural human language and designed in a manner\nthat the user gives the robot several commands with their execution date/time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "(non)-automaticity of completely multiplicative sequences having negligible many non-trivial prime factors.   In this article we consider the completely multiplicative sequences $(a_n)_{n\n\\in \\mathbf{N}}$ defined on a field $\\mathbf{K}$ and satisfying $$\\sum_{p| p\n\\leq n, a_p \\neq 1, p \\in \\mathbf{P}}\\frac{1}{p}<\\infty,$$ where $\\mathbf{P}$\nis the set of prime numbers. We prove that if such sequences are automatic then\nthey cannot have infinitely many prime numbers $p$ such that $a_{p}\\neq 1$.\nUsing this fact, we prove that if a completely multiplicative sequence\n$(a_n)_{n \\in \\mathbf{N}}$, vanishing or not, can be written in the form\n$a_n=b_n\\chi_n$ such that $(b_n)_{n \\in \\mathbf{N}}$ is a non ultimately\nperiodic, completely multiplicative automatic sequence satisfying the above\ncondition, and $(\\chi_n)_{n \\in \\mathbf{N}}$ is a Dirichlet character or a\nconstant sequence, then there exists only one prime number $p$ such that $b_p\n\\neq 1$ or $0$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Semantics and Complexity of Probabilistic Logic Programs.   We examine the meaning and the complexity of probabilistic logic programs\nthat consist of a set of rules and a set of independent probabilistic facts\n(that is, programs based on Sato's distribution semantics). We focus on two\nsemantics, respectively based on stable and on well-founded models. We show\nthat the semantics based on stable models (referred to as the \"credal\nsemantics\") produces sets of probability models that dominate infinitely\nmonotone Choquet capacities, we describe several useful consequences of this\nresult. We then examine the complexity of inference with probabilistic logic\nprograms. We distinguish between the complexity of inference when a\nprobabilistic program and a query are given (the inferential complexity), and\nthe complexity of inference when the probabilistic program is fixed and the\nquery is given (the query complexity, akin to data complexity as used in\ndatabase theory). We obtain results on the inferential and query complexity for\nacyclic, stratified, and cyclic propositional and relational programs,\ncomplexity reaches various levels of the counting hierarchy and even\nexponential levels.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cross-validation in high-dimensional spaces: a lifeline for least-squares models and multi-class LDA.   Least-squares models such as linear regression and Linear Discriminant\nAnalysis (LDA) are amongst the most popular statistical learning techniques.\nHowever, since their computation time increases cubically with the number of\nfeatures, they are inefficient in high-dimensional neuroimaging datasets.\nFortunately, for k-fold cross-validation, an analytical approach has been\ndeveloped that yields the exact cross-validated predictions in least-squares\nmodels without explicitly training the model. Its computation time grows with\nthe number of test samples. Here, this approach is systematically investigated\nin the context of cross-validation and permutation testing. LDA is used\nexemplarily but results hold for all other least-squares methods. Furthermore,\na non-trivial extension to multi-class LDA is formally derived. The analytical\napproach is evaluated using complexity calculations, simulations, and\npermutation testing of an EEG/MEG dataset. Depending on the ratio between\nfeatures and samples, the analytical approach is up to 10,000x faster than the\nstandard approach (retraining the model on each training set). This allows for\na fast cross-validation of least-squares models and multi-class LDA in\nhigh-dimensional data, with obvious applications in multi-dimensional datasets,\nRepresentational Similarity Analysis, and permutation testing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spatial Risk Measure for Max-Stable and Max-Mixture Processes.   In this paper, we consider isotropic and stationary max-stable, inverse\nmax-stable and max-mixture processes $X=(X(s))\\_{s\\in\\bR^2}$ and the damage\nfunction $\\cD\\_X^{\\nu}= |X|^\\nu$ with $0<\\nu<1/2$. We study the quantitative\nbehavior of a risk measure which is the variance of the average of\n$\\cD\\_X^{\\nu}$ over a region $\\mathcal{A}\\subset \\bR^2$.} This kind of risk\nmeasure has already been introduced and studied for \\vero{some} max-stable\nprocesses in \\cite{koch2015spatial}. %\\textcolor{red}{In this study, we\ngeneralised this risk measure to be applicable for several models: asymptotic\ndependence represented by max-stable, asymptotic independence represented by\ninverse max-stable and mixing between of them.} We evaluated the proposed risk\nmeasure by a simulation study.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Applications of Fractional Calculus to Newtonian Mechanics.   We investigate some basic applications of Fractional Calculus (FC) to\nNewtonian mechanics. After a brief review of FC, we consider a possible\ngeneralization of Newton's second law of motion and apply it to the case of a\nbody subject to a constant force. In our second application of FC to Newtonian\ngravity, we consider a generalized fractional gravitational potential and\nderive the related circular orbital velocities. This analysis might be used as\na tool to model galactic rotation curves, in view of the dark matter problem.\nBoth applications have a pedagogical value in connecting fractional calculus to\nstandard mechanics and can be used as a starting point for a more advanced\ntreatment of fractional mechanics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "prDeep: Robust Phase Retrieval with a Flexible Deep Network.   Phase retrieval algorithms have become an important component in many modern\ncomputational imaging systems. For instance, in the context of ptychography and\nspeckle correlation imaging, they enable imaging past the diffraction limit and\nthrough scattering media, respectively. Unfortunately, traditional phase\nretrieval algorithms struggle in the presence of noise. Progress has been made\nrecently on more robust algorithms using signal priors, but at the expense of\nlimiting the range of supported measurement models (e.g., to Gaussian or coded\ndiffraction patterns). In this work we leverage the regularization-by-denoising\nframework and a convolutional neural network denoiser to create prDeep, a new\nphase retrieval algorithm that is both robust and broadly applicable. We test\nand validate prDeep in simulation to demonstrate that it is robust to noise and\ncan handle a variety of system models.\nA MatConvNet implementation of prDeep is available at\nthis https URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A general family of congruences for Bernoulli numbers.   We prove a general family of congruences for Bernoulli numbers whose index is\na polynomial function of a prime, modulo a power of that prime. Our family\ngeneralizes many known results, including the von Staudt--Clausen theorem and\nKummer's congruence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Design discussion on the ISDA Common Domain Model.   A new initiative from the International Swaps and Derivatives Association\n(ISDA) aims to establish a \"Common Domain Model\" (ISDA CDM): a new standard for\ndata and process representation across the full range of derivatives\ninstruments. Design of the ISDA CDM is at an early stage and the draft\ndefinition contains considerable complexity. This paper contributes by offering\ninsight, analysis and discussion relating to key topics in the design space\nsuch as data lineage, timestamps, consistency, operations, events, state and\nstate transitions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topology data analysis of critical transitions in financial networks.   We develop a topology data analysis-based method to detect early signs for\ncritical transitions in financial data. From the time-series of multiple stock\nprices, we build time-dependent correlation networks, which exhibit topological\nstructures. We compute the persistent homology associated to these structures\nin order to track the changes in topology when approaching a critical\ntransition. As a case study, we investigate a portfolio of stocks during a\nperiod prior to the US financial crisis of 2007-2008, and show the presence of\nearly signs of the critical transition.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "From which world is your graph?.   Discovering statistical structure from links is a fundamental problem in the\nanalysis of social networks. Choosing a misspecified model, or equivalently, an\nincorrect inference algorithm will result in an invalid analysis or even\nfalsely uncover patterns that are in fact artifacts of the model. This work\nfocuses on unifying two of the most widely used link-formation models: the\nstochastic blockmodel (SBM) and the small world (or latent space) model (SWM).\nIntegrating techniques from kernel learning, spectral graph theory, and\nnonlinear dimensionality reduction, we develop the first statistically sound\npolynomial-time algorithm to discover latent patterns in sparse graphs for both\nmodels. When the network comes from an SBM, the algorithm outputs a block\nstructure. When it is from an SWM, the algorithm outputs estimates of each\nnode's latent position.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sources of inter-model scatter in TRACMIP, the Tropical Rain belts with an Annual cycle and a Continent Model Intercomparison Project.   We analyze the source of inter-model scatter in the surface temperature\nresponse to quadrupling CO2 in two sets of GCM simulations from the Tropical\nRain Belts with an Annual cycle and a Continent Model Intercomparison Project\n(TRACMIP; Voigt et al, 2016). TRACMIP provides simulations of idealized\nclimates that allow for studying the fundamental dynamics of tropical rainfall\nand its response to climate change. One configuration is an aquaplanet\natmosphere (i.e., with zonally-symmetric boundary conditions) coupled to a slab\nocean (AquaCTL and Aqua4x). The other includes an equatorial continent\nrepresented by a thin slab ocean with increased surface albedo and decreased\nevaporation (LandCTL and Land4x).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ternary and $n$-ary $f$-distributive Structures.   We introduce and study ternary $f$-distributive structures, Ternary\n$f$-quandles and more generally their higher $n$-ary analogues. A\nclassification of ternary $f$-quandles is provided in low dimensions. Moreover,\nwe study extension theory and introduce a cohomology theory for ternary, and\nmore generally $n$-ary, $f$-quandles. Furthermore, we give some computational\nexamples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Calibrated Fairness in Bandits.   We study fairness within the stochastic, \\emph{multi-armed bandit} (MAB)\ndecision making framework. We adapt the fairness framework of \"treating similar\nindividuals similarly\" to this setting. Here, an `individual' corresponds to an\narm and two arms are `similar' if they have a similar quality distribution.\nFirst, we adopt a {\\em smoothness constraint} that if two arms have a similar\nquality distribution then the probability of selecting each arm should be\nsimilar. In addition, we define the {\\em fairness regret}, which corresponds to\nthe degree to which an algorithm is not calibrated, where perfect calibration\nrequires that the probability of selecting an arm is equal to the probability\nwith which the arm has the best quality realization. We show that a variation\non Thompson sampling satisfies smooth fairness for total variation distance,\nand give an $\\tilde{O}((kT)^{2/3})$ bound on fairness regret. This complements\nprior work, which protects an on-average better arm from being less favored. We\nalso explain how to extend our algorithm to the dueling bandit setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quivers with potentials for cluster varieties associated to braid semigroups.   Let $C$ be a simply laced generalized Cartan matrix. Given an element $b$ of\nthe generalized braid semigroup related to $C$, we construct a collection of\nmutation-equivalent quivers with potentials. A quiver with potential in such a\ncollection corresponds to an expression of $b$ in terms of the standard\ngenerators. For two expressions that differ by a braid relation, the\ncorresponding quivers with potentials are related by a mutation.\nThe main application of this result is a construction of a family of $CY_3$\n$A_\\infty$-categories associated to elements of the braid semigroup related to\n$C$. In particular, we construct a canonical up to equivalence $CY_3$\n$A_\\infty$-category associated to quotient of any Double Bruhat cell\n$G^{u,v}/{\\rm Ad} H$ in a simply laced reductive Lie group $G$.\nWe describe the full set of parameters these categories depend on by defining\na 2-dimensional CW-complex and proving that the set of parameters is identified\nwith second cohomology group of this complex.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scraping and Preprocessing Commercial Auction Data for Fraud Classification.   In the last three decades, we have seen a significant increase in trading\ngoods and services through online auctions. However, this business created an\nattractive environment for malicious moneymakers who can commit different types\nof fraud activities, such as Shill Bidding (SB). The latter is predominant\nacross many auctions but this type of fraud is difficult to detect due to its\nsimilarity to normal bidding behaviour. The unavailability of SB datasets makes\nthe development of SB detection and classification models burdensome.\nFurthermore, to implement efficient SB detection models, we should produce SB\ndata from actual auctions of commercial sites. In this study, we first scraped\na large number of eBay auctions of a popular product. After preprocessing the\nraw auction data, we build a high-quality SB dataset based on the most reliable\nSB strategies. The aim of our research is to share the preprocessed auction\ndataset as well as the SB training (unlabelled) dataset, thereby researchers\ncan apply various machine learning techniques by using authentic data of\nauctions and fraud.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Proton-induced halo formation in charged meteors.   Despite a very long history of meteor science, our understanding of meteor\nablation and its shocked plasma physics is still far from satisfactory as we\nare still missing the microphysics of meteor shock formation and its plasma\ndynamics. Here we argue that electrons and ions in the meteor plasma above\n$\\sim$100 km altitude undergo spatial separation due to electrons being trapped\nby gyration in the Earth's magnetic field, while the ions are carried by the\nmeteor as their dynamics is dictated by collisions. This separation process\ncharges the meteor and creates a strong local electric field. We show how\nacceleration of protons in this field leads to the collisional excitation of\nionospheric N$_2$ on the scale of many 100 m. This mechanism explains the\npuzzling large halo detected around Leonid meteors, while it also fits into the\ntheoretical expectations of several other unexplained meteor related phenomena.\nWe expect our work to lead to more advanced models of meteor-ionosphere\ninteraction, combined with the electrodynamics of meteor trail evolution.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Decentralized Tube-based Model Predictive Control of Uncertain Nonlinear Multi-Agent Systems.   This paper addresses the problem of decentralized tube-based nonlinear Model\nPredictive Control (NMPC) for a class of uncertain nonlinear continuous-time\nmulti-agent systems with additive and bounded disturbance. In particular, the\nproblem of robust navigation of a multi-agent system to predefined states of\nthe workspace while using only local information is addressed, under certain\ndistance and control input constraints. We propose a decentralized feedback\ncontrol protocol that consists of two terms: a nominal control input, which is\ncomputed online and is the outcome of a Decentralized Finite Horizon Optimal\nControl Problem (DFHOCP) that each agent solves at every sampling time, for its\nnominal system dynamics; and an additive state feedback law which is computed\noffline and guarantees that the real trajectories of each agent will belong to\na hyper-tube centered along the nominal trajectory, for all times. The volume\nof the hyper-tube depends on the upper bound of the disturbances as well as the\nbounds of the derivatives of the dynamics. In addition, by introducing certain\ndistance constraints, the proposed scheme guarantees that the initially\nconnected agents remain connected for all times. Under standard assumptions\nthat arise in nominal NMPC schemes, controllability assumptions as well as\ncommunication capabilities between the agents, we guarantee that the\nmulti-agent system is ISS (Input to State Stable) with respect to the\ndisturbances, for all initial conditions satisfying the state constraints.\nSimulation results verify the correctness of the proposed framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Switching divergences for spectral learning in blind speech dereverberation.   When recorded in an enclosed room, a sound signal will most certainly get\naffected by reverberation. This not only undermines audio quality, but also\nposes a problem for many human-machine interaction technologies that use speech\nas their input. In this work, a new blind, two-stage dereverberation approach\nbased in a generalized \\beta-divergence as a fidelity term over a non-negative\nrepresentation is proposed. The first stage consists of learning the spectral\nstructure of the signal solely from the observed spectrogram, while the second\nstage is devoted to model reverberation. Both steps are taken by minimizing a\ncost function in which the aim is put either in constructing a dictionary or a\ngood representation by changing the divergence involved. In addition, an\napproach for finding an optimal fidelity parameter for dictionary learning is\nproposed. An algorithm for implementing the proposed method is described and\ntested against state-of-the-art methods. Results show improvements for both\nartificial reverberation and real recordings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "First results from the IllustrisTNG simulations: the stellar mass content of groups and clusters of galaxies.   The IllustrisTNG project is a new suite of cosmological\nmagneto-hydrodynamical simulations of galaxy formation performed with the Arepo\ncode and updated models for feedback physics. Here we introduce the first two\nsimulations of the series, TNG100 and TNG300, and quantify the stellar mass\ncontent of about 4000 massive galaxy groups and clusters ($10^{13} \\leq M_{\\rm\n200c}/M_{\\rm sun} \\leq 10^{15}$) at recent times ($z \\leq 1$). The richest\nclusters have half of their total stellar mass bound to satellite galaxies,\nwith the other half being associated with the central galaxy and the diffuse\nintra-cluster light. The exact ICL fraction depends sensitively on the\ndefinition of a central galaxy's mass and varies in our most massive clusters\nbetween 20 to 40% of the total stellar mass. Haloes of $5\\times 10^{14}M_{\\rm\nsun}$ and above have more diffuse stellar mass outside 100 kpc than within 100\nkpc, with power-law slopes of the radial mass density distribution as shallow\nas the dark matter's ( $-3.5 < \\alpha_{\\rm 3D} < -3$). Total halo mass is a\nvery good predictor of stellar mass, and vice versa: at $z=0$, the 3D stellar\nmass measured within 30 kpc scales as $\\propto (M_{\\rm 500c})^{0.49}$ with a\n$\\sim 0.12$ dex scatter. This is possibly too steep in comparison to the\navailable observational constraints, even though the abundance of TNG less\nmassive galaxies ($< 10^{11}M_{\\rm sun}$ in stars) is in good agreement with\nthe measured galaxy stellar mass functions at recent epochs. The 3D sizes of\nmassive galaxies fall too on a tight ($\\sim$0.16 dex scatter) power-law\nrelation with halo mass, with $r^{\\rm stars}_{\\rm 0.5} \\propto (M_{\\rm\n500c})^{0.53}$. Even more fundamentally, halo mass alone is a good predictor\nfor the whole stellar mass profiles beyond the inner few kpc, and we show how\non average these can be precisely recovered given a single mass measurement of\nthe galaxy or its halo.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Quasinonexpansive Iterations on the Affine Hull of Orbits: From Mann's Mean Value Algorithm to Inertial Methods.   Fixed point iterations play a central role in the design and the analysis of\na large number of optimization algorithms. We study a new iterative scheme in\nwhich the update is obtained by applying a composition of quasinonexpansive\noperators to a point in the affine hull of the orbit generated up to the\ncurrent iterate. This investigation unifies several algorithmic constructs,\nincluding Mann's mean value method, inertial methods, and multi-layer\nmemoryless methods. It also provides a framework for the development of new\nalgorithms, such as those we propose for solving monotone inclusion and\nminimization problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strong electron-hole symmetric Rashba spin-orbit coupling in graphene/monolayer transition metal dichalcogenide heterostructures.   Despite its extremely weak intrinsic spin-orbit coupling (SOC), graphene has\nbeen shown to acquire considerable SOC by proximity coupling with exfoliated\ntransition metal dichalcogenides (TMDs). Here we demonstrate strong induced\nRashba SOC in graphene that is proximity coupled to a monolayer TMD film, MoS2\nor WSe2, grown by chemical vapor deposition with drastically different Fermi\nlevel positions. Graphene/TMD heterostructures are fabricated with a\npickup-transfer technique utilizing hexagonal boron nitride, which serves as a\nflat template to promote intimate contact and therefore a strong interfacial\ninteraction between TMD and graphene as evidenced by quenching of the TMD\nphotoluminescence. We observe strong induced graphene SOC that manifests itself\nin a pronounced weak anti-localization (WAL) effect in the graphene\nmagnetoconductance. The spin relaxation rate extracted from the WAL analysis\nvaries linearly with the momentum scattering time and is independent of the\ncarrier type. This indicates a dominantly Dyakonov-Perel spin relaxation\nmechanism caused by the induced Rashba SOC. Our analysis yields a Rashba SOC\nenergy of ~1.5 meV in graphene/WSe2 and ~0.9 meV in graphene/MoS2,\nrespectively. The nearly electron-hole symmetric nature of the induced Rashba\nSOC provides a clue to possible underlying SOC mechanisms.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Enhanced Network Embeddings via Exploiting Edge Labels.   Network embedding methods aim at learning low-dimensional latent\nrepresentation of nodes in a network. While achieving competitive performance\non a variety of network inference tasks such as node classification and link\nprediction, these methods treat the relations between nodes as a binary\nvariable and ignore the rich semantics of edges. In this work, we attempt to\nlearn network embeddings which simultaneously preserve network structure and\nrelations between nodes. Experiments on several real-world networks illustrate\nthat by considering different relations between different node pairs, our\nmethod is capable of producing node embeddings of higher quality than a number\nof state-of-the-art network embedding methods, as evaluated on a challenging\nmulti-label node classification task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Group Field theory and Tensor Networks: towards a Ryu-Takayanagi formula in full quantum gravity.   We establish a dictionary between group field theory (thus, spin networks and\nrandom tensors) states and generalized random tensor networks. Then, we use\nthis dictionary to compute the Rényi entropy of such states and recover the\nRyu-Takayanagi formula, in two different cases corresponding to two different\ntruncations/approximations, suggested by the established correspondence.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Graph Convolutional Networks for Classification with a Structured Label Space.   It is a usual practice to ignore any structural information underlying\nclasses in multi-class classification. In this paper, we propose a graph\nconvolutional network (GCN) augmented neural network classifier to exploit a\nknown, underlying graph structure of labels. The proposed approach resembles an\n(approximate) inference procedure in, for instance, a conditional random field\n(CRF). We evaluate the proposed approach on document classification and object\nrecognition and report both accuracies and graph-theoretic metrics that\ncorrespond to the consistency of the model's prediction. The experiment results\nreveal that the proposed model outperforms a baseline method which ignores the\ngraph structures of a label space in terms of graph-theoretic metrics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Virtual Constraints and Hybrid Zero Dynamics for Realizing Underactuated Bipedal Locomotion.   Underactuation is ubiquitous in human locomotion and should be ubiquitous in\nbipedal robotic locomotion as well. This chapter presents a coherent theory for\nthe design of feedback controllers that achieve stable walking gaits in\nunderactuated bipedal robots. Two fundamental tools are introduced, virtual\nconstraints and hybrid zero dynamics. Virtual constraints are relations on the\nstate variables of a mechanical model that are imposed through a time-invariant\nfeedback controller. One of their roles is to synchronize the robot's joints to\nan internal gait phasing variable. A second role is to induce a low dimensional\nsystem, the zero dynamics, that captures the underactuated aspects of a robot's\nmodel, without any approximations. To enhance intuition, the relation between\nphysical constraints and virtual constraints is first established. From here,\nthe hybrid zero dynamics of an underactuated bipedal model is developed, and\nits fundamental role in the design of asymptotically stable walking motions is\nestablished. The chapter includes numerous references to robots on which the\nhighlighted techniques have been implemented.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effects of Interactions on Dynamic Correlations of Hard-Core Bosons at Finite Temperatures.   We investigate how dynamic correlations of hard-core bosonic excitation at\nfinite temperature are affected by additional interactions besides the\nhard-core repulsion which prevents them from occupying the same site. We focus\nespecially on dimerized spin systems, where these additional interactions\nbetween the elementary excitations, triplons, lead to the formation of bound\nstates, relevant for the correct description of scattering processes. In order\nto include these effects quantitatively we extend the previously developed\nBrückner approach to include also nearest-neighbor (NN) and next-nearest\nneighbor (NNN) interactions correctly in a low-temperature expansion. This\nleads to the extension of the scalar Bethe-Salpeter equation to a matrix-valued\nequation. Exemplarily, we consider the Heisenberg spin ladder to illustrate the\nsignificance of the additional interactions on the spectral functions at finite\ntemperature which are proportional to inelastic neutron scattering rates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The SLUGGS Survey: Dark matter fractions at large radii and assembly epochs of early-type galaxies from globular cluster kinematics.   We use globular cluster kinematics data, primarily from the SLUGGS survey, to\nmeasure the dark matter fraction ($f_{\\rm DM}$) and the average dark matter\ndensity ($\\left< \\rho_{\\rm DM} \\right>$) within the inner 5 effective radii\n($R_{\\rm e}$) for 32 nearby early--type galaxies (ETGs) with stellar mass log\n$(M_*/\\rm M_\\odot)$ ranging from $10.1$ to $11.8$. We compare our results with\na simple galaxy model based on scaling relations as well as with cosmological\nhydrodynamical simulations where the dark matter profile has been modified\nthrough various physical processes.\nWe find a high $f_{\\rm DM}$ ($\\geq0.6$) within 5~$R_{\\rm e}$ in most of our\nsample, which we interpret as a signature of a late mass assembly history that\nis largely devoid of gas-rich major mergers. However, around log $(M_*/M_\\odot)\n\\sim 11$, there is a wide range of $f_{\\rm DM}$ which may be challenging to\nexplain with any single cosmological model. We find tentative evidence that\nlenticulars (S0s), unlike ellipticals, have mass distributions that are similar\nto spiral galaxies, with decreasing $f_{\\rm DM}$ within 5~$R_{\\rm e}$ as galaxy\nluminosity increases. However, we do not find any difference between the\n$\\left< \\rho_{\\rm DM} \\right>$ of S0s and ellipticals in our sample, despite\nthe differences in their stellar populations. We have also used $\\left<\n\\rho_{\\rm DM} \\right>$ to infer the epoch of halo assembly ($z{\\sim}2-4$). By\ncomparing the age of their central stars with the inferred epoch of halo\nformation, we are able to gain more insight into their mass assembly histories.\nOur results suggest a fundamental difference in the dominant late-phase mass\nassembly channel between lenticulars and elliptical galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A SAT+CAS Approach to Finding Good Matrices: New Examples and Counterexamples.   We enumerate all circulant good matrices with odd orders divisible by 3 up to\norder 70. As a consequence of this we find a previously overlooked set of good\nmatrices of order 27 and a new set of good matrices of order 57. We also find\nthat circulant good matrices do not exist in the orders 51, 63, and 69, thereby\nfinding three new counterexamples to the conjecture that such matrices exist in\nall odd orders. Additionally, we prove a new relationship between the entries\nof good matrices and exploit this relationship in our enumeration algorithm.\nOur method applies the SAT+CAS paradigm of combining computer algebra\nfunctionality with modern SAT solvers to efficiently search large spaces which\nare specified by both algebraic and logical constraints.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Support Feature Machines.   Support Vector Machines (SVMs) with various kernels have played dominant role\nin machine learning for many years, finding numerous applications. Although\nthey have many attractive features interpretation of their solutions is quite\ndifficult, the use of a single kernel type may not be appropriate in all areas\nof the input space, convergence problems for some kernels are not uncommon, the\nstandard quadratic programming solution has $O(m^3)$ time and $O(m^2)$ space\ncomplexity for $m$ training patterns. Kernel methods work because they\nimplicitly provide new, useful features. Such features, derived from various\nkernels and other vector transformations, may be used directly in any machine\nlearning algorithm, facilitating multiresolution, heterogeneous models of data.\nTherefore Support Feature Machines (SFM) based on linear models in the extended\nfeature spaces, enabling control over selection of support features, give at\nleast as good results as any kernel-based SVMs, removing all problems related\nto interpretation, scaling and convergence. This is demonstrated for a number\nof benchmark datasets analyzed with linear discrimination, SVM, decision trees\nand nearest neighbor methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Social Events in a Time-Varying Mobile Phone Graph.   The large-scale study of human mobility has been significantly enhanced over\nthe last decade by the massive use of mobile phones in urban populations.\nStudying the activity of mobile phones allows us, not only to infer social\nnetworks between individuals, but also to observe the movements of these\nindividuals in space and time. In this work, we investigate how these two\nrelated sources of information can be integrated within the context of\ndetecting and analyzing large social events. We show that large social events\ncan be characterized not only by an anomalous increase in activity of the\nantennas in the neighborhood of the event, but also by an increase in social\nrelationships of the attendants present in the event. Moreover, having detected\na large social event via increased antenna activity, we can use the network\nconnections to infer whether an unobserved user was present at the event. More\nprecisely, we address the following three challenges: (i) automatically\ndetecting large social events via increased antenna activity; (ii)\ncharacterizing the social cohesion of the detected event; and (iii) analyzing\nthe feasibility of inferring whether unobserved users were in the event.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Towards Efficient Verification of Population Protocols.   Population protocols are a well established model of computation by\nanonymous, identical finite state agents. A protocol is well-specified if from\nevery initial configuration, all fair executions reach a common consensus. The\ncentral verification question for population protocols is the\nwell-specification problem: deciding if a given protocol is well-specified.\nEsparza et al. have recently shown that this problem is decidable, but with\nvery high complexity: it is at least as hard as the Petri net reachability\nproblem, which is EXPSPACE-hard, and for which only algorithms of non-primitive\nrecursive complexity are currently known.\nIn this paper we introduce the class WS3 of well-specified strongly-silent\nprotocols and we prove that it is suitable for automatic verification. More\nprecisely, we show that WS3 has the same computational power as general\nwell-specified protocols, and captures standard protocols from the literature.\nMoreover, we show that the membership problem for WS3 reduces to solving\nboolean combinations of linear constraints over N. This allowed us to develop\nthe first software able to automatically prove well-specification for all of\nthe infinitely many possible inputs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analytical solution of the integral equation for partial wave Coulomb t-matrices at excited-state energy.   Starting from the integral representation of the three-dimensional Coulomb\ntransition matrix elaborated by us formerly with the use of specific symmetry\nof the interaction in a four-dimensional Euclidean space introduced by Fock,\nthe possibility of the analytical solving of the integral equation for the\npartial wave transition matrices at the excited bound state energy has been\nstudied. New analytical expressions for the partial s-, p- and d-wave Coulomb\nt-matrices for like-charged particles and the expression for the partial d-wave\nt-matrix for unlike-charged particles at the energy of the first excited bound\nstate have been derived.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Wave-Shaped Round Functions and Primitive Groups.   Round functions used as building blocks for iterated block ciphers, both in\nthe case of Substitution-Permutation Networks and Feistel Networks, are often\nobtained as the composition of different layers which provide confusion and\ndiffusion, and key additions. The bijectivity of any encryption function,\ncrucial in order to make the decryption possible, is guaranteed by the use of\ninvertible layers or by the Feistel structure. In this work a new family of\nciphers, called wave ciphers, is introduced. In wave ciphers, round functions\nfeature wave functions, which are vectorial Boolean functions obtained as the\ncomposition of non-invertible layers, where the confusion layer enlarges the\nmessage which returns to its original size after the diffusion layer is\napplied. This is motivated by the fact that relaxing the requirement that all\nthe layers are invertible allows to consider more functions which are optimal\nwith regard to non-linearity. In particular it allows to consider injective APN\nS-boxes. In order to guarantee efficient decryption we propose to use wave\nfunctions in Feistel Networks. With regard to security, the immunity from some\ngroup-theoretical attacks is investigated. In particular, it is shown how to\navoid that the group generated by the round functions acts imprimitively, which\nrepresent a serious flaw for the cipher.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Occupants in simplicial complexes.   Let $M$ be a smooth manifold and $K\\subset M$ be a simplicial complex of\ncodimension at least 3. Functor calculus methods lead to a homotopical formula\nof $M\\setminus K$ in terms of spaces $M\\setminus T$ where $T$ is a finite\nsubset of $K$. This is a generalization of the author's previous work with\nMichael Weiss where the subset $K$ is assumed to be a smooth submanifold of $M$\nand uses his generalization of manifold calculus adapted for simplicial\ncomplexes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "It's Like Python But: Towards Supporting Transfer of Programming Language Knowledge.   Expertise in programming traditionally assumes a binary novice-expert divide.\nLearning resources typically target programmers who are learning programming\nfor the first time, or expert programmers for that language. An\nunderrepresented, yet important group of programmers are those that are\nexperienced in one programming language, but desire to author code in a\ndifferent language. For this scenario, we postulate that an effective form of\nfeedback is presented as a transfer from concepts in the first language to the\nsecond. Current programming environments do not support this form of feedback.\nIn this study, we apply the theory of learning transfer to teach a language\nthat programmers are less familiar with--such as R--in terms of a programming\nlanguage they already know--such as Python. We investigate learning transfer\nusing a new tool called Transfer Tutor that presents explanations for R code in\nterms of the equivalent Python code. Our study found that participants\nleveraged learning transfer as a cognitive strategy, even when unprompted.\nParticipants found Transfer Tutor to be useful across a number of affordances\nlike stepping through and highlighting facts that may have been missed or\nmisunderstood. However, participants were reluctant to accept facts without\ncode execution or sometimes had difficulty reading explanations that are\nverbose or complex. These results provide guidance for future designs and\nresearch directions that can support learning transfer when learning new\nprogramming languages.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the relevance of generalized disclinations in defect mechanics.   The utility of the notion of generalized disclinations in materials science\nis discussed within the physical context of modeling interfacial and bulk line\ndefects like defected grain and phase boundaries, dislocations and\ndisclinations. The Burgers vector of a disclination dipole in linear elasticity\nis derived, clearly demonstrating the equivalence of its stress field to that\nof an edge dislocation. We also prove that the inverse deformation/displacement\njump of a defect line is independent of the cut-surface when its g.disclination\nstrength vanishes. An explicit formula for the displacement jump of a single\nlocalized composite defect line in terms of given g.disclination and\ndislocation strengths is deduced based on the Weingarten theorem for\ng.disclination theory (Weingarten-gd theorem) at finite deformation. The\nBurgers vector of a g.disclination dipole at finite deformation is also\nderived.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "DFTerNet: Towards 2-bit Dynamic Fusion Networks for Accurate Human Activity Recognition.   Deep Convolutional Neural Networks (DCNNs) are currently popular in human\nactivity recognition applications. However, in the face of modern artificial\nintelligence sensor-based games, many research achievements cannot be\npractically applied on portable devices. DCNNs are typically resource-intensive\nand too large to be deployed on portable devices, thus this limits the\npractical application of complex activity detection. In addition, since\nportable devices do not possess high-performance Graphic Processing Units\n(GPUs), there is hardly any improvement in Action Game (ACT) experience.\nBesides, in order to deal with multi-sensor collaboration, all previous human\nactivity recognition models typically treated the representations from\ndifferent sensor signal sources equally. However, distinct types of activities\nshould adopt different fusion strategies. In this paper, a novel scheme is\nproposed. This scheme is used to train 2-bit Convolutional Neural Networks with\nweights and activations constrained to {-0.5,0,0.5}. It takes into account the\ncorrelation between different sensor signal sources and the activity types.\nThis model, which we refer to as DFTerNet, aims at producing a more reliable\ninference and better trade-offs for practical applications. Our basic idea is\nto exploit quantization of weights and activations directly in pre-trained\nfilter banks and adopt dynamic fusion strategies for different activity types.\nExperiments demonstrate that by using dynamic fusion strategy can exceed the\nbaseline model performance by up to ~5% on activity recognition like\nOPPORTUNITY and PAMAP2 datasets. Using the quantization method proposed, we\nwere able to achieve performances closer to that of full-precision counterpart.\nThese results were also verified using the UniMiB-SHAR dataset. In addition,\nthe proposed method can achieve ~9x acceleration on CPUs and ~11x memory\nsaving.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Susceptibility Propagation by Using Diagonal Consistency.   A susceptibility propagation that is constructed by combining a belief\npropagation and a linear response method is used for approximate computation\nfor Markov random fields. Herein, we formulate a new, improved susceptibility\npropagation by using the concept of a diagonal matching method that is based on\nmean-field approaches to inverse Ising problems. The proposed susceptibility\npropagation is robust for various network structures, and it is reduced to the\nordinary susceptibility propagation and to the adaptive\nThouless-Anderson-Palmer equation in special cases.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Direct simulation of liquid-gas-solid flow with a free surface lattice Boltzmann method.   Direct numerical simulation of liquid-gas-solid flows is uncommon due to the\nconsiderable computational cost. As the grid spacing is determined by the\nsmallest involved length scale, large grid sizes become necessary -- in\nparticular if the bubble-particle aspect ratio is on the order of 10 or larger.\nHence, it arises the question of both feasibility and reasonability. In this\npaper, we present a fully parallel, scalable method for direct numerical\nsimulation of bubble-particle interaction at a size ratio of 1-2 orders of\nmagnitude that makes simulations feasible on currently available\nsuper-computing resources. With the presented approach, simulations of bubbles\nin suspension columns consisting of more than $100\\,000$ fully resolved\nparticles become possible. Furthermore, we demonstrate the significance of\nparticle-resolved simulations by comparison to previous unresolved solutions.\nThe results indicate that fully-resolved direct numerical simulation is indeed\nnecessary to predict the flow structure of bubble-particle interaction problems\ncorrectly.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Pair Correlation and Gap Distributions for Substitution Tilings and Generalized Ulam Sets in the Plane.   We study empirical statistical and gap distributions of several important\ntilings of the plane. In particular, we consider the slope distributions, the\nangle distributions, pair correlation, squared-distance pair correlation, angle\ngap distributions, and slope gap distributions for the Ammann Chair tiling, the\nrecently discovered fifteenth pentagonal tiling, and a few pertinent tilings\nrelated to these famous examples. We also consider the spatial statistics of\ngeneralized Ulam sets in two dimensions. Additionally, we carefully prove a\ntight asymptotic formula for the time steps in which Ulam set points at certain\nprescribed geometric positions in their plots in the plane formally enter the\nrecursively-defined sets.\nThe software we have developed to these generate numerical approximations to\nthe distributions for the tilings we consider here is written in Python under\nthe Sage environment and is released as open-source software which is available\nfreely on our websites. In addition to the small subset of tilings and other\npoint sets in the plane we study within the article, our program supports many\nother tiling variants and is easily extended for researchers to explore related\ntilings and iterative sets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interferometric Monitoring of Gamma-ray Bright AGNs: S5 0716+714.   We present the results of very long baseline interferometry (VLBI)\nobservations of gamma-ray bright blazar S5 0716+714 using the Korean VLBI\nNetwork (KVN) at the 22, 43, 86, and 129 GHz bands, as part of the\nInterferometric Monitoring of Gamma-ray Bright AGNs (iMOGABA) KVN key science\nprogram. Observations were conducted in 29 sessions from January 16, 2013 to\nMarch 1, 2016, with the source being detected and imaged at all available\nfrequencies. In all epochs, the source was compact on the milliarcsecond (mas)\nscale, yielding a compact VLBI core dominating the synchrotron emission on\nthese scales. Based on the multi-wavelength data between 15 GHz (Owens Valley\nRadio Observatory) and 230 GHz (Submillimeter Array), we found that the source\nshows multiple prominent enhancements of the flux density at the centimeter\n(cm) and millimeter (mm) wavelengths, with mm enhancements leading cm\nenhancements by -16$\\pm$8 days. The turnover frequency was found to vary\nbetween 21 to 69GHz during our observations. By assuming a synchrotron\nself-absorption model for the relativistic jet emission in S5 0716+714, we\nfound the magnetic field strength in the mas emission region to be $\\le$5 mG\nduring the observing period, yielding a weighted mean of 1.0$\\pm$0.6 mG for\nhigher turnover frequencies (e.g., >45 GHz).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Gross-Hopkins Duals of Higher Real K-theory Spectra.   We determine the Gross-Hopkins duals of certain higher real K-theory spectra.\nMore specifically, let p be an odd prime, and consider the Morava E-theory\nspectrum of height n=p-1. It is known, in the expert circles, that for certain\nfinite subgroups G of the Morava stabilizer group, the homotopy fixed point\nspectra E_n^{hG} are Gross-Hopkins self-dual up to a shift. In this paper, we\ndetermine the shift for those finite subgroups G which contain p-torsion. This\ngeneralizes previous results for n=2 and p=3.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Measuring LDA Topic Stability from Clusters of Replicated Runs.   Background: Unstructured and textual data is increasing rapidly and Latent\nDirichlet Allocation (LDA) topic modeling is a popular data analysis methods\nfor it. Past work suggests that instability of LDA topics may lead to\nsystematic errors. Aim: We propose a method that relies on replicated LDA runs,\nclustering, and providing a stability metric for the topics. Method: We\ngenerate k LDA topics and replicate this process n times resulting in n*k\ntopics. Then we use K-medioids to cluster the n*k topics to k clusters. The k\nclusters now represent the original LDA topics and we present them like normal\nLDA topics showing the ten most probable words. For the clusters, we try\nmultiple stability metrics, out of which we recommend Rank-Biased Overlap,\nshowing the stability of the topics inside the clusters. Results: We provide an\ninitial validation where our method is used for 270,000 Mozilla Firefox commit\nmessages with k=20 and n=20. We show how our topic stability metrics are\nrelated to the contents of the topics. Conclusions: Advances in text mining\nenable us to analyze large masses of text in software engineering but\nnon-deterministic algorithms, such as LDA, may lead to unreplicable\nconclusions. Our approach makes LDA stability transparent and is also\ncomplementary rather than alternative to many prior works that focus on LDA\nparameter tuning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Model Agnostic Time Series Analysis via Matrix Estimation.   We propose an algorithm to impute and forecast a time series by transforming\nthe observed time series into a matrix, utilizing matrix estimation to recover\nmissing values and de-noise observed entries, and performing linear regression\nto make predictions. At the core of our analysis is a representation result,\nwhich states that for a large model class, the transformed time series matrix\nis (approximately) low-rank. In effect, this generalizes the widely used\nSingular Spectrum Analysis (SSA) in time series literature, and allows us to\nestablish a rigorous link between time series analysis and matrix estimation.\nThe key to establishing this link is constructing a Page matrix with\nnon-overlapping entries rather than a Hankel matrix as is commonly done in the\nliterature (e.g., SSA). This particular matrix structure allows us to provide\nfinite sample analysis for imputation and prediction, and prove the asymptotic\nconsistency of our method. Another salient feature of our algorithm is that it\nis model agnostic with respect to both the underlying time dynamics and the\nnoise distribution in the observations. The noise agnostic property of our\napproach allows us to recover the latent states when only given access to noisy\nand partial observations a la a Hidden Markov Model; e.g., recovering the\ntime-varying parameter of a Poisson process without knowing that the underlying\nprocess is Poisson. Furthermore, since our forecasting algorithm requires\nregression with noisy features, our approach suggests a matrix estimation based\nmethod - coupled with a novel, non-standard matrix estimation error metric - to\nsolve the error-in-variable regression problem, which could be of interest in\nits own right. Through synthetic and real-world datasets, we demonstrate that\nour algorithm outperforms standard software packages (including R libraries) in\nthe presence of missing data as well as high levels of noise.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Balanced Quantization: An Effective and Efficient Approach to Quantized Neural Networks.   Quantized Neural Networks (QNNs), which use low bitwidth numbers for\nrepresenting parameters and performing computations, have been proposed to\nreduce the computation complexity, storage size and memory usage. In QNNs,\nparameters and activations are uniformly quantized, such that the\nmultiplications and additions can be accelerated by bitwise operations.\nHowever, distributions of parameters in Neural Networks are often imbalanced,\nsuch that the uniform quantization determined from extremal values may under\nutilize available bitwidth. In this paper, we propose a novel quantization\nmethod that can ensure the balance of distributions of quantized values. Our\nmethod first recursively partitions the parameters by percentiles into balanced\nbins, and then applies uniform quantization. We also introduce computationally\ncheaper approximations of percentiles to reduce the computation overhead\nintroduced. Overall, our method improves the prediction accuracies of QNNs\nwithout introducing extra computation during inference, has negligible impact\non training speed, and is applicable to both Convolutional Neural Networks and\nRecurrent Neural Networks. Experiments on standard datasets including ImageNet\nand Penn Treebank confirm the effectiveness of our method. On ImageNet, the\ntop-5 error rate of our 4-bit quantized GoogLeNet model is 12.7\\%, which is\nsuperior to the state-of-the-arts of QNNs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "CODA: Enabling Co-location of Computation and Data for Near-Data Processing.   Recent studies have demonstrated that near-data processing (NDP) is an\neffective technique for improving performance and energy efficiency of\ndata-intensive workloads. However, leveraging NDP in realistic systems with\nmultiple memory modules introduces a new challenge. In today's systems, where\nno computation occurs in memory modules, the physical address space is\ninterleaved at a fine granularity among all memory modules to help improve the\nutilization of processor-memory interfaces by distributing the memory traffic.\nHowever, this is at odds with efficient use of NDP, which requires careful\nplacement of data in memory modules such that near-data computations and their\nexclusively used data can be localized in individual memory modules, while\ndistributing shared data among memory modules to reduce hotspots. In order to\naddress this new challenge, we propose a set of techniques that (1) enable\ncollections of OS pages to either be fine-grain interleaved among memory\nmodules (as is done today) or to be placed contiguously on individual memory\nmodules (as is desirable for NDP private data), and (2) decide whether to\nlocalize or distribute each memory object based on its anticipated access\npattern and steer computations to the memory where the data they access is\nlocated. Our evaluations across a wide range of workloads show that the\nproposed mechanism improves performance by 31% and reduces 38% remote data\naccesses over a baseline system that cannot exploit computate-data affinity\ncharacteristics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scalable Inference for Nested Chinese Restaurant Process Topic Models.   Nested Chinese Restaurant Process (nCRP) topic models are powerful\nnonparametric Bayesian methods to extract a topic hierarchy from a given text\ncorpus, where the hierarchical structure is automatically determined by the\ndata. Hierarchical Latent Dirichlet Allocation (hLDA) is a popular instance of\nnCRP topic models. However, hLDA has only been evaluated at small scale,\nbecause the existing collapsed Gibbs sampling and instantiated weight\nvariational inference algorithms either are not scalable or sacrifice inference\nquality with mean-field assumptions. Moreover, an efficient distributed\nimplementation of the data structures, such as dynamically growing count\nmatrices and trees, is challenging.\nIn this paper, we propose a novel partially collapsed Gibbs sampling (PCGS)\nalgorithm, which combines the advantages of collapsed and instantiated weight\nalgorithms to achieve good scalability as well as high model quality. An\ninitialization strategy is presented to further improve the model quality.\nFinally, we propose an efficient distributed implementation of PCGS through\nvectorization, pre-processing, and a careful design of the concurrent data\nstructures and communication strategy.\nEmpirical studies show that our algorithm is 111 times more efficient than\nthe previous open-source implementation for hLDA, with comparable or even\nbetter model quality. Our distributed implementation can extract 1,722 topics\nfrom a 131-million-document corpus with 28 billion tokens, which is 4-5 orders\nof magnitude larger than the previous largest corpus, with 50 machines in 7\nhours.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum Query Algorithms are Completely Bounded Forms.   We prove a characterization of $t$-query quantum algorithms in terms of the\nunit ball of a space of degree-$2t$ polynomials. Based on this, we obtain a\nrefined notion of approximate polynomial degree that equals the quantum query\ncomplexity, answering a question of Aaronson et al. (CCC'16). Our proof is\nbased on a fundamental result of Christensen and Sinclair (J. Funct. Anal.,\n1987) that generalizes the well-known Stinespring representation for quantum\nchannels to multilinear forms. Using our characterization, we show that many\npolynomials of degree four are far from those coming from two-query quantum\nalgorithms. We also give a simple and short proof of one of the results of\nAaronson et al. showing an equivalence between one-query quantum algorithms and\nbounded quadratic polynomials.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Uncertainty Quantification and Information Fusion in CALPHAD-based Thermodynamic Modeling.   Calculation of phase diagrams is one of the fundamental tools in alloy\ndesign---more specifically under the framework of Integrated Computational\nMaterials Engineering. Uncertainty quantification of phase diagrams is the\nfirst step required to provide confidence for decision making in property- or\nperformance-based design. As a manner of illustration, a thorough probabilistic\nassessment of the CALPHAD model parameters is performed against the available\ndata for a Hf-Si binary case study using a Markov Chain Monte Carlo sampling\napproach. The plausible optimum values and uncertainties of the parameters are\nthus obtained, which can be propagated to the resulting phase diagram. Using\nthe parameter values obtained from deterministic optimization in a\ncomputational thermodynamic assessment tool (in this case Thermo-Calc) as the\nprior information for the parameter values and ranges in the sampling process\nis often necessary to achieve a reasonable cost for uncertainty quantification.\nThis brings up the problem of finding an appropriate CALPHAD model with\nhigh-level of confidence which is a very hard and costly task that requires\nconsiderable expert skill. A Bayesian hypothesis testing based on Bayes'\nfactors is proposed to fulfill the need of model selection in this case, which\nis applied to compare four recommended models for the Hf-Si system. However, it\nis demonstrated that information fusion approaches, i.e., Bayesian model\naveraging and an error correlation-based model fusion, can be used to combine\nthe useful information existing in all the given models rather than just using\nthe best selected model, which may lack some information about the system being\nmodelled.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Dichotomy for Digraph Homomorphism Problems (two algorithms).   Update : An issue has been found in the correctness of our algorithm, and we\nare working to resolve the issue. Until a resolution is found, we retract our\nmain claim that our approach gives a combinatorial solution to the CSP\nconjecture. We remain hopeful that we can resolve the issues. We thank Ross\nWillard for carefully checking the algorithm and pointing out the mistake in\nthe version of this manuscript. We briefly explain one issue at the beginning\nof the text, and leave the rest of the manuscript intact for the moment . Ross\nWillard is posting a more involved description of a counter-example to the\nalgorithm in the present manuscript. We have an updated manuscript that\ncorrects some issues while still not arriving at a full solution; we will keep\nthis private as long as unresolved issues remain.\nPrevious abstract : We consider the problem of finding a homomorphism from an\ninput digraph G to a fixed digraph H. We show that if H admits a\nweak-near-unanimity polymorphism $\\phi$ then deciding whether G admits a\nhomomorphism to H (HOM(H)) is polynomial time solvable. This confirms the\nconjecture of Maroti and McKenzie, and consequently implies the validity of the\ncelebrated dichotomy conjecture due to Feder and Vardi. We transform the\nproblem into an instance of the list homomorphism problem where initially all\nthe lists are full (contain all the vertices of H). Then we use the\npolymorphism $\\phi$ as a guide to reduce the lists to singleton lists, which\nyields a homomorphism if one exists.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uniform rank gradient, cost and local-global convergence.   We analyze the rank gradient of finitely generated groups with respect to\nsequences of subgroups of finite index that do not necessarily form a chain, by\nconnecting it to the cost of p.m.p. actions. We generalize several results that\nwere only known for chains before. The connection is made by the notion of\nlocal-global convergence.\nIn particular, we show that for a finitely generated group $\\Gamma$ with\nfixed price $c$, every Farber sequence has rank gradient $c-1$. By adapting\nLackenby's trichotomy theorem to this setting, we also show that in a finitely\npresented amenable group, every sequence of subgroups with index tending to\ninfinity has vanishing rank gradient.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The cauchy problem for radially symmetric homogeneous boltzmann equation with shubin class initial datum and gelfand-shilov smoothing effect.   In this paper, we study the Cauchy problem for radially symmetric homogeneous\nnon-cutoff Boltzmann equation with Maxwellian molecules, the initial datum\nbelongs to Shubin space of the negative index which can be characterized by\nspectral decomposition of the harmonic oscillators. The Shubin space of the\nnegative index contains the measure functions. Based on this spectral\ndecomposition, we construct the weak solution with Shubin class initial datum,\nwe also prove that the Cauchy problem enjoys Gelfand-Shilov smoothing effect,\nmeaning that the smoothing properties are the same as the Cauchy problem\ndefined by the evolution equation associated to a fractional harmonic\noscillator.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Laplace operators on holomorphic Lie algebroids.   The paper introduces Laplace-type operators for functions defined on the\ntangent space of a Finsler Lie algebroid, using a volume form on the\nprolongation of the algebroid. It also presents the construction of a\nhorizontal Laplace operator for forms defined on the prolongation of the\nalgebroid. All of the Laplace operators considered in the paper are also\nlocally expressed using the Chern-Finsler connection of the algebroid.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tunable Optoelectronic Properties of Triply-Bonded Carbon Molecules with Linear and Graphyne Substructures.   In this paper we present a detailed computational study of the electronic\nstructure and optical properties of triply-bonded hydrocarbons with linear, and\ngraphyne substructures, with the aim of identifying their potential in\nopto-electronic device applications. For the purpose, we employed a correlated\nelectron methodology based upon the Pariser-Parr-Pople model Hamiltonian,\ncoupled with the configuration interaction (CI) approach, and studied\nstructures containing up to 42 carbon atoms. Our calculations, based upon\nlarge-scale CI expansions, reveal that the linear structures have intense\noptical absorption at the HOMO-LUMO gap, while the graphyne ones have those at\nhigher energies. Thus, the opto-electronic properties depend on the topology of\nthe {graphyne substructures, suggesting that they can be tuned by means of\nstructural modifications. Our results are in very good agreement with the\navailable experimental data.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Feynman-Kac equation for anomalous processes with space- and time-dependent forces.   Functionals of a stochastic process Y(t) model many physical time-extensive\nobservables, e.g. particle positions, local and occupation times or accumulated\nmechanical work. When Y(t) is a normal diffusive process, their statistics are\nobtained as the solution of the Feynman-Kac equation. This equation provides\nthe crucial link between the expected values of diffusion processes and the\nsolutions of deterministic second-order partial differential equations. When\nY(t) is an anomalous diffusive process, generalizations of the Feynman-Kac\nequation that incorporate power-law or more general waiting time distributions\nof the underlying random walk have recently been derived. A general\nrepresentation of such waiting times is provided in terms of a Lévy process\nwhose Laplace exponent is related to the memory kernel appearing in the\ngeneralized Feynman-Kac equation. The corresponding anomalous processes have\nbeen shown to capture nonlinear mean square displacements exhibiting crossovers\nbetween different scaling regimes, which have been observed in biological\nsystems like migrating cells or diffusing macromolecules in intracellular\nenvironments. However, the case where both space- and time-dependent forces\ndrive the dynamics of the generalized anomalous process has not been solved\nyet. Here, we present the missing derivation of the Feynman-Kac equation in\nsuch general case by using the subordination technique. Furthermore, we discuss\nits extension to functionals explicitly depending on time, which are relevant\nfor the stochastic thermodynamics of anomalous diffusive systems. Exact results\non the work fluctuations of a simple non-equilibrium model are obtained. In\nthis paper we also provide a pedagogical introduction to Lévy processes,\nsemimartingales and their associated stochastic calculus, which underlie the\nmathematical formulation of anomalous diffusion as a subordinated process.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Would You Like to Motivate Software Testers? Ask Them How.   Context. Considering the importance of software testing to the development of\nhigh quality and reliable software systems, this paper aims to investigate how\ncan work-related factors influence the motivation of software testers. Method.\nWe applied a questionnaire that was developed using a previous theory of\nmotivation and satisfaction of software engineers to conduct a survey-based\nstudy to explore and understand how professional software testers perceive and\nvalue work-related factors that could influence their motivation at work.\nResults. With a sample of 80 software testers we observed that software testers\nare strongly motivated by variety of work, creative tasks, recognition for\ntheir work, and activities that allow them to acquire new knowledge, but in\ngeneral the social impact of this activity has low influence on their\nmotivation. Conclusion. This study discusses the difference of opinions among\nsoftware testers, regarding work-related factors that could impact their\nmotivation, which can be relevant for managers and leaders in software\nengineering practice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-locality of the meet levels of the Trotter-Weil Hierarchy.   We prove that the meet level $m$ of the Trotter-Weil, $\\mathsf{V}_m$ is not\nlocal for all $m \\geq 1$, as conjectured in a paper by Kufleitner and Lauser.\nIn order to show this, we explicitly provide a language whose syntactic\nsemigroup is in $L \\mathsf{V}_m$ and not in $\\mathsf{V}_m*\\mathsf{D}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Intelligent Pothole Detection and Road Condition Assessment.   Poor road conditions are a public nuisance, causing passenger discomfort,\ndamage to vehicles, and accidents. In the U.S., road-related conditions are a\nfactor in 22,000 of the 42,000 traffic fatalities each year. Although we often\ncomplain about bad roads, we have no way to detect or report them at scale. To\naddress this issue, we developed a system to detect potholes and assess road\nconditions in real-time. Our solution is a mobile application that captures\ndata on a car's movement from gyroscope and accelerometer sensors in the phone.\nTo assess roads using this sensor data, we trained SVM models to classify road\nconditions with 93% accuracy and potholes with 92% accuracy, beating the base\nrate for both problems. As the user drives, the models use the sensor data to\nclassify whether the road is good or bad, and whether it contains potholes.\nThen, the classification results are used to create data-rich maps that\nillustrate road conditions across the city. Our system will empower civic\nofficials to identify and repair damaged roads which inconvenience passengers\nand cause accidents. This paper details our data science process for collecting\ntraining data on real roads, transforming noisy sensor data into useful\nsignals, training and evaluating machine learning models, and deploying those\nmodels to production through a real-time classification app. It also highlights\nhow cities can use our system to crowdsource data and deliver road repair\nresources to areas in need.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the coefficients of the Alekseev Torossian associator.   This paper explains a method to calculate the coefficients of the\nAlekseev-Torossian associator as linear combinations of iterated integrals of\nKontsevich weight forms of Lie graphs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Training DNNs with Hybrid Block Floating Point.   The wide adoption of DNNs has given birth to unrelenting computing\nrequirements, forcing datacenter operators to adopt domain-specific\naccelerators to train them. These accelerators typically employ densely packed\nfull precision floating-point arithmetic to maximize performance per area.\nOngoing research efforts seek to further increase that performance density by\nreplacing floating-point with fixed-point arithmetic. However, a significant\nroadblock for these attempts has been fixed point's narrow dynamic range, which\nis insufficient for DNN training convergence. We identify block floating point\n(BFP) as a promising alternative representation since it exhibits wide dynamic\nrange and enables the majority of DNN operations to be performed with\nfixed-point logic. Unfortunately, BFP alone introduces several limitations that\npreclude its direct applicability. In this work, we introduce HBFP, a hybrid\nBFP-FP approach, which performs all dot products in BFP and other operations in\nfloating point. HBFP delivers the best of both worlds: the high accuracy of\nfloating point at the superior hardware density of fixed point. For a wide\nvariety of models, we show that HBFP matches floating point's accuracy while\nenabling hardware implementations that deliver up to 8.5x higher throughput.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Framework for Algorithm Stability.   We say that an algorithm is stable if small changes in the input result in\nsmall changes in the output. This kind of algorithm stability is particularly\nrelevant when analyzing and visualizing time-varying data. Stability in general\nplays an important role in a wide variety of areas, such as numerical analysis,\nmachine learning, and topology, but is poorly understood in the context of\n(combinatorial) algorithms. In this paper we present a framework for analyzing\nthe stability of algorithms. We focus in particular on the tradeoff between the\nstability of an algorithm and the quality of the solution it computes. Our\nframework allows for three types of stability analysis with increasing degrees\nof complexity: event stability, topological stability, and Lipschitz stability.\nWe demonstrate the use of our stability framework by applying it to kinetic\nEuclidean minimum spanning trees.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning from Label Proportions in Brain-Computer Interfaces: Online Unsupervised Learning with Guarantees.   Objective: Using traditional approaches, a Brain-Computer Interface (BCI)\nrequires the collection of calibration data for new subjects prior to online\nuse. Calibration time can be reduced or eliminated e.g.~by transfer of a\npre-trained classifier or unsupervised adaptive classification methods which\nlearn from scratch and adapt over time. While such heuristics work well in\npractice, none of them can provide theoretical guarantees. Our objective is to\nmodify an event-related potential (ERP) paradigm to work in unison with the\nmachine learning decoder to achieve a reliable calibration-less decoding with a\nguarantee to recover the true class means.\nMethod: We introduce learning from label proportions (LLP) to the BCI\ncommunity as a new unsupervised, and easy-to-implement classification approach\nfor ERP-based BCIs. The LLP estimates the mean target and non-target responses\nbased on known proportions of these two classes in different groups of the\ndata. We modified a visual ERP speller to meet the requirements of the LLP. For\nevaluation, we ran simulations on artificially created data sets and conducted\nan online BCI study with N=13 subjects performing a copy-spelling task.\nResults: Theoretical considerations show that LLP is guaranteed to minimize\nthe loss function similarly to a corresponding supervised classifier. It\nperformed well in simulations and in the online application, where 84.5% of\ncharacters were spelled correctly on average without prior calibration.\nSignificance: The continuously adapting LLP classifier is the first\nunsupervised decoder for ERP BCIs guaranteed to find the true class means. This\nmakes it an ideal solution to avoid a tedious calibration and to tackle\nnon-stationarities in the data. Additionally, LLP works on complementary\nprinciples compared to existing unsupervised methods, allowing for their\nfurther enhancement when combined with LLP.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-Labelled Value Networks for Computer Go.   This paper proposes a new approach to a novel value network architecture for\nthe game Go, called a multi-labelled (ML) value network. In the ML value\nnetwork, different values (win rates) are trained simultaneously for different\nsettings of komi, a compensation given to balance the initiative of playing\nfirst. The ML value network has three advantages, (a) it outputs values for\ndifferent komi, (b) it supports dynamic komi, and (c) it lowers the mean\nsquared error (MSE). This paper also proposes a new dynamic komi method to\nimprove game-playing strength. This paper also performs experiments to\ndemonstrate the merits of the architecture. First, the MSE of the ML value\nnetwork is generally lower than the value network alone. Second, the program\nbased on the ML value network wins by a rate of 67.6% against the program based\non the value network alone. Third, the program with the proposed dynamic komi\nmethod significantly improves the playing strength over the baseline that does\nnot use dynamic komi, especially for handicap games. To our knowledge, up to\ndate, no handicap games have been played openly by programs using value\nnetworks. This paper provides these programs with a useful approach to playing\nhandicap games.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Implications of right-handed neutrinos in $B-L$ extended standard model with scalar dark matter.   We investigate the Standard Model (SM) with a $U(1)_{B-L}$ gauge extension\nwhere a $B-L$ charged scalar is a viable dark matter (DM) candidate. The\ndominant annihilation process, for the DM particle is through the $B-L$\nsymmetry breaking scalar to right-handed neutrino pair. We exploit the effect\nof decay and inverse decay of the right-handed neutrino in thermal relic\nabundance of the DM. Depending on the values of the decay rate, the DM relic\ndensity can be significantly different from what is obtained in the standard\ncalculation assuming the right-handed neutrino is in thermal equilibrium and\nthere appear different regions of the parameter space satisfying the observed\nDM relic density. For a DM mass less than $\\mathcal{O}$(TeV), the direct\ndetection experiments impose a competitive bound on the mass of the\n$U(1)_{B-L}$ gauge boson $Z^\\prime$ with the collider experiments. Utilizing\nthe non-observation of the displaced vertices arising from the right-handed\nneutrino decays, bound on the mass of $Z^\\prime$ has been obtained at present\nand higher luminosities at the LHC with 14 TeV centre of mass energy where an\nintegrated luminosity of 100fb$^{-1}$ is sufficient to probe $m_{Z'} \\sim 5.5$\nTeV.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On ramification in transcendental extensions of local fields.   Let $L/K$ be an extension of complete discrete valuation fields, and assume\nthat the residue field of $K$ is perfect and of positive characteristic. The\nresidue field of $L$ is not assumed to be perfect.\nIn this paper, we prove a formula for the Swan conductor of the image of a\ncharacter $\\chi \\in H^1(K, \\mathbb{Q}/\\mathbb{Z})$ in $H^1(L,\n\\mathbb{Q}/\\mathbb{Z})$ for $\\chi$ sufficiently ramified. Further, we define\ngeneralizations $\\psi_{L/K}^{\\mathrm{ab}}$ and $\\psi_{L/K}^{\\mathrm{AS}}$ of\nthe classical Hasse-Herbrand $\\psi$-function and prove a formula for\n$\\psi_{L/K}^{\\mathrm{ab}}(t)$ for sufficiently large $t\\in \\mathbb{R}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exploring Features for Predicting Policy Citations.   In this study we performed an initial investigation and evaluation of\naltmetrics and their relationship with public policy citation of research\npapers. We examined methods for using altmetrics and other data to predict\nwhether a research paper is cited in public policy and applied receiver\noperating characteristic curve on various feature groups in order to evaluate\ntheir potential usefulness. From the methods we tested, classifying based on\ntweet count provided the best results, achieving an area under the ROC curve of\n0.91.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Short-time behavior of the heat kernel and Weyl's law on $RCD^*(K, N)$-spaces.   In this paper, we prove pointwise convergence of heat kernels for\nmGH-convergent sequences of $RCD^*(K,N)$-spaces. We obtain as a corollary\nresults on the short-time behavior of the heat kernel in $RCD^*(K,N)$-spaces.\nWe use then these results to initiate the study of Weyl's law in the $RCD$\nsetting",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comments on the National Toxicology Program Report on Cancer, Rats and Cell Phone Radiation.   With the National Toxicology Program issuing its final report on cancer, rats\nand cell phone radiation, one can draw the following conclusions from their\ndata. There is a roughly linear relationship between gliomas (brain cancers)\nand schwannomas (cancers of the nerve sheaths around the heart) with increased\nabsorption of 900 MHz radiofrequency radiation for male rats. The rate of these\ncancers in female rats is about one third the rate in male rats; the rate of\ngliomas in female humans is about two thirds the rate in male humans. Both of\nthese observations can be explained by a decrease in sensitivity to chemical\ncarcinogenesis in both female rats and female humans. The increase in male rat\nlife spans with increased radiofrequency absorption is due to a reduction in\nkidney failure from a decrease in food intake. No such similar increase in the\nlife span of humans who use cell phones is expected.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "New concepts of inertial measurements with multi-species atom interferometry.   In the field of cold atom inertial sensors, we present and analyze innovative\nconfigurations for improving their measurement range and sensitivity,\nespecially attracting for onboard applications. These configurations rely on\nmulti-species atom interferometry, involving the simultaneous manipulation of\ndifferent atomic species in a unique instrument to deduce inertial\nmeasurements. Using a dual-species atom accelerometer manipulating\nsimultaneously both isotopes of rubidium, we report a preliminary experimental\nrealization of original concepts involving the implementation of two atom\ninterferometers first with different interrogation times and secondly in phase\nquadrature. These results open the door to a new generation of atomic sensors\nrelying on high performance multi-species atom interferometric measurements.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Long-Term Sequential Prediction Using Expert Advice.   For the prediction with experts' advice setting, we consider some methods to\nconstruct forecasting algorithms that suffer loss not much more than any expert\nin the pool. In contrast to the standard approach, we investigate the case of\nlong-term forecasting of time series. This approach implies that each expert\nissues a forecast for a time point ahead (or a time interval), and then the\nmaster algorithm combines these forecasts into one aggregated forecast\n(sequence of forecasts). We introduce two new approaches to aggregating\nexperts' long-term interval predictions. Both are based on Vovk's aggregating\nalgorithm. The first approach applies the method of Mixing Past Posteriors\nmethod to the long-term prediction. The second approach is used for the\ninterval forecasting and considers overlapping experts. The upper bounds for\nregret of these algorithms for adversarial case are obtained. We also present\nthe results of numerical experiments on time series long-term prediction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Radial anisotropy in omega Cen limiting the room for an intermediate-mass black hole.   Finding an intermediate-mass black hole (IMBH) in a globular cluster (or\nproving its absence) would provide valuable insights into our understanding of\ngalaxy formation and evolution. However, it is challenging to identify a unique\nsignature of an IMBH that cannot be accounted for by other processes.\nObservational claims of IMBH detection are indeed often based on analyses of\nthe kinematics of stars in the cluster core, the most common signature being a\nrise in the velocity dispersion profile towards the centre of the system.\nUnfortunately, this IMBH signal is degenerate with the presence of\nradially-biased pressure anisotropy in the globular cluster. To explore the\nrole of anisotropy in shaping the observational kinematics of clusters, we\nanalyse the case of omega Cen by comparing the observed profiles to those\ncalculated from the family of LIMEPY models, that account for the presence of\nanisotropy in the system in a physically motivated way. The best-fit radially\nanisotropic models reproduce the observational profiles well, and describe the\ncentral kinematics as derived from Hubble Space Telescope proper motions\nwithout the need for an IMBH.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Academic Engagement and Commercialization in an Institutional Transition Environment: Evidence from Shanghai Maritime University.   Does academic engagement accelerate or crowd out the commercialization of\nuniversity knowledge? Research on this topic seldom considers the impact of the\ninstitutional environment, especially when a formal institution for encouraging\nthe commercial activities of scholars has not yet been established. This study\ninvestigates this question in the context of China, which is in the\ninstitutional transition stage. Based on a survey of scholars from Shanghai\nMaritime University, we demonstrate that academic engagement has a positive\nimpact on commercialization and that this impact is greater for risk-averse\nscholars than for other risk-seeking scholars. Our results suggest that in an\ninstitutional transition environment, the government should consider\nencouraging academic engagement to stimulate the commercialization activities\nof conservative scholars.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The univalence axiom in cubical sets.   In this note we show that Voevodsky's univalence axiom holds in the model of\ntype theory based on symmetric cubical sets. We will also discuss Swan's\nconstruction of the identity type in this variation of cubical sets. This\nproves that we have a model of type theory supporting dependent products,\ndependent sums, univalent universes, and identity types with the usual\njudgmental equality, and this model is formulated in a constructive metatheory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-hop assortativities for networks classification.   Several social, medical, engineering and biological challenges rely on\ndiscovering the functionality of networks from their structure and node\nmetadata, when it is available. For example, in chemoinformatics one might want\nto detect whether a molecule is toxic based on structure and atomic types, or\ndiscover the research field of a scientific collaboration network. Existing\ntechniques rely on counting or measuring structural patterns that are known to\nshow large variations from network to network, such as the number of triangles,\nor the assortativity of node metadata. We introduce the concept of multi-hop\nassortativity, that captures the similarity of the nodes situated at the\nextremities of a randomly selected path of a given length. We show that\nmulti-hop assortativity unifies various existing concepts and offers a\nversatile family of 'fingerprints' to characterize networks. These fingerprints\nallow in turn to recover the functionalities of a network, with the help of the\nmachine learning toolbox. Our method is evaluated empirically on established\nsocial and chemoinformatic network benchmarks. Results reveal that our\nassortativity based features are competitive providing highly accurate results\noften outperforming state of the art methods for the network classification\ntask.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An anti-incursion algorithm for unknown probabilistic adversaries on connected graphs.   A gambler moves on the vertices $1, \\ldots, n$ of a graph using the\nprobability distribution $p_{1}, \\ldots, p_{n}$. A cop pursues the gambler on\nthe graph, only being able to move between adjacent vertices. What is the\nexpected number of moves that the gambler can make until the cop catches them?\nKomarov and Winkler proved an upper bound of approximately $1.97n$ for the\nexpected capture time on any connected $n$-vertex graph when the cop does not\nknow the gambler's distribution. We improve this upper bound to approximately\n$1.95n$ by modifying the cop's pursuit algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An EM Based Probabilistic Two-Dimensional CCA with Application to Face Recognition.   Recently, two-dimensional canonical correlation analysis (2DCCA) has been\nsuccessfully applied for image feature extraction. The method instead of\nconcatenating the columns of the images to the one-dimensional vectors,\ndirectly works with two-dimensional image matrices. Although 2DCCA works well\nin different recognition tasks, it lacks a probabilistic interpretation. In\nthis paper, we present a probabilistic framework for 2DCCA called probabilistic\n2DCCA (P2DCCA) and an iterative EM based algorithm for optimizing the\nparameters. Experimental results on synthetic and real data demonstrate\nsuperior performance in loading factor estimation for P2DCCA compared to 2DCCA.\nFor real data, three subsets of AR face database and also the UMIST face\ndatabase confirm the robustness of the proposed algorithm in face recognition\ntasks with different illumination conditions, facial expressions, poses and\nocclusions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gould's Belt: Local Large Scale Structure in the Milky Way.   Gould's Belt is a flat local system composed of young OB stars, molecular\nclouds and neutral hydrogen within 500 pc from the Sun. It is inclined about 20\ndegrees to the galactic plane and its velocity field significantly deviates\nfrom rotation around the distant center of the Milky Way. We discuss possible\nmodels of its origin: free expansion from a point or from a ring, expansion of\na shell, or a collision of a high velocity cloud with the plane of the Milky\nWay. Currently, no convincing model exists. Similar structures are identified\nin HI and CO distribution in our and other nearby galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Automatic Segmentation of the Left Ventricle in Cardiac CT Angiography Using Convolutional Neural Network.   Accurate delineation of the left ventricle (LV) is an important step in\nevaluation of cardiac function. In this paper, we present an automatic method\nfor segmentation of the LV in cardiac CT angiography (CCTA) scans. Segmentation\nis performed in two stages. First, a bounding box around the LV is detected\nusing a combination of three convolutional neural networks (CNNs).\nSubsequently, to obtain the segmentation of the LV, voxel classification is\nperformed within the defined bounding box using a CNN. The study included CCTA\nscans of sixty patients, fifty scans were used to train the CNNs for the LV\nlocalization, five scans were used to train LV segmentation and the remaining\nfive scans were used for testing the method. Automatic segmentation resulted in\nthe average Dice coefficient of 0.85 and mean absolute surface distance of 1.1\nmm. The results demonstrate that automatic segmentation of the LV in CCTA scans\nusing voxel classification with convolutional neural networks is feasible.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Effects of Arrival Type and Degree of Saturation on Queue Length Estimation at Signalized Intersections.   Purpose of this study is evaluation of the relationship between different\narrival types and degree of saturation (X) with overestimations of HCM 2010\nprocedure for estimating the back of queue within a study area. Further\nanalysis is performed to establish the relationship between queue length and\ndelay and also between each of them individually and X in cases with\noverestimation. The analyses are based on the 50th percentile queue lengths for\ndata collected at four signalized intersections along a corridor in 4 time\nperiods (off peak period and AM, Noon and PM peak periods). Based on the\nstatistical test results, arrival type did not play a role in overestimations.\nHowever, there is a significant relationship between the overestimations on\nminor and major street and different ranges of X. On minor streets, about 59%\nof the overestimations are at X values less than half; while near 23% of the\noverestimations are at oversaturation condition with X values greater than 1.\nThe relationship between amount of overestimations and degree of saturation\nshould be established based on the numerical amount of overestimations versus X\nvalues rather than the relative amounts; since the statistical comparison\nbetween the relative amount of overestimations and X values, resulted in a\nwrong idea of the real world condition. There was a significant correlation\nbetween field queue and delay data of the cases with overestimated queue length\nin all cases on major and minor streets. Also, field queue is correlated to X,\nin all cases on minor and major streets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Abdominal aortic aneurysms and endovascular sealing: deformation and dynamic response.   Endovascular sealing is a new technique for the repair of abdominal aortic\naneurysms. Commercially available in Europe since~2013, it takes a\nrevolutionary approach to aneurysm repair through minimally invasive\ntechniques. Although aneurysm sealing may be thought as more stable than\nconventional endovascular stent graft repairs, post-implantation movement of\nthe endoprosthesis has been described, potentially leading to late\ncomplications. The paper presents for the first time a model, which explains\nthe nature of forces, in static and dynamic regimes, acting on sealed abdominal\naortic aneurysms, with references to real case studies. It is shown that\nelastic deformation of the aorta and of the endoprosthesis induced by static\nforces and vibrations during daily activities can potentially promote undesired\nmovements of the endovascular sealing structure.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Introduction to Formal Concept Analysis and Its Applications in Information Retrieval and Related Fields.   This paper is a tutorial on Formal Concept Analysis (FCA) and its\napplications. FCA is an applied branch of Lattice Theory, a mathematical\ndiscipline which enables formalisation of concepts as basic units of human\nthinking and analysing data in the object-attribute form. Originated in early\n80s, during the last three decades, it became a popular human-centred tool for\nknowledge representation and data analysis with numerous applications. Since\nthe tutorial was specially prepared for RuSSIR 2014, the covered FCA topics\ninclude Information Retrieval with a focus on visualisation aspects, Machine\nLearning, Data Mining and Knowledge Discovery, Text Mining and several others.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ASDA : Analyseur Syntaxique du Dialecte Alg{é}rien dans un but d'analyse s{é}mantique.   Opinion mining and sentiment analysis in social media is a research issue\nhaving a great interest in the scientific community. However, before begin this\nanalysis, we are faced with a set of problems. In particular, the problem of\nthe richness of languages and dialects within these media. To address this\nproblem, we propose in this paper an approach of construction and\nimplementation of Syntactic analyzer named ASDA. This tool represents a parser\nfor the Algerian dialect that label the terms of a given corpus. Thus, we\nconstruct a labeling table containing for each term its stem, different\nprefixes and suffixes, allowing us to determine the different grammatical parts\na sort of POS tagging. This labeling will serve us later in the semantic\nprocessing of the Algerian dialect, like the automatic translation of this\ndialect or sentiment analysis",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Approach to Controller Design Based on the Generalized Cloud Model.   In this paper, an approach to controller design based on the cloud models,\nwithout using the analog plant model is presented.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phasebook and Friends: Leveraging Discrete Representations for Source Separation.   Deep learning based speech enhancement and source separation systems have\nrecently reached unprecedented levels of quality, to the point that performance\nis reaching a new ceiling. Most systems rely on estimating the magnitude of a\ntarget source by estimating a real-valued mask to be applied to a\ntime-frequency representation of the mixture signal. A limiting factor in such\napproaches is a lack of phase estimation: the phase of the mixture is most\noften used when reconstructing the estimated time-domain signal. Here, we\npropose `MagBook', `phasebook', and `Combook', three new types of layers based\non discrete representations that can be used to estimate complex time-frequency\nmasks. MagBook layers extend classical sigmoidal units and a recently\nintroduced convex softmax activation for mask-based magnitude estimation.\nPhasebook layers use a similar structure to give an estimate of the phase mask\nwithout suffering from phase wrapping issues. Combook layers are an alternative\nto the MagBook-Phasebook combination that directly estimate complex masks. We\npresent various training and inference regimes involving these representations,\nand explain in particular how to include them in an end-to-end learning\nframework. We also present an oracle study to assess upper bounds on\nperformance for various types of masks using discrete phase representations. We\nevaluate the proposed methods on the wsj0-2mix dataset, a well-studied corpus\nfor single-channel speaker-independent speaker separation, matching the\nperformance of state-of-the-art mask-based approaches without requiring\nadditional phase reconstruction steps.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Jamming-Resistant Receivers for the Massive MIMO Uplink.   We design a jamming-resistant receiver scheme to enhance the robustness of a\nmassive MIMO uplink system against jamming. We assume that a jammer attacks the\nsystem both in the pilot and data transmission phases. The key feature of the\nproposed scheme is that, in the pilot phase, we estimate not only the\nlegitimate channel, but also the jamming channel by exploiting a purposely\nunused pilot sequence. The jamming channel estimate is used to constructed\nlinear receive filters that reject the impact of the jamming signal. The\nperformance of the proposed scheme is analytically evaluated using asymptotic\nproperties of massive MIMO. The optimal regularized zero-forcing receiver and\nthe optimal power allocation are also studied. Numerical results are provided\nto verify our analysis and show that the proposed scheme greatly improves the\nachievable rates, as compared to conventional receivers. Interestingly, the\nproposed scheme works particularly well under strong jamming attacks, since the\nimproved estimate of the jamming channel outweighs the extra jamming power.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The list chromatic number of graphs with small clique number.   We prove that every triangle-free graph with maximum degree $\\Delta$ has list\nchromatic number at most $(1+o(1))\\frac{\\Delta}{\\ln \\Delta}$. This matches the\nbest-known bound for graphs of girth at least 5. We also provide a new proof\nthat for any $r\\geq 4$ every $K_r$-free graph has list-chromatic number at most\n$200r\\frac{\\Delta\\ln\\ln\\Delta}{\\ln\\Delta}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A robust RUV-testing procedure via gamma-divergence.   Identification of differentially expressed genes (DE-genes) is commonly\nconducted in modern biomedical researches. However, unwanted variation\ninevitably arises during the data collection process, which could make the\ndetection results heavily biased. It is suggested to remove the unwanted\nvariation while keeping the biological variation to ensure a reliable analysis\nresult. Removing Unwanted Variation (RUV) is recently proposed for this purpose\nby the virtue of negative control genes. On the other hand, outliers are\nfrequently appear in modern high-throughput genetic data that can heavily\naffect the performances of RUV and its downstream analysis. In this work, we\npropose a robust RUV-testing procedure via gamma-divergence. The advantages of\nour method are twofold: (1) it does not involve any modeling for the outlier\ndistribution, which is applicable to various situations, (2) it is easy to\nimplement in the sense that its robustness is controlled by a single tuning\nparameter gamma of gamma-divergence, and a data-driven criterion is developed\nto select $\\gamma$. In the Gender Study, our method can successfully remove\nunwanted variation, and is able to identify more DE-genes than conventional\nmethods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Model-Agnostic Meta-Learning.   Learning to infer Bayesian posterior from a few-shot dataset is an important\nstep towards robust meta-learning due to the model uncertainty inherent in the\nproblem. In this paper, we propose a novel Bayesian model-agnostic\nmeta-learning method. The proposed method combines scalable gradient-based\nmeta-learning with nonparametric variational inference in a principled\nprobabilistic framework. During fast adaptation, the method is capable of\nlearning complex uncertainty structure beyond a point estimate or a simple\nGaussian approximation. In addition, a robust Bayesian meta-update mechanism\nwith a new meta-loss prevents overfitting during meta-update. Remaining an\nefficient gradient-based meta-learner, the method is also model-agnostic and\nsimple to implement. Experiment results show the accuracy and robustness of the\nproposed method in various tasks: sinusoidal regression, image classification,\nactive learning, and reinforcement learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Transient behavior of the solutions to the second order difference equations by the renormalization method based on Newton-Maclaurin expansion.   The renormalization method based on the Newton-Maclaurin expansion is applied\nto study the transient behavior of the solutions to the difference equations as\nthey tend to the steady-states. The key and also natural step is to make the\nrenormalization equations to be continuous such that the elementary functions\ncan be used to describe the transient behavior of the solutions to difference\nequations. As the concrete examples, we deal with the important second order\nnonlinear difference equations with a small parameter. The result shows that\nthe method is more natural than the multi-scale method.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Emotion Controlled Spectrum Mobility Scheme for Efficient Syntactic Interoperability In Cognitive Radio Based Internet of Vehicles.   Blind spots are one of the causes of road accidents in the hilly and flat\nareas. These blind spot accidents can be decreased by establishing an Internet\nof Vehicles (IoV) using Vehicle-2-Vehicle (V2V) and Vehicle-2-Infrastrtructure\n(V2I) communication systems. But the problem with these IoV is that most of\nthem are using DSRC or single Radio Access Technology (RAT) as a wireless\ntechnology, which has been proven to be failed for efficient communication\nbetween vehicles. Recently, Cognitive Radio (CR) based IoV have to be proven\nbest wireless communication systems for vehicular networks. However, the\nspectrum mobility is a challenging task to keep CR based vehicular networks\ninteroperable and has not been addressed sufficiently in existing research. In\nour previous research work, the Cognitive Radio Site (CR-Site) has been\nproposed as in-vehicle CR-device, which can be utilized to establish efficient\nIoV systems. H In this paper, we have introduced the Emotions Inspired\nCognitive Agent (EIC_Agent) based spectrum mobility mechanism in CR-Site and\nproposed a novel emotions controlled spectrum mobility scheme for efficient\nsyntactic interoperability between vehicles. For this purpose, a probabilistic\ndeterministic finite automaton using fear factor is proposed to perform\nefficient spectrum mobility using fuzzy logic. In addition, the quantitative\ncomputation of different fear intensity levels has been performed with the help\nof fuzzy logic. The system has been tested using active data from different GSM\nservice providers on Mangla-Mirpur road. This is supplemented by extensive\nsimulation experiments which validate the proposed scheme for CR based\nhigh-speed vehicular networks. The qualitative comparison with the\nexisting-state-of the-art has proven the superiority of the proposed emotions\ncontrolled syntactic interoperable spectrum mobility scheme within cognitive\nradio based IoV systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pressure Induced Superconductivity in the New Compound ScZrCo1-$δ$.   It is widely perceived that the correlation effect may play an important role\nin several unconventional superconducting families, such as cuprate, iron-based\nand heavy-fermion superconductors. The application of high pressure can tune\nthe ground state properties and balance the localization and itineracy of\nelectrons in correlated systems, which may trigger unconventional\nsuperconductivity. Moreover, non-centrosymmetric structure may induce the spin\ntriplet pairing which is very rare in nature. Here, we report a new compound\nScZrCo1-${\\delta}$ crystallizing in the Ti2Ni structure with the space group of\nFD3-MS without a spatial inversion center. The resistivity of the material at\nambient pressure shows a bad metal and weak semiconducting behavior.\nFurthermore, specific heat and magnetic susceptibility measurements yield a\nrather large value of Wilson ratio ~4.47. Both suggest a ground state with\ncorrelation effect. By applying pressure, the up-going behavior of resistivity\nin lowering temperature at ambient pressure is suppressed and gradually it\nbecomes metallic. At a pressure of about 19.5 GPa superconductivity emerges. Up\nto 36.05 GPa, a superconducting transition at about 3.6 K with a quite high\nupper critical field is observed. Our discovery here provides a new platform\nfor investigating the relationship between correlation effect and\nsuperconductivity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Fast Global Convergence via Landscape of Empirical Loss.   While optimizing convex objective (loss) functions has been a powerhouse for\nmachine learning for at least two decades, non-convex loss functions have\nattracted fast growing interests recently, due to many desirable properties\nsuch as superior robustness and classification accuracy, compared with their\nconvex counterparts. The main obstacle for non-convex estimators is that it is\nin general intractable to find the optimal solution. In this paper, we study\nthe computational issues for some non-convex M-estimators. In particular, we\nshow that the stochastic variance reduction methods converge to the global\noptimal with linear rate, by exploiting the statistical property of the\npopulation loss. En route, we improve the convergence analysis for the batch\ngradient method in \\cite{mei2016landscape}.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Algebraic and logistic investigations on free lattices.   Lorenzen's \"Algebraische und logistische Untersuchungen über freie\nVerbände\" appeared in 1951 in The journal of symbolic logic. These\n\"Investigations\" have immediately been recognised as a landmark in the history\nof infinitary proof theory, but their approach and method of proof have not\nbeen incorporated into the corpus of proof theory. More precisely, Lorenzen\nproves the admissibility of cut by double induction, on the cut formula and on\nthe complexity of the derivations, without using any ordinal assignment,\ncontrary to the presentation of cut elimination in most standard texts on proof\ntheory. This translation has the intent of giving a new impetus to their\nreception.\nThe \"Investigations\" are best known for providing a constructive proof of\nconsistency for ramified type theory without axiom of reducibility. They do so\nby showing that it is a part of a trivially consistent \"inductive calculus\"\nthat describes our knowledge of arithmetic without detour. The proof resorts\nonly to the inductive definition of formulas and theorems.\nThey propose furthermore a definition of a semilattice, of a distributive\nlattice, of a pseudocomplemented semilattice, and of a countably complete\nboolean lattice as deductive calculuses, and show how to present them for\nconstructing the respective free object over a given preordered set.\nThis translation is published with the kind permission of Lorenzen's\ndaughter, Jutta Reinhardt.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "City-Scale Intelligent Systems and Platforms.   As of 2014, 54% of the earth's population resides in urban areas, and it is\nsteadily increasing, expecting to reach 66% by 2050. Urban areas range from\nsmall cities with tens of thousands of people to megacities with greater than\n10 million people. Roughly 12% of the global population today lives in 28\nmegacities, and at least 40 are projected by 2030. At these scales, the urban\ninfrastructure such as roads, buildings, and utility networks will cover areas\nas large as New England. This steady urbanization and the resulting expansion\nof infrastructure, combined with renewal of aging urban infrastructure,\nrepresent tens of trillion of dollars in new urban infrastructure investment\nover the coming decades. These investments must balance factors including\nimpact on clean air and water, energy and maintenance costs, and the\nproductivity and health of city dwellers. Moreover, cost-effective management\nand sustainability of these growing urban areas will be one of the most\ncritical challenges to our society, motivating the concept of science- and\ndata-driven urban design, retrofit, and operation-that is, \"Smart Cities\".",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The near-critical Gibbs measure of the branching random walk.   Consider the supercritical branching random walk on the real line in the\nboundary case and the associated Gibbs measure $\\nu_{n,\\beta}$ on the\n$n^\\text{th}$ generation, which is also the polymer measure on a disordered\ntree with inverse temperature $\\beta$. The convergence of the partition\nfunction $W_{n,\\beta}$, after rescaling, towards a nontrivial limit has been\nproved by A\\\"{\\i}dékon and Shi in the critical case $\\beta = 1$ and by\nMadaule when $\\beta >1$. We study here the near-critical case, where $\\beta_n\n\\to 1$, and prove the convergence of $W_{n,\\beta_n}$, after rescaling, towards\na constant multiple of the limit of the derivative martingale. Moreover,\ntrajectories of particles chosen according to the Gibbs measure $\\nu_{n,\\beta}$\nhave been studied by Madaule in the critical case, with convergence towards the\nBrownian meander, and by Chen, Madaule and Mallein in the strong disorder\nregime, with convergence towards the normalized Brownian excursion. We prove\nhere the convergence for trajectories of particles chosen according to the\nnear-critical Gibbs measure and display continuous families of processes from\nthe meander to the excursion or to the Brownian motion.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On the Genus of the Moonshine Module.   We provide a novel and simple description of Schellekens' seventy-one affine\nKac-Moody structures of self-dual vertex operator algebras of central charge 24\nby utilizing cyclic subgroups of the glue codes of the Niemeier lattices with\nroots. We also discuss a possible uniform construction procedure of the\nself-dual vertex operator algebras of central charge 24 starting from the Leech\nlattice. This also allows us to consider the uniqueness question for all\nnon-trivial affine Kac-Moody structures. We finally discuss our description\nfrom a Lorentzian viewpoint.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "TF Boosted Trees: A scalable TensorFlow based framework for gradient boosting.   TF Boosted Trees (TFBT) is a new open-sourced frame-work for the distributed\ntraining of gradient boosted trees. It is based on TensorFlow, and its\ndistinguishing features include a novel architecture, automatic loss\ndifferentiation, layer-by-layer boosting that results in smaller ensembles and\nfaster prediction, principled multi-class handling, and a number of\nregularization techniques to prevent overfitting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiprocessor Approximate Message Passing with Column-Wise Partitioning.   Solving a large-scale regularized linear inverse problem using multiple\nprocessors is important in various real-world applications due to the\nlimitations of individual processors and constraints on data sharing policies.\nThis paper focuses on the setting where the matrix is partitioned column-wise.\nWe extend the algorithmic framework and the theoretical analysis of approximate\nmessage passing (AMP), an iterative algorithm for solving linear inverse\nproblems, whose asymptotic dynamics are characterized by state evolution (SE).\nIn particular, we show that column-wise multiprocessor AMP (C-MP-AMP) obeys an\nSE under the same assumptions when the SE for AMP holds. The SE results imply\nthat (i) the SE of C-MP-AMP converges to a state that is no worse than that of\nAMP and (ii) the asymptotic dynamics of C-MP-AMP and AMP can be identical.\nMoreover, for a setting that is not covered by SE, numerical results show that\ndamping can improve the convergence performance of C-MP-AMP.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Face Deidentification with Generative Deep Neural Networks.   Face deidentification is an active topic amongst privacy and security\nresearchers. Early deidentification methods relying on image blurring or\npixelization were replaced in recent years with techniques based on formal\nanonymity models that provide privacy guaranties and at the same time aim at\nretaining certain characteristics of the data even after deidentification. The\nlatter aspect is particularly important, as it allows to exploit the\ndeidentified data in applications for which identity information is irrelevant.\nIn this work we present a novel face deidentification pipeline, which ensures\nanonymity by synthesizing artificial surrogate faces using generative neural\nnetworks (GNNs). The generated faces are used to deidentify subjects in images\nor video, while preserving non-identity-related aspects of the data and\nconsequently enabling data utilization. Since generative networks are very\nadaptive and can utilize a diverse set of parameters (pertaining to the\nappearance of the generated output in terms of facial expressions, gender,\nrace, etc.), they represent a natural choice for the problem of face\ndeidentification. To demonstrate the feasibility of our approach, we perform\nexperiments using automated recognition tools and human annotators. Our results\nshow that the recognition performance on deidentified images is close to\nchance, suggesting that the deidentification process based on GNNs is highly\neffective.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A parallel orbital-updating based plane-wave basis method for electronic structure calculations.   Motivated by the recently proposed parallel orbital-updating approach in real\nspace method, we propose a parallel orbital-updating based plane-wave basis\nmethod for electronic structure calculations, for solving the corresponding\neigenvalue problems. In addition, we propose two new modified parallel\norbital-updating methods. Compared to the traditional plane-wave methods, our\nmethods allow for two-level parallelization, which is particularly interesting\nfor large scale parallelization. Numerical experiments show that these new\nmethods are more reliable and efficient for large scale calculations on modern\nsupercomputers",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Generative Mixture of Networks.   A generative model based on training deep architectures is proposed. The\nmodel consists of K networks that are trained together to learn the underlying\ndistribution of a given data set. The process starts with dividing the input\ndata into K clusters and feeding each of them into a separate network. After\nfew iterations of training networks separately, we use an EM-like algorithm to\ntrain the networks together and update the clusters of the data. We call this\nmodel Mixture of Networks. The provided model is a platform that can be used\nfor any deep structure and be trained by any conventional objective function\nfor distribution modeling. As the components of the model are neural networks,\nit has high capability in characterizing complicated data distributions as well\nas clustering data. We apply the algorithm on MNIST hand-written digits and\nYale face datasets. We also demonstrate the clustering ability of the model\nusing some real-world and toy examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Computational complexity, torsion-freeness of homoclinic Floer homology, and homoclinic Morse inequalities.   Floer theory was originally devised to estimate the number of 1-periodic\norbits of Hamiltonian systems. In earlier works, we constructed Floer homology\nfor homoclinic orbits on two dimensional manifolds using combinatorial\ntechniques. In the present paper, we study theoretic aspects of computational\ncomplexity of homoclinic Floer homology. More precisely, for finding the\nhomoclinic points and immersions that generate the homology and its boundary\noperator, we establish sharp upper bounds in terms of iterations of the\nunderlying symplectomorphism. This prepares the ground for future numerical\nworks.\nAlthough originally aimed at numerics, the above bounds provide also purely\nalgebraic applications, namely\n1) Torsion-freeness of primary homoclinic Floer homology.\n2) Morse type inequalities for primary homoclinic orbits.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Differentially Private High Dimensional Sparse Covariance Matrix Estimation.   In this paper, we study the problem of estimating the covariance matrix under\ndifferential privacy, where the underlying covariance matrix is assumed to be\nsparse and of high dimensions. We propose a new method, called DP-Thresholding,\nto achieve a non-trivial $\\ell_2$-norm based error bound, which is\nsignificantly better than the existing ones from adding noise directly to the\nempirical covariance matrix. We also extend the $\\ell_2$-norm based error bound\nto a general $\\ell_w$-norm based one for any $1\\leq w\\leq \\infty$, and show\nthat they share the same upper bound asymptotically. Our approach can be easily\nextended to local differential privacy. Experiments on the synthetic datasets\nshow consistent results with our theoretical claims.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Influence maximization on correlated networks through community identification.   The identification of the minimal set of nodes that maximizes the propagation\nof information is one of the most important problems in network science. In\nthis paper, we introduce a new method to find the set of initial spreaders to\nmaximize the information propagation in complex networks. We evaluate this\nmethod in assortative networks and verify that degree-degree correlation plays\na fundamental role on the spreading dynamics. Simulation results show that our\nalgorithm is statistically similar, in terms of the average size of outbreaks,\nto the greedy approach. However, our method is much less time consuming than\nthe greedy algorithm.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Higher-rank graph algebras are iterated Cuntz-Pimsner algebras.   Given a finitely aligned $k$-graph $\\Lambda$, we let $\\Lambda^i$ denote the\n$(k-1)$-graph formed by removing all edges of degree $e_i$ from $\\Lambda$. We\nshow that the Toeplitz-Cuntz-Krieger algebra of $\\Lambda$, denoted by\n$\\mathcal{T}C^*(\\Lambda)$, may be realised as the Toeplitz algebra of a Hilbert\n$\\mathcal{T}C^*(\\Lambda^i)$-bimodule. When $\\Lambda$ is locally-convex, we show\nthat the Cuntz-Krieger algebra of $\\Lambda$, which we denote by $C^*(\\Lambda)$,\nmay be realised as the Cuntz-Pimsner algebra of a Hilbert\n$C^*(\\Lambda^i)$-bimodule. Consequently, $\\mathcal{T}C^*(\\Lambda)$ and\n$C^*(\\Lambda)$ may be viewed as iterated Toeplitz and iterated Cuntz-Pimsner\nalgebras over $c_0(\\Lambda^0)$ respectively.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Population splitting of rodlike swimmers in Couette flow.   We present a quantitative analysis on the response of a dilute active\nsuspension of self-propelled rods (swimmers) in a planar channel subjected to\nan imposed shear flow. To best capture the salient features of shear-induced\neffects, we consider the case of an imposed Couette flow, providing a constant\nshear rate across the channel. We argue that the steady-state behavior of\nswimmers can be understood in the light of a population splitting phenomenon,\noccurring as the shear rate exceeds a certain threshold, initiating the\nreversal of swimming direction for a finite fraction of swimmers from down- to\nupstream or vice versa, depending on swimmer position within the channel.\nSwimmers thus split into two distinct, statistically significant and oppositely\nswimming majority and minority populations. The onset of population splitting\ntranslates into a transition from a self-propulsion-dominated regime to a\nshear-dominated regime, corresponding to a unimodal-to-bimodal change in the\nprobability distribution function of the swimmer orientation. We present a\nphase diagram in terms of the swim and flow Peclet numbers showing the\nseparation of these two regimes by a discontinuous transition line. Our results\nshed further light on the behavior of swimmers in a shear flow and provide an\nexplanation for the previously reported non-monotonic behavior of the mean,\nnear-wall, parallel-to-flow orientation of swimmers with increasing shear\nstrength.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Connection between Fermi contours of zero-field electrons and $ν=\\frac12$ composite fermions in two-dimensional systems.   We investigate the relation between the Fermi sea (FS) of zero-field carriers\nin two-dimensional systems and the FS of the corresponding composite fermions\nwhich emerge in a high magnetic field at filling $\\nu = \\frac{1}{2}$, as the\nkinetic energy dispersion is varied. We study cases both with and without\nrotational symmetry, and find that there is generally no straightforward\nrelation between the geometric shapes and topologies of the two FSs. In\nparticular, we show analytically that the composite Fermi liquid (CFL) is\ncompletely insensitive to a wide range of changes to the zero-field dispersion\nwhich preserve rotational symmetry, including ones that break the zero-field FS\ninto multiple disconnected pieces. In the absence of rotational symmetry, we\nshow that the notion of `valley pseudospin' in many-valley systems is\ngenerically not transferred to the CFL, in agreement with experimental\nobservations. We also discuss how a rotationally symmetric band structure can\ninduce a reordering of the Landau levels, opening interesting possibilities of\nobserving higher-Landau-level physics in the high-field regime.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Optimized Bacteria are Environmental Prediction Engines.   Experimentalists have observed phenotypic variability in isogenic bacteria\npopulations. We explore the hypothesis that in fluctuating environments this\nvariability is tuned to maximize a bacterium's expected log growth rate,\npotentially aided by epigenetic markers that store information about past\nenvironments. We show that, in a complex, memoryful environment, the maximal\nexpected log growth rate is linear in the instantaneous predictive\ninformation---the mutual information between a bacterium's epigenetic markers\nand future environmental states. Hence, under resource constraints, optimal\nepigenetic markers are causal states---the minimal sufficient statistics for\nprediction. This is the minimal amount of information about the past needed to\npredict the future as well as possible. We suggest new theoretical\ninvestigations into and new experiments on bacteria phenotypic bet-hedging in\nfluctuating complex environments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Motivic Cofiber of $τ$.   Consider the Tate twist $\\tau \\in H^{0,1}(S^{0,0})$ in the mod 2 cohomology\nof the motivic sphere. After 2-completion, the motivic Adams spectral sequence\nrealizes this element as a map $\\tau \\colon S^{0,-1} \\to S^{0,0}$, with cofiber\n$C\\tau$. We show that this motivic 2-cell complex can be endowed with a unique\n$E_{\\infty}$ ring structure. Moreover, this promotes the known isomorphism\n$\\pi_{\\ast,\\ast} C\\tau \\cong\n\\mathrm{Ext}^{\\ast,\\ast}_{BP_{\\ast}BP}(BP_{\\ast},BP_{\\ast})$ to an isomorphism\nof rings which also preserves higher products.\nWe then consider the closed symmetric monoidal category $({\n}_{C\\tau}\\textbf{Mod}, - \\wedge_{C\\tau} -)$ which lives in the kernel of Betti\nrealization. Given a motivic spectrum $X$, the $C\\tau$-induced spectrum $X\n\\wedge C\\tau$ is usually better behaved and easier to understand than $X$\nitself. We specifically illustrate this concept in the examples of the mod 2\nEilenberg-Maclane spectrum $H\\mathbb{F}_2$, the mod 2 Moore spectrum\n$S^{0,0}/2$ and the connective hermitian $K$-theory spectrum $kq$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A novel quantum dynamical approach in electron microscopy combining wave-packet propagation with Bohmian trajectories.   The numerical analysis of the diffraction features rendered by transmission\nelectron microscopy (TEM) typically relies either on classical approximations\n(Monte Carlo simulations) or quantum paraxial tomography (the multislice method\nand any of its variants). Although numerically advan- tageous (relatively\nsimple implementations and low computational costs), they involve important\napproximations and thus their range of applicability is limited. To overcome\nsuch limitations, an alternative, more general approach is proposed, based on\nan optimal combination of wave-packet propagation with the on-the-fly\ncomputation of associated Bohmian trajectories. For the sake of clarity, but\nwithout loss of generality, the approach is used to analyze the diffraction of\nan electron beam by a thin aluminum slab as a function of three different\nincidence (work) conditions which are of interest in electron microscopy: the\nprobe width, the tilting angle, and the beam energy. Specifically, it is shown\nthat, because there is a dependence on particular thresholds of the beam\nenergy, this approach provides a clear description of the diffraction process\nat any energy, revealing at the same time any diversion of the beam inside the\nmaterial towards directions that cannot be accounted for by other conventional\nmethods, which is of much interest when dealing with relatively low energies\nand/or relatively large tilting angles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weighted $1\\times1$ cut-and-project sets in bounded distance to a lattice.   Recent results of Grepstad and Lev are used to show that weighted\ncut-and-project sets with one-dimensional physical space and one-dimensional\ninternal space are bounded distance equivalent to some lattice if the weight\nfunction $h$ is continuous on the internal space, and if $h$ is either\npiecewise linear, or twice differentiable with bounded curvature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Persistent Monitoring of Stochastic Spatio-temporal Phenomena with a Small Team of Robots.   This paper presents a solution for persistent monitoring of real-world\nstochastic phenomena, where the underlying covariance structure changes sharply\nacross time, using a small number of mobile robot sensors. We propose an\nadaptive solution for the problem where stochastic real-world dynamics are\nmodeled as a Gaussian Process (GP). The belief on the underlying covariance\nstructure is learned from recently observed dynamics as a Gaussian Mixture (GM)\nin the low-dimensional hyper-parameters space of the GP and adapted across time\nusing Sequential Monte Carlo methods. Each robot samples a belief point from\nthe GM and locally optimizes a set of informative regions by greedy\nmaximization of the submodular entropy function. The key contributions of this\npaper are threefold: adapting the belief on the covariance using Markov Chain\nMonte Carlo (MCMC) sampling such that particles survive even under sharp\ncovariance changes across time; exploiting the belief to transform the problem\nof entropy maximization into a decentralized one; and developing an\napproximation algorithm to maximize entropy on a set of informative regions in\nthe continuous space. We illustrate the application of the proposed solution\nthrough extensive simulations using an artificial dataset and multiple real\ndatasets from fixed sensor deployments, and compare it to three competing\nstate-of-the-art approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On 2-level polytopes arising in combinatorial settings.   2-level polytopes naturally appear in several areas of pure and applied\nmathematics, including combinatorial optimization, polyhedral combinatorics,\ncommunication complexity, and statistics. In this paper, we present a study of\nsome 2-level polytopes arising in combinatorial settings. Our first\ncontribution is proving that v(P)*f(P) is upper bounded by d*2^(d+1), for a\nlarge collection of families of such polytopes P. Here v(P) (resp. f(P)) is the\nnumber of vertices (resp. facets) of P, and d is its dimension. Whether this\nholds for all 2-level polytopes was asked in [Bohn et al., ESA 2015], and\nexperimental results from [Fiorini et al., ISCO 2016] showed it true up to\ndimension 7. The key to most of our proofs is a deeper understanding of the\nrelations among those polytopes and their underlying combinatorial structures.\nThis leads to a number of results that we believe to be of independent\ninterest: a trade-off formula for the number of cliques and stable sets in a\ngraph; a description of stable matching polytopes as affine projections of\ncertain order polytopes; and a linear-size description of the base polytope of\nmatroids that are 2-level in terms of cuts of an associated tree.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mapping stable direct and retrograde orbits around the triple system of asteroids (45) Eugenia.   It is well accepted that knowing the composition and the orbital evolution of\nasteroids may help us to understand the process of formation of the Solar\nSystem. It is also known that asteroids can represent a threat to our planet.\nSuch important role made space missions to asteroids a very popular topic in\nthe current astrodynamics and astronomy studies. By taking into account the\nincreasingly interest in space missions to asteroids, especially to multiple\nsystems, we present a study aimed to characterize the stable and unstable\nregions around the triple system of asteroids (45) Eugenia. The goal is to\ncharacterize unstable and stable regions of this system and compare with the\nsystem 2001 SN263 - the target of the ASTER mission. Besides, Prado (2014) used\na new concept for mapping orbits considering the disturbance received by the\nspacecraft from all the perturbing forces individually. This method was also\napplied to (45) Eugenia. We present the stable and unstable regions for\nparticles with relative inclination between 0 and 180 degrees. We found that\n(45) Eugenia presents larger stable regions for both, prograde and retrograde\ncases. This is mainly because the satellites of this system are small when\ncompared to the primary body, and because they are not so close to each other.\nWe also present a comparison between those two triple systems, and a discussion\non how these results may guide us in the planning of future missions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Attacking Similarity-Based Link Prediction in Social Networks.   Link prediction is one of the fundamental problems in computational social\nscience. A particularly common means to predict existence of unobserved links\nis via structural similarity metrics, such as the number of common neighbors;\nnode pairs with higher similarity are thus deemed more likely to be linked.\nHowever, a number of applications of link prediction, such as predicting links\nin gang or terrorist networks, are adversarial, with another party incentivized\nto minimize its effectiveness by manipulating observed information about the\nnetwork. We offer a comprehensive algorithmic investigation of the problem of\nattacking similarity-based link prediction through link deletion, focusing on\ntwo broad classes of such approaches, one which uses only local information\nabout target links, and another which uses global network information. While we\nshow several variations of the general problem to be NP-Hard for both local and\nglobal metrics, we exhibit a number of well-motivated special cases which are\ntractable. Additionally, we provide principled and empirically effective\nalgorithms for the intractable cases, in some cases proving worst-case\napproximation guarantees.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emergent SU(N) symmetry in disordered SO(N) spin chains.   Strongly disordered spin chains invariant under the SO(N) group are shown to\ndisplay antiferromagnetic phases with emergent SU(N) symmetry without fine\ntuning. The phases with emergent SU(N) symmetry are of two kinds: one has a\nground state formed of randomly distributed singlets of strongly bound pairs of\nSO(N) spins (the `mesonic' phase), while the other has a ground state composed\nof singlets made out of strongly bound integer multiples of N SO(N) spins (the\n`baryonic' phase). Although the mechanism is general, we argue that the cases\nN=2,3,4 and 6 can in principle be realized with the usual spin and orbital\ndegrees of freedom.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Improved Accounting for Differentially Private Learning.   We consider the problem of differential privacy accounting, i.e. estimation\nof privacy loss bounds, in machine learning in a broad sense. We propose two\nversions of a generic privacy accountant suitable for a wide range of learning\nalgorithms. Both versions are derived in a simple and principled way using\nwell-known tools from probability theory, such as concentration inequalities.\nWe demonstrate that our privacy accountant is able to achieve state-of-the-art\nestimates of DP guarantees and can be applied to new areas like variational\ninference. Moreover, we show that the latter enjoys differential privacy at\nminor cost.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamic Transition in Symbiotic Evolution Induced by Growth Rate Variation.   In a standard bifurcation of a dynamical system, the stationary points (or\nmore generally attractors) change qualitatively when varying a control\nparameter. Here we describe a novel unusual effect, when the change of a\nparameter, e.g. a growth rate, does not influence the stationary states, but\nnevertheless leads to a qualitative change of dynamics. For instance, such a\ndynamic transition can be between the convergence to a stationary state and a\nstrong increase without stationary states, or between the convergence to one\nstationary state and that to a different state. This effect is illustrated for\na dynamical system describing two symbiotic populations, one of which exhibits\na growth rate larger than the other one. We show that, although the stationary\nstates of the dynamical system do not depend on the growth rates, the latter\ninfluence the boundary of the basins of attraction. This change of the basins\nof attraction explains this unusual effect of the quantitative change of\ndynamics by growth rate variation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Activation of Microwave Fields in a Spin-Torque Nano-Oscillator by Neuronal Action Potentials.   Action potentials are the basic unit of information in the nervous system and\ntheir reliable detection and decoding holds the key to understanding how the\nbrain generates complex thought and behavior. Transducing these signals into\nmicrowave field oscillations can enable wireless sensors that report on brain\nactivity through magnetic induction. In the present work we demonstrate that\naction potentials from crayfish lateral giant neuron can trigger microwave\noscillations in spin-torque nano-oscillators. These nanoscale devices take as\ninput small currents and convert them to microwave current oscillations that\ncan wirelessly broadcast neuronal activity, opening up the possibility for\ncompact neuro-sensors. We show that action potentials activate microwave\noscillations in spin-torque nano-oscillators with an amplitude that follows the\naction potential signal, demonstrating that the device has both the sensitivity\nand temporal resolution to respond to action potentials from a single neuron.\nThe activation of magnetic oscillations by action potentials, together with the\nsmall footprint and the high frequency tunability, makes these devices\npromising candidates for high resolution sensing of bioelectric signals from\nneural tissues. These device attributes may be useful for design of\nhigh-throughput bi-directional brain-machine interfaces.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Network Design with Probabilistic Capacities.   We consider a network design problem with random arc capacities and give a\nformulation with a probabilistic capacity constraint on each cut of the\nnetwork. To handle the exponentially-many probabilistic constraints a\nseparation procedure that solves a nonlinear minimum cut problem is introduced.\nFor the case with independent arc capacities, we exploit the supermodularity of\nthe set function defining the constraints and generate cutting planes based on\nthe supermodular covering knapsack polytope. For the general correlated case,\nwe give a reformulation of the constraints that allows to uncover and utilize\nthe submodularity of a related function. The computational results indicate\nthat exploiting the underlying submodularity and supermodularity arising with\nthe probabilistic constraints provides significant advantages over the\nclassical approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Master equation for She-Leveque scaling and its classification in terms of other Markov models of developed turbulence.   We derive the Markov process equivalent to She-Leveque scaling in homogeneous\nand isotropic turbulence. The Markov process is a jump process for velocity\nincrements $u(r)$ in scale $r$ in which the jumps occur randomly but with\ndeterministic width in $u$. From its master equation we establish a\nprescription to simulate the She-Leveque process and compare it with Kolmogorov\nscaling. To put the She-Leveque process into the context of other established\nturbulence models on the Markov level, we derive a diffusion process for $u(r)$\nfrom two properties of the Navier-Stokes equation. This diffusion process\nalready includes Kolmogorov scaling, extended self-similarity and a class of\nrandom cascade models. The fluctuation theorem of this Markov process implies a\n\"second law\" that puts a loose bound on the multipliers of the random cascade\nmodels. This bound explicitly allows for inverse cascades, which are necessary\nto satisfy the fluctuation theorem. By adding a jump process to the diffusion\nprocess, we go beyond Kolmogorov scaling and formulate the most general scaling\nlaw for the class of Markov processes having both diffusion and jump parts.\nThis Markov scaling law includes She-Leveque scaling and a scaling law derived\nby Yakhot.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Iterated failure rate monotonicity and ordering relations within Gamma and Weibull distributions.   Stochastic ordering of distributions of random variables may be defined by\nthe relative convexity of the tail functions. This has been extended to higher\norder stochastic orderings, by iteratively reassigning tail-weights. The actual\nverification of those stochastic orderings is not simple, as this depends on\ninverting distribution functions for which there may be no explicit expression.\nThe iterative definition of distributions, of course, contributes to make that\nverification even harder. We have a look at the stochastic ordering,\nintroducing a method that allows for explicit usage, applying it to the Gamma\nand Weibull distributions, giving a complete description of the order relations\nwithin each of those families.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Existence and uniqueness of steady weak solutions to the Navier-Stokes equations in $\\mathbb{R}^2$.   The existence of weak solutions to the stationary Navier-Stokes equations in\nthe whole plane $\\mathbb{R}^2$ is proven. This particular geometry was the only\ncase left open since the work of Leray in 1933. The reason is that due to the\nabsence of boundaries the local behavior of the solutions cannot be controlled\nby the enstrophy in two dimensions. We overcome this difficulty by constructing\napproximate weak solutions having a prescribed mean velocity on some given\nbounded set. As a corollary, we obtain infinitely many weak solutions in\n$\\mathbb{R}^2$ parameterized by this mean velocity, which is reminiscent of the\nexpected convergence of the velocity field at large distances to any prescribed\nconstant vector field. This explicit parameterization of the weak solutions\nallows us to prove a weak-strong uniqueness theorem for small data. The\nquestion of the asymptotic behavior of the weak solutions remains however open,\nwhen the uniqueness theorem doesn't apply.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Simulator: Understanding Adaptive Sampling in the Moderate-Confidence Regime.   We propose a novel technique for analyzing adaptive sampling called the {\\em\nSimulator}. Our approach differs from the existing methods by considering not\nhow much information could be gathered by any fixed sampling strategy, but how\ndifficult it is to distinguish a good sampling strategy from a bad one given\nthe limited amount of data collected up to any given time. This change of\nperspective allows us to match the strength of both Fano and change-of-measure\ntechniques, without succumbing to the limitations of either method. For\nconcreteness, we apply our techniques to a structured multi-arm bandit problem\nin the fixed-confidence pure exploration setting, where we show that the\nconstraints on the means imply a substantial gap between the\nmoderate-confidence sample complexity, and the asymptotic sample complexity as\n$\\delta \\to 0$ found in the literature. We also prove the first instance-based\nlower bounds for the top-k problem which incorporate the appropriate\nlog-factors. Moreover, our lower bounds zero-in on the number of times each\n\\emph{individual} arm needs to be pulled, uncovering new phenomena which are\ndrowned out in the aggregate sample complexity. Our new analysis inspires a\nsimple and near-optimal algorithm for the best-arm and top-k identification,\nthe first {\\em practical} algorithm of its kind for the latter problem which\nremoves extraneous log factors, and outperforms the state-of-the-art in\nexperiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Common Knowledge in a Logic of Gossips.   Gossip protocols aim at arriving, by means of point-to-point or group\ncommunications, at a situation in which all the agents know each other secrets.\nRecently a number of authors studied distributed epistemic gossip protocols.\nThese protocols use as guards formulas from a simple epistemic logic, which\nmakes their analysis and verification substantially easier.\nWe study here common knowledge in the context of such a logic. First, we\nanalyze when it can be reduced to iterated knowledge. Then we show that the\nsemantics and truth for formulas without nested common knowledge operator are\ndecidable. This implies that implementability, partial correctness and\ntermination of distributed epistemic gossip protocols that use non-nested\ncommon knowledge operator is decidable, as well. Given that common knowledge is\nequivalent to an infinite conjunction of nested knowledge, these results are\nnon-trivial generalizations of the corresponding decidability results for the\noriginal epistemic logic, established in (Apt & Wojtczak, 2016).\nK. R. Apt & D. Wojtczak (2016): On Decidability of a Logic of Gossips. In\nProc. of JELIA 2016, pp. 18-33, doi:10.1007/ 978-3-319-48758-8_2.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Time-delay signature suppression in a chaotic semiconductor laser by fiber random grating induced distributed feedback.   We demonstrate that a semiconductor laser perturbed by the distributed\nfeedback from a fiber random grating can emit light chaotically without the\ntime delay signature. A theoretical model is developed based on the\nLang-Kobayashi model in order to numerically explore the chaotic dynamics of\nthe laser diode subjected to the random distributed feedback. It is predicted\nthat the random distributed feedback is superior to the single reflection\nfeedback in suppressing the time-delay signature. In experiments, a massive\nnumber of feedbacks with randomly varied time delays induced by a fiber random\ngrating introduce large numbers of external cavity modes into the semiconductor\nlaser, leading to the high dimension of chaotic dynamics and thus the\nconcealment of the time delay signature. The obtained time delay signature with\nthe maximum suppression is 0.0088, which is the smallest to date.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the mapping of Points of Interest through StreetView imagery and paid crowdsourcing.   The use of volunteers has emerged as low-cost alternative to generate\naccurate geographical information, an approach known as Volunteered Geographic\nInformation (VGI). However, VGI is limited by the number and availability of\nvolunteers in the area to be mapped, hindering scalability for large areas and\nmaking difficult to map within a time-frame. Fortunately, the availability of\nstreet-view imagery enables the virtual exploration of urban environments,\nmaking possible the recruitment of contributors not necessarily located in the\narea to be mapped. In this paper, we describe the design, implementation, and\nevaluation of the Virtual City Explorer (VCE), a system to collect the\ncoordinates of Points of Interest within a bounded area on top of a street view\nservice with the use of paid crowdworkers. Our evaluation suggests that paid\ncrowdworkers are effective for finding PoIs, and cover almost all the area.\nWith respect to completeness, our approach does not find all PoIs found by\nexperts or VGI communities, but is able to find PoIs that were not found by\nthem, suggesting complementarity. We also studied the impact of making PoIs\nalready discovered by a certain number of workers \\emph{taboo} for incoming\nworkers, finding that it encourages more exploration from workers , increase\nthe number of detected PoIs , and reduce costs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A New Achievable Rate Region for Multiple-Access Channel with States.   The problem of reliable communication over the multiple-access channel (MAC)\nwith states is investigated. We propose a new coding scheme for this problem\nwhich uses quasi-group codes (QGC). We derive a new computable single-letter\ncharacterization of the achievable rate region. As an example, we investigate\nthe problem of doubly-dirty MAC with modulo-$4$ addition. It is shown that the\nsum-rate $R_1+R_2=1$ bits per channel use is achievable using the new scheme.\nWhereas, the natural extension of the Gel'fand-Pinsker scheme, sum-rates\ngreater than $0.32$ are not achievable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An explicit determination of the $K$-theoretic structure constants of the affine Grassmannian associated to $SL_2$.   Let $G:=\\widehat{SL_2}$ denote the affine Kac-Moody group associated to\n$SL_2$ and $\\bar{\\mathcal{X}}$ the associated affine Grassmannian. We determine\nan inductive formula for the Schubert basis structure constants in the\ntorus-equivariant Grothendieck group of $\\bar{\\mathcal{X}}$. In the case of\nordinary (non-equivariant) $K$-theory we find an explicit closed form for the\nstructure constants. We also determine an inductive formula for the structure\nconstants in the torus-equivariant cohomology ring, and use this formula to\nfind closed forms for some of the structure constants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From Monte Carlo to Las Vegas: Improving Restricted Boltzmann Machine Training Through Stopping Sets.   We propose a Las Vegas transformation of Markov Chain Monte Carlo (MCMC)\nestimators of Restricted Boltzmann Machines (RBMs). We denote our approach\nMarkov Chain Las Vegas (MCLV). MCLV gives statistical guarantees in exchange\nfor random running times. MCLV uses a stopping set built from the training data\nand has maximum number of Markov chain steps K (referred as MCLV-K). We present\na MCLV-K gradient estimator (LVS-K) for RBMs and explore the correspondence and\ndifferences between LVS-K and Contrastive Divergence (CD-K), with LVS-K\nsignificantly outperforming CD-K training RBMs over the MNIST dataset,\nindicating MCLV to be a promising direction in learning generative models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nichols Algebras and Quantum Principal Bundles.   A general procedure for constructing Yetter-Drinfeld modules from quantum\nprincipal bundles is introduced. As an application a Yetter-Drinfeld structure\nis put on the cotangent space of the Heckenberger-Kolb calculi of the quantum\nGrassmannians. For the special case of quantum projective space the associated\nbraiding is shown to be non-diagonal and of Hecke type. Moreover, its Nichols\nalgebra is shown to be finite-dimensional and equal to the anti-holomorphic\npart of the total differential calculus.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Generative Hashing.   Learning-based binary hashing has become a powerful paradigm for fast search\nand retrieval in massive databases. However, due to the requirement of discrete\noutputs for the hash functions, learning such functions is known to be very\nchallenging. In addition, the objective functions adopted by existing hashing\ntechniques are mostly chosen heuristically. In this paper, we propose a novel\ngenerative approach to learn hash functions through Minimum Description Length\nprinciple such that the learned hash codes maximally compress the dataset and\ncan also be used to regenerate the inputs. We also develop an efficient\nlearning algorithm based on the stochastic distributional gradient, which\navoids the notorious difficulty caused by binary output constraints, to jointly\noptimize the parameters of the hash function and the associated generative\nmodel. Extensive experiments on a variety of large-scale datasets show that the\nproposed method achieves better retrieval results than the existing\nstate-of-the-art methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A time series distance measure for efficient clustering of input output signals by their underlying dynamics.   Starting from a dataset with input/output time series generated by multiple\ndeterministic linear dynamical systems, this paper tackles the problem of\nautomatically clustering these time series. We propose an extension to the\nso-called Martin cepstral distance, that allows to efficiently cluster these\ntime series, and apply it to simulated electrical circuits data. Traditionally,\ntwo ways of handling the problem are used. The first class of methods employs a\ndistance measure on time series (e.g. Euclidean, Dynamic Time Warping) and a\nclustering technique (e.g. k-means, k-medoids, hierarchical clustering) to find\nnatural groups in the dataset. It is, however, often not clear whether these\ndistance measures effectively take into account the specific temporal\ncorrelations in these time series. The second class of methods uses the\ninput/output data to identify a dynamic system using an identification scheme,\nand then applies a model norm-based distance (e.g. H2, H-infinity) to find out\nwhich systems are similar. This, however, can be very time consuming for large\namounts of long time series data. We show that the new distance measure\npresented in this paper performs as good as when every input/output pair is\nmodelled explicitly, but remains computationally much less complex. The\ncomplexity of calculating this distance between two time series of length N is\nO(N logN).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Oblivious Routing via Random Walks.   We present novel oblivious routing algorithms for both splittable and\nunsplittable multicommodity flow. Our algorithm for minimizing congestion for\n\\emph{unsplittable} multicommodity flow is the first oblivious routing\nalgorithm for this setting. As an intermediate step towards this algorithm, we\npresent a novel generalization of Valiant's classical load balancing scheme for\npacket-switched networks to arbitrary graphs, which is of independent interest.\nOur algorithm for minimizing congestion for \\emph{splittable} multicommodity\nflow improves upon the state-of-the-art, in terms of both running time and\nperformance, for graphs that exhibit good expansion guarantees. Our algorithms\nrely on diffusing traffic via iterative applications of the random walk\noperator. Consequently, the performance guarantees of our algorithms are\nderived from the convergence of the random walk operator to the stationary\ndistribution and are expressed in terms of the spectral gap of the graph (which\ndominates the mixing time).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A novel approach to the Lindelöf hypothesis.   Lindel{ö}f's hypothesis, one of the most important open problems in the\nhistory of mathematics, states that for large $t$, Riemann's zeta function\n$\\zeta(\\frac{1}{2}+it)$ is of order $O(t^{\\varepsilon})$ for any\n$\\varepsilon>0$. It is well known that for large $t$, the leading order\nasymptotics of the Riemann zeta function can be expressed in terms of a\ntranscendental exponential sum. The usual approach to the Lindelöf hypothesis\ninvolves the use of ingenious techniques for the estimation of this sum.\nHowever, since such estimates can not yield an asymptotic formula for the above\nsum, it appears that this approach cannot lead to the proof of the Lindelöf\nhypothesis. Here, a completely different approach is introduced: the Riemann\nzeta function is embedded in a classical problem in the theory of complex\nanalysis known as a Riemann-Hilbert problem, and then, the large\n$t$-asymptotics of the associated integral equation is formally computed. This\nyields two different results. First, the formal proof that a certain Riemann\nzeta-type double exponential sum satisfies the asymptotic estimate of the\nLindelöf hypothesis. Second, it is formally shown that the sum of\n$|\\zeta(1/2+it)|^2$ and of a certain sum which depends on $\\epsilon$, satisfies\nfor large $t$ the estimate of the Lindelöf hypothesis. Hence, since the above\nidentity is valid for all $\\epsilon$, this asymptotic identity suggests the\nvalidity of Lindelöf's hypothesis. The completion of the rigorous derivation\nof the above results will be presented in a companion paper.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An intracardiac electrogram model to bridge virtual hearts and implantable cardiac devices.   Virtual heart models have been proposed to enhance the safety of implantable\ncardiac devices through closed loop validation. To communicate with a virtual\nheart, devices have been driven by cardiac signals at specific sites. As a\nresult, only the action potentials of these sites are sensed. However, the real\ndevice implanted in the heart will sense a complex combination of near and\nfar-field extracellular potential signals. Therefore many device functions,\nsuch as blanking periods and refractory periods, are designed to handle these\nunexpected signals. To represent these signals, we develop an intracardiac\nelectrogram (IEGM) model as an interface between the virtual heart and the\ndevice. The model can capture not only the local excitation but also far-field\nsignals and pacing afterpotentials. Moreover, the sensing controller can\nspecify unipolar or bipolar electrogram (EGM) sensing configurations and\nintroduce various oversensing and undersensing modes. The simulation results\nshow that the model is able to reproduce clinically observed sensing problems,\nwhich significantly extends the capabilities of the virtual heart model in the\ncontext of device validation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Fermions in Two Dimensions: Scattering and Many-Body Properties.   Ultracold atomic Fermi gases in two-dimensions (2D) are an increasingly\npopular topic of research. The interaction strength between spin-up and\nspin-down particles in two-component Fermi gases can be tuned in experiments,\nallowing for a strongly interacting regime where the gas properties are yet to\nbe fully understood. We have probed this regime for 2D Fermi gases by\nperforming T=0 ab initio diffusion Monte Carlo calculations. The many-body\ndynamics are largely dependent on the two-body interactions, therefore we start\nwith an in-depth look at scattering theory in 2D. We show the partial-wave\nexpansion and its relation to the scattering length and effective range. Then\nwe discuss our numerical methods for determining these scattering parameters.\nWe close out this discussion by illustrating the details of bound states in 2D.\nTransitioning to the many-body system, we use variationally optimized wave\nfunctions to calculate ground-state properties of the gas over a range of\ninteraction strengths. We show results for the energy per particle and\nparametrize an equation of state. We then proceed to determine the chemical\npotential for the strongly interacting gas.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Sorted Concave Penalized Regression.   The Lasso is biased. Concave penalized least squares estimation (PLSE) takes\nadvantage of signal strength to reduce this bias, leading to sharper error\nbounds in prediction, coefficient estimation and variable selection. For\nprediction and estimation, the bias of the Lasso can be also reduced by taking\na smaller penalty level than what selection consistency requires, but such\nsmaller penalty level depends on the sparsity of the true coefficient vector.\nThe sorted L1 penalized estimation (Slope) was proposed for adaptation to such\nsmaller penalty levels. However, the advantages of concave PLSE and Slope do\nnot subsume each other. We propose sorted concave penalized estimation to\ncombine the advantages of concave and sorted penalizations. We prove that\nsorted concave penalties adaptively choose the smaller penalty level and at the\nsame time benefits from signal strength, especially when a significant\nproportion of signals are stronger than the corresponding adaptively selected\npenalty levels. A local convex approximation, which extends the local linear\nand quadratic approximations to sorted concave penalties, is developed to\nfacilitate the computation of sorted concave PLSE and proven to possess desired\nprediction and estimation error bounds. We carry out a unified treatment of\npenalty functions in a general optimization setting, including the penalty\nlevels and concavity of the above mentioned sorted penalties and mixed\npenalties motivated by Bayesian considerations. Our analysis of prediction and\nestimation errors requires the restricted eigenvalue condition on the design,\nnot beyond, and provides selection consistency under a required minimum signal\nstrength condition in addition. Thus, our results also sharpens existing\nresults on concave PLSE by removing the upper sparse eigenvalue component of\nthe sparse Riesz condition.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accelerated Stochastic Quasi-Newton Optimization on Riemann Manifolds.   We propose an L-BFGS optimization algorithm on Riemannian manifolds using\nminibatched stochastic variance reduction techniques for fast convergence with\nconstant step sizes, without resorting to linesearch methods designed to\nsatisfy Wolfe conditions. We provide a new convergence proof for strongly\nconvex functions without using curvature conditions on the manifold, as well as\na convergence discussion for nonconvex functions. We discuss a couple of ways\nto obtain the correction pairs used to calculate the product of the gradient\nwith the inverse Hessian, and empirically demonstrate their use in synthetic\nexperiments on computation of Karcher means for symmetric positive definite\nmatrices and leading eigenvalues of large scale data matrices. We compare our\nmethod to VR-PCA for the latter experiment, along with Riemannian SVRG for both\ncases, and show strong convergence results for a range of datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emergence and complexity in theoretical models of self-organized criticality.   In this thesis we present few theoretical studies of the models of\nself-organized criticality. Following a brief introduction of self-organized\ncriticality, we discuss three main problems. The first problem is about growing\npatterns formed in the abelian sandpile model (ASM). The patterns exhibit\nproportionate growth where different parts of the pattern grow in same rate,\nkeeping the overall shape unchanged. This non-trivial property, often found in\nbiological growth, has received increasing attention in recent years. In this\nthesis, we present a mathematical characterization of a large class of such\npatterns in terms of discrete holomorphic functions. In the second problem, we\ndiscuss a well known model of self-organized criticality introduced by Zhang in\n1989. We present an exact analysis of the model and quantitatively explain an\nintriguing property known as the emergence of quasi-units. In the third\nproblem, we introduce an operator algebra to determine the steady state of a\nclass of stochastic sandpile models.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Effective mass of quasiparticles from thermodynamics.   We discuss the potential advantages of calculating the effective mass of\nquasiparticles in the interacting electron liquid from the low-temperature free\nenergy vis-a-vis the conventional approach, in which the effective mass is\nobtained from approximate calculations of the self-energy, or from a quantum\nMonte Carlo evaluation of the energy of a variational \"quasiparticle wave\nfunction\". While raw quantum Monte Carlo data are presently too sparse to allow\nfor an accurate determination of the effective mass, the values estimated by\nthis method are numerically close to the ones obtained in previous calculations\nusing diagrammatic many-body theory. In contrast to this, a recently published\nparametrization of quantum Monte Carlo data for the free energy of the\nhomogeneous electron liquid yields effective masses that considerably deviate\nfrom previous calculations and even change sign for low densities, reflecting\nan unphysical negative entropy. We suggest that this anomaly is related to the\ntreatment of the exchange energy at finite temperature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Testing for Feature Relevance: The HARVEST Algorithm.   Feature selection with high-dimensional data and a very small proportion of\nrelevant features poses a severe challenge to standard statistical methods. We\nhave developed a new approach (HARVEST) that is straightforward to apply,\nalbeit somewhat computer-intensive. This algorithm can be used to pre-screen a\nlarge number of features to identify those that are potentially useful. The\nbasic idea is to evaluate each feature in the context of many random subsets of\nother features. HARVEST is predicated on the assumption that an irrelevant\nfeature can add no real predictive value, regardless of which other features\nare included in the subset. Motivated by this idea, we have derived a simple\nstatistical test for feature relevance. Empirical analyses and simulations\nproduced so far indicate that the HARVEST algorithm is highly effective in\npredictive analytics, both in science and business.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Universal geometric constraints during epithelial jamming.   As an injury heals, an embryo develops, or a carcinoma spreads, epithelial\ncells systematically change their shape. In each of these processes cell shape\nis studied extensively, whereas variation of shape from cell-to-cell is\ndismissed most often as biological noise. But where do cell shape and variation\nof cell shape come from? Here we report that cell shape and shape variation are\nmutually constrained through a relationship that is purely geometrical. That\nrelationship is shown to govern maturation of the pseudostratified bronchial\nepithelial layer cultured from both non-asthmatic and asthmatic donors as well\nas formation of the ventral furrow in the epithelial monolayer of the\nDrosophila embryo in vivo. Across these and other vastly different epithelial\nsystems, cell shape variation collapses to a family of distributions that is\ncommon to all and potentially universal. That distribution, in turn, is\naccounted for quantitatively by a mechanistic theory of cell-cell interaction\nshowing that cell shape becomes progressively less elongated and less variable\nas the layer becomes progressively more jammed. These findings thus uncover a\nconnection between jamming and geometry that is generic -spanning jammed living\nand inert systems alike- and demonstrate that proximity of the cell layer to\nthe jammed state is the principal determinant of the most primitive features of\nepithelial cell shape and shape variation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Randomization-based Inference for Bernoulli-Trial Experiments and Implications for Observational Studies.   We present a randomization-based inferential framework for experiments\ncharacterized by a strongly ignorable assignment mechanism where units have\nindependent probabilities of receiving treatment. Previous works on\nrandomization tests often assume these probabilities are equal within blocks of\nunits. We consider the general case where they differ across units and show how\nto perform randomization tests and obtain point estimates and confidence\nintervals. Furthermore, we develop a rejection-sampling algorithm to conduct\nrandomization-based inference conditional on ancillary statistics, covariate\nbalance, or other statistics of interest. Through simulation we demonstrate how\nour algorithm can yield powerful randomization tests and thus precise\ninference. Our work also has implications for observational studies, which\ncommonly assume a strongly ignorable assignment mechanism. Most methodologies\nfor observational studies make additional modeling or asymptotic assumptions,\nwhile our framework only assumes the strongly ignorable assignment mechanism,\nand thus can be considered a minimal-assumption approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inner-Scene Similarities as a Contextual Cue for Object Detection.   Using image context is an effective approach for improving object detection.\nPreviously proposed methods used contextual cues that rely on semantic or\nspatial information. In this work, we explore a different kind of contextual\ninformation: inner-scene similarity. We present the CISS (Context by Inner\nScene Similarity) algorithm, which is based on the observation that two\nvisually similar sub-image patches are likely to share semantic identities,\nespecially when both appear in the same image. CISS uses base-scores provided\nby a base detector and performs as a post-detection stage. For each candidate\nsub-image (denoted anchor), the CISS algorithm finds a few similar sub-images\n(denoted supporters), and, using them, calculates a new enhanced score for the\nanchor. This is done by utilizing the base-scores of the supporters and a\npre-trained dependency model. The new scores are modeled as a linear function\nof the base scores of the anchor and the supporters and is estimated using a\nminimum mean square error optimization. This approach results in: (a) improved\ndetection of partly occluded objects (when there are similar non-occluded\nobjects in the scene), and (b) fewer false alarms (when the base detector\nmistakenly classifies a background patch as an object). This work relates to\nDuncan and Humphreys' \"similarity theory,\" a psychophysical study. which\nsuggested that the human visual system perceptually groups similar image\nregions and that the classification of one region is affected by the estimated\nidentity of the other. Experimental results demonstrate the enhancement of a\nbase detector's scores on the PASCAL VOC dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uniform Consistency in Stochastic Block Model with Continuous Community Label.   \\cite{bickel2009nonparametric} developed a general framework to establish\nconsistency of community detection in stochastic block model (SBM). In most\napplications of this framework, the community label is discrete. For example,\nin \\citep{bickel2009nonparametric,zhao2012consistency} the degree corrected SBM\nis assumed to have a discrete degree parameter. In this paper, we generalize\nthe method of \\cite{bickel2009nonparametric} to give consistency analysis of\nmaximum likelihood estimator (MLE) in SBM with continuous community label. We\nshow that there is a standard procedure to transform the $||\\cdot||_2$ error\nbound to the uniform error bound. We demonstrate the application of our general\nresults by proving the uniform consistency (strong consistency) of the MLE in\nthe exponential network model with interaction effect. Unfortunately, in the\ncontinuous parameter case, the condition ensuring uniform consistency we\nobtained is much stronger than that in the discrete parameter case, namely\n$n\\mu_n^5/(\\log n)^{8}\\rightarrow\\infty$ versus $n\\mu_n/\\log\nn\\rightarrow\\infty$. Where $n\\mu_n$ represents the average degree of the\nnetwork. But continuous is the limit of discrete. So it is not surprising as we\nshow that by discretizing the community label space into sufficiently small\n(but not too small) pieces and applying the MLE on the discretized community\nlabel space, uniform consistency holds under almost the same condition as in\ndiscrete community label space. Such a phenomenon is surprising since the\ndiscretization does not depend on the data or the model. This reminds us of the\nthresholding method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Banach Algebra of Complex Bounded Radon Measures on Homogeneous Space.   Let $ H $ be a compact subgroup of a locally compact group $G$. In this paper\nwe define a convolution on $ M(G/H) $, the space of all complex bounded Radon\nmeasures on the homogeneous space G/H. Then we prove that the measure space $\nM(G/H, *) $ is a non-unital Banach algebra that possesses an approximate\nidentity. Finally, it is shown that the Banach algebra $ M(G/H, *) $ is not\ninvolutive and also $ L^1(G/H, *) $ is a two-sided ideal of it.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SOTER: Programming Safe Robotics System using Runtime Assurance.   Autonomous robots increasingly depend on third-party off-the-shelf components\nand complex machine-learning techniques. This trend makes it challenging to\nprovide strong design-time certification of correct operation. To address this\nchallenge, we present SOTER, a programming framework that integrates the core\nprinciples of runtime assurance to enable the use of uncertified controllers,\nwhile still providing safety guarantees.\nRuntime Assurance (RTA) is an approach used for safety-critical systems where\ndesign-time analysis is coupled with run-time techniques to switch between\nunverified advanced controllers and verified simple controllers. In this paper,\nwe present a runtime assurance programming framework for modular design of\nprovably-safe robotics software. \\tool provides language primitives to\ndeclaratively construct a \\rta module consisting of an advanced controller\n(untrusted), a safe controller (trusted), and the desired safety specification\n(S). If the RTA module is well formed then the framework provides a formal\nguarantee that it satisfies property S. The compiler generates code for\nmonitoring system state and switching control between the advanced and safe\ncontroller in order to guarantee S. RTA allows complex systems to be\nconstructed through the composition of RTA modules.\nTo demonstrate the efficacy of our framework, we consider a real-world\ncase-study of building a safe drone surveillance system. Our experiments both\nin simulation and on actual drones show that RTA-enabled RTA ensures safety of\nthe system, including when untrusted third-party components have bugs or\ndeviate from the desired behavior.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Joint Power Allocation and Beamforming for Energy-Efficient Two-Way Multi-Relay Communications.   This paper considers the joint design of user power allocation and relay\nbeamforming in relaying communications, in which multiple pairs of\nsingle-antenna users exchange information with each other via multiple-antenna\nrelays in two time slots. All users transmit their signals to the relays in the\nfirst time slot while the relays broadcast the beamformed signals to all users\nin the second time slot. The aim is to maximize the system's energy efficiency\n(EE) subject to quality-of-service (QoS) constraints in terms of exchange\nthroughput requirements. The QoS constraints are nonconvex with many nonlinear\ncross-terms, so finding a feasible point is already computationally\nchallenging. The sum throughput appears in the numerator while the total\nconsumption power appears in the denominator of the EE objective function. The\nformer is a nonconcave function and the latter is a nonconvex function, making\nfractional programming useless for EE optimization. Nevertheless, efficient\niterations of low complexity to obtain its optimized solutions are developed.\nThe performances of the multiple-user and multiple-relay networks under various\nscenarios are evaluated to show the merit of the paper development.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Idempotent ordered semigroup.   An element e of an ordered semigroup $(S,\\cdot,\\leq)$ is called an ordered\nidempotent if $e\\leq e^2$. We call an ordered semigroup $S$ idempotent ordered\nsemigroup if every element of $S$ is an ordered idempotent. Every idempotent\nsemigroup is a complete semilattice of rectangular idempotent semigroups and in\nthis way we arrive to many other important classes of idempotent ordered\nsemigroups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Wall modeling via function enrichment: extension to detached-eddy simulation.   We extend the approach of wall modeling via function enrichment to\ndetached-eddy simulation. The wall model aims at using coarse cells in the\nnear-wall region by modeling the velocity profile in the viscous sublayer and\nlog-layer. However, unlike other wall models, the full Navier-Stokes equations\nare still discretely fulfilled, including the pressure gradient and convective\nterm. This is achieved by enriching the elements of the high-order\ndiscontinuous Galerkin method with the law-of-the-wall. As a result, the\nGalerkin method can \"choose\" the optimal solution among the polynomial and\nenrichment shape functions. The detached-eddy simulation methodology provides a\nsuitable turbulence model for the coarse near-wall cells. The approach is\napplied to wall-modeled LES of turbulent channel flow in a wide range of\nReynolds numbers. Flow over periodic hills shows the superiority compared to an\nequilibrium wall model under separated flow conditions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The first and second fundamental theorems of invariant theory for the quantum general linear supergroup.   We develop the non-commutative polynomial version of the invariant theory for\nthe quantum general linear supergroup ${\\rm{ U}}_q(\\mathfrak{gl}_{m|n})$. A\nnon-commutative ${\\rm{ U}}_q(\\mathfrak{gl}_{m|n})$-module superalgebra\n$\\mathcal{P}^{k|l}_{\\,r|s}$ is constructed, which is the quantum analogue of\nthe supersymmetric algebra over $\\mathbb{C}^{k|l}\\otimes \\mathbb{C}^{m|n}\\oplus\n\\mathbb{C}^{r|s}\\otimes (\\mathbb{C}^{m|n})^{\\ast}$. We analyse the structure of\nthe subalgebra of ${\\rm{ U}}_q(\\mathfrak{gl}_{m|n})$-invariants in\n$\\mathcal{P}^{k|l}_{\\,r|s}$ by using the quantum super analogue of Howe\nduality.\nThe subalgebra of ${\\rm{ U}}_q(\\mathfrak{gl}_{m|n})$-invariants in\n$\\mathcal{P}^{k|l}_{\\,r|s}$ is shown to be finitely generated. We determine its\ngenerators and establish a surjective superalgebra homomorphism from a braided\nsupersymmetric algebra onto it. This establishes the first fundamental theorem\nof invariant theory for ${\\rm{ U}}_q(\\mathfrak{gl}_{m|n})$.\nWe show that the above mentioned superalgebra homomorphism is an isomorphism\nif and only if $m\\geq \\min\\{k,r\\}$ and $n\\geq \\min\\{l,s\\}$, and obtain a\nmonomial basis for the subalgebra of invariants in this case. When the\nhomomorphism is not injective, we give a representation theoretical description\nof the generating elements of the kernel associated to the partition\n$((m+1)^{n+1})$, producing the second fundamental theorem of invariant theory\nfor ${\\rm{ U}}_q(\\mathfrak{gl}_{m|n})$.\nWe consider two applications of our results. A complete treatment of the\nnon-commutative polynomial version of invariant theory for ${\\rm{\nU}}_q(\\mathfrak{gl}_{m})$ is obtained as the special case with $n=0$, where an\nexplicit SFT is proved, which we believe to be new. The FFT and SFT of the\ninvariant theory for the general linear superalgebra are recovered from the\nclassical (i.e., $q\\to 1$) limit of our results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Algorithms Made Secure: A Graph Theoretic Approach.   In the area of distributed graph algorithms a number of network's entities\nwith local views solve some computational task by exchanging messages with\ntheir neighbors. Quite unfortunately, an inherent property of most existing\ndistributed algorithms is that throughout the course of their execution, the\nnodes get to learn not only their own output but rather learn quite a lot on\nthe inputs or outputs of many other entities. This leakage of information might\nbe a major obstacle in settings where the output (or input) of network's\nindividual is a private information. In this paper, we introduce a new\nframework for \\emph{secure distributed graph algorithms} and provide the first\n\\emph{general compiler} that takes any \"natural\" non-secure distributed\nalgorithm that runs in $r$ rounds, and turns it into a secure algorithm that\nruns in $\\widetilde{O}(r \\cdot D \\cdot poly(\\Delta))$ rounds where $\\Delta$ is\nthe maximum degree in the graph and $D$ is its diameter. The security of the\ncompiled algorithm is information-theoretic but holds only against a\nsemi-honest adversary that controls a single node in the network.\nThis compiler is made possible due to a new combinatorial structure called\n\\emph{private neighborhood trees}: a collection of $n$ trees\n$T(u_1),\\ldots,T(u_n)$, one for each vertex $u_i \\in V(G)$, such that each tree\n$T(u_i)$ spans the neighbors of $u_i$ {\\em without going through $u_i$}.\nIntuitively, each tree $T(u_i)$ allows all neighbors of $u_i$ to exchange a\n\\emph{secret} that is hidden from $u_i$, which is the basic graph\ninfrastructure of the compiler. In a $(d,c)$-private neighborhood trees each\ntree $T(u_i)$ has depth at most $d$ and each edge $e \\in G$ appears in at most\n$c$ different trees. We show a construction of private neighborhood trees with\n$d=\\widetilde{O}(\\Delta \\cdot D)$ and $c=\\widetilde{O}(D)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dropout is a special case of the stochastic delta rule: faster and more accurate deep learning.   Multi-layer neural networks have lead to remarkable performance on many kinds\nof benchmark tasks in text, speech and image processing. Nonlinear parameter\nestimation in hierarchical models is known to be subject to overfitting. One\napproach to this overfitting and related problems (local minima, colinearity,\nfeature discovery etc.) is called dropout (Srivastava, et al 2014, Baldi et al\n2016). This method removes hidden units with a Bernoulli random variable with\nprobability $p$ over updates. In this paper we will show that Dropout is a\nspecial case of a more general model published originally in 1990 called the\nstochastic delta rule ( SDR, Hanson, 1990). SDR parameterizes each weight in\nthe network as a random variable with mean $\\mu_{w_{ij}}$ and standard\ndeviation $\\sigma_{w_{ij}}$. These random variables are sampled on each forward\nactivation, consequently creating an exponential number of potential networks\nwith shared weights. Both parameters are updated according to prediction error,\nthus implementing weight noise injections that reflect a local history of\nprediction error and efficient model averaging. SDR therefore implements a\nlocal gradient-dependent simulated annealing per weight converging to a bayes\noptimal network. Tests on standard benchmarks (CIFAR) using a modified version\nof DenseNet shows the SDR outperforms standard dropout in error by over 50% and\nin loss by over 50%. Furthermore, the SDR implementation converges on a\nsolution much faster, reaching a training error of 5 in just 15 epochs with\nDenseNet-40 compared to standard DenseNet-40's 94 epochs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uniform Rates of Convergence of Some Representations of Extremes : a first approach.   Uniform convergence rates are provided for asymptotic representations of\nsample extremes. These bounds which are universal in the sense that they do not\ndepend on the extreme value index are meant to be extended to arbitrary samples\nextremes in coming papers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Greed Works - Online Algorithms For Unrelated Machine Stochastic Scheduling.   This paper establishes the first performance guarantees for a combinatorial\nonline algorithm that schedules stochastic, nonpreemptive jobs on unrelated\nmachines to minimize the expected total weighted completion time. Prior work on\nunrelated machine scheduling with stochastic jobs was restricted to the offline\ncase, and required sophisticated linear or convex programming relaxations for\nthe assignment of jobs to machines. The algorithm introduced in this paper is\nbased on a purely combinatorial assignment of jobs to machines, hence it also\nworks online. The performance bounds are of the same order of magnitude as\nthose of earlier work, and depend linearly on an upper bound $\\Delta$ on the\nsquared coefficient of variation of the jobs' processing times. They are\n$4+2\\Delta$ when there are no release dates, and $12+6\\Delta$ when jobs are\nreleased over time. For the special case of deterministic processing times,\nwithout and with release times, this paper shows that the same combinatorial\ngreedy algorithm has a competitive ratio of 4 and 6, respectively. As to the\ntechnical contribution, the paper shows for the first time how dual fitting\ntechniques can be used for stochastic and nonpreemptive scheduling problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hybrid Optimization Method for Reconfiguration of AC/DC Microgrids in All-Electric Ships.   Since the limited power capacity, finite inertia, and dynamic loads make the\nshipboard power system (SPS) vulnerable, the automatic reconfiguration for\nfailure recovery in SPS is an extremely significant but still challenging\nproblem. It is not only required to operate accurately and optimally, but also\nto satisfy operating constraints. In this paper, we consider the\nreconfiguration optimization for hybrid AC/DC microgrids in all-electric ships.\nFirstly, the multi-zone medium voltage DC (MVDC) SPS model is presented. In\nthis model, the DC power flow for reconfiguration and a generalized AC/DC\nconverter are modeled for accurate reconfiguration. Secondly, since this\nproblem is mixed integer nonlinear programming (MINLP), a hybrid method based\non Newton Raphson and Biogeography based Optimization (NRBBO) is designed\naccording to the characteristics of system, loads, and faults. This method\nfacilitates to maximize the weighted load restoration while satisfying\noperating constraints. Finally, the simulation results demonstrate this method\nhas advantages in terms of power restoration and convergence speed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Automatic classification of trees using a UAV onboard camera and deep learning.   Automatic classification of trees using remotely sensed data has been a dream\nof many scientists and land use managers. Recently, Unmanned aerial vehicles\n(UAV) has been expected to be an easy-to-use, cost-effective tool for remote\nsensing of forests, and deep learning has attracted attention for its ability\nconcerning machine vision. In this study, using a commercially available UAV\nand a publicly available package for deep learning, we constructed a machine\nvision system for the automatic classification of trees. In our method, we\nsegmented a UAV photography image of forest into individual tree crowns and\ncarried out object-based deep learning. As a result, the system was able to\nclassify 7 tree types at 89.0% accuracy. This performance is notable because we\nonly used basic RGB images from a standard UAV. In contrast, most of previous\nstudies used expensive hardware such as multispectral imagers to improve the\nperformance. This result means that our method has the potential to classify\nindividual trees in a cost-effective manner. This can be a usable tool for many\nforest researchers and managements.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Faster Learning by Reduction of Data Access Time.   Nowadays, the major challenge in machine learning is the Big Data challenge.\nThe big data problems due to large number of data points or large number of\nfeatures in each data point, or both, the training of models have become very\nslow. The training time has two major components: Time to access the data and\ntime to process (learn from) the data. So far, the research has focused only on\nthe second part, i.e., learning from the data. In this paper, we have proposed\none possible solution to handle the big data problems in machine learning. The\nidea is to reduce the training time through reducing data access time by\nproposing systematic sampling and cyclic/sequential sampling to select\nmini-batches from the dataset. To prove the effectiveness of proposed sampling\ntechniques, we have used Empirical Risk Minimization, which is commonly used\nmachine learning problem, for strongly convex and smooth case. The problem has\nbeen solved using SAG, SAGA, SVRG, SAAG-II and MBSGD (Mini-batched SGD), each\nusing two step determination techniques, namely, constant step size and\nbacktracking line search method. Theoretical results prove the same convergence\nfor systematic sampling, cyclic sampling and the widely used random sampling\ntechnique, in expectation. Experimental results with bench marked datasets\nprove the efficacy of the proposed sampling techniques and show up to six times\nfaster training.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mean-variance portfolio selection under partial information with drift uncertainty.   This paper studies a mean-variance portfolio selection problem under partial\ninformation with drift uncertainty. It is proved that all the contingent claims\nin this model are attainable in the sense of Xiong and Zhou. Further, we\npropose a numerical scheme to approximate the optimal portfolio. Malliavin\ncalculus and the strong law of large numbers play important roles in this\nscheme.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Sparse Adversarial Dictionaries For Multi-Class Audio Classification.   Audio events are quite often overlapping in nature, and more prone to noise\nthan visual signals. There has been increasing evidence for the superior\nperformance of representations learned using sparse dictionaries for\napplications like audio denoising and speech enhancement. This paper\nconcentrates on modifying the traditional reconstructive dictionary learning\nalgorithms, by incorporating a discriminative term into the objective function\nin order to learn class-specific adversarial dictionaries that are good at\nrepresenting samples of their own class at the same time poor at representing\nsamples belonging to any other class. We quantitatively demonstrate the\neffectiveness of our learned dictionaries as a stand-alone solution for both\nbinary as well as multi-class audio classification problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Global spectral graph wavelet signature for surface analysis of carpal bones.   In this paper, we present a spectral graph wavelet approach for shape\nanalysis of carpal bones of human wrist. We apply a metric called global\nspectral graph wavelet signature for representation of cortical surface of the\ncarpal bone based on eigensystem of Laplace-Beltrami operator. Furthermore, we\npropose a heuristic and efficient way of aggregating local descriptors of a\ncarpal bone surface to global descriptor. The resultant global descriptor is\nnot only isometric invariant, but also much more efficient and requires less\nmemory storage. We perform experiments on shape of the carpal bones of ten\nwomen and ten men from a publicly-available database. Experimental results show\nthe excellency of the proposed GSGW compared to recent proposed GPS embedding\napproach for comparing shapes of the carpal bones across populations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "OLÉ: Orthogonal Low-rank Embedding, A Plug and Play Geometric Loss for Deep Learning.   Deep neural networks trained using a softmax layer at the top and the\ncross-entropy loss are ubiquitous tools for image classification. Yet, this\ndoes not naturally enforce intra-class similarity nor inter-class margin of the\nlearned deep representations. To simultaneously achieve these two goals,\ndifferent solutions have been proposed in the literature, such as the pairwise\nor triplet losses. However, such solutions carry the extra task of selecting\npairs or triplets, and the extra computational burden of computing and learning\nfor many combinations of them. In this paper, we propose a plug-and-play loss\nterm for deep networks that explicitly reduces intra-class variance and\nenforces inter-class margin simultaneously, in a simple and elegant geometric\nmanner. For each class, the deep features are collapsed into a learned linear\nsubspace, or union of them, and inter-class subspaces are pushed to be as\northogonal as possible. Our proposed Orthogonal Low-rank Embedding (OLÉ) does\nnot require carefully crafting pairs or triplets of samples for training, and\nworks standalone as a classification loss, being the first reported deep metric\nlearning framework of its kind. Because of the improved margin between features\nof different classes, the resulting deep networks generalize better, are more\ndiscriminative, and more robust. We demonstrate improved classification\nperformance in general object recognition, plugging the proposed loss term into\nexisting off-the-shelf architectures. In particular, we show the advantage of\nthe proposed loss in the small data/model scenario, and we significantly\nadvance the state-of-the-art on the Stanford STL-10 benchmark.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Limits of Predictability of Cascading Overload Failures in Spatially-Embedded Networks with Distributed Flows.   Cascading failures are a critical vulnerability of complex information or\ninfrastructure networks. Here we investigate the properties of load-based\ncascading failures in real and synthetic spatially-embedded network structures,\nand propose mitigation strategies to reduce the severity of damages caused by\nsuch failures. We introduce a stochastic method for optimal heterogeneous\ndistribution of resources (node capacities) subject to a fixed total cost.\nAdditionally, we design and compare the performance of networks with N-stable\nand (N-1)-stable network-capacity allocations by triggering cascades using\nvarious real-world node-attack and node-failure scenarios. We show that failure\nmitigation through increased node protection can be effectively achieved\nagainst single node failures. However, mitigating against multiple node\nfailures is much more difficult due to the combinatorial increase in possible\nfailures. We analyze the robustness of the system with increasing protection,\nand find that a critical tolerance exists at which the system undergoes a phase\ntransition, and above which the network almost completely survives an attack.\nMoreover, we show that cascade-size distributions measured in this region\nexhibit a power-law decay. Finally, we find a strong correlation between\ncascade sizes induced by individual nodes and sets of nodes. We also show that\nnetwork topology alone is a weak factor in determining the progression of\ncascading failures.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Chatbots as Conversational Recommender Systems in Urban Contexts.   In this paper, we outline the vision of chatbots that facilitate the\ninteraction between citizens and policy-makers at the city scale. We report the\nresults of a co-design session attended by more than 60 participants. We give\nan outlook of how some challenges associated with such chatbot systems could be\naddressed in the future.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Imani Periodic Functions: Genesis and Preliminary Results.   The Leah-Hamiltonian, $H(x,y)=y^2/2+3x^{4/3}/4$, is introduced as a\nfunctional equation for $x(t)$ and $y(t)$. By means of a nonlinear\ntransformation to new independent variables, we show that this functional\nequation has a special class of periodic solutions which we designate the Imani\nfunctions. The explicit construction of these functions is done such that they\npossess many of the general properties of the standard trigonometric cosine and\nsine functions. We conclude by providing a listing of a number of currently\nunresolved issues relating to the Imani functions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On irrationality measure of Thue-Morse constant.   We provide a non-trivial measure of irrationality for a class of Mahler\nnumbers defined with infinite products which cover the Thue-Morse constant.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Image-based immersed boundary model of the aortic root.   Each year, approximately 300,000 heart valve repair or replacement procedures\nare performed worldwide, including approximately 70,000 aortic valve\nreplacement surgeries in the United States alone. This paper describes progress\nin constructing anatomically and physiologically realistic immersed boundary\n(IB) models of the dynamics of the aortic root and ascending aorta. This work\nbuilds on earlier IB models of fluid-structure interaction (FSI) in the aortic\nroot, which previously achieved realistic hemodynamics over multiple cardiac\ncycles, but which also were limited to simplified aortic geometries and\nidealized descriptions of the biomechanics of the aortic valve cusps. By\ncontrast, the model described herein uses an anatomical geometry reconstructed\nfrom patient-specific computed tomography angiography (CTA) data, and employs a\ndescription of the elasticity of the aortic valve leaflets based on a\nfiber-reinforced constitutive model fit to experimental tensile test data.\nNumerical tests show that the model is able to resolve the leaflet biomechanics\nin diastole and early systole at practical grid spacings. The model is also\nused to examine differences in the mechanics and fluid dynamics yielded by\nfresh valve leaflets and glutaraldehyde-fixed leaflets similar to those used in\nbioprosthetic heart valves. Although there are large differences in the leaflet\ndeformations during diastole, the differences in the open configurations of the\nvalve models are relatively small, and nearly identical hemodynamics are\nobtained in all cases considered.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Morphological Simplification of Archaeological Fracture Surfaces.   We propose to employ scale spaces of mathematical morphology to\nhierarchically simplify fracture surfaces of complementarily fitting\narchaeological fragments. This representation preserves contact and is\ninsensitive to different kinds of abrasion affecting the exact complementarity\nof the original fragments. We present a pipeline for morphologically\nsimplifying fracture surfaces, based on their Lipschitz nature; its core is a\nnew embedding of fracture surfaces to simultaneously compute both closing and\nopening morphological operations, using distance transforms.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On Ordinal Invariants in Well Quasi Orders and Finite Antichain Orders.   We investigate the ordinal invariants height, length, and width of well quasi\norders (WQO), with particular emphasis on width, an invariant of interest for\nthe larger class of orders with finite antichain condition (FAC). We show that\nthe width in the class of FAC orders is completely determined by the width in\nthe class of WQOs, in the sense that if we know how to calculate the width of\nany WQO then we have a procedure to calculate the width of any given FAC order.\nWe show how the width of WQO orders obtained via some classical constructions\ncan sometimes be computed in a compositional way. In particular, this allows\nproving that every ordinal can be obtained as the width of some WQO poset. One\nof the difficult questions is to give a complete formula for the width of\nCartesian products of WQOs. Even the width of the product of two ordinals is\nonly known through a complex recursive formula. Although we have not given a\ncomplete answer to this question we have advanced the state of knowledge by\nconsidering some more complex special cases and in particular by calculating\nthe width of certain products containing three factors. In the course of\nwriting the paper we have discovered that some of the relevant literature was\nwritten on cross-purposes and some of the notions re-discovered several times.\nTherefore we also use the occasion to give a unified presentation of the known\nresults.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Development of ICA and IVA Algorithms with Application to Medical Image Analysis.   Independent component analysis (ICA) is a widely used BSS method that can\nuniquely achieve source recovery, subject to only scaling and permutation\nambiguities, through the assumption of statistical independence on the part of\nthe latent sources. Independent vector analysis (IVA) extends the applicability\nof ICA by jointly decomposing multiple datasets through the exploitation of the\ndependencies across datasets. Though both ICA and IVA algorithms cast in the\nmaximum likelihood (ML) framework enable the use of all available statistical\ninformation in reality, they often deviate from their theoretical optimality\nproperties due to improper estimation of the probability density function\n(PDF). This motivates the development of flexible ICA and IVA algorithms that\nclosely adhere to the underlying statistical description of the data. Although\nit is attractive minimize the assumptions, important prior information about\nthe data, such as sparsity, is usually available. If incorporated into the ICA\nmodel, use of this additional information can relax the independence\nassumption, resulting in an improvement in the overall separation performance.\nTherefore, the development of a unified mathematical framework that can take\ninto account both statistical independence and sparsity is of great interest.\nIn this work, we first introduce a flexible ICA algorithm that uses an\neffective PDF estimator to accurately capture the underlying statistical\nproperties of the data. We then discuss several techniques to accurately\nestimate the parameters of the multivariate generalized Gaussian distribution,\nand how to integrate them into the IVA model. Finally, we provide a\nmathematical framework that enables direct control over the influence of\nstatistical independence and sparsity, and use this framework to develop an\neffective ICA algorithm that can jointly exploit these two forms of diversity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strongly regular decompositions and symmetric association schemes of a power of two.   For any positive integer $m$, the complete graph on $2^{2m}(2^m+2)$ vertices\nis decomposed into $2^m+1$ commuting strongly regular graphs, which give rise\nto a symmetric association scheme of class $2^{m+2}-2$. Furthermore, the\neigenmatrices of the symmetric association schemes are determined explicitly.\nAs an application, the eigenmatrix of the commutative strongly regular\ndecomposition obtained from the strongly regular graphs is derived.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Musical Instrument Recognition Using Their Distinctive Characteristics in Artificial Neural Networks.   In this study an Artificial Neural Network was trained to classify musical\ninstruments, using audio samples transformed to the frequency domain. Different\nfeatures of the sound, in both time and frequency domain, were analyzed and\ncompared in relation to how much information that could be derived from that\nlimited data. The study concluded that in comparison with the base experiment,\nthat had an accuracy of 93.5%, using the attack only resulted in 80.2% and the\ninitial 100 Hz in 64.2%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lagrangians of hypergraphs: The Frankl-Füredi conjecture holds almost everywhere.   Frankl and Füredi conjectured in 1989 that the maximum Lagrangian of all\n$r$-uniform hypergraphs of fixed size $m$ is realised by the initial segment of\nthe colexicographic order. In particular, in the principal case\n$m=\\binom{t}{r}$ their conjecture states that every $H\\subseteq\n\\mathbb{N}^{(r)}$ of size $\\binom{t}{r}$ satisfies \\begin{align*} \\max\n\\{\\sum_{A \\in H}\\prod_{i\\in A} y_i \\ \\colon \\ y_1,y_2,\\ldots \\geq 0; \\sum_{i\\in\n\\mathbb{N}} y_i=1 \\}&\\leq \\frac{1}{t^r}\\binom{t}{r}. \\end{align*}\nWe prove the above statement for all $r\\geq 4$ and large values of $t$ (the\ncase $r=3$ was settled by Talbot in 2002). More generally, we show for any\n$r\\geq 4$ that the Frankl-Füredi conjecture holds whenever $\\binom{t-1}{r}\n\\leq m \\leq \\binom{t}{r}- \\gamma_r t^{r-2}$ for a constant $\\gamma_r>0$,\nthereby verifying it for `most' $m\\in \\mathbb{N}$.\nFurthermore, for $r=3$ we make an improvement on the results of\nTalbot~\\cite{Tb} and Tang, Peng, Zhang and Zhao~\\cite{TPZZ}.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strong-coupling of WSe2 in ultra-compact plasmonic nanocavities at room temperature.   Strong-coupling of monolayer metal dichalcogenide semiconductors with light\noffers encouraging prospects for realistic exciton devices at room temperature.\nHowever, the nature of this coupling depends extremely sensitively on the\noptical confinement and the orientation of electronic dipoles and fields. Here,\nwe show how plasmon strong coupling can be achieved in compact robust\neasily-assembled gold nano-gap resonators at room temperature. We prove that\nstrong coupling is impossible with monolayers due to the large exciton\ncoherence size, but resolve clear anti-crossings for 8 layer devices with Rabi\nsplittings exceeding 135 meV. We show that such structures improve on prospects\nfor nonlinear exciton functionalities by at least 10^4, while retaining quantum\nefficiencies above 50%.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Proximodistal Exploration in Motor Learning as an Emergent Property of Optimization.   To harness the complexity of their high-dimensional bodies during\nsensorimotor development, infants are guided by patterns of freezing and\nfreeing of degrees of freedom. For instance, when learning to reach, infants\nfree the degrees of freedom in their arm proximodistally, i.e. from joints that\nare closer to the body to those that are more distant. Here, we formulate and\nstudy computationally the hypothesis that such patterns can emerge\nspontaneously as the result of a family of stochastic optimization processes\n(evolution strategies with covariance-matrix adaptation), without an innate\nencoding of a maturational schedule. In particular, we present simulated\nexperiments with an arm where a computational learner progressively acquires\nreaching skills through adaptive exploration, and we show that a proximodistal\norganization appears spontaneously, which we denote PDFF (ProximoDistal\nFreezing and Freeing of degrees of freedom). We also compare this emergent\norganization between different arm morphologies -- from human-like to quite\nunnatural ones -- to study the effect of different kinematic structures on the\nemergence of PDFF. Keywords: human motor learning; proximo-distal exploration;\nstochastic optimization; modelling; evolution strategies; cross-entropy\nmethods; policy search; morphology.}",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Robust Kalman Filter.   A Robust Markov Decision Process (RMDP) is a sequential decision making model\nthat accounts for uncertainty in the parameters of dynamic systems. This\nuncertainty introduces difficulties in learning an optimal policy, especially\nfor environments with large state spaces. We propose two algorithms, RTD-DQN\nand Deep-RoK, for solving large-scale RMDPs using nonlinear approximation\nschemes such as deep neural networks. The RTD-DQN algorithm incorporates the\nrobust Bellman temporal difference error into a robust loss function, yielding\nrobust policies for the agent. The Deep-RoK algorithm is a robust Bayesian\nmethod, based on the Extended Kalman Filter (EKF), that accounts for both the\nuncertainty in the weights of the approximated value function and the\nuncertainty in the transition probabilities, improving the robustness of the\nagent. We provide theoretical results for our approach and test the proposed\nalgorithms on a continuous state domain.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A variant of Gromov's problem on Hölder equivalence of Carnot groups.   It is unknown if there exists a locally $\\alpha$-Hölder homeomorphism\n$f:\\mathbb{R}^3\\to \\mathbb{H}^1$ for any $\\frac{1}{2}< \\alpha\\le \\frac{2}{3}$,\nalthough the identity map $\\mathbb{R}^3\\to \\mathbb{H}^1$ is locally\n$\\frac{1}{2}$-Hölder. More generally, Gromov asked: Given $k$ and a Carnot\ngroup $G$, for which $\\alpha$ does there exist a locally $\\alpha$-Hölder\nhomeomorphism $f:\\mathbb{R}^k\\to G$? Here, we equip a Carnot group $G$ with the\nCarnot-Carathéodory metric. In 2014, Balogh, Hajlasz, and Wildrick considered\na variant of this problem. These authors proved that if $k>n$, there does not\nexist an injective, $(\\frac{1}{2}+)$-Hölder mapping $f:\\mathbb{R}^k\\to\n\\mathbb{H}^n$ that is also locally Lipschitz as a mapping into\n$\\mathbb{R}^{2n+1}$. For their proof, they use the fact that $\\mathbb{H}^n$ is\npurely $k$-unrectifiable for $k>n$. In this paper, we will extend their result\nfrom the Heisenberg group to model filiform groups and Carnot groups of step at\nmost three. We will now require that the Carnot group is purely\n$k$-unrectifiable. The main key to our proof will be showing that\n$(\\frac{1}{2}+)$-Hölder maps $f:\\mathbb{R}^k\\to G$ that are locally Lipschitz\ninto Euclidean space, are weakly contact. Proving weak contactness in these two\nsettings requires understanding the relationship between the algebraic and\nmetric structures of the Carnot group. We will use coordinates of the first and\nsecond kind for Carnot groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological Representation of the Transit Sets of k-Point Crossover Operators.   $k$-point crossover operators and their recombination sets are studied from\ndifferent perspectives. We show that transit functions of $k$-point crossover\ngenerate, for all $k>1$, the same convexity as the interval function of the\nunderlying graph. This settles in the negative an open problem by Mulder about\nwhether the geodesic convexity of a connected graph $G$ is uniquely determined\nby its interval function $I$. The conjecture of Gitchoff and Wagner that for\neach transit set $R_k(x,y)$ distinct from a hypercube there is a unique pair of\nparents from which it is generated is settled affirmatively. Along the way we\ncharacterize transit functions whose underlying graphs are Hamming graphs, and\nthose with underlying partial cube graphs. For general values of $k$ it is\nshown that the transit sets of $k$-point crossover operators are the subsets\nwith maximal Vapnik-Chervonenkis dimension. Moreover, the transit sets of\n$k$-point crossover on binary strings form topes of uniform oriented matroid of\nVC-dimension $k+1$. The Topological Representation Theorem for oriented\nmatroids therefore implies that $k$-point crossover operators can be\nrepresented by pseudosphere arrangements. This provides the tools necessary to\nstudy the special case $k=2$ in detail.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A New Compton-thick AGN in our Cosmic Backyard: Unveiling the Buried Nucleus in NGC 1448 with NuSTAR.   NGC 1448 is one of the nearest luminous galaxies ($L_{8-1000\\mu m} >$ 10$^{9}\nL_{\\odot}$) to ours ($z$ $=$ 0.00390), and yet the active galactic nucleus\n(AGN) it hosts was only recently discovered, in 2009. In this paper, we present\nan analysis of the nuclear source across three wavebands: mid-infrared (MIR)\ncontinuum, optical, and X-rays. We observed the source with the Nuclear\nSpectroscopic Telescope Array (NuSTAR), and combined this data with archival\nChandra data to perform broadband X-ray spectral fitting ($\\approx$0.5-40 keV)\nof the AGN for the first time. Our X-ray spectral analysis reveals that the AGN\nis buried under a Compton-thick (CT) column of obscuring gas along our\nline-of-sight, with a column density of $N_{\\rm H}$(los) $\\gtrsim$ 2.5 $\\times$\n10$^{24}$ cm$^{-2}$. The best-fitting torus models measured an intrinsic 2-10\nkeV luminosity of $L_{2-10\\rm{,int}}$ $=$ (3.5-7.6) $\\times$ 10$^{40}$ erg\ns$^{-1}$, making NGC 1448 one of the lowest luminosity CTAGNs known. In\naddition to the NuSTAR observation, we also performed optical spectroscopy for\nthe nucleus in this edge-on galaxy using the European Southern Observatory New\nTechnology Telescope. We re-classify the optical nuclear spectrum as a Seyfert\non the basis of the Baldwin-Philips-Terlevich diagnostic diagrams, thus\nidentifying the AGN at optical wavelengths for the first time. We also present\nhigh spatial resolution MIR observations of NGC 1448 with Gemini/T-ReCS, in\nwhich a compact nucleus is clearly detected. The absorption-corrected 2-10 keV\nluminosity measured from our X-ray spectral analysis agrees with that predicted\nfrom the optical [OIII]$\\lambda$5007\\AA\\ emission line and the MIR 12$\\mu$m\ncontinuum, further supporting the CT nature of the AGN.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The empirical Christoffel function with applications in data analysis.   We illustrate the potential applications in machine learning of the\nChristoffel function, or more precisely, its empirical counterpart associated\nwith a counting measure uniformly supported on a finite set of points. Firstly,\nwe provide a thresholding scheme which allows to approximate the support of a\nmeasure from a finite subset of its moments with strong asymptotic guaranties.\nSecondly, we provide a consistency result which relates the empirical\nChristoffel function and its population counterpart in the limit of large\nsamples. Finally, we illustrate the relevance of our results on simulated and\nreal world datasets for several applications in statistics and machine\nlearning: (a) density and support estimation from finite samples, (b) outlier\nand novelty detection and (c) affine matching.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonparametric Variational Auto-encoders for Hierarchical Representation Learning.   The recently developed variational autoencoders (VAEs) have proved to be an\neffective confluence of the rich representational power of neural networks with\nBayesian methods. However, most work on VAEs use a rather simple prior over the\nlatent variables such as standard normal distribution, thereby restricting its\napplications to relatively simple phenomena. In this work, we propose\nhierarchical nonparametric variational autoencoders, which combines\ntree-structured Bayesian nonparametric priors with VAEs, to enable infinite\nflexibility of the latent representation space. Both the neural parameters and\nBayesian priors are learned jointly using tailored variational inference. The\nresulting model induces a hierarchical structure of latent semantic concepts\nunderlying the data corpus, and infers accurate representations of data\ninstances. We apply our model in video representation learning. Our method is\nable to discover highly interpretable activity hierarchies, and obtain improved\nclustering accuracy and generalization capacity based on the learned rich\nrepresentations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Defend against advanced persistent threats: An optimal control approach.   The new cyber attack pattern of advanced persistent threat (APT) has posed a\nserious threat to modern society. This paper addresses the APT defense problem,\ni.e., the problem of how to effectively defend against an APT campaign. Based\non a novel APT attack-defense model, the effectiveness of an APT defense\nstrategy is quantified. Thereby, the APT defense problem is modeled as an\noptimal control problem, in which an optimal control stands for a most\neffective APT defense strategy. The existence of an optimal control is proved,\nand an optimality system is derived. Consequently, an optimal control can be\nfigured out by solving the optimality system. Some examples of the optimal\ncontrol are given. Finally, the influence of some factors on the effectiveness\nof an optimal control is examined through computer experiments. These findings\nhelp organizations to work out policies of defending against APTs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evolution of Morphological and Physical Properties of Laboratory Interstellar Organic Residues with Ultraviolet Irradiation.   Refractory organic compounds formed in molecular clouds are among the\nbuilding blocks of the solar system objects and could be the precursors of\norganic matter found in primitive meteorites and cometary materials. However,\nlittle is known about the evolutionary pathways of molecular cloud organics\nfrom dense molecular clouds to planetary systems. In this study, we focus on\nthe evolution of the morphological and viscoelastic properties of molecular\ncloud refractory organic matter. We found that the organic residue,\nexperimentally synthesized at about 10 K from UV-irradiated H2O-CH3OH-NH3 ice,\nchanged significantly in terms of its nanometer- to micrometer-scale morphology\nand viscoelastic properties after UV irradiation at room temperature. The dose\nof this irradiation was equivalent to that experienced after short residence in\ndiffuse clouds (equal or less than 10,000 years) or irradiation in outer\nprotoplanetary disks. The irradiated organic residues became highly porous and\nmore rigid and formed amorphous nanospherules. These nanospherules are\nmorphologically similar to organic nanoglobules observed in the least-altered\nchondrites, chondritic porous interplanetary dust particles, and cometary\nsamples, suggesting that irradiation of refractory organics could be a possible\nformation pathway for such nanoglobules. The storage modulus (elasticity) of\nphoto-irradiated organic residues is about 100 MPa irrespective of vibrational\nfrequency, a value that is lower than the storage moduli of minerals and ice.\nDust grains coated with such irradiated organics would therefore stick together\nefficiently, but growth to larger grains might be suppressed due to an increase\nin aggregate brittleness caused by the strong connections between grains.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Testing the validity of the local and global GKLS master equations on an exactly solvable model.   When deriving a master equation for a multipartite weakly-interacting open\nquantum systems, dissipation is often addressed \\textit{locally} on each\ncomponent, i.e. ignoring the coherent couplings, which are later added `by\nhand'. Although simple, the resulting local master equation (LME) is known to\nbe thermodynamically inconsistent. Otherwise, one may always obtain a\nconsistent \\textit{global} master equation (GME) by working on the energy basis\nof the full interacting Hamiltonian. Here, we consider a two-node `quantum\nwire' connected to two heat baths. The stationary solution of the LME and GME\nare obtained and benchmarked against the exact result. Importantly, in our\nmodel, the validity of the GME is constrained by the underlying secular\napproximation. Whenever this breaks down (for resonant weakly-coupled nodes),\nwe observe that the LME, in spite of being thermodynamically flawed: (a)\npredicts the correct steady state, (b) yields the exact asymptotic heat\ncurrents, and (c) reliably reflects the correlations between the nodes. In\ncontrast, the GME fails at all three tasks. Nonetheless, as the inter-node\ncoupling grows, the LME breaks down whilst the GME becomes correct. Hence, the\nglobal and local approach may be viewed as \\textit{complementary} tools, best\nsuited to different parameter regimes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Training of Deep Neural Networks based on Distance Measures using RMSProp.   The vanishing gradient problem was a major obstacle for the success of deep\nlearning. In recent years it was gradually alleviated through multiple\ndifferent techniques. However the problem was not really overcome in a\nfundamental way, since it is inherent to neural networks with activation\nfunctions based on dot products. In a series of papers, we are going to analyze\nalternative neural network structures which are not based on dot products. In\nthis first paper, we revisit neural networks built up of layers based on\ndistance measures and Gaussian activation functions. These kinds of networks\nwere only sparsely used in the past since they are hard to train when using\nplain stochastic gradient descent methods. We show that by using Root Mean\nSquare Propagation (RMSProp) it is possible to efficiently learn multi-layer\nneural networks. Furthermore we show that when appropriately initialized these\nkinds of neural networks suffer much less from the vanishing and exploding\ngradient problem than traditional neural networks even for deep networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exhaustive Exploration of the Failure-oblivious Computing Search Space.   High-availability of software systems requires automated handling of crashes\nin presence of errors. Failure-oblivious computing is one technique that aims\nto achieve high availability. We note that failure-obliviousness has not been\nstudied in depth yet, and there is very few study that helps understand why\nfailure-oblivious techniques work. In order to make failure-oblivious computing\nto have an impact in practice, we need to deeply understand failure-oblivious\nbehaviors in software. In this paper, we study, design and perform an\nexperiment that analyzes the size and the diversity of the failure-oblivious\nbehaviors. Our experiment consists of exhaustively computing the search space\nof 16 field failures of large-scale open-source Java software. The outcome of\nthis experiment is a much better understanding of what really happens when\nfailure-oblivious computing is used, and this opens new promising research\ndirections.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Confluence of Conditional Term Rewrite Systems via Transformations.   Conditional term rewriting is an intuitive yet complex extension of term\nrewriting. In order to benefit from the simpler framework of unconditional\nrewriting, transformations have been defined to eliminate the conditions of\nconditional term rewrite systems.\nRecent results provide confluence criteria for conditional term rewrite\nsystems via transformations, yet they are restricted to CTRSs with certain\nsyntactic properties like weak left-linearity. These syntactic properties imply\nthat the transformations are sound for the given CTRS.\nThis paper shows how to use transformations to prove confluence of\noperationally terminating, right-stable deterministic conditional term rewrite\nsystems without the necessity of soundness restrictions. For this purpose, it\nis shown that certain rewrite strategies, in particular almost U-eagerness and\ninnermost rewriting, always imply soundness.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From bare interactions, low--energy constants and unitary gas to nuclear density functionals without free parameters: application to neutron matter.   We further progress along the line of Ref. [Phys. Rev. {\\bf A 94}, 043614\n(2016)] where a functional for Fermi systems with anomalously large $s$-wave\nscattering length $a_s$ was proposed that has no free parameters. The\nfunctional is designed to correctly reproduce the unitary limit in Fermi gases\ntogether with the leading-order contributions in the s- and p-wave channels at\nlow density. The functional is shown to be predictive up to densities\n$\\sim0.01$ fm$^{-3}$ that is much higher densities compared to the Lee-Yang\nfunctional, valid for $\\rho < 10^{-6}$ fm$^{-3}$. The form of the functional\nretained in this work is further motivated. It is shown that the new functional\ncorresponds to an expansion of the energy in $(a_s k_F)$ and $(r_e k_F)$ to all\norders, where $r_e$ is the effective range and $k_F$ is the Fermi momentum. One\nconclusion from the present work is that, except in the extremely low--density\nregime, nuclear systems can be treated perturbatively in $-(a_s k_F)^{-1}$ with\nrespect to the unitary limit. Starting from the functional, we introduce\ndensity--dependent scales and show that scales associated to the bare\ninteraction are strongly renormalized by medium effects. As a consequence, some\nof the scales at play around saturation are dominated by the unitary gas\nproperties and not directly to low-energy constants. For instance, we show that\nthe scale in the s-wave channel around saturation is proportional to the\nso-called Bertsch parameter $\\xi_0$ and becomes independent of $a_s$. We also\npoint out that these scales are of the same order of magnitude than those\nempirically obtained in the Skyrme energy density functional. We finally\npropose a slight modification of the functional such that it becomes accurate\nup to the saturation density $\\rho\\simeq 0.16$ fm$^{-3}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards the study of least squares estimators with convex penalty.   Penalized least squares estimation is a popular technique in high-dimensional\nstatistics. It includes such methods as the LASSO, the group LASSO, and the\nnuclear norm penalized least squares. The existing theory of these methods is\nnot fully satisfying since it allows one to prove oracle inequalities with\nfixed high probability only for the estimators depending on this probability.\nFurthermore, the control of compatibility factors appearing in the oracle\nbounds is often not explicit. Some very recent developments suggest that the\ntheory of oracle inequalities can be revised in an improved way. In this paper,\nwe provide an overview of ideas and tools leading to such an improved theory.\nWe show that, along with overcoming the disadvantages mentioned above, the\nmethodology extends to the hilbertian framework and it applies to a large class\nof convex penalties. This paper is partly expository. In particular, we provide\nadapted proofs of some results from other recent work.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Residual Learning for Instrument Segmentation in Robotic Surgery.   Detection, tracking, and pose estimation of surgical instruments are crucial\ntasks for computer assistance during minimally invasive robotic surgery. In the\nmajority of cases, the first step is the automatic segmentation of surgical\ntools. Prior work has focused on binary segmentation, where the objective is to\nlabel every pixel in an image as tool or background. We improve upon previous\nwork in two major ways. First, we leverage recent techniques such as deep\nresidual learning and dilated convolutions to advance binary-segmentation\nperformance. Second, we extend the approach to multi-class segmentation, which\nlets us segment different parts of the tool, in addition to background. We\ndemonstrate the performance of this method on the MICCAI Endoscopic Vision\nChallenge Robotic Instruments dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optical bandgap engineering in nonlinear silicon nitride waveguides.   Silicon nitride is awell-established material for photonic devices and\nintegrated circuits. It displays a broad transparency window spanning from the\nvisible to the mid-IR and waveguides can be manufactured with low losses. An\nabsence of nonlinear multi-photon absorption in the erbium lightwave\ncommunications band has enabled various nonlinear optic applications in the\npast decade. Silicon nitride is a dielectric material whose optical and\nmechanical properties strongly depend on the deposition conditions. In\nparticular, the optical bandgap can be modified with the gas flow ratio during\nlow-pressure chemical vapor deposition (LPCVD). Here we show that this\nparameter can be controlled in a highly reproducible manner, providing an\napproach to synthesize the nonlinear Kerr coefficient of the material. This\nholistic empirical study provides relevant guidelines to optimize the\nproperties of LPCVD silicon nitride waveguides for nonlinear optics\napplications that rely on the Kerr effect.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On a Neumann-type series for modified Bessel functions of the first kind.   In this paper, we are interested in a Neumann-type series for modified Bessel\nfunctions of the first kind which arises in the study of Dunkl operators\nassociated with dihedral groups and as an instance of the Laguerre semigroup\nconstructed by Ben Said-Kobayashi-Orsted. We first revisit the particular case\ncorresponding to the group of square-preserving symmetries for which we give\ntwo new and different proofs other than the existing ones. The first proof uses\nthe expansion of powers in a Neumann series of Bessel functions while the\nsecond one is based on a quadratic transformation for the Gauss hypergeometric\nfunction and opens the way to derive further expressions when the orders of the\nunderlying dihedral groups are powers of two. More generally, we give another\nproof of De Bie \\& al formula expressing this series as a $\\Phi_2$-Horn\nconfluent hypergeometric function. In the course of proving, we shed the light\non the occurrence of multiple angles in their formula through elementary\nsymmetric functions, and get a new representation of Gegenbauer polynomials.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Antropologia de la Informatica Social: Teoria de la Convergencia Tecno-Social.   The traditional humanism of the twentieth century, inspired by the culture of\nthe book, systematically distanced itself from the new society of digital\ninformation; the Internet and tools of information processing revolutionized\nthe world, society during this period developed certain adaptive\ncharacteristics based on coexistence (Human - Machine), this transformation\nsets based on the impact of three technology segments: devices, applications\nand infrastructure of social communication, which are involved in various\nphysical, behavioural and cognitive changes of the human being; and the\nemergence of new models of influence and social control through the new\nubiquitous communication; however in this new process of conviviality new\nmodels like the \"collaborative thinking\" and \"InfoSharing\" develop; managing\nsocial information under three Human ontological dimensions (h) - Information\n(i) - Machine (m), which is the basis of a new physical-cyber ecosystem, where\nthey coexist and develop new social units called \"virtual communities \". This\nnew communication infrastructure and social management of information given\ndiscovered areas of vulnerability \"social perspective of risk\", impacting all\nsocial units through massive impact vector (i); The virtual environment \"H + i\n+ M\"; and its components, as well as the life cycle management of social\ninformation allows us to understand the path of integration \"Techno - Social\"\nand setting a new contribution to cybernetics, within the convergence of\ntechnology with society and the new challenges of coexistence, aimed at a new\nholistic and not pragmatic vision, as the human component (h) in the virtual\nenvironment is the precursor of the future and needs to be studied not as an\napplication, but as the hub of a new society.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Identifiability of Gaussian Structural Equation Models with Dependent Errors Having Equal Variances.   In this paper, we prove that some Gaussian structural equation models with\ndependent errors having equal variances are identifiable from their\ncorresponding Gaussian distributions. Specifically, we prove identifiability\nfor the Gaussian structural equation models that can be represented as\nAndersson-Madigan-Perlman chain graphs (Andersson et al., 2001). These chain\ngraphs were originally developed to represent independence models. However,\nthey are also suitable for representing causal models with additive noise\n(Peña, 2016. Our result implies then that these causal models can be\nidentified from observational data alone. Our result generalizes the result by\nPeters and Bühlmann (2014), who considered independent errors having equal\nvariances. The suitability of the equal error variances assumption should be\nassessed on a per domain basis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Redshift, metallicity and size of two extended dwarf Irregular galaxies. A link between dwarf Irregulars and Ultra Diffuse Galaxies?.   We present the results of the spectroscopic and photometric follow-up of two\nfield galaxies that were selected as possible stellar counterparts of local\nhigh velocity clouds. Our analysis shows that the two systems are distant (D>20\nMpc) dwarf irregular galaxies unrelated to the local HI clouds. However, the\nnewly derived distance and structural parameters reveal that the two galaxies\nhave luminosities and effective radii very similar to the recently identified\nUltra Diffuse Galaxies (UDGs). At odds with classical UDGs, they are remarkably\nisolated, having no known giant galaxy within ~2.0 Mpc. Moreover, one of them\nhas a very high gas content compared to galaxies of similar stellar mass, with\na HI to stellar mass ratio M_HI/M_* ~90, typical of almost-dark dwarfs.\nExpanding on this finding, we show that extended dwarf irregulars overlap the\ndistribution of UDGs in the M_V vs. log(r_e) plane and that the sequence\nincluding dwarf spheroidals, dwarf irregulars and UDGs appears as continuously\npopulated in this plane.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Statistical foundations for assessing the difference between the classical and weighted-Gini betas.   The `beta' is one of the key quantities in the capital asset pricing model\n(CAPM). In statistical language, the beta can be viewed as the slope of the\nregression line fitted to financial returns on the market against the returns\non the asset under consideration. The insurance counterpart of CAPM, called the\nweighted insurance pricing model (WIPM), gives rise to the so-called\nweighted-Gini beta. The aforementioned two betas may or may not coincide,\ndepending on the form of the underlying regression function, and this has\nprofound implications when designing portfolios and allocating risk capital. To\nfacilitate these tasks, in this paper we develop large-sample statistical\ninference results that, in a straightforward fashion, imply confidence\nintervals for, and hypothesis tests about, the equality of the two betas.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Genetic and Memetic Algorithm with Diversity Equilibrium based on Greedy Diversification.   The lack of diversity in a genetic algorithm's population may lead to a bad\nperformance of the genetic operators since there is not an equilibrium between\nexploration and exploitation. In those cases, genetic algorithms present a fast\nand unsuitable convergence.\nIn this paper we develop a novel hybrid genetic algorithm which attempts to\nobtain a balance between exploration and exploitation. It confronts the\ndiversity problem using the named greedy diversification operator. Furthermore,\nthe proposed algorithm applies a competition between parent and children so as\nto exploit the high quality visited solutions. These operators are complemented\nby a simple selection mechanism designed to preserve and take advantage of the\npopulation diversity.\nAdditionally, we extend our proposal to the field of memetic algorithms,\nobtaining an improved model with outstanding results in practice.\nThe experimental study shows the validity of the approach as well as how\nimportant is taking into account the exploration and exploitation concepts when\ndesigning an evolutionary algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Characterizing Minimal Semantics-preserving Slices of predicate-linear, Free, Liberal Program Schemas.   A program schema defines a class of programs, all of which have identical\nstatement structure, but whose functions and predicates may differ. A schema\nthus defines an entire class of programs according to how its symbols are\ninterpreted. A subschema of a schema is obtained from a schema by deleting some\nof its statements. We prove that given a schema $S$ which is predicate-linear,\nfree and liberal, such that the true and false parts of every if predicate\nsatisfy a simple additional condition, and a slicing criterion defined by the\nfinal value of a given variable after execution of any program defined by $S$,\nthe minimal subschema of $S$ which respects this slicing criterion contains all\nthe function and predicate symbols `needed' by the variable according to the\ndata dependence and control dependence relations used in program slicing, which\nis the symbol set given by Weiser's static slicing algorithm. Thus this\nalgorithm gives predicate-minimal slices for classes of programs represented by\nschemas satisfying our set of conditions. We also give an example to show that\nthe corresponding result with respect to the slicing criterion defined by\ntermination behaviour is incorrect. This complements a result by the authors in\nwhich $S$ was required to be function-linear, instead of predicate-linear.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Developing an edge computing platform for real-time descriptive analytics.   The Internet of Mobile Things encompasses stream data being generated by\nsensors, network communications that pull and push these data streams, as well\nas running processing and analytics that can effectively leverage actionable\ninformation for transportation planning, management, and business advantage.\nEdge computing emerges as a new paradigm that decentralizes the communication,\ncomputation, control and storage resources from the cloud to the edge of the\nnetwork. This paper proposes an edge computing platform where mobile edge nodes\nare physical devices deployed on a transit bus where descriptive analytics is\nused to uncover meaningful patterns from real-time transit data streams. An\napplication experiment is used to evaluate the advantages and disadvantages of\nour proposed platform to support descriptive analytics at a mobile edge node\nand generate actionable information to transit managers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Refracting Metasurfaces without Spurious Diffraction.   Refraction represents one of the most fundamental operations that may be\nperformed by a metasurface. However, simple phasegradient metasurface designs\nsuffer from restricted angular deflection due to spurious diffraction orders.\nIt has been recently shown, using a circuit-based approach, that refraction\nwithout spurious diffraction, or diffraction-free, can fortunately be achieved\nby a transverse metasurface exhibiting either loss-gain or bianisotropy. Here,\nwe rederive these conditions using a medium-based - and hence more insightfull\n- approach based on Generalized Sheet Transition Conditions (GSTCs) and surface\nsusceptibility tensors, and experimentally demonstrate two diffraction-free\nrefractive metasurfaces that are essentially lossless, passive, bianisotropic\nand reciprocal.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Weyl's asymptotics and remainder term for the orthogonal and unitary groups.   We examine the asymptotics of the spectral counting function of a compact\nRiemannian manifold by V.G.~Avakumovic \\cite{Avakumovic} and L.~Hörmander\n\\cite{Hormander-eigen} and show that for the scale of orthogonal and unitary\ngroups ${\\bf SO}(N)$, ${\\bf SU}(N)$, ${\\bf U}(N)$ and ${\\bf Spin}(N)$ it is not\nsharp. While for negative sectional curvature improvements are possible and\nknown, {\\it cf.} e.g., J.J.~Duistermaat $\\&$ V.~Guillemin \\cite{Duist-Guill},\nhere, we give sharp and contrasting examples in the positive Ricci curvature\ncase [non-negative for ${\\bf U}(N)$]. Furthermore here the improvements are\nsharp and quantitative relating to the dimension and {\\it rank} of the group.\nWe discuss the implications of these results on the closely related problem of\nclosed geodesics and the length spectrum.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Parallel Parameterized Complexity of the Graph Isomorphism Problem.   In this paper, we study the parallel and the space complexity of the graph\nisomorphism problem (\\GI{}) for several parameterizations. Let\n$\\mathcal{H}=\\{H_1,H_2,\\cdots,H_l\\}$ be a finite set of graphs where\n$|V(H_i)|\\leq d$ for all $i$ and for some constant $d$. Let $\\mathcal{G}$ be an\n$\\mathcal{H}$-free graph class i.e., none of the graphs $G\\in \\mathcal{G}$\ncontain any $H \\in \\mathcal{H}$ as an induced subgraph. We show that \\GI{}\nparameterized by vertex deletion distance to $\\mathcal{G}$ is in a\nparameterized version of $\\AC^1$, denoted $\\PL$-$\\AC^1$, provided the colored\ngraph isomorphism problem for graphs in $\\mathcal{G}$ is in $\\AC^1$. From this,\nwe deduce that \\GI{} parameterized by the vertex deletion distance to cographs\nis in $\\PL$-$\\AC^1$.\nThe parallel parameterized complexity of \\GI{} parameterized by the size of a\nfeedback vertex set remains an open problem. Towards this direction we show\nthat the graph isomorphism problem is in $\\PL$-$\\TC^0$ when parameterized by\nvertex cover or by twin-cover.\nLet $\\mathcal{G}'$ be a graph class such that recognizing graphs from\n$\\mathcal{G}'$ and the colored version of \\GI{} for $\\mathcal{G}'$ is in\nlogspace ($\\L$). We show that \\GI{} for bounded vertex deletion distance to\n$\\mathcal{G}'$ is in $\\L$. From this, we obtain logspace algorithms for \\GI{}\nfor graphs with bounded vertex deletion distance to interval graphs and graphs\nwith bounded vertex deletion distance to cographs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Semi-supervised Embedding in Attributed Networks with Outliers.   In this paper, we propose a novel framework, called Semi-supervised Embedding\nin Attributed Networks with Outliers (SEANO), to learn a low-dimensional vector\nrepresentation that systematically captures the topological proximity,\nattribute affinity and label similarity of vertices in a partially labeled\nattributed network (PLAN). Our method is designed to work in both transductive\nand inductive settings while explicitly alleviating noise effects from\noutliers. Experimental results on various datasets drawn from the web, text and\nimage domains demonstrate the advantages of SEANO over state-of-the-art methods\nin semi-supervised classification under transductive as well as inductive\nsettings. We also show that a subset of parameters in SEANO is interpretable as\noutlier score and can significantly outperform baseline methods when applied\nfor detecting network outliers. Finally, we present the use of SEANO in a\nchallenging real-world setting -- flood mapping of satellite images and show\nthat it is able to outperform modern remote sensing algorithms for this task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometrically finite amalgamations of hyperbolic 3-manifold groups are not LERF.   We prove that, for any two finite volume hyperbolic $3$-manifolds, the\namalgamation of their fundamental groups along any nontrivial geometrically\nfinite subgroup is not LERF. This generalizes the author's previous work on\nnonLERFness of amalgamations of hyperbolic $3$-manifold groups along abelian\nsubgroups. A consequence of this result is that closed arithmetic hyperbolic\n$4$-manifolds have nonLERF fundamental groups. Along with the author's previous\nwork, we get that, for any arithmetic hyperbolic manifold with dimension at\nleast $4$, with possible exceptions in $7$-dimensional manifolds defined by the\noctonion, its fundamental group is not LERF.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using polarimetry to retrieve the cloud coverage of Earth-like exoplanets.   Context. Clouds have already been detected in exoplanetary atmospheres. They\nplay crucial roles in a planet's atmosphere and climate and can also create\nambiguities in the determination of atmospheric parameters such as trace gas\nmixing ratios. Knowledge of cloud properties is required when assessing the\nhabitability of a planet. Aims. We aim to show that various types of cloud\ncover such as polar cusps, subsolar clouds, and patchy clouds on Earth-like\nexoplanets can be distinguished from each other using the polarization and flux\nof light that is reflected by the planet. Methods. We have computed the flux\nand polarization of reflected starlight for different types of (liquid water)\ncloud covers on Earth-like model planets using the adding-doubling method, that\nfully includes multiple scattering and polarization. Variations in cloud-top\naltitudes and planet-wide cloud cover percentages were taken into account.\nResults. We find that the different types of cloud cover (polar cusps, subsolar\nclouds, and patchy clouds) can be distinguished from each other and that the\npercentage of cloud cover can be estimated within 10%. Conclusions. Using our\nproposed observational strategy, one should be able to determine basic orbital\nparameters of a planet such as orbital inclination and estimate cloud coverage\nwith reduced ambiguities from the planet's polarization signals along its\norbit.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The First Measurement of the $2^{3}S_{1} \\rightarrow 3^{3}P - 2^{3}P$ Tune-Out Wavelength in He*.   The workhorse of atomic physics: quantum electrodynamics is one of the best\ntested theories in physics. However recent discrepancies have shed doubt on its\naccuracy for complex atomic systems. To facilitate the development of the\ntheory further we aim to measure transition dipole matrix elements of\nmetastable helium (He*) (the ideal 3 body test-bed) to the highest accuracy\nthus far. We have undertaken a measurement of the `tune-out wavelength' which\noccurs when the contributions to the dynamic polarizability from all atomic\ntransitions sum to zero; thus illuminating an atom with this wavelength of\nlight then produces no net energy shift. This provides a strict constraint on\nthe transition dipole matrix elements without the complication and inaccuracy\nof other methods.\nUsing a novel atom-laser based technique we have made the first measurement\nof the the tune-out wavelength in metastable helium between the\n$3^{3}P_{1,2,3}$ and $2^{3}P_{1,2,3}$ states at 413.07(2)nm which compares well\nwith the predicted value\\cite{Mitroy2013} of 413.02(9). We have additionally\ndeveloped many of the methods necessary to improve this measurement to the\n100fm level of accuracy where it will form the most accurate determination of\ntransition rate information ever made in He* and provide a stringent test for\natomic QED simulations. We believe this measurement to be one of the most\nsensitive ever made of an optical dipole potential, able to detect changes in\npotentials of $\\sim200pK$ and is widely applicable to other species and areas\nof atom optics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning to Optimize Neural Nets.   Learning to Optimize is a recently proposed framework for learning\noptimization algorithms using reinforcement learning. In this paper, we explore\nlearning an optimization algorithm for training shallow neural nets. Such\nhigh-dimensional stochastic optimization problems present interesting\nchallenges for existing reinforcement learning algorithms. We develop an\nextension that is suited to learning optimization algorithms in this setting\nand demonstrate that the learned optimization algorithm consistently\noutperforms other known optimization algorithms even on unseen tasks and is\nrobust to changes in stochasticity of gradients and the neural net\narchitecture. More specifically, we show that an optimization algorithm trained\nwith the proposed method on the problem of training a neural net on MNIST\ngeneralizes to the problems of training neural nets on the Toronto Faces\nDataset, CIFAR-10 and CIFAR-100.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Complexity of Simple and Optimal Deterministic Mechanisms for an Additive Buyer.   We show that the Revenue-Optimal Deterministic Mechanism Design problem for a\nsingle additive buyer is #P-hard, even when the distributions have support size\n2 for each item and, more importantly, even when the optimal solution is\nguaranteed to be of a very simple kind: the seller picks a price for each\nindividual item and a price for the grand bundle of all the items; the buyer\ncan purchase either the grand bundle at its given price or any subset of items\nat their total individual prices. The following problems are also #P-hard, as\nimmediate corollaries of the proof:\n1. determining if individual item pricing is optimal for a given instance,\n2. determining if grand bundle pricing is optimal, and\n3. computing the optimal (deterministic) revenue.\nOn the positive side, we show that when the distributions are i.i.d. with\nsupport size 2, the optimal revenue obtainable by any mechanism, even a\nrandomized one, can be achieved by a simple solution of the above kind\n(individual item pricing with a discounted price for the grand bundle) and\nfurthermore, it can be computed in polynomial time. The problem can be solved\nin polynomial time too when the number of items is constant.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Run-Wise Simulations for Imaging Atmospheric Cherenkov Telescope Arrays.   We present a new paradigm for the simulation of arrays of Imaging Atmospheric\nCherenkov Telescopes (IACTs) which overcomes limitations of current approaches.\nUp to now, all major IACT experiments rely on the same Monte-Carlo simulation\nstrategy, using predefined observation and instrument settings. Simulations\nwith varying parameters are generated to provide better estimates of the\nInstrument Response Functions (IRFs) of different observations. However, a\nlarge fraction of the simulation configuration remains preserved, leading to\ncomplete negligence of all related influences. Additionally, the simulation\nscheme relies on interpolations between different array configurations, which\nare never fully reproducing the actual configuration for a given observation.\nInterpolations are usually performed on zenith angles, off-axis angles, array\nmultiplicity, and the optical response of the instrument. With the advent of\nhybrid systems consisting of a large number of IACTs with different sizes,\ntypes, and camera configurations, the complexity of the interpolation and the\nsize of the phase space becomes increasingly prohibitive. Going beyond the\nexisting approaches, we introduce a new simulation and analysis concept which\ntakes into account the actual observation conditions as well as individual\ntelescope configurations of each observation run of a given data set. These\nrun-wise simulations (RWS) thus exhibit considerably reduced systematic\nuncertainties compared to the existing approach, and are also more\ncomputationally efficient and simple. The RWS framework has been implemented in\nthe H.E.S.S. software and tested, and is already being exploited in science\nanalysis.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hierarchical RNN with Static Sentence-Level Attention for Text-Based Speaker Change Detection.   Speaker change detection (SCD) is an important task in dialog modeling. Our\npaper addresses the problem of text-based SCD, which differs from existing\naudio-based studies and is useful in various scenarios, for example, processing\ndialog transcripts where speaker identities are missing (e.g., OpenSubtitle),\nand enhancing audio SCD with textual information. We formulate text-based SCD\nas a matching problem of utterances before and after a certain decision point;\nwe propose a hierarchical recurrent neural network (RNN) with static\nsentence-level attention. Experimental results show that neural networks\nconsistently achieve better performance than feature-based approaches, and that\nour attention-based model significantly outperforms non-attention neural\nnetworks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Digital Neuromorphic Architecture Efficiently Facilitating Complex Synaptic Response Functions Applied to Liquid State Machines.   Information in neural networks is represented as weighted connections, or\nsynapses, between neurons. This poses a problem as the primary computational\nbottleneck for neural networks is the vector-matrix multiply when inputs are\nmultiplied by the neural network weights. Conventional processing architectures\nare not well suited for simulating neural networks, often requiring large\namounts of energy and time. Additionally, synapses in biological neural\nnetworks are not binary connections, but exhibit a nonlinear response function\nas neurotransmitters are emitted and diffuse between neurons. Inspired by\nneuroscience principles, we present a digital neuromorphic architecture, the\nSpiking Temporal Processing Unit (STPU), capable of modeling arbitrary complex\nsynaptic response functions without requiring additional hardware components.\nWe consider the paradigm of spiking neurons with temporally coded information\nas opposed to non-spiking rate coded neurons used in most neural networks. In\nthis paradigm we examine liquid state machines applied to speech recognition\nand show how a liquid state machine with temporal dynamics maps onto the\nSTPU-demonstrating the flexibility and efficiency of the STPU for instantiating\nneural algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Improving the Capacity of Solving Large-scale Wireless Network Design Problems by Genetic Algorithms.   Over the last decade, wireless networks have experienced an impressive growth\nand now play a main role in many telecommunications systems. As a consequence,\nscarce radio resources, such as frequencies, became congested and the need for\neffective and efficient assignment methods arose. In this work, we present a\nGenetic Algorithm for solving large instances of the Power, Frequency and\nModulation Assignment Problem, arising in the design of wireless networks. To\nour best knowledge, this is the first Genetic Algorithm that is proposed for\nsuch problem. Compared to previous works, our approach allows a wider\nexploration of the set of power solutions, while eliminating sources of\nnumerical problems. The performance of the algorithm is assessed by tests over\na set of large realistic instances of a Fixed WiMAX Network.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lorentzian surfaces and the curvature of the Schmidt metric.   The b-boundary is a mathematical tool used to attach a topological boundary\nto incomplete Lorentzian manifolds using a Riemaniann metric called the Schmidt\nmetric on the frame bundle. In this paper, we give the general form of the\nSchmidt metric in the case of Lorentzian surfaces. Furthermore, we write the\nRicci scalar of the Schmidt metric in terms of the Ricci scalar of the\nLorentzian manifold and give some examples. Finally, we discuss some\napplications to general relativity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phase partitioning in a novel near equi-atomic AlCuFeMn alloy.   A novel low cost, near equi-atomic alloy comprising of Al, Cu, Fe and Mn is\nsynthesized using arc-melting technique. The cast alloy possesses a dendritic\nmicrostructure where the dendrites consist of disordered FCC and ordered FCC\nphases. The inter-dendritic region is comprised of ordered FCC phase and\nspinodally decomposed BCC phases. A Cu segregation is observed in the\ninter-dendritic region while dendritic region is rich in Fe. The bulk hardness\nof the alloy is ~ 380 HV, indicating significant yield strength.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Localization properties and high-fidelity state transfer in electronic hopping models with correlated disorder.   We investigate a tight-binding electronic chain featuring diagonal and\noff-diagonal disorder, these being modelled through the long-range-correlated\nfractional Brownian motion. Particularly, by employing exact diagonalization\nmethods, we evaluate how the eigenstate spectrum of the system and its related\nsingle-particle dynamics respond to both competing sources of disorder.\nMoreover, we report the possibility of carrying out efficient end-to-end\nquantum-state transfer protocols even in the presence of such generalized\ndisorder due to the appearance of extended states around the middle of the band\nin the limit of strong correlations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Threat Modeling Data Analysis in Socio-technical Systems.   Our decision-making processes are becoming more data driven, based on data\nfrom multiple sources, of different types, processed by a variety of\ntechnologies. As technology becomes more relevant for decision processes, the\nmore likely they are to be subjects of attacks aimed at disrupting their\nexecution or changing their outcome. With the increasing complexity and\ndependencies on technical components, such attempts grow more sophisticated and\ntheir impact will be more severe. This is especially important in scenarios\nwith shared goals, which had to be previously agreed to, or decisions with\nbroad social impact. We need to think about our decisions-making and underlying\ndata analysis processes in a systemic way to correctly evaluate benefits and\nrisks of specific solutions and to design them to be resistant to attacks. To\nreach these goals, we can apply experiences from threat modeling analysis used\nin software security. We will need to adapt these practices to new types of\nthreats, protecting different assets and operating in socio-technical systems.\nWith these changes, threat modeling can become a foundation for implementing\ndetailed technical, organizational or legal mitigations and making our\ndecisions more reliable and trustworthy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Thompson Sampling for a Fatigue-aware Online Recommendation System.   In this paper we consider an online recommendation setting, where a platform\nrecommends a sequence of items to its users at every time period. The users\nrespond by selecting one of the items recommended or abandon the platform due\nto fatigue from seeing less useful items. Assuming a parametric stochastic\nmodel of user behavior, which captures positional effects of these items as\nwell as the abandoning behavior of users, the platform's goal is to recommend\nsequences of items that are competitive to the single best sequence of items in\nhindsight, without knowing the true user model a priori. Naively applying a\nstochastic bandit algorithm in this setting leads to an exponential dependence\non the number of items. We propose a new Thompson sampling based algorithm with\nexpected regret that is polynomial in the number of items in this combinatorial\nsetting, and performs extremely well in practice. We also show a contextual\nversion of our solution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Are multi-factor Gaussian term structure models still useful? An empirical analysis on Italian BTPs.   In this paper, we empirically study models for pricing Italian sovereign\nbonds under a reduced form framework, by assuming different dynamics for the\nshort-rate process. We analyze classical Cox-Ingersoll-Ross and Vasicek\nmulti-factor models, with a focus on optimization algorithms applied in the\ncalibration exercise. The Kalman filter algorithm together with a maximum\nlikelihood estimation method are considered to fit the Italian term-structure\nover a 12-year horizon, including the global financial crisis and the euro area\nsovereign debt crisis. Analytic formulas for the gradient vector and the\nHessian matrix of the likelihood function are provided.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coppersmith's lattices and \"focus groups\": an attack on small-exponent RSA.   We present a principled technique for reducing the matrix size in some\napplications of Coppersmith's lattice method for finding roots of modular\npolynomial equations. It relies on an analysis of the actual performance of\nCoppersmith's attack for smaller parameter sizes, which can be thought of as\n\"focus group\" testing. When applied to the small-exponent RSA problem, it\nreduces lattice dimensions and consequently running times (sometimes by factors\nof two or more). We also argue that existing metrics (such as enabling\ncondition bounds) are not as important as often thought for measuring the true\nperformance of attacks based on Coppersmith's method. Finally, experiments are\ngiven to indicate that certain lattice reductive algorithms (such as\nNguyen-Stehlé's L2) may be particularly well-suited for Coppersmith's method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An efficient methodology for the analysis and modeling of computer experiments with large number of inputs.   Complex computer codes are often too time expensive to be directly used to\nperform uncertainty, sensitivity, optimization and robustness analyses. A\nwidely accepted method to circumvent this problem consists in replacing\ncpu-time expensive computer models by cpu inexpensive mathematical functions,\ncalled metamodels. For example, the Gaussian process (Gp) model has shown\nstrong capabilities to solve practical problems , often involving several\ninterlinked issues. However, in case of high dimensional experiments (with\ntypically several tens of inputs), the Gp metamodel building process remains\ndifficult, even unfeasible, and application of variable selection techniques\ncannot be avoided. In this paper, we present a general methodology allowing to\nbuild a Gp metamodel with large number of inputs in a very efficient manner.\nWhile our work focused on the Gp metamodel, its principles are fully generic\nand can be applied to any types of metamodel. The objective is twofold:\nestimating from a minimal number of computer experiments a highly predictive\nmetamodel. This methodology is successfully applied on an industrial computer\ncode.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hochschild Cohomology and Deformation Quantization of Affine Toric Varieties.   For an affine toric variety $\\mathrm{Spec}(A)$, we give a convex geometric\ndescription of the Hodge decomposition of its Hochschild cohomology. Under\ncertain assumptions we compute the dimensions of the Hodge summands\n$T^1_{(i)}(A)$, generalizing the existing results about the Andre-Quillen\ncohomology group $T^1_{(1)}(A)$. We prove that every Poisson structure on a\npossibly singular affine toric variety can be quantized in the sense of\ndeformation quantization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ensemble of Part Detectors for Simultaneous Classification and Localization.   Part-based representation has been proven to be effective for a variety of\nvisual applications. However, automatic discovery of discriminative parts\nwithout object/part-level annotations is challenging. This paper proposes a\ndiscriminative mid-level representation paradigm based on the responses of a\ncollection of part detectors, which only requires the image-level labels.\nTowards this goal, we first develop a detector-based spectral clustering method\nto mine the representative and discriminative mid-level patterns for detector\ninitialization. The advantage of the proposed pattern mining technology is that\nthe distance metric based on detectors only focuses on discriminative details,\nand a set of such grouped detectors offer an effective way for consistent\npattern mining. Relying on the discovered patterns, we further formulate the\ndetector learning process as a confidence-loss sparse Multiple Instance\nLearning (cls-MIL) task, which considers the diversity of the positive samples,\nwhile avoid drifting away the well localized ones by assigning a confidence\nvalue to each positive sample. The responses of the learned detectors can form\nan effective mid-level image representation for both image classification and\nobject localization. Experiments conducted on benchmark datasets demonstrate\nthe superiority of our method over existing approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Are Bitcoin Bubbles Predictable? Combining a Generalized Metcalfe's Law and the LPPLS Model.   We develop a strong diagnostic for bubbles and crashes in bitcoin, by\nanalyzing the coincidence (and its absence) of fundamental and technical\nindicators. Using a generalized Metcalfe's law based on network properties, a\nfundamental value is quantified and shown to be heavily exceeded, on at least\nfour occasions, by bubbles that grow and burst. In these bubbles, we detect a\nuniversal super-exponential unsustainable growth. We model this universal\npattern with the Log-Periodic Power Law Singularity (LPPLS) model, which\nparsimoniously captures diverse positive feedback phenomena, such as herding\nand imitation. The LPPLS model is shown to provide an ex-ante warning of market\ninstabilities, quantifying a high crash hazard and probabilistic bracket of the\ncrash time consistent with the actual corrections; although, as always, the\nprecise time and trigger (which straw breaks the camel's back) being exogenous\nand unpredictable. Looking forward, our analysis identifies a substantial but\nnot unprecedented overvaluation in the price of bitcoin, suggesting many months\nof volatile sideways bitcoin prices ahead (from the time of writing, March\n2018).",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Gapless surface states originated from accidentally degenerate quadratic band touching in a three-dimensional tetragonal photonic crystal.   A tetragonal photonic crystal composed of high-index pillars can exhibit a\nfrequency-isolated accidental degeneracy at a high-symmetry point in the first\nBrillouin zone. A photonic band gap can be formed there by introducing a\ngeometrical anisotropy in the pillars. In this gap, gapless surface/domain-wall\nstates emerge under a certain condition. We analyze their physical property in\nterms of an effective hamiltonian, and a good agreement between the effective\ntheory and numerical calculation is obtained.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Empirical analysis of non-linear activation functions for Deep Neural Networks in classification tasks.   We provide an overview of several non-linear activation functions in a neural\nnetwork architecture that have proven successful in many machine learning\napplications. We conduct an empirical analysis on the effectiveness of using\nthese function on the MNIST classification task, with the aim of clarifying\nwhich functions produce the best results overall. Based on this first set of\nresults, we examine the effects of building deeper architectures with an\nincreasing number of hidden layers. We also survey the impact of using, on the\nsame task, different initialisation schemes for the weights of our neural\nnetwork. Using these sets of experiments as a base, we conclude by providing a\noptimal neural network architecture that yields impressive results in accuracy\non the MNIST classification task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coupon Advertising in Online Social Systems: Algorithms and Sampling Techniques.   Online social systems have become important platforms for viral marketing\nwhere the advertising of products is carried out with the communication of\nusers. After adopting the product, the seed buyers may spread the information\nto their friends via online messages e.g. posts and tweets. In another issue,\nelectronic coupon system is one of the relevant promotion vehicles that help\nmanufacturers and retailers attract more potential customers. By offering\ncoupons to seed buyers, there is a chance to convince the influential users who\nare, however, at first not very interested in the product. In this paper, we\npropose a coupon based online influence model and consider the problem that how\nto maximize the profit by selecting appropriate seed buyers. The considered\nproblem herein is markedly different from other influence related problems as\nits objective function is not monotone. We provide an algorithmic analysis and\ngive several algorithms designed with different sampling techniques. In\nparticular, we propose the RA-T and RA-S algorithms which are not only provably\neffective but also scalable on large datasets. The proposed theoretical results\nare evaluated by extensive experiments done on large-scale real-world social\nnetworks. The analysis of this paper also provides an algorithmic framework for\nnon-monotone submodular maximization problems in social networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear elliptic equations on Carnot groups.   This article concerns a class of elliptic equations on Carnot groups\ndepending on one real positive parameter and involving a subcritical\nnonlinearity (for the critical case we refer to G. Molica Bisci and D.\nRepovš, Yamabe-type equations on Carnot groups, Potential Anal. 46:2\n(2017), 369-383; arXiv:1705.10100 [math.AP]). As a special case of our results\nwe prove the existence of at least one nontrivial solution for a subelliptic\nequation defined on a smooth and bounded domain $D$ of the Heisenberg group\n$\\mathbb{H}^n=\\mathbb{C}^n\\times \\mathbb{R}$. The main approach is based on\nvariational methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Application of Spin-Exchange Relaxation-Free Magnetometry to the Cosmic Axion Spin Precession Experiment.   The Cosmic Axion Spin Precession Experiment (CASPEr) seeks to measure\noscillating torques on nuclear spins caused by axion or axion-like-particle\n(ALP) dark matter via nuclear magnetic resonance (NMR) techniques. A sample\nspin-polarized along a leading magnetic field experiences a resonance when the\nLarmor frequency matches the axion/ALP Compton frequency, generating precessing\ntransverse nuclear magnetization. Here we demonstrate a Spin-Exchange\nRelaxation-Free (SERF) magnetometer with sensitivity $\\approx 1~{\\rm\nfT/\\sqrt{Hz}}$ and an effective sensing volume of 0.1 $\\rm{cm^3}$ that may be\nuseful for NMR detection in CASPEr. A potential drawback of\nSERF-magnetometer-based NMR detection is the SERF's limited dynamic range. Use\nof a magnetic flux transformer to suppress the leading magnetic field is\nconsidered as a potential method to expand the SERF's dynamic range in order to\nprobe higher axion/ALP Compton frequencies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Individual Impact Index ($i^3$) Statistic: A Novel Article-Level Citation Metric.   Citation metrics are analytic measures used to evaluate the usage, impact and\ndissemination of scientific research. Traditionally, citation metrics have been\nindependently measured at each level of the publication pyramid, namely at the\narticle-level, at the author-level, and at the journal-level. The most commonly\nused metrics have been focused on journal-level measurements, such as the\nImpact Factor and the Eigenfactor, as well as on researcher-level metrics like\nthe Hirsch index (h-index) and i10 index. On the other hand, reliable\narticle-level metrics are less widespread, and are often reserved to\nnon-standardized and non-scientific characteristics of individual articles,\nsuch as views, citations, downloads, and mentions in social and news media.\nThese characteristics are known as 'altmetrics'. However, when the number of\nviews and citations are similar between two articles, no discriminating measure\ncurrently exists with which to assess and compare each articles' individual\nimpact. Given the modern, exponentially growing scientific literature,\nscientists and readers of Science need optimized, reliable, objective methods\nfor managing, measuring and comparing research outputs and individual\npublications. To this end, I hereby describe and propose a new standardized\narticle-level metric henceforth known as the 'Individual Impact Index\nStatistic', or $i^3$ for short. The $i^3$ is a weighted algorithm that takes\nadvantage of the peer-review process, and considers a number of characteristics\nof individual scientific publications in order to yield a standardized and\nreadily comparable measure of impact and dissemination. The strengths,\nlimitations, and potential uses of this novel metric are also discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On The Communication Complexity of High-Dimensional Permutations.   We study the multiparty communication complexity of high dimensional\npermutations, in the Number On the Forehead (NOF) model. This model is due to\nChandra, Furst and Lipton (CFL) who also gave a nontrivial protocol for the\nExactly-n problem where three players receive integer inputs and need to decide\nif their inputs sum to a given integer $n$. There is a considerable body of\nliterature dealing with the same problem, where $(\\mathbb{N},+)$ is replaced by\nsome other abelian group. Our work can be viewed as a far-reaching extension of\nthis line of work.\nWe show that the known lower bounds for that group-theoretic problem apply to\nall high dimensional permutations. We introduce new proof techniques that\nappeal to recent advances in Additive Combinatorics and Ramsey theory. We\nreveal new and unexpected connections between the NOF communication complexity\nof high dimensional permutations and a variety of well known and thoroughly\nstudied problems in combinatorics.\nPrevious protocols for Exactly-n all rely on the construction of large sets\nof integers without a 3-term arithmetic progression. No direct algorithmic\nprotocol was previously known for the problem, and we provide the first such\nalgorithm. This suggests new ways to significantly improve the CFL protocol.\nMany new open questions are presented throughout.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nudging the particle filter.   We investigate a new sampling scheme aimed at improving the performance of\nparticle filters whenever (a) there is a significant mismatch between the\nassumed model dynamics and the actual system, or (b) the posterior probability\ntends to concentrate in relatively small regions of the state space. The\nproposed scheme pushes some particles towards specific regions where the\nlikelihood is expected to be high, an operation known as nudging in the\ngeophysics literature. We re-interpret nudging in a form applicable to any\nparticle filtering scheme, as it does not involve any changes in the rest of\nthe algorithm. Since the particles are modified, but the importance weights do\nnot account for this modification, the use of nudging leads to additional bias\nin the resulting estimators. However, we prove analytically that nudged\nparticle filters can still attain asymptotic convergence with the same error\nrates as conventional particle methods. Simple analysis also yields an\nalternative interpretation of the nudging operation that explains its\nrobustness to model errors. Finally, we show numerical results that illustrate\nthe improvements that can be attained using the proposed scheme. In particular,\nwe present nonlinear tracking examples with synthetic data and a model\ninference example using real-world financial data.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Incorporation of prior knowledge of the signal behavior into the reconstruction to accelerate the acquisition of MR diffusion data.   Diffusion MRI measurements using hyperpolarized gases are generally acquired\nduring patient breath hold, which yields a compromise between achievable image\nresolution, lung coverage and number of b-values. In this work, we propose a\nnovel method that accelerates the acquisition of MR diffusion data by\nundersampling in both spatial and b-value dimensions, thanks to incorporating\nknowledge about the signal decay into the reconstruction (SIDER). SIDER is\ncompared to total variation (TV) reconstruction by assessing their effect on\nboth the recovery of ventilation images and estimated mean alveolar dimensions\n(MAD). Both methods are assessed by retrospectively undersampling diffusion\ndatasets of normal volunteers and COPD patients (n=8) for acceleration factors\nbetween x2 and x10. TV led to large errors and artefacts for acceleration\nfactors equal or larger than x5. SIDER improved TV, presenting lower errors and\nhistograms of MAD closer to those obtained from fully sampled data for\naccelerations factors up to x10. SIDER preserved image quality at all\nacceleration factors but images were slightly smoothed and some details were\nlost at x10. In conclusion, we have developed and validated a novel compressed\nsensing method for lung MRI imaging and achieved high acceleration factors,\nwhich can be used to increase the amount of data acquired during a breath-hold.\nThis methodology is expected to improve the accuracy of estimated lung\nmicrostructure dimensions and widen the possibilities of studying lung diseases\nwith MRI.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Forecasting in the light of Big Data.   Predicting the future state of a system has always been a natural motivation\nfor science and practical applications. Such a topic, beyond its obvious\ntechnical and societal relevance, is also interesting from a conceptual point\nof view. This owes to the fact that forecasting lends itself to two equally\nradical, yet opposite methodologies. A reductionist one, based on the first\nprinciples, and the naive inductivist one, based only on data. This latter view\nhas recently gained some attention in response to the availability of\nunprecedented amounts of data and increasingly sophisticated algorithmic\nanalytic techniques. The purpose of this note is to assess critically the role\nof big data in reshaping the key aspects of forecasting and in particular the\nclaim that bigger data leads to better predictions. Drawing on the\nrepresentative example of weather forecasts we argue that this is not generally\nthe case. We conclude by suggesting that a clever and context-dependent\ncompromise between modelling and quantitative analysis stands out as the best\nforecasting strategy, as anticipated nearly a century ago by Richardson and von\nNeumann.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Diffusion of new products with recovering consumers.   We consider the diffusion of new products in the discrete Bass-SIR model, in\nwhich consumers who adopt the product can later \"recover\" and stop influencing\ntheir peers to adopt the product. To gain insight into the effect of the social\nnetwork structure on the diffusion, we focus on two extreme cases. In the\n\"most-connected\" configuration where all consumers are inter-connected\n(complete network), averaging over all consumers leads to an aggregate model,\nwhich combines the Bass model for diffusion of new products with the SIR model\nfor epidemics. In the \"least-connected\" configuration where consumers are\narranged on a circle and each consumer can only be influenced by his left\nneighbor (one-sided 1D network), averaging over all consumers leads to a\ndifferent aggregate model which is linear, and can be solved explicitly. We\nconjecture that for any other network, the diffusion is bounded from below and\nfrom above by that on a one-sided 1D network and on a complete network,\nrespectively. When consumers are arranged on a circle and each consumer can be\ninfluenced by his left and right neighbors (two-sided 1D network), the\ndiffusion is strictly faster than on a one-sided 1D network. This is different\nfrom the case of non-recovering adopters, where the diffusion on one-sided and\non two-sided 1D networks is identical. We also propose a nonlinear model for\nrecoveries, and show that consumers' heterogeneity has a negligible effect on\nthe aggregate diffusion.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Planar Drawings of Fixed-Mobile Bigraphs.   A fixed-mobile bigraph G is a bipartite graph such that the vertices of one\npartition set are given with fixed positions in the plane and the mobile\nvertices of the other part, together with the edges, must be added to the\ndrawing. We assume that G is planar and study the problem of finding, for a\ngiven k >= 0, a planar poly-line drawing of G with at most k bends per edge. In\nthe most general case, we show NP-hardness. For k=0 and under additional\nconstraints on the positions of the fixed or mobile vertices, we either prove\nthat the problem is polynomial-time solvable or prove that it belongs to NP.\nFinally, we present a polynomial-time testing algorithm for a certain type of\n\"layered\" 1-bend drawings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The strong ring of simplicial complexes.   We define a ring R of geometric objects G generated by finite abstract\nsimplicial complexes. To every G belongs Hodge Laplacian H as the square of the\nDirac operator determining its cohomology and a unimodular connection matrix\nL). The sum of the matrix entries of the inverse of L is the Euler\ncharacteristic. The spectra of H as well as inductive dimension add under\nmultiplication while the spectra of L multiply. The nullity of the Hodge of H\nare the Betti numbers which can now be signed. The map assigning to G its\nPoincare polynomial is a ring homomorphism from R the polynomials. Especially\nthe Euler characteristic is a ring homomorphism. Also Wu characteristic\nproduces a ring homomorphism. The Kuenneth correspondence between cohomology\ngroups is explicit as a basis for the product can be obtained from a basis of\nthe factors. The product in R produces the strong product for the connection\ngraphs and leads to tensor products of connection Laplacians. The strong ring R\nis also a subring of the full Stanley-Reisner ring S Every element G can be\nvisualized by its Barycentric refinement graph G1 and its connection graph G'.\nGauss-Bonnet, Poincare-Hopf or the Brouwer-Lefschetz extend to the strong ring.\nThe isomorphism of R with a subring of the strong Sabidussi ring shows that the\nmultiplicative primes in R are the simplicial complexes and that every\nconnected element in the strong ring has a unique prime factorization. The\nSabidussi ring is dual to the Zykov ring, in which the Zykov join is the\naddition. The connection Laplacian of the d-dimensional lattice remains\ninvertible in the infinite volume limit: there is a mass gap in any dimension.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Construction of dynamical semigroups by a functional regularisation à la Kato.   A functional version of the Kato one-parametric regularisation for the\nconstruction of a dynamical semigroup generator of a relative bound one\nperturbation is introduced. It does not require that the minus generator of the\nunperturbed semigroup is a positivity preserving operator. The regularisation\nis illustrated by an example of a boson-number cut-off regularisation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unveiling Bias Compensation in Turbo-Based Algorithms for (Discrete) Compressed Sensing.   In Compressed Sensing, a real-valued sparse vector has to be recovered from\nan underdetermined system of linear equations. In many applications, however,\nthe elements of the sparse vector are drawn from a finite set. Adapted\nalgorithms incorporating this additional knowledge are required for the\ndiscrete-valued setup. In this paper, turbo-based algorithms for both cases are\nelucidated and analyzed from a communications engineering perspective, leading\nto a deeper understanding of the algorithm. In particular, we gain the\nintriguing insight that the calculation of extrinsic values is equal to the\nunbiasing of a biased estimate and present an improved algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cheap Orthogonal Constraints in Neural Networks: A Simple Parametrization of the Orthogonal and Unitary Group.   We introduce a novel approach to perform first-order optimization with\northogonal and unitary constraints. This approach is based on a parametrization\nstemming from Lie group theory through the exponential map. The parametrization\ntransforms the constrained optimization problem into an unconstrained one over\na Euclidean space, for which common first-order optimization methods can be\nused. The theoretical results presented are general enough to cover the special\northogonal group, the unitary group and, in general, any connected compact Lie\ngroup. We discuss how this and other parametrizations can be computed\nefficiently through an implementation trick, making numerically complex\nparametrizations usable at a negligible runtime cost in neural networks. In\nparticular, we apply our results to RNNs with orthogonal recurrent weights,\nyielding a new architecture called expRNN. We demonstrate how our method\nconstitutes a more robust approach to optimization with orthogonal constraints,\nshowing faster, accurate, and more stable convergence in several tasks designed\nto test RNNs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stability Analysis for Switched Systems with Sequence-based Average Dwell Time.   This note investigates the stability of both linear and nonlinear switched\nsystems with average dwell time. Two new analysis methods are proposed.\nDifferent from existing approaches, the proposed methods take into account the\nsequence in which the subsystems are switched. Depending on the predecessor or\nsuccessor subsystems to be considered, sequence-based average preceding dwell\ntime (SBAPDT) and sequence-based average subsequence dwell time (SBASDT)\napproaches are proposed and discussed for both continuous and discrete time\nsystems. These proposed methods, when considering the switch sequence, have the\npotential to further reduce the conservativeness of the existing approaches. A\ncomparative numerical example is also given to demonstrate the advantages of\nthe proposed approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Convex Programming Relaxations for the Permanent.   In recent years, several convex programming relaxations have been proposed to\nestimate the permanent of a non-negative matrix, notably in the works of\nGurvits and Samorodnitsky. However, the origins of these relaxations and their\nrelationships to each other have remained somewhat mysterious. We present a\nconceptual framework, implicit in the belief propagation literature, to\nsystematically arrive at these convex programming relaxations for estimating\nthe permanent -- as approximations to an exponential-sized max-entropy convex\nprogram for computing the permanent. Further, using standard convex programming\ntechniques such as duality, we establish equivalence of these aforementioned\nrelaxations to those based on capacity-like quantities studied by Gurvits and\nAnari et al.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Optimal Control Formulation of Pulse-Based Control Using Koopman Operator.   In many applications, and in systems/synthetic biology, in particular, it is\ndesirable to compute control policies that force the trajectory of a bistable\nsystem from one equilibrium (the initial point) to another equilibrium (the\ntarget point), or in other words to solve the switching problem. It was\nrecently shown that, for monotone bistable systems, this problem admits\neasy-to-implement open-loop solutions in terms of temporal pulses (i.e., step\nfunctions of fixed length and fixed magnitude). In this paper, we develop this\nidea further and formulate a problem of convergence to an equilibrium from an\narbitrary initial point. We show that this problem can be solved using a static\noptimization problem in the case of monotone systems. Changing the initial\npoint to an arbitrary state allows to build closed-loop, event-based or\nopen-loop policies for the switching/convergence problems. In our derivations\nwe exploit the Koopman operator, which offers a linear infinite-dimensional\nrepresentation of an autonomous nonlinear system. One of the main advantages of\nusing the Koopman operator is the powerful computational tools developed for\nthis framework. Besides the presence of numerical solutions, the\nswitching/convergence problem can also serve as a building block for solving\nmore complicated control problems and can potentially be applied to\nnon-monotone systems. We illustrate this argument on the problem of\nsynchronizing cardiac cells by defibrillation. Potentially, our approach can be\nextended to problems with different parametrizations of control signals since\nthe only fundamental limitation is the finite time application of the control\nsignal.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Real-time monitoring of the structure of ultra thin Fe$_3$O$_4$ films during growth on Nb-doped SrTiO$_3$(001).   In this work thin magnetite films were deposited on SrTiO$_3$ via reactive\nmolecular beam epitaxy at different substrate temperatures. The growth process\nwas monitored in-situ during deposition by means of x-ray diffraction. While\nthe magnetite film grown at 400$^\\circ$C shows a fully relaxed vertical lattice\nconstant already in the early growth stages, the film deposited at 270$^\\circ$C\nexhibits a strong vertical compressive strain and relaxes towards the bulk\nvalue with increasing film thickness. Furthermore, a lateral tensile strain was\nobserved under these growth conditions although the inverse behavior is\nexpected due to the lattice mismatch of -7.5%. Additionally, the occupancy of\nthe A and B sublattices of magnetite with tetrahedral and octahedral sites was\ninvestigated showing a lower occupancy of the A sites compared to an ideal\ninverse spinel structure. The occupation of A sites decreases for a higher\ngrowth temperature. Thus, we assume a relocation of the iron ions from\ntetrahedral sites to octahedral vacancies forming a deficient rock salt\nlattice.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Particle Filters for Partially-Observed Boolean Dynamical Systems.   Partially-observed Boolean dynamical systems (POBDS) are a general class of\nnonlinear models with application in estimation and control of Boolean\nprocesses based on noisy and incomplete measurements. The optimal minimum mean\nsquare error (MMSE) algorithms for POBDS state estimation, namely, the Boolean\nKalman filter (BKF) and Boolean Kalman smoother (BKS), are intractable in the\ncase of large systems, due to computational and memory requirements. To address\nthis, we propose approximate MMSE filtering and smoothing algorithms based on\nthe auxiliary particle filter (APF) method from sequential Monte-Carlo theory.\nThese algorithms are used jointly with maximum-likelihood (ML) methods for\nsimultaneous state and parameter estimation in POBDS models. In the presence of\ncontinuous parameters, ML estimation is performed using the\nexpectation-maximization (EM) algorithm; we develop for this purpose a special\nsmoother which reduces the computational complexity of the EM algorithm. The\nresulting particle-based adaptive filter is applied to a POBDS model of Boolean\ngene regulatory networks observed through noisy RNA-Seq time series data, and\nperformance is assessed through a series of numerical experiments using the\nwell-known cell cycle gene regulatory model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Corrupt Bandits for Preserving Local Privacy.   We study a variant of the stochastic multi-armed bandit (MAB) problem in\nwhich the rewards are corrupted. In this framework, motivated by privacy\npreservation in online recommender systems, the goal is to maximize the sum of\nthe (unobserved) rewards, based on the observation of transformation of these\nrewards through a stochastic corruption process with known parameters. We\nprovide a lower bound on the expected regret of any bandit algorithm in this\ncorrupted setting. We devise a frequentist algorithm, KLUCB-CF, and a Bayesian\nalgorithm, TS-CF and give upper bounds on their regret. We also provide the\nappropriate corruption parameters to guarantee a desired level of local privacy\nand analyze how this impacts the regret. Finally, we present some experimental\nresults that confirm our analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Approximating the Backbone in the Weighted Maximum Satisfiability Problem.   The weighted Maximum Satisfiability problem (weighted MAX-SAT) is a NP-hard\nproblem with numerous applications arising in artificial intelligence. As an\nefficient tool for heuristic design, the backbone has been applied to\nheuristics design for many NP-hard problems. In this paper, we investigated the\ncomputational complexity for retrieving the backbone in weighted MAX-SAT and\ndeveloped a new algorithm for solving this problem. We showed that it is\nintractable to retrieve the full backbone under the assumption that . Moreover,\nit is intractable to retrieve a fixed fraction of the backbone as well. And\nthen we presented a backbone guided local search (BGLS) with Walksat operator\nfor weighted MAX-SAT. BGLS consists of two phases: the first phase samples the\nbackbone information from local optima and the backbone phase conducts local\nsearch under the guideline of backbone. Extensive experimental results on the\nbenchmark showed that BGLS outperforms the existing heuristics in both solution\nquality and runtime.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On algebraic branching programs of small width.   In 1979 Valiant showed that the complexity class VP_e of families with\npolynomially bounded formula size is contained in the class VP_s of families\nthat have algebraic branching programs (ABPs) of polynomially bounded size.\nMotivated by the problem of separating these classes we study the topological\nclosure VP_e-bar, i.e. the class of polynomials that can be approximated\narbitrarily closely by polynomials in VP_e. We describe VP_e-bar with a\nstrikingly simple complete polynomial (in characteristic different from 2)\nwhose recursive definition is similar to the Fibonacci numbers. Further\nunderstanding this polynomial seems to be a promising route to new formula\nlower bounds.\nOur methods are rooted in the study of ABPs of small constant width. In 1992\nBen-Or and Cleve showed that formula size is polynomially equivalent to width-3\nABP size. We extend their result (in characteristic different from 2) by\nshowing that approximate formula size is polynomially equivalent to approximate\nwidth-2 ABP size. This is surprising because in 2011 Allender and Wang gave\nexplicit polynomials that cannot be computed by width-2 ABPs at all! The\ndetails of our construction lead to the aforementioned characterization of\nVP_e-bar.\nAs a natural continuation of this work we prove that the class VNP can be\ndescribed as the class of families that admit a hypercube summation of\npolynomially bounded dimension over a product of polynomially many affine\nlinear forms. This gives the first separations of algebraic complexity classes\nfrom their nondeterministic analogs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Primordial Black Holes and Slow-Roll Violation.   For primordial black holes (PBH) to be the dark matter in single-field\ninflation, the slow-roll approximation must be violated by at least ${\\cal\nO}(1)$ in order to enhance the curvature power spectrum within the required\nnumber of efolds between CMB scales and PBH mass scales. Power spectrum\npredictions which rely on the inflaton remaining on the slow-roll attractor can\nfail dramatically leading to qualitatively incorrect conclusions in models like\nan inflection potential and misestimate the mass scale in a running mass model.\nWe show that an optimized temporal evaluation of the Hubble slow-roll\nparameters to second order remains a good description for a wide range of PBH\nformation models where up to a $10^7$ amplification of power occurs in $10$\nefolds or more.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the origin of the hydraulic jump in a thin liquid film.   For more than a century, it has been believed that all hydraulic jumps are\ncreated due to gravity. However, we found that thin-film hydraulic jumps are\nnot induced by gravity. This study explores the initiation of thin-film\nhydraulic jumps. For circular jumps produced by the normal impingement of a jet\nonto a solid surface, we found that the jump is formed when surface tension and\nviscous forces balance the momentum in the film and gravity plays no\nsignificant role. Experiments show no dependence on the orientation of the\nsurface and a scaling relation balancing viscous forces and surface tension\ncollapses the experimental data. Experiments on thin film planar jumps in a\nchannel also show that the predominant balance is with surface tension,\nalthough for the thickness of the films we studied gravity also played a role\nin the jump formation. A theoretical analysis shows that the downstream\ntransport of surface tension energy is the previously neglected, critical\ningredient in these flows and that capillary waves play the role of gravity\nwaves in a traditional jump in demarcating the transition from the\nsupercritical to subcritical flow associated with these jumps.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Muon detector for the COSINE-100 experiment.   The COSINE-100 dark matter search experiment has started taking physics data\nwith the goal of performing an independent measurement of the annual modulation\nsignal observed by DAMA/LIBRA. A muon detector was constructed by using plastic\nscintillator panels in the outermost layer of the shield surrounding the\nCOSINE-100 detector. It is used to detect cosmic ray muons in order to\nunderstand the impact of the muon annual modulation on dark matter analysis.\nAssembly and initial performance test of each module have been performed at a\nground laboratory. The installation of the detector in Yangyang Underground\nLaboratory (Y2L) was completed in the summer of 2016. Using three months of\ndata, the muon underground flux was measured to be 328 $\\pm$ 1(stat.)$\\pm$\n10(syst.) muons/m$^2$/day. In this report, the assembly of the muon detector\nand the results from the analysis are presented.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Restriction of representations of metaplectic $GL_{2}(F)$ to tori.   Let $F$ be a non-Archimedean local field. We study the restriction of an\nirreducible admissible genuine representations of the two fold metaplectic\ncover $\\widetilde{GL}_{2}(F)$ of $GL_{2}(F)$ to the inverse image in\n$\\widetilde{GL}_{2}(F)$ of a maximal torus in $GL_{2}(F)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "PatternListener: Cracking Android Pattern Lock Using Acoustic Signals.   Pattern lock has been widely used for authentication to protect user privacy\non mobile devices (e.g., smartphones and tablets). Given its pervasive usage,\nthe compromise of pattern lock could lead to serious consequences. Several\nattacks have been constructed to crack the lock. However, these approaches\nrequire the attackers to either be physically close to the target device or be\nable to manipulate the network facilities (e.g., WiFi hotspots) used by the\nvictims. Therefore, the effectiveness of the attacks is significantly impacted\nby the environment of mobile devices. Also, these attacks are not scalable\nsince they cannot easily infer unlock patterns of a large number of devices.\nMotivated by an observation that fingertip motions on the screen of a mobile\ndevice can be captured by analyzing surrounding acoustic signals on it, we\npropose PatternListener, a novel acoustic attack that cracks pattern lock by\nanalyzing imperceptible acoustic signals reflected by the fingertip. It\nleverages speakers and microphones of the victim's device to play imperceptible\naudio and record the acoustic signals reflected by the fingertip. In\nparticular, it infers each unlock pattern by analyzing individual lines that\ncompose the pattern and are the trajectories of the fingertip. We propose\nseveral algorithms to construct signal segments according to the captured\nsignals for each line and infer possible candidates of each individual line\naccording to the signal segments. Finally, we map all line candidates into grid\npatterns and thereby obtain the candidates of the entire unlock pattern. We\nimplement a PatternListener prototype by using off-the-shelf smartphones and\nthoroughly evaluate it using 130 unique patterns. The real experimental results\ndemonstrate that PatternListener can successfully exploit over 90% patterns\nwithin five attempts.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bio-Inspired Local Information-Based Control for Probabilistic Swarm Distribution Guidance.   This paper addresses a task allocation problem for a large-scale robotic\nswarm, namely swarm distribution guidance problem. Unlike most of the existing\nframeworks handling this problem, the proposed framework suggests utilising\nlocal information available to generate its time-varying stochastic policies.\nAs each agent requires only local consistency on information with neighbouring\nagents, rather than the global consistency, the proposed framework offers\nvarious advantages, e.g., a shorter timescale for using new information and\npotential to incorporate an asynchronous decision-making process. We perform\ntheoretical analysis on the properties of the proposed framework. From the\nanalysis, it is proved that the framework can guarantee the convergence to the\ndesired density distribution even using local information while maintaining\nadvantages of global-information-based approaches. The design requirements for\nthese advantages are explicitly listed in this paper. This paper also provides\nspecific examples of how to implement the framework developed. The results of\nnumerical experiments confirm the effectiveness and comparability of the\nproposed framework, compared with the global-information-based framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cantor series and rational numbers.   The article is devoted to the investigation of representation of rational\nnumbers by Cantor series. Necessary and sufficient conditions for a rational\nnumber to be representable by a positive Cantor series are formulated for the\ncase of an arbitrary sequence $(q_k)$ and some its corollaries are considered.\nResults of this article were presented by the author of this article on the\nInternational Conference on Algebra dedicated to 100th anniversary of S. M.\nChernikov (www.researchgate.net/publication/311415815,\nwww.researchgate.net/publication/301849984). This investigation was also\npresented in some reports (links to the reports:\nwww.researchgate.net/publication/303736670,\nwww.researchgate.net/publication/303720573, etc.).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Automatically Leveraging MapReduce Frameworks for Data-Intensive Applications.   MapReduce is a popular programming paradigm for developing large-scale,\ndata-intensive computation. Many frameworks that implement this paradigm have\nrecently been developed. To leverage these frameworks, however, developers must\nbecome familiar with their APIs and rewrite existing code. Casper is a new tool\nthat automatically translates sequential Java programs into the MapReduce\nparadigm. Casper identifies potential code fragments to rewrite and translates\nthem in two steps: (1) Casper uses program synthesis to search for a program\nsummary (i.e., a functional specification) of each code fragment. The summary\nis expressed using a high-level intermediate language resembling the MapReduce\nparadigm and verified to be semantically equivalent to the original using a\ntheorem prover. (2) Casper generates executable code from the summary, using\neither the Hadoop, Spark, or Flink API. We evaluated Casper by automatically\nconverting real-world, sequential Java benchmarks to MapReduce. The resulting\nbenchmarks perform up to 48.2x faster compared to the original.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The effect of stellar and AGN feedback on the low redshift Lyman-$α$ forest in the Sherwood simulation suite.   We study the effect of different feedback prescriptions on the properties of\nthe low redshift ($z\\leq1.6$) Ly$\\alpha$ forest using a selection of\nhydrodynamical simulations drawn from the Sherwood simulation suite. The\nsimulations incorporate stellar feedback, AGN feedback and a simplified scheme\nfor efficiently modelling the low column density Ly$\\alpha$ forest. We confirm\na discrepancy remains between Cosmic Origins Spectrograph (COS) observations of\nthe Ly$\\alpha$ forest column density distribution function (CDDF) at $z \\simeq\n0.1$ for high column density systems ($N_{\\rm HI}>10^{14}\\rm\\,cm^{-2}$), as\nwell as Ly$\\alpha$ velocity widths that are too narrow compared to the COS\ndata. Stellar or AGN feedback -- as currently implemented in our simulations --\nhave only a small effect on the CDDF and velocity width distribution. We\nconclude that resolving the discrepancy between the COS data and simulations\nrequires an increase in the temperature of overdense gas with $\\Delta=4$--$40$,\neither through additional He$\\,\\rm \\scriptstyle II\\ $ photo-heating at $z>2$ or\nfine-tuned feedback that ejects overdense gas into the IGM at just the right\ntemperature for it to still contribute significantly to the Ly$\\alpha$ forest.\nAlternatively a larger, currently unresolved turbulent component to the line\nwidth could resolve the discrepancy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Positive solutions for nonlinear problems involving the one-dimensional ϕ-Laplacian.   Let $\\Omega:=\\left( a,b\\right) \\subset\\mathbb{R}$, $m\\in L^{1}\\left(\n\\Omega\\right) $ and $\\lambda>0$ be a real parameter. Let $\\mathcal{L}$ be the\ndifferential operator given by $\\mathcal{L}u:=-\\phi\\left( u^{\\prime}\\right)\n^{\\prime}+r\\left( x\\right) \\phi\\left( u\\right) $, where $\\phi\n:\\mathbb{R\\rightarrow R}$ is an odd increasing homeomorphism and $0\\leq r\\in\nL^{1}\\left( \\Omega\\right) $. We study the existence of positive solutions for\nproblems of the form $\\mathcal{L}u=\\lambda m\\left( x\\right) f\\left( u\\right)$\nin $\\Omega,$ $u=0$ on $\\partial\\Omega$, where $f:\\left[ 0,\\infty\\right)\n\\rightarrow\\left[ 0,\\infty\\right) $ is a continuos function which is, roughly\nspeaking, sublinear with respect to $\\phi$. Our approach combines the sub and\nsupersolution method with some estimates on related nonlinear problems. We\npoint out that our results are new even in the cases $r\\equiv0$ and/or\n$m\\geq0$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Combinatorics of Weighted Vector Compositions.   A vector composition of a vector $\\mathbf{\\ell}$ is a matrix $\\mathbf{A}$\nwhose rows sum to $\\mathbf{\\ell}$. We define a weighted vector composition as a\nvector composition in which the column values of $\\mathbf{A}$ may appear in\ndifferent colors. We study vector compositions from different viewpoints: (1)\nWe show how they are related to sums of random vectors and (2) how they allow\nto derive formulas for partial derivatives of composite functions. (3) We study\ncongruence properties of the number of weighted vector compositions, for fixed\nand arbitrary number of parts, many of which are analogous to those of ordinary\nbinomial coefficients and related quantities. Via the Central Limit Theorem and\ntheir multivariate generating functions, (4) we also investigate the asymptotic\nbehavior of several special cases of numbers of weighted vector compositions.\nFinally, (5) we conjecture an extension of a primality criterion due to Mann\nand Shanks in the context of weighted vector compositions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Approximations of the allelic frequency spectrum in general supercritical branching populations.   We consider a general branching population where the lifetimes of individuals\nare i.i.d.\\ with arbitrary distribution and where each individual gives birth\nto new individuals at Poisson times independently from each other. In addition,\nwe suppose that individuals experience mutations at Poissonian rate $\\theta$\nunder the infinitely many alleles assumption assuming that types are\ntransmitted from parents to offspring. This mechanism leads to a partition of\nthe population by type, called the allelic partition. The main object of this\nwork is the frequency spectrum $A(k,t)$ which counts the number of families of\nsize $k$ in the population at time $t$. The process $(A(k,t),\\\nt\\in\\mathbb{R}_+)$ is an example of non-Markovian branching process belonging\nto the class of general branching processes counted by random characteristics.\nIn this work, we propose methods of approximation to replace the frequency\nspectrum by simpler quantities. Our main goal is study the asymptotic error\nmade during these approximations through central limit theorems. In a last\nsection, we perform several numerical analysis using this model, in particular\nto analyze the behavior of one of these approximations with respect to Sabeti's\nExtended Haplotype Homozygosity [18].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Existence and convexity of local solutions to degenerate hessian equations.   In this work, we prove the existence of local convex solution to the\ndegenerate Hessian equation",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quasi-Static Internal Magnetic Field Detected in the Pseudogap Phase of Bi$_{2+x}$Sr$_{2-x}$CaCu$_2$O$_{8+δ}$ by $μ$SR.   We report muon spin relaxation ($\\mu$SR) measurements of optimally-doped and\noverdoped Bi$_{2+x}$Sr$_{2-x}$CaCu$_2$O$_{8+\\delta}$ (Bi2212) single crystals\nthat reveal the presence of a weak temperature-dependent quasi-static internal\nmagnetic field of electronic origin in the superconducting (SC) and pseudogap\n(PG) phases. In both samples the internal magnetic field persists up to 160~K,\nbut muon diffusion prevents following the evolution of the field to higher\ntemperatures. We consider the evidence from our measurments in support of PG\norder parameter candidates, namely, electronic loop currents and\nmagnetoelectric quadrupoles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Activating spin-forbidden transitions in molecules by the highly localized plasmonic field.   Optical spectroscopy has been the primary tool to study the electronic\nstructure of molecules. However the strict spin selection rule has severely\nlimited its ability to access states of different spin multiplicities. Here we\npropose a new strategy to activate spin-forbidden transitions in molecules by\nintroducing spatially highly inhomogeneous plasmonic field. The giant\nenhancement of the magnetic field strength resulted from the curl of the\ninhomogeneous vector potential makes the transition between states of different\nspin multiplicities naturally feasible. The dramatic effect of the\ninhomogeneity of the plasmonic field on the spin and symmetry selection rules\nis well illustrated by first principles calculations of C60. Remarkably, the\nintensity of singlet-triplet transitions can even be stronger than that of\nsinglet-singlet transitions when the plasmon spatial distribution is comparable\nwith the molecular size. This approach offers a powerful means to completely\nmap out all excited states of molecules and to actively control their\nphotochemical processes. The same concept can also be applied to study nano and\nbiological systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Robust Regulation of Infinite-Dimensional Port-Hamiltonian Systems.   We will give general sufficient conditions under which a controller achieves\nrobust regulation for a boundary control and observation system. Utilizing\nthese conditions we construct a minimal order robust controller for an\narbitrary order impedance passive linear port-Hamiltonian system. The\ntheoretical results are illustrated with a numerical example where we implement\na controller for a one-dimensional Euler-Bernoulli beam with boundary controls\nand boundary observations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "White Matter Network Architecture Guides Direct Electrical Stimulation Through Optimal State Transitions.   Electrical brain stimulation is currently being investigated as a therapy for\nneurological disease. However, opportunities to optimize such therapies are\nchallenged by the fact that the beneficial impact of focal stimulation on both\nneighboring and distant regions is not well understood. Here, we use network\ncontrol theory to build a model of brain network function that makes\npredictions about how stimulation spreads through the brain's white matter\nnetwork and influences large-scale dynamics. We test these predictions using\ncombined electrocorticography (ECoG) and diffusion weighted imaging (DWI) data\nwho volunteered to participate in an extensive stimulation regimen. We posit a\nspecific model-based manner in which white matter tracts constrain stimulation,\ndefining its capacity to drive the brain to new states, including states\nassociated with successful memory encoding. In a first validation of our model,\nwe find that the true pattern of white matter tracts can be used to more\naccurately predict the state transitions induced by direct electrical\nstimulation than the artificial patterns of null models. We then use a targeted\noptimal control framework to solve for the optimal energy required to drive the\nbrain to a given state. We show that, intuitively, our model predicts larger\nenergy requirements when starting from states that are farther away from a\ntarget memory state. We then suggest testable hypotheses about which structural\nproperties will lead to efficient stimulation for improving memory based on\nenergy requirements. Our work demonstrates that individual white matter\narchitecture plays a vital role in guiding the dynamics of direct electrical\nstimulation, more generally offering empirical support for the utility of\nnetwork control theoretic models of brain response to stimulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotics of ABC.   We present an informal review of recent work on the asymptotics of\nApproximate Bayesian Computation (ABC). In particular we focus on how does the\nABC posterior, or point estimates obtained by ABC, behave in the limit as we\nhave more data? The results we review show that ABC can perform well in terms\nof point estimation, but standard implementations will over-estimate the\nuncertainty about the parameters. If we use the regression correction of\nBeaumont et al. then ABC can also accurately quantify this uncertainty. The\ntheoretical results also have practical implications for how to implement ABC.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "RSI-CB: A Large Scale Remote Sensing Image Classification Benchmark via Crowdsource Data.   Remote sensing image classification is a fundamental task in remote sensing\nimage processing. Remote sensing field still lacks of such a large-scale\nbenchmark compared to ImageNet, Place2. We propose a remote sensing image\nclassification benchmark (RSI-CB) based on crowd-source data which is massive,\nscalable, and diversity. Using crowdsource data, we can efficiently annotate\nground objects in remotes sensing image by point of interests, vectors data\nfrom OSM or other crowd-source data. Based on this method, we construct a\nworldwide large-scale benchmark for remote sensing image classification. In\nthis benchmark, there are two sub datasets with 256 * 256 and 128 * 128 size\nrespectively since different convolution neural networks requirement different\nimage size. The former sub dataset contains 6 categories with 35 subclasses\nwith total of more than 24,000 images; the later one contains 6 categories with\n45 subclasses with total of more than 36,000 images. The six categories are\nagricultural land, construction land and facilities, transportation and\nfacilities, water and water conservancy facilities, woodland and other land,\nand each category has several subclasses. This classification system is defined\naccording to the national standard of land use classification in China, and is\ninspired by the hierarchy mechanism of ImageNet. Finally, we have done a large\nnumber of experiments to compare RSI-CB with SAT-4, UC-Merced datasets on\nhandcrafted features, such as such as SIFT, and classical CNN models, such as\nAlexNet, VGG, GoogleNet, and ResNet. We also show CNN models trained by RSI-CB\nhave good performance when transfer to other dataset, i.e. UC-Merced, and good\ngeneralization ability. The experiments show that RSI-CB is more suitable as a\nbenchmark for remote sensing image classification task than other ones in big\ndata era, and can be potentially used in practical applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-Entity Dependence Learning with Rich Context via Conditional Variational Auto-encoder.   Multi-Entity Dependence Learning (MEDL) explores conditional correlations\namong multiple entities. The availability of rich contextual information\nrequires a nimble learning scheme that tightly integrates with deep neural\nnetworks and has the ability to capture correlation structures among\nexponentially many outcomes. We propose MEDL_CVAE, which encodes a conditional\nmultivariate distribution as a generating process. As a result, the variational\nlower bound of the joint likelihood can be optimized via a conditional\nvariational auto-encoder and trained end-to-end on GPUs. Our MEDL_CVAE was\nmotivated by two real-world applications in computational sustainability: one\nstudies the spatial correlation among multiple bird species using the eBird\ndata and the other models multi-dimensional landscape composition and human\nfootprint in the Amazon rainforest with satellite images. We show that\nMEDL_CVAE captures rich dependency structures, scales better than previous\nmethods, and further improves on the joint likelihood taking advantage of very\nlarge datasets that are beyond the capacity of previous methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Flow-Sensitive Composition of Thread-Modular Abstract Interpretation.   We propose a constraint-based flow-sensitive static analysis for concurrent\nprograms by iteratively composing thread-modular abstract interpreters via the\nuse of a system of lightweight constraints. Our method is compositional in that\nit first applies sequential abstract interpreters to individual threads and\nthen composes their results. It is flow-sensitive in that the causality\nordering of interferences (flow of data from global writes to reads) is modeled\nby a system of constraints. These interference constraints are lightweight\nsince they only refer to the execution order of program statements as opposed\nto their numerical properties: they can be decided efficiently using an\noff-the-shelf Datalog engine. Our new method has the advantage of being more\naccurate than existing, flow-insensitive, static analyzers while remaining\nscalable and providing the expected soundness and termination guarantees even\nfor programs with unbounded data. We implemented our method and evaluated it on\na large number of benchmarks, demonstrating its effectiveness at increasing the\naccuracy of thread-modular abstract interpretation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hydrodynamic stability in the presence of a stochastic forcing:a case study in convection.   We investigate the stability of a statistically stationary conductive state\nfor Rayleigh-Bénard convection between stress-free plates that arises due to\na bulk stochastic internal heating. This setup may be seen as a generalization\nto a stochastic setting of the seminal 1916 study of Lord Rayleigh. Our results\nindicate that stochastic forcing at small magnitude has a stabilizing effect,\nwhile strong stochastic forcing has a destabilizing effect. The methodology put\nforth in this article, which combines rigorous analysis with careful\ncomputation, also provides an approach to hydrodynamic stability for a variety\nof systems subject to a large scale stochastic forcing.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Power-Sum Denominators.   The power sum $1^n + 2^n + \\cdots + x^n$ has been of interest to\nmathematicians since classical times. Johann Faulhaber, Jacob Bernoulli, and\nothers who followed expressed power sums as polynomials in $x$ of degree $n+1$\nwith rational coefficients. Here we consider the denominators of these\npolynomials, and prove some of their properties. A remarkable one is that such\na denominator equals $n+1$ times the squarefree product of certain primes $p$\nobeying the condition that the sum of the base-$p$ digits of $n+1$ is at least\n$p$. As an application, we derive a squarefree product formula for the\ndenominators of the Bernoulli polynomials.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detecting Recycled Commodity SoCs: Exploiting Aging-Induced SRAM PUF Unreliability.   A physical unclonable function (PUF), analogous to a human fingerprint, has\ngained an enormous amount of attention from both academia and industry. SRAM\nPUF is among one of the popular silicon PUF constructions that exploits random\ninitial power-up states from SRAM cells to extract hardware intrinsic secrets\nfor identification and key generation applications. The advantage of SRAM PUFs\nis that they are widely embedded into commodity devices, thus such a PUF is\nobtained without a custom design and virtually free of implementation costs. A\nphenomenon known as `aging' alters the consistent\nreproducibility---reliability---of responses that can be extracted from a\nreadout of a set of SRAM PUF cells. Similar to how a PUF exploits undesirable\nmanufacturing randomness for generating a hardware intrinsic fingerprint, SRAM\nPUF unreliability induced by aging can be exploited to detect recycled\ncommodity devices requiring no additional cost to the device. In this context,\nthe SRAM PUF itself acts as an aging sensor by exploiting responses sensitive\nto aging. We use SRAMs available in pervasively deployed commercial\noff-the-shelf micro-controllers for experimental validations, which complements\nrecent work demonstrated in FPGA platforms, and we present a simplified\ndetection methodology along experimental results. We show that less than 1,000\nSRAM responses are adequate to guarantee that both false acceptance rate and\nfalse rejection rate are no more than 0.001.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stealthy Deception Attacks Against SCADA Systems.   SCADA protocols for Industrial Control Systems (ICS) are vulnerable to\nnetwork attacks such as session hijacking. Hence, research focuses on network\nanomaly detection based on meta--data (message sizes, timing, command\nsequence), or on the state values of the physical process. In this work we\npresent a class of semantic network-based attacks against SCADA systems that\nare undetectable by the above mentioned anomaly detection. After hijacking the\ncommunication channels between the Human Machine Interface (HMI) and\nProgrammable Logic Controllers (PLCs), our attacks cause the HMI to present a\nfake view of the industrial process, deceiving the human operator into taking\nmanual actions. Our most advanced attack also manipulates the messages\ngenerated by the operator's actions, reversing their semantic meaning while\ncausing the HMI to present a view that is consistent with the attempted human\nactions. The attacks are totaly stealthy because the message sizes and timing,\nthe command sequences, and the data values of the ICS's state all remain\nlegitimate.\nWe implemented and tested several attack scenarios in the test lab of our\nlocal electric company, against a real HMI and real PLCs, separated by a\ncommercial-grade firewall. We developed a real-time security assessment tool,\nthat can simultaneously manipulate the communication to multiple PLCs and cause\nthe HMI to display a coherent system--wide fake view. Our tool is configured\nwith message-manipulating rules written in an ICS Attack Markup Language (IAML)\nwe designed, which may be of independent interest. Our semantic attacks all\nsuccessfully fooled the operator and brought the system to states of blackout\nand possible equipment damage.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Tutte embedding of the mated-CRT map converges to Liouville quantum gravity.   We prove that the Tutte embeddings (a.k.a. harmonic/embeddings) of certain\nrandom planar maps converge to $\\gamma$-Liouville quantum gravity\n($\\gamma$-LQG). Specifically, we treat mated-CRT maps, which are discretized\nmatings of correlated continuum random trees, and $\\gamma$ ranges from $0$ to\n$2$ as one varies the correlation parameter. We also show that the associated\nspace-filling path on the embedded map converges to space-filling\nSLE$_{\\kappa}$ for $\\kappa =16/\\gamma^2$ (in the annealed sense) and that\nsimple random walk on the embedded map converges to Brownian motion (in the\nquenched sense). Our arguments also yield analogous statements for the Smith\n(square tiling) embedding of the mated-CRT map.\nThis work constitutes the first proof that a discrete conformal embedding of\na random planar map converges to LQG. Many more such statements have been\nconjectured. Since the mated-CRT map can be viewed as a coarse-grained\napproximation to other random planar maps (the UIPT, tree-weighted maps,\nbipolar-oriented maps, etc.), our results indicate a potential approach for\nproving that embeddings of these maps converge to LQG as well.\nTo prove the main result, we establish several (independently interesting)\ntheorems about LQG surfaces decorated by space-filling SLE. There is a natural\nway to use the SLE curve to divide the plane into `cells' corresponding to\nvertices of the mated-CRT map. We study the law of the shape of the\norigin-containing cell, in particular proving moments for the ratio of its\nsquared diameter to its area. We also give bounds on the degree of the\norigin-containing cell and establish a form of ergodicity for the entire\nconfiguration. Ultimately, we use these properties to show (using a general\ntheorem proved in a separate paper) that random walk on these cells converges\nto a time change of Brownian motion, which in turn leads to the Tutte embedding\nresult.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological orders of strongly interacting particles.   We investigate the self-organization of strongly interacting particles\nconfined in 1D and 2D. We consider hardcore bosons in spinless Hubbard lattice\nmodels with short range interactions. We show that, many-body orders with\ntopological characteristics emerge, at different energy bands separated by\nlarge gaps. These topological orders manifest in the way the particles organize\nin real space to form states with different energy. Each of these states\ncontains topological defects/condensations whose Euler characteristic can be\nused as a topological number to categorize states belonging to the same energy\nband. We provide analytical formulas for this topological number and the full\nenergy spectrum of the system for both sparsely and densely filled systems.\nFurthermore, we discuss the connection with the Gauss-Bonnet theorem of\ndifferential geometry, by using the curvature generated in real space by the\nparticle structures. Our result is a demonstration of how topological orders\ncan arise in strongly interacting many-body systems with simple underlying\nrules, without considering the spin, long-range microscopic interactions, or\nexternal fields.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Boosting Adversarial Attacks with Momentum.   Deep neural networks are vulnerable to adversarial examples, which poses\nsecurity concerns on these algorithms due to the potentially severe\nconsequences. Adversarial attacks serve as an important surrogate to evaluate\nthe robustness of deep learning models before they are deployed. However, most\nof existing adversarial attacks can only fool a black-box model with a low\nsuccess rate. To address this issue, we propose a broad class of momentum-based\niterative algorithms to boost adversarial attacks. By integrating the momentum\nterm into the iterative process for attacks, our methods can stabilize update\ndirections and escape from poor local maxima during the iterations, resulting\nin more transferable adversarial examples. To further improve the success rates\nfor black-box attacks, we apply momentum iterative algorithms to an ensemble of\nmodels, and show that the adversarially trained models with a strong defense\nability are also vulnerable to our black-box attacks. We hope that the proposed\nmethods will serve as a benchmark for evaluating the robustness of various deep\nmodels and defense methods. With this method, we won the first places in NIPS\n2017 Non-targeted Adversarial Attack and Targeted Adversarial Attack\ncompetitions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improved SVD-based Initialization for Nonnegative Matrix Factorization using Low-Rank Correction.   Due to the iterative nature of most nonnegative matrix factorization\n(\\textsc{NMF}) algorithms, initialization is a key aspect as it significantly\ninfluences both the convergence and the final solution obtained. Many\ninitialization schemes have been proposed for NMF, among which one of the most\npopular class of methods are based on the singular value decomposition (SVD).\nHowever, these SVD-based initializations do not satisfy a rather natural\ncondition, namely that the error should decrease as the rank of factorization\nincreases. In this paper, we propose a novel SVD-based \\textsc{NMF}\ninitialization to specifically address this shortcoming by taking into account\nthe SVD factors that were discarded to obtain a nonnegative initialization.\nThis method, referred to as nonnegative SVD with low-rank correction\n(NNSVD-LRC), allows us to significantly reduce the initial error at a\nnegligible additional computational cost using the low-rank structure of the\ndiscarded SVD factors. NNSVD-LRC has two other advantages compared to previous\nSVD-based initializations: (1) it provably generates sparse initial factors,\nand (2) it is faster as it only requires to compute a truncated SVD of rank\n$\\lceil r/2 + 1 \\rceil$ where $r$ is the factorization rank of the sought NMF\ndecomposition (as opposed to a rank-$r$ truncated SVD for other methods). We\nshow on several standard dense and sparse data sets that our new method\ncompetes favorably with state-of-the-art SVD-based initializations for NMF.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Disorder-protected topological entropy after a quantum quench.   Topological phases of matter are considered the bedrock of novel quantum\nmaterials as well as ideal candidates for quantum computers that possess\nrobustness at the physical level. The robustness of the topological phase at\nfinite temperature or away from equilibrium is therefore a very desirable\nfeature. Disorder can improve the lifetime of the encoded topological qubits.\nHere we tackle the problem of the survival of the topological phase as detected\nby topological entropy, after a sudden quantum quench. We introduce a method to\nstudy analytically the time evolution of the system after a quantum quench and\nshow that disorder in the couplings of the Hamiltonian of the toric code and\nthe resulting Anderson localization can make the topological entropy resilient.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Value Propagation for Decentralized Networked Deep Multi-agent Reinforcement Learning.   We consider the networked multi-agent reinforcement learning (MARL) problem\nin a fully decentralized setting, where agents learn to coordinate to achieve\nthe joint success. This problem is widely encountered in many areas including\ntraffic control, distributed control, and smart grids. We assume that the\nreward function for each agent can be different and observed only locally by\nthe agent itself. Furthermore, each agent is located at a node of a\ncommunication network and can exchanges information only with its neighbors.\nUsing softmax temporal consistency and a decentralized optimization method, we\nobtain a principled and data-efficient iterative algorithm. In the first step\nof each iteration, an agent computes its local policy and value gradients and\nthen updates only policy parameters. In the second step, the agent propagates\nto its neighbors the messages based on its value function and then updates its\nown value function. Hence we name the algorithm value propagation. We prove a\nnon-asymptotic convergence rate 1/T with the nonlinear function approximation.\nTo the best of our knowledge, it is the first MARL algorithm with convergence\nguarantee in the control, off-policy and non-linear function approximation\nsetting. We empirically demonstrate the effectiveness of our approach in\nexperiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evaluating Compositionality in Sentence Embeddings.   An important challenge for human-like AI is compositional semantics. Recent\nresearch has attempted to address this by using deep neural networks to learn\nvector space embeddings of sentences, which then serve as input to other tasks.\nWe present a new dataset for one such task, `natural language inference' (NLI),\nthat cannot be solved using only word-level knowledge and requires some\ncompositionality. We find that the performance of state of the art sentence\nembeddings (InferSent; Conneau et al., 2017) on our new dataset is poor. We\nanalyze the decision rules learned by InferSent and find that they are\nconsistent with simple heuristics that are ecologically valid in its training\ndataset. Further, we find that augmenting training with our dataset improves\ntest performance on our dataset without loss of performance on the original\ntraining dataset. This highlights the importance of structured datasets in\nbetter understanding and improving AI systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient determination of optimised multi-arm multi-stage experimental designs with control of generalised error-rates.   Primarily motivated by the drug development process, several publications\nhave now presented methodology for the design of multi-arm multi-stage\nexperiments with normally distributed outcome variables of known variance.\nHere, we extend these past considerations to allow the design of what we refer\nto as an abcd multi-arm multi-stage experiment. We provide a proof of how\nstrong control of the a-generalised type-I familywise error-rate can be\nensured. We then describe how to attain the power to reject at least b out of c\nfalse hypotheses, which is related to controlling the b-generalised type-II\nfamilywise error-rate. Following this, we detail how a design can be optimised\nfor a scenario in which rejection of any d null hypotheses brings about\ntermination of the experiment. We achieve this by proposing a highly\ncomputationally efficient approach for evaluating the performance of a\ncandidate design. Finally, using a real clinical trial as a motivating example,\nwe explore the effect of the design's control parameters on the statistical\noperating characteristics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Direct and indirect seismic inversion: interpretation of certain mathematical theorems.   Quantitative methods are more familiar to most geophysicists with direct\ninversion or indirect inversion. We will discuss seismic inversion in a high\nlevel sense without getting into the actual algorithms. We will stay with\nmeta-equations and argue pros and cons based on certain mathematical theorems.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Vibrational Density Matrix Renormalization Group.   Variational approaches for the calculation of vibrational wave functions and\nenergies are a natural route to obtain highly accurate results with\ncontrollable errors. However, the unfavorable scaling and the resulting high\ncomputational cost of standard variational approaches limit their application\nto small molecules with only few vibrational modes. Here, we demonstrate how\nthe density matrix renormalization group (DMRG) can be exploited to optimize\nvibrational wave functions (vDMRG) expressed as matrix product states. We study\nthe convergence of these calculations with respect to the size of the local\nbasis of each mode, the number of renormalized block states, and the number of\nDMRG sweeps required. We demonstrate the high accuracy achieved by vDMRG for\nsmall molecules that were intensively studied in the literature. We then\nproceed to show that the complete fingerprint region of the sarcosyn-glycin\ndipeptide can be calculated with vDMRG.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Characterizing a CCD detector for astronomical purposes: OAUNI Project.   This work verifies the instrumental characteristics of the CCD detector which\nis part of the UNI astronomical observatory. We measured the linearity of the\nCCD detector of the SBIG STXL6303E camera, along with the associated gain and\nreadout noise. The linear response to the incident light of the detector is\nextremely linear (R2 =99.99%), its effective gain is 1.65 +/- 0.01 e-/ADU and\nits readout noise is 12.2 e-. These values are in agreement with the\nmanufacturer. We confirm that this detector is extremely precise to make\nmeasurements for astronomical purposes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning from Experience: A Dynamic Closed-Loop QoE Optimization for Video Adaptation and Delivery.   The quality of experience (QoE) is known to be subjective and\ncontext-dependent. Identifying and calculating the factors that affect QoE is\nindeed a difficult task. Recently, a lot of effort has been devoted to estimate\nthe users QoE in order to improve video delivery. In the literature, most of\nthe QoE-driven optimization schemes that realize trade-offs among different\nquality metrics have been addressed under the assumption of homogenous\npopulations. Nevertheless, people perceptions on a given video quality may not\nbe the same, which makes the QoE optimization harder. This paper aims at taking\na step further in order to address this limitation and meet users profiles. To\ndo so, we propose a closed-loop control framework based on the\nusers(subjective) feedbacks to learn the QoE function and optimize it at the\nsame time. Our simulation results show that our system converges to a steady\nstate, where the resulting QoE function noticeably improves the users\nfeedbacks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Motion optimization and parameter identification for a human and lower-back exoskeleton model.   Designing an exoskeleton to reduce the risk of low-back injury during lifting\nis challenging. Computational models of the human-robot system coupled with\npredictive movement simulations can help to simplify this design process. Here,\nwe present a study that models the interaction between a human model actuated\nby muscles and a lower-back exoskeleton. We provide a computational framework\nfor identifying the spring parameters of the exoskeleton using an optimal\ncontrol approach and forward-dynamics simulations. This is applied to generate\ndynamically consistent bending and lifting movements in the sagittal plane. Our\ncomputations are able to predict motions and forces of the human and\nexoskeleton that are within the torque limits of a subject. The identified\nexoskeleton could also yield a considerable reduction of the peak lower-back\ntorques as well as the cumulative lower-back load during the movements. This\nwork is relevant to the research communities working on human-robot\ninteraction, and can be used as a basis for a better human-centered design\nprocess.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SARAH: A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient.   In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH),\nas well as its practical variant SARAH+, as a novel approach to the finite-sum\nminimization problems. Different from the vanilla SGD and other modern\nstochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple\nrecursive framework for updating stochastic gradient estimates; when comparing\nto SAG/SAGA, SARAH does not require a storage of past gradients. The linear\nconvergence rate of SARAH is proven under strong convexity assumption. We also\nprove a linear convergence rate (in the strongly convex case) for an inner loop\nof SARAH, the property that SVRG does not possess. Numerical experiments\ndemonstrate the efficiency of our algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Self-dual and logarithmic representations of the twisted Heisenberg--Virasoro algebra at level zero.   This paper is a continuation of arXiv:1405.1707. We present certain new\napplications and generalizations of the free field realization of the twisted\nHeisenberg-Virasoro algebra ${\\mathcal H}$ at level zero.\nWe find explicit formulas for singular vectors in certain Verma modules. A\nfree field realization of self-dual modules for ${\\mathcal H}$ is presented by\ncombining a bosonic construction of Whittaker modules from arXiv:1409.5354 with\na construction of logarithmic modules for vertex algebras. As an application,\nwe prove that there exists a non-split self-extension of irreducible self-dual\nmodule which is a logarithmic module of rank two.\nWe construct a large family of logarithmic modules containing different types\nof highest weight modules as subquotients. We believe that these logarithmic\nmodules are related with projective covers of irreducible modules in a suitable\ncategory of ${\\mathcal H}$-modules.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modular groups, Hurwitz classes and dynamic portraits of NET maps.   An orientation-preserving branched covering $f: S^2 \\to S^2$ is a nearly\nEuclidean Thurston (NET) map if each critical point is simple and its\npostcritical set has exactly four points. Inspired by classical, non-dynamical\nnotions such as Hurwitz equivalence of branched covers of surfaces, we develop\ninvariants for such maps. We then apply these notions to the classification and\nenumeration of NET maps. As an application, we obtain a complete classification\nof the dynamic critical orbit portraits of NET maps.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Observational Diagnostic for Distinguishing Between Clouds and Haze in Hot Exoplanet Atmospheres.   The nature of aerosols in hot exoplanet atmospheres is one of the primary\nvexing questions facing the exoplanet field. The complex chemistry, multiple\nformation pathways, and lack of easily identifiable spectral features\nassociated with aerosols make it especially challenging to constrain their key\nproperties. We propose a transmission spectroscopy technique to identify the\nprimary aerosol formation mechanism for the most highly irradiated hot Jupiters\n(HIHJs). The technique is based on the expectation that the two key types of\naerosols -- photochemically generated hazes and equilibrium condensate clouds\n-- are expected to form and persist in different regions of a highly irradiated\nplanet's atmosphere. Haze can only be produced on the permanent daysides of\ntidally-locked hot Jupiters, and will be carried downwind by atmospheric\ndynamics to the evening terminator (seen as the trailing limb during transit).\nClouds can only form in cooler regions on the night side and morning terminator\nof HIHJs (seen as the leading limb during transit). Because opposite limbs are\nexpected to be impacted by different types of aerosols, ingress and egress\nspectra, which primarily probe opposing sides of the planet, will reveal the\ndominant aerosol formation mechanism. We show that the benchmark HIHJ,\nWASP-121b, has a transmission spectrum consistent with partial aerosol coverage\nand that ingress-egress spectroscopy would constrain the location and formation\nmechanism of those aerosols. In general, using this diagnostic we find that\nobservations with JWST and potentially with HST should be able to distinguish\nbetween clouds and haze for currently known HIHJs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Degenerate and chiral states in the extended Heisenberg model in the kagome lattice.   We present a study of the low temperature phases of the antiferromagnetic\nextended classical Heisenberg model in the kagome lattice, up to third nearest\nneighbors. First, we focus on the degenerate lines in the boundaries of the\nwell-known staggered chiral phases. These boundaries have either semi-extensive\nor extensive degeneracy, and we discuss the partial selection of states by\nthermal fluctuations. Then, we study the model under an external magnetic field\non these lines and in the staggered chiral phases. We pay particular attention\nto the highly frustrated point, where the three exchange couplings are equal.\nWe show that this point can me mapped to a model with spin liquid behavior and\nnon-zero chirality. Finally, we explore the effect of Dzyaloshinskii-Moriya\n(DM) interactions in two ways: an homogeneous and a staggered DM interaction.\nIn both cases, there is a rich low temperature phase diagram, with different\nspontaneously broken symmetries and non trivial chiral phases.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Discrete Integrable Systems, Supersymmetric Quantum Mechanics, and Framed BPS States - I.   It is possible to understand whether a given BPS spectrum is generated by a\nrelevant deformation of a 4D N=2 SCFT or of an asymptotically free theory from\nthe periodicity properties of the corresponding quantum monodromy. With the aim\nof giving a better understanding of the above conjecture, in this paper we\nrevisit the description of framed BPS states of four-dimensional relativistic\nquantum field theories with eight conserved supercharges in terms of\nsupersymmetric quantum mechanics. We unveil aspects of the deep\ninterrelationship in between the Seiberg-dualities of the latter, the discrete\nsymmetries of the theory in the bulk, and quantum discrete integrable systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning Geometric Concepts with Nasty Noise.   We study the efficient learnability of geometric concept classes -\nspecifically, low-degree polynomial threshold functions (PTFs) and\nintersections of halfspaces - when a fraction of the data is adversarially\ncorrupted. We give the first polynomial-time PAC learning algorithms for these\nconcept classes with dimension-independent error guarantees in the presence of\nnasty noise under the Gaussian distribution. In the nasty noise model, an\nomniscient adversary can arbitrarily corrupt a small fraction of both the\nunlabeled data points and their labels. This model generalizes well-studied\nnoise models, including the malicious noise model and the agnostic (adversarial\nlabel noise) model. Prior to our work, the only concept class for which\nefficient malicious learning algorithms were known was the class of\norigin-centered halfspaces.\nSpecifically, our robust learning algorithm for low-degree PTFs succeeds\nunder a number of tame distributions -- including the Gaussian distribution\nand, more generally, any log-concave distribution with (approximately) known\nlow-degree moments. For LTFs under the Gaussian distribution, we give a\npolynomial-time algorithm that achieves error $O(\\epsilon)$, where $\\epsilon$\nis the noise rate. At the core of our PAC learning results is an efficient\nalgorithm to approximate the low-degree Chow-parameters of any bounded function\nin the presence of nasty noise. To achieve this, we employ an iterative\nspectral method for outlier detection and removal, inspired by recent work in\nrobust unsupervised learning. Our aforementioned algorithm succeeds for a range\nof distributions satisfying mild concentration bounds and moment assumptions.\nThe correctness of our robust learning algorithm for intersections of\nhalfspaces makes essential use of a novel robust inverse independence lemma\nthat may be of broader interest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Free quantitative fourth moment theorems on Wigner space.   We prove a quantitative Fourth Moment Theorem for Wigner integrals of any\norder with symmetric kernels, generalizing an earlier result from Kemp et al.\n(2012). The proof relies on free stochastic analysis and uses a new biproduct\nformula for bi-integrals. A consequence of our main result is a\nNualart-Ortiz-Latorre type characterization of convergence in law to the\nsemicircular distribution for Wigner integrals. As an application, we provide\nBerry-Esseen type bounds in the context of the free Breuer-Major theorem for\nthe free fractional Brownian motion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Plane graphs without 4- and 5-cycles and without ext-triangular 7-cycles are 3-colorable.   Listed as No. 53 among the one hundred famous unsolved problems in [J. A.\nBondy, U. S. R. Murty, Graph Theory, Springer, Berlin, 2008] is Steinberg's\nconjecture, which states that every planar graph without 4- and 5-cycles is\n3-colorable. In this paper, we show that plane graphs without 4- and 5-cycles\nare 3-colorable if they have no ext-triangular 7-cycles. This implies that (1)\nplanar graphs without 4-, 5-, 7-cycles are 3-colorable, and (2) planar graphs\nwithout 4-, 5-, 8-cycles are 3-colorable, which cover a number of known results\nin the literature motivated by Steinberg's conjecture.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "GuideR: a guided separate-and-conquer rule learning in classification, regression, and survival settings.   This article presents GuideR, a user-guided rule induction algorithm, which\novercomes the largest limitation of the existing methods-the lack of the\npossibility to introduce user's preferences or domain knowledge to the rule\nlearning process. Automatic selection of attributes and attribute ranges often\nleads to the situation in which resulting rules do not contain interesting\ninformation. We propose an induction algorithm which takes into account user's\nrequirements. Our method uses the sequential covering approach and is suitable\nfor classification, regression, and survival analysis problems. The\neffectiveness of the algorithm in all these tasks has been verified\nexperimentally, confirming guided rule induction to be a powerful data analysis\ntool.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Grassmannian flows and applications to nonlinear partial differential equations.   We show how solutions to a large class of partial differential equations with\nnonlocal Riccati-type nonlinearities can be generated from the corresponding\nlinearized equations, from arbitrary initial data. It is well known that\nevolutionary matrix Riccati equations can be generated by projecting linear\nevolutionary flows on a Stiefel manifold onto a coordinate chart of the\nunderlying Grassmann manifold. Our method relies on extending this idea to the\ninfinite dimensional case. The key is an integral equation analogous to the\nMarchenko equation in integrable systems, that represents the coodinate chart\nmap. We show explicitly how to generate such solutions to scalar partial\ndifferential equations of arbitrary order with nonlocal quadratic\nnonlinearities using our approach. We provide numerical simulations that\ndemonstrate the generation of solutions to\nFisher--Kolmogorov--Petrovskii--Piskunov equations with nonlocal\nnonlinearities. We also indicate how the method might extend to more general\nclasses of nonlinear partial differential systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Spin conductance of YIG thin films driven from thermal to subthermal magnons regime by large spin-orbit torque.   We report a study on spin conductance in ultra-thin films of Yttrium Iron\nGarnet (YIG), where spin transport is provided by propagating spin waves, that\nare generated and detected by direct and inverse spin Hall effects in two Pt\nwires deposited on top. While at low current the spin conductance is dominated\nby transport of thermal magnons, at high current, the spin conductance is\ndominated by low-damping non-equilibrium magnons thermalized near the spectral\nbottom by magnon-magnon interaction, with consequent a sensitivity to the\napplied magnetic field and a longer decay length. This picture is supported by\nmicrofocus Brillouin Light Scattering spectroscopy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Multiscale-Analysis of Stochastic Bistable Reaction-Diffusion Equations.   A multiscale analysis of 1D stochastic bistable reaction-diffusion equations\nwith additive noise is carried out w.r.t. travelling waves within the\nvariational approach to stochastic partial differential equations. It is shown\nwith explicit error estimates on appropriate function spaces that up to lower\norder w.r.t. the noise amplitude, the solution can be decomposed into the\northogonal sum of a travelling wave moving with random speed and into Gaussian\nfluctuations. A stochastic differential equation describing the speed of the\ntravelling wave and a linear stochastic partial differential equation\ndescribing the fluctuations are derived in terms of the coefficients. Our\nresults extend corresponding results obtained for stochastic neural field\nequations to the present class of stochastic dynamics.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Forest-based methods and ensemble model output statistics for rainfall ensemble forecasting.   Rainfall ensemble forecasts have to be skillful for both low precipitation\nand extreme events. We present statistical post-processing methods based on\nQuantile Regression Forests (QRF) and Gradient Forests (GF) with a parametric\nextension for heavy-tailed distributions. Our goal is to improve ensemble\nquality for all types of precipitation events, heavy-tailed included, subject\nto a good overall performance. Our hybrid proposed methods are applied to daily\n51-h forecasts of 6-h accumulated precipitation from 2012 to 2015 over France\nusing the M{é}t{é}o-France ensemble prediction system called PEARP. They\nprovide calibrated pre-dictive distributions and compete favourably with\nstate-of-the-art methods like Analogs method or Ensemble Model Output\nStatistics. In particular, hybrid forest-based procedures appear to bring an\nadded value to the forecast of heavy rainfall.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "United Nations Digital Blue Helmets as a Starting Point for Cyber Peacekeeping.   Prior works, such as the Tallinn manual on the international law applicable\nto cyber warfare, focus on the circumstances of cyber warfare. Many\norganizations are considering how to conduct cyber warfare, but few have\ndiscussed methods to reduce, or even prevent, cyber conflict. A recent series\nof publications started developing the framework of Cyber Peacekeeping (CPK)\nand its legal requirements. These works assessed the current state of\norganizations such as ITU IMPACT, NATO CCDCOE and Shanghai Cooperation\nOrganization, and found that they did not satisfy requirements to effectively\nhost CPK activities. An assessment of organizations currently working in the\nareas related to CPK found that the United Nations (UN) has mandates and\norganizational structures that appear to somewhat overlap the needs of CPK.\nHowever, the UN's current approach to Peacekeeping cannot be directly mapped to\ncyberspace. In this research we analyze the development of traditional\nPeacekeeping in the United Nations, and current initiatives in cyberspace.\nSpecifically, we will compare the proposed CPK framework with the recent\ninitiative of the United Nations named the 'Digital Blue Helmets' as well as\nwith other projects in the UN which helps to predict and mitigate conflicts.\nOur goal is to find practical recommendations for the implementation of the CPK\nframework in the United Nations, and to examine how responsibilities defined in\nthe CPK framework overlap with those of the 'Digital Blue Helmets' and the\nGlobal Pulse program.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Submodularity-Based Approach for Multi-Agent Optimal Coverage Problems.   We consider the optimal coverage problem where a multi-agent network is\ndeployed in an environment with obstacles to maximize a joint event detection\nprobability. The objective function of this problem is non-convex and no global\noptimum is guaranteed by gradient-based algorithms developed to date. We first\nshow that the objective function is monotone submodular, a class of functions\nfor which a simple greedy algorithm is known to be within 0.63 of the optimal\nsolution. We then derive two tighter lower bounds by exploiting the curvature\ninformation (total curvature and elemental curvature) of the objective\nfunction. We further show that the tightness of these lower bounds is\ncomplementary with respect to the sensing capabilities of the agents. The\ngreedy algorithm solution can be subsequently used as an initial point for a\ngradient-based algorithm to obtain solutions even closer to the global optimum.\nSimulation results show that this approach leads to significantly better\nperformance relative to previously used algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The finiteness dimension of modules and relative Cohen-Macaulayness.   Let $R$ be a commutative Noetherian ring, $\\mathfrak a$ and $\\mathfrak b$\nideals of $R$. In this paper, we study the finiteness dimension $f_{\\mathfrak\na}(M)$ of $M$ relative to $\\mathfrak a$ and the $\\mathfrak b$-minimum\n$\\mathfrak a$-adjusted depth $\\lambda_{\\mathfrak a}^{\\mathfrak b}(M)$ of $M$,\nwhere the underlying module $M$ is relative Cohen-Macaulay w.r.t $\\mathfrak a$.\nSome applications of such modules are given.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Riemannian Gaussian distributions on the space of positive-definite quaternion matrices.   Recently, Riemannian Gaussian distributions were defined on spaces of\npositive-definite real and complex matrices. The present paper extends this\ndefinition to the space of positive-definite quaternion matrices. In order to\ndo so, it develops the Riemannian geometry of the space of positive-definite\nquaternion matrices, which is shown to be a Riemannian symmetric space of\nnon-positive curvature. The paper gives original formulae for the Riemannian\nmetric of this space, its geodesics, and distance function. Then, it develops\nthe theory of Riemannian Gaussian distributions, including the exact expression\nof their probability density, their sampling algorithm and statistical\ninference.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Attribution of extreme rainfall in Southeast China during May 2015.   Anthropogenic climate change increased the probability that a short-duration,\nintense rainfall event would occur in parts of southeast China. This type of\nevent occurred in May 2015, causing serious flooding.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Topological Kondo insulators in one dimension: Continuous Haldane-type ground-state evolution from the strongly-interacting to the non-interacting limit.   We study, by means of the density-matrix renormalization group (DMRG)\ntechnique, the evolution of the ground state in a one-dimensional topological\ninsulator, from the non-interacting to the strongly-interacting limit, where\nthe system can be mapped onto a topological Kondo-insulator model. We focus on\na toy model Hamiltonian (i.e., the interacting \"$sp$-ladder\" model), which\ncould be experimentally realized in optical lattices with higher orbitals\nloaded with ultra-cold fermionic atoms. Our goal is to shed light on the\nemergence of the strongly-interacting ground state and its topological\nclassification as the Hubbard-$U$ interaction parameter of the model is\nincreased. Our numerical results show that the ground state can be generically\nclassified as a symmetry-protected topological phase of the Haldane-type, even\nin the non-interacting case $U=0$ where the system can be additionally\nclassified as a time-reversal $\\mathbb{Z}_{2}$-topological insulator, and\nevolves adiabatically between the non-interacting and strongly interacting\nlimits.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Binarized octree generation for Cartesian adaptive mesh refinement around immersed geometries.   We revisit the generation of balanced octrees for adaptive mesh refinement\n(AMR) of Cartesian domains with immersed complex geometries. In a recent short\nnote [Hasbestan and Senocak, J. Comput. Phys. vol. 351:473-477 (2017)], we\nshowed that the data-locality of the Z-order curve in hashed linear octree\ngeneration methods may not be perfect because of potential collisions in the\nhash table. Building on that observation, we propose a binarized octree\ngeneration method that complies with the Z-order curve exactly. Similar to a\nhashed linear octree generation method, we use Morton encoding to index the\nnodes of an octree, but use a red-black tree in place of the hash table.\nRed-black tree is a special kind of a binary tree, which we use for insertion\nand deletion of elements during mesh adaptation. By strictly working with the\nbitwise representation of the octree, we remove computer hardware limitations\non the depth of adaptation on a single processor. Additionally, we introduce a\ngeometry encoding technique for rapidly tagging the solid geometry for\nrefinement. Our results for several geometries with different levels of\nadaptations show that the binarized octree generation outperforms the linear\noctree generation in terms of runtime performance at the expense of only a\nslight increase in memory usage. We provide the current AMR capability as\nopen-source software.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Supercharacters and the discrete Fourier, cosine, and sine transforms.   Using supercharacter theory, we identify the matrices that are diagonalized\nby the discrete cosine and discrete sine transforms, respectively. Our method\naffords a combinatorial interpretation for the matrix entries.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Advanced Steel Microstructural Classification by Deep Learning Methods.   The inner structure of a material is called microstructure. It stores the\ngenesis of a material and determines all its physical and chemical properties.\nWhile microstructural characterization is widely spread and well known, the\nmicrostructural classification is mostly done manually by human experts, which\ngives rise to uncertainties due to subjectivity. Since the microstructure could\nbe a combination of different phases or constituents with complex substructures\nits automatic classification is very challenging and only a few prior studies\nexist. Prior works focused on designed and engineered features by experts and\nclassified microstructures separately from the feature extraction step.\nRecently, Deep Learning methods have shown strong performance in vision\napplications by learning the features from data together with the\nclassification step. In this work, we propose a Deep Learning method for\nmicrostructural classification in the examples of certain microstructural\nconstituents of low carbon steel. This novel method employs pixel-wise\nsegmentation via Fully Convolutional Neural Networks (FCNN) accompanied by a\nmax-voting scheme. Our system achieves 93.94% classification accuracy,\ndrastically outperforming the state-of-the-art method of 48.89% accuracy.\nBeyond the strong performance of our method, this line of research offers a\nmore robust and first of all objective way for the difficult task of steel\nquality appreciation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Angle-dependent electron spin resonance of YbRh$_2$Si$_2$ measured with planar microwave resonators and in-situ rotation.   We present a new experimental approach to investigate the magnetic properties\nof the anisotropic heavy-fermion system YbRh$_2$Si$_2$ as a function of\ncrystallographic orientation. Angle-dependent electron spin resonance (ESR)\nmeasurements are performed at a low temperature of 1.6 K and at an ESR\nfrequency of 4.4 GHz utilizing a superconducting planar microwave resonator in\na $^4$He-cryostat in combination with in-situ sample rotation. The obtained ESR\ng-factor of YbRh$_2$Si$_2$ as a function of the crystallographic angle is\nconsistent with results of previous measurements using conventional ESR\nspectrometers at higher frequencies and fields. Perspectives to implement this\nexperimental approach into a dilution refrigerator and to reach the\nmagnetically ordered phase of YbRh$_2$Si$_2$ are discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Surface plasmons in superintense laser-solid interactions.   We review studies of superintense laser interaction with solid targets where\nthe generation of propagating surface plasmons (or surface waves) plays a key\nrole. These studies include the onset of plasma instabilities at the irradiated\nsurface, the enhancement of secondary emissions (protons, electrons, and\nphotons as high harmonics in the XUV range) in femtosecond interactions with\ngrating targets, and the generation of unipolar current pulses with picosecond\nduration. The experimental results give evidence of the existence of surface\nplasmons in the nonlinear regime of relativistic electron dynamics. These\nfindings open up a route to the improvement of ultrashort laser-driven sources\nof energetic radiation and, more in general, to the extension of plasmonics in\na high field regime.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Two types of criticality in the brain.   Neural networks with equal excitatory and inhibitory feedback show high\ncomputational performance. They operate close to a critical point characterized\nby the joint activation of large populations of neurons. Yet, in macaque motor\ncortex we observe very different dynamics with weak fluctuations on the\npopulation level. This suggests that motor cortex operates in a sub-optimal\nregime. Here we show the opposite: the large dispersion of correlations across\nneurons is a signature of a rich dynamical repertoire, hidden from macroscopic\nbrain signals, but essential for high performance in such concepts as reservoir\ncomputing. Our findings suggest a refinement of the view on criticality in\nneural systems: network topology and heterogeneity endow the brain with two\ncomplementary substrates for critical dynamics of largely different\ncomplexities.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "FORM version 4.2.   We introduce FORM 4.2, a new minor release of the symbolic manipulation\ntoolkit. We demonstrate several new features, such as a new pattern matching\noption, new output optimization, and automatic expansion of rational functions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sparse Bounds for Discrete Quadratic Phase Hilbert Transform.   Consider the discrete quadratic phase Hilbert Transform acting on $\\ell^{2}$\nfinitely supported functions $$ H^{\\alpha} f(n) : = \\sum_{m \\neq 0} \\frac{e^{2\n\\pi i\\alpha m^2} f(n - m)}{m}. $$ We prove that, uniformly in $\\alpha \\in\n\\mathbb{T}$, there is a sparse bound for the bilinear form $\\langle H^{\\alpha}\nf , g \\rangle$. The sparse bound implies several mapping properties such as\nweighted inequalities in an intersection of Muckenhoupt and reverse Hölder\nclasses.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiband NFC for High-Throughput Wireless Computer Vision Sensor Network.   Vision sensors lie in the heart of computer vision. In many computer vision\napplications, such as AR/VR, non-contacting near-field communication (NFC) with\nhigh throughput is required to transfer information to algorithms. In this\nwork, we proposed a novel NFC system which utilizes multiple frequency bands to\nachieve high throughput.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Incompressible fillings of manifolds.   We find boundaries of Borel-Serre compactifications of locally symmetric\nspaces, for which any filling is incompressible. We prove this result by\nshowing that these boundaries have small singular models and using these models\nto obstruct compressions. We also show that small singular models of boundaries\nobstruct $S^1$-actions (and more generally homotopically trivial $\\mathbb\nZ/p$-actions) on interiors of aspherical fillings. We use this to bound the\nsymmetry of complete Riemannian metrics on such interiors in terms of the\nfundamental group. We also use small singular models to simplify the proofs of\nsome already known theorems about moduli spaces (the minimal orbifold theorem\nand a topological analogue of Royden's theorem).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Metric Reduction and Generalized Holomorphic Structures.   In this paper, metric reduction in generalized geometry is investigated. We\nshow how the Bismut connections on the quotient manifold are obtained from\nthose on the original manifold. The result facilitates the analysis of\ngeneralized K$\\ddot{a}$hler reduction, which motivates the concept of metric\ngeneralized principal bundles and our approach to construct a family of\ngeneralized holomorphic line bundles over $\\mathbb{C}P^2$ equipped with some\nnon-trivial generalized K$\\ddot{a}$hler structures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Method for Aspect-Based Sentiment Annotation Using Rhetorical Analysis.   This paper fills a gap in aspect-based sentiment analysis and aims to present\na new method for preparing and analysing texts concerning opinion and\ngenerating user-friendly descriptive reports in natural language. We present a\ncomprehensive set of techniques derived from Rhetorical Structure Theory and\nsentiment analysis to extract aspects from textual opinions and then build an\nabstractive summary of a set of opinions. Moreover, we propose aspect-aspect\ngraphs to evaluate the importance of aspects and to filter out unimportant ones\nfrom the summary. Additionally, the paper presents a prototype solution of data\nflow with interesting and valuable results. The proposed method's results\nproved the high accuracy of aspect detection when applied to the gold standard\ndataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "High-field transport properties of a P-doped BaFe2As2 film on technical substrate.   High temperature (high-Tc) superconductors like cuprates have superior\ncritical current properties in magnetic fields over other superconductors.\nHowever, superconducting wires for high-field-magnet applications are still\ndominated by low-Tc Nb3Sn due probably to cost and processing issues. The\nrecent discovery of a second class of high-Tc materials, Fe-based\nsuperconductors, may provide another option for high-field-magnet wires. In\nparticular, AEFe2As2 (AE: Alkali earth elements, AE-122) is one of the best\ncandidates for high-field-magnet applications because of its high upper\ncritical field, Hc2, moderate Hc2 anisotropy, and intermediate Tc. Here we\nreport on in-field transport properties of P-doped BaFe2As2 (Ba-122) thin films\ngrown on technical substrates (i.e., biaxially textured oxides templates on\nmetal tapes) by pulsed laser deposition. The P-doped Ba-122 coated conductor\nsample exceeds a transport Jc of 10^5 A/cm^2 at 15 T for both major\ncrystallographic directions of the applied magnetic field, which is favourable\nfor practical applications. Our P-doped Ba-122 coated conductors show a\nsuperior in-field Jc over MgB2 and NbTi, and a comparable level to Nb3Sn above\n20 T. By analysing the E-J curves for determining Jc, a non-Ohmic linear\ndifferential signature is observed at low field due to flux flow along the\ngrain boundaries. However, grain boundaries work as flux pinning centres as\ndemonstrated by the pinning force analysis.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Remarkably strong chemisorption of nitric oxide on insulating oxide films promoted by hybrid structure.   The remarkably strong chemical adsorption behaviors of nitric oxide on\nmagnesia (001) film deposited on metal substrate have been investigated by\nemploying periodic density functional calculations with Van der Waals\ncorrections. The molybdenum supported magnesia (001) show significantly\nenhanced adsorption properties and the nitric oxide is chemisorbed strongly and\npreferably trapped in flat adsorption configuration on metal supported oxide\nfilm, due to the substantially large adsorption energies and transformation\nbarriers. The analysis of Bader charges, projected density of states,\ndifferential charge densities, electron localization function, highest occupied\norbital and particular orbital with largest Mg-NO-Mg bonding coefficients, are\napplied to reveal the electronic adsorption properties and characteristics of\nbonding between nitric oxide and surface as well as the bonding within the\nhybrid structure. The strong chemical binding of nitric oxide on magnesia\ndeposited on molybdenum slab offers new opportunities for toxic gas detection\nand treatment. We anticipate that hybrid structure promoted remarkable chemical\nadsorption of nitric oxide on magnesia in this study will provide versatile\nstrategy for enhancing chemical reactivity and properties of insulating oxide.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Scaling of the Detonation Product State with Reactant Kinetic Energy.   This submissions has been withdrawn by arXiv administrators because the\nsubmitter did not have the right to agree to our license.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Effects of a Price limit Change on Market Stability at the Intraday Horizon in the Korean Stock Market.   This paper investigates the effects of a price limit change on the volatility\nof the Korean stock market's (KRX) intraday stock price process. Based on the\nmost recent transaction data from the KRX, which experienced a change in the\nprice limit on June 15, 2015, we examine the change in realized variance after\nthe price limit change to investigate the overall effects of the change on the\nintraday market volatility. We then analyze the effects in more detail by\napplying the discrete Fourier transform (DFT) to the data set. We find evidence\nthat the market becomes more volatile in the intraday horizon because of the\nincrease in the amplitudes of the low-frequency components of the price\nprocesses after the price limit change. Therefore, liquidity providers are in a\nworse situation than they were prior to the change.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adjusting systematic bias in high dimensional principal component scores.   Principal component analysis continues to be a powerful tool in dimension\nreduction of high dimensional data. We assume a variance-diverging model and\nuse the high-dimension, low-sample-size asymptotics to show that even though\nthe principal component directions are not consistent, the sample and\nprediction principal component scores can be useful in revealing the population\nstructure. We further show that these scores are biased, and the bias is\nasymptotically decomposed into rotation and scaling parts. We propose methods\nof bias-adjustment that are shown to be consistent and work well in the finite\nbut high dimensional situations with small sample sizes. The potential\nadvantage of bias-adjustment is demonstrated in a classification setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Heterogeneous Supervision for Relation Extraction: A Representation Learning Approach.   Relation extraction is a fundamental task in information extraction. Most\nexisting methods have heavy reliance on annotations labeled by human experts,\nwhich are costly and time-consuming. To overcome this drawback, we propose a\nnovel framework, REHession, to conduct relation extractor learning using\nannotations from heterogeneous information source, e.g., knowledge base and\ndomain heuristics. These annotations, referred as heterogeneous supervision,\noften conflict with each other, which brings a new challenge to the original\nrelation extraction task: how to infer the true label from noisy labels for a\ngiven instance. Identifying context information as the backbone of both\nrelation extraction and true label discovery, we adopt embedding techniques to\nlearn the distributed representations of context, which bridges all components\nwith mutual enhancement in an iterative fashion. Extensive experimental results\ndemonstrate the superiority of REHession over the state-of-the-art.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cusp shape and tunnel number.   We show that the set of cusp shapes of hyperbolic tunnel number one manifolds\nis dense in the Teichmuller space of the torus. A similar result holds for\ntunnel number n manifolds. As a consequence, for fixed n, there are infinitely\nmany hyperbolic tunnel number n manifolds with at most one exceptional Dehn\nfilling. This is in contrast to large volume Berge knots, which are tunnel\nnumber one manifolds, but with cusp shapes converging to a single point in\nTeichmuller space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Derivation of a multilayer approach to model suspended sediment transport: application to hyperpycnal and hypopycnal plumes.   We propose a multi-layer approach to simulate hyperpycnal and hypopycnal\nplumes in flows with free surface. The model allows to compute the vertical\nprofile of the horizontal and the vertical components of the velocity of the\nfluid flow. The model can describe as well the vertical profile of the sediment\nconcentration and the velocity components of each one of the sediment species\nthat form the turbidity current. To do so, it takes into account the settling\nvelocity of the particles and their interaction with the fluid. This allows to\nbetter describe the phenomena than a single layer approach. It is in better\nagreement with the physics of the problem and gives promising results. The\nnumerical simulation is carried out by rewriting the multi-layer approach in a\ncompact formulation, which corresponds to a system with non-conservative\nproducts, and using path-conservative numerical scheme. Numerical results are\npresented in order to show the potential of the model.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Survey on QoE-oriented Wireless Resources Scheduling.   Future wireless systems are expected to provide a wide range of services to\nmore and more users. Advanced scheduling strategies thus arise not only to\nperform efficient radio resource management, but also to provide fairness among\nthe users. On the other hand, the users' perceived quality, i.e., Quality of\nExperience (QoE), is becoming one of the main drivers within the schedulers\ndesign. In this context, this paper starts by providing a comprehension of what\nis QoE and an overview of the evolution of wireless scheduling techniques.\nAfterwards, a survey on the most recent QoE-based scheduling strategies for\nwireless systems is presented, highlighting the application/service of the\ndifferent approaches reported in the literature, as well as the parameters that\nwere taken into account for QoE optimization. Therefore, this paper aims at\nhelping readers interested in learning the basic concepts of QoE-oriented\nwireless resources scheduling, as well as getting in touch with the present\ntime research frontier.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Three hypergraph eigenvector centralities.   Eigenvector centrality is a standard network analysis tool for determining\nthe importance of (or ranking of) entities in a connected system that is\nrepresented by a graph. However, many complex systems and datasets have natural\nmulti-way interactions that are more faithfully modeled by a hypergraph. Here\nwe extend the notion of graph eigenvector centrality to uniform hypergraphs.\nTraditional graph eigenvector centralities are given by a positive eigenvector\nof the adjacency matrix, which is guaranteed to exist by the Perron-Frobenius\ntheorem under some mild conditions. The natural representation of a hypergraph\nis a hypermatrix (colloquially, a tensor). Using recently established\nPerron-Frobenius theory for tensors, we develop three tensor eigenvectors\ncentralities for hypergraphs, each with different interpretations. We show that\nthese centralities can reveal different information on real-world data by\nanalyzing hypergraphs constructed from n-gram frequencies, co-tagging on stack\nexchange, and drug combinations observed in patient emergency room visits.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "CTCF Degradation Causes Increased Usage of Upstream Exons in Mouse Embryonic Stem Cells.   Transcriptional repressor CTCF is an important regulator of chromatin 3D\nstructure, facilitating the formation of topologically associating domains\n(TADs). However, its direct effects on gene regulation is less well understood.\nHere, we utilize previously published ChIP-seq and RNA-seq data to investigate\nthe effects of CTCF on alternative splicing of genes with CTCF sites. We\ncompared the amount of RNA-seq signals in exons upstream and downstream of\nbinding sites following auxin-induced degradation of CTCF in mouse embryonic\nstem cells. We found that changes in gene expression following CTCF depletion\nwere significant, with a general increase in the presence of upstream exons. We\ninfer that a possible mechanism by which CTCF binding contributes to\nalternative splicing is by causing pauses in the transcription mechanism during\nwhich splicing elements are able to concurrently act on upstream exons already\ntranscribed into RNA.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Truncation in Hahn Fields is Undecidable and Wild.   We show that in any nontrivial Hahn field with truncation as a primitive\noperation we can interpret the monadic second-order logic of the additive\nmonoid of natural numbers and are thus undecidable. We also specify a definable\nbinary relation on such a structure that has $\\SOP$ and $\\TP$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Autocorrelation and Lower Bound on the 2-Adic Complexity of LSB Sequence of $p$-ary $m$-Sequence.   In modern stream cipher, there are many algorithms, such as ZUC, LTE\nencryption algorithm and LTE integrity algorithm, using bit-component sequences\nof $p$-ary $m$-sequences as the input of the algorithm. Therefore, analyzing\ntheir statistical property (For example, autocorrelation, linear complexity and\n2-adic complexity) of bit-component sequences of $p$-ary $m$-sequences is\nbecoming an important research topic. In this paper, we first derive some\nautocorrelation properties of LSB (Least Significant Bit) sequences of $p$-ary\n$m$-sequences, i.e., we convert the problem of computing autocorrelations of\nLSB sequences of period $p^n-1$ for any positive $n\\geq2$ to the problem of\ndetermining autocorrelations of LSB sequence of period $p-1$. Then, based on\nthis property and computer calculation, we list some autocorrelation\ndistributions of LSB sequences of $p$-ary $m$-sequences with order $n$ for some\nsmall primes $p$'s, such as $p=3,5,7,11,17,31$. Additionally, using their\nautocorrelation distributions and the method inspired by Hu, we give the lower\nbounds on the 2-adic complexities of these LSB sequences. Our results show that\nthe main parts of all the lower bounds on the 2-adic complexity of these LSB\nsequencesare larger than $\\frac{N}{2}$, where $N$ is the period of these\nsequences. Therefor, these bounds are large enough to resist the analysis of\nRAA (Rational Approximation Algorithm) for FCSR (Feedback with Carry Shift\nRegister). Especially, for a Mersenne prime $p=2^k-1$, since all its\nbit-component sequences of a $p$-ary $m$-sequence are shift equivalent, our\nresults hold for all its bit-component sequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robbins-Monro conditions for persistent exploration learning strategies.   We formulate simple assumptions, implying the Robbins-Monro conditions for\nthe $Q$-learning algorithm with the local learning rate, depending on the\nnumber of visits of a particular state-action pair (local clock) and the number\nof iteration (global clock). It is assumed that the Markov decision process is\ncommunicating and the learning policy ensures the persistent exploration. The\nrestrictions are imposed on the functional dependence of the learning rate on\nthe local and global clocks. The result partially confirms the conjecture of\nBradkte (1994).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A two-layer shallow water model for bedload sediment transport: convergence to Saint-Venant-Exner model.   A two-layer shallow water type model is proposed to describe bedload sediment\ntransport. The upper layer is filled by water and the lower one by sediment.\nThe key point falls on the definition of the friction laws between the two\nlayers, which are a generalization of those introduced in Fernández-Nieto et\nal. (ESAIM: M2AN, 51:115-145, 2017). This definition allows to apply properly\nthe two-layer shallow water model for the case of intense and slow bedload\nsediment transport. Moreover, we prove that the two-layer model converges to a\nSaint-Venant-Exner system (SVE) including gravitational effects when the ratio\nbetween the hydrodynamic and morphodynamic time scales is small. The SVE with\ngravitational effects is a degenerated nonlinear parabolic system. This means\nthat its numerical approximation is very expensive from a computational point\nof view, see for example T. Morales de Luna et al. (J. Sci. Comp., 48(1):\n258-273, 2011). In this work, gravitational effects are introduced into the\ntwo-layer system without such extra computational cost. Finally, we also\nconsider a generalization of the model that includes a non-hydrostatic pressure\ncorrection for the fluid layer and the boundary condition at the sediment\nsurface. Numerical tests show that the model provides promising results and\nbehave well in low transport rate regimes as well as in many other situations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Uncertainty quantification in graph-based classification of high dimensional data.   Classification of high dimensional data finds wide-ranging applications. In\nmany of these applications equipping the resulting classification with a\nmeasure of uncertainty may be as important as the classification itself. In\nthis paper we introduce, develop algorithms for, and investigate the properties\nof, a variety of Bayesian models for the task of binary classification; via the\nposterior distribution on the classification labels, these methods\nautomatically give measures of uncertainty. The methods are all based around\nthe graph formulation of semi-supervised learning.\nWe provide a unified framework which brings together a variety of methods\nwhich have been introduced in different communities within the mathematical\nsciences. We study probit classification in the graph-based setting, generalize\nthe level-set method for Bayesian inverse problems to the classification\nsetting, and generalize the Ginzburg-Landau optimization-based classifier to a\nBayesian setting; we also show that the probit and level set approaches are\nnatural relaxations of the harmonic function approach introduced in [Zhu et al\n2003].\nWe introduce efficient numerical methods, suited to large data-sets, for both\nMCMC-based sampling as well as gradient-based MAP estimation. Through numerical\nexperiments we study classification accuracy and uncertainty quantification for\nour models; these experiments showcase a suite of datasets commonly used to\nevaluate graph-based semi-supervised learning algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Pool-based Active Learning With Abstention Feedbacks.   We study pool-based active learning with abstention feedbacks, where a\nlabeler can abstain from labeling a queried example with some unknown\nabstention rate. This is an important problem with many useful applications. We\ntake a Bayesian approach to the problem and develop two new greedy algorithms\nthat learn both the classification problem and the unknown abstention rate at\nthe same time. These are achieved by simply incorporating the estimated\nabstention rate into the greedy criteria. We prove that both of our algorithms\nhave near-optimality guarantees: they respectively achieve a\n${(1-\\frac{1}{e})}$ constant factor approximation of the optimal expected or\nworst-case value of a useful utility function. Our experiments show the\nalgorithms perform well in various practical scenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Logical Approach to Cloud Federation.   Federated clouds raise a variety of challenges for managing identity,\nresource access, naming, connectivity, and object access control. This paper\nshows how to address these challenges in a comprehensive and uniform way using\na data-centric approach. The foundation of our approach is a trust logic in\nwhich participants issue authenticated statements about principals, objects,\nattributes, and relationships in a logic language, with reasoning based on\ndeclarative policy rules. We show how to use the logic to implement a trust\ninfrastructure for cloud federation that extends the model of NSF GENI, a\nfederated IaaS testbed. It captures shared identity management, GENI authority\nservices, cross-site interconnection using L2 circuits, and a naming and access\ncontrol system similar to AWS Identity and Access Management (IAM), but\nextended to a federated system without central control.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cyclic Hypergraph Degree Sequences.   The problem of efficiently characterizing degree sequences of simple\nhypergraphs is a fundamental long-standing open problem in Graph Theory.\nSeveral results are known for restricted versions of this problem. This paper\nadds to the list of sufficient conditions for a degree sequence to be {\\em\nhypergraphic}. This paper proves a combinatorial lemma about cyclically\npermuting the columns of a binary table with length $n$ binary sequences as\nrows. We prove that for any set of cyclic permutations acting on its columns,\nthe resulting table has all of its $2^n$ rows distinct. Using this property, we\nfirst define a subset {\\em cyclic hyper degrees} of hypergraphic sequences and\nshow that they admit a polynomial time recognition algorithm. Next, we prove\nthat there are at least $2^{\\frac{(n-1)(n-2)}{2}}$ {\\em cyclic hyper degrees},\nwhich also serves as a lower bound on the number of {\\em hypergraphic}\nsequences. The {\\em cyclic hyper degrees} also enjoy a structural\ncharacterization, they are the integral points contained in the union of some\n$n$-dimensional rectangles.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Amorphous Alloys, Degradation Performance of Azo Dyes: Review.   Today freshwater is more important than ever before and it is contaminated\nfrom textile industry. Removal of dyes from effluent of textile using amorphous\nalloys has been studied extensively by many researchers. In this review article\nit is presented up to date development on the azo dye degradation performance\nof amorphous alloys, a new class of catalytic materials. Numerous amorphous\nalloys have been developed for increasing higher degradation efficiency in\ncomparison to conventional ones for the removal of azo dyes in wastewater. One\nof the objectives of this review article is to organize the scattered available\ninformation on various aspects on a wide range of potentially effective in the\nremoval of dyes by using amorphous alloys. This study comprises the affective\nremoval factors of azo dye such as solution pH, initial dye concentration, and\nadsorbent dosage. It was concluded that Fe, Mg, Co, Al and Mn-based amorphous\nalloys with wide availability have appreciable for removing several types of\nazo dyes from wastewater. Concerning amorphous alloys for future research, some\nsuggestions are proposed and conclusions have been drawn.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Topic Modeling on Health Journals with Regularized Variational Inference.   Topic modeling enables exploration and compact representation of a corpus.\nThe CaringBridge (CB) dataset is a massive collection of journals written by\npatients and caregivers during a health crisis. Topic modeling on the CB\ndataset, however, is challenging due to the asynchronous nature of multiple\nauthors writing about their health journeys. To overcome this challenge we\nintroduce the Dynamic Author-Persona topic model (DAP), a probabilistic\ngraphical model designed for temporal corpora with multiple authors. The\nnovelty of the DAP model lies in its representation of authors by a persona ---\nwhere personas capture the propensity to write about certain topics over time.\nFurther, we present a regularized variational inference algorithm, which we use\nto encourage the DAP model's personas to be distinct. Our results show\nsignificant improvements over competing topic models --- particularly after\nregularization, and highlight the DAP model's unique ability to capture common\njourneys shared by different authors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unsupervised Learning by Predicting Noise.   Convolutional neural networks provide visual features that perform remarkably\nwell in many computer vision applications. However, training these networks\nrequires significant amounts of supervision. This paper introduces a generic\nframework to train deep networks, end-to-end, with no supervision. We propose\nto fix a set of target representations, called Noise As Targets (NAT), and to\nconstrain the deep features to align to them. This domain agnostic approach\navoids the standard unsupervised learning issues of trivial solutions and\ncollapsing of features. Thanks to a stochastic batch reassignment strategy and\na separable square loss function, it scales to millions of images. The proposed\napproach produces representations that perform on par with state-of-the-art\nunsupervised methods on ImageNet and Pascal VOC.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Regularity of symbolic powers and Arboricity of matroids.   Let $\\Delta$ be a simplicial complex of a matroid $M$. In this paper, we\nexplicitly compute the regularity of all the symbolic powers of a\nStanley-Reisner ideal $I_\\Delta$ in terms of combinatorial data of the matroid\n$M$. In order to do that, we provide a sharp bound between the arboricity of\n$M$ and the circumference of its dual $M^*$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Type-II Dirac Photons.   The Dirac equation for relativistic electron waves is the parent model for\nWeyl and Majorana fermions as well as topological insulators. Simulation of\nDirac physics in three-dimensional photonic crystals, though fundamentally\nimportant for topological phenomena at optical frequencies, encounters the\nchallenge of synthesis of both Kramers double degeneracy and parity inversion.\nHere we show how type-II Dirac points---exotic Dirac relativistic waves yet to\nbe discovered---are robustly realized through the nonsymmorphic screw symmetry.\nThe emergent type-II Dirac points carry nontrivial topology and are the mother\nstates of type-II Weyl points. The proposed all-dielectric architecture enables\nrobust cavity states at photonic-crystal---air interfaces and anomalous\nrefraction, with very low energy dissipation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Unveiling Eilenberg-type Correspondences: Birkhoff's Theorem for (finite) Algebras + Duality.   The purpose of the present paper is to show that: Eilenberg-type\ncorrespondences = Birkhoff's theorem for (finite) algebras + duality. We\nconsider algebras for a monad T on a category D and we study (pseudo)varieties\nof T-algebras. Pseudovarieties of algebras are also known in the literature as\nvarieties of finite algebras. Two well-known theorems that characterize\nvarieties and pseudovarieties of algebras play an important role here:\nBirkhoff's theorem and Birkhoff's theorem for finite algebras, the latter also\nknown as Reiterman's theorem. We prove, under mild assumptions, a categorical\nversion of Birkhoff's theorem for (finite) algebras to establish a one-to-one\ncorrespondence between (pseudo)varieties of T-algebras and (pseudo)equational\nT-theories. Now, if C is a category that is dual to D and B is the comonad on C\nthat is the dual of T, we get a one-to-one correspondence between\n(pseudo)equational T-theories and their dual, (pseudo)coequational B-theories.\nParticular instances of (pseudo)coequational B-theories have been already\nstudied in language theory under the name of \"varieties of languages\" to\nestablish Eilenberg-type correspondences. All in all, we get a one-to-one\ncorrespondence between (pseudo)varieties of T-algebras and (pseudo)coequational\nB-theories, which will be shown to be exactly the nature of Eilenberg-type\ncorrespondences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Molecular Structures of Local Arm and Perseus Arm in the Galactic Region of l=[139.75,149.75]$^\\circ$, b=[-5.25,5.25]$^\\circ$.   Using the Purple Mountain Observatory Delingha (PMODLH) 13.7 m telescope, we\nreport a 96-square-degree 12CO/13CO/C18O mapping observation toward the\nGalactic region of l = [139.75, 149.75]$^\\circ$, b = [-5.25, 5.25]$^\\circ$. The\nmolecular structure of the Local Arm and Perseus Arm are presented. Combining\nHI data and part of the Outer Arm results, we obtain that the warp structure of\nboth atomic and molecular gas is obvious, while the flare structure only exists\nin atomic gas in this observing region. In addition, five filamentary giant\nmolecular clouds on the Perseus Arm are identified. Among them, four are newly\nidentified. Their relations with the Milky Way large-scale structure are\ndiscussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Continuous Relaxations for the Traveling Salesman Problem.   In this work, we aim to explore connections between dynamical systems\ntechniques and combinatorial optimization problems. In particular, we construct\nheuristic approaches for the traveling salesman problem (TSP) based on\nembedding the relaxed discrete optimization problem into appropriate manifolds.\nWe explore multiple embedding techniques -- namely, the construction of new\ndynamical systems on the manifold of orthogonal matrices and associated\nProcrustes approximations of the TSP cost function. Using these dynamical\nsystems, we analyze the local neighborhood around the optimal TSP solutions\n(which are equilibria) using computations to approximate the associated\n\\emph{stable manifolds}. We find that these flows frequently converge to\nundesirable equilibria. However, the solutions of the dynamical systems and the\nassociated Procrustes approximation provide an interesting biasing approach for\nthe popular Lin--Kernighan heuristic which yields fast convergence. The\nLin--Kernighan heuristic is typically based on the computation of edges that\nhave a `high probability' of being in the shortest tour, thereby effectively\npruning the search space. Our new approach, instead, relies on a natural\nrelaxation of the combinatorial optimization problem to the manifold of\northogonal matrices and the subsequent use of this solution to bias the\nLin--Kernighan heuristic. Although the initial cost of computing these edges\nusing the Procrustes solution is higher than existing methods, we find that the\nProcrustes solution, when coupled with a homotopy computation, contains\nvaluable information regarding the optimal edges. We explore the Procrustes\nbased approach on several TSP instances and find that our approach often\nrequires fewer $k$-opt moves than existing approaches. Broadly, we hope that\nthis work initiates more work in the intersection of dynamical systems theory\nand combinatorial optimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Balancing Selection Pressures, Multiple Objectives, and Neural Modularity to Coevolve Cooperative Agent Behavior.   Previous research using evolutionary computation in Multi-Agent Systems\nindicates that assigning fitness based on team vs.\\ individual behavior has a\nstrong impact on the ability of evolved teams of artificial agents to exhibit\nteamwork in challenging tasks. However, such research only made use of\nsingle-objective evolution. In contrast, when a multiobjective evolutionary\nalgorithm is used, populations can be subject to individual-level objectives,\nteam-level objectives, or combinations of the two. This paper explores the\nperformance of cooperatively coevolved teams of agents controlled by artificial\nneural networks subject to these types of objectives. Specifically, predator\nagents are evolved to capture scripted prey agents in a torus-shaped grid\nworld. Because of the tension between individual and team behaviors, multiple\nmodes of behavior can be useful, and thus the effect of modular neural networks\nis also explored. Results demonstrate that fitness rewarding individual\nbehavior is superior to fitness rewarding team behavior, despite being applied\nto a cooperative task. However, the use of networks with multiple modules\nallows predators to discover intelligent behavior, regardless of which type of\nobjectives are used.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the presentation of Hecke-Hopf algebras for non-simply-laced type.   Hecke-Hopf algebras were defined by A. Berenstein and D. Kazhdan. We give an\nexplicit presentation of an Hecke-Hopf algebra when the parameter $m_{ij},$\nassociated to any two distinct vertices $i$ and $j$ in the presentation of a\nCoxeter group, equals $4,$ $5$ or $6$. As an application, we give a proof of a\nconjecture of Berenstein and Kazhdan when the Coxeter group is crystallographic\nand non-simply-laced. As another application, we show that another conjecture\nof Berenstein and Kazhdan holds when $m_{ij},$ associated to any two distinct\nvertices $i$ and $j,$ equals $4$ and that the conjecture does not hold when\nsome $m_{ij}$ equals $6$ by giving a counterexample to it.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Surface depression with double-angle geometry during the discharge of close-packed grains from a silo.   When rough grains in standard packing conditions are discharged from a silo,\na conical depression with a single slope is formed at the surface. We observed\nthat the increase of the volume fraction generates a more complex depression\ncharacterized by two angles of discharge: a lower angle close to the one\nmeasured for standard packing and a considerably larger upper angle. The change\nin slope appears at the boundary between a densely packed stagnant region at\nthe periphery and the central flowing channel formed over the aperture. Since\nthe material in the latter zone is always fluidized, the flow rate is\nunaffected by the initial packing of the bed. On the other hand, the contrast\nbetween both angles is markedly smaller when smooth particles of the same size\nand density are used, which reveals that high volume fraction and friction must\ncombine to produce the observed geometry. Our results show that the surface\nprofile helps to identify by simple visual inspection the packing conditions of\na granular bed, and this can be useful to prevent undesirable collapses during\nsilo discharge in industry.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Finsler structures on holomorphic Lie algebroids.   Complex Finsler vector bundles have been studied mainly by T. Aikou, who\ndefined complex Finsler structures on holomorphic vector bundles. In this\npaper, we consider the more general case of a holomorphic Lie algebroid E and\nwe introduce Finsler structures, partial and Chern-Finsler connections on it.\nFirst, we recall some basic notions on holomorphic Lie algebroids. Then, using\nan idea from E. Martinez, we introduce the concept of complexified prolongation\nof such an algebroid. Also, we study nonlinear and linear connections on the\ntangent bundle of E and on the prolongation of E and we investigate the\nrelation between their coefficients. The analogue of the classical\nChern-Finsler connection is defined and studied in the paper for the case of\nthe holomorphic Lie algebroid.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Advanced reduced-order models for moisture diffusion in porous media.   It is of great concern to produce numerically efficient methods for moisture\ndiffusion through porous media, capable of accurately calculate moisture\ndistribution with a reduced computational effort. In this way, model reduction\nmethods are promising approaches to bring a solution to this issue since they\ndo not degrade the physical model and provide a significant reduction of\ncomputational cost. Therefore, this article explores in details the\ncapabilities of two model-reduction techniques - the Spectral Reduced-Order\nModel (Spectral-ROM) and the Proper Generalised Decomposition (PGD) - to\nnumerically solve moisture diffusive transfer through porous materials. Both\napproaches are applied to three different problems to provide clear examples of\nthe construction and use of these reduced-order models. The methodology of both\napproaches is explained extensively so that the article can be used as a\nnumerical benchmark by anyone interested in building a reduced-order model for\ndiffusion problems in porous materials. Linear and non-linear unsteady\nbehaviors of unidimensional moisture diffusion are investigated. The last case\nfocuses on solving a parametric problem in which the solution depends on space,\ntime and the diffusivity properties. Results have highlighted that both methods\nprovide accurate solutions and enable to reduce significantly the order of the\nmodel around ten times lower than the large original model. It also allows an\nefficient computation of the physical phenomena with an error lower than\n10^{-2} when compared to a reference solution.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Dependencies: Formalising Semantic Catenae for Information Retrieval.   Building machines that can understand text like humans is an AI-complete\nproblem. A great deal of research has already gone into this, with astounding\nresults, allowing everyday people to discuss with their telephones, or have\ntheir reading materials analysed and classified by computers. A prerequisite\nfor processing text semantics, common to the above examples, is having some\ncomputational representation of text as an abstract object. Operations on this\nrepresentation practically correspond to making semantic inferences, and by\nextension simulating understanding text. The complexity and granularity of\nsemantic processing that can be realised is constrained by the mathematical and\ncomputational robustness, expressiveness, and rigour of the tools used.\nThis dissertation contributes a series of such tools, diverse in their\nmathematical formulation, but common in their application to model semantic\ninferences when machines process text. These tools are principally expressed in\nnine distinct models that capture aspects of semantic dependence in highly\ninterpretable and non-complex ways. This dissertation further reflects on\npresent and future problems with the current research paradigm in this area,\nand makes recommendations on how to overcome them.\nThe amalgamation of the body of work presented in this dissertation advances\nthe complexity and granularity of semantic inferences that can be made\nautomatically by machines.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discriminative k-shot learning using probabilistic models.   This paper introduces a probabilistic framework for k-shot image\nclassification. The goal is to generalise from an initial large-scale\nclassification task to a separate task comprising new classes and small numbers\nof examples. The new approach not only leverages the feature-based\nrepresentation learned by a neural network from the initial task\n(representational transfer), but also information about the classes (concept\ntransfer). The concept information is encapsulated in a probabilistic model for\nthe final layer weights of the neural network which acts as a prior for\nprobabilistic k-shot learning. We show that even a simple probabilistic model\nachieves state-of-the-art on a standard k-shot learning dataset by a large\nmargin. Moreover, it is able to accurately model uncertainty, leading to well\ncalibrated classifiers, and is easily extensible and flexible, unlike many\nrecent approaches to k-shot learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotically safe cosmology - a status report.   Asymptotic Safety, based on a non-Gaussian fixed point of the gravitational\nrenormalization group flow, provides an elegant mechanism for completing the\ngravitational force at sub-Planckian scales. At high energies the fixed point\ncontrols the scaling of couplings such that unphysical divergences are absent\nwhile the emergence of classical low-energy physics is linked to a crossover\nbetween two renormalization group fixed points. These features make Asymptotic\nSafety an attractive framework for cosmological model building. The resulting\nscenarios may naturally give rise to a quantum gravity driven inflationary\nphase in the very early universe and an almost scale-free fluctuation spectrum.\nMoreover, effective descriptions arising from an renormalization group\nimprovement permit a direct comparison to cosmological observations as, e.g.\nPlanck data.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Machine Learning Framework for Stock Selection.   This paper demonstrates how to apply machine learning algorithms to\ndistinguish good stocks from the bad stocks. To this end, we construct 244\ntechnical and fundamental features to characterize each stock, and label stocks\naccording to their ranking with respect to the return-to-volatility ratio.\nAlgorithms ranging from traditional statistical learning methods to recently\npopular deep learning method, e.g. Logistic Regression (LR), Random Forest\n(RF), Deep Neural Network (DNN), and the Stacking, are trained to solve the\nclassification task. Genetic Algorithm (GA) is also used to implement feature\nselection. The effectiveness of the stock selection strategy is validated in\nChinese stock market in both statistical and practical aspects, showing that:\n1) Stacking outperforms other models reaching an AUC score of 0.972; 2) Genetic\nAlgorithm picks a subset of 114 features and the prediction performances of all\nmodels remain almost unchanged after the selection procedure, which suggests\nsome features are indeed redundant; 3) LR and DNN are radical models; RF is\nrisk-neutral model; Stacking is somewhere between DNN and RF. 4) The portfolios\nconstructed by our models outperform market average in back tests.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Carrier driven coupling in ferromagnetic oxide heterostructures.   Transition metal oxides are well known for their complex magnetic and\nelectrical properties. When brought together in heterostructure geometries,\nthey show particular promise for spintronics and colossal magnetoresistance\napplications. In this letter, we propose a new mechanism for the coupling\nbetween layers of itinerant ferromagnetic materials in heterostructures. The\ncoupling is mediated by charge carriers that strive to maximally delocalize\nthrough the heterostructure to gain kinetic energy. In doing so, they force a\nferromagnetic or antiferromagnetic coupling between the constituent layers. To\nillustrate this, we focus on heterostructures composed of SrRuO$_3$ and\nLa$_{1-x}$A$_{x}$MnO$_3$ (A=Ca/Sr). Our mechanism is consistent with\nantiferromagnetic alignment that is known to occur in multilayers of\nSrRuO$_3$-La$_{1-x}$A$_{x}$MnO$_3$. To support our assertion, we present a\nminimal Kondo-lattice model which reproduces the known magnetization properties\nof such multilayers. In addition, we discuss a quantum well model for\nheterostructures and argue that the spin-dependent density of states determines\nthe nature of the coupling. As a smoking gun signature, we propose that\nbilayers with the same constituents will oscillate between ferromagnetic and\nantiferromagnetic coupling upon tuning the relative thicknesses of the layers.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Personalized Thread Recommendation for MOOC Discussion Forums.   Social learning, i.e., students learning from each other through social\ninteractions, has the potential to significantly scale up instruction in online\neducation. In many cases, such as in massive open online courses (MOOCs),\nsocial learning is facilitated through discussion forums hosted by course\nproviders. In this paper, we propose a probabilistic model for the process of\nlearners posting on such forums, using point processes. Different from existing\nworks, our method integrates topic modeling of the post text, timescale\nmodeling of the decay in post activity over time, and learner topic interest\nmodeling into a single model, and infers this information from user data. Our\nmethod also varies the excitation levels induced by posts according to the\nthread structure, to reflect typical notification settings in discussion\nforums. We experimentally validate the proposed model on three real-world MOOC\ndatasets, with the largest one containing up to 6,000 learners making 40,000\nposts in 5,000 threads. Results show that our model excels at thread\nrecommendation, achieving significant improvement over a number of baselines,\nthus showing promise of being able to direct learners to threads that they are\ninterested in more efficiently. Moreover, we demonstrate analytics that our\nmodel parameters can provide, such as the timescales of different topic\ncategories in a course.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Computational Results for Extensive-Form Adversarial Team Games.   We provide, to the best of our knowledge, the first computational study of\nextensive-form adversarial team games. These games are sequential, zero-sum\ngames in which a team of players, sharing the same utility function, faces an\nadversary. We define three different scenarios according to the communication\ncapabilities of the team. In the first, the teammates can communicate and\ncorrelate their actions both before and during the play. In the second, they\ncan only communicate before the play. In the third, no communication is\npossible at all. We define the most suitable solution concepts, and we study\nthe inefficiency caused by partial or null communication, showing that the\ninefficiency can be arbitrarily large in the size of the game tree.\nFurthermore, we study the computational complexity of the equilibrium-finding\nproblem in the three scenarios mentioned above, and we provide, for each of the\nthree scenarios, an exact algorithm. Finally, we empirically evaluate the\nscalability of the algorithms in random games and the inefficiency caused by\npartial or null communication.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Novel Structured Low-rank algorithm to recover spatially smooth exponential image time series.   We propose a structured low rank matrix completion algorithm to recover a\ntime series of images consisting of linear combination of exponential\nparameters at every pixel, from under-sampled Fourier measurements. The spatial\nsmoothness of these parameters is exploited along with the exponential\nstructure of the time series at every pixel, to derive an annihilation relation\nin the $k-t$ domain. This annihilation relation translates into a structured\nlow rank matrix formed from the $k-t$ samples. We demonstrate the algorithm in\nthe parameter mapping setting and show significant improvement over state of\nthe art methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unidirectional control of optically induced spin waves.   Unidirectional control of optically induced spin waves in a rare-earth iron\ngarnet crystal is demonstrated. We observed the interference of two spin-wave\npackets with different initial phases generated by circularly polarized light\npulses. This interference results in unidirectional propagation if the\nspin-wave sources are spaced apart at 1/4 of the wavelength of the spin waves\nand the initial phase difference is set to pi/2. The propagating direction of\nthe spin wave is switched by the polarization helicity of the light pulses.\nMoreover, in a numerical simulation, applying more than two spin-wave sources\nwith a suitable polarization and spot shape, arbitrary manipulation of the spin\nwave by the phased array method was replicated.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Automated Vulnerability Detection in Source Code Using Deep Representation Learning.   Increasing numbers of software vulnerabilities are discovered every year\nwhether they are reported publicly or discovered internally in proprietary\ncode. These vulnerabilities can pose serious risk of exploit and result in\nsystem compromise, information leaks, or denial of service. We leveraged the\nwealth of C and C++ open-source code available to develop a large-scale\nfunction-level vulnerability detection system using machine learning. To\nsupplement existing labeled vulnerability datasets, we compiled a vast dataset\nof millions of open-source functions and labeled it with carefully-selected\nfindings from three different static analyzers that indicate potential\nexploits. The labeled dataset is available at: this https URL. Using\nthese datasets, we developed a fast and scalable vulnerability detection tool\nbased on deep feature representation learning that directly interprets lexed\nsource code. We evaluated our tool on code from both real software packages and\nthe NIST SATE IV benchmark dataset. Our results demonstrate that deep feature\nrepresentation learning on source code is a promising approach for automated\nsoftware vulnerability detection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A general theory of singular values with applications to signal denoising.   We study the Pareto frontier for two competing norms $\\|\\cdot\\|_X$ and\n$\\|\\cdot\\|_Y$ on a vector space. For a given vector $c$, the pareto frontier\ndescribes the possible values of $(\\|a\\|_X,\\|b\\|_Y)$ for a decomposition\n$c=a+b$. The singular value decomposition of a matrix is closely related to the\nPareto frontier for the spectral and nuclear norm. We will develop a general\ntheory that extends the notion of singular values of a matrix to arbitrary\nfinite dimensional euclidean vector spaces equipped with dual norms. This also\ngeneralizes the diagonal singular value decompositions for tensors introduced\nby the author in previous work. We can apply the results to denoising, where\n$c$ is a noisy signal, $a$ is a sparse signal and $b$ is noise. Applications\ninclude 1D total variation denoising, 2D total variation Rudin-Osher-Fatemi\nimage denoising, LASSO, basis pursuit denoising and tensor decompositions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Model-Based Deep Reinforcement Learning with Variational State Tabulation.   Modern reinforcement learning algorithms reach super-human performance on\nmany board and video games, but they are sample inefficient, i.e. they\ntypically require significantly more playing experience than humans to reach an\nequal performance level. To improve sample efficiency, an agent may build a\nmodel of the environment and use planning methods to update its policy. In this\narticle we introduce Variational State Tabulation (VaST), which maps an\nenvironment with a high-dimensional state space (e.g. the space of visual\ninputs) to an abstract tabular model. Prioritized sweeping with small backups,\na highly efficient planning method, can then be used to update state-action\nvalues. We show how VaST can rapidly learn to maximize reward in tasks like 3D\nnavigation and efficiently adapt to sudden changes in rewards or transition\nprobabilities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fractional differential and fractional integral modified-Bloch equations for PFG anomalous diffusion and their general solutions.   The studying of anomalous diffusion by pulsed field gradient (PFG) diffusion\ntechnique still faces challenges. Two different research groups have proposed\nmodified Bloch equation for anomalous diffusion. However, these equations have\ndifferent forms and, therefore, yield inconsistent results. The discrepancy in\nthese reported modified Bloch equations may arise from different ways of\ncombining the fractional diffusion equation with the precession equation where\nthe time derivatives have different derivative orders and forms. Moreover, to\nthe best of my knowledge, the general PFG signal attenuation expression\nincluding finite gradient pulse width (FGPW) effect for time-space fractional\ndiffusion based on the fractional derivative has yet to be reported by other\nmethods. Here, based on different combination strategy, two new modified Bloch\nequations are proposed, which belong to two significantly different types: a\ndifferential type based on the fractal derivative and an integral type based on\nthe fractional derivative. The merit of the integral type modified Bloch\nequation is that the original properties of the contributions from linear or\nnonlinear processes remain unchanged at the instant of the combination. The\ngeneral solutions including the FGPW effect were derived from these two\nequations as well as from two other methods: a method observing the signal\nintensity at the origin and the recently reported effective phase shift\ndiffusion equation method. The relaxation effect was also considered. It is\nfound that the relaxation behavior influenced by fractional diffusion based on\nthe fractional derivative deviates from that of normal diffusion. The general\nsolution agrees perfectly with continuous-time random walk (CTRW) simulations\nas well as reported literature results. The new modified Bloch equations is a\nvaluable tool to describe PFG anomalous diffusion in NMR and MRI.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Relaxation of p-growth integral functionals under space-dependent differential constraints.   A representation formula for the relaxation of integral energies\n$$(u,v)\\mapsto\\int_{\\Omega} f(x,u(x),v(x))\\,dx,$$ is obtained, where $f$\nsatisfies $p$-growth assumptions, $1<p<+\\infty$, and the fields $v$ are\nsubjected to space-dependent first order linear differential constraints in the\nframework of $\\mathscr{A}$-quasiconvexity with variable coefficients.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Event Analysis of Pulse-reclosers in Distribution Systems Through Sparse Representation.   The pulse-recloser uses pulse testing technology to verify that the line is\nclear of faults before initiating a reclose operation, which significantly\nreduces stress on the system components (e.g. substation transformers) and\nvoltage sags on adjacent feeders. Online event analysis of pulse-reclosers are\nessential to increases the overall utility of the devices, especially when\nthere are numerous devices installed throughout the distribution system. In\nthis paper, field data recorded from several devices were analyzed to identify\nspecific activity and fault locations. An algorithm is developed to screen the\ndata to identify the status of each pole and to tag time windows with a\npossible pulse event. In the next step, selected time windows are further\nanalyzed and classified using a sparse representation technique by solving an\nl1-regularized least-square problem. This classification is obtained by\ncomparing the pulse signature with the reference dictionary to find a set that\nmost closely matches the pulse features. This work also sheds additional light\non the possibility of fault classification based on the pulse signature. Field\ndata collected from a distribution system are used to verify the effectiveness\nand reliability of the proposed method.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Sensor Transformation Attention Networks.   Recent work on encoder-decoder models for sequence-to-sequence mapping has\nshown that integrating both temporal and spatial attention mechanisms into\nneural networks increases the performance of the system substantially. In this\nwork, we report on the application of an attentional signal not on temporal and\nspatial regions of the input, but instead as a method of switching among inputs\nthemselves. We evaluate the particular role of attentional switching in the\npresence of dynamic noise in the sensors, and demonstrate how the attentional\nsignal responds dynamically to changing noise levels in the environment to\nachieve increased performance on both audio and visual tasks in three\ncommonly-used datasets: TIDIGITS, Wall Street Journal, and GRID. Moreover, the\nproposed sensor transformation network architecture naturally introduces a\nnumber of advantages that merit exploration, including ease of adding new\nsensors to existing architectures, attentional interpretability, and increased\nrobustness in a variety of noisy environments not seen during training.\nFinally, we demonstrate that the sensor selection attention mechanism of a\nmodel trained only on the small TIDIGITS dataset can be transferred directly to\na pre-existing larger network trained on the Wall Street Journal dataset,\nmaintaining functionality of switching between sensors to yield a dramatic\nreduction of error in the presence of noise.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Algebraic relations between solutions of Painlevé equations.   We calculate model theoretic ranks of Painlevé equations in this article,\nshowing in particular, that any equation in any of the Painlevé families has\nMorley rank one, extending results of Nagloo and Pillay (2011). We show that\nthe type of the generic solution of any equation in the second Painlevé\nfamily is geometrically trivial, extending a result of Nagloo (2015).\nWe also establish the orthogonality of various pairs of equations in the\nPainlevé families, showing at least generically, that all instances of\nnonorthogonality between equations in the same Painlevé family come from\nclassically studied B{ä}cklund transformations. For instance, we show that if\nat least one of $\\alpha, \\beta$ is transcendental, then $P_{II} (\\alpha)$ is\nnonorthogonal to $P_{II} ( \\beta )$ if and only if $\\alpha+ \\beta \\in \\mathbb\nZ$ or $\\alpha - \\beta \\in \\mathbb Z$. Our results have concrete interpretations\nin terms of characterizing the algebraic relations between solutions of\nPainlevé equations. We give similar results for orthogonality relations\nbetween equations in different Painlevé families, and formulate some general\nquestions which extend conjectures of Nagloo and Pillay (2011) on transcendence\nand algebraic independence of solutions to Painlevé equations. We also apply\nour analysis of ranks to establish some orthogonality results for pairs of\nPainlevé equations from different families. For instance, we answer several\nopen questions of Nagloo (2016), and in the process answer a question of Boalch\n(2012).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convergence of the Expectation-Maximization Algorithm Through Discrete-Time Lyapunov Stability Theory.   In this paper, we propose a dynamical systems perspective of the\nExpectation-Maximization (EM) algorithm. More precisely, we can analyze the EM\nalgorithm as a nonlinear state-space dynamical system. The EM algorithm is\nwidely adopted for data clustering and density estimation in statistics,\ncontrol systems, and machine learning. This algorithm belongs to a large class\nof iterative algorithms known as proximal point methods. In particular, we\nre-interpret limit points of the EM algorithm and other local maximizers of the\nlikelihood function it seeks to optimize as equilibria in its dynamical system\nrepresentation. Furthermore, we propose to assess its convergence as asymptotic\nstability in the sense of Lyapunov. As a consequence, we proceed by leveraging\nrecent results regarding discrete-time Lyapunov stability theory in order to\nestablish asymptotic stability (and thus, convergence) in the dynamical system\nrepresentation of the EM algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Heating and cooling of coronal loops with turbulent suppression of parallel heat conduction.   Using the \"enthalpy-based thermal evolution of loops\" (EBTEL) model, we\ninvestigate the hydrodynamics of the plasma in a flaring coronal loop in which\nheat conduction is limited by turbulent scattering of the electrons that\ntransport the thermal heat flux. The EBTEL equations are solved analytically in\neach of the two (conduction-dominated and radiation-dominated) cooling phases.\nComparison of the results with typical observed cooling times in solar flares\nshows that the turbulent mean free-path $\\lambda_T$ lies in a range\ncorresponding to a regime in which classical (collision-dominated) conduction\nplays at most a limited role. We also consider the magnitude and duration of\nthe heat input that is necessary to account for the enhanced values of\ntemperature and density at the beginning of the cooling phase and for the\nobserved cooling times. We find through numerical modeling that in order to\nproduce a peak temperature $\\simeq 1.5 \\times 10^7$~K and a 200~s cooling time\nconsistent with observations, the flare heating profile must extend over a\nsignificant period of time; in particular, its lingering role must be taken\ninto consideration in any description of the cooling phase. Comparison with\nobservationally-inferred values of post-flare loop temperatures, densities, and\ncooling times thus leads to useful constraints on both the magnitude and\nduration of the magnetic energy release in the loop, as well as on the value of\nthe turbulent mean free-path $\\lambda_T$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hasse diagrams of non-isomorphic posets with $n$ elements, $2\\leq n \\leq 7,$ and the number of posets with $10$ elements, without the aid of any computer program.   Let $P(n)$ be the set of all posets with $n$ elements and $NIP(n)$ the set of\nnon-isomorphic posets with $n$ elements. Let $P^{(j)}(n)$, $1\\leq j\\leq 2^n,$\nbe the number of all posets with $n$ elements possessing exactly $j$\nantichains. We have determined the numbers $P^{(j)}(7),$ $1\\leq j\\leq 128$, and\nusing a result of M. Erné \\cite{EM4}, we compute $|P(10)|$ without the aid of\nany computer program. We include the Hasse diagrams of all the non-isomorphic\nposets of $P(7)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Survey on the Adoption of Cloud Computing in Education Sector.   Education is a key factor in ensuring economic growth, especially for\ncountries with growing economies. Today, students have become more\ntechnologically savvy as teaching and learning uses more advance technology day\nin, day out. Due to virtualize resources through the Internet, as well as\ndynamic scalability, cloud computing has continued to be adopted by more\norganizations. Despite the looming financial crisis, there has been increasing\npressure for educational institutions to deliver better services using minimal\nresources. Leaning institutions, both public and private can utilize the\npotential advantage of cloud computing to ensure high quality service\nregardless of the minimal resources available. Cloud computing is taking a\ncenter stage in academia because of its various benefits. Various learning\ninstitutions use different cloud-based applications provided by the service\nproviders to ensure that their students and other users can perform both\nacademic as well as business-related tasks. Thus, this research will seek to\nestablish the benefits associated with the use of cloud computing in learning\ninstitutions. The solutions provided by the cloud technology ensure that the\nresearch and development, as well as the teaching is more sustainable and\nefficient, thus positively influencing the quality of learning and teaching\nwithin educational institutions. This has led to various learning institutions\nadopting cloud technology as a solution to various technological challenges\nthey face on a daily routine.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal one-shot quantum algorithm for EQUALITY and AND.   We study the computation complexity of Boolean functions in the quantum black\nbox model. In this model our task is to compute a function\n$f:\\{0,1\\}\\to\\{0,1\\}$ on an input $x\\in\\{0,1\\}^n$ that can be accessed by\nquerying the black box. Quantum algorithms are inherently probabilistic; we are\ninterested in the lowest possible probability that the algorithm outputs\nincorrect answer (the error probability) for a fixed number of queries. We show\nthat the lowest possible error probability for $AND_n$ and $EQUALITY_{n+1}$ is\n$1/2-n/(n^2+1)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A high resolution ion microscope for cold atoms.   We report on an ion-optical system that serves as a microscope for ultracold\nground state and Rydberg atoms. The system is designed to achieve a\nmagnification of up to 1000 and a spatial resolution in the 100 nm range,\nthereby surpassing many standard imaging techniques for cold atoms. The\nmicroscope consists of four electrostatic lenses and a microchannel plate in\nconjunction with a delay line detector in order to achieve single particle\nsensitivity with high temporal and spatial resolution. We describe the design\nprocess of the microscope including ion-optical simulations of the imaging\nsystem and characterize aberrations and the resolution limit. Furthermore, we\npresent the experimental realization of the microscope in a cold atom setup and\ninvestigate its performance by patterned ionization with a structure size down\nto 2.7 {\\mu}m. The microscope meets the requirements for studying various\nmany-body effects, ranging from correlations in cold quantum gases up to\nRydberg molecule formation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Siamese Network of Deep Fisher-Vector Descriptors for Image Retrieval.   This paper addresses the problem of large scale image retrieval, with the aim\nof accurately ranking the similarity of a large number of images to a given\nquery image. To achieve this, we propose a novel Siamese network. This network\nconsists of two computational strands, each comprising of a CNN component\nfollowed by a Fisher vector component. The CNN component produces dense, deep\nconvolutional descriptors that are then aggregated by the Fisher Vector method.\nCrucially, we propose to simultaneously learn both the CNN filter weights and\nFisher Vector model parameters. This allows us to account for the evolving\ndistribution of deep descriptors over the course of the learning process. We\nshow that the proposed approach gives significant improvements over the\nstate-of-the-art methods on the Oxford and Paris image retrieval datasets.\nAdditionally, we provide a baseline performance measure for both these datasets\nwith the inclusion of 1 million distractors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-Agent Diverse Generative Adversarial Networks.   We propose MAD-GAN, an intuitive generalization to the Generative Adversarial\nNetworks (GANs) and its conditional variants to address the well known problem\nof mode collapse. First, MAD-GAN is a multi-agent GAN architecture\nincorporating multiple generators and one discriminator. Second, to enforce\nthat different generators capture diverse high probability modes, the\ndiscriminator of MAD-GAN is designed such that along with finding the real and\nfake samples, it is also required to identify the generator that generated the\ngiven fake sample. Intuitively, to succeed in this task, the discriminator must\nlearn to push different generators towards different identifiable modes. We\nperform extensive experiments on synthetic and real datasets and compare\nMAD-GAN with different variants of GAN. We show high quality diverse sample\ngenerations for challenging tasks such as image-to-image translation and face\ngeneration. In addition, we also show that MAD-GAN is able to disentangle\ndifferent modalities when trained using highly challenging diverse-class\ndataset (e.g. dataset with images of forests, icebergs, and bedrooms). In the\nend, we show its efficacy on the unsupervised feature representation task. In\nAppendix, we introduce a similarity based competing objective (MAD-GAN-Sim)\nwhich encourages different generators to generate diverse samples based on a\nuser defined similarity metric. We show its performance on the image-to-image\ntranslation, and also show its effectiveness on the unsupervised feature\nrepresentation task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Segmentation of the Proximal Femur from MR Images using Deep Convolutional Neural Networks.   Magnetic resonance imaging (MRI) has been proposed as a complimentary method\nto measure bone quality and assess fracture risk. However, manual segmentation\nof MR images of bone is time-consuming, limiting the use of MRI measurements in\nthe clinical practice. The purpose of this paper is to present an automatic\nproximal femur segmentation method that is based on deep convolutional neural\nnetworks (CNNs). This study had institutional review board approval and written\ninformed consent was obtained from all subjects. A dataset of volumetric\nstructural MR images of the proximal femur from 86 subject were\nmanually-segmented by an expert. We performed experiments by training two\ndifferent CNN architectures with multiple number of initial feature maps and\nlayers, and tested their segmentation performance against the gold standard of\nmanual segmentations using four-fold cross-validation. Automatic segmentation\nof the proximal femur achieved a high dice similarity score of 0.94$\\pm$0.05\nwith precision = 0.95$\\pm$0.02, and recall = 0.94$\\pm$0.08 using a CNN\narchitecture based on 3D convolution exceeding the performance of 2D CNNs. The\nhigh segmentation accuracy provided by CNNs has the potential to help bring the\nuse of structural MRI measurements of bone quality into clinical practice for\nmanagement of osteoporosis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tensor network method for reversible classical computation.   We develop a tensor network technique that can solve universal reversible\nclassical computational problems, formulated as vertex models on a square\nlattice [Nat. Commun. 8, 15303 (2017)]. By encoding the truth table of each\nvertex constraint in a tensor, the total number of solutions compatible with\npartial inputs/outputs at the boundary can be represented as the full\ncontraction of a tensor network. We introduce an iterative\ncompression-decimation (ICD) scheme that performs this contraction efficiently.\nThe ICD algorithm first propagates local constraints to longer ranges via\nrepeated contraction-decomposition sweeps over all lattice bonds, thus\nachieving compression on a given length scale. It then decimates the lattice\nvia coarse-graining tensor contractions. Repeated iterations of these two steps\ngradually collapse the tensor network and ultimately yield the exact tensor\ntrace for large systems, without the need for manual control of tensor\ndimensions. Our protocol allows us to obtain the exact number of solutions for\ncomputations where a naive enumeration would take astronomically long times.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Minimax Optimal Estimators for Additive Scalar Functionals of Discrete Distributions.   In this paper, we consider estimators for an additive functional of $\\phi$,\nwhich is defined as $\\theta(P;\\phi)=\\sum_{i=1}^k\\phi(p_i)$, from $n$ i.i.d.\nrandom samples drawn from a discrete distribution $P=(p_1,...,p_k)$ with\nalphabet size $k$. We propose a minimax optimal estimator for the estimation\nproblem of the additive functional. We reveal that the minimax optimal rate is\ncharacterized by the divergence speed of the fourth derivative of $\\phi$ if the\ndivergence speed is high. As a result, we show there is no consistent estimator\nif the divergence speed of the fourth derivative of $\\phi$ is larger than\n$p^{-4}$. Furthermore, if the divergence speed of the fourth derivative of\n$\\phi$ is $p^{4-\\alpha}$ for $\\alpha \\in (0,1)$, the minimax optimal rate is\nobtained within a universal multiplicative constant as $\\frac{k^2}{(n\\ln\nn)^{2\\alpha}} + \\frac{k^{2-2\\alpha}}{n}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiset Combinatorial Batch Codes.   Batch codes, first introduced by Ishai, Kushilevitz, Ostrovsky, and Sahai,\nmimic a distributed storage of a set of $n$ data items on $m$ servers, in such\na way that any batch of $k$ data items can be retrieved by reading at most some\n$t$ symbols from each server. Combinatorial batch codes, are replication-based\nbatch codes in which each server stores a subset of the data items.\nIn this paper, we propose a generalization of combinatorial batch codes,\ncalled multiset combinatorial batch codes (MCBC), in which $n$ data items are\nstored in $m$ servers, such that any multiset request of $k$ items, where any\nitem is requested at most $r$ times, can be retrieved by reading at most $t$\nitems from each server. The setup of this new family of codes is motivated by\nrecent work on codes which enable high availability and parallel reads in\ndistributed storage systems. The main problem under this paradigm is to\nminimize the number of items stored in the servers, given the values of\n$n,m,k,r,t$, which is denoted by $N(n,k,m,t;r)$. We first give a necessary and\nsufficient condition for the existence of MCBCs. Then, we present several\nbounds on $N(n,k,m,t;r)$ and constructions of MCBCs. In particular, we\ndetermine the value of $N(n,k,m,1;r)$ for any $n\\geq\n\\left\\lfloor\\frac{k-1}{r}\\right\\rfloor{m\\choose k-1}-(m-k+1)A(m,4,k-2)$, where\n$A(m,4,k-2)$ is the maximum size of a binary constant weight code of length\n$m$, distance four and weight $k-2$. We also determine the exact value of\n$N(n,k,m,1;r)$ when $r\\in\\{k,k-1\\}$ or $k=m$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Geometric Matrix Completion with Recurrent Multi-Graph Neural Networks.   Matrix completion models are among the most common formulations of\nrecommender systems. Recent works have showed a boost of performance of these\ntechniques when introducing the pairwise relationships between users/items in\nthe form of graphs, and imposing smoothness priors on these graphs. However,\nsuch techniques do not fully exploit the local stationarity structures of\nuser/item graphs, and the number of parameters to learn is linear w.r.t. the\nnumber of users and items. We propose a novel approach to overcome these\nlimitations by using geometric deep learning on graphs. Our matrix completion\narchitecture combines graph convolutional neural networks and recurrent neural\nnetworks to learn meaningful statistical graph-structured patterns and the\nnon-linear diffusion process that generates the known ratings. This neural\nnetwork system requires a constant number of parameters independent of the\nmatrix size. We apply our method on both synthetic and real datasets, showing\nthat it outperforms state-of-the-art techniques.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ExoMol molecular line lists XX: a comprehensive line list for H$_3^+$.   H$_3^+$ is a ubiquitous and important astronomical species whose spectrum has\nbeen observed in the interstellar medium, planets and tentatively in the\nremnants of supernova SN1897a. Its role as a cooler is important for gas giant\nplanets and exoplanets, and possibly the early Universe. All this makes the\nspectral properties, cooling function and partition function of H$_3^+$ key\nparameters for astronomical models and analysis. A new high-accuracy, very\nextensive line list for H$_3^+$ called MiZATeP was computed as part of the\nExoMol project alongside a temperature-dependent cooling function and partition\nfunction as well as lifetimes for %individual excited states. These data are\nmade available in electronic form as supplementary data to this article and at\nthis http URL",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multiagent Bidirectionally-Coordinated Nets: Emergence of Human-level Coordination in Learning to Play StarCraft Combat Games.   Many artificial intelligence (AI) applications often require multiple\nintelligent agents to work in a collaborative effort. Efficient learning for\nintra-agent communication and coordination is an indispensable step towards\ngeneral AI. In this paper, we take StarCraft combat game as a case study, where\nthe task is to coordinate multiple agents as a team to defeat their enemies. To\nmaintain a scalable yet effective communication protocol, we introduce a\nMultiagent Bidirectionally-Coordinated Network (BiCNet ['bIknet]) with a\nvectorised extension of actor-critic formulation. We show that BiCNet can\nhandle different types of combats with arbitrary numbers of AI agents for both\nsides. Our analysis demonstrates that without any supervisions such as human\ndemonstrations or labelled data, BiCNet could learn various types of advanced\ncoordination strategies that have been commonly used by experienced game\nplayers. In our experiments, we evaluate our approach against multiple\nbaselines under different scenarios; it shows state-of-the-art performance, and\npossesses potential values for large-scale real-world applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rigidity of volume-minimizing hypersurfaces in Riemannian 5-manifolds.   In this paper we generalize the main result of [4] for manifolds that are not\nnecessarily Einstein. In fact, we obtain an upper bound for the volume of a\nlocally volume-minimizing closed hypersurface $\\Sigma$ of a Riemannian\n5-manifold $M$ with scalar curvature bounded from below by a positive constant\nin terms of the total traceless Ricci curvature of $\\Sigma$. Furthermore, if\n$\\Sigma$ saturates the respective upper bound and $M$ has nonnegative Ricci\ncurvature, then $\\Sigma$ is isometric to $\\mathbb{S}^4$ up to scaling and $M$\nsplits in a neighborhood of $\\Sigma$. Also, we obtain a rigidity result for the\nRiemannian cover of $M$ when $\\Sigma$ minimizes the volume in its homotopy\nclass and saturates the upper bound.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hybrid Kinematic Control for Rigid Body Pose Stabilization using Dual Quaternions.   In this paper, we address the rigid body pose stabilization problem using\ndual quaternion formalism. We propose a hybrid control strategy to design a\nswitching control law with hysteresis in such a way that the global asymptotic\nstability of the closed-loop system is guaranteed and such that the global\nattractivity of the stabilization pose does not exhibit chattering, a problem\nthat is present in all discontinuous-based feedback controllers. Using\nnumerical simulations, we illustrate the problems that arise from existing\nresults in the literature -- as unwinding and chattering -- and verify the\neffectiveness of the proposed controller to solve the robust global pose\nstability problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed sub-optimal resource allocation over weight-balanced graph via singular perturbation.   In this paper, we consider distributed optimization design for resource\nallocation problems over weight-balanced graphs. With the help of singular\nperturbation analysis, we propose a simple sub-optimal continuous-time\noptimization algorithm. Moreover, we prove the existence and uniqueness of the\nalgorithm equilibrium, and then show the convergence with an exponential rate.\nFinally, we verify the sub-optimality of the algorithm, which can approach the\noptimal solution as an adjustable parameter tends to zero.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust and Fast Decoding of High-Capacity Color QR Codes for Mobile Applications.   The use of color in QR codes brings extra data capacity, but also inflicts\ntremendous challenges on the decoding process due to chromatic distortion,\ncross-channel color interference and illumination variation. Particularly, we\nfurther discover a new type of chromatic distortion in high-density color QR\ncodes, cross-module color interference, caused by the high density which also\nmakes the geometric distortion correction more challenging. To address these\nproblems, we propose two approaches, namely, LSVM-CMI and QDA-CMI, which\njointly model these different types of chromatic distortion. Extended from SVM\nand QDA, respectively, both LSVM-CMI and QDA-CMI optimize over a particular\nobjective function to learn a color classifier. Furthermore, a robust geometric\ntransformation method and several pipeline refinements are proposed to boost\nthe decoding performance for mobile applications. We put forth and implement a\nframework for high-capacity color QR codes equipped with our methods, called\nHiQ. To evaluate the performance of HiQ, we collect a challenging large-scale\ncolor QR code dataset, CUHK-CQRC, which consists of 5390 high-density color QR\ncode samples. The comparison with the baseline method [2] on CUHK-CQRC shows\nthat HiQ at least outperforms [2] by 188% in decoding success rate and 60% in\nbit error rate. Our implementation of HiQ in iOS and Android also demonstrates\nthe effectiveness of our framework in real-world applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Walking Through Waypoints.   We initiate the study of a fundamental combinatorial problem: Given a\ncapacitated graph $G=(V,E)$, find a shortest walk (\"route\") from a source $s\\in\nV$ to a destination $t\\in V$ that includes all vertices specified by a set\n$\\mathscr{W}\\subseteq V$: the \\emph{waypoints}. This waypoint routing problem\nfinds immediate applications in the context of modern networked distributed\nsystems. Our main contribution is an exact polynomial-time algorithm for graphs\nof bounded treewidth. We also show that if the number of waypoints is\nlogarithmically bounded, exact polynomial-time algorithms exist even for\ngeneral graphs. Our two algorithms provide an almost complete characterization\nof what can be solved exactly in polynomial-time: we show that more general\nproblems (e.g., on grid graphs of maximum degree 3, with slightly more\nwaypoints) are computationally intractable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Demand Response in the Smart Grid: the Impact of Consumers Temporal Preferences.   In Demand Response programs, price incentives might not be sufficient to\nmodify residential consumers load profile. Here, we consider that each consumer\nhas a preferred profile and a discomfort cost when deviating from it. Consumers\ncan value this discomfort at a varying level that we take as a parameter. This\nwork analyses Demand Response as a game theoretic environment. We study the\nequilibria of the game between consumers with preferences within two different\ndynamic pricing mechanisms, respectively the daily proportional mechanism\nintroduced by Mohsenian-Rad et al, and an hourly proportional mechanism. We\ngive new results about equilibria as functions of the preference level in the\ncase of quadratic system costs and prove that, whatever the preference level,\nsystem costs are smaller with the hourly mechanism. We simulate the Demand\nResponse environment using real consumption data from PecanStreet database.\nWhile the Price of Anarchy remains always close to one up to 0.1% with the\nhourly mechanism, it can be more than 10% bigger with the daily mechanism.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Sequential MCMC for Combined State and Parameter Estimation.   In the case of a linear state space model, we implement an MCMC sampler with\ntwo phases. In the learning phase, a self-tuning sampler is used to learn the\nparameter mean and covariance structure. In the estimation phase, the parameter\nmean and covariance structure informs the proposed mechanism and is also used\nin a delayed-acceptance algorithm. Information on the resulting state of the\nsystem is given by a Gaussian mixture. In on-line mode, the algorithm is\nadaptive and uses a sliding window approach to accelerate sampling speed and to\nmaintain appropriate acceptance rates. We apply the algorithm to joined state\nand parameter estimation in the case of irregularly sampled GPS time series\ndata.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Goodness-of-fit tests for the functional linear model based on randomly projected empirical processes.   We consider marked empirical processes indexed by a randomly projected\nfunctional covariate to construct goodness-of-fit tests for the functional\nlinear model with scalar response. The test statistics are built from\ncontinuous functionals over the projected process, resulting in computationally\nefficient tests that exhibit root-n convergence rates and circumvent the curse\nof dimensionality. The weak convergence of the empirical process is obtained\nconditionally on a random direction, whilst the almost surely equivalence\nbetween the testing for significance expressed on the original and on the\nprojected functional covariate is proved. The computation of the test in\npractice involves calibration by wild bootstrap resampling and the combination\nof several p-values, arising from different projections, by means of the false\ndiscovery rate method. The finite sample properties of the tests are\nillustrated in a simulation study for a variety of linear models, underlying\nprocesses, and alternatives. The software provided implements the tests and\nallows the replication of simulations and data applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mixtures of Hidden Truncation Hyperbolic Factor Analyzers.   The mixture of factor analyzers model was first introduced over 20 years ago\nand, in the meantime, has been extended to several non-Gaussian analogues. In\ngeneral, these analogues account for situations with heavy tailed and/or skewed\nclusters. An approach is introduced that unifies many of these approaches into\none very general model: the mixture of hidden truncation hyperbolic factor\nanalyzers (MHTHFA) model. In the process of doing this, a hidden truncation\nhyperbolic factor analysis model is also introduced. The MHTHFA model is\nillustrated for clustering as well as semi-supervised classification using two\nreal datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Finding influential nodes for integration in brain networks using optimal percolation theory.   Global integration of information in the brain results from complex\ninteractions of segregated brain networks. Identifying the most influential\nneuronal populations that efficiently bind these networks is a fundamental\nproblem of systems neuroscience. Here we apply optimal percolation theory and\npharmacogenetic interventions in-vivo to predict and subsequently target nodes\nthat are essential for global integration of a memory network in rodents. The\ntheory predicts that integration in the memory network is mediated by a set of\nlow-degree nodes located in the nucleus accumbens. This result is confirmed\nwith pharmacogenetic inactivation of the nucleus accumbens, which eliminates\nthe formation of the memory network, while inactivations of other brain areas\nleave the network intact. Thus, optimal percolation theory predicts essential\nnodes in brain networks. This could be used to identify targets of\ninterventions to modulate brain function.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Projected Variational Integrators for Degenerate Lagrangian Systems.   We propose and compare several projection methods applied to variational\nintegrators for degenerate Lagrangian systems, whose Lagrangian is of the form\n$L = \\vartheta(q) \\cdot \\dot{q} - H(q)$ and thus linear in velocities. While\nprevious methods for such systems only work reliably in the case of $\\vartheta$\nbeing a linear function of $q$, our methods are long-time stable also for\nsystems where $\\vartheta$ is a nonlinear function of $q$. We analyse the\nproperties of the resulting algorithms, in particular with respect to the\nconservation of energy, momentum maps and symplecticity. In numerical\nexperiments, we verify the favourable properties of the projected integrators\nand demonstrate their excellent long-time fidelity. In particular, we consider\na two-dimensional Lotka-Volterra system, planar point vortices with\nposition-dependent circulation and guiding centre dynamics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Measurably entire functions and their growth.   In 1997 B. Weiss introduced the notion of measurably entire functions and\nproved that they exist on every arbitrary free C- action defined on standard\nprobability space. In the same paper he asked about the minimal possible growth\nof measurably entire functions. In this work we show that for every arbitrary\nfree C- action defined on a standard probability space there exists a\nmeasurably entire function whose growth does not exceed exp (exp[log^p |z|])\nfor any p > 3. This complements a recent result by Buhovski, Glücksam,\nLogunov, and Sodin (arXiv:1703.08101) who showed that such functions cannot\ngrow slower than exp (exp[log^p |z|]) for any p < 2.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Neural Network Based Speaker Classification and Verification Systems with Enhanced Features.   This work presents a novel framework based on feed-forward neural network for\ntext-independent speaker classification and verification, two related systems\nof speaker recognition. With optimized features and model training, it achieves\n100% classification rate in classification and less than 6% Equal Error Rate\n(ERR), using merely about 1 second and 5 seconds of data respectively. Features\nwith stricter Voice Active Detection (VAD) than the regular one for speech\nrecognition ensure extracting stronger voiced portion for speaker recognition,\nspeaker-level mean and variance normalization helps to eliminate the\ndiscrepancy between samples from the same speaker. Both are proven to improve\nthe system performance. In building the neural network speaker classifier, the\nnetwork structure parameters are optimized with grid search and dynamically\nreduced regularization parameters are used to avoid training terminated in\nlocal minimum. It enables the training goes further with lower cost. In speaker\nverification, performance is improved with prediction score normalization,\nwhich rewards the speaker identity indices with distinct peaks and penalizes\nthe weak ones with high scores but more competitors, and speaker-specific\nthresholding, which significantly reduces ERR in the ROC curve. TIMIT corpus\nwith 8K sampling rate is used here. First 200 male speakers are used to train\nand test the classification performance. The testing files of them are used as\nin-domain registered speakers, while data from the remaining 126 male speakers\nare used as out-of-domain speakers, i.e. imposters in speaker verification.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interleaving and Gromov-Hausdorff distance.   One of the central notions to emerge from the study of persistent homology is\nthat of interleaving distance. It has found recent applications in symplectic\nand contact geometry, sheaf theory, computational geometry, and phylogenetics.\nHere we present a general study of this topic. We define interleaving of\nfunctors with common codomain as solutions to an extension problem. In order to\ndefine interleaving distance in this setting we are led to categorical\ngeneralizations of Hausdorff distance, Gromov-Hausdorff distance, and the space\nof metric spaces. We obtain comparisons with previous notions of interleaving\nvia the study of future equivalences. As an application we recover a definition\nof shift equivalences of discrete dynamical systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multinomial Sum Formulas of Multiple Zeta Values.   For a pair of positive integers $n,k$ with $n\\geq 2$, in this paper we prove\nthat $$ \\sum_{r=1}^k\\sum_{|\\bf\\alpha|=k}{k\\choose\\bf\\alpha}\n\\zeta(n\\bf\\alpha)=\\zeta(n)^k =\\sum^k_{r=1}\\sum_{|\\bf\\alpha|=k}\n{k\\choose\\bf\\alpha}(-1)^{k-r}\\zeta^\\star(n\\bf\\alpha), $$ where\n$\\bf\\alpha=(\\alpha_1,\\alpha_2,\\ldots,\\alpha_r)$ is a $r$-tuple of positive\nintegers. Moreover, we give an application to combinatorics and get the\nfollowing identity: $$ \\sum^{2k}_{r=1}r!{2k\\brace\nr}=\\sum^k_{p=1}\\sum^k_{q=1}{k\\brace p}{k\\brace q} p!q!D(p,q), $$ where\n${k\\brace p}$ is the Stirling numbers of the second kind and $D(p,q)$ is the\nDelannoy number.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inference-Based Distributed Channel Allocation in Wireless Sensor Networks.   Interference-aware resource allocation of time slots and frequency channels\nin single-antenna, halfduplex radio wireless sensor networks (WSN) is\nchallenging. Devising distributed algorithms for such task further complicates\nthe problem. This work studiesWSN joint time and frequency channel allocation\nfor a given routing tree, such that: a) allocation is performed in a fully\ndistributed way, i.e., information exchange is only performed among neighboring\nWSN terminals, within communication up to two hops, and b) detection of\npotential interfering terminals is simplified and can be practically realized.\nThe algorithm imprints space, time, frequency and radio hardware constraints\ninto a loopy factor graph and performs iterative message passing/ loopy belief\npropagation (BP) with randomized initial priors. Sufficient conditions for\nconvergence to a valid solution are offered, for the first time in the\nliterature, exploiting the structure of the proposed factor graph. Based on\ntheoretical findings, modifications of BP are devised that i) accelerate\nconvergence to a valid solution and ii) reduce computation cost. Simulations\nreveal promising throughput results of the proposed distributed algorithm, even\nthough it utilizes simplified interfering terminals set detection. Future work\ncould modify the constraints such that other disruptive wireless technologies\n(e.g., full-duplex radios or network coding) could be accommodated within the\nsame inference framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the risk of convex-constrained least squares estimators under misspecification.   We consider the problem of estimating the mean of a noisy vector. When the\nmean lies in a convex constraint set, the least squares projection of the\nrandom vector onto the set is a natural estimator. Properties of the risk of\nthis estimator, such as its asymptotic behavior as the noise tends to zero,\nhave been well studied. We instead study the behavior of this estimator under\nmisspecification, that is, without the assumption that the mean lies in the\nconstraint set. For appropriately defined notions of risk in the misspecified\nsetting, we prove a generalization of a low noise characterization of the risk\ndue to Oymak and Hassibi in the case of a polyhedral constraint set. An\ninteresting consequence of our results is that the risk can be much smaller in\nthe misspecified setting than in the well-specified setting. We also discuss\nconsequences of our result for isotonic regression.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The inverse hull of 0-left cancellative semigroups.   Given a semigroup S with zero, which is left-cancellative in the sense that\nst=sr \\neq 0 implies that t=r, we construct an inverse semigroup called the\ninverse hull of S, denoted H(S). When S admits least common multiples, in a\nprecise sense defined below, we study the idempotent semilattice of H(S), with\na focus on its spectrum. When S arises as the language semigroup for a subsift\nX on a finite alphabet, we discuss the relationship between H(S) and several\nC*-algebras associated to X appearing in the literature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Object Centric Policies for Autonomous Driving.   While learning visuomotor skills in an end-to-end manner is appealing, deep\nneural networks are often uninterpretable and fail in surprising ways. For\nrobotics tasks, such as autonomous driving, models that explicitly represent\nobjects may be more robust to new scenes and provide intuitive visualizations.\nWe describe a taxonomy of object-centric models which leverage both object\ninstances and end-to-end learning. In the Grand Theft Auto V simulator, we show\nthat object centric models outperform object-agnostic methods in scenes with\nother vehicles and pedestrians, even with an imperfect detector. We also\ndemonstrate that our architectures perform well on real world environments by\nevaluating on the Berkeley DeepDrive Video dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quench-induced entanglement and relaxation dynamics in Luttinger liquids.   We investigate the time evolution towards the asymptotic steady state of a\none dimensional interacting system after a quantum quench. We show that at\nfinite time the latter induces entanglement between right- and left- moving\ndensity excitations, encoded in their cross-correlators, which vanishes in the\nlong-time limit. This behavior results in a universal time-decay in system\nspectral properties $ \\propto t^{-2} $, in addition to non-universal power-law\ncontributions typical of Luttinger liquids. Importantly, we argue that the\npresence of quench-induced entanglement clearly emerges in transport\nproperties, such as charge and energy currents injected in the system from a\nbiased probe, and determines their long-time dynamics. In particular, energy\nfractionalization phenomenon turns out to be a promising platform to observe\nthe universal power-law decay $ \\propto t^{-2} $ induced by entanglement and\nrepresents a novel way to study the corresponding relaxation mechanism.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weak Form of Stokes-Dirac Structures and Geometric Discretization of Port-Hamiltonian Systems.   We present the mixed Galerkin discretization of distributed parameter\nport-Hamiltonian systems. On the prototypical example of hyperbolic systems of\ntwo conservation laws in arbitrary spatial dimension, we derive the main\ncontributions: (i) A weak formulation of the underlying geometric\n(Stokes-Dirac) structure with a segmented boundary according to the causality\nof the boundary ports. (ii) The geometric approximation of the Stokes-Dirac\nstructure by a finite-dimensional Dirac structure is realized using a mixed\nGalerkin approach and power-preserving linear maps, which define minimal\ndiscrete power variables. (iii) With a consistent approximation of the\nHamiltonian, we obtain finite-dimensional port-Hamiltonian state space models.\nBy the degrees of freedom in the power-preserving maps, the resulting family of\nstructure-preserving schemes allows for trade-offs between centered\napproximations and upwinding. We illustrate the method on the example of\nWhitney finite elements on a 2D simplicial triangulation and compare the\neigenvalue approximation in 1D with a related approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Attention using a Fixed-Size Memory Representation.   The standard content-based attention mechanism typically used in\nsequence-to-sequence models is computationally expensive as it requires the\ncomparison of large encoder and decoder states at each time step. In this work,\nwe propose an alternative attention mechanism based on a fixed size memory\nrepresentation that is more efficient. Our technique predicts a compact set of\nK attention contexts during encoding and lets the decoder compute an efficient\nlookup that does not need to consult the memory. We show that our approach\nperforms on-par with the standard attention mechanism while yielding inference\nspeedups of 20% for real-world translation tasks and more for tasks with longer\nsequences. By visualizing attention scores we demonstrate that our models learn\ndistinct, meaningful alignments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Ensemble Classification Algorithm Based on Information Entropy for Data Streams.   Data stream mining problem has caused widely concerns in the area of machine\nlearning and data mining. In some recent studies, ensemble classification has\nbeen widely used in concept drift detection, however, most of them regard\nclassification accuracy as a criterion for judging whether concept drift\nhappening or not. Information entropy is an important and effective method for\nmeasuring uncertainty. Based on the information entropy theory, a new algorithm\nusing information entropy to evaluate a classification result is developed. It\nuses ensemble classification techniques, and the weight of each classifier is\ndecided through the entropy of the result produced by an ensemble classifiers\nsystem. When the concept in data streams changing, the classifiers' weight\nbelow a threshold value will be abandoned to adapt to a new concept in one\ntime. In the experimental analysis section, six databases and four proposed\nalgorithms are executed. The results show that the proposed method can not only\nhandle concept drift effectively, but also have a better classification\naccuracy and time performance than the contrastive algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multiresolution Tensor Decomposition for Multiple Spatial Passing Networks.   This article is motivated by soccer positional passing networks collected\nacross multiple games. We refer to these data as replicated spatial passing\nnetworks---to accurately model such data it is necessary to take into account\nthe spatial positions of the passer and receiver for each passing event. This\nspatial registration and replicates that occur across games represent key\ndifferences with usual social network data. As a key step before investigating\nhow the passing dynamics influence team performance, we focus on developing\nmethods for summarizing different team's passing strategies. Our proposed\napproach relies on a novel multiresolution data representation framework and\nPoisson nonnegative block term decomposition model, which automatically\nproduces coarse-to-fine low-rank network motifs. The proposed methods are\napplied to detailed passing record data collected from the 2014 FIFA World Cup.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A giant with feet of clay: on the validity of the data that feed machine learning in medicine.   This paper considers the use of Machine Learning (ML) in medicine by focusing\non the main problem that this computational approach has been aimed at solving\nor at least minimizing: uncertainty. To this aim, we point out how uncertainty\nis so ingrained in medicine that it biases also the representation of clinical\nphenomena, that is the very input of ML models, thus undermining the clinical\nsignificance of their output. Recognizing this can motivate both medical\ndoctors, in taking more responsibility in the development and use of these\ndecision aids, and the researchers, in pursuing different ways to assess the\nvalue of these systems. In so doing, both designers and users could take this\nintrinsic characteristic of medicine more seriously and consider alternative\napproaches that do not \"sweep uncertainty under the rug\" within an objectivist\nfiction, which everyone can come up by believing as true.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Photometric and radial-velocity time-series of RR Lyrae stars in M3: analysis of single-mode variables.   We present the first simultaneous photometric and spectroscopic investigation\nof a large set of RR Lyrae variables in a globular cluster. The radial-velocity\ndata presented comprise the largest sample of RVs of RR Lyrae stars ever\nobtained. The target is M3; $BVI_{\\mathrm{C}}$ time-series of 111 and $b$ flux\ndata of further 64 RRab stars, and RV data of 79 RR Lyrae stars are published.\nBlazhko modulation of the light curves of 47 percent of the RRab stars are\ndetected. The mean value of the center-of-mass velocities of RR Lyrae stars is\n$-146.8$ km s$^{-1}$ with 4.52 km s$^{-1}$ standard deviation, which is in good\nagreement with the results obtained for the red giants of the cluster. The\n${\\Phi_{21}}^{\\mathrm RV}$ phase difference of the RV curves of RRab stars is\nfound to be uniformly constant both for the M3 and for Galactic field RRab\nstars; no period or metallicity dependence of the ${\\Phi_{21}}^{\\mathrm RV}$ is\ndetected. The Baade-Wesselink distances of 26 non-Blazhko variables with the\nbest phase-coverage radial-velocity curves are determined; the corresponding\ndistance of the cluster, $10480\\pm210$ pc, agrees with the previous literature\ninformation. A quadratic formula for the $A_{\\mathrm{puls}}-A_V$ relation of\nRRab stars is given, which is valid for both OoI and OoII variables. We also\nshow that the $(V-I)_0$ of RRab stars measured at light minimum is period\ndependent, there is at least 0.1 mag difference between the colours at minimum\nlight of the shortest- and longest-period variables.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Simplifying branched covering surface-knots by chart moves involving black vertices.   A branched covering surface-knot is a surface-knot in the form of a branched\ncovering over an oriented surface-knot $F$, where we include the case when the\ncovering has no branch points. A branched covering surface-knot is presented by\na graph called a chart on a surface diagram of $F$. We can simplify a branched\ncovering surface-knot by an addition of 1-handles with chart loops to a form\nsuch that its chart is the union of free edges and 1-handles with chart loops.\nWe investigate properties of such simplifications for the case when branched\ncovering surface-knots have a non-zero number of branch points, using chart\nmoves involving black vertices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Game Efficiency through Linear Programming Duality.   The efficiency of a game is typically quantified by the price of anarchy\n(PoA), defined as the worst ratio of the objective function value of an\nequilibrium --- solution of the game --- and that of an optimal outcome. Given\nthe tremendous impact of tools from mathematical programming in the design of\nalgorithms and the similarity of the price of anarchy and different measures\nsuch as the approximation and competitive ratios, it is intriguing to develop a\nduality-based method to characterize the efficiency of games.\nIn the paper, we present an approach based on linear programming duality to\nstudy the efficiency of games. We show that the approach provides a general\nrecipe to analyze the efficiency of games and also to derive concepts leading\nto improvements. The approach is particularly appropriate to bound the PoA.\nSpecifically, in our approach the dual programs naturally lead to competitive\nPoA bounds that are (almost) optimal for several classes of games. The approach\nindeed captures the smoothness framework and also some current non-smooth\ntechniques/concepts. We show the applicability to the wide variety of games and\nenvironments, from congestion games to Bayesian welfare, from full-information\nsettings to incomplete-information ones.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-stationary Stochastic Optimization under $L_{p,q}$-Variation Measures.   We consider a non-stationary sequential stochastic optimization problem, in\nwhich the underlying cost functions change over time under a variation budget\nconstraint. We propose an $L_{p,q}$-variation functional to quantify the\nchange, which yields less variation for dynamic function sequences whose\nchanges are constrained to short time periods or small subsets of input domain.\nUnder the $L_{p,q}$-variation constraint, we derive both upper and matching\nlower regret bounds for smooth and strongly convex function sequences, which\ngeneralize previous results in Besbes et al. (2015). Furthermore, we provide an\nupper bound for general convex function sequences with noisy gradient feedback,\nwhich matches the optimal rate as $p\\to\\infty$. Our results reveal some\nsurprising phenomena under this general variation functional, such as the curse\nof dimensionality of the function domain. The key technical novelties in our\nanalysis include affinity lemmas that characterize the distance of the\nminimizers of two convex functions with bounded Lp difference, and a cubic\nspline based construction that attains matching lower bounds.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Repair Strategies for Storage on Mobile Clouds.   We study the data reliability problem for a community of devices forming a\nmobile cloud storage system. We consider the application of regenerating codes\nfor file maintenance within a geographically-limited area. Such codes require\nlower bandwidth to regenerate lost data fragments compared to file replication\nor reconstruction. We investigate threshold-based repair strategies where data\nrepair is initiated after a threshold number of data fragments have been lost\ndue to node mobility. We show that at a low departure-to-repair rate regime, a\nlazy repair strategy in which repairs are initiated after several nodes have\nleft the system outperforms eager repair in which repairs are initiated after a\nsingle departure. This optimality is reversed when nodes are highly mobile. We\nfurther compare distributed and centralized repair strategies and derive the\noptimal repair threshold for minimizing the average repair cost per unit of\ntime, as a function of underlying code parameters. In addition, we examine\ncooperative repair strategies and show performance improvements compared to\nnon-cooperative codes. We investigate several models for the time needed for\nnode repair including a simple fixed time model that allows for the computation\nof closed-form expressions and a more realistic model that takes into account\nthe number of repaired nodes. We derive the conditions under which the former\nmodel approximates the latter. Finally, an extended model where additional\nfailures are allowed during the repair process is investigated. Overall, our\nresults establish the joint effect of code design and repair algorithms on the\nmaintenance cost of distributed storage systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Origins of bond and spin order in rare-earth nickelate bulk and heterostructures.   We analyze the charge- and spin response functions of rare-earth nickelates\nRNiO3 and their heterostructures using random-phase approximation in a two-band\nHubbard model. The inter-orbital charge fluctuation is found to be the driving\nmechanism for the rock-salt type bond order in bulk RNiO3, and good agreement\nof the ordering temperature with experimental values is achieved for all RNiO3\nusing realistic crystal structures and interaction parameters. We further show\nthat magnetic ordering in bulk is not driven by the spin fluctuation and should\nbe instead explained as ordering of localized moments. This picture changes for\nlow-dimensional heterostructures, where the charge fluctuation is suppressed\nand overtaken by the enhanced spin instability, which results in a\nspin-density-wave ground state observed in recent experiments. Predictions for\nspectroscopy allow for further experimental testing of our claims.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Delayed pull-in transitions in overdamped MEMS devices.   We consider the dynamics of overdamped MEMS devices undergoing the pull-in\ninstability. Numerous previous experiments and numerical simulations have shown\na significant increase in the pull-in time under DC voltages close to the\npull-in voltage. Here the transient dynamics slow down as the device passes\nthrough a meta-stable or bottleneck phase, but this slowing down is not well\nunderstood quantitatively. Using a lumped parallel-plate model, we perform a\ndetailed analysis of the pull-in dynamics in this regime. We show that the\nbottleneck phenomenon is a type of critical slowing down arising from the\npull-in transition. This allows us to show that the pull-in time obeys an\ninverse square-root scaling law as the transition is approached; moreover we\ndetermine an analytical expression for this pull-in time. We then compare our\nprediction to a wide range of pull-in time data reported in the literature,\nshowing that the observed slowing down is well captured by our scaling law,\nwhich appears to be generic for overdamped pull-in under DC loads. This\nrealization provides a useful design rule with which to tune dynamic response\nin applications, including state-of-the-art accelerometers and pressure sensors\nthat use pull-in time as a sensing mechanism. We also propose a method to\nestimate the pull-in voltage based only on data of the pull-in times.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "code2vec: Learning Distributed Representations of Code.   We present a neural model for representing snippets of code as continuous\ndistributed vectors (\"code embeddings\"). The main idea is to represent a code\nsnippet as a single fixed-length $\\textit{code vector}$, which can be used to\npredict semantic properties of the snippet. This is performed by decomposing\ncode to a collection of paths in its abstract syntax tree, and learning the\natomic representation of each path $\\textit{simultaneously}$ with learning how\nto aggregate a set of them. We demonstrate the effectiveness of our approach by\nusing it to predict a method's name from the vector representation of its body.\nWe evaluate our approach by training a model on a dataset of 14M methods. We\nshow that code vectors trained on this dataset can predict method names from\nfiles that were completely unobserved during training. Furthermore, we show\nthat our model learns useful method name vectors that capture semantic\nsimilarities, combinations, and analogies. Comparing previous techniques over\nthe same data set, our approach obtains a relative improvement of over 75%,\nbeing the first to successfully predict method names based on a large,\ncross-project, corpus. Our trained model, visualizations and vector\nsimilarities are available as an interactive online demo at\nthis http URL. The code, data, and trained models are available at\nthis https URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cloaking for a quasi-linear elliptic partial differential equation.   In this article we consider cloaking for a quasi-linear elliptic partial\ndifferential equation of divergence type defined on a bounded domain in\n$\\mathbb{R}^N$ for $N=2,3$. We show that a perfect cloak can be obtained via a\nsingular change of variables scheme and an approximate cloak can be achieved\nvia a regular change of variables scheme. These approximate cloaks though\nnon-degenerate are anisotropic. We also show, within the framework of\nhomogenization, that it is possible to get isotropic regular approximate\ncloaks. This work generalizes to quasi-linear settings previous work on\ncloaking in the context of Electrical Impedance Tomography for the conductivity\nequation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uncertainty in Multitask Transfer Learning.   Using variational Bayes neural networks, we develop an algorithm capable of\naccumulating knowledge into a prior from multiple different tasks. The result\nis a rich and meaningful prior capable of few-shot learning on new tasks. The\nposterior can go beyond the mean field approximation and yields good\nuncertainty on the performed experiments. Analysis on toy tasks shows that it\ncan learn from significantly different tasks while finding similarities among\nthem. Experiments of Mini-Imagenet yields the new state of the art with 74.5%\naccuracy on 5 shot learning. Finally, we provide experiments showing that other\nexisting methods can fail to perform well in different benchmarks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Population of collective modes in light scattering by many atoms.   The interaction of light with an atomic sample containing a large number of\nparticles gives rise to many collective (or cooperative) effects, such as\nmultiple scattering, superradiance and subradiance, even if the atomic density\nis low and the incident optical intensity weak (linear optics regime). Tracing\nover the degrees of freedom of the light field, the system can be well\ndescribed by an effective atomic Hamiltonian, which contains the light-mediated\ndipole-dipole interaction between atoms. This long-range interaction is at the\norigin of the various collective effects, or of collective excitation modes of\nthe system. Even though an analysis of the eigenvalues and eigenfunctions of\nthese collective modes does allow distinguishing superradiant modes, for\ninstance, from other collective modes, this is not sufficient to understand the\ndynamics of a driven system, as not all collective modes are significantly\npopulated. Here, we study how the excitation parameters, i.e. the driving\nfield, determines the population of the collective modes. We investigate in\nparticular the role of the laser detuning from the atomic transition, and\ndemonstrate a simple relation between the detuning and the steady-state\npopulation of the modes. This relation allows understanding several properties\nof cooperative scattering, such as why superradiance and subradiance become\nindependent of the detuning at large enough detuning without vanishing, and why\nsuperradiance, but not subradiance, is suppressed near resonance.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Transient flows in active porous media.   Stimuli-responsive materials that modify their shape in response to changes\nin environmental conditions -- such as solute concentration, temperature, pH,\nand stress -- are widespread in nature and technology. Applications include\nmicro- and nanoporous materials used in filtration and flow control. The\nphysiochemical mechanisms that induce internal volume modifications have been\nwidely studies. The coupling between induced volume changes and solute\ntransport through porous materials, however, is not well understood. Here, we\nconsider advective and diffusive transport through a small channel linking two\nlarge reservoirs. A section of stimulus-responsive material regulates the\nchannel permeability, which is a function of the local solute concentration. We\nderive an exact solution to the coupled transport problem and demonstrate the\nexistence of a flow regime in which the steady state is reached via a damped\noscillation around the equilibrium concentration value. Finally, the\nfeasibility of an experimental observation of the phenomena is discussed.\nPlease note that this version of the paper has not been formally peer reviewed,\nrevised or accepted by a journal.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The asymptotic behavior of automorphism groups of function fields over finite fields.   The purpose of this paper is to investigate the asymptotic behavior of\nautomorphism groups of function fields when genus tends to infinity.\nMotivated by applications in coding and cryptography, we consider the maximum\nsize of abelian subgroups of the automorphism group\n$\\mbox{Aut}(F/\\mathbb{F}_q)$ in terms of genus ${g_F}$ for a function field $F$\nover a finite field $\\mathbb{F}_q$. Although the whole group\n$\\mbox{Aut}(F/\\mathbb{F}_q)$ could have size $\\Omega({g_F}^4)$, the maximum\nsize $m_F$ of abelian subgroups of the automorphism group\n$\\mbox{Aut}(F/\\mathbb{F}_q)$ is upper bounded by $4g_F+4$ for $g_F\\ge 2$. In\nthe present paper, we study the asymptotic behavior of $m_F$ by defining\n$M_q=\\limsup_{{g_F}\\rightarrow\\infty}\\frac{m_F \\cdot \\log_q m_F}{g_F}$, where\n$F$ runs through all function fields over $\\mathbb{F}_q$. We show that $M_q$\nlies between $2$ and $3$ (or $4$) for odd characteristic (or for even\ncharacteristic, respectively). This means that $m_F$ grows much more slowly\nthan genus does asymptotically.\nThe second part of this paper is to study the maximum size $b_F$ of subgroups\nof $\\mbox{Aut}(F/\\mathbb{F}_q)$ whose order is coprime to $q$. The Hurwitz\nbound gives an upper bound $b_F\\le 84(g_F-1)$ for every function field\n$F/\\mathbb{F}_q$ of genus $g_F\\ge 2$. We investigate the asymptotic behavior of\n$b_F$ by defining ${B_q}=\\limsup_{{g_F}\\rightarrow\\infty}\\frac{b_F}{g_F}$,\nwhere $F$ runs through all function fields over $\\mathbb{F}_q$. Although the\nHurwitz bound shows ${B_q}\\le 84$, there are no lower bounds on $B_q$ in\nliterature. One does not even know if ${B_q}=0$. For the first time, we show\nthat ${B_q}\\ge 2/3$ by explicitly constructing some towers of function fields\nin this paper.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Training L1-Regularized Models with Orthant-Wise Passive Descent Algorithms.   The $L_1$-regularized models are widely used for sparse regression or\nclassification tasks. In this paper, we propose the orthant-wise passive\ndescent algorithm (OPDA) for optimizing $L_1$-regularized models, as an\nimproved substitute of proximal algorithms, which are the standard tools for\noptimizing the models nowadays. OPDA uses a stochastic variance-reduced\ngradient (SVRG) to initialize the descent direction, then apply a novel\nalignment operator to encourage each element keeping the same sign after one\niteration of update, so the parameter remains in the same orthant as before. It\nalso explicitly suppresses the magnitude of each element to impose sparsity.\nThe quasi-Newton update can be utilized to incorporate curvature information\nand accelerate the speed. We prove a linear convergence rate for OPDA on\ngeneral smooth and strongly-convex loss functions. By conducting experiments on\n$L_1$-regularized logistic regression and convolutional neural networks, we\nshow that OPDA outperforms state-of-the-art stochastic proximal algorithms,\nimplying a wide range of applications in training sparse models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Secrecy and Robustness for Active Attack in Secure Network Coding and its Application to Network Quantum Key Distribution.   In network coding, we discuss the effect of sequential error injection on\ninformation leakage. We show that there is no improvement when the operations\nin the network are linear operations. However, when the operations in the\nnetwork contains non-linear operations, we find a counterexample to improve\nEve's obtained information. Furthermore, we discuss the asymptotic rate in a\nlinear network under the secrecy and robustness conditions as well as under the\nsecrecy condition alone. Finally, we apply our results to network quantum key\ndistribution, which clarifies the type of network that enables us to realize\nsecure long distance communication via short distance quantum key distribution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exact Tensor Completion from Sparsely Corrupted Observations via Convex Optimization.   This paper conducts a rigorous analysis for provable estimation of\nmultidimensional arrays, in particular third-order tensors, from a random\nsubset of its corrupted entries. Our study rests heavily on a recently proposed\ntensor algebraic framework in which we can obtain tensor singular value\ndecomposition (t-SVD) that is similar to the SVD for matrices, and define a new\nnotion of tensor rank referred to as the tubal rank. We prove that by simply\nsolving a convex program, which minimizes a weighted combination of tubal\nnuclear norm, a convex surrogate for the tubal rank, and the $\\ell_1$-norm, one\ncan recover an incoherent tensor exactly with overwhelming probability,\nprovided that its tubal rank is not too large and that the corruptions are\nreasonably sparse. Interestingly, our result includes the recovery guarantees\nfor the problems of tensor completion (TC) and tensor principal component\nanalysis (TRPCA) under the same algebraic setup as special cases. An\nalternating direction method of multipliers (ADMM) algorithm is presented to\nsolve this optimization problem. Numerical experiments verify our theory and\nreal-world applications demonstrate the effectiveness of our algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inferring health conditions from fMRI-graph data.   Automated classification methods for disease diagnosis are currently in the\nlimelight, especially for imaging data. Classification does not fully meet a\nclinician's needs, however: in order to combine the results of multiple tests\nand decide on a course of treatment, a clinician needs the likelihood of a\ngiven health condition rather than binary classification yielded by such\nmethods. We illustrate how likelihoods can be derived step by step from first\nprinciples and approximations, and how they can be assessed and selected,\nillustrating our approach using fMRI data from a publicly available data set\ncontaining schizophrenic and healthy control subjects. We start from the basic\nassumption of partial exchangeability, and then the notion of sufficient\nstatistics and the \"method of translation\" (Edgeworth, 1898) combined with\nconjugate priors. This method can be used to construct a likelihood that can be\nused to compare different data-reduction algorithms. Despite the\nsimplifications and possibly unrealistic assumptions used to illustrate the\nmethod, we obtain classification results comparable to previous, more realistic\nstudies about schizophrenia, whilst yielding likelihoods that can naturally be\ncombined with the results of other diagnostic tests.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Behavioural Change Support Intelligent Transportation Applications.   This workshop invites researchers and practitioners to participate in\nexploring behavioral change support intelligent transportation applications. We\nwelcome submissions that explore intelligent transportation systems (ITS),\nwhich interact with travelers in order to persuade them or nudge them towards\nsustainable transportation behaviors and decisions. Emerging opportunities\nincluding the use of data and information generated by ITS and users' mobile\ndevices in order to render personalized, contextualized and timely transport\nbehavioral change interventions are in our focus. We invite submissions and\nideas from domains of ITS including, but not limited to, multi-modal journey\nplanners, advanced traveler information systems and in-vehicle systems. The\nexpected outcome will be a deeper understanding of the challenges and future\nresearch directions with respect to behavioral change support through ITS.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Models of the strongly lensed quasar DES J0408-5354.   We present gravitational lens models of the multiply imaged quasar DES\nJ0408-5354, recently discovered in the Dark Energy Survey (DES) footprint, with\nthe aim of interpreting its remarkable quad-like configuration. We first model\nthe DES single-epoch $grizY$ images as a superposition of a lens galaxy and\nfour point-like objects, obtaining spectral energy distributions (SEDs) and\nrelative positions for the objects. Three of the point sources (A,B,D) have\nSEDs compatible with the discovery quasar spectra, while the faintest\npoint-like image (G2/C) shows significant reddening and a `grey' dimming of\n$\\approx0.8$mag. In order to understand the lens configuration, we fit\ndifferent models to the relative positions of A,B,D. Models with just a single\ndeflector predict a fourth image at the location of G2/C but considerably\nbrighter and bluer. The addition of a small satellite galaxy ($R_{\\rm\nE}\\approx0.2$\") in the lens plane near the position of G2/C suppresses the flux\nof the fourth image and can explain both the reddening and grey dimming. All\nmodels predict a main deflector with Einstein radius between $1.7\"$ and $2.0\",$\nvelocity dispersion $267-280$km/s and enclosed mass $\\approx\n6\\times10^{11}M_{\\odot},$ even though higher resolution imaging data are needed\nto break residual degeneracies in model parameters. The longest time-delay\n(B-A) is estimated as $\\approx 85$ (resp. $\\approx125$) days by models with\n(resp. without) a perturber near G2/C. The configuration and predicted\ntime-delays of J0408-5354 make it an excellent target for follow-up aimed at\nunderstanding the source quasar host galaxy and substructure in the lens, and\nmeasuring cosmological parameters. We also discuss some lessons learnt from\nJ0408-5354 on lensed quasar finding strategies, due to its chromaticity and\nmorphology.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Competitive Equilibrium For almost All Incomes.   Competitive equilibrium from equal incomes (CEEI) is a well-known rule for\nfair allocation of resources among agents with different preferences. It has\nmany advantages, among them is the fact that a CEEI allocation is both Pareto\nefficient and envy-free. However, when the resources are indivisible, a CEEI\nallocation might not exist even when there are two agents and a single item.\nIn contrast to this discouraging non-existence result, Babaioff, Nisan and\nTalgam-Cohen (2017) recently suggested a new and more encouraging approach to\nallocation of indivisible items: instead of insisting that the incomes be\nequal, they suggest to look at the entire space of possible incomes, and check\nwhether there exists a competitive equilibrium for almost all income-vectors\n(CEFAI) --- all income-space except a subset of measure zero. They show that a\nCEFAI exists when there are at most 3 items, or when there are 4 items and two\nagents. They also show that when there are 5 items and two agents there might\nnot exist a CEFAI. They leave open the cases of 4 items with three or four\nagents.\nThis paper presents a new way to implement a CEFAI, as a subgame-perfect\nequilibrium of a sequential game. This new implementation allows us both to\noffer much simpler solutions to the known cases (at most 3 items, and 4 items\nwith two agents), and to prove that a CEFAI exists even in the much more\ndifficult case of 4 items and three agents. Moreover, we prove that a CEFAI\nmight not exist with 4 items and four agents. When the items to be divided are\nbads (chores), CEFAI exists for two agents with at most 4 chores, but does not\nexist for two agents with 5 chores or with three agents with 3 or more chores.\nThus, this paper completes the characterization of CEFAI existence for monotone\npreferences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Extend of the $\\mathbb{Z}_2$-spin liquid phase on the Kagomé-lattice.   The $\\mathbb{Z}_2$ topological phase in the quantum dimer model on the\nKagomé-lattice is a candidate for the description of the low-energy physics\nof the anti-ferromagnetic Heisenberg model on the same lattice. We study the\nextend of the topological phase by interpolating between the exactly solvable\nparent Hamiltonian of the topological phase and an effective low-energy\ndescription of the Heisenberg model in terms of a quantum-dimer Hamiltonian.\nTherefore, we perform a perturbative treatment of the low-energy excitations in\nthe topological phase including free and interacting quasi-particles. We find a\nphase transition out of the topological phase far from the Heisenberg point.\nThe resulting phase is characterized by a spontaneously broken rotational\nsymmetry and a unit cell involving six sites.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Efficient Regret Minimization in Non-Convex Games.   We consider regret minimization in repeated games with non-convex loss\nfunctions. Minimizing the standard notion of regret is computationally\nintractable. Thus, we define a natural notion of regret which permits efficient\noptimization and generalizes offline guarantees for convergence to an\napproximate local optimum. We give gradient-based methods that achieve optimal\nregret, which in turn guarantee convergence to equilibrium in this framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological quantization of energy transport in micro- and nano-mechanical lattices.   Topological effects typically discussed in the context of quantum physics are\nemerging as one of the central paradigms of physics. Here, we demonstrate the\nrole of topology in energy transport through dimerized micro- and\nnano-mechanical lattices in the classical regime, i.e., essentially \"masses and\nsprings\". We show that the thermal conductance factorizes into topological and\nnon-topological components. The former takes on three discrete values and\narises due to the appearance of edge modes that prevent good contact between\nthe heat reservoirs and the bulk, giving a length-independent reduction of the\nconductance. In essence, energy input at the boundary mostly stays there, an\neffect robust against disorder and nonlinearity. These results bridge two\nseemingly disconnected disciplines of physics, namely topology and thermal\ntransport, and suggest ways to engineer thermal contacts, opening a direction\nto explore the ramifications of topological properties on nanoscale technology.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Phonetic-attention scoring for deep speaker features in speaker verification.   Recent studies have shown that frame-level deep speaker features can be\nderived from a deep neural network with the training target set to discriminate\nspeakers by a short speech segment. By pooling the frame-level features,\nutterance-level representations, called d-vectors, can be derived and used in\nthe automatic speaker verification (ASV) task. This simple average pooling,\nhowever, is inherently sensitive to the phonetic content of the utterance. An\ninteresting idea borrowed from machine translation is the attention-based\nmechanism, where the contribution of an input word to the translation at a\nparticular time is weighted by an attention score. This score reflects the\nrelevance of the input word and the present translation. We can use the same\nidea to align utterances with different phonetic contents. This paper proposes\na phonetic-attention scoring approach for d-vector systems. By this approach,\nan attention score is computed for each frame pair. This score reflects the\nsimilarity of the two frames in phonetic content, and is used to weigh the\ncontribution of this frame pair in the utterance-based scoring. This new\nscoring approach emphasizes the frame pairs with similar phonetic contents,\nwhich essentially provides a soft alignment for utterances with any phonetic\ncontents. Experimental results show that compared with the naive average\npooling, this phonetic-attention scoring approach can deliver consistent\nperformance improvement in ASV tasks of both text-dependent and\ntext-independent.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Giant interfacial perpendicular magnetic anisotropy in Fe/CuIn$_{1-x}$Ga$_x$Se$_2$ beyond Fe/MgO.   We study interfacial magnetocrystalline anisotropies in various\nFe/semiconductor heterostructures by means of first-principles calculations. We\nfind that many of those systems show perpendicular magnetic anisotropy (PMA)\nwith a positive value of the interfacial anisotropy constant $K_{\\rm i}$. In\nparticular, the Fe/CuInSe$_2$ interface has a large $K_{\\rm i}$ of $\\sim\n2.3\\,{\\rm mJ/m^2}$, which is about 1.6 times larger than that of Fe/MgO known\nas a typical system with relatively large PMA. We also find that the values of\n$K_{\\rm i}$ in almost all the systems studied in this work follow the\nwell-known Bruno's relation, which indicates that minority-spin states around\nthe Fermi level provide dominant contributions to the interfacial\nmagnetocrystalline anisotropies. Detailed analyses of the local density of\nstates and wave-vector-resolved anisotropy energy clarify that the large\n$K_{\\rm i}$ in Fe/CuInSe$_2$ is attributed to the preferable $3d$-orbital\nconfigurations around the Fermi level in the minority-spin states of the\ninterfacial Fe atoms. Moreover, we have shown that the locations of interfacial\nSe atoms are the key for such orbital configurations of the interfacial Fe\natoms.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Solvability regions of affinely parameterized quadratic equations.   Quadratic systems of equations appear in several applications. The results in\nthis paper are motivated by quadratic systems of equations that describe\nequilibrium behavior of physical infrastructure networks like the power and gas\ngrids. The quadratic systems in infrastructure networks are parameterized- the\nparameters can represent uncertainty (estimation error in resistance/inductance\nof a power transmission line, for example)or controllable decision variables\n(power outputs of generators,for example). It is then of interest to understand\nconditions on the parameters under which the quadratic system is guaranteed to\nhave a solution within a specified set (for example, bounds on voltages and\nflows in a power grid). Given nominal values of the parameters at which the\nquadratic system has a solution and the Jacobian of the quadratic system at the\nsolution i snon-singular, we develop a general framework to construct convex\nregions around the nominal value such that the system is guaranteed to have a\nsolution within a given distance of the nominal solution. We show that several\nresults from recen tliterature can be recovered as special cases of our\nframework,and demonstrate our approach on several benchmark power systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Rigorous proof of the Boltzmann-Gibbs distribution of money on connected graphs.   Models in econophysics, i.e., the emerging field of statistical physics that\napplies the main concepts of traditional physics to economics, typically\nconsist of large systems of economic agents who are characterized by the amount\nof money they have. In the simplest model, at each time step, one agent gives\none dollar to another agent, with both agents being chosen independently and\nuniformly at random from the system. Numerical simulations of this model\nsuggest that, at least when the number of agents and the average amount of\nmoney per agent are large, the distribution of money converges to an\nexponential distribution reminiscent of the Boltzmann-Gibbs distribution of\nenergy in physics. The main objective of this paper is to give a rigorous proof\nof this result and show that the convergence to the exponential distribution is\nuniversal in the sense that it holds more generally when the economic agents\nare located on the vertices of a connected graph and interact locally with\ntheir neighbors rather than globally with all the other agents. We also study a\nclosely related model where, at each time step, agents buy with a probability\nproportional to the amount of money they have, and prove that in this case the\nlimiting distribution of money is Poissonian.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectroscopic evidence of odd frequency superconducting order.   Spin filter superconducting S/I/N tunnel junctions (NbN/GdN/TiN) show a\nrobust and pronounced zero bias conductance peak at low temperatures, the\nmagnitude of which is several times the normal state conductance of the\njunction. Such a conductance anomaly is representative of unconventional\nsuperconductivity and is interpreted as a direct signature of an odd frequency\nsuperconducting order.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Cross-lingual Distillation for Text Classification.   Cross-lingual text classification(CLTC) is the task of classifying documents\nwritten in different languages into the same taxonomy of categories. This paper\npresents a novel approach to CLTC that builds on model distillation, which\nadapts and extends a framework originally proposed for model compression. Using\nsoft probabilistic predictions for the documents in a label-rich language as\nthe (induced) supervisory labels in a parallel corpus of documents, we train\nclassifiers successfully for new languages in which labeled training data are\nnot available. An adversarial feature adaptation technique is also applied\nduring the model training to reduce distribution mismatch. We conducted\nexperiments on two benchmark CLTC datasets, treating English as the source\nlanguage and German, French, Japan and Chinese as the unlabeled target\nlanguages. The proposed approach had the advantageous or comparable performance\nof the other state-of-art methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On zeros of polynomials in best $L^p$-approximation and inserting mass points.   The purpose of this note is to revive in $L^p$ spaces the original A. Markov\nideas to study monotonicity of zeros of orthogonal polynomials. This allows us\nto prove and improve in a simple and unified way our previous result [Electron.\nTrans. Numer. Anal., 44 (2015), pp. 271-280] concerning the discrete version of\nA. Markov's theorem on monotonicity of zeros.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SONS: The JCMT legacy survey of debris discs in the submillimetre.   Debris discs are evidence of the ongoing destructive collisions between\nplanetesimals, and their presence around stars also suggests that planets exist\nin these systems. In this paper, we present submillimetre images of the thermal\nemission from debris discs that formed the SCUBA-2 Observations of Nearby Stars\n(SONS) survey, one of seven legacy surveys undertaken on the James Clerk\nMaxwell telescope between 2012 and 2015. The overall results of the survey are\npresented in the form of 850 microns (and 450 microns, where possible) images\nand fluxes for the observed fields. Excess thermal emission, over that expected\nfrom the stellar photosphere, is detected around 49 stars out of the 100\nobserved fields. The discs are characterised in terms of their flux density,\nsize (radial distribution of the dust) and derived dust properties from their\nspectral energy distributions. The results show discs over a range of sizes,\ntypically 1-10 times the diameter of the Edgeworth-Kuiper Belt in our Solar\nSystem. The mass of a disc, for particles up to a few millimetres in size, is\nuniquely obtainable with submillimetre observations and this quantity is\npresented as a function of the host stars' age, showing a tentative decline in\nmass with age. Having doubled the number of imaged discs at submillimetre\nwavelengths from ground-based, single dish telescope observations, one of the\nkey legacy products from the SONS survey is to provide a comprehensive target\nlist to observe at high angular resolution using submillimetre/millimetre\ninterferometers (e.g., ALMA, SMA).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ordered p-median problems with neighborhoods.   In this paper, we introduce a new variant of the $p$-median facility location\nproblem in which it is assumed that the exact location of the potential\nfacilities is unknown. Instead, each of the facilities must be located in a\nregion around their initially assigned location (the neighborhood). In this\nproblem, two main decisions have to be made simultaneously: the determination\nof the potential facilities that must be open to serve the demands of the\ncustomers and the location of the open facilities in their neighborhoods, at\nglobal minimum cost. We present several mixed integer non-linear programming\nformulations for a wide family of objective functions which are common in\nLocation Analysis: ordered median functions. We also develop two math-heuristic\napproaches for solving the problem. We report the results of extensive\ncomputational experiments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exponential error rates of SDP for block models: Beyond Grothendieck's inequality.   In this paper we consider the cluster estimation problem under the Stochastic\nBlock Model. We show that the semidefinite programming (SDP) formulation for\nthis problem achieves an error rate that decays exponentially in the\nsignal-to-noise ratio. The error bound implies weak recovery in the sparse\ngraph regime with bounded expected degrees, as well as exact recovery in the\ndense regime. An immediate corollary of our results yields error bounds under\nthe Censored Block Model. Moreover, these error bounds are robust, continuing\nto hold under heterogeneous edge probabilities and a form of the so-called\nmonotone attack.\nSignificantly, this error rate is achieved by the SDP solution itself without\nany further pre- or post-processing, and improves upon existing\npolynomially-decaying error bounds proved using the Grothendieck\\textquoteright\ns inequality. Our analysis has two key ingredients: (i) showing that the graph\nhas a well-behaved spectrum, even in the sparse regime, after discounting an\nexponentially small number of edges, and (ii) an order-statistics argument that\ngoverns the final error rate. Both arguments highlight the implicit\nregularization effect of the SDP formulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Virtual retraction and Howson's theorem in pro-$p$ groups.   We show that for every finitely generated closed subgroup $K$ of a\nnon-solvable Demushkin group $G$, there exists an open subgroup $U$ of $G$\ncontaining $K$, and a continuous homomorphism $\\tau \\colon U \\to K$ satisfying\n$\\tau(k) = k$ for every $k \\in K$. We prove that the intersection of a pair of\nfinitely generated closed subgroups of a Demushkin group is finitely generated\n(giving an explicit bound on the number of generators). Furthermore, we show\nthat these properties of Demushkin groups are preserved under free pro-$p$\nproducts, and deduce that Howson's theorem holds for the Sylow subgroups of the\nabsolute Galois group of a number field. Finally, we confirm two conjectures of\nRibes, thus classifying the finitely generated pro-$p$ M. Hall groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convergence analysis of the information matrix in Gaussian belief propagation.   Gaussian belief propagation (BP) has been widely used for distributed\nestimation in large-scale networks such as the smart grid, communication\nnetworks, and social networks, where local measurements/observations are\nscattered over a wide geographical area. However, the convergence of Gaus- sian\nBP is still an open issue. In this paper, we consider the convergence of\nGaussian BP, focusing in particular on the convergence of the information\nmatrix. We show analytically that the exchanged message information matrix\nconverges for arbitrary positive semidefinite initial value, and its dis- tance\nto the unique positive definite limit matrix decreases exponentially fast.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Event-Triggered Control for Global Consensus of Multi-Agent Systems with Input Saturation.   We consider the global consensus problem for multi-agent systems with input\nsaturation over digraphs. Under a mild connectivity condition that the\nunderlying digraph has a directed spanning tree, we use Lyapunov methods to\nshow that the widely used distributed consensus protocol, which solves the\nconsensus problem for the case without input saturation constraints, also\nsolves the global consensus problem for the case with input saturation\nconstraints. In order to reduce the overall need of communication and system\nupdates, we then propose a distributed event-triggered control law. Global\nconsensus is still realized and Zeno behavior is excluded. Numerical\nsimulations are provided to illustrate the effectiveness of the theoretical\nresults.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Atomic-scale identification of novel planar defect phases in heteroepitaxial YBa$_2$Cu$_3$O$_{7-δ}$ thin films.   We have discovered two novel types of planar defects that appear in\nheteroepitaxial YBa$_2$Cu$_3$O$_{7-\\delta}$ (YBCO123) thin films, grown by\npulsed-laser deposition (PLD) either with or without a\nLa$_{2/3}$Ca$_{1/3}$MnO$_3$ (LCMO) overlayer, using the combination of\nhigh-angle annular dark-field scanning transmission electron microscopy\n(HAADF-STEM) imaging and electron energy loss spectroscopy (EELS) mapping for\nunambiguous identification. These planar lattice defects are based on the\nintergrowth of either a BaO plane between two CuO chains or multiple Y-O layers\nbetween two CuO$_2$ planes, resulting in non-stoichiometric layer sequences\nthat could directly impact the high-$T_c$ superconductivity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Tracking Emerges by Colorizing Videos.   We use large amounts of unlabeled video to learn models for visual tracking\nwithout manual human supervision. We leverage the natural temporal coherency of\ncolor to create a model that learns to colorize gray-scale videos by copying\ncolors from a reference frame. Quantitative and qualitative experiments suggest\nthat this task causes the model to automatically learn to track visual regions.\nAlthough the model is trained without any ground-truth labels, our method\nlearns to track well enough to outperform the latest methods based on optical\nflow. Moreover, our results suggest that failures to track are correlated with\nfailures to colorize, indicating that advancing video colorization may further\nimprove self-supervised visual tracking.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Directional convexity of harmonic mappings.   The convolution properties are discussed for the complex-valued harmonic\nfunctions in the unit disk $\\mathbb{D}$ constructed from the harmonic shearing\nof the analytic function $\\phi(z):=\\int_0^z\n(1/(1-2\\xi\\textit{e}^{\\textit{i}\\mu}\\cos\\nu+\\xi^2\\textit{e}^{2\\textit{i}\\mu}))\\textit{d}\\xi$,\nwhere $\\mu$ and $\\nu$ are real numbers. For any real number $\\alpha$ and\nharmonic function $f=h+\\overline{g}$, define an analytic function\n$f_{\\alpha}:=h+\\textit{e}^{-2\\textit{i}\\alpha}g$. Let $\\mu_1$ and $\\mu_2$\n$(\\mu_1+\\mu_2=\\mu)$ be real numbers, and $f=h+\\overline{g}$ and\n$F=H+\\overline{G}$ be locally-univalent and sense-preserving harmonic functions\nsuch that $f_{\\mu_1}*F_{\\mu_2}=\\phi$. It is shown that the convolution $f*F$ is\nunivalent and convex in the direction of $-\\mu$, provided it is locally\nunivalent and sense-preserving. Also, local-univalence of the above convolution\n$f*F$ is shown for some specific analytic dilatations of $f$ and $F$.\nFurthermore, if $g\\equiv0$ and both the analytic functions $f_{\\mu_1}$ and\n$F_{\\mu_2}$ are convex, then the convolution $f*F$ is shown to be convex. These\nresults extends the work done by Dorff \\textit{et al.} to a larger class of\nfunctions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Semidefinite Relaxation-Based Optimization of Multiple-Input Wireless Power Transfer Systems.   An optimization procedure for multi-transmitter (MISO) wireless power\ntransfer (WPT) systems based on tight semidefinite relaxation (SDR) is\npresented. This method ensures physical realizability of MISO WPT systems\ndesigned via convex optimization -- a robust, semi-analytical and intuitive\nroute to optimizing such systems. To that end, the nonconvex constraints\nrequiring that power is fed into rather than drawn from the system via all\ntransmitter ports are incorporated in a convex semidefinite relaxation, which\nis efficiently and reliably solvable by dedicated algorithms. A test of the\nsolution then confirms that this modified problem is equivalent (tight\nrelaxation) to the original (nonconvex) one and that the true global optimum\nhas been found. This is a clear advantage over global optimization methods\n(e.g. genetic algorithms), where convergence to the true global optimum cannot\nbe ensured or tested. Discussions of numerical results yielded by both the\nclosed-form expressions and the refined technique illustrate the importance and\npracticability of the new method. It, is shown that this technique offers a\nrigorous optimization framework for a broad range of current and emerging WPT\napplications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Shapley effects for sensitivity analysis with correlated inputs: comparisons with Sobol' indices, numerical estimation and applications.   The global sensitivity analysis of a numerical model aims to quantify, by\nmeans of sensitivity indices estimate, the contributions of each uncertain\ninput variable to the model output uncertainty. The so-called Sobol' indices,\nwhich are based on the functional variance analysis, present a difficult\ninterpretation in the presence of statistical dependence between inputs. The\nShapley effect was recently introduced to overcome this problem as they\nallocate the mutual contribution (due to correlation and interaction) of a\ngroup of inputs to each individual input within the group.In this paper, using\nseveral new analytical results, we study the effects of linear correlation\nbetween some Gaussian input variables on Shapley effects, and compare these\neffects to classical first-order and total Sobol' indices.This illustrates the\ninterest, in terms of sensitivity analysis setting and interpretation, of the\nShapley effects in the case of dependent inputs. We also investigate the\nnumerical convergence of the estimated Shapley effects. For the practical issue\nof computationally demanding computer models, we show that the substitution of\nthe original model by a metamodel (here, kriging) makes it possible to estimate\nthese indices with precision at a reasonable computational cost.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sparse Approximation of 3D Meshes using the Spectral Geometry of the Hamiltonian Operator.   The discrete Laplace operator is ubiquitous in spectral shape analysis, since\nits eigenfunctions are provably optimal in representing smooth functions\ndefined on the surface of the shape. Indeed, subspaces defined by its\neigenfunctions have been utilized for shape compression, treating the\ncoordinates as smooth functions defined on the given surface. However, surfaces\nof shapes in nature often contain geometric structures for which the general\nsmoothness assumption may fail to hold. At the other end, some explicit mesh\ncompression algorithms utilize the order by which vertices that represent the\nsurface are traversed, a property which has been ignored in spectral\napproaches. Here, we incorporate the order of vertices into an operator that\ndefines a novel spectral domain. We propose a method for representing 3D meshes\nusing the spectral geometry of the Hamiltonian operator, integrated within a\nsparse approximation framework. We adapt the concept of a potential function\nfrom quantum physics and incorporate vertex ordering information into the\npotential, yielding a novel data-dependent operator. The potential function\nmodifies the spectral geometry of the Laplacian to focus on regions with finer\ndetails of the given surface. By sparsely encoding the geometry of the shape\nusing the proposed data-dependent basis, we improve compression performance\ncompared to previous results that use the standard Laplacian basis and spectral\ngraph wavelets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "WKB solutions of difference equations and reconstruction by the topological recursion.   The purpose of this article is to analyze the connection between\nEynard-Orantin topological recursion and formal WKB solutions of a\n$\\hbar$-difference equation: $\\Psi(x+\\hbar)=\\left(e^{\\hbar\\frac{d}{dx}}\\right)\n\\Psi(x)=L(x;\\hbar)\\Psi(x)$ with $L(x;\\hbar)\\in GL_2( (\\mathbb{C}(x))[\\hbar])$.\nIn particular, we extend the notion of determinantal formulas and topological\ntype property proposed for formal WKB solutions of $\\hbar$-differential systems\nto this setting. We apply our results to a specific $\\hbar$-difference system\nassociated to the quantum curve of the Gromov-Witten invariants of\n$\\mathbb{P}^1$ for which we are able to prove that the correlation functions\nare reconstructed from the Eynard-Orantin differentials computed from the\ntopological recursion applied to the spectral curve $y=\\cosh^{-1}\\frac{x}{2}$.\nFinally, identifying the large $x$ expansion of the correlation functions,\nproves a recent conjecture made by B. Dubrovin and D. Yang regarding a new\ngenerating series for Gromov-Witten invariants of $\\mathbb{P}^1$.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Fates of the dense cores formed by fragmentation of filaments: do they fragment again or not?.   Fragmentation of filaments into dense cores is thought to be an important\nstep in forming stars. The bar-mode instability of spherically collapsing cores\nfound in previous linear analysis invokes a possibility of re-fragmentation of\nthe cores due to their ellipsoidal (prolate or oblate) deformation. To\ninvestigate this possibility, here we perform three-dimensional\nself-gravitational hydrodynamics simulations that follow all the way from\nfilament fragmentation to subsequent core collapse. We assume the gas is\npolytropic with index \\gamma, which determines the stability of the bar-mode.\nFor the case that the fragmentation of isolated hydrostatic filaments is\ntriggered by the most unstable fragmentation mode, we find the bar mode grows\nas collapse proceeds if \\gamma < 1.1, in agreement with the linear analysis.\nHowever, it takes more than ten orders-of-magnitude increase in the central\ndensity for the distortion to become non-linear. In addition to this fiducial\ncase, we also study non-fiducial ones such as the fragmentation is triggered by\na fragmentation mode with a longer wavelength and it occurs during radial\ncollapse of filaments and find the distortion rapidly grows. In most of\nastrophysical applications, the effective polytropic index of collapsing gas\nexceeds 1.1 before ten orders-of-magnitude increase in the central density.\nThus, supposing the fiducial case of filament fragmentation, re-fragmentation\nof dense cores would not be likely and their final mass would be determined\nwhen the filaments fragment.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Supervised Approach to Extractive Summarisation of Scientific Papers.   Automatic summarisation is a popular approach to reduce a document to its\nmain arguments. Recent research in the area has focused on neural approaches to\nsummarisation, which can be very data-hungry. However, few large datasets exist\nand none for the traditionally popular domain of scientific publications, which\nopens up challenging research avenues centered on encoding large, complex\ndocuments. In this paper, we introduce a new dataset for summarisation of\ncomputer science publications by exploiting a large resource of author provided\nsummaries and show straightforward ways of extending it further. We develop\nmodels on the dataset making use of both neural sentence encoding and\ntraditionally used summarisation features and show that models which encode\nsentences as well as their local and global context perform best, significantly\noutperforming well-established baseline methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structural Nonrealism and Quantum Information.   The article introduces a new concept of structure, defined, echoing J. A.\nWheeler's concept of \"law without law,\" as a \"structure without law,\" and a new\nphilosophical viewpoint, that of structural nnnrealism, and considers how this\nconcept and this viewpoint work in quantum theory in general and quantum\ninformation theory in particular. It takes as its historical point of departure\nW. Heisenberg's discovery of quantum mechanics, which, the article argues,\ncould, in retrospect, be considered in quantum-informational terms, while,\nconversely, quantum information theory could be seen in Heisenbergian terms.\nThe article takes advantage of the circumstance that any instance of quantum\ninformation is a \"structure\"--an organization of elements, ultimately bits, of\nclassical information, manifested in measuring instruments. While, however,\nthis organization can, along with the observed behavior of measuring\ninstruments, be described by means of classical physics, it cannot be predicted\nby means of classical physics, but only, probabilistically or statistically, by\nmeans of quantum mechanics, or in high-energy physics, by means of quantum\nfield theory (or possibly some alternative theories within each scope). By\ncontrast, the emergences of this information and of this structure cannot, in\nthe present view, be described by either classical or quantum theory, or\npossibly by any other means, which leads to the concept of \"structure without\nlaw\" and the viewpoint of structural nnnrealism. The article also considers,\nfrom this perspective, some recent work in quantum information theory.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hyperbolic Pascal simplex.   In this article we introduce a new geometric object called hyperbolic Pascal\nsimplex. This new object is presented by the regular hypercube mosaic in the\n4-dimensional hyperbolic space. The definition of the hyperbolic Pascal\nsimplex, whose hyperfaces are hyperbolic Pascal pyramids and faces are\nhyperbolic Pascals triangles, is a natural generalization of the definition of\nthe hyperbolic Pascal triangle and pyramid. We describe the growing of the\nhyperbolic Pascal simplex considering the numbers and the values of the\nelements. Further figures illustrate the stepping from a level to the next one.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inference on Breakdown Frontiers.   Given a set of baseline assumptions, a breakdown frontier is the boundary\nbetween the set of assumptions which lead to a specific conclusion and those\nwhich do not. In a potential outcomes model with a binary treatment, we\nconsider two conclusions: First, that ATE is at least a specific value (e.g.,\nnonnegative) and second that the proportion of units who benefit from treatment\nis at least a specific value (e.g., at least 50\\%). For these conclusions, we\nderive the breakdown frontier for two kinds of assumptions: one which indexes\nrelaxations of the baseline random assignment of treatment assumption, and one\nwhich indexes relaxations of the baseline rank invariance assumption. These\nclasses of assumptions nest both the point identifying assumptions of random\nassignment and rank invariance and the opposite end of no constraints on\ntreatment selection or the dependence structure between potential outcomes.\nThis frontier provides a quantitative measure of robustness of conclusions to\nrelaxations of the baseline point identifying assumptions. We derive\n$\\sqrt{N}$-consistent sample analog estimators for these frontiers. We then\nprovide two asymptotically valid bootstrap procedures for constructing lower\nuniform confidence bands for the breakdown frontier. As a measure of\nrobustness, estimated breakdown frontiers and their corresponding confidence\nbands can be presented alongside traditional point estimates and confidence\nintervals obtained under point identifying assumptions. We illustrate this\napproach in an empirical application to the effect of child soldiering on\nwages. We find that sufficiently weak conclusions are robust to simultaneous\nfailures of rank invariance and random assignment, while some stronger\nconclusions are fairly robust to failures of rank invariance but not\nnecessarily to relaxations of random assignment.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Polyteam Semantics.   Team semantics is the mathematical framework of modern logics of dependence\nand independence in which formulae are interpreted by sets of assignments\n(teams) instead of single assignments as in first-order logic. In order to\ndeepen the fruitful interplay between team semantics and database dependency\ntheory, we define \"Polyteam Semantics\" in which formulae are evaluated over a\nfamily of teams. We begin by defining a novel polyteam variant of dependence\natoms and give a finite axiomatisation for the associated implication problem.\nWe also characterise the expressive power of poly-dependence logic by\nproperties of polyteams that are downward closed and definable in existential\nsecond-order logic (ESO). The analogous result is shown to hold for\npoly-independence logic and all ESO-definable properties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A 588 Gbps LDPC Decoder Based on Finite-Alphabet Message Passing.   An ultra-high throughput low-density parity check (LDPC) decoder with an\nunrolled full-parallel architecture is proposed, which achieves the highest\ndecoding throughput compared to previously reported LDPC decoders in the\nliterature. The decoder benefits from a serial message-transfer approach\nbetween the decoding stages to alleviate the well-known routing congestion\nproblem in parallel LDPC decoders. Furthermore, a finite-alphabet message\npassing algorithm is employed to replace the variable node update rule of the\nstandard min-sum decoder with look-up tables, which are designed in a way that\nmaximizes the mutual information between decoding messages. The proposed\nalgorithm results in an architecture with reduced bit-width messages, leading\nto a significantly higher decoding throughput and to a lower area as compared\nto a min-sum decoder when serial message-transfer is used. The architecture is\nplaced and routed for the standard min-sum reference decoder and for the\nproposed finite-alphabet decoder using a custom pseudo-hierarchical backend\ndesign strategy to further alleviate routing congestions and to handle the\nlarge design. Post-layout results show that the finite-alphabet decoder with\nthe serial message-transfer architecture achieves a throughput as large as 588\nGbps with an area of 16.2 mm$^2$ and dissipates an average power of 22.7 pJ per\ndecoded bit in a 28 nm FD-SOI library. Compared to the reference min-sum\ndecoder, this corresponds to 3.1 times smaller area and 2 times better energy\nefficiency.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "High-order schemes for the Euler equations in cylindrical/spherical coordinates.   We consider implementations of high-order finite difference Weighted\nEssentially Non-Oscillatory (WENO) schemes for the Euler equations in\ncylindrical and spherical coordinate systems with radial dependence only. The\nmain concern of this work lies in ensuring both high-order accuracy and\nconservation. Three different spatial discretizations are assessed: one that is\nshown to be high-order accurate but not conservative, one conservative but not\nhigh-order accurate, and a new approach that is both high-order accurate and\nconservative. For cylindrical and spherical coordinates, we present convergence\nresults for the advection equation and the Euler equations with an acoustics\nproblem; we then use the Sod shock tube and the Sedov point-blast problems in\ncylindrical coordinates to verify our analysis and implementations.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Robust method for finding sparse solutions to linear inverse problems using an L2 regularization.   We analyzed the performance of a biologically inspired algorithm called the\nCorrected Projections Algorithm (CPA) when a sparseness constraint is required\nto unambiguously reconstruct an observed signal using atoms from an\novercomplete dictionary. By changing the geometry of the estimation problem,\nCPA gives an analytical expression for a binary variable that indicates the\npresence or absence of a dictionary atom using an L2 regularizer. The\nregularized solution can be implemented using an efficient real-time\nKalman-filter type of algorithm. The smoother L2 regularization of CPA makes it\nvery robust to noise, and CPA outperforms other methods in identifying known\natoms in the presence of strong novel atoms in the signal.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Optimization of Multi-Beam Directional Communication Networks.   We formulate an optimization problem for maximizing the data rate of a common\nmessage transmitted from nodes within an airborne network broadcast to a\ncentral station receiver while maintaining a set of intra-network rate demands.\nAssuming that the network has full-duplex links with multi-beam directional\ncapability, we obtain a convex multi-commodity flow problem and use a\ndistributed augmented Lagrangian algorithm to solve for the optimal flows\nassociated with each beam in the network. For each augmented Lagrangian\niteration, we propose a scaled gradient projection method to minimize the local\nLagrangian function that incorporates the local topology of each node in the\nnetwork. Simulation results show fast convergence of the algorithm in\ncomparison to simple distributed primal dual methods and highlight performance\ngains over standard minimum distance-based routing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Variational Monte Carlo study of spin dynamics in underdoped cuprates.   The hour-glass-like dispersion of spin excitations is a common feature of\nunderdoped cuprates. It was qualitatively explained by the random phase\napproximation based on various ordered states with some phenomenological\nparameters; however, its origin remains elusive. Here, we present a numerical\nstudy of spin dynamics in the $t$-$J$ model using the variational Monte Carlo\nmethod. This parameter-free method satisfies the no double-occupancy constraint\nof the model and thus provides a better evaluation on the spin dynamics with\nrespect to various mean-field trial states. We conclude that the lower branch\nof the hour-glass dispersion is a collective mode and the upper branch is more\nlikely the consequence of the stripe state than the other candidates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hidden Truncation Hyperbolic Distributions, Finite Mixtures Thereof, and Their Application for Clustering.   A hidden truncation hyperbolic (HTH) distribution is introduced and finite\nmixtures thereof are applied for clustering. A stochastic representation of the\nHTH distribution is given and a density is derived. A hierarchical\nrepresentation is described, which aids in parameter estimation. Finite\nmixtures of HTH distributions are presented and their identifiability is\nproved. The convexity of the HTH distribution is discussed, which is important\nin clustering applications, and some theoretical results in this direction are\npresented. The relationship between the HTH distribution and other skewed\ndistributions in the literature is discussed. Illustrations are provided ---\nboth of the HTH distribution and application of finite mixtures thereof for\nclustering.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Design Decisions for Weave: A Real-Time Web-based Collaborative Visualization Framework.   There are many web-based visualization systems available to date, each having\nits strengths and limitations. The goals these systems set out to accomplish\ninfluence design decisions and determine how reusable and scalable they are.\nWeave is a new web-based visualization platform with the broad goal of enabling\nvisualization of any available data by anyone for any purpose. Our open source\nframework supports highly interactive linked visualizations for users of\nvarying skill levels. What sets Weave apart from other systems is its\nconsideration for real-time remote collaboration with session history. We\nprovide a detailed account of the various framework designs we considered with\ncomparisons to existing state-of-the-art systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Network Slicing for Ultra-Reliable Low Latency Communication in Industry 4.0 Scenarios.   An important novelty of 5G is its role in transforming the industrial\nproduction into Industry 4.0. Specifically, Ultra-Reliable Low Latency\nCommunications (URLLC) will, in many cases, enable replacement of cables with\nwireless connections and bring freedom in designing and operating\ninterconnected machines, robots, and devices. However, not all industrial links\nwill be of URLLC type; e.g. some applications will require high data rates.\nFurthermore, these industrial networks will be highly heterogeneous, featuring\nvarious communication technologies. We consider network slicing as a mechanism\nto handle the diverse set of requirements to the network. We present methods\nfor slicing deterministic and packet-switched industrial communication\nprotocols at an abstraction level that is decoupled from the specific\nimplementation of the underlying technologies. Finally, we show how network\ncalculus can be used to assess the end-to-end properties of the network slices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Borel class and Cartan involution.   In this note we prove that the Borel class of representations of 3-manifold\ngroups to PGL(n,C) is preserved under Cartan involution up to sign. For\nrepresentations to PGL(3,C) this is implied by a more general result of E.\nFalbel and Q. Wang, however our proof appears to be much shorter for that\nspecial case.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "History-aware Autonomous Exploration in Confined Environments using MAVs.   Many scenarios require a robot to be able to explore its 3D environment\nonline without human supervision. This is especially relevant for inspection\ntasks and search and rescue missions. To solve this high-dimensional path\nplanning problem, sampling-based exploration algorithms have proven successful.\nHowever, these do not necessarily scale well to larger environments or spaces\nwith narrow openings. This paper presents a 3D exploration planner based on the\nprinciples of Next-Best Views (NBVs). In this approach, a Micro-Aerial Vehicle\n(MAV) equipped with a limited field-of-view depth sensor randomly samples its\nconfiguration space to find promising future viewpoints. In order to obtain\nhigh sampling efficiency, our planner maintains and uses a history of visited\nplaces, and locally optimizes the robot's orientation with respect to\nunobserved space. We evaluate our method in several simulated scenarios, and\ncompare it against a state-of-the-art exploration algorithm. The experiments\nshow substantial improvements in exploration time ($2\\times$ faster),\ncomputation time, and path length, and advantages in handling difficult\nsituations such as escaping dead-ends (up to $20\\times$ faster). Finally, we\nvalidate the on-line capability of our algorithm on a computational constrained\nreal world MAV.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "B-spline-like bases for $C^2$ cubics on the Powell-Sabin 12-split.   For spaces of constant, linear, and quadratic splines of maximal smoothness\non the Powell-Sabin 12-split of a triangle, the so-called S-bases were recently\nintroduced. These are simplex spline bases with B-spline-like properties on the\n12-split of a single triangle, which are tied together across triangles in a\nBézier-like manner.\nIn this paper we give a formal definition of an S-basis in terms of certain\nbasic properties. We proceed to investigate the existence of S-bases for the\naforementioned spaces and additionally the cubic case, resulting in an\nexhaustive list. From their nature as simplex splines, we derive simple\ndifferentiation and recurrence formulas to other S-bases. We establish a\nMarsden identity that gives rise to various quasi-interpolants and domain\npoints forming an intuitive control net, in terms of which conditions for\n$C^0$-, $C^1$-, and $C^2$-smoothness are derived.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spin pumping into superconductors: A new probe of spin dynamics in a superconducting thin film.   Spin pumping refers to the microwave-driven spin current injection from a\nferromagnet into the adjacent target material. We theoretically investigate the\nspin pumping into superconductors by fully taking account of impurity\nspin-orbit scattering that is indispensable to describe diffusive spin\ntransport with finite spin diffusion length. We calculate temperature\ndependence of the spin pumping signal and show that a pronounced coherence peak\nappears immediately below the superconducting transition temperature Tc, which\nsurvives even in the presence of the spin-orbit scattering. The phenomenon\nprovides us with a new way of studying the dynamic spin susceptibility in a\nsuperconducting thin film. This is contrasted with the nuclear magnetic\nresonance technique used to study a bulk superconductor.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "SuperMinHash - A New Minwise Hashing Algorithm for Jaccard Similarity Estimation.   This paper presents a new algorithm for calculating hash signatures of sets\nwhich can be directly used for Jaccard similarity estimation. The new approach\nis an improvement over the MinHash algorithm, because it has a better runtime\nbehavior and the resulting signatures allow a more precise estimation of the\nJaccard index.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning the Sparse and Low Rank PARAFAC Decomposition via the Elastic Net.   In this article, we derive a Bayesian model to learning the sparse and low\nrank PARAFAC decomposition for the observed tensor with missing values via the\nelastic net, with property to find the true rank and sparse factor matrix which\nis robust to the noise. We formulate efficient block coordinate descent\nalgorithm and admax stochastic block coordinate descent algorithm to solve it,\nwhich can be used to solve the large scale problem. To choose the appropriate\nrank and sparsity in PARAFAC decomposition, we will give a solution path by\ngradually increasing the regularization to increase the sparsity and decrease\nthe rank. When we find the sparse structure of the factor matrix, we can fixed\nthe sparse structure, using a small to regularization to decreasing the\nrecovery error, and one can choose the proper decomposition from the solution\npath with sufficient sparse factor matrix with low recovery error. We test the\npower of our algorithm on the simulation data and real data, which show it is\npowerful.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simulated Tempering Method in the Infinite Switch Limit with Adaptive Weight Learning.   We investigate the theoretical foundations of the simulated tempering method\nand use our findings to design efficient algorithms. Employing a large\ndeviation argument first used for replica exchange molecular dynamics [Plattner\net al., J. Chem. Phys. 135:134111 (2011)], we demonstrate that the most\nefficient approach to simulated tempering is to vary the temperature infinitely\nrapidly. In this limit, we can replace the equations of motion for the\ntemperature and physical variables by averaged equations for the latter alone,\nwith the forces rescaled according to a position-dependent function defined in\nterms of temperature weights. The averaged equations are similar to those used\nin Gao's integrated-over-temperature method, except that we show that it is\nbetter to use a continuous rather than a discrete set of temperatures. We give\na theoretical argument for the choice of the temperature weights as the\nreciprocal partition function, thereby relating simulated tempering to\nWang-Landau sampling. Finally, we describe a self-consistent algorithm for\nsimultaneously sampling the canonical ensemble and learning the weights during\nsimulation. This algorithm is tested on a system of harmonic oscillators as\nwell as a continuous variant of the Curie-Weiss model, where it is shown to\nperform well and to accurately capture the second-order phase transition\nobserved in this model.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Grothendieck rigidity of 3-manifold groups.   We show that fundamental groups of compact, orientable, irreducible\n3-manifolds with toroidal boundary are Grothendieck rigid.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Liouville heat kernel for k-coarse MBRW and nonuniversality.   We study the Liouville heat kernel (in the $L^2$ phase) associated with a\nclass of logarithmically correlated Gaussian fields on the two dimensional\ntorus. We show that for each $\\varepsilon>0$ there exists such a field, whose\ncovariance is a bounded perturbation of that of the two dimensional Gaussian\nfree field, and such that the associated Liouville heat kernel satisfies the\nshort time estimates, $$ \\exp \\left( - t^{ - \\frac 1 { 1 + \\frac 1 2 \\gamma^2 }\n- \\varepsilon } \\right) \\le p_t^\\gamma (x, y) \\le \\exp \\left( - t^{- \\frac 1 {\n1 + \\frac 1 2 \\gamma^2 } + \\varepsilon } \\right) , $$ for $\\gamma<1/2$. In\nparticular, these are different from predictions, due to Watabiki, concerning\nthe Liouville heat kernel for the two dimensional Gaussian free field.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotic Goodness-of-Fit Tests for Point Processes Based on Scaled Empirical K-Functions.   We study sequences of scaled edge-corrected empirical (generalized)\nK-functions (modifying Ripley's K-function) each of them constructed from a\nsingle observation of a $d$-dimensional fourth-order stationary point process\nin a sampling window W_n which grows together with some scaling rate\nunboundedly as n --> infty. Under some natural assumptions it is shown that the\nnormalized difference between scaled empirical and scaled theoretical\nK-function converges weakly to a mean zero Gaussian process with simple\ncovariance function. This result suggests discrepancy measures between\nempirical and theoretical K-function with known limit distribution which allow\nto perform goodness-of-fit tests for checking a hypothesized point process\nbased only on its intensity and (generalized) K-function. Similar test\nstatistics are derived for testing the hypothesis that two independent point\nprocesses in W_n have the same distribution without explicit knowledge of their\nintensities and K-functions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Persistence Codebooks for Topological Data Analysis.   Topological data analysis, such as persistent homology has shown beneficial\nproperties for machine learning in many tasks. Topological representations,\nsuch as the persistence diagram (PD), however, have a complex structure\n(multiset of intervals) which makes it difficult to combine with typical\nmachine learning workflows. We present novel compact fixed-size vectorial\nrepresentations of PDs based on clustering and bag of words encodings that cope\nwell with the inherent sparsity of PDs. Our novel representations outperform\nstate-of-the-art approaches from topological data analysis and are\ncomputationally more efficient.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Flatness results for nonlocal minimal cones and subgraphs.   We show that nonlocal minimal cones which are non-singular subgraphs outside\nthe origin are necessarily halfspaces.\nThe proof is based on classical ideas of~\\cite{DG1} and on the computation of\nthe linearized nonlocal mean curvature operator, which is proved to satisfy a\nsuitable maximum principle.\nWith this, we obtain new, and somehow simpler, proofs of the Bernstein-type\nresults for nonlocal minimal surfaces which have been recently established\nin~\\cite{FV}. In addition, we establish a new nonlocal Bernstein-Moser-type\nresult which classifies Lipschitz nonlocal minimal subgraphs outside a ball.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ACtuAL: Actor-Critic Under Adversarial Learning.   Generative Adversarial Networks (GANs) are a powerful framework for deep\ngenerative modeling. Posed as a two-player minimax problem, GANs are typically\ntrained end-to-end on real-valued data and can be used to train a generator of\nhigh-dimensional and realistic images. However, a major limitation of GANs is\nthat training relies on passing gradients from the discriminator through the\ngenerator via back-propagation. This makes it fundamentally difficult to train\nGANs with discrete data, as generation in this case typically involves a\nnon-differentiable function. These difficulties extend to the reinforcement\nlearning setting when the action space is composed of discrete decisions. We\naddress these issues by reframing the GAN framework so that the generator is no\nlonger trained using gradients through the discriminator, but is instead\ntrained using a learned critic in the actor-critic framework with a Temporal\nDifference (TD) objective. This is a natural fit for sequence modeling and we\nuse it to achieve improvements on language modeling tasks over the standard\nTeacher-Forcing methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Determinantal Generalizations of Instrumental Variables.   Linear structural equation models relate the components of a random vector\nusing linear interdependencies and Gaussian noise. Each such model can be\nnaturally associated with a mixed graph whose vertices correspond to the\ncomponents of the random vector. The graph contains directed edges that\nrepresent the linear relationships between components, and bidirected edges\nthat encode unobserved confounding. We study the problem of generic\nidentifiability, that is, whether a generic choice of linear and confounding\neffects can be uniquely recovered from the joint covariance matrix of the\nobserved random vector. An existing combinatorial criterion for establishing\ngeneric identifiability is the half-trek criterion (HTC), which uses the\nexistence of trek systems in the mixed graph to iteratively discover\ngenerically invertible linear equation systems in polynomial time. By focusing\non edges one at a time, we establish new sufficient and necessary conditions\nfor generic identifiability of edge effects extending those of the HTC. In\nparticular, we show how edge coefficients can be recovered as quotients of\nsubdeterminants of the covariance matrix, which constitutes a determinantal\ngeneralization of formulas obtained when using instrumental variables for\nidentification.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Hierarchical Max-infinitely Divisible Process for Extreme Areal Precipitation Over Watersheds.   Understanding the spatial extent of extreme precipitation is necessary for\ndetermining flood risk and adequately designing infrastructure (e.g.,\nstormwater pipes) to withstand such hazards. While environmental phenomena\ntypically exhibit weakening spatial dependence at increasingly extreme levels,\nlimiting max-stable process models for block maxima have a rigid dependence\nstructure that does not capture this type of behavior. We propose a flexible\nBayesian model from a broader family of max-infinitely divisible processes that\nallows for weakening spatial dependence at increasingly extreme levels, and due\nto a hierarchical representation of the likelihood in terms of random effects,\nour inference approach scales to large datasets. The proposed model is\nconstructed using flexible random basis functions that are estimated from the\ndata, allowing for straightforward inspection of the predominant spatial\npatterns of extremes. In addition, the described process possesses\nmax-stability as a special case, making inference on the tail dependence class\npossible. We apply our model to extreme precipitation in eastern North America,\nand show that the proposed model adequately captures the extremal behavior of\nthe data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "R-C3D: Region Convolutional 3D Network for Temporal Activity Detection.   We address the problem of activity detection in continuous, untrimmed video\nstreams. This is a difficult task that requires extracting meaningful\nspatio-temporal features to capture activities, accurately localizing the start\nand end times of each activity. We introduce a new model, Region Convolutional\n3D Network (R-C3D), which encodes the video streams using a three-dimensional\nfully convolutional network, then generates candidate temporal regions\ncontaining activities, and finally classifies selected regions into specific\nactivities. Computation is saved due to the sharing of convolutional features\nbetween the proposal and the classification pipelines. The entire model is\ntrained end-to-end with jointly optimized localization and classification\nlosses. R-C3D is faster than existing methods (569 frames per second on a\nsingle Titan X Maxwell GPU) and achieves state-of-the-art results on THUMOS'14.\nWe further demonstrate that our model is a general activity detection framework\nthat does not rely on assumptions about particular dataset properties by\nevaluating our approach on ActivityNet and Charades. Our code is available at\nthis http URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SenGen: Sentence Generating Neural Variational Topic Model.   We present a new topic model that generates documents by sampling a topic for\none whole sentence at a time, and generating the words in the sentence using an\nRNN decoder that is conditioned on the topic of the sentence. We argue that\nthis novel formalism will help us not only visualize and model the topical\ndiscourse structure in a document better, but also potentially lead to more\ninterpretable topics since we can now illustrate topics by sampling\nrepresentative sentences instead of bag of words or phrases. We present a\nvariational auto-encoder approach for learning in which we use a factorized\nvariational encoder that independently models the posterior over topical\nmixture vectors of documents using a feed-forward network, and the posterior\nover topic assignments to sentences using an RNN. Our preliminary experiments\non two different datasets indicate early promise, but also expose many\nchallenges that remain to be addressed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Transfer of magnetic order and anisotropy through epitaxial integration of 3$d$ and 4$f$ spin systems.   Resonant x-ray scattering at the Dy $M_5$ and Ni $L_3$ absorption edges was\nused to probe the temperature and magnetic field dependence of magnetic order\nin epitaxial LaNiO$_3$-DyScO$_3$ superlattices. For superlattices with 2 unit\ncell thick LaNiO$_3$ layers, a commensurate spiral state develops in the Ni\nspin system below 100 K. Upon cooling below $T_{ind} = 18$ K, Dy-Ni exchange\ninteractions across the LaNiO$_3$-DyScO$_3$ interfaces induce collinear\nmagnetic order of interfacial Dy moments as well as a reorientation of the Ni\nspins to a direction dictated by the strong magneto-crystalline anisotropy of\nDy. This transition is reversible by an external magnetic field of 3 T.\nTailored exchange interactions between rare-earth and transition-metal ions\nthus open up new perspectives for the manipulation of spin structures in\nmetal-oxide heterostructures and devices.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Unbiased and Consistent Nested Sampling via Sequential Monte Carlo.   We introduce a new class of sequential Monte Carlo methods called Nested\nSampling via Sequential Monte Carlo (NS-SMC), which reframes the Nested\nSampling method of Skilling (2006) in terms of sequential Monte Carlo\ntechniques. This new framework allows convergence results to be obtained in the\nsetting when Markov chain Monte Carlo (MCMC) is used to produce new samples. An\nadditional benefit is that marginal likelihood estimates are unbiased. In\ncontrast to NS, the analysis of NS-SMC does not require the (unrealistic)\nassumption that the simulated samples be independent. As the original NS\nalgorithm is a special case of NS-SMC, this provides insights as to why NS\nseems to produce accurate estimates despite a typical violation of its\nassumptions. For applications of NS-SMC, we give advice on tuning MCMC kernels\nin an automated manner via a preliminary pilot run, and present a new method\nfor appropriately choosing the number of MCMC repeats at each iteration.\nFinally, a numerical study is conducted where the performance of NS-SMC and\ntemperature-annealed SMC is compared on several challenging and realistic\nproblems. MATLAB code for our experiments is made available at\nthis https URL .",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Charge Collection in Coplanar Grid Radiation Detectors.   We have modeled laser-induced transient current waveforms in radiation\ncoplanar grid detectors. Poisson's equation has been solved by finite element\nmethod and currents induced by photo-generated charge were obtained using\nShockley-Ramo theorem. The spectral response on a radiation flux has been\nmodeled by Monte-Carlo simulations. We show 10$\\times$ improved spectral\nresolution of coplanar grid detector using differential signal sensing. We\nmodel the current waveform dependence on doping, depletion width, diffusion and\ndetector shielding and their mutual dependence is discussed in terms of\ndetector optimization. The numerical simulations are successfully compared to\nexperimental data and further model simplifications are proposed. The space\ncharge below electrodes and a non-homogeneous electric field on a coplanar grid\nanode are found to be the dominant contributions to laser-induced transient\ncurrent waveforms.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "In-Silico Proportional-Integral Moment Control of Stochastic Reaction Networks with Applications to Gene Expression (with Dimerization).   The problem of controlling the mean and the variance of a species of interest\nin a simple gene expression is addressed. It is shown that the protein mean\nlevel can be globally and robustly tracked to any desired value using a simple\nPI controller that satisfies certain sufficient conditions. Controlling both\nthe mean and variance however requires an additional control input, e.g. the\nmRNA degradation rate, and local robust tracking of mean and variance is proved\nto be achievable using multivariable PI control, provided that the reference\npoint satisfies necessary conditions imposed by the system. Even more\nimportantly, it is shown that there exist PI controllers that locally, robustly\nand simultaneously stabilize all the equilibrium points inside the admissible\nregion. The results are then extended to the mean control of a gene expression\nwith protein dimerization. It is shown that the moment closure problem can be\ncircumvented without invoking any moment closure technique. Local stabilization\nand convergence of the average dimer population to any desired reference value\nis ensured using a pure integral control law. Explicit bounds on the controller\ngain are provided and shown to be valid for any reference value. As a\nbyproduct, an explicit upper-bound of the variance of the monomer species,\nacting on the system as unknown input due to the moment openness, is obtained.\nThe results are illustrated by simulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discovery of water at high spectral resolution in the atmosphere of 51 Peg b.   We report the detection of water absorption features in the dayside spectrum\nof the first-known hot Jupiter, 51 Peg b, confirming the star-planet system to\nbe a double-lined spectroscopic binary. We used high-resolution (R~100,000),\n3.2 micron spectra taken with CRIRES/VLT to trace the radial-velocity shift of\nthe water features in the planet's dayside atmosphere during 4 hours of its\n4.23-day orbit after superior conjunction. We detect the signature of molecular\nabsorption by water at a significance of 5.6 sigma at a systemic velocity of\nVsys=-33+/-2 km/s, coincident with the host star, with a corresponding orbital\nvelocity Kp = 133^+4.3_-3.5 km/s. This translates directly to a planet mass of\nMp=0.476^+0.032_-0.031MJ, placing it at the transition boundary between Jovian\nand Neptunian worlds. We determine upper and lower limits on the orbital\ninclination of the system of 70<i (deg)<82.2. We also provide an updated\norbital solution for 51 Peg b, using an extensive set of 639 stellar radial\nvelocities measured between 1994 and 2013, finding no significant evidence of\nan eccentric orbit. We find no evidence of significant absorption or emission\nfrom other major carbon-bearing molecules of the planet, including methane and\ncarbon dioxide. The atmosphere is non-inverted in the temperature-pressure\nregion probed by these observations. The deepest absorption lines reach an\nobserved relative contrast of 0.9x10^-3 with respect to the host star continuum\nflux, at an angular separation of 3 milliarcseconds. This work is consistent\nwith a previous tentative report of K-band molecular absorption for 51 Peg b by\nBrogi et al. (2013).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Frequentist coverage and sup-norm convergence rate in Gaussian process regression.   Gaussian process (GP) regression is a powerful interpolation technique due to\nits flexibility in capturing non-linearity. In this paper, we provide a general\nframework for understanding the frequentist coverage of point-wise and\nsimultaneous Bayesian credible sets in GP regression. As an intermediate\nresult, we develop a Bernstein von-Mises type result under supremum norm in\nrandom design GP regression. Identifying both the mean and covariance function\nof the posterior distribution of the Gaussian process as regularized\n$M$-estimators, we show that the sampling distribution of the posterior mean\nfunction and the centered posterior distribution can be respectively\napproximated by two population level GPs. By developing a comparison inequality\nbetween two GPs, we provide exact characterization of frequentist coverage\nprobabilities of Bayesian point-wise credible intervals and simultaneous\ncredible bands of the regression function. Our results show that inference\nbased on GP regression tends to be conservative; when the prior is\nunder-smoothed, the resulting credible intervals and bands have minimax-optimal\nsizes, with their frequentist coverage converging to a non-degenerate value\nbetween their nominal level and one. As a byproduct of our theory, we show that\nthe GP regression also yields minimax-optimal posterior contraction rate\nrelative to the supremum norm, which provides a positive evidence to the long\nstanding problem on optimal supremum norm contraction rate in GP regression.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "BFGS convergence to nonsmooth minimizers of convex functions.   The popular BFGS quasi-Newton minimization algorithm under reasonable\nconditions converges globally on smooth convex functions. This result was\nproved by Powell in 1976: we consider its implications for functions that are\nnot smooth. In particular, an analogous convergence result holds for functions,\nlike the Euclidean norm, that are nonsmooth at the minimizer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ac properties of short Josephson weak links.   The admittance of two types of Josephson weak links is calculated, i.e., of a\none-dimensional superconducting wire with a local suppression of the order\nparameter, and the second is a short S-c-S structure, where S denotes a\nsuperconductor and c---a constriction. The systems of the first type are\nanalyzed on the basis of time-dependent Ginzburg-Landau equations. We show that\nthe impedance $Z(\\Omega)$ has a maximum as a function of the frequency\n$\\Omega$, and the electric field $E_{\\Omega}$ is determined by two\ngauge-invariant quantities---the condensate momentum $Q_{\\Omega}$ and the\npotential $\\mu$ related to charge imbalance. The structures of the second type\nare studied on the basis of microscopic equations for quasiclassical Green's\nfunctions in the Keldysh technique. For short S-c-S contacts (the Thouless\nenergy ${E_{\\text{Th}} = D/L^{2} \\gg \\Delta}$) we present a formula for\nadmittance $Y$ valid at frequencies $\\Omega$ and temperatures $T$ less than the\nThouless energy but arbitrary with respect to the energy gap $\\Delta$. It is\nshown that, at low temperatures, the absorption is absent [${\\mathrm{Re}(Y) =\n0}$] if the frequency does not exceed the energy gap in the center of the\nconstriction (${\\Omega < \\Delta \\cos \\varphi_{0}}$, where $2 \\varphi_{0}$ is\nthe phase difference between the S reservoirs). The absorption gradually\nincreases with increasing the difference ${(\\Omega - \\Delta \\cos \\varphi_{0})}$\nif $2 \\varphi_{0}$ is less than the phase difference $2 \\varphi_{\\text{c}}$\ncorresponding to the critical Josephson current. In the interval ${2\n\\varphi_{\\text{c}} < 2 \\varphi_{0} < \\pi}$, the absorption has a maximum. This\ninterval of the phase difference is achievable in phase-biased Josephson\njunctions. Close to $T_{\\text{c}}$ the admittance has a maximum at low $\\Omega$\nwhich is described by an analytical formula.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Information Elicitation for Bayesian Auctions.   In this paper we design information elicitation mechanisms for Bayesian\nauctions. While in Bayesian mechanism design the distributions of the players'\nprivate types are often assumed to be common knowledge, information elicitation\nconsiders the situation where the players know the distributions better than\nthe decision maker. To weaken the information assumption in Bayesian auctions,\nwe consider an information structure where the knowledge about the\ndistributions is arbitrarily scattered among the players. In such an\nunstructured information setting, we design mechanisms for unit-demand auctions\nand additive auctions that aggregate the players' knowledge, generating revenue\nthat are constant approximations to the optimal Bayesian mechanisms with a\ncommon prior. Our mechanisms are 2-step dominant-strategy truthful and the\nrevenue increases gracefully with the amount of knowledge the players\ncollectively have.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A short note on Godbersen's Conjecture.   In this short note we improve the best to date bound in Godbersen's\nconjecture, and show some implications for unbalanced difference bodies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Third-Person Imitation Learning.   Reinforcement learning (RL) makes it possible to train agents capable of\nachiev- ing sophisticated goals in complex and uncertain environments. A key\ndifficulty in reinforcement learning is specifying a reward function for the\nagent to optimize. Traditionally, imitation learning in RL has been used to\novercome this problem. Unfortunately, hitherto imitation learning methods tend\nto require that demonstra- tions are supplied in the first-person: the agent is\nprovided with a sequence of states and a specification of the actions that it\nshould have taken. While powerful, this kind of imitation learning is limited\nby the relatively hard problem of collect- ing first-person demonstrations.\nHumans address this problem by learning from third-person demonstrations: they\nobserve other humans perform tasks, infer the task, and accomplish the same\ntask themselves.\nIn this paper, we present a method for unsupervised third-person imitation\nlearn- ing. Here third-person refers to training an agent to correctly achieve\na simple goal in a simple environment when it is provided a demonstration of a\nteacher achieving the same goal but from a different viewpoint; and\nunsupervised refers to the fact that the agent receives only these third-person\ndemonstrations, and is not provided a correspondence between teacher states and\nstudent states. Our methods primary insight is that recent advances from domain\nconfusion can be utilized to yield domain agnostic features which are crucial\nduring the training process. To validate our approach, we report successful\nexperiments on learning from third-person demonstrations in a pointmass domain,\na reacher domain, and inverted pendulum.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Chiral Topological Superconductors Enhanced by Long-Range Interactions.   We study the phase diagram and edge states of a two-dimensional p-wave\nsuperconductor with long-range hopping and pairing amplitudes. New topological\nphases and quasiparticles different from the usual short-range model are\nobtained. When both hopping and pairing terms decay with the same exponent, one\nof the topological chiral phases with propagating Majorana edge states gets\nsignificantly enhanced by long-range couplings. On the other hand, when the\nlong-range pairing amplitude decays more slowly than the hopping, we discover\nnew topological phases where propagating Majorana fermions at each edge pair\nnonlocally and become gapped even in the thermodynamic limit. Remarkably, these\nnonlocal edge states are still robust, remain separated from the bulk, and are\nlocalized at both edges at the same time. The inclusion of long-range effects\nis potentially applicable to recent experiments with magnetic impurities and\nislands in 2D superconductors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "MACS J0416.1-2403: Impact of line-of-sight structures on strong gravitational lensing modelling of galaxy clusters.   Exploiting the powerful tool of strong gravitational lensing by galaxy\nclusters to study the highest-redshift Universe and cluster mass distributions\nrelies on precise lens mass modelling. In this work, we present the first\nattempt at modelling line-of-sight mass distribution in addition to that of the\ncluster, extending previous modelling techniques that assume mass distributions\nto be on a single lens plane. We focus on the Hubble Frontier Field cluster\nMACS J0416.1-2403, and our multi-plane model reproduces the observed image\npositions with a rms offset of ~0.53\". Starting from this best-fitting model,\nwe simulate a mock cluster that resembles MACS J0416.1-2403 in order to explore\nthe effects of line-of-sight structures on cluster mass modelling. By\nsystematically analysing the mock cluster under different model assumptions, we\nfind that neglecting the lensing environment has a significant impact on the\nreconstruction of image positions (rms ~0.3\"); accounting for line-of-sight\ngalaxies as if they were at the cluster redshift can partially reduce this\noffset. Moreover, foreground galaxies are more important to include into the\nmodel than the background ones. While the magnification factors of the lensed\nmultiple images are recovered within ~10% for ~95% of them, those ~5% that lie\nnear critical curves can be significantly affected by the exclusion of the\nlensing environment in the models (up to a factor of ~200). In addition,\nline-of-sight galaxies cannot explain the apparent discrepancy in the\nproperties of massive subhalos between MACS J0416.1-2403 and N-body simulated\nclusters. Since our model of MACS J0416.1-2403 with line-of-sight galaxies only\nreduced modestly the rms offset in the image positions, we conclude that\nadditional complexities, such as more flexible halo shapes, would be needed in\nfuture models of MACS J0416.1-2403.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A note on integrating products of linear forms over the unit simplex.   Integrating a product of linear forms over the unit simplex can be done in\npolynomial time if the number of variables n is fixed (V. Baldoni et al.,\n2011). In this note, we highlight that this problem is equivalent to obtaining\nthe normalizing constant of state probabilities for a popular class of Markov\nprocesses used in queueing network theory. In light of this equivalence, we\nsurvey existing computational algorithms developed in queueing theory that can\nbe used for exact integration. For example, under some regularity conditions,\nqueueing theory algorithms can exactly integrate a product of linear forms of\ntotal degree N by solving N systems of linear equations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Expansion of percolation critical points for Hamming graphs.   The Hamming graph $H(d,n)$ is the Cartesian product of $d$ complete graphs on\n$n$ vertices. Let $m=d(n-1)$ be the degree and $V = n^d$ be the number of\nvertices of $H(d,n)$. Let $p_c^{(d)}$ be the critical point for bond\npercolation on $H(d,n)$. We show that, for $d \\in \\mathbb N$ fixed and $n \\to\n\\infty$,\n\\begin{equation*}\np_c^{(d)}= \\dfrac{1}{m} + \\dfrac{2d^2-1}{2(d-1)^2}\\dfrac{1}{m^2}\n+ O(m^{-3}) + O(m^{-1}V^{-1/3}),\n\\end{equation*} which extends the asymptotics found in\n\\cite{BorChaHofSlaSpe05b} by one order. The term $O(m^{-1}V^{-1/3})$ is the\nwidth of the critical window. For $d=4,5,6$ we have $m^{-3} =\nO(m^{-1}V^{-1/3})$, and so the above formula represents the full asymptotic\nexpansion of $p_c^{(d)}$. In \\cite{FedHofHolHul16a} \\st{we show that} this\nformula is a crucial ingredient in the study of critical bond percolation on\n$H(d,n)$ for $d=2,3,4$. The proof uses a lace expansion for the upper bound and\na novel comparison with a branching random walk for the lower bound. The proof\nof the lower bound also yields a refined asymptotics for the susceptibility of\na subcritical Erdős-Rényi random graph.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On a cross-diffusion system arising in image denosing.   We study a generalization of a cross-diffusion problem deduced from a\nnonlinear complex-variable diffusion model for signal and image denoising.\nWe prove the existence of weak solutions of the time-independent problem with\nfidelity terms under mild conditions on the data problem. Then, we show that\nthis translates on the well-posedness of a quasi-steady state approximation of\nthe evolution problem, and also prove the existence of weak solutions of the\nlatter under more restrictive hypothesis.\nWe finally perform some numerical simulations for image denoising, comparing\nthe performance of the cross-diffusion model and its corresponding scalar\nPerona-Malik equation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The GTC exoplanet transit spectroscopy survey. VII. Detection of sodium in WASP-52b's cloudy atmosphere.   We report the first detection of sodium absorption in the atmosphere of the\nhot Jupiter WASP-52b. We observed one transit of WASP-52b with the\nlow-resolution Optical System for Imaging and low-Intermediate-Resolution\nIntegrated Spectroscopy (OSIRIS) at the 10.4 m Gran Telescopio Canarias (GTC).\nThe resulting transmission spectrum, covering the wavelength range from 522 nm\nto 903 nm, is flat and featureless, except for the significant narrow\nabsorption signature at the sodium doublet, which can be explained by an\natmosphere in solar composition with clouds at 1 mbar. A cloud-free atmosphere\nis stringently ruled out. By assessing the absorption depths of sodium in\nvarious bin widths, we find that temperature increases towards lower\natmospheric pressure levels, with a positive temperature gradient of 0.88 +/-\n0.65 K/km, possibly indicative of upper atmospheric heating and a temperature\ninversion.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Threshold Selection for Multivariate Heavy-Tailed Data.   Regular variation is often used as the starting point for modeling\nmultivariate heavy-tailed data. A random vector is regularly varying if and\nonly if its radial part $R$ is regularly varying and is asymptotically\nindependent of the angular part $\\Theta$ as $R$ goes to infinity. The\nconditional limiting distribution of $\\Theta$ given $R$ is large characterizes\nthe tail dependence of the random vector and hence its estimation is the\nprimary goal of applications. A typical strategy is to look at the angular\ncomponents of the data for which the radial parts exceed some threshold. While\na large class of methods has been proposed to model the angular distribution\nfrom these exceedances, the choice of threshold has been scarcely discussed in\nthe literature. In this paper, we describe a procedure for choosing the\nthreshold by formally testing the independence of $R$ and $\\Theta$ using a\nmeasure of dependence called distance covariance. We generalize the limit\ntheorem for distance covariance to our unique setting and propose an algorithm\nwhich selects the threshold for $R$. This algorithm incorporates a subsampling\nscheme that is also applicable to weakly dependent data. Moreover, it avoids\nthe heavy computation in the calculation of the distance covariance, a typical\nlimitation for this measure. The performance of our method is illustrated on\nboth simulated and real data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entombed: An archaeological examination of an Atari 2600 game.   The act and experience of programming is, at its heart, a fundamentally human\nactivity that results in the production of artifacts. When considering\nprogramming, therefore, it would be a glaring omission to not involve people\nwho specialize in studying artifacts and the human activity that yields them:\narchaeologists. Here we consider this with respect to computer games, the focus\nof archaeology's nascent subarea of archaeogaming.\nOne type of archaeogaming research is digital excavation, a technical\nexamination of the code and techniques used in old games' implementation. We\napply that in a case study of Entombed, an Atari 2600 game released in 1982 by\nUS Games. The player in this game is, appropriately, an archaeologist who must\nmake their way through a zombie-infested maze. Maze generation is a fruitful\narea for comparative retrogame archaeology, because a number of early games on\ndifferent platforms featured mazes, and their variety of approaches can be\ncompared. The maze in Entombed is particularly interesting: it is shaped in\npart by the extensive real-time constraints of the Atari 2600 platform, and\nalso had to be generated efficiently and use next to no memory. We reverse\nengineered key areas of the game's code to uncover its unusual maze-generation\nalgorithm, which we have also built a reconstruction of, and analyzed the\nmysterious table that drives it. In addition, we discovered what appears to be\na 35-year-old bug in the code, as well as direct evidence of code-reuse\npractices amongst game developers.\nWhat further makes this game's development interesting is that, in an era\nwhere video games were typically solo projects, a total of five people were\ninvolved in various ways with Entombed. We piece together some of the backstory\nof the game's development and intoxicant-fueled design using interviews to\ncomplement our technical work.\nFinally, we contextualize this example in archaeology and lay the groundwork\nfor a broader interdisciplinary discussion about programming, one that includes\nboth computer scientists and archaeologists.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stability and elasticity of metastable solid solutions and superlattices in the MoN-TaN system: a first-principles study.   Employing ab initio calculations, we discuss chemical, mechanical, and\ndynamical stability of MoN-TaN solid solutions together with cubic-like MoN/TaN\nsuperlattices, as another materials design concept. Hexagonal-type structures\nbased on low-energy modifications of MoN and TaN are the most stable ones over\nthe whole composition range. Despite being metastable, disordered cubic\npolymorphs are energetically significantly preferred over their ordered\ncounterparts. An in-depth analysis of atomic environments in terms of bond\nlengths and angles reveals that the chemical disorder results in (partially)\nbroken symmetry, i.e., the disordered cubic structure relaxes towards a\nhexagonal NiAs-type phase, the ground state of MoN. Surprisingly, also the\nsuperlattice architecture is clearly favored over the ordered cubic solid\nsolution. We show that the bi-axial coherency stresses in superlattices break\nthe cubic symmetry beyond simple tetragonal distortions and lead to a new\ntetragonal $\\zeta$-phase (space group P4/nmm), which exhibits a more negative\nformation energy than the symmetry-stabilized cubic structures of MoN and TaN.\nUnlike cubic TaN, the $\\zeta\\text{-TaN}$ is elastically and vibrationally\nstable, while $\\zeta$-MoN is stabilized only by the superlattice structure. To\nmap compositional trends in elasticity, we establish mechanical stability of\nvarious Mo$_{1-x}$Ta$_x$N systems and find the closest high-symmetry\napproximants of the corresponding elastic tensors. According to the estimated\npolycrystalline moduli, the hexagonal polymorphs are predicted to be extremely\nhard, however, less ductile than the cubic phases and superlattices. The trends\nin stability based on energetics and elasticity are corroborated by density of\nelectronic states.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Generalization of Convolutional Neural Networks to Graph-Structured Data.   This paper introduces a generalization of Convolutional Neural Networks\n(CNNs) from low-dimensional grid data, such as images, to graph-structured\ndata. We propose a novel spatial convolution utilizing a random walk to uncover\nthe relations within the input, analogous to the way the standard convolution\nuses the spatial neighborhood of a pixel on the grid. The convolution has an\nintuitive interpretation, is efficient and scalable and can also be used on\ndata with varying graph structure. Furthermore, this generalization can be\napplied to many standard regression or classification problems, by learning the\nthe underlying graph. We empirically demonstrate the performance of the\nproposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular\nactivity data set.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Combinatorial Optimization Algorithms over Graphs.   The design of good heuristics or approximation algorithms for NP-hard\ncombinatorial optimization problems often requires significant specialized\nknowledge and trial-and-error. Can we automate this challenging, tedious\nprocess, and learn the algorithms instead? In many real-world applications, it\nis typically the case that the same optimization problem is solved again and\nagain on a regular basis, maintaining the same problem structure but differing\nin the data. This provides an opportunity for learning heuristic algorithms\nthat exploit the structure of such recurring problems. In this paper, we\npropose a unique combination of reinforcement learning and graph embedding to\naddress this challenge. The learned greedy policy behaves like a meta-algorithm\nthat incrementally constructs a solution, and the action is determined by the\noutput of a graph embedding network capturing the current state of the\nsolution. We show that our framework can be applied to a diverse range of\noptimization problems over graphs, and learns effective algorithms for the\nMinimum Vertex Cover, Maximum Cut and Traveling Salesman problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Sparsification of Recurrent Neural Networks.   Recurrent neural networks show state-of-the-art results in many text analysis\ntasks but often require a lot of memory to store their weights. Recently\nproposed Sparse Variational Dropout eliminates the majority of the weights in a\nfeed-forward neural network without significant loss of quality. We apply this\ntechnique to sparsify recurrent neural networks. To account for recurrent\nspecifics we also rely on Binary Variational Dropout for RNN. We report 99.5%\nsparsity level on sentiment analysis task without a quality drop and up to 87%\nsparsity level on language modeling task with slight loss of accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Characteristics of stratified flows of Newtonian/non-Newtonian shear-thinning fluids.   Exact solutions for laminar stratified flows of Newtonian/non-Newtonian\nshear-thinning fluids in horizontal and inclined channels are presented. An\niterative algorithm is proposed to compute the laminar solution for the general\ncase of a Carreau non-Newtonian fluid. The exact solution is used to study the\neffect of the rheology of the shear-thinning liquid on two-phase flow\ncharacteristics considering both gas/liquid and liquid/liquid systems.\nConcurrent and counter-current inclined systems are investigated, including the\nmapping of multiple solution boundaries. Aspects relevant to practical\napplications are discussed, such as the insitu hold-up, or lubrication effects\nachieved by adding a less viscous phase. A characteristic of this family of\nsystems is that, even if the liquid has a complex rheology (Carreau fluid), the\ntwo-phase stratified flow can behave like the liquid is Newtonian for a wide\nrange of operational conditions. The capability of the two-fluid model to yield\nsatisfactory predictions in the presence of shear-thinning liquids is tested,\nand an algorithm is proposed to a priori predict if the Newtonian (zero shear\nrate viscosity) behaviour arises for a given operational conditions in order to\navoid large errors in the predictions of flow characteristics when the\npower-law is considered for modelling the shear-thinning behaviour. Two-fluid\nmodel closures implied by the exact solution and the effect of a turbulent gas\nlayer are also addressed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Interacting Fields and Flows: Magnetic Hot Jupiters.   We present Magnetohydrodynamic (MHD) simulations of the magnetic interactions\nbetween a solar type star and short period hot Jupiter exoplanets, using the\npublicly available MHD code PLUTO. It has been predicted that emission due to\nmagnetic interactions such as the electron cyclotron maser instability (ECMI)\nwill be observable. In our simulations, a planetary outflow, due to UV\nevaporation of the exoplanets atmosphere, results in the build-up of\ncircumplanetary material. We predict the ECMI emission and determine that the\nemission is prevented from escaping from the system. This is due to the\nevaporated material leading to a high plasma frequency in the vicinity of the\nplanet, which inhibits the ECMI process.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "F-index of graphs based on four operations related to the lexicographic product.   The forgotten topological index or F-index of a graph is defined as the sum\nof cubes of the degree of all the vertices of the graph. In this paper we study\nthe F-index of four operations related to the lexicographic product on graphs\nwhich were introduced by Sarala et al. [D. Sarala, H. Deng, S.K. Ayyaswamya and\nS. Balachandrana, The Zagreb indices of graphs based on four new operations\nrelated to the lexicographic product, \\textit{Applied Mathematics and\nComputation}, 309 (2017) 156--169.].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Batched High-dimensional Bayesian Optimization via Structural Kernel Learning.   Optimization of high-dimensional black-box functions is an extremely\nchallenging problem. While Bayesian optimization has emerged as a popular\napproach for optimizing black-box functions, its applicability has been limited\nto low-dimensional problems due to its computational and statistical challenges\narising from high-dimensional settings. In this paper, we propose to tackle\nthese challenges by (1) assuming a latent additive structure in the function\nand inferring it properly for more efficient and effective BO, and (2)\nperforming multiple evaluations in parallel to reduce the number of iterations\nrequired by the method. Our novel approach learns the latent structure with\nGibbs sampling and constructs batched queries using determinantal point\nprocesses. Experimental validations on both synthetic and real-world functions\ndemonstrate that the proposed method outperforms the existing state-of-the-art\napproaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Reliability-Aware Server Consolidation in Cloud Datacenters.   In the past few years, datacenter (DC) energy consumption has become an\nimportant issue in technology world. Server consolidation using virtualization\nand virtual machine (VM) live migration allows cloud DCs to improve resource\nutilization and hence energy efficiency. In order to save energy, consolidation\ntechniques try to turn off the idle servers, while because of workload\nfluctuations, these offline servers should be turned on to support the\nincreased resource demands. These repeated on-off cycles could affect the\nhardware reliability and wear-and-tear of servers and as a result, increase the\nmaintenance and replacement costs. In this paper we propose a holistic\nmathematical model for reliability-aware server consolidation with the\nobjective of minimizing total DC costs including energy and reliability costs.\nIn fact, we try to minimize the number of active PMs and racks, in a\nreliability-aware manner. We formulate the problem as a Mixed Integer Linear\nProgramming (MILP) model which is in form of NP-complete. Finally, we evaluate\nthe performance of our approach in different scenarios using extensive\nnumerical MATLAB simulations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parametrizations, weights, and optimal prediction: Part 1.   We consider the problem of the annual mean temperature prediction. The years\ntaken into account and the corresponding annual mean temperatures are denoted\nby $0,\\ldots, n$ and $t_0$, $\\ldots$, $t_n$, respectively. We propose to\npredict the temperature $t_{n+1}$ using the data $t_0$, $\\ldots$, $t_n$. For\neach $0\\leq l\\leq n$ and each parametrization $\\Theta^{(l)}$ of the Euclidean\nspace $\\mathbb{R}^{l+1}$ we construct a list of weights for the data\n$\\{t_0,\\ldots, t_l\\}$ based on the rows of $\\Theta^{(l)}$ which are correlated\nwith the constant trend. Using these weights we define a list of predictors of\n$t_{l+1}$ from the data $t_0$, $\\ldots$, $t_l$. We analyse how the\nparametrization affects the prediction, and provide three optimality criteria\nfor the selection of weights and parametrization. We illustrate our results for\nthe annual mean temperature of France and Morocco.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-Generic Unramified Representations in Metaplectic Covering Groups.   Let $G^{(r)}$ denote the metaplectic covering group of the linear algebraic\ngroup $G$. In this paper we study conditions on unramified representations of\nthe group $G^{(r)}$ not to have a nonzero Whittaker function. We state a\ngeneral Conjecture about the possible unramified characters $\\chi$ such that\nthe unramified sub-representation of\n$Ind_{B^{(r)}}^{G^{(r)}}\\chi\\delta_B^{1/2}$ will have no nonzero Whittaker\nfunction. We prove this Conjecture for the groups $GL_n^{(r)}$ with $r\\ge n-1$,\nand for the exceptional groups $G_2^{(r)}$ when $r\\ne 2$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Atomic Data Revisions for Transitions Relevant to Observations of Interstellar, Circumgalactic, and Intergalactic Matter.   Measurements of element abundances in galaxies from astrophysical\nspectroscopy depend sensitively on the atomic data used. With the goal of\nmaking the latest atomic data accessible to the community, we present a\ncompilation of selected atomic data for resonant absorption lines at\nwavelengths longward of 911.753 {\\AA} (the \\ion{H}{1} Lyman limit), for key\nheavy elements (heavier than atomic number 5) of astrophysical interest. In\nparticular, we focus on the transitions of those ions that have been observed\nin the Milky Way interstellar medium (ISM), the circumgalactic medium (CGM) of\nthe Milky Way and/or other galaxies, and the intergalactic medium (IGM).\nWe provide wavelengths, oscillator strengths, associated accuracy grades, and\nreferences to the oscillator strength determinations. We also attempt to\ncompare and assess the recent oscillator strength determinations. For about\n22\\% of the lines that have updated oscillator strength values, the differences\nbetween the former values and the updated ones are $\\gtrsim$~0.1 dex.\nOur compilation will be a useful resource for absorption line studies of the\nISM, as well as studies of the CGM and IGM traced by sight lines to quasars and\ngamma-ray bursts. Studies (including those enabled by future generations of\nextremely large telescopes) of absorption by galaxies against the light of\nbackground galaxies will also benefit from our compilation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bernoulli-Carlitz and Cauchy-Carlitz numbers with Stirling-Carlitz numbers.   Recently, the Cauchy-Carlitz number was defined as the counterpart of the\nBernoulli-Carlitz number. Both numbers can be expressed explicitly in terms of\nso-called Stirling-Carlitz numbers. In this paper, we study the second analogue\nof Stirling-Carlitz numbers and give some general formulae, including Bernoulli\nand Cauchy numbers in formal power series with complex coefficients, and\nBernoulli-Carlitz and Cauchy-Carlitz numbers in function fields. We also give\nsome applications of Hasse-Teichmüller derivative to hypergeometric Bernoulli\nand Cauchy numbers in terms of associated Stirling numbers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On (in)stabilities of perturbations in mimetic models with higher derivatives.   Usually when applying the mimetic model to the early universe, higher\nderivative terms are needed to promote the mimetic field to be dynamical.\nHowever such models suffer from the ghost and/or the gradient instabilities and\nsimple extensions cannot cure this pathology. We point out in this paper that\nit is possible to overcome this difficulty by considering the direct couplings\nof the higher derivatives of the mimetic field to the curvature of the\nspacetime.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "From optimal transport to generative modeling: the VEGAN cookbook.   We study unsupervised generative modeling in terms of the optimal transport\n(OT) problem between true (but unknown) data distribution $P_X$ and the latent\nvariable model distribution $P_G$. We show that the OT problem can be\nequivalently written in terms of probabilistic encoders, which are constrained\nto match the posterior and prior distributions over the latent space. When\nrelaxed, this constrained optimization problem leads to a penalized optimal\ntransport (POT) objective, which can be efficiently minimized using stochastic\ngradient descent by sampling from $P_X$ and $P_G$. We show that POT for the\n2-Wasserstein distance coincides with the objective heuristically employed in\nadversarial auto-encoders (AAE) (Makhzani et al., 2016), which provides the\nfirst theoretical justification for AAEs known to the authors. We also compare\nPOT to other popular techniques like variational auto-encoders (VAE) (Kingma\nand Welling, 2014). Our theoretical results include (a) a better understanding\nof the commonly observed blurriness of images generated by VAEs, and (b)\nestablishing duality between Wasserstein GAN (Arjovsky and Bottou, 2017) and\nPOT for the 1-Wasserstein distance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Noise Cancellation Using Deep Cerebellar Model Articulation Controller.   This paper proposes a deep cerebellar model articulation controller (DCMAC)\nfor adaptive noise cancellation (ANC). We expand upon the conventional CMAC by\nstacking sin-gle-layer CMAC models into multiple layers to form a DCMAC model\nand derive a modified backpropagation training algorithm to learn the DCMAC\nparameters. Com-pared with conventional CMAC, the DCMAC can characterize\nnonlinear transformations more effectively because of its deep structure.\nExperimental results confirm that the pro-posed DCMAC model outperforms the\nCMAC in terms of residual noise in an ANC task, showing that DCMAC provides\nenhanced modeling capability based on channel characteristics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bound states of the two-dimensional Dirac equation for an energy-dependent hyperbolic Scarf potential.   We study the two-dimensional massless Dirac equation for a potential that is\nallowed to depend on the energy and on one of the spatial variables. After\ndetermining a modified orthogonality relation and norm for such systems, we\npresent an application involving an energy-dependent version of the hyperbolic\nScarf potential. We construct closed-form bound state solutions of the\nassociated Dirac equation.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "First measeurements in search for keV-sterile neutrino in tritium beta-decay by Troitsk nu-mass experiment.   We present the first measurements of tritium beta-decay spectrum in the\nelectron energy range 16-18.6 keV. The goal is to find distortions which may\ncorrespond to the presence of a heavy sterile neutrinos. A possible\ncontribution of this kind would manifest itself as a kink in the spectrum with\na similar shape but with end point shifted by the value of a heavy neutrino\nmass. We set a new upper limits to the neutrino mixing matrix element U^2_{e4}\nwhich improve existing limits by a factor from 2 to 5 in the mass range 0.1-2\nkeV.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Accelerated Consensus via Min-Sum Splitting.   We apply the Min-Sum message-passing protocol to solve the consensus problem\nin distributed optimization. We show that while the ordinary Min-Sum algorithm\ndoes not converge, a modified version of it known as Splitting yields\nconvergence to the problem solution. We prove that a proper choice of the\ntuning parameters allows Min-Sum Splitting to yield subdiffusive accelerated\nconvergence rates, matching the rates obtained by shift-register methods. The\nacceleration scheme embodied by Min-Sum Splitting for the consensus problem\nbears similarities with lifted Markov chains techniques and with multi-step\nfirst order methods in convex optimization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Hand-Held Multimedia Translation and Interpretation System with Application to Diet Management.   We propose a network independent, hand-held system to translate and\ndisambiguate foreign restaurant menu items in real-time. The system is based on\nthe use of a portable multimedia device, such as a smartphones or a PDA. An\naccurate and fast translation is obtained using a Machine Translation engine\nand a context-specific corpora to which we apply two pre-processing steps,\ncalled translation standardization and $n$-gram consolidation. The phrase-table\ngenerated is orders of magnitude lighter than the ones commonly used in market\napplications, thus making translations computationally less expensive, and\ndecreasing the battery usage. Translation ambiguities are mitigated using\nmultimedia information including images of dishes and ingredients, along with\ningredient lists. We implemented a prototype of our system on an iPod Touch\nSecond Generation for English speakers traveling in Spain. Our tests indicate\nthat our translation method yields higher accuracy than translation engines\nsuch as Google Translate, and does so almost instantaneously. The memory\nrequirements of the application, including the database of images, are also\nwell within the limits of the device. By combining it with a database of\nnutritional information, our proposed system can be used to help individuals\nwho follow a medical diet maintain this diet while traveling.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotics of Hankel determinants with a one-cut regular potential and Fisher-Hartwig singularities.   We obtain asymptotics of large Hankel determinants whose weight depends on a\none-cut regular potential and any number of Fisher-Hartwig singularities. This\ngeneralises two results: 1) a result of Berestycki, Webb and Wong [5] for\nroot-type singularities, and 2) a result of Its and Krasovsky [37] for a\nGaussian weight with a single jump-type singularity. We show that when we apply\na piecewise constant thinning on the eigenvalues of a random Hermitian matrix\ndrawn from a one-cut regular ensemble, the gap probability in the thinned\nspectrum, as well as correlations of the characteristic polynomial of the\nassociated conditional point process, can be expressed in terms of these\ndeterminants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonparametric Poisson regression from independent and weakly dependent observations by model selection.   We consider the non-parametric Poisson regression problem where the integer\nvalued response $Y$ is the realization of a Poisson random variable with\nparameter $\\lambda(X)$. The aim is to estimate the functional parameter\n$\\lambda$ from independent or weakly dependent observations\n$(X_1,Y_1),\\ldots,(X_n,Y_n)$ in a random design framework.\nFirst we determine upper risk bounds for projection estimators on finite\ndimensional subspaces under mild conditions. In the case of Sobolev ellipsoids\nthe obtained rates of convergence turn out to be optimal.\nThe main part of the paper is devoted to the construction of adaptive\nprojection estimators of $\\lambda$ via model selection. We proceed in two\nsteps: first, we assume that an upper bound for $\\Vert \\lambda \\Vert_\\infty$ is\nknown. Under this assumption, we construct an adaptive estimator whose\ndimension parameter is defined as the minimizer of a penalized contrast\ncriterion. Second, we replace the known upper bound on $\\Vert \\lambda\n\\Vert_\\infty$ by an appropriate plug-in estimator of $\\Vert \\lambda\n\\Vert_\\infty$. The resulting adaptive estimator is shown to attain the minimax\noptimal rate up to an additional logarithmic factor both in the independent and\nthe weakly dependent setup. Appropriate concentration inequalities for Poisson\npoint processes turn out to be an important ingredient of the proofs.\nWe illustrate our theoretical findings by a short simulation study and\nconclude by indicating directions of future research.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Multi-objective Optimization on a Budget: Application to multi-pass wire drawing with quantified uncertainties.   Design optimization of engineering systems with multiple competing objectives\nis a painstakingly tedious process especially when the objective functions are\nexpensive-to-evaluate computer codes with parametric uncertainties. The\neffectiveness of the state-of-the-art techniques is greatly diminished because\nthey require a large number of objective evaluations, which makes them\nimpractical for problems of the above kind. Bayesian global optimization (BGO),\nhas managed to deal with these challenges in solving single-objective\noptimization problems and has recently been extended to multi-objective\noptimization (MOO). BGO models the objectives via probabilistic surrogates and\nuses the epistemic uncertainty to define an information acquisition function\n(IAF) that quantifies the merit of evaluating the objective at new designs.\nThis iterative data acquisition process continues until a stopping criterion is\nmet. The most commonly used IAF for MOO is the expected improvement over the\ndominated hypervolume (EIHV) which in its original form is unable to deal with\nparametric uncertainties or measurement noise. In this work, we provide a\nsystematic reformulation of EIHV to deal with stochastic MOO problems. The\nprimary contribution of this paper lies in being able to filter out the noise\nand reformulate the EIHV without having to observe or estimate the stochastic\nparameters. An addendum of the probabilistic nature of our methodology is that\nit enables us to characterize our confidence about the predicted Pareto front.\nWe verify and validate the proposed methodology by applying it to synthetic\ntest problems with known solutions. We demonstrate our approach on an\nindustrial problem of die pass design for a steel wire drawing process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Caching Meets Millimeter Wave Communications for Enhanced Mobility Management in 5G Networks.   One of the most promising approaches to overcome the uncertainty and dynamic\nchannel variations of millimeter wave (mmW) communications is to deploy\ndual-mode base stations that integrate both mmW and microwave ($\\mu$W)\nfrequencies. If properly designed, such dual-mode base stations can enhance\nmobility and handover in highly mobile wireless environments. In this paper, a\nnovel approach for analyzing and managing mobility in joint $\\mu$W-mmW networks\nis proposed. The proposed approach leverages device-level caching along with\nthe capabilities of dual-mode base stations to minimize handover failures,\nreduce inter-frequency measurement energy consumption, and provide seamless\nmobility in emerging dense heterogeneous networks. First, fundamental results\non the caching capabilities, including caching probability and cache duration\nare derived for the proposed dual-mode network scenario. Second, the average\nachievable rate of caching is derived for mobile users. Third, the proposed\ncache-enabled mobility management problem is formulated as a dynamic matching\ngame between mobile user equipments (MUEs) and small base stations (SBSs). The\ngoal of this game is to find a distributed handover mechanism that subject to\nthe network constraints on HOFs and limited cache sizes, allows each MUE to\nchoose between executing an HO to a target SBS, being connected to the\nmacrocell base station (MBS), or perform a transparent HO by using the cached\ncontent. The formulated matching game allows capturing the dynamics of the\nmobility management problem caused by HOFs. To solve this dynamic matching\nproblem, a novel algorithm is proposed and its convergence to a two-sided\ndynamically stable HO policy is proved. Numerical results corroborate the\nanalytical derivations and show that the proposed solution will provides\nsignificant reductions in both the HOF and energy consumption by MUEs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Suppression of material transfer at contacting surfaces: The effect of adsorbates on Al/TiN and Cu/diamond interfaces from first-principles calculations.   The effect of monolayers of oxygen (O) and hydrogen (H) on the possibility of\nmaterial transfer at aluminium/titanium nitride (Al/TiN) and copper/diamond\n(Cu/C$_{\\text{dia}}$) interfaces, respectively, were investigated within the\nframework of density functional theory (DFT). To this end the approach,\ncontact, and subsequent separation of two atomically flat surfaces consisting\nof the aforementioned pairs of materials were simulated. These calculations\nwere performed for the clean as well as oxygenated and hydrogenated Al and\nC$_{\\text{dia}}$ surfaces, respectively. Various contact configurations were\nconsidered by studying several lateral arrangements of the involved surfaces at\nthe interface. Material transfer is typically possible at interfaces between\nthe investigated clean surfaces; however, the addition of O to the Al and H to\nthe C$_{\\text{dia}}$ surfaces was found to hinder material transfer. This\npassivation occurs because of a significant reduction of the adhesion energy at\nthe examined interfaces, which can be explained by the distinct bonding\nsituations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Pre-Synaptic Pool Modification (PSPM): A Supervised Learning Procedure for Spiking Neural Networks.   A central question in neuroscience is how to develop realistic models that\npredict output firing behavior based on provided external stimulus. Given a set\nof external inputs and a set of output spike trains, the objective is to\ndiscover a network structure which can accomplish the transformation as\naccurately as possible. Due to the difficulty of this problem in its most\ngeneral form, approximations have been made in previous work. Past\napproximations have sacrificed network size, recurrence, allowed spiked count,\nor have imposed layered network structure. Here we present a learning rule\nwithout these sacrifices, which produces a weight matrix of a leaky\nintegrate-and-fire (LIF) network to match the output activity of both\ndeterministic LIF networks as well as probabilistic integrate-and-fire (PIF)\nnetworks. Inspired by synaptic scaling, our pre-synaptic pool modification\n(PSPM) algorithm outputs deterministic, fully recurrent spiking neural networks\nthat can provide a novel generative model for given spike trains. Similarity in\noutput spike trains is evaluated with a variety of metrics including a\nvan-Rossum like measure and a numerical comparison of inter-spike interval\ndistributions. Application of our algorithm to randomly generated networks\nimproves similarity to the reference spike trains on both of these stated\nmeasures. In addition, we generated LIF networks that operate near criticality\nwhen trained on critical PIF outputs. Our results establish that learning rules\nbased on synaptic homeostasis can be used to represent input-output\nrelationships in fully recurrent spiking neural networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Nonlinear Dimensionality Reduction, Linear Smoothing and Autoencoding.   We develop theory for nonlinear dimensionality reduction (NLDR). A number of\nNLDR methods have been developed, but there is limited understanding of how\nthese methods work and the relationships between them. There is limited basis\nfor using existing NLDR theory for deriving new algorithms. We provide a novel\nframework for analysis of NLDR via a connection to the statistical theory of\nlinear smoothers. This allows us to both understand existing methods and derive\nnew ones. We use this connection to smoothing to show that asymptotically,\nexisting NLDR methods correspond to discrete approximations of the solutions of\nsets of differential equations given a boundary condition. In particular, we\ncan characterize many existing methods in terms of just three limiting\ndifferential operators and boundary conditions. Our theory also provides a way\nto assert that one method is preferable to another; indeed, we show Local\nTangent Space Alignment is superior within a class of methods that assume a\nglobal coordinate chart defines an isometric embedding of the manifold.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning an internal representation of the end-effector configuration space.   Current machine learning techniques proposed to automatically discover a\nrobot kinematics usually rely on a priori information about the robot's\nstructure, sensors properties or end-effector position. This paper proposes a\nmethod to estimate a certain aspect of the forward kinematics model with no\nsuch information. An internal representation of the end-effector configuration\nis generated from unstructured proprioceptive and exteroceptive data flow under\nvery limited assumptions. A mapping from the proprioceptive space to this\nrepresentational space can then be used to control the robot.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sample Efficient Feature Selection for Factored MDPs.   In reinforcement learning, the state of the real world is often represented\nby feature vectors. However, not all of the features may be pertinent for\nsolving the current task. We propose Feature Selection Explore and Exploit\n(FS-EE), an algorithm that automatically selects the necessary features while\nlearning a Factored Markov Decision Process, and prove that under mild\nassumptions, its sample complexity scales with the in-degree of the dynamics of\njust the necessary features, rather than the in-degree of all features. This\ncan result in a much better sample complexity when the in-degree of the\nnecessary features is smaller than the in-degree of all features.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Approximate Message-Passing Decoder for Universal Sparse Superposition Codes.   Sparse superposition (SS) codes were originally proposed as a\ncapacity-achieving communication scheme over the additive white Gaussian noise\nchannel (AWGNC) [1]. Very recently, it was discovered that these codes are\nuniversal, in the sense that they achieve capacity over any memoryless channel\nunder generalized approximate message-passing (GAMP) decoding [2], although\nthis decoder has never been stated for SS codes. In this contribution we\nintroduce the GAMP decoder for SS codes, we confirm empirically the\nuniversality of this communication scheme through its study on various channels\nand we provide the main analysis tools: state evolution and potential. We also\ncompare the performance of GAMP with the Bayes-optimal MMSE decoder. We\nempirically illustrate that despite the presence of a phase transition\npreventing GAMP to reach the optimal performance, spatial coupling allows to\nboost the performance that eventually tends to capacity in a proper limit. We\nalso prove that, in contrast with the AWGNC case, SS codes for binary input\nchannels have a vanishing error floor in the limit of large codewords.\nMoreover, the performance of Hadamard-based encoders is assessed for practical\nimplementations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Complete algebraic solution of multidimensional optimization problems in tropical semifield.   We consider multidimensional optimization problems that are formulated in the\nframework of tropical mathematics to minimize functions defined on vectors over\na tropical semifield (a semiring with idempotent addition and invertible\nmultiplication). The functions, given by a matrix and calculated through\nmultiplicative conjugate transposition, are nonlinear in the tropical\nmathematics sense. We start with known results on the solution of the problems\nwith irreducible matrices. To solve the problems in the case of arbitrary\n(reducible) matrices, we first derive the minimum value of the objective\nfunction, and find a set of solutions. We show that all solutions of the\nproblem satisfy a system of vector inequalities, and then use these\ninequalities to establish characteristic properties of the solution set.\nFurthermore, all solutions of the problem are represented as a family of\nsubsets, each defined by a matrix that is obtained by using a matrix\nsparsification technique. We describe a backtracking procedure that allows one\nto reduce the brute-force generation of sparsified matrices by skipping those,\nwhich cannot provide solutions, and thus offers an economical way to obtain all\nsubsets in the family. Finally, the characteristic properties of the solution\nset are used to provide complete solutions in a closed form. We illustrate the\nresults obtained with simple numerical examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Urban Vibrancy and Safety in Philadelphia.   Statistical analyses of urban environments have been recently improved\nthrough publicly available high resolution data and mapping technologies that\nhave been adopted across industries. These technologies allow us to create\nmetrics to empirically investigate urban design principles of the past\nhalf-century. Philadelphia is an interesting case study for this work, with its\nrapid urban development and population increase in the last decade. We outline\na data analysis pipeline for exploring the association between safety and local\nneighborhood features such as population, economic health and the built\nenvironment. As a particular example of our analysis pipeline, we focus on\nquantitative measures of the built environment that serve as proxies for\nvibrancy: the amount of human activity in a local area. Historically, vibrancy\nhas been very challenging to measure empirically. Measures based on land use\nzoning are not an adequate description of local vibrancy and so we construct a\ndatabase and set of measures of business activity in each neighborhood. We\nemploy several matching analyses to explore the relationship between\nneighborhood vibrancy and safety, such as comparing high crime versus low crime\nlocations within the same neighborhood. As additional sources of urban data\nbecome available, our analysis pipeline can serve as the template for further\ninvestigations into the relationships between safety, economic factors and the\nbuilt environment at the local neighborhood level.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On perpetuities with gamma-like tails.   An infinite convergent sum of independent and identically distributed random\nvariables discounted by a multiplicative random walk is called perpetuity,\nbecause of a possible actuarial application. We give three disjoint groups of\nsufficient conditions which ensure that the distribution right tail of a\nperpetuity $\\mathbb{P}\\{X>x\\}$ is asymptotic to $ax^ce^{-bx}$ as $x\\to\\infty$\nfor some $a,b>0$ and $c\\in\\mathbb{R}$. Our results complement those of Denisov\nand Zwart [J. Appl. Probab. 44 (2007), 1031--1046]. As an auxiliary tool we\nprovide criteria for the finiteness of the one-sided exponential moments of\nperpetuities. Several examples are given in which the distributions of\nperpetuities are explicitly identified.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phrase-based Image Captioning with Hierarchical LSTM Model.   Automatic generation of caption to describe the content of an image has been\ngaining a lot of research interests recently, where most of the existing works\ntreat the image caption as pure sequential data. Natural language, however\npossess a temporal hierarchy structure, with complex dependencies between each\nsubsequence. In this paper, we propose a phrase-based hierarchical Long\nShort-Term Memory (phi-LSTM) model to generate image description. In contrast\nto the conventional solutions that generate caption in a pure sequential\nmanner, our proposed model decodes image caption from phrase to sentence. It\nconsists of a phrase decoder at the bottom hierarchy to decode noun phrases of\nvariable length, and an abbreviated sentence decoder at the upper hierarchy to\ndecode an abbreviated form of the image description. A complete image caption\nis formed by combining the generated phrases with sentence during the inference\nstage. Empirically, our proposed model shows a better or competitive result on\nthe Flickr8k, Flickr30k and MS-COCO datasets in comparison to the state-of-the\nart models. We also show that our proposed model is able to generate more novel\ncaptions (not seen in the training data) which are richer in word contents in\nall these three datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detecting and Explaining Causes From Text For a Time Series Event.   Explaining underlying causes or effects about events is a challenging but\nvaluable task. We define a novel problem of generating explanations of a time\nseries event by (1) searching cause and effect relationships of the time series\nwith textual data and (2) constructing a connecting chain between them to\ngenerate an explanation. To detect causal features from text, we propose a\nnovel method based on the Granger causality of time series between features\nextracted from text such as N-grams, topics, sentiments, and their composition.\nThe generation of the sequence of causal entities requires a commonsense\ncausative knowledge base with efficient reasoning. To ensure good\ninterpretability and appropriate lexical usage we combine symbolic and neural\nrepresentations, using a neural reasoning algorithm trained on commonsense\ncausal tuples to predict the next cause step. Our quantitative and human\nanalysis show empirical evidence that our method successfully extracts\nmeaningful causality relationships between time series with textual features\nand generates appropriate explanation between them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Consistency of Dirichlet Partitions.   A Dirichlet $k$-partition of a domain $U \\subseteq \\mathbb{R}^d$ is a\ncollection of $k$ pairwise disjoint open subsets such that the sum of their\nfirst Laplace-Dirichlet eigenvalues is minimal. A discrete version of Dirichlet\npartitions has been posed on graphs with applications in data analysis. Both\nversions admit variational formulations: solutions are characterized by\nminimizers of the Dirichlet energy of mappings from $U$ into a singular space\n$\\Sigma_k \\subseteq \\mathbb{R}^k$. In this paper, we extend results of N.\\\nGarcía Trillos and D.\\ Slepčev to show that there exist solutions of the\ncontinuum problem arising as limits to solutions of a sequence of discrete\nproblems. Specifically, a sequence of points $\\{x_i\\}_{i \\in \\mathbb{N}}$ from\n$U$ is sampled i.i.d.\\ with respect to a given probability measure $\\nu$ on $U$\nand for all $n \\in \\mathbb{N}$, a geometric graph $G_n$ is constructed from the\nfirst $n$ points $x_1, x_2, \\ldots, x_n$ and the pairwise distances between the\npoints. With probability one with respect to the choice of points $\\{x_i\\}_{i\n\\in \\mathbb{N}}$, we show that as $n \\to \\infty$ the discrete Dirichlet\nenergies for functions $G_n \\to \\Sigma_k$ $\\Gamma$-converge to (a scalar\nmultiple of) the continuum Dirichlet energy for functions $U \\to \\Sigma_k$ with\nrespect to a metric coming from the theory of optimal transport. This, along\nwith a compactness property for the aforementioned energies that we prove,\nimplies the convergence of minimizers. When $\\nu$ is the uniform distribution,\nour results also imply the statistical consistency statement that Dirichlet\npartitions of geometric graphs converge to partitions of the sampled space in\nthe Hausdorff sense.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Reactive and Efficient Walking Pattern Generator for Robust Bipedal Locomotion.   Available possibilities to prevent a biped robot from falling down in the\npresence of severe disturbances are mainly Center of Pressure (CoP) modulation,\nstep location and timing adjustment, and angular momentum regulation. In this\npaper, we aim at designing a walking pattern generator which employs an optimal\ncombination of these tools to generate robust gaits. In this approach, first,\nthe next step location and timing are decided consistent with the commanded\nwalking velocity and based on the Divergent Component of Motion (DCM)\nmeasurement. This stage which is done by a very small-size Quadratic Program\n(QP) uses the Linear Inverted Pendulum Model (LIPM) dynamics to adapt the\nswitching contact location and time. Then, consistent with the first stage, the\nLIPM with flywheel dynamics is used to regenerate the DCM and angular momentum\ntrajectories at each control cycle. This is done by modulating the CoP and\nCentroidal Momentum Pivot (CMP) to realize a desired DCM at the end of current\nstep. Simulation results show the merit of this reactive approach in generating\nrobust and dynamically consistent walking patterns.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Muon g-2 experiment at Fermilab.   The upcoming Fermilab E989 experiment will measure the muon anomalous\nmagnetic moment $a_{\\mu}$ . This measurement is motivated by the previous\nmeasurement performed in 2001 by the BNL E821 experiment that reported a 3-4\nstandard deviation discrepancy between the measured value and the Standard\nModel prediction. The new measurement at Fermilab aims to improve the precision\nby a factor of four reducing the total uncertainty from 540 parts per billion\n(BNL E821) to 140 parts per billion (Fermilab E989). This paper gives the\nstatus of the experiment.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Covering and tiling hypergraphs with tight cycles.   Given $3 \\leq k \\leq s$, we say that a $k$-uniform hypergraph $C^k_s$ is a\ntight cycle on $s$ vertices if there is a cyclic ordering of the vertices of\n$C^k_s$ such that every $k$ consecutive vertices under this ordering form an\nedge. We prove that if $k \\ge 3$ and $s \\ge 2k^2$, then every $k$-uniform\nhypergraph on $n$ vertices with minimum codegree at least $(1/2 + o(1))n$ has\nthe property that every vertex is covered by a copy of $C^k_s$. Our result is\nasymptotically best possible for infinitely many pairs of $s$ and $k$, e.g.\nwhen $s$ and $k$ are coprime.\nA perfect $C^k_s$-tiling is a spanning collection of vertex-disjoint copies\nof $C^k_s$. When $s$ is divisible by $k$, the problem of determining the\nminimum codegree that guarantees a perfect $C^k_s$-tiling was solved by a\nresult of Mycroft. We prove that if $k \\ge 3$ and $s \\ge 5k^2$ is not divisible\nby $k$ and $s$ divides $n$, then every $k$-uniform hypergraph on $n$ vertices\nwith minimum codegree at least $(1/2 + 1/(2s) + o(1))n$ has a perfect\n$C^k_s$-tiling. Again our result is asymptotically best possible for infinitely\nmany pairs of $s$ and $k$, e.g. when $s$ and $k$ are coprime with $k$ even.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "QWIRE Practice: Formal Verification of Quantum Circuits in Coq.   We describe an embedding of the QWIRE quantum circuit language in the Coq\nproof assistant. This allows programmers to write quantum circuits using\nhigh-level abstractions and to prove properties of those circuits using Coq's\ntheorem proving features. The implementation uses higher-order abstract syntax\nto represent variable binding and provides a type-checking algorithm for linear\nwire types, ensuring that quantum circuits are well-formed. We formalize a\ndenotational semantics that interprets QWIRE circuits as superoperators on\ndensity matrices, and prove the correctness of some simple quantum programs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Normal-state Properties of a Unitary Bose-Fermi Mixture: A Combined Strong-coupling Approach with Universal Thermodynamics.   We theoretically investigate normal-state properties of a unitary Bose-Fermi\nmixture. Including strong hetero-pairing fluctuations, we evaluate the Bose and\nFermi chemical potential, internal energy, pressure, entropy, as well as\nspecific heat at constant volume $C_V$, within the framework of a combined\nstrong-coupling theory with exact thermodynamic identities. We show that\nhetero-pairing fluctuations at the unitarity cause non-monotonic temperature\ndependence of $C_V$, being qualitatively different from the monotonic behavior\nof this quantity in the weak- and strong-coupling limit. On the other hand,\nsuch an anomalous behavior is not seen in the other quantities. Our results\nindicate that the specific heat $C_V$, which has recently become observable in\ncold atom physics, is a useful quantity for understanding strong-coupling\naspects of this quantum system.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "BézierGAN: Automatic Generation of Smooth Curves from Interpretable Low-Dimensional Parameters.   Many real-world objects are designed by smooth curves, especially in the\ndomain of aerospace and ship, where aerodynamic shapes (e.g., airfoils) and\nhydrodynamic shapes (e.g., hulls) are designed. To facilitate the design\nprocess of those objects, we propose a deep learning based generative model\nthat can synthesize smooth curves. The model maps a low-dimensional latent\nrepresentation to a sequence of discrete points sampled from a rational\nBézier curve. We demonstrate the performance of our method in completing both\nsynthetic and real-world generative tasks. Results show that our method can\ngenerate diverse and realistic curves, while preserving consistent shape\nvariation in the latent space, which is favorable for latent space design\noptimization or design space exploration.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nearest-neighbour Markov point processes on graphs with Euclidean edges.   We define nearest-neighbour point processes on graphs with Euclidean edges\nand linear networks. They can be seen as the analogues of renewal processes on\nthe real line. We show that the Delaunay neighbourhood relation on a tree\nsatisfies the Baddeley--M{\\o}ller consistency conditions and provide a\ncharacterisation of Markov functions with respect to this relation. We show\nthat a modified relation defined in terms of the local geometry of the graph\nsatisfies the consistency conditions for all graphs with Euclidean edges.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Resilience of Life to Astrophysical Events.   Much attention has been given in the literature to the effects of\nastrophysical events on human and land-based life. However, little has been\ndiscussed on the resilience of life itself. Here we instead explore the\nstatistics of events that completely sterilise an Earth-like planet with planet\nradii in the range $0.5-1.5 R_{Earth}$ and temperatures of $\\sim 300 \\;\n\\text{K}$, eradicating all forms of life. We consider the relative likelihood\nof complete global sterilisation events from three astrophysical sources --\nsupernovae, gamma-ray bursts, large asteroid impacts, and passing-by stars. To\nassess such probabilities we consider what cataclysmic event could lead to the\nannihilation of not just human life, but also extremophiles, through the\nboiling of all water in Earth's oceans. Surprisingly we find that although\nhuman life is somewhat fragile to nearby events, the resilience of Ecdysozoa\nsuch as \\emph{Milnesium tardigradum} renders global sterilisation an unlikely\nevent.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A supernova at 50 pc: Effects on the Earth's atmosphere and biota.   Recent 60Fe results have suggested that the estimated distances of supernovae\nin the last few million years should be reduced from 100 pc to 50 pc. Two\nevents or series of events are suggested, one about 2.7 million years to 1.7\nmillion years ago, and another may at 6.5 to 8.7 million years ago. We ask what\neffects such supernovae are expected to have on the terrestrial atmosphere and\nbiota. Assuming that the Local Bubble was formed before the event being\nconsidered, and that the supernova and the Earth were both inside a weak,\ndisordered magnetic field at that time, TeV-PeV cosmic rays at Earth will\nincrease by a factor of a few hundred. Tropospheric ionization will increase\nproportionately, and the overall muon radiation load on terrestrial organisms\nwill increase by a factor of 150. All return to pre-burst levels within 10kyr.\nIn the case of an ordered magnetic field, effects depend strongly on the field\norientation. The upper bound in this case is with a largely coherent field\naligned along the line of sight to the supernova, in which case TeV-PeV cosmic\nray flux increases are 10^4; in the case of a transverse field they are below\ncurrent levels. We suggest a substantial increase in the extended effects of\nsupernovae on Earth and in the lethal distance estimate; more work is\nneeded.This paper is an explicit followup to Thomas et al. (2016). We also here\nprovide more detail on the computational procedures used in both works.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Experimental study of extrinsic spin Hall effect in CuPt alloy.   We have experimentally studied the effects on the spin Hall angle due to\nsystematic addition of Pt into the light metal Cu. We perform spin torque\nferromagnetic resonance measurements on Py/CuPt bilayer and find that as the Pt\nconcentration increases, the spin Hall angle of CuPt alloy increases. Moreover,\nonly 28% Pt in CuPt alloy can give rise to a spin Hall angle close to that of\nPt. We further extract the spin Hall resistivity of CuPt alloy for different Pt\nconcentrations and find that the contribution of skew scattering is larger for\nlower Pt concentrations, while the side-jump contribution is larger for higher\nPt concentrations. From technological perspective, since the CuPt alloy can\nsustain high processing temperatures and Cu is the most common metallization\nelement in the Si platform, it would be easier to integrate the CuPt alloy\nbased spintronic devices into existing Si fabrication technology.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weakly- and Semi-Supervised Object Detection with Expectation-Maximization Algorithm.   Object detection when provided image-level labels instead of instance-level\nlabels (i.e., bounding boxes) during training is an important problem in\ncomputer vision, since large scale image datasets with instance-level labels\nare extremely costly to obtain. In this paper, we address this challenging\nproblem by developing an Expectation-Maximization (EM) based object detection\nmethod using deep convolutional neural networks (CNNs). Our method is\napplicable to both the weakly-supervised and semi-supervised settings.\nExtensive experiments on PASCAL VOC 2007 benchmark show that (1) in the weakly\nsupervised setting, our method provides significant detection performance\nimprovement over current state-of-the-art methods, (2) having access to a small\nnumber of strongly (instance-level) annotated images, our method can almost\nmatch the performace of the fully supervised Fast RCNN. We share our source\ncode at this https URL.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A parametric level-set method for partially discrete tomography.   This paper introduces a parametric level-set method for tomographic\nreconstruction of partially discrete images. Such images consist of a\ncontinuously varying background and an anomaly with a constant (known)\ngrey-value. We represent the geometry of the anomaly using a level-set\nfunction, which we represent using radial basis functions. We pose the\nreconstruction problem as a bi-level optimization problem in terms of the\nbackground and coefficients for the level-set function. To constrain the\nbackground reconstruction we impose smoothness through Tikhonov regularization.\nThe bi-level optimization problem is solved in an alternating fashion; in each\niteration we first reconstruct the background and consequently update the\nlevel-set function. We test our method on numerical phantoms and show that we\ncan successfully reconstruct the geometry of the anomaly, even from limited\ndata. On these phantoms, our method outperforms Total Variation reconstruction,\nDART and P-DART.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Merlin-Arthur with efficient quantum Merlin and quantum supremacy for the second level of the Fourier hierarchy.   We introduce a simple sub-universal quantum computing model, which we call\nthe Hadamard-classical circuit with one-qubit (HC1Q) model. It consists of a\nclassical reversible circuit sandwiched by two layers of Hadamard gates, and\ntherefore it is in the second level of the Fourier hierarchy. We show that\noutput probability distributions of the HC1Q model cannot be classically\nefficiently sampled within a multiplicative error unless the polynomial-time\nhierarchy collapses to the second level. The proof technique is different from\nthose used for previous sub-universal models, such as IQP, Boson Sampling, and\nDQC1, and therefore the technique itself might be useful for finding other\nsub-universal models that are hard to classically simulate. We also study the\nclassical verification of quantum computing in the second level of the Fourier\nhierarchy. To this end, we define a promise problem, which we call the\nprobability distribution distinguishability with maximum norm (PDD-Max). It is\na promise problem to decide whether output probability distributions of two\nquantum circuits are far apart or close. We show that PDD-Max is BQP-complete,\nbut if the two circuits are restricted to some types in the second level of the\nFourier hierarchy, such as the HC1Q model or the IQP model, PDD-Max has a\nMerlin-Arthur system with quantum polynomial-time Merlin and classical\nprobabilistic polynomial-time Arthur.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Supersonic Flow onto Solid Wedges, Multidimensional Shock Waves and Free Boundary Problems.   When an upstream steady uniform supersonic flow impinges onto a symmetric\nstraight-sided wedge, governed by the Euler equations, there are two possible\nsteady oblique shock configurations if the wedge angle is less than the\ndetachment angle -- the steady weak shock with supersonic or subsonic\ndownstream flow (determined by the wedge angle that is less or larger than the\nsonic angle) and the steady strong shock with subsonic downstream flow, both of\nwhich satisfy the entropy condition. The fundamental issue -- whether one or\nboth of the steady weak and strong shocks are physically admissible solutions\n-- has been vigorously debated over the past eight decades. In this paper, we\nsurvey some recent developments on the stability analysis of the steady shock\nsolutions in both the steady and dynamic regimes. For the static stability, we\nfirst show how the stability problem can be formulated as an initial-boundary\nvalue type problem and then reformulate it into a free boundary problem when\nthe perturbation of both the upstream steady supersonic flow and the wedge\nboundary are suitably regular and small, and we finally present some recent\nresults on the static stability of the steady supersonic and transonic shocks.\nFor the dynamic stability for potential flow, we first show how the stability\nproblem can be formulated as an initial-boundary value problem and then use the\nself-similarity of the problem to reduce it into a boundary value problem and\nfurther reformulate it into a free boundary problem, and we finally survey some\nrecent developments in solving this free boundary problem for the existence of\nthe Prandtl-Meyer configurations that tend to the steady weak supersonic or\ntransonic oblique shock solutions as time goes to infinity. Some further\ndevelopments and mathematical challenges in this direction are also discussed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Structure preserving schemes for mean-field equations of collective behavior.   In this paper we consider the development of numerical schemes for mean-field\nequations describing the collective behavior of a large group of interacting\nagents. The schemes are based on a generalization of the classical Chang-Cooper\napproach and are capable to preserve the main structural properties of the\nsystems, namely nonnegativity of the solution, physical conservation laws,\nentropy dissipation and stationary solutions. In particular, the methods here\nderived are second order accurate in transient regimes whereas they can reach\narbitrary accuracy asymptotically for large times. Several examples are\nreported to show the generality of the approach.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Exponential Decay of the lengths of Spectral Gaps for Extended Harper's Model with Liouvillean Frequency.   In this paper, we study the non-self dual extended Harper's model with\nLiouvillean frequency. By establishing quantitative reducibility results\ntogether with the averaging method, we prove that the lengths of spectral gaps\ndecay exponentially.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Octupolar Tensors for Liquid Crystals.   A third-order three-dimensional symmetric traceless tensor, called the\n\\emph{octupolar} tensor, has been introduced to study tetrahedratic nematic\nphases in liquid crystals. The octupolar \\emph{potential}, a scalar-valued\nfunction generated on the unit sphere by that tensor, should ideally have four\nmaxima capturing the most probable molecular orientations (on the vertices of a\ntetrahedron), but it was recently found to possess an equally generic variant\nwith \\emph{three} maxima instead of four. It was also shown that the\nirreducible admissible region for the octupolar tensor in a three-dimensional\nparameter space is bounded by a dome-shaped surface, beneath which is a\n\\emph{separatrix} surface connecting the two generic octupolar states. The\nlatter surface, which was obtained through numerical continuation, may be\nphysically interpreted as marking a possible \\emph{intra-octupolar} transition.\nIn this paper, by using the resultant theory of algebraic geometry and the\nE-characteristic polynomial of spectral theory of tensors, we give a\nclosed-form, algebraic expression for both the dome-shaped surface and the\nseparatrix surface. This turns the envisaged intra-octupolar transition into a\nquantitative, possibly observable prediction. Some other properties of\noctupolar tensors are also studied.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "The relationship between the number of editorial board members and the scientific output of universities in the chemistry field.   Editorial board members, who are considered the gatekeepers of scientific\njournals, play an important role in academia, and may directly or indirectly\naffect the scientific output of a university. In this article, we used the\nquantile regression method among a sample of 1,387 university in chemistry to\ncharacterize the correlation between the number of editorial board members and\nthe scientific output of their universities. Furthermore, we used time-series\ndata and the Granger causality test to explore the causal relationship between\nthe number of editorial board members and the number of articles of some top\nuniversities. Our results suggest that the number of editorial board members is\npositively and significantly related to the scientific output (as measured by\nthe number of articles, total number of citations, citations per paper, and h\nindex) of their universities. However, the Granger causality test results\nsuggest that the causal relationship between the number of editorial board\nmembers and the number of articles of some top universities is not obvious.\nCombining these findings with the results of qualitative interviews with\neditorial board members, we discuss the causal relationship between the number\nof editorial board members and the scientific output of their universities.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On 2d-4d motivic wall-crossing formulas.   In this paper we propose definitions and examples of categorical enhancements\nof the data involved in the $2d$-$4d$ wall-crossing formulas which generalize\nboth Cecotti-Vafa and Kontsevich-Soibelman motivic wall-crossing formulas.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accurate Single Stage Detector Using Recurrent Rolling Convolution.   Most of the recent successful methods in accurate object detection and\nlocalization used some variants of R-CNN style two stage Convolutional Neural\nNetworks (CNN) where plausible regions were proposed in the first stage then\nfollowed by a second stage for decision refinement. Despite the simplicity of\ntraining and the efficiency in deployment, the single stage detection methods\nhave not been as competitive when evaluated in benchmarks consider mAP for high\nIoU thresholds. In this paper, we proposed a novel single stage end-to-end\ntrainable object detection network to overcome this limitation. We achieved\nthis by introducing Recurrent Rolling Convolution (RRC) architecture over\nmulti-scale feature maps to construct object classifiers and bounding box\nregressors which are \"deep in context\". We evaluated our method in the\nchallenging KITTI dataset which measures methods under IoU threshold of 0.7. We\nshowed that with RRC, a single reduced VGG-16 based model already significantly\noutperformed all the previously published results. At the time this paper was\nwritten our models ranked the first in KITTI car detection (the hard level),\nthe first in cyclist detection and the second in pedestrian detection. These\nresults were not reached by the previous single stage methods. The code is\npublicly available.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Composition Properties of Inferential Privacy for Time-Series Data.   With the proliferation of mobile devices and the internet of things,\ndeveloping principled solutions for privacy in time series applications has\nbecome increasingly important. While differential privacy is the gold standard\nfor database privacy, many time series applications require a different kind of\nguarantee, and a number of recent works have used some form of inferential\nprivacy to address these situations.\nHowever, a major barrier to using inferential privacy in practice is its lack\nof graceful composition -- even if the same or related sensitive data is used\nin multiple releases that are safe individually, the combined release may have\npoor privacy properties. In this paper, we study composition properties of a\nform of inferential privacy called Pufferfish when applied to time-series data.\nWe show that while general Pufferfish mechanisms may not compose gracefully, a\nspecific Pufferfish mechanism, called the Markov Quilt Mechanism, which was\nrecently introduced, has strong composition properties comparable to that of\npure differential privacy when applied to time series data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Typed Closure Conversion for the Calculus of Constructions.   Dependently typed languages such as Coq are used to specify and verify the\nfull functional correctness of source programs. Type-preserving compilation can\nbe used to preserve these specifications and proofs of correctness through\ncompilation into the generated target-language programs. Unfortunately,\ntype-preserving compilation of dependent types is hard. In essence, the problem\nis that dependent type systems are designed around high-level compositional\nabstractions to decide type checking, but compilation interferes with the\ntype-system rules for reasoning about run-time terms.\nWe develop a type-preserving closure-conversion translation from the Calculus\nof Constructions (CC) with strong dependent pairs ($\\Sigma$ types)---a subset\nof the core language of Coq---to a type-safe, dependently typed compiler\nintermediate language named CC-CC. The central challenge in this work is how to\ntranslate the source type-system rules for reasoning about functions into\ntarget type-system rules for reasoning about closures. To justify these rules,\nwe prove soundness of CC-CC by giving a model in CC. In addition to type\npreservation, we prove correctness of separate compilation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pseudo asymptotically periodic solutions for fractional integro-differential neutral equations.   In this paper, we study the existence and uniqueness of pseudo\n$S$-asymptotically $\\omega$-periodic mild solutions of class $r$ for fractional\nintegro-differential neutral equations. An example is presented to illustrate\nthe application of the abstract results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Benford analysis of quantum critical phenomena: First digit provides high finite-size scaling exponent while first two and further are not much better.   Benford's law is an empirical edict stating that the lower digits appear more\noften than higher ones as the first few significant digits in statistics of\nnatural phenomena and mathematical tables. A marked proportion of such analyses\nis restricted to the first significant digit. We employ violation of Benford's\nlaw, up to the first four significant digits, for investigating magnetization\nand correlation data of paradigmatic quantum many-body systems to detect\ncooperative phenomena, focusing on the finite-size scaling exponents thereof.\nWe find that for the transverse field quantum XY model, behavior of the very\nfirst significant digit of an observable, at an arbitrary point of the\nparameter space, is enough to capture the quantum phase transition in the model\nwith a relatively high scaling exponent. A higher number of significant digits\ndo not provide an appreciable further advantage, in particular, in terms of an\nincrease in scaling exponents. Since the first significant digit of a physical\nquantity is relatively simple to obtain in experiments, the results have\npotential implications for laboratory observations in noisy environments.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Security Analysis of Cache Replacement Policies.   Modern computer architectures share physical resources between different\nprograms in order to increase area-, energy-, and cost-efficiency.\nUnfortunately, sharing often gives rise to side channels that can be exploited\nfor extracting or transmitting sensitive information. We currently lack\ntechniques for systematic reasoning about this interplay between security and\nefficiency. In particular, there is no established way for quantifying security\nproperties of shared caches.\nIn this paper, we propose a novel model that enables us to characterize\nimportant security properties of caches. Our model encompasses two aspects: (1)\nThe amount of information that can be absorbed by a cache, and (2) the amount\nof information that can effectively be extracted from the cache by an\nadversary. We use our model to compute both quantities for common cache\nreplacement policies (FIFO, LRU, and PLRU) and to compare their isolation\nproperties. We further show how our model for information extraction leads to\nan algorithm that can be used to improve the bounds delivered by the CacheAudit\nstatic analyzer.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SGD Learns the Conjugate Kernel Class of the Network.   We show that the standard stochastic gradient decent (SGD) algorithm is\nguaranteed to learn, in polynomial time, a function that is competitive with\nthe best function in the conjugate kernel space of the network, as defined in\nDaniely, Frostig and Singer. The result holds for log-depth networks from a\nrich family of architectures. To the best of our knowledge, it is the first\npolynomial-time guarantee for the standard neural network learning algorithm\nfor networks of depth more that two.\nAs corollaries, it follows that for neural networks of any depth between $2$\nand $\\log(n)$, SGD is guaranteed to learn, in polynomial time, constant degree\npolynomials with polynomially bounded coefficients. Likewise, it follows that\nSGD on large enough networks can learn any continuous function (not in\npolynomial time), complementing classical expressivity results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A tutorial on the synthesis and validation of a closed-loop wind farm controller using a steady-state surrogate model.   In wind farms, wake interaction leads to losses in power capture and\naccelerated structural degradation when compared to freestanding turbines. One\nmethod to reduce wake losses is by misaligning the rotor with the incoming flow\nusing its yaw actuator, thereby laterally deflecting the wake away from\ndownstream turbines. However, this demands an accurate and computationally\ntractable model of the wind farm dynamics. This problem calls for a closed-loop\nsolution. This tutorial paper fills the scientific gap by demonstrating the\nfull closed-loop controller synthesis cycle using a steady-state surrogate\nmodel. Furthermore, a novel, computationally efficient and modular\ncommunication interface is presented that enables researchers to\nstraight-forwardly test their control algorithms in large-eddy simulations.\nHigh-fidelity simulations of a 9-turbine farm show a power production increase\nof up to 11% using the proposed closed-loop controller compared to traditional,\ngreedy wind farm operation.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Identification of Voice Utterance with Aging Factor Using the Method of MFCC Multichannel.   This research was conducted to develop a method to identify voice utterance.\nFor voice utterance that encounters change caused by aging factor, with the\ninterval of 10 to 25 years. The change of voice utterance influenced by aging\nfactor might be extracted by MFCC (Mel Frequency Cepstrum Coefficient).\nHowever, the level of the compatibility of the feature may be dropped down to\n55%. While the ones which do not encounter it may reach 95%. To improve the\ncompatibility of the changing voice feature influenced by aging factor, then\nthe method of the more specific feature extraction is developed: which is by\nseparating the voice into several channels, suggested as MFCC multichannel,\nconsisting of multichannel 5 filterbank (M5FB), multichannel 2 filterbank\n(M2FB) and multichannel 1 filterbank (M1FB). The result of the test shows that\nfor model M5FB and M2FB have the highest score in the level of compatibility\nwith 85% and 82% with 25 years interval. While model M5FB gets the highest\nscore of 86% for 10 years time interval.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Architectures for Neural Machine Translation.   It has been shown that increasing model depth improves the quality of neural\nmachine translation. However, different architectural variants to increase\nmodel depth have been proposed, and so far, there has been no thorough\ncomparative study.\nIn this work, we describe and evaluate several existing approaches to\nintroduce depth in neural machine translation. Additionally, we explore novel\narchitectural variants, including deep transition RNNs, and we vary how\nattention is used in the deep decoder. We introduce a novel \"BiDeep\" RNN\narchitecture that combines deep transition RNNs and stacked RNNs.\nOur evaluation is carried out on the English to German WMT news translation\ndataset, using a single-GPU machine for both training and inference. We find\nthat several of our proposed architectures improve upon existing approaches in\nterms of speed and translation quality. We obtain best improvements with a\nBiDeep RNN of combined depth 8, obtaining an average improvement of 1.5 BLEU\nover a strong shallow baseline.\nWe release our code for ease of adoption.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamics of Relaxed Inflation.   The cosmological relaxation of the electroweak scale has been proposed as a\nmechanism to address the hierarchy problem of the Standard Model. A field, the\nrelaxion, rolls down its potential and, in doing so, scans the squared mass\nparameter of the Higgs, relaxing it to a parametrically small value. In this\nwork, we promote the relaxion to an inflaton. We couple it to Abelian gauge\nbosons, thereby introducing the necessary dissipation mechanism which slows\ndown the field in the last stages. We describe a novel reheating mechanism,\nwhich relies on the gauge-boson production leading to strong electromagnetic\nfields, and proceeds via the vacuum production of electron-positron pairs\nthrough the Schwinger effect. We refer to this mechanism as Schwinger\nreheating. We discuss the cosmological dynamics of the model and the\nphenomenological constraints from CMB and other experiments. We find that a\ncutoff close to the Planck scale may be achieved. In its minimal form, the\nmodel does not generate sufficient curvature perturbations and additional\ningredients, such as a curvaton field, are needed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Borel subsets of the real line and continuous reducibility.   We study classes of Borel subsets of the real line $\\mathbb{R}$ such as\nlevels of the Borel hierarchy and the class of sets that are reducible to the\nset $\\mathbb{Q}$ of rationals, endowed with the Wadge quasi-order of\nreducibility with respect to continuous functions on $\\mathbb{R}$. Notably, we\nexplore several structural properties of Borel subsets of $\\mathbb{R}$ that\ndiverge from those of Polish spaces with dimension zero. Our first main result\nis on the existence of embeddings of several posets into the restriction of\nthis quasi-order to any Borel class that is strictly above the classes of open\nand closed sets, for instance the linear order $\\omega_1$, its reverse\n$\\omega_1^\\star$ and the poset $\\mathcal{P}(\\omega)/\\mathsf{fin}$ of inclusion\nmodulo finite error. As a consequence of its proof, it is shown that there are\nno complete sets for these classes. We further extend the previous theorem to\ntargets that are reducible to $\\mathbb{Q}$. These non-structure results\nmotivate the study of further restrictions of the Wadge quasi-order. In our\nsecond main theorem, we introduce a combinatorial property that is shown to\ncharacterize those $F_\\sigma$ sets that are reducible to $\\mathbb{Q}$. This is\napplied to construct a minimal set below $\\mathbb{Q}$ and prove its uniqueness\nup to Wadge equivalence. We finally prove several results concerning gaps and\ncardinal characteristics of the Wadge quasi-order and thereby answer questions\nof Brendle and Geschke.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning to Detect and Mitigate Cross-layer Attacks in Wireless Networks: Framework and Applications.   Security threats such as jamming and route manipulation can have significant\nconsequences on the performance of modern wireless networks. To increase the\nefficacy and stealthiness of such threats, a number of extremely challenging,\ncross-layer attacks have been recently unveiled. Although existing research has\nthoroughly addressed many single-layer attacks, the problem of detecting and\nmitigating cross-layer attacks still remains unsolved. For this reason, in this\npaper we propose a novel framework to analyze and address cross-layer attacks\nin wireless networks. Specifically, our framework consists of a detection and a\nmitigation component. The attack detection component is based on a Bayesian\nlearning detection scheme that constructs a model of observed evidence to\nidentify stealthy attack activities. The mitigation component comprises a\nscheme that achieves the desired trade-off between security and performance. We\nspecialize and evaluate the proposed framework by considering a specific\ncross-layer attack that uses jamming as an auxiliary tool to achieve route\nmanipulation. Simulations and experimental results obtained with a test-bed\nmade up by USRP software-defined radios demonstrate the effectiveness of the\nproposed methodology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Space of initial conditions for a cubic Hamiltonian system.   In this paper we perform the analysis that leads to the space of initial\nconditions for the Hamiltonian system $q' = p^2 + zq + \\alpha$, $p' = -q^2 - zp\n- \\beta$, studied by the author in an earlier article. By compactifying the\nphase space of the system from $\\mathbb{C}^2$ to $\\mathbb{CP}^2$ three base\npoints arise in the standard coordinate charts covering the complex projective\nspace. Each of these is removed by a sequence of three blow-ups, a construction\nto regularise the system at these points. The resulting space, where the\nexceptional curves introduced after the first and second blow-up are removed,\nis the so-called Okamoto's space of initial conditions for this system which,\nat every point, defines a regular initial value problem in some coordinate\nchart of the space.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Trajectory Tracking Control of a Flexible Spine Robot, With and Without a Reference Input.   The Underactuated Lightweight Tensegrity Robotic Assistive Spine (ULTRA\nSpine) project is an ongoing effort to develop a flexible, actuated backbone\nfor quadruped robots. In this work, model-predictive control is used to track a\ntrajectory in the robot's state space, in simulation. The state trajectory used\nhere corresponds to a bending motion of the spine, with translations and\nrotations of the moving vertebrae. Two different controllers are presented in\nthis work: one that does not use a reference input but includes smoothing\nconstrants, and a second one that uses a reference input without smoothing. For\nthe smoothing controller, without reference inputs, the error converges to\nzero, while the simpler-to-tune controller with an input reference shows small\nerrors but not complete convergence. It is expected that this controller will\nconverge as it is improved further.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Survey on Mobile Edge Computing: The Communication Perspective.   Driven by the visions of Internet of Things and 5G communications, recent\nyears have seen a paradigm shift in mobile computing, from the centralized\nMobile Cloud Computing towards Mobile Edge Computing (MEC). The main feature of\nMEC is to push mobile computing, network control and storage to the network\nedges (e.g., base stations and access points) so as to enable\ncomputation-intensive and latency-critical applications at the resource-limited\nmobile devices. MEC promises dramatic reduction in latency and mobile energy\nconsumption, tackling the key challenges for materializing 5G vision. The\npromised gains of MEC have motivated extensive efforts in both academia and\nindustry on developing the technology. A main thrust of MEC research is to\nseamlessly merge the two disciplines of wireless communications and mobile\ncomputing, resulting in a wide-range of new designs ranging from techniques for\ncomputation offloading to network architectures. This paper provides a\ncomprehensive survey of the state-of-the-art MEC research with a focus on joint\nradio-and-computational resource management. We also present a research outlook\nconsisting of a set of promising directions for MEC research, including MEC\nsystem deployment, cache-enabled MEC, mobility management for MEC, green MEC,\nas well as privacy-aware MEC. Advancements in these directions will facilitate\nthe transformation of MEC from theory to practice. Finally, we introduce recent\nstandardization efforts on MEC as well as some typical MEC application\nscenarios.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Generalized Function defined by the Euler first kind integral and its connection with the Dirac delta function.   We have shown that in some region where the Euler integral of the first kind\ndiverges, the Euler formula defines a generalized function. The connected of\nthis generalized function with the Dirac delta function is found.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Well quasi-orders and the functional interpretation.   The purpose of this article is to study the role of Gödel's functional\ninterpretation in the extraction of programs from proofs in well quasi-order\ntheory. The main focus is on the interpretation of Nash-Williams' famous\nminimal bad sequence construction, and the exploration of a number of much\nbroader problems which are related to this, particularly the question of the\nconstructive meaning of Zorn's lemma and the notion of recursion over the\nnon-wellfounded lexicographic ordering on infinite sequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optical Music Recognition with Convolutional Sequence-to-Sequence Models.   Optical Music Recognition (OMR) is an important technology within Music\nInformation Retrieval. Deep learning models show promising results on OMR\ntasks, but symbol-level annotated data sets of sufficient size to train such\nmodels are not available and difficult to develop. We present a deep learning\narchitecture called a Convolutional Sequence-to-Sequence model to both move\ntowards an end-to-end trainable OMR pipeline, and apply a learning process that\ntrains on full sentences of sheet music instead of individually labeled\nsymbols. The model is trained and evaluated on a human generated data set, with\nvarious image augmentations based on real-world scenarios. This data set is the\nfirst publicly available set in OMR research with sufficient size to train and\nevaluate deep learning models. With the introduced augmentations a pitch\nrecognition accuracy of 81% and a duration accuracy of 94% is achieved,\nresulting in a note level accuracy of 80%. Finally, the model is compared to\ncommercially available methods, showing a large improvements over these\napplications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scene Graph Generation by Iterative Message Passing.   Understanding a visual scene goes beyond recognizing individual objects in\nisolation. Relationships between objects also constitute rich semantic\ninformation about the scene. In this work, we explicitly model the objects and\ntheir relationships using scene graphs, a visually-grounded graphical structure\nof an image. We propose a novel end-to-end model that generates such structured\nscene representation from an input image. The model solves the scene graph\ninference problem using standard RNNs and learns to iteratively improves its\npredictions via message passing. Our joint inference model can take advantage\nof contextual cues to make better predictions on objects and their\nrelationships. The experiments show that our model significantly outperforms\nprevious methods for generating scene graphs using Visual Genome dataset and\ninferring support relations with NYU Depth v2 dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Weak quadrupole moments.   Collective effects in deformed atomic nuclei present possible avenues of\nstudy on the non-spherical distribution of neutrons and the violation of the\nlocal Lorentz invariance. We introduce the weak quadrupole moment of nuclei,\nrelated to the quadrupole distribution of the weak charge in the nucleus. The\nweak quadrupole moment produces tensor weak interaction between the nucleus and\nelectrons and can be observed in atomic and molecular experiments measuring\nparity nonconservation. The dominating contribution to the weak quadrupole is\ngiven by the quadrupole moment of the neutron distribution, therefore,\ncorresponding experiments should allow one to measure the neutron quadrupoles.\nUsing the deformed oscillator model and the Schmidt model we calculate the\nquadrupole distributions of neutrons, $Q_{n}$, the weak quadrupole moments\n,$Q_{W}^{(2)}$, and the Lorentz Innvariance violating energy shifts in\n$^{9}$Be, $^{21}$Ne , $^{27}$Al, $^{131}$Xe, $^{133}$Cs, $^{151}$Eu,\n$^{153}$Eu, $^{163}$Dy, $^{167}$Er, $^{173}$Yb, $^{177}$Hf, $^{179}$Hf,\n$^{181}$Ta, $^{201}$Hg and $^{229}$Th.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Most Complex Non-Returning Regular Languages.   A regular language $L$ is non-returning if in the minimal deterministic\nfinite automaton accepting it there are no transitions into the initial state.\nEom, Han and Jirásková derived upper bounds on the state complexity of\nboolean operations and Kleene star, and proved that these bounds are tight\nusing two different binary witnesses. They derived upper bounds for\nconcatenation and reversal using three different ternary witnesses. These five\nwitnesses use a total of six different transformations. We show that for each\n$n\\ge 4$ there exists a ternary witness of state complexity $n$ that meets the\nbound for reversal and that at least three letters are needed to meet this\nbound. Moreover, the restrictions of this witness to binary alphabets meet the\nbounds for product, star, and boolean operations. We also derive tight upper\nbounds on the state complexity of binary operations that take arguments with\ndifferent alphabets. We prove that the maximal syntactic semigroup of a\nnon-returning language has $(n-1)^n$ elements and requires at least\n$\\binom{n}{2}$ generators. We find the maximal state complexities of atoms of\nnon-returning languages. Finally, we show that there exists a most complex\nnon-returning language that meets the bounds for all these complexity measures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Internal Boundaries (GIB).   Representing large-scale motions and topological changes in the finite volume\n(FV) framework, while at the same time preserving the accuracy of the numerical\nsolution, is difficult. In this paper, we present a robust, highly efficient\nmethod designed to achieve this capability. The proposed approach conceptually\nshares many of the characteristics of the cut-cell interface tracking method,\nbut without the need for complex cell splitting/merging operations. The heart\nof the new technique is to align existing mesh facets with the geometry to be\nrepresented. We then modify the matrix contributions from these facets such\nthat they are represented in an identical fashion to traditional boundary\nconditions. The collection of such faces is named a Generalised Internal\nBoundary (GIB). In order to introduce motion into the system, we rely on the\nclassical ALE (Arbitrary Lagrangian-Eulerian) approach, but with the caveat\nthat the non-time-dependent motion of elements instantaneously crossing the\ninterface is handled separately from the time dependent component. The new\nmethodology is validated through comparison with: a) a body-fitted grid\nsimulation of an oscillating two dimensional cylinder and b) experimental\nresults of a butterfly valve.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "On a family of Caldero-Chapoton algebras that have the Laurent phenomenon.   We realize a family of generalized cluster algebras as Caldero-Chapoton\nalgebras of quivers with relations. Each member of this family arises from an\nunpunctured polygon with one orbifold point of order 3, and is realized as a\nCaldero-Chapoton algebra of a quiver with relations naturally associated to any\ntriangulation of the alluded polygon. The realization is done by defining for\nevery arc $j$ on the polygon with orbifold point a representation $M(j)$ of the\nreferred quiver with relations, and by proving that for every triangulation\n$\\tau$ and every arc $j\\in\\tau$, the product of the Caldero-Chapoton functions\nof $M(j)$ and $M(j')$, where $j'$ is the arc that replaces $j$ when we flip $j$\nin $\\tau$, equals the corresponding exchange polynomial of Chekhov-Shapiro in\nthe generalized cluster algebra. Furthermore, we show that there is a bijection\nbetween the set of generalized cluster variables and the isomorphism classes of\n$E$-rigid indecomposable decorated representations of $\\Lambda$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On solving a restricted linear congruence using generalized Ramanujan sums.   Consider the linear congruence equation $x_1+\\ldots+x_k \\equiv b\\,(\\text{mod\n} n)$ for $b,n\\in\\mathbb{Z}$. By $(a,b)_s$, we mean the largest\n$l^s\\in\\mathbb{N}$ which divides $a$ and $b$ simultaneously. For each $d_j|n$,\ndefine $\\mathcal{C}_{j,s} = \\{1\\leq x\\leq n^s | (x,n^s)_s = d^s_j\\}$. Bibak et\nal. gave a formula using Ramanujan sums for the number of solutions of the\nabove congruence equation with some gcd restrictions on $x_i$. We generalize\ntheir result with generalized gcd restrictions on $x_i$ by proving that for the\nabove linear congruence, the number of solutions is\n$$\\frac{1}{n^s}\\sum\\limits_{d|n}c_{d,s}(b)\\prod\\limits_{j=1}^{\\tau(n)}\\left(c_{\\frac{n}{d_j},s}(\\frac{n^s}{d^s})\\right)^{g_j}$$\nwhere $g_j = |\\{x_1,\\ldots, x_k\\}\\cap \\mathcal{C}_{j,s}|$ for $j=1,\\ldots\n\\tau(n)$ and $c_{d,s}$ denote the generalized ramanujan sum defined by E.\nCohen.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tensors Come of Age: Why the AI Revolution will help HPC.   This article discusses how the automation of tensor algorithms, based on A\nMathematics of Arrays and Psi Calculus, and a new way to represent numbers,\nUnum Arithmetic, enables mechanically provable, scalable, portable, and more\nnumerically accurate software.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Capillary Surface with No Radial Limits.   In 1996, Kirk Lancaster and David Siegel investigated the existence and\nbehavior of radial limits at a corner of the boundary of the domain of\nsolutions of capillary and other prescribed mean curvature problems with\ncontact angle boundary data. In Theorem 3, they provide an example of a\ncapillary surface in a unit disk $D$ which has no radial limits at\n$(0,0)\\in\\partial D.$ In their example, the contact angle ($\\gamma$) cannot be\nbounded away from zero and $\\pi.$\nHere we consider a domain $\\Omega$ with a convex corner at $(0,0)$ and find a\ncapillary surface $z=f(x,y)$ in $\\Omega\\times\\mathbb{R}$ which has no radial\nlimits at $(0,0)\\in\\partial\\Omega$ such that $\\gamma$ is bounded away from $0$\nand $\\pi.$",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Robust Tie-line Scheduling in Multi-Area Power Systems.   The tie-line scheduling problem in a multi-area power system seeks to\noptimize tie-line power flows across areas that are independently operated by\ndifferent system operators (SOs). In this paper, we leverage the theory of\nmulti-parametric linear programming to propose algorithms for optimal tie-line\nscheduling within a deterministic and a robust optimization framework. Through\na coordinator, the proposed algorithms are proved to converge to the optimal\nschedule within a finite number of iterations. A key feature of the proposed\nalgorithms, besides their finite step convergence, is the privacy of the\ninformation exchanges; the SO in an area does not need to reveal its dispatch\ncost structure, network constraints, or the nature of the uncertainty set to\nthe coordinator. The performance of the algorithms is evaluated using several\npower system examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "INtERAcT: Interaction Network Inference from Vector Representations of Words.   In recent years, the number of biomedical publications has steadfastly grown,\nresulting in a rich source of untapped new knowledge. Most biomedical facts are\nhowever not readily available, but buried in the form of unstructured text, and\nhence their exploitation requires the time-consuming manual curation of\npublished articles. Here we present INtERAcT, a novel approach to extract\nprotein-protein interactions from a corpus of biomedical articles related to a\nbroad range of scientific domains in a completely unsupervised way. INtERAcT\nexploits vector representation of words, computed on a corpus of domain\nspecific knowledge, and implements a new metric that estimates an interaction\nscore between two molecules in the space where the corresponding words are\nembedded. We demonstrate the power of INtERAcT by reconstructing the molecular\npathways associated to 10 different cancer types using a corpus of\ndisease-specific articles for each cancer type. We evaluate INtERAcT using\nSTRING database as a benchmark, and show that our metric outperforms currently\nadopted approaches for similarity computation at the task of identifying known\nmolecular interactions in all studied cancer types. Furthermore, our approach\ndoes not require text annotation, manual curation or the definition of semantic\nrules based on expert knowledge, and hence it can be easily and efficiently\napplied to different scientific domains. Our findings suggest that INtERAcT may\nincrease our capability to summarize the understanding of a specific disease\nusing the published literature in an automated and completely unsupervised\nfashion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-Hamiltonian isotopic Lagrangians on the one-point blow-up of CP^2.   We show that two Hamiltonian isotopic Lagrangians in\n(CP^2,\\omega_\\textup{FS}) induce two Lagrangian submanifolds in the one-point\nblow-up (\\widetilde{CP}^2,\\widetilde{\\omega}_\\rho) that are not Hamiltonian\nisotopic. Furthermore, we show that for any integer k>1 there are k Hamiltonian\nisotopic Lagrangians in (CP^2,\\omega_\\textup{FS}) that induce k Lagrangian\nsubmanifolds in the one-point blow-up such that no two of them are Hamiltonian\nisotopic.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Large Scale Automated Forecasting for Monitoring Network Safety and Security.   Real time large scale streaming data pose major challenges to forecasting, in\nparticular defying the presence of human experts to perform the corresponding\nanalysis. We present here a class of models and methods used to develop an\nautomated, scalable and versatile system for large scale forecasting oriented\ntowards safety and security monitoring. Our system provides short and long term\nforecasts and uses them to detect safety and security issues in relation with\nmultiple internet connected devices well in advance they might take place.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Neurofeedback: principles, appraisal and outstanding issues.   Neurofeedback is a form of brain training in which subjects are fed back\ninformation about some measure of their brain activity which they are\ninstructed to modify in a way thought to be functionally advantageous. Over the\nlast twenty years, NF has been used to treat various neurological and\npsychiatric conditions, and to improve cognitive function in various contexts.\nHowever, despite its growing popularity, each of the main steps in NF comes\nwith its own set of often covert assumptions. Here we critically examine some\nconceptual and methodological issues associated with the way general objectives\nand neural targets of NF are defined, and review the neural mechanisms through\nwhich NF may act, and the way its efficacy is gauged. The NF process is\ncharacterised in terms of functional dynamics, and possible ways in which it\nmay be controlled are discussed. Finally, it is proposed that improving NF will\nrequire better understanding of various fundamental aspects of brain dynamics\nand a more precise definition of functional brain activity and brain-behaviour\nrelationships.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Meta Networks.   Neural networks have been successfully applied in applications with a large\namount of labeled data. However, the task of rapid generalization on new\nconcepts with small training data while preserving performances on previously\nlearned ones still presents a significant challenge to neural network models.\nIn this work, we introduce a novel meta learning method, Meta Networks\n(MetaNet), that learns a meta-level knowledge across tasks and shifts its\ninductive biases via fast parameterization for rapid generalization. When\nevaluated on Omniglot and Mini-ImageNet benchmarks, our MetaNet models achieve\na near human-level performance and outperform the baseline approaches by up to\n6% accuracy. We demonstrate several appealing properties of MetaNet relating to\ngeneralization and continual learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Playing Pairs with Pepper.   As robots become increasingly prevalent in almost all areas of society, the\nfactors affecting humans trust in those robots becomes increasingly important.\nThis paper is intended to investigate the factor of robot attributes, looking\nspecifically at the relationship between anthropomorphism and human development\nof trust. To achieve this, an interaction game, Matching the Pairs, was\ndesigned and implemented on two robots of varying levels of anthropomorphism,\nPepper and Husky. Participants completed both pre- and post-test questionnaires\nthat were compared and analyzed predominantly with the use of quantitative\nmethods, such as paired sample t-tests. Post-test analyses suggested a positive\nrelationship between trust and anthropomorphism with $80\\%$ of participants\nconfirming that the robots' adoption of facial features assisted in\nestablishing trust. The results also indicated a positive relationship between\ninteraction and trust with $90\\%$ of participants confirming this for both\nrobots post-test",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Program Synthesis from Visual Specification.   Program synthesis is the process of automatically translating a specification\ninto computer code. Traditional synthesis settings require a formal, precise\nspecification. Motivated by computer education applications where a student\nlearns to code simple turtle-style drawing programs, we study a novel synthesis\nsetting where only a noisy user-intention drawing is specified. This allows\nstudents to sketch their intended output, optionally together with their own\nincomplete program, to automatically produce a completed program. We formulate\nthis synthesis problem as search in the space of programs, with the score of a\nstate being the Hausdorff distance between the program output and the user\ndrawing. We compare several search algorithms on a corpus consisting of real\nuser drawings and the corresponding programs, and demonstrate that our\nalgorithms can synthesize programs optimally satisfying the specification.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The cavity approach for Steiner trees packing problems.   The Belief Propagation approximation, or cavity method, has been recently\napplied to several combinatorial optimization problems in its zero-temperature\nimplementation, the max-sum algorithm. In particular, recent developments to\nsolve the edge-disjoint paths problem and the prize-collecting Steiner tree\nproblem on graphs have shown remarkable results for several classes of graphs\nand for benchmark instances. Here we propose a generalization of these\ntechniques for two variants of the Steiner trees packing problem where multiple\n\"interacting\" trees have to be sought within a given graph. Depending on the\ninteraction among trees we distinguish the vertex-disjoint Steiner trees\nproblem, where trees cannot share nodes, from the edge-disjoint Steiner trees\nproblem, where edges cannot be shared by trees but nodes can be members of\nmultiple trees. Several practical problems of huge interest in network design\ncan be mapped into these two variants, for instance, the physical design of\nVery Large Scale Integration (VLSI) chips. The formalism described here relies\non two components edge-variables that allows us to formulate a massage-passing\nalgorithm for the V-DStP and two algorithms for the E-DStP differing in the\nscaling of the computational time with respect to some relevant parameters. We\nwill show that one of the two formalisms used for the edge-disjoint variant\nallow us to map the max-sum update equations into a weighted maximum matching\nproblem over proper bipartite graphs. We developed a heuristic procedure based\non the max-sum equations that shows excellent performance in synthetic networks\n(in particular outperforming standard multi-step greedy procedures by large\nmargins) and on large benchmark instances of VLSI for which the optimal\nsolution is known, on which the algorithm found the optimum in two cases and\nthe gap to optimality was never larger than 4 %.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Soft Weight-Sharing for Neural Network Compression.   The success of deep learning in numerous application domains created the de-\nsire to run and train them on mobile devices. This however, conflicts with\ntheir computationally, memory and energy intense nature, leading to a growing\ninterest in compression. Recent work by Han et al. (2015a) propose a pipeline\nthat involves retraining, pruning and quantization of neural network weights,\nobtaining state-of-the-art compression rates. In this paper, we show that\ncompetitive compression rates can be achieved by using a version of soft\nweight-sharing (Nowlan & Hinton, 1992). Our method achieves both quantization\nand pruning in one simple (re-)training procedure. This point of view also\nexposes the relation between compression and the minimum description length\n(MDL) principle.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structural subnetwork evolution across the life-span: rich-club, feeder, seeder.   The impact of developmental and aging processes on brain connectivity and the\nconnectome has been widely studied. Network theoretical measures and certain\ntopological principles are computed from the entire brain, however there is a\nneed to separate and understand the underlying subnetworks which contribute\ntowards these observed holistic connectomic alterations. One organizational\nprinciple is the rich-club - a core subnetwork of brain regions that are\nstrongly connected, forming a high-cost, high-capacity backbone that is\ncritical for effective communication in the network. Investigations primarily\nfocus on its alterations with disease and age. Here, we present a systematic\nanalysis of not only the rich-club, but also other subnetworks derived from\nthis backbone - namely feeder and seeder subnetworks. Our analysis is applied\nto structural connectomes in a normal cohort from a large, publicly available\nlifespan study. We demonstrate changes in rich-club membership with age\nalongside a shift in importance from 'peripheral' seeder to feeder subnetworks.\nOur results show a refinement within the rich-club structure (increase in\ntransitivity and betweenness centrality), as well as increased efficiency in\nthe feeder subnetwork and decreased measures of network integration and\nsegregation in the seeder subnetwork. These results demonstrate the different\ndevelopmental patterns when analyzing the connectome stratified according to\nits rich-club and the potential of utilizing this subnetwork analysis to reveal\nthe evolution of brain architectural alterations across the life-span.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Supervised Speech Separation Based on Deep Learning: An Overview.   Speech separation is the task of separating target speech from background\ninterference. Traditionally, speech separation is studied as a signal\nprocessing problem. A more recent approach formulates speech separation as a\nsupervised learning problem, where the discriminative patterns of speech,\nspeakers, and background noise are learned from training data. Over the past\ndecade, many supervised separation algorithms have been put forward. In\nparticular, the recent introduction of deep learning to supervised speech\nseparation has dramatically accelerated progress and boosted separation\nperformance. This article provides a comprehensive overview of the research on\ndeep learning based supervised speech separation in the last several years. We\nfirst introduce the background of speech separation and the formulation of\nsupervised separation. Then we discuss three main components of supervised\nseparation: learning machines, training targets, and acoustic features. Much of\nthe overview is on separation algorithms where we review monaural methods,\nincluding speech enhancement (speech-nonspeech separation), speaker separation\n(multi-talker separation), and speech dereverberation, as well as\nmulti-microphone techniques. The important issue of generalization, unique to\nsupervised learning, is discussed. This overview provides a historical\nperspective on how advances are made. In addition, we discuss a number of\nconceptual issues, including what constitutes the target source.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using Big Data Technologies for HEP Analysis.   The HEP community is approaching an era were the excellent performances of\nthe particle accelerators in delivering collision at high rate will force the\nexperiments to record a large amount of information. The growing size of the\ndatasets could potentially become a limiting factor in the capability to\nproduce scientific results timely and efficiently. Recently, new technologies\nand new approaches have been developed in industry to answer to the necessity\nto retrieve information as quickly as possible to analyze PB and EB datasets.\nProviding the scientists with these modern computing tools will lead to\nrethinking the principles of data analysis in HEP, making the overall\nscientific process faster and smoother.\nIn this paper, we are presenting the latest developments and the most recent\nresults on the usage of Apache Spark for HEP analysis. The study aims at\nevaluating the efficiency of the application of the new tools both\nquantitatively, by measuring the performances, and qualitatively, focusing on\nthe user experience. The first goal is achieved by developing a data reduction\nfacility: working together with CERN Openlab and Intel, CMS replicates a real\nphysics search using Spark-based technologies, with the ambition of reducing 1\nPB of public data in 5 hours, collected by the CMS experiment, to 1 TB of data\nin a format suitable for physics analysis.\nThe second goal is achieved by implementing multiple physics use-cases in\nApache Spark using as input preprocessed datasets derived from official CMS\ndata and simulation. By performing different end-analyses up to the publication\nplots on different hardware, feasibility, usability and portability are\ncompared to the ones of a traditional ROOT-based workflow.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Current induced magnetization switching in PtCoCr structures with enhanced perpendicular magnetic anisotropy and spin-orbit torques.   Magnetic trilayers having large perpendicular magnetic anisotropy (PMA) and\nhigh spin-orbit torques (SOTs) efficiency are the key to fabricate nonvolatile\nmagnetic memory and logic devices. In this work, PMA and SOTs are\nsystematically studied in Pt/Co/Cr stacks as a function of Cr thickness. An\nenhanced perpendicular anisotropy field around 10189 Oe is obtained and is\nrelated to the interface between Co and Cr layers. In addition, an effective\nspin Hall angle up to 0.19 is observed due to the improved antidamping-like\ntorque by employing dissimilar metals Pt and Cr with opposite signs of spin\nHall angles on opposite sides of Co layer. Finally, we observed a nearly linear\ndependence between spin Hall angle and longitudinal resistivity from their\ntemperature dependent properties, suggesting that the spin Hall effect may\narise from extrinsic skew scattering mechanism. Our results indicate that 3d\ntransition metal Cr with a large negative spin Hall angle could be used to\nengineer the interfaces of trilayers to enhance PMA and SOTs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Comparative Benchmarking of Causal Discovery Techniques.   In this paper we present a comprehensive view of prominent causal discovery\nalgorithms, categorized into two main categories (1) assuming acyclic and no\nlatent variables, and (2) allowing both cycles and latent variables, along with\nexperimental results comparing them from three perspectives: (a) structural\naccuracy, (b) standard predictive accuracy, and (c) accuracy of counterfactual\ninference. For (b) and (c) we train causal Bayesian networks with structures as\npredicted by each causal discovery technique to carry out counterfactual or\nstandard predictive inference. We compare causal algorithms on two pub- licly\navailable and one simulated datasets having different sample sizes: small,\nmedium and large. Experiments show that structural accuracy of a technique does\nnot necessarily correlate with higher accuracy of inferencing tasks. Fur- ther,\nsurveyed structure learning algorithms do not perform well in terms of\nstructural accuracy in case of datasets having large number of variables.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structure of martingale transports in finite dimensions.   We study the structure of martingale transports in finite dimensions. We\nconsider the family $\\mathcal{M}(\\mu,\\nu) $ of martingale measures on\n$\\mathbb{R}^N \\times \\mathbb{R}^N$ with given marginals $\\mu,\\nu$, and\nconstruct a family of relatively open convex sets $\\{C_x:x\\in \\mathbb{R}^N \\}$,\nwhich forms a partition of $\\mathbb{R}^N$, and such that any martingale\ntransport in $\\mathcal{M}(\\mu,\\nu) $ sends mass from $x$ to within\n$\\overline{C_x}$, $\\mu(dx)$--a.e. Our results extend the analogous\none-dimensional results of M. Beiglböck and N. Juillet (2016) and M.\nBeiglböck, M. Nutz, and N. Touzi (2015). We conjecture that the decomposition\nis canonical and minimal in the sense that it allows to characterise the\nmartingale polar sets, i.e. the sets which have zero mass under all measures in\n$\\mathcal{M}(\\mu,\\nu)$, and offers the martingale analogue of the\ncharacterisation of transport polar sets proved in M. Beiglböck, M.\nGoldstern, G. Maresch, and W. Schachermayer (2009).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On Gallai's and Hajós' Conjectures for graphs with treewidth at most 3.   A path (resp. cycle) decomposition of a graph $G$ is a set of edge-disjoint\npaths (resp. cycles) of $G$ that covers the edge set of $G$. Gallai (1966)\nconjectured that every graph on $n$ vertices admits a path decomposition of\nsize at most $\\lfloor (n+1)/2\\rfloor$, and Hajós (1968) conjectured that\nevery Eulerian graph on $n$ vertices admits a cycle decomposition of size at\nmost $\\lfloor (n-1)/2\\rfloor$. Gallai's Conjecture was verified for many\nclasses of graphs. In particular, Lovász (1968) verified this conjecture for\ngraphs with at most one vertex of even degree, and Pyber (1996) verified it for\ngraphs in which every cycle contains a vertex of odd degree. Hajós'\nConjecture, on the other hand, was verified only for graphs with maximum degree\n$4$ and for planar graphs. In this paper, we verify Gallai's and Hajós'\nConjectures for graphs with treewidth at most $3$. Moreover, we show that the\nonly graphs with treewidth at most $3$ that do not admit a path decomposition\nof size at most $\\lfloor n/2\\rfloor$ are isomorphic to $K_3$ or $K_5-e$.\nFinally, we use the technique developed in this paper to present new proofs for\nGallai's and Hajós' Conjectures for graphs with maximum degree at most $4$,\nand for planar graphs with girth at least $6$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Application of Convolutional Neural Network to Predict Airfoil Lift Coefficient.   The adaptability of the convolutional neural network (CNN) technique for\naerodynamic meta-modeling tasks is probed in this work. The primary objective\nis to develop suitable CNN architecture for variable flow conditions and object\ngeometry, in addition to identifying a sufficient data preparation process.\nMultiple CNN structures were trained to learn the lift coefficients of the\nairfoils with a variety of shapes in multiple flow Mach numbers, Reynolds\nnumbers, and diverse angles of attack. This is conducted to illustrate the\nconcept of the technique. A multi-layered perceptron (MLP) is also used for the\ntraining sets. The MLP results are compared with that of the CNN results. The\nnewly proposed meta-modeling concept has been found to be comparable with the\nMLP in learning capability; and more importantly, our CNN model exhibits a\ncompetitive prediction accuracy with minimal constraints in a geometric\nrepresentation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Uncertainty Principle for Estimates of Floquet Multipliers.   We derive a Cramér-Rao lower bound for the variance of Floquet multiplier\nestimates that have been constructed from stable limit cycles perturbed by\nnoise. To do so, we consider perturbed periodic orbits in the plane. We use a\nperiodic autoregressive process to model the intersections of these orbits with\ncross sections, then passing to the limit of a continuum of sections to obtain\na bound that depends on the continuous flow restricted to the (nontrivial)\nFloquet mode. We compare our bound against the empirical variance of estimates\nconstructed using several cross sections. The section-based estimates are close\nto being optimal. We posit that the utility of our bound persists in higher\ndimensions when computed along Floquet modes for real and distinct multipliers.\nOur bound elucidates some of the empirical observations noted in the\nliterature; e.g., (a) it is the number of cycles (as opposed to the frequency\nof observations) that drives the variance of estimates to zero, and (b) the\nestimator variance has a positive lower bound as the noise amplitude tends to\nzero.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Bistability of Cavity Magnon Polaritons.   We report the first observation of the magnon-polariton bistability in a\ncavity magnonics system consisting of cavity photons strongly interacting with\nthe magnons in a small yttrium iron garnet (YIG) sphere. The bistable behaviors\nare emerged as sharp frequency switchings of the cavity magnon-polaritons\n(CMPs) and related to the transition between states with large and small number\nof polaritons. In our experiment, we align, respectively, the [100] and [110]\ncrystallographic axes of the YIG sphere parallel to the static magnetic field\nand find very different bistable behaviors (e.g., clockwise and\ncounter-clockwise hysteresis loops) in these two cases. The experimental\nresults are well fitted and explained as being due to the Kerr nonlinearity\nwith either positive or negative coefficient. Moreover, when the magnetic field\nis tuned away from the anticrossing point of CMPs, we observe simultaneous\nbistability of both magnons and cavity photons by applying a drive field on the\nlower branch.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Continuity properties for Born-Jordan operators with symbols in Hörmander classes and modulation spaces.   We show that the Weyl symbol of a Born-Jordan operator is in the same class\nas the Born-Jordan symbol, when Hörmander symbols and certain types of\nmodulation spaces are used as symbol classes. We use these properties to carry\nover continuity and Schatten-von Neumann properties to the Born-Jordan\ncalculus.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Limitations on Variance-Reduction and Acceleration Schemes for Finite Sum Optimization.   We study the conditions under which one is able to efficiently apply\nvariance-reduction and acceleration schemes on finite sum optimization\nproblems. First, we show that, perhaps surprisingly, the finite sum structure\nby itself, is not sufficient for obtaining a complexity bound of\n$\\tilde{\\cO}((n+L/\\mu)\\ln(1/\\epsilon))$ for $L$-smooth and $\\mu$-strongly\nconvex individual functions - one must also know which individual function is\nbeing referred to by the oracle at each iteration. Next, we show that for a\nbroad class of first-order and coordinate-descent finite sum algorithms\n(including, e.g., SDCA, SVRG, SAG), it is not possible to get an `accelerated'\ncomplexity bound of $\\tilde{\\cO}((n+\\sqrt{n L/\\mu})\\ln(1/\\epsilon))$, unless\nthe strong convexity parameter is given explicitly. Lastly, we show that when\nthis class of algorithms is used for minimizing $L$-smooth and convex finite\nsums, the optimal complexity bound is $\\tilde{\\cO}(n+L/\\epsilon)$, assuming\nthat (on average) the same update rule is used in every iteration, and\n$\\tilde{\\cO}(n+\\sqrt{nL/\\epsilon})$, otherwise.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting Pulsar Scintillation from Refractive Plasma Sheets.   The dynamic and secondary spectra of many pulsars show evidence for\nlong-lived, aligned images of the pulsar that are stationary on a thin\nscattering sheet. One explanation for this phenomenon considers the effects of\nwave crests along sheets in the ionized interstellar medium, such as those due\nto Alfvén waves propagating along current sheets. If these sheets are closely\naligned to our line-of-sight to the pulsar, high bending angles arise at the\nwave crests and a selection effect causes alignment of images produced at\ndifferent crests, similar to grazing reflection off of a lake. Using geometric\noptics, we develop a simple parameterized model of these corrugated sheets that\ncan be constrained with a single observation and that makes observable\npredictions for variations in the scintillation of the pulsar over time and\nfrequency. This model reveals qualitative differences between lensing from\noverdense and underdense corrugated sheets: Only if the sheet is overdense\ncompared to the surrounding interstellar medium can the lensed images be\nbrighter than the line-of-sight image to the pulsar, and the faint lensed\nimages are closer to the pulsar at higher frequencies if the sheet is\nunderdense, but at lower frequencies if the sheet is overdense.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Exceptional points in two simple textbook examples.   We propose to introduce the concept of exceptional points in intermediate\ncourses on mathematics and classical mechanics by means of simple textbook\nexamples. The first one is an ordinary second-order differential equation with\nconstant coefficients. The second one is the well known damped harmonic\noscillator. They enable one to connect the occurrence of linearly dependent\nexponential solutions with a defective matrix that cannot be diagonalized but\ncan be transformed into a Jordan canonical form.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Inflationary Features and Shifts in Cosmological Parameters from Planck 2015 Data.   We explore the relationship between features in the Planck 2015 temperature\nand polarization data, shifts in the cosmological parameters, and features from\ninflation. Residuals in the temperature data at low multipole $\\ell$, which are\nresponsible for the high $H_0\\approx 70$ km s$^{-1}$Mpc$^{-1}$ and low\n$\\sigma_8\\Omega_m^{1/2}$ values from $\\ell<1000$ in power-law $\\Lambda$CDM\nmodels, are better fit to inflationary features with a $1.9\\sigma$ preference\nfor running of the running of the tilt or a stronger $99\\%$ CL local\nsignificance preference for a sharp drop in power around $k=0.004$ Mpc$^{-1}$\nin generalized slow roll and a lower $H_0\\approx 67$ km s$^{-1}$Mpc$^{-1}$. The\nsame in-phase acoustic residuals at $\\ell>1000$ that drive the global $H_0$\nconstraints and appear as a lensing anomaly also favor running parameters which\nallow even lower $H_0$, but not once lensing reconstruction is considered.\nPolarization spectra are intrinsically highly sensitive to these parameter\nshifts, and even more so in the Planck 2015 TE data due to an outlier at $\\ell\n\\approx 165$, which disfavors the best fit $H_0$ $\\Lambda$CDM solution by more\nthan $2\\sigma$, and high $H_0$ value at almost $3\\sigma$. Current polarization\ndata also slightly enhance the significance of a sharp suppression of\nlarge-scale power but leave room for large improvements in the future with\ncosmic variance limited $E$-mode measurements.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Universality of group embeddability.   Working in the framework of Borel reducibility, we study various notions of\nembeddability between groups. We prove that the embeddability between countable\ngroups, the topological embeddability between (discrete) Polish groups, and the\nisometric embeddability between separable groups with a bounded bi-invariant\ncomplete metric are all invariantly universal analytic quasi-orders. This\nstrengthens some results from [Wil14] and [FLR09].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Detection of virial shocks in stacked Fermi-LAT clusters.   Galaxy clusters are thought to grow by accreting mass through large-scale,\nstrong, yet elusive, virial shocks. Such a shock is expected to accelerate\nrelativistic electrons, thus generating a spectrally-flat leptonic virial-ring.\nHowever, until now, only the nearby Coma cluster has shown evidence for a\n$\\gamma$-ray virial ring. We stack Fermi-LAT data for the 112 most massive,\nhigh latitude, extended clusters, enhancing the ring sensitivity by rescaling\nclusters to their virial radii and utilizing the expected flat energy spectrum.\nIn addition to a central unresolved, hard signal (detected at the $\\sim\n5.8\\sigma$ confidence level), probably dominated by AGN, we identify (at the\n$5.8\\sigma$ confidence level) a bright, spectrally-flat $\\gamma$-ray ring at\nthe expected virial shock position. The ring signal implies that the shock\ndeposits $\\sim 0.6\\%$ (with an interpretation uncertainty factor $\\sim2$) of\nthe thermal energy in relativistic electrons over a Hubble time. This result,\nconsistent with the Coma signal, validates and calibrates the virial shock\nmodel, and indicates that the cumulative emission from such shocks\nsignificantly contributes to the diffuse extragalactic $\\gamma$-ray and\nlow-frequency radio backgrounds.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Generalized $k$-core pruning process on directed networks.   The resilience of a complex interconnected system concerns the size of the\nmacroscopic functioning node clusters after external perturbations based on a\nrandom or designed scheme. For a representation of the interconnected systems\nwith directional or asymmetrical interactions among constituents, the directed\nnetwork is a convenient choice. Yet how the interaction directions affect the\nnetwork resilience still lacks thorough exploration. Here, we study the\nresilience of directed networks with a generalized $k$-core pruning process as\na simple failure procedure based on both the in- and out-degrees of nodes, in\nwhich any node with an in-degree $< k_{in}$ or an out-degree $< k_{ou}$ is\nremoved iteratively. With an explicitly analytical framework, we can predict\nthe relative sizes of residual node clusters on uncorrelated directed random\ngraphs. We show that the discontinuous transitions rise for cases with $k_{in}\n\\geq 2$ or $k_{ou} \\geq 2$, and the unidirectional interactions among nodes\ndrive the networks more vulnerable against perturbations based on in- and\nout-degrees separately.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Magnetic polarons in a nonequilibrium polariton condensate.   We consider a condensate of exciton-polaritons in a diluted magnetic\nsemiconductor microcavity. Such system may exhibit magnetic self-trapping in\nthe case of sufficiently strong coupling between polaritons and magnetic ions\nembedded in the semiconductor. We investigate the effect of the nonequilibrium\nnature of exciton-polaritons on the physics of the resulting self-trapped\nmagnetic polarons. We find that multiple polarons can exist at the same time,\nand derive a critical condition for self-trapping which is different to the one\npredicted previously in the equilibrium case. Using the Bogoliubov-de Gennes\napproximation, we calculate the excitation spectrum and provide a physical\nexplanation in terms of the effective magnetic attraction between polaritons,\nmediated by the ion subsystem.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Periodic Airy process and equilibrium dynamics of edge fermions in a trap.   We establish an exact mapping between (i) the equilibrium (imaginary time)\ndynamics of non-interacting fermions trapped in a harmonic potential at\ntemperature $T=1/\\beta$ and (ii) non-intersecting Ornstein-Uhlenbeck (OU)\nparticles constrained to return to their initial positions after time $\\beta$.\nExploiting the determinantal structure of the process we compute the universal\ncorrelation functions both in the bulk and at the edge of the trapped Fermi\ngas. The latter corresponds to the top path of the non-intersecting OU\nparticles, and leads us to introduce and study the time-periodic Airy$_2$\nprocess, ${\\cal A}^b_2(u)$, depending on a single parameter, the period $b$.\nThe standard Airy$_2$ process is recovered for $b=+\\infty$. We discuss\napplications of our results to the real time quantum dynamics of trapped\nfermions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Rule Formats for Nominal Process Calculi.   The nominal transition systems (NTSs) of Parrow et al. describe the\noperational semantics of nominal process calculi. We study NTSs in terms of the\nnominal residual transition systems (NRTSs) that we introduce. We provide rule\nformats for the specifications of NRTSs that ensure that the associated NRTS is\nan NTS and apply them to the operational specifications of the early and late\npi-calculus. We also explore alternative specifications of the NTSs in which we\nallow residuals of abstraction sort, and introduce translations between the\nsystems with and without residuals of abstraction sort. Our study stems from\nthe Nominal SOS of Cimini et al. and from earlier works in nominal sets and\nnominal logic by Gabbay, Pitts and their collaborators.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A bound for the shortest reset words for semisimple synchronizing automata via the packing number.   We show that if a semisimple synchronizing automaton with $n$ states has a\nminimal reachable non-unary subset of cardinality $r\\ge 2$, then there is a\nreset word of length at most $(n-1)D(2,r,n)$, where $D(2,r,n)$ is the\n$2$-packing number for families of $r$-subsets of $[1,n]$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Renormalization group theory for percolation in time-varying networks.   Motivated by multi-hop communication in unreliable wireless networks, we\npresent a percolation theory for time-varying networks. We develop a\nrenormalization group theory for a prototypical network on a regular grid,\nwhere individual links switch stochastically between active and inactive\nstates. The question whether a given source node can communicate with a\ndestination node along paths of active links is equivalent to a percolation\nproblem. Our theory maps the temporal existence of multi-hop paths on an\neffective two-state Markov process. We show analytically how this Markov\nprocess converges towards a memory-less Bernoulli process as the hop distance\nbetween source and destination node increases. Our work extends classical\npercolation theory to the dynamic case and elucidates temporal correlations of\nmessage losses. Quantification of temporal correlations has implications for\nthe design of wireless communication and control protocols, e.g. in\ncyber-physical systems such as self-organized swarms of drones or smart traffic\nnetworks.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "From Language to Programs: Bridging Reinforcement Learning and Maximum Marginal Likelihood.   Our goal is to learn a semantic parser that maps natural language utterances\ninto executable programs when only indirect supervision is available: examples\nare labeled with the correct execution result, but not the program itself.\nConsequently, we must search the space of programs for those that output the\ncorrect result, while not being misled by spurious programs: incorrect programs\nthat coincidentally output the correct result. We connect two common learning\nparadigms, reinforcement learning (RL) and maximum marginal likelihood (MML),\nand then present a new learning algorithm that combines the strengths of both.\nThe new algorithm guards against spurious programs by combining the systematic\nsearch traditionally employed in MML with the randomized exploration of RL, and\nby updating parameters such that probability is spread more evenly across\nconsistent programs. We apply our learning algorithm to a new neural semantic\nparser and show significant gains over existing state-of-the-art results on a\nrecent context-dependent semantic parsing task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evaluation of Trace Alignment Quality and its Application in Medical Process Mining.   Trace alignment algorithms have been used in process mining for discovering\nthe consensus treatment procedures and process deviations. Different alignment\nalgorithms, however, may produce very different results. No widely-adopted\nmethod exists for evaluating the results of trace alignment. Existing\nreference-free evaluation methods cannot adequately and comprehensively assess\nthe alignment quality. We analyzed and compared the existing evaluation\nmethods, identifying their limitations, and introduced improvements in two\nreference-free evaluation methods. Our approach assesses the alignment result\nglobally instead of locally, and therefore helps the algorithm to optimize\noverall alignment quality. We also introduced a novel metric to measure the\nalignment complexity, which can be used as a constraint on alignment algorithm\noptimization. We tested our evaluation methods on a trauma resuscitation\ndataset and provided the medical explanation of the activities and patterns\nidentified as deviations using our proposed evaluation methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Band structure engineered layered metals for low-loss plasmonics.   Plasmonics currently faces the problem of seemingly inevitable optical losses\noccurring in the metallic components that challenges the implementation of\nessentially any application. In this work we show that Ohmic losses are reduced\nin certain layered metals, such as the transition metal dichalcogenide TaS$_2$,\ndue to an extraordinarily small density of states for scattering in the near-IR\noriginating from their special electronic band structure. Based on this\nobservation we propose a new class of band structure engineered van der Waals\nlayered metals composed of hexagonal transition metal chalcogenide-halide\nlayers with greatly suppressed intrinsic losses. Using first-principles\ncalculations we show that the suppression of optical losses lead to improved\nperformance for thin film waveguiding and transformation optics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Device-Aware Routing and Scheduling in Multi-Hop Device-to-Device Networks.   The dramatic increase in data and connectivity demand, in addition to\nheterogeneous device capabilities, poses a challenge for future wireless\nnetworks. One of the promising solutions is Device-to-Device (D2D) networking.\nD2D networking, advocating the idea of connecting two or more devices directly\nwithout traversing the core network, is promising to address the increasing\ndata and connectivity demand. In this paper, we consider D2D networks, where\ndevices with heterogeneous capabilities including computing power, energy\nlimitations, and incentives participate in D2D activities heterogeneously. We\ndevelop (i) a device-aware routing and scheduling algorithm (DARS) by taking\ninto account device capabilities, and (ii) a multi-hop D2D testbed using\nAndroid-based smartphones and tablets by exploiting Wi-Fi Direct and legacy\nWi-Fi connections. We show that DARS significantly improves throughput in our\ntestbed as compared to state-of-the-art.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On a property of the nodal set of least energy sign-changing solutions for quasilinear elliptic equations.   In this note we prove the Payne-type conjecture about the behaviour of the\nnodal set of least energy sign-changing solutions for the equation $-\\Delta_p u\n= f(u)$ in bounded Steiner symmetric domains $\\Omega \\subset \\mathbb{R}^N$\nunder the zero Dirichlet boundary conditions. The nonlinearity $f$ is assumed\nto be either superlinear or resonant. In the latter case, least energy\nsign-changing solutions are second eigenfunctions of the zero Dirichlet\n$p$-Laplacian in $\\Omega$. We show that the nodal set of any least energy\nsign-changing solution intersects the boundary of $\\Omega$. The proof is based\non a moving polarization argument.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Anisotropic functional Laplace deconvolution.   In the present paper we consider the problem of estimating a\nthree-dimensional function $f$ based on observations from its noisy Laplace\nconvolution. Our study is motivated by the analysis of Dynamic Contrast\nEnhanced (DCE) imaging data. We construct an adaptive wavelet-Laguerre\nestimator of $f$, derive minimax lower bounds for the $L^2$-risk when $f$\nbelongs to a three-dimensional Laguerre-Sobolev ball and demonstrate that the\nwavelet-Laguerre estimator is adaptive and asymptotically near-optimal in a\nwide range of Laguerre-Sobolev spaces. We carry out a limited simulations study\nand show that the estimator performs well in a finite sample setting. Finally,\nwe use the technique for the solution of the Laplace deconvolution problem on\nthe basis of DCE Computerized Tomography data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Molecular Beam Epitaxy Growth of [CrGe/MnGe/FeGe] Superlattices: Toward Artificial B20 Skyrmion Materials with Tunable Interactions.   Skyrmions are localized magnetic spin textures whose stability has been shown\ntheoretically to depend on material parameters including bulk Dresselhaus spin\norbit coupling (SOC), interfacial Rashba SOC, and magnetic anisotropy. Here, we\nestablish the growth of a new class of artificial skyrmion materials, namely\nB20 superlattices, where these parameters could be systematically tuned.\nSpecifically, we report the successful growth of B20 superlattices comprised of\nsingle crystal thin films of FeGe, MnGe, and CrGe on Si(111) substrates. Thin\nfilms and superlattices are grown by molecular beam epitaxy and are\ncharacterized through a combination of reflection high energy electron\ndiffraction, x-ray diffraction, and cross-sectional scanning transmission\nelectron microscopy (STEM). X-ray energy dispersive spectroscopy (XEDS)\ndistinguishes layers by elemental mapping and indicates good interface quality\nwith relatively low levels of intermixing in the [CrGe/MnGe/FeGe] superlattice.\nThis demonstration of epitaxial, single-crystalline B20 superlattices is a\nsignificant advance toward tunable skyrmion systems for fundamental scientific\nstudies and applications in magnetic storage and logic.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Applying Gromov's Amenable Localization to Geodesic Flows.   Let $M$ be a compact connected smooth Riemannian $n$-manifold with boundary.\nWe combine Gromov's amenable localization technique with the Poincaré\nduality to study the traversally generic geodesic flows on $SM$, the space of\nthe spherical tangent bundle. Such flows generate stratifications of $SM$,\ngoverned by rich universal combinatorics. The stratification reflects the ways\nin which the geodesic flow trajectories interact with the boundary $\\d(SM)$.\nSpecifically, we get lower estimates of the numbers of connected components of\nthese flow-generated strata of any given codimension $k$. These universal\nbounds are expressed in terms of the normed homology $H_k(M; \\R)$ and $H_k(DM;\n\\R)$, where $DM = M\\cup_{\\d M} M$ denotes the double of $M$. The norms here are\nthe Gromov simplicial semi-norms in homology. The more complex the metric on\n$M$ is, the more numerous the strata of $SM$ and $S(DM)$ are. So one may regard\nour estimates as analogues of the Morse inequalities for the geodesics on\nmanifolds with boundary.\nIt turns out that some close relatives of the normed homology spaces form\nobstructions to the existence of globally $k$-convex traversally generic\nmetrics on $M$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Knowledge Transfer for Out-of-Knowledge-Base Entities: A Graph Neural Network Approach.   Knowledge base completion (KBC) aims to predict missing information in a\nknowledge base.In this paper, we address the out-of-knowledge-base (OOKB)\nentity problem in KBC:how to answer queries concerning test entities not\nobserved at training time. Existing embedding-based KBC models assume that all\ntest entities are available at training time, making it unclear how to obtain\nembeddings for new entities without costly retraining. To solve the OOKB entity\nproblem without retraining, we use graph neural networks (Graph-NNs) to compute\nthe embeddings of OOKB entities, exploiting the limited auxiliary knowledge\nprovided at test time.The experimental results show the effectiveness of our\nproposed model in the OOKB setting.Additionally, in the standard KBC setting in\nwhich OOKB entities are not involved, our model achieves state-of-the-art\nperformance on the WordNet dataset. The code and dataset are available at\nthis https URL",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Visual analytics for loan guarantee network risk management.   Groups of enterprises guarantee each other and form complex guarantee\nnetworks when they try to obtain loans from banks. Such secured loan can\nenhance the solvency and promote the rapid growth in the economic upturn\nperiod. However, potential systemic risk may happen within the risk binding\ncommunity. Especially, during the economic down period, the crisis may spread\nin the guarantee network like a domino. Monitoring the financial status,\npreventing or reducing systematic risk when crisis happens is highly concerned\nby the regulatory commission and banks. We propose visual analytics approach\nfor loan guarantee network risk management, and consolidate the five analysis\ntasks with financial experts: i) visual analytics for enterprises default risk,\nwhereby a hybrid representation is devised to predict the default risk and\ndeveloped an interface to visualize key indicators; ii) visual analytics for\nhigh default groups, whereby a community detection based interactive approach\nis presented; iii) visual analytics for high defaults pattern, whereby a motif\ndetection based interactive approach is described, and we adopt a Shneiderman\nMantra strategy to reduce the computation complexity. iv) visual analytics for\nevolving guarantee network, whereby animation is used to help understanding the\nguarantee dynamic; v) visual analytics approach and interface for default\ndiffusion path. The temporal diffusion path analysis can be useful for the\ngovernment and bank to monitor the default spread status. It also provides\ninsight for taking precautionary measures to prevent and dissolve systemic\nfinancial risk. We implement the system with case studies on a real-world\nguarantee network. Two financial experts are consulted with endorsement on the\ndeveloped tool. To the best of our knowledge, this is the first visual\nanalytics tool to explore the guarantee network risks in a systematic manner.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An infinite class of unsaturated rooted trees corresponding to designable RNA secondary structures.   An RNA secondary structure is designable if there is an RNA sequence which\ncan attain its maximum number of base pairs only by adopting that structure.\nThe combinatorial RNA design problem, introduced by Haleš et al. in 2016,\nis to determine whether or not a given RNA secondary structure is designable.\nHaleš et al. identified certain classes of designable and non-designable\nsecondary structures by reference to their corresponding rooted trees. We\nintroduce an infinite class of rooted trees containing unpaired nucleotides at\nthe greatest height, and prove constructively that their corresponding\nsecondary structures are designable. This complements previous results for the\ncombinatorial RNA design problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Analyzing biological and artificial neural networks: challenges with opportunities for synergy?.   Deep neural networks (DNNs) transform stimuli across multiple processing\nstages to produce representations that can be used to solve complex tasks, such\nas object recognition in images. However, a full understanding of how they\nachieve this remains elusive. The complexity of biological neural networks\nsubstantially exceeds the complexity of DNNs, making it even more challenging\nto understand the representations that they learn. Thus, both machine learning\nand computational neuroscience are faced with a shared challenge: how can we\nanalyze their representations in order to understand how they solve complex\ntasks?\nWe review how data-analysis concepts and techniques developed by\ncomputational neuroscientists can be useful for analyzing representations in\nDNNs, and in turn, how recently developed techniques for analysis of DNNs can\nbe useful for understanding representations in biological neural networks. We\nexplore opportunities for synergy between the two fields, such as the use of\nDNNs as in-silico model systems for neuroscience, and how this synergy can lead\nto new hypotheses about the operating principles of biological neural networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bipartite Envy-Free Matching.   Bipartite Envy-Free Matching (BEFM) is a relaxation of perfect matching. In a\nbipartite graph with parts X and Y, a BEFM is a matching of some vertices in X\nto some vertices in Y, such that each unmatched vertex in X is not adjacent to\nany matched vertex in Y (so the unmatched vertices do not \"envy\" the matched\nones). The empty matching is always a BEFM. This paper presents sufficient and\nnecessary conditions for the existence of a non-empty BEFM. These conditions\nare based on cardinality of neighbor-sets, similarly to Hall's condition for\nthe existence of a perfect matching. The conditions can be verified in\npolynomial time, and in case they are satisfied, a non-empty BEFM can be found\nby a polynomial-time algorithm. The paper presents some applications of BEFM as\na subroutine in fair division algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Binary Evolution and the Progenitor of SN 1987A.   Since the majority of massive stars are members of binary systems, an\nunderstanding of the intricacies of binary interactions is essential for\nunderstanding the large variety of supernova types and sub-types. I therefore\nbriefly review the basic elements of binary evolution theory and discuss how\nbinary interactions affect the presupernova structure of massive stars and the\nresulting supernovae.\nSN 1987A was a highly anomalous supernova, almost certainly because of a\nprevious binary interaction. The most likely scenario at present is that the\nprogenitor was a member of a massive close binary that experienced dynamical\nmass transfer during its second red-supergiant phase and merged completely with\nits companion as a consequence. This can naturally explain the three main\nanomalies of SN 1987A: the blue color of the progenitor, the chemical anomalies\nand the complex triple-ring nebula.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A 3pi Search for Planet Nine at 3.4 microns with WISE and NEOWISE.   The recent 'Planet Nine' hypothesis has led to many observational and\narchival searches for this giant planet proposed to orbit the Sun at hundreds\nof astronomical units. While trans-Neptunian object searches are typically\nconducted in the optical, models suggest Planet Nine could be self-luminous and\npotentially bright enough at ~3-5 microns to be detected by the Wide-field\nInfrared Survey Explorer (WISE). We have previously demonstrated a Planet Nine\nsearch methodology based on time-resolved WISE coadds, allowing us to detect\nmoving objects much fainter than would be possible using single-frame\nextractions. In the present work, we extend our 3.4 micron (W1) search to cover\nmore than three quarters of the sky and incorporate four years of WISE\nobservations spanning a seven year time period. This represents the deepest and\nwidest-area WISE search for Planet Nine to date. We characterize the spatial\nvariation of our survey's sensitivity and rule out the presence of Planet Nine\nin the parameter space searched at W1 < 16.7 in high Galactic latitude regions\n(90% completeness).",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Recent Survey on the Applications of Genetic Programming in Image Processing.   During the last two decades, Genetic Programming (GP) has been largely used\nto tackle optimization, classification, and automatic features selection\nrelated tasks. The widespread use of GP is mainly due to its flexible and\ncomprehensible tree-type structure. Similarly, research is also gaining\nmomentum in the field of Image Processing (IP) because of its promising results\nover wide areas of applications ranging from medical IP to multispectral\nimaging. IP is mainly involved in applications such as computer vision, pattern\nrecognition, image compression, storage and transmission, and medical\ndiagnostics. This prevailing nature of images and their associated algorithm\ni.e complexities gave an impetus to the exploration of GP. GP has thus been\nused in different ways for IP since its inception. Many interesting GP\ntechniques have been developed and employed in the field of IP. To give the\nresearch community an extensive view of these techniques, this paper presents\nthe diverse applications of GP in IP and provides useful resources for further\nresearch. Also, comparison of different parameters used in ten different\napplications of IP are summarized in tabular form. Moreover, analysis of\ndifferent parameters used in IP related tasks is carried-out to save the time\nneeded in future for evaluating the parameters of GP. As more advancement is\nmade in GP methodologies, its success in solving complex tasks not only related\nto IP but also in other fields will increase. Additionally, guidelines are\nprovided for applying GP in IP related tasks, pros and cons of GP techniques\nare discussed, and some future directions are also set.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Up-down colorings of virtual-link diagrams and the necessity of Reidemeister moves of type II.   We introduce an up-down coloring of a virtual-link diagram. The\ncolorabilities give a lower bound of the minimum number of Reidemeister moves\nof type II which are needed between two 2-component virtual-link diagrams. By\nusing the notion of a quandle cocycle invariant, we determine the necessity of\nReidemeister moves of type II for a pair of diagrams of the trivial\nvirtual-knot. This implies that for any virtual-knot diagram $D$, there exists\na diagram $D'$ representing the same virtual-knot such that any sequence of\ngeneralized Reidemeister moves between them includes at least one Reidemeister\nmove of type II.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Supervised Typing of Big Graphs using Semantic Embeddings.   We propose a supervised algorithm for generating type embeddings in the same\nsemantic vector space as a given set of entity embeddings. The algorithm is\nagnostic to the derivation of the underlying entity embeddings. It does not\nrequire any manual feature engineering, generalizes well to hundreds of types\nand achieves near-linear scaling on Big Graphs containing many millions of\ntriples and instances by virtue of an incremental execution. We demonstrate the\nutility of the embeddings on a type recommendation task, outperforming a\nnon-parametric feature-agnostic baseline while achieving 15x speedup and\nnear-constant memory usage on a full partition of DBpedia. Using\nstate-of-the-art visualization, we illustrate the agreement of our\nextensionally derived DBpedia type embeddings with the manually curated domain\nontology. Finally, we use the embeddings to probabilistically cluster about 4\nmillion DBpedia instances into 415 types in the DBpedia ontology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exact relativistic Toda chain eigenfunctions from Separation of Variables and gauge theory.   We provide a proposal, motivated by Separation of Variables and gauge theory\narguments, for constructing exact solutions to the quantum Baxter equation\nassociated to the $N$-particle relativistic Toda chain and test our proposal\nagainst numerical results. Quantum Mechanical non-perturbative corrections,\nessential in order to obtain a sensible solution, are taken into account in our\ngauge theory approach by considering codimension two defects on curved\nbackgrounds (squashed $S^5$ and degenerate limits) rather than flat space; this\nsetting also naturally incorporates exact quantization conditions and energy\nspectrum of the relativistic Toda chain as well as its modular dual structure.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ordering Garside groups.   We introduce a condition on Garside groups that we call Dehornoy structure.\nAn iteration of such a structure leads to a left order on the group. We show\nconditions for a Garside group to admit a Dehornoy structure, and we apply\nthese criteria to prove that the Artin groups of type A and I 2 (m), m $\\ge$ 4,\nhave Dehornoy structures. We show that the left orders on the Artin groups of\ntype A obtained from their Dehornoy structures are the Dehornoy orders. In the\ncase of the Artin groups of type I 2 (m), m $\\ge$ 4, we show that the left\norders derived from their Dehornoy structures coincide with the orders obtained\nfrom embeddings of the groups into braid groups. 20F36",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Convergence Results for Neural Networks via Electrodynamics.   We study whether a depth two neural network can learn another depth two\nnetwork using gradient descent. Assuming a linear output node, we show that the\nquestion of whether gradient descent converges to the target function is\nequivalent to the following question in electrodynamics: Given $k$ fixed\nprotons in $\\mathbb{R}^d,$ and $k$ electrons, each moving due to the attractive\nforce from the protons and repulsive force from the remaining electrons,\nwhether at equilibrium all the electrons will be matched up with the protons,\nup to a permutation. Under the standard electrical force, this follows from the\nclassic Earnshaw's theorem. In our setting, the force is determined by the\nactivation function and the input distribution. Building on this equivalence,\nwe prove the existence of an activation function such that gradient descent\nlearns at least one of the hidden nodes in the target network. Iterating, we\nshow that gradient descent can be used to learn the entire network one node at\na time.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Dimensional crossover of effective orbital dynamics in polar distorted 3He-A: Transitions to anti-spacetime.   Topologically protected superfluid phases of $^3$He allow one to simulate\nmany important aspects of relativistic quantum field theories and quantum\ngravity in condensed matter. Here we discuss a topological Lifshitz transition\nof the effective quantum vacuum in which the determinant of the tetrad field\nchanges sign through a crossing to a vacuum state with a degenerate fermionic\nmetric. Such a transition is realized in polar distorted superfluid $^3$He-A in\nterms of the effective tetrad fields emerging in the vicinity of the superfluid\ngap nodes: the tetrads of the Weyl points in the chiral A-phase of $^3$He and\nthe degenerate tetrad in the vicinity of a Dirac nodal line in the polar phase\nof $^3$He. The continuous phase transition from the $A$-phase to the polar\nphase, i.e. in the transition from the Weyl nodes to the Dirac nodal line and\nback, allows one to follow the behavior of the fermionic and bosonic effective\nactions when the sign of the tetrad determinant changes, and the effective\nchiral space-time transforms to anti-chiral \"anti-spacetime\". This condensed\nmatter realization demonstrates that while the original fermionic action is\nanalytic across the transition, the effective action for the orbital degrees of\nfreedom (pseudo-EM) fields and gravity have non-analytic behavior. In\nparticular, the action for the pseudo-EM field in the vacuum with Weyl fermions\n(A-phase) contains the modulus of the tetrad determinant. In the vacuum with\nthe degenerate metric (polar phase) the nodal line is effectively a family of\n$2+1$d Dirac fermion patches, which leads to a non-analytic $(B^2-E^2)^{3/4}$\nQED action in the vicinity of the Dirac line.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Using PCA and Factor Analysis for Dimensionality Reduction of Bio-informatics Data.   Large volume of Genomics data is produced on daily basis due to the\nadvancement in sequencing technology. This data is of no value if it is not\nproperly analysed. Different kinds of analytics are required to extract useful\ninformation from this raw data. Classification, Prediction, Clustering and\nPattern Extraction are useful techniques of data mining. These techniques\nrequire appropriate selection of attributes of data for getting accurate\nresults. However, Bioinformatics data is high dimensional, usually having\nhundreds of attributes. Such large a number of attributes affect the\nperformance of machine learning algorithms used for classification/prediction.\nSo, dimensionality reduction techniques are required to reduce the number of\nattributes that can be further used for analysis. In this paper, Principal\nComponent Analysis and Factor Analysis are used for dimensionality reduction of\nBioinformatics data. These techniques were applied on Leukaemia data set and\nthe number of attributes was reduced from to.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Superconvergence analysis of linear FEM based on the polynomial preserving recovery and Richardson extrapolation for Helmholtz equation with high wave number.   We study superconvergence property of the linear finite element method with\nthe polynomial preserving recovery (PPR) and Richardson extrapolation for the\ntwo dimensional Helmholtz equation. The $H^1$-error estimate with explicit\ndependence on the wave number $k$ {is} derived.\nFirst, we prove that under the assumption $k(kh)^2\\leq C_0$ ($h$ is the mesh\nsize) and certain mesh condition, the estimate between the finite element\nsolution and the linear interpolation of the exact solution is superconvergent\nunder the $H^1$-seminorm, although the pollution error still exists. Second, we\nprove a similar result for the recovered gradient by PPR and found that the PPR\ncan only improve the interpolation error and has no effect on the pollution\nerror. Furthermore, we estimate the error between the finite element gradient\nand recovered gradient and discovered that the pollution error is canceled\nbetween these two quantities. Finally, we apply the Richardson extrapolation to\nrecovered gradient and demonstrate numerically that PPR combined with the\nRichardson extrapolation can reduce the interpolation and pollution errors\nsimultaneously, and therefore, leads to an asymptotically exact {\\it a\nposteriori} error estimator. All theoretical findings are verified by numerical\ntests.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simultaneous Block-Sparse Signal Recovery Using Pattern-Coupled Sparse Bayesian Learning.   In this paper, we consider the block-sparse signals recovery problem in the\ncontext of multiple measurement vectors (MMV) with common row sparsity\npatterns. We develop a new method for recovery of common row sparsity MMV\nsignals, where a pattern-coupled hierarchical Gaussian prior model is\nintroduced to characterize both the block-sparsity of the coefficients and the\nstatistical dependency between neighboring coefficients of the common row\nsparsity MMV signals. Unlike many other methods, the proposed method is able to\nautomatically capture the block sparse structure of the unknown signal. Our\nmethod is developed using an expectation-maximization (EM) framework.\nSimulation results show that our proposed method offers competitive performance\nin recovering block-sparse common row sparsity pattern MMV signals.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sun/Moon photometer for the Cherenkov Telescope Array - first results.   Determination of the energy and flux of the gamma photons by Imaging\nAtmospheric Cherenkov Technique is strongly dependent on optical properties of\nthe atmosphere. Therefore, atmospheric monitoring during the future\nobservations of the Cherenkov Telescope Array (CTA) as well as anticipated\nlong-term monitoring in order to characterize overal properties and annual\nvariation of atmospheric conditions are very important. Several instruments are\nalready installed at the CTA sites in order to monitor atmospheric conditions\non long-term. One of them is a Sun/Moon photometer CE318-T, installed at the\nSouthern CTA site. Since the photometer is installed at a place with very\nstable atmospheric conditions, it can be also used for characterization of its\nperformance and testing of new methods of aerosol optical depth (AOD)\nretrieval, cloud-screening and calibration. In this work, we describe our\ncalibration method for nocturnal measurements and the modification of\ncloud-screening for purposes of nocturnal AOD retrieval. We applied these\nmethods on two months of observations and present the distribution of AODs in\nfour photometric passbands together with their uncertainties.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Online Learning with an Almost Perfect Expert.   We study the multiclass online learning problem where a forecaster makes a\nsequence of predictions using the advice of $n$ experts. Our main contribution\nis to analyze the regime where the best expert makes at most $b$ mistakes and\nto show that when $b = o(\\log_4{n})$, the expected number of mistakes made by\nthe optimal forecaster is at most $\\log_4{n} + o(\\log_4{n})$. We also describe\nan adversary strategy showing that this bound is tight and that the worst case\nis attained for binary prediction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Projection-Based Reformulation and Decomposition Algorithm for Global Optimization of a Class of Mixed Integer Bilevel Linear Programs.   We propose an extended variant of the reformulation and decomposition\nalgorithm for solving a special class of mixed-integer bilevel linear programs\n(MIBLPs) where continuous and integer variables are involved in both upper- and\nlower-level problems. In particular, we consider MIBLPs with upper-level\nconstraints that involve lower-level variables. We assume that the inducible\nregion is nonempty and all variables are bounded. By using the reformulation\nand decomposition scheme, an MIBLP is first converted into its equivalent\nsingle-level formulation, then computed by a column-and-constraint generation\nbased decomposition algorithm. The solution procedure is enhanced by a\nprojection strategy that does not require the relatively complete response\nproperty. To ensure its performance, we prove that our new method converges to\nthe global optimal solution in a finite number of iterations. A large-scale\ncomputational study on random instances and instances of hierarchical supply\nchain planning are presented to demonstrate the effectiveness of the algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Persistent Spread Measurement for Big Network Data Based on Register Intersection.   Persistent spread measurement is to count the number of distinct elements\nthat persist in each network flow for predefined time periods. It has many\npractical applications, including detecting long-term stealthy network\nactivities in the background of normal-user activities, such as stealthy DDoS\nattack, stealthy network scan, or faked network trend, which cannot be detected\nby traditional flow cardinality measurement. With big network data, one\nchallenge is to measure the persistent spreads of a massive number of flows\nwithout incurring too much memory overhead as such measurement may be performed\nat the line speed by network processors with fast but small on-chip memory. We\npropose a highly compact Virtual Intersection HyperLogLog (VI-HLL) architecture\nfor this purpose. It achieves far better memory efficiency than the best prior\nwork of V-Bitmap, and in the meantime drastically extends the measurement\nrange. Theoretical analysis and extensive experiments demonstrate that VI-HLL\nprovides good measurement accuracy even in very tight memory space of less than\n1 bit per flow.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Lagrangian Model to Predict Microscallop Motion in non Newtonian Fluids.   The need to develop models to predict the motion of microrobots, or robots of\na much smaller scale, moving in fluids in a low Reynolds number regime, and in\nparticular, in non Newtonian fluids, cannot be understated. The article\ndevelops a Lagrangian based model for one such mechanism - a two-link mechanism\ntermed a microscallop, moving in a low Reynolds number environment in a non\nNewtonian fluid. The modelling proceeds through the conventional Lagrangian\nconstruction for a two-link mechanism and then goes on to model the external\nfluid forces using empirically based models for viscosity to complete the\ndynamic model. The derived model is then simulated for different initial\nconditions and key parameters of the non Newtonian fluid, and the results are\ncorroborated with a few existing experimental results on a similar mechanism\nunder identical conditions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Test Case Prioritization Techniques for Model-Based Testing: A Replicated Study.   Recently, several Test Case Prioritization (TCP) techniques have been\nproposed to order test cases for achieving a goal during test execution,\nparticularly, revealing faults sooner. In the Model-Based Testing (MBT)\ncontext, such techniques are usually based on heuristics related to structural\nelements of the model and derived test cases. In this sense, techniques'\nperformance may vary due to a number of factors. While empirical studies\ncomparing the performance of TCP techniques have already been presented in\nliterature, there is still little knowledge, particularly in the MBT context,\nabout which factors may influence the outcomes suggested by a TCP technique. In\na previous family of empirical studies focusing on labeled transition systems,\nwe identified that the model layout, i.e. amount of branches, joins, and loops\nin the model, alone may have little influence on the performance of TCP\ntechniques investigated, whereas characteristics of test cases that actually\nfail definitely influences their performance. However, we considered only\nsynthetic artifacts in the study, which reduced the ability of representing\nproperly the reality. In this paper, we present a replication of one of these\nstudies, now with a larger and more representative selection of techniques and\nconsidering test suites from industrial applications as experimental objects.\nOur objective is to find out whether the results remain while increasing the\nvalidity in comparison to the original study. Results reinforce that there is\nno best performer among the investigated techniques and characteristics of test\ncases that fail represent an important factor, although adaptive random based\ntechniques are less affected by it.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Integrable Trotterization: Local Conservation Laws and Boundary Driving.   We discuss a general procedure to construct an integrable real-time\ntrotterization of interacting lattice models. As an illustrative example we\nconsider a spin-$1/2$ chain, with continuous time dynamics described by the\nisotropic ($XXX$) Heisenberg Hamiltonian. For periodic boundary conditions\nlocal conservation laws are derived from an inhomogeneous transfer matrix and a\nboost operator is constructed. In the continuous time limit these local charges\nreduce to the known integrals of motion of the Heisenberg chain. In a simple\nKraus representation we also examine the nonequilibrium setting, where our\nintegrable cellular automaton is driven by stochastic processes at the\nboundaries. We show explicitly, how an exact nonequilibrium steady state\ndensity matrix can be written in terms of a staggered matrix product ansatz.\nThis simple trotterization scheme, in particular in the open system framework,\ncould prove to be a useful tool for experimental simulations of the lattice\nmodels in terms of trapped ion and atom optics setups.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Review of image quality measures for solar imaging.   The observations of solar photosphere from the ground encounter significant\nproblems due to the presence of Earth's turbulent atmosphere. Prior to applying\nimage reconstruction techniques, the frames obtained in most favorable\natmospheric conditions (so-called lucky frames) have to be carefully selected.\nHowever, the estimation of the quality of images containing complex\nphotospheric structures is not a trivial task and the standard routines applied\nin night-time Lucky Imaging observations are not applicable. In this paper we\nevaluate 36 methods dedicated for the assessment of image quality which were\npresented in the rich literature over last 40 years. We compare their\neffectiveness on simulated solar observations of both active regions and\ngranulation patches, using reference data obtained by the Solar Optical\nTelescope on the Hindoe satellite. To create the images affected by a known\ndegree of atmospheric degradation, we employ the Random Wave Vector method\nwhich faithfully models all the seeing characteristics. The results provide\nuseful information about the methods performance depending on the average\nseeing conditions expressed by the ratio of the telescope's aperture to the\nFried parameter, $D/r_0$. The comparison identifies three methods for\nconsideration by observers: Helmli and Scherer's Mean, Median Filter Gradient\nSimilarity, and Discrete Cosine Transform Energy Ratio. While the first one\nrequires less computational effort and can be used effectively virtually in any\natmospherics conditions, the second one shows its superiority at good seeing\n($D/r_0<4$). The last one should be considered mainly for the post-processing\nof strongly blurred images.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Alzer's inequality.   Extensions and generalizations of Alzer's inequality; which is of Wirtinger\ntype are proved. As applications, sharp trapezoid type inequality and sharp\nbound for the geometric mean are deduced.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Avoiding a Tragedy of the Commons in the Peer Review Process.   Peer review is the foundation of scientific publication, and the task of\nreviewing has long been seen as a cornerstone of professional service. However,\nthe massive growth in the field of machine learning has put this community\nbenefit under stress, threatening both the sustainability of an effective\nreview process and the overall progress of the field. In this position paper,\nwe argue that a tragedy of the commons outcome may be avoided by emphasizing\nthe professional aspects of this service. In particular, we propose a rubric to\nhold reviewers to an objective standard for review quality. In turn, we also\npropose that reviewers be given appropriate incentive. As one possible such\nincentive, we explore the idea of financial compensation on a per-review basis.\nWe suggest reasonable funding models and thoughts on long term effects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Affordance-grounded Sensorimotor Object Recognition.   It is well-established by cognitive neuroscience that human perception of\nobjects constitutes a complex process, where object appearance information is\ncombined with evidence about the so-called object \"affordances\", namely the\ntypes of actions that humans typically perform when interacting with them. This\nfact has recently motivated the \"sensorimotor\" approach to the challenging task\nof automatic object recognition, where both information sources are fused to\nimprove robustness. In this work, the aforementioned paradigm is adopted,\nsurpassing current limitations of sensorimotor object recognition research.\nSpecifically, the deep learning paradigm is introduced to the problem for the\nfirst time, developing a number of novel neuro-biologically and\nneuro-physiologically inspired architectures that utilize state-of-the-art\nneural networks for fusing the available information sources in multiple ways.\nThe proposed methods are evaluated using a large RGB-D corpus, which is\nspecifically collected for the task of sensorimotor object recognition and is\nmade publicly available. Experimental results demonstrate the utility of\naffordance information to object recognition, achieving an up to 29% relative\nerror reduction by its inclusion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fairness in representation: quantifying stereotyping as a representational harm.   While harms of allocation have been increasingly studied as part of the\nsubfield of algorithmic fairness, harms of representation have received\nconsiderably less attention. In this paper, we formalize two notions of\nstereotyping and show how they manifest in later allocative harms within the\nmachine learning pipeline. We also propose mitigation strategies and\ndemonstrate their effectiveness on synthetic datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast Approximate Natural Gradient Descent in a Kronecker-factored Eigenbasis.   Optimization algorithms that leverage gradient covariance information, such\nas variants of natural gradient descent (Amari, 1998), offer the prospect of\nyielding more effective descent directions. For models with many parameters,\nthe covariance matrix they are based on becomes gigantic, making them\ninapplicable in their original form. This has motivated research into both\nsimple diagonal approximations and more sophisticated factored approximations\nsuch as KFAC (Heskes, 2000; Martens & Grosse, 2015; Grosse & Martens, 2016). In\nthe present work we draw inspiration from both to propose a novel approximation\nthat is provably better than KFAC and amendable to cheap partial updates. It\nconsists in tracking a diagonal variance, not in parameter coordinates, but in\na Kronecker-factored eigenbasis, in which the diagonal approximation is likely\nto be more effective. Experiments show improvements over KFAC in optimization\nspeed for several deep network architectures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "PROBE: Predictive Robust Estimation for Visual-Inertial Navigation.   Navigation in unknown, chaotic environments continues to present a\nsignificant challenge for the robotics community. Lighting changes,\nself-similar textures, motion blur, and moving objects are all considerable\nstumbling blocks for state-of-the-art vision-based navigation algorithms. In\nthis paper we present a novel technique for improving localization accuracy\nwithin a visual-inertial navigation system (VINS). We make use of training data\nto learn a model for the quality of visual features with respect to\nlocalization error in a given environment. This model maps each visual\nobservation from a predefined prediction space of visual-inertial predictors\nonto a scalar weight, which is then used to scale the observation covariance\nmatrix. In this way, our model can adjust the influence of each observation\naccording to its quality. We discuss our choice of predictors and report\nsubstantial reductions in localization error on 4 km of data from the KITTI\ndataset, as well as on experimental datasets consisting of 700 m of indoor and\noutdoor driving on a small ground rover equipped with a Skybotix VI-Sensor.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Large Area X-ray Proportional Counter (LAXPC) Instrument on AstroSat.   Large Area X-ray Proportional Counter (LAXPC) is one of the major AstroSat\npayloads. LAXPC instrument will provide high time resolution X-ray observations\nin 3 to 80 keV energy band with moderate energy resolution. A cluster of three\nco-aligned identical LAXPC detectors is used in AstroSat to provide large\ncollection area of more than 6000 cm2 . The large detection volume (15 cm\ndepth) filled with xenon gas at about 2 atmosphere pressure, results in\ndetection efficiency greater than 50%, above 30 keV. With its broad energy\nrange and fine time resolution (10 microsecond), LAXPC instrument is well\nsuited for timing and spectral studies of a wide variety of known and transient\nX-ray sources in the sky. We have done extensive calibration of all LAXPC\ndetectors using radioactive sources as well as GEANT4 simulation of LAXPC\ndetectors. We describe in brief some of the results obtained during the payload\nverification phase along with LXAPC capabilities.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Ridesourcing Car Detection by Transfer Learning.   Ridesourcing platforms like Uber and Didi are getting more and more popular\naround the world. However, unauthorized ridesourcing activities taking\nadvantages of the sharing economy can greatly impair the healthy development of\nthis emerging industry. As the first step to regulate on-demand ride services\nand eliminate black market, we design a method to detect ridesourcing cars from\na pool of cars based on their trajectories. Since licensed ridesourcing car\ntraces are not openly available and may be completely missing in some cities\ndue to legal issues, we turn to transferring knowledge from public transport\nopen data, i.e, taxis and buses, to ridesourcing detection among ordinary\nvehicles. We propose a two-stage transfer learning framework. In Stage 1, we\ntake taxi and bus data as input to learn a random forest (RF) classifier using\ntrajectory features shared by taxis/buses and ridesourcing/other cars. Then, we\nuse the RF to label all the candidate cars. In Stage 2, leveraging the subset\nof high confident labels from the previous stage as input, we further learn a\nconvolutional neural network (CNN) classifier for ridesourcing detection, and\niteratively refine RF and CNN, as well as the feature set, via a co-training\nprocess. Finally, we use the resulting ensemble of RF and CNN to identify the\nridesourcing cars in the candidate pool. Experiments on real car, taxi and bus\ntraces show that our transfer learning framework, with no need of a pre-labeled\nridesourcing dataset, can achieve similar accuracy as the supervised learning\nmethods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast readout algorithm for cylindrical beam position monitors providing good accuracy for particle bunches with large offsets.   A simple, analytically correct algorithm is developed for calculating pencil\nbeam coordinates using the signals from an ideal cylindrical particle beam\nposition monitor (BPM) with four pickup electrodes (PUEs) of infinitesimal\nwidths. The algorithm is then applied to simulations of realistic BPMs with\nfinite width PUEs. Surprisingly small deviations are found. Simple empirically\ndetermined correction terms reduce the deviations even further. The algorithm\nis then used to study the impact of beam-size upon the precision of BPMs in the\nnon-linear region. As an example of the data acquisition speed advantage, a\nFPGA-based BPM readout implementation of the new algorithm has been developed\nand characterized. Finally,the algorithm is tested with BPM data from the\nCornell Preinjector.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Driving Interactive Graph Exploration Using 0-Dimensional Persistent Homology Features.   Graphs are commonly used to encode relationships among entities, yet, their\nabstractness makes them incredibly difficult to analyze. Node-link diagrams are\na popular method for drawing graphs. Classical techniques for the node-link\ndiagrams include various layout methods that rely on derived information to\nposition points, which often lack interactive exploration functionalities; and\nforce-directed layouts, which ignore global structures of the graph. This paper\naddresses the graph drawing challenge by leveraging topological features of a\ngraph as derived information for interactive graph drawing. We first discuss\nextracting topological features from a graph using persistent homology. We then\nintroduce an interactive persistence barcodes to study the substructures of a\nforce-directed graph layout; in particular, we add contracting and repulsing\nforces guided by the 0-dimensional persistent homology features. Finally, we\ndemonstrate the utility of our approach across three datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Time crystal platform: from quasi-crystal structures in time to systems with exotic interactions.   Time crystals are quantum many-body systems which, due to interactions\nbetween particles, are able to spontaneously self-organize their motion in a\nperiodic way in time by analogy with the formation of crystalline structures in\nspace in condensed matter physics. In solid state physics properties of space\ncrystals are often investigated with the help of external potentials that are\nspatially periodic and reflect various crystalline structures. A similar\napproach can be applied for time crystals, as periodically driven systems\nconstitute counterparts of spatially periodic systems, but in the time domain.\nHere we show that condensed matter problems ranging from single particles in\npotentials of quasi-crystal structure to many-body systems with exotic\nlong-range interactions can be realized in the time domain with an appropriate\nperiodic driving. Moreover, it is possible to create molecules where atoms are\nbound together due to destructive interference if the atomic scattering length\nis modulated in time.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Gallucci's axiom revisited.   In this paper we propose a well-justified synthetic approach of the\nprojective space. We define the concepts of plane and space of incidence and\nalso the Gallucci's axiom as an axiom to our classical projective space. To\nthis purpose we prove from our space axioms, the theorems of Desargues, Pappus,\nthe fundamental theorem of projectivities, and the fundamental theorem of\ncentral-axial collinearities, respectively. Our building up do not use any\ninformation on analytical projective geometry, as the concept of cross-ratio\nand the homogeneous coordinates of points.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structural, elastic, electronic, and bonding properties of intermetallic Nb3Pt and Nb3Os compounds: a DFT study.   Theoretical investigation of structural, elastic, electronic and bonding\nproperties of A-15 Nb-based intermetallic compounds Nb3B (B = Pt, Os) have been\nperformed using first principles calculations based on the density functional\ntheory (DFT). Optimized cell parameters are found to be in good agreement with\navailable experimental and theoretical results. The elastic constants at zero\npressure and temperature are calculated and the anisotropic behaviors of the\ncompounds are studied. Both the compounds are mechanically stable and ductile\nin nature. Other elastic properties such as Pugh's ratio, Cauchy pressure,\nmachinability index are derived for the first time. Nb3Os is expected to have\ngood lubricating properties compared to Nb3Pt. The electronic band structure\nand energy density of states (DOS) have been studied with and without\nspin-orbit coupling (SOC). The band structures of both the compounds are spin\nsymmetric. Electronic band structure and DOS reveal that both the compounds are\nmetallic and the conductivity mainly arise from the Nb 4d states. The Fermi\nsurface features have been studied for the first time. The Fermi surfaces of\nNb3B contain both hole- and electron-like sheets which change as one replaces\nPt with Os. The electronic charge density distribution shows that Nb3Pt and\nNb3Os both have a mixture of ionic and covalent bonding. The charge transfer\nbetween atomic species in these compounds has been explained by the Mulliken\nbond population analysis.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Existence and symmetry of solutions for critical fractional Schrödinger equations with bounded potentials.   This paper is concerned with the following fractional Schrödinger\nequations involving critical exponents: \\begin{eqnarray*}\n(-\\Delta)^{\\alpha}u+V(x)u=k(x)f(u)+\\lambda|u|^{2_{\\alpha}^{*}-2}u\\quad\\quad\n\\mbox{in}\\ \\mathbb{R}^{N}, \\end{eqnarray*} where $(-\\Delta)^{\\alpha}$ is the\nfractional Laplacian operator with $\\alpha\\in(0,1)$, $N\\geq2$, $\\lambda$ is a\npositive real parameter and $2_{\\alpha}^{*}=2N/(N-2\\alpha)$ is the critical\nSobolev exponent, $V(x)$ and $k(x)$ are positive and bounded functions\nsatisfying some extra hypotheses. Based on the principle of concentration\ncompactness in the fractional Sobolev space and the minimax arguments, we\nobtain the existence of a nontrivial radially symmetric weak solution for the\nabove-mentioned equations without assuming the Ambrosetti-Rabinowitz condition\non the subcritical nonlinearity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Probabilistic Numerical Methods.   The emergent field of probabilistic numerics has thus far lacked clear\nstatistical principals. This paper establishes Bayesian probabilistic numerical\nmethods as those which can be cast as solutions to certain inverse problems\nwithin the Bayesian framework. This allows us to establish general conditions\nunder which Bayesian probabilistic numerical methods are well-defined,\nencompassing both non-linear and non-Gaussian models. For general computation,\na numerical approximation scheme is proposed and its asymptotic convergence\nestablished. The theoretical development is then extended to pipelines of\ncomputation, wherein probabilistic numerical methods are composed to solve more\nchallenging numerical tasks. The contribution highlights an important research\nfrontier at the interface of numerical analysis and uncertainty quantification,\nwith a challenging industrial application presented.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Upper-Bounding the Regularization Constant for Convex Sparse Signal Reconstruction.   Consider reconstructing a signal $x$ by minimizing a weighted sum of a convex\ndifferentiable negative log-likelihood (NLL) (data-fidelity) term and a convex\nregularization term that imposes a convex-set constraint on $x$ and enforces\nits sparsity using $\\ell_1$-norm analysis regularization. We compute upper\nbounds on the regularization tuning constant beyond which the regularization\nterm overwhelmingly dominates the NLL term so that the set of minimum points of\nthe objective function does not change. Necessary and sufficient conditions for\nirrelevance of sparse signal regularization and a condition for the existence\nof finite upper bounds are established. We formulate an optimization problem\nfor finding these bounds when the regularization term can be globally minimized\nby a feasible $x$ and also develop an alternating direction method of\nmultipliers (ADMM) type method for their computation. Simulation examples show\nthat the derived and empirical bounds match.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Higher order mobile coverage control with application to localization.   Most current results on coverage control using mobile sensors require that\none partitioned cell is associated with precisely one sensor. In this paper, we\nconsider a class of coverage control problems involving higher order Voronoi\npartitions, motivated by applications where more than one sensor is required to\nmonitor and cover one cell. Such applications are frequent in scenarios\nrequiring the sensors to localize targets. We introduce a framework depending\non a coverage performance function incorporating higher order Voronoi cells and\nthen design a gradient-based controller which allows the multi-sensor system to\nachieve a local equilibrium in a distributed manner. The convergence properties\nare studied and related to Lloyd algorithm. We study also the extension to\ncoverage of a discrete set of points. In addition, we provide a number of real\nworld scenarios where our framework can be applied. Simulation results are also\nprovided to show the controller performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simple Classification using Binary Data.   Binary, or one-bit, representations of data arise naturally in many\napplications, and are appealing in both hardware implementations and algorithm\ndesign. In this work, we study the problem of data classification from binary\ndata and propose a framework with low computation and resource costs. We\nillustrate the utility of the proposed approach through stylized and realistic\nnumerical experiments, and provide a theoretical analysis for a simple case. We\nhope that our framework and analysis will serve as a foundation for studying\nsimilar types of approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Statistical Challenges of Echo State Networks and Some Potential Remedies.   Echo state networks are powerful recurrent neural networks. However, they are\noften unstable and shaky, making the process of finding an good ESN for a\nspecific dataset quite hard. Obtaining a superb accuracy by using the Echo\nState Network is a challenging task. We create, develop and implement a family\nof predictably optimal robust and stable ensemble of Echo State Networks via\nregularizing the training and perturbing the input. Furthermore, several\ndistributions of weights have been tried based on the shape to see if the shape\nof the distribution has the impact for reducing the error. We found ESN can\ntrack in short term for most dataset, but it collapses in the long run.\nShort-term tracking with large size reservoir enables ESN to perform strikingly\nwith superior prediction. Based on this scenario, we go a further step to\naggregate many of ESNs into an ensemble to lower the variance and stabilize the\nsystem by stochastic replications and bootstrapping of input data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comparison of multi-task convolutional neural network (MT-CNN) and a few other methods for toxicity prediction.   Toxicity analysis and prediction are of paramount importance to human health\nand environmental protection. Existing computational methods are built from a\nwide variety of descriptors and regressors, which makes their performance\nanalysis difficult. For example, deep neural network (DNN), a successful\napproach in many occasions, acts like a black box and offers little conceptual\nelegance or physical understanding. The present work constructs a common set of\nmicroscopic descriptors based on established physical models for charges,\nsurface areas and free energies to assess the performance of multi-task\nconvolutional neural network (MT-CNN) architectures and a few other approaches,\nincluding random forest (RF) and gradient boosting decision tree (GBDT), on an\nequal footing. Comparison is also given to convolutional neural network (CNN)\nand non-convolutional deep neural network (DNN) algorithms. Four benchmark\ntoxicity data sets (i.e., endpoints) are used to evaluate various approaches.\nExtensive numerical studies indicate that the present MT-CNN architecture is\nable to outperform the state-of-the-art methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Service adoption spreading in online social networks.   The collective behaviour of people adopting an innovation, product or online\nservice is commonly interpreted as a spreading phenomenon throughout the fabric\nof society. This process is arguably driven by social influence, social\nlearning and by external effects like media. Observations of such processes\ndate back to the seminal studies by Rogers and Bass, and their mathematical\nmodelling has taken two directions: One paradigm, called simple contagion,\nidentifies adoption spreading with an epidemic process. The other one, named\ncomplex contagion, is concerned with behavioural thresholds and successfully\nexplains the emergence of large cascades of adoption resulting in a rapid\nspreading often seen in empirical data. The observation of real world adoption\nprocesses has become easier lately due to the availability of large digital\nsocial network and behavioural datasets. This has allowed simultaneous study of\nnetwork structures and dynamics of online service adoption, shedding light on\nthe mechanisms and external effects that influence the temporal evolution of\nbehavioural or innovation adoption. These advancements have induced the\ndevelopment of more realistic models of social spreading phenomena, which in\nturn have provided remarkably good predictions of various empirical adoption\nprocesses. In this chapter we review recent data-driven studies addressing\nreal-world service adoption processes. Our studies provide the first detailed\nempirical evidence of a heterogeneous threshold distribution in adoption. We\nalso describe the modelling of such phenomena with formal methods and\ndata-driven simulations. Our objective is to understand the effects of\nidentified social mechanisms on service adoption spreading, and to provide\npotential new directions and open questions for future research.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Maximally rotating waves in AdS and on spheres.   We study the cubic wave equation in AdS_(d+1) (and a closely related cubic\nwave equation on S^3) in a weakly nonlinear regime. Via time-averaging, these\nsystems are accurately described by simplified infinite-dimensional quartic\nHamiltonian systems, whose structure is mandated by the fully resonant spectrum\nof linearized perturbations. The maximally rotating sector, comprising only the\nmodes of maximal angular momentum at each frequency level, consistently\ndecouples in the weakly nonlinear regime. The Hamiltonian systems obtained by\nthis decoupling display remarkable periodic return behaviors closely analogous\nto what has been demonstrated in recent literature for a few other related\nequations (the cubic Szego equation, the conformal flow, the LLL equation).\nThis suggests a powerful underlying analytic structure, such as integrability.\nWe comment on the connection of our considerations to the Gross-Pitaevskii\nequation for harmonically trapped Bose-Einstein condensates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Pressure-induced Superconductivity in the Three-component Fermion Topological Semimetal Molybdenum Phosphide.   Topological semimetal, a novel state of quantum matter hosting exotic\nemergent quantum phenomena dictated by the non-trivial band topology, has\nemerged as a new frontier in condensed-matter physics. Very recently, a\ncoexistence of triply degenerate points of band crossing and Weyl points near\nthe Fermi level was theoretically predicted and immediately experimentally\nverified in single crystalline molybdenum phosphide (MoP). Here we show in this\nmaterial the high-pressure electronic transport and synchrotron X-ray\ndiffraction (XRD) measurements, combined with density functional theory (DFT)\ncalculations. We report the emergence of pressure-induced superconductivity in\nMoP with a critical temperature Tc of about 2 K at 27.6 GPa, rising to 3.7 K at\nthe highest pressure of 95.0 GPa studied. No structural phase transitions is\ndetected up to 60.6 GPa from the XRD. Meanwhile, the Weyl points and triply\ndegenerate points topologically protected by the crystal symmetry are retained\nat high pressure as revealed by our DFT calculations. The coexistence of\nthree-component fermion and superconductivity in heavily pressurized MoP offers\nan excellent platform to study the interplay between topological phase of\nmatter and superconductivity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Implementing GraphQL as a Query Language for Deductive Databases in SWI-Prolog Using DCGs, Quasi Quotations, and Dicts.   The methods to access large relational databases in a distributed system are\nwell established: the relational query language SQL often serves as a language\nfor data access and manipulation, and in addition public interfaces are exposed\nusing communication protocols like REST. Similarly to REST, GraphQL is the\nquery protocol of an application layer developed by Facebook. It provides a\nunified interface between the client and the server for data fetching and\nmanipulation. Using GraphQL's type system, it is possible to specify data\nhandling of various sources and to combine, e.g., relational with NoSQL\ndatabases. In contrast to REST, GraphQL provides a single API endpoint and\nsupports flexible queries over linked data.\nGraphQL can also be used as an interface for deductive databases. In this\npaper, we give an introduction of GraphQL and a comparison to REST. Using\nlanguage features recently added to SWI-Prolog 7, we have developed the Prolog\nlibrary GraphQL.pl, which implements the GraphQL type system and query syntax\nas a domain-specific language with the help of definite clause grammars (DCG),\nquasi quotations, and dicts. Using our library, the type system created for a\ndeductive database can be validated, while the query system provides a unified\ninterface for data access and introspection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A second-order stochastic maximum principle for generalized mean-field control problem.   In this paper, we study the generalized mean-field stochastic control problem\nwhen the usual stochastic maximum principle (SMP) is not applicable due to the\nsingularity of the Hamiltonian function. In this case, we derive a second order\nSMP. We introduce the adjoint process by the generalized mean-field backward\nstochastic differential equation. The keys in the proofs are the expansion of\nthe cost functional in terms of a perturbation parameter, and the use of the\nrange theorem for vector-valued measures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Double spend races.   We correct the double spend race analysis given in Nakamoto's foundational\nBitcoin article and give a closed-form formula for the probability of success\nof a double spend attack using the Regularized Incomplete Beta Function. We\ngive a proof of the exponential decay on the number of confirmations, often\ncited in the literature, and find an asymptotic formula. Larger number of\nconfirmations are necessary compared to those given by Nakamoto. We also\ncompute the probability conditional to the known validation time of the blocks.\nThis provides a finer risk analysis than the classical one.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tilings of convex sets by mutually incongruent equilateral triangles contain arbitrarily small tiles.   We show that every tiling of a convex set in the Euclidean plane\n$\\mathbb{R}^2$ by equilateral triangles of mutually different sizes contains\narbitrarily small tiles. The proof is purely elementary up to the discussion of\none family of tilings of the full plane $\\mathbb{R}^2$, which is based on a\nsurprising connection to a random walk on a directed graph.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Search for Food of Birds, Fish and Insects.   This book chapter introduces to the problem to which extent search strategies\nof foraging biological organisms can be identified by statistical data analysis\nand mathematical modeling. A famous paradigm in this field is the Levy Flight\nHypothesis: It states that under certain mathematical conditions Levy flights,\nwhich are a key concept in the theory of anomalous stochastic processes,\nprovide an optimal search strategy. This hypothesis may be understood\nbiologically as the claim that Levy flights represent an evolutionary adaptive\noptimal search strategy for foraging organisms. Another interpretation,\nhowever, is that Levy flights emerge from the interaction between a forager and\na given (scale-free) distribution of food sources. These hypotheses are\ndiscussed controversially in the current literature. We give examples and\ncounterexamples of experimental data and their analyses supporting and\nchallenging them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Galerkin Least-Squares Stabilization in Ice Sheet Modeling - Accuracy, Robustness, and Comparison to other Techniques.   We investigate the accuracy and robustness of one of the most common methods\nused in glaciology for the discretization of the $\\mathfrak{p}$-Stokes\nequations: equal order finite elements with Galerkin Least-Squares (GLS)\nstabilization. Furthermore we compare the results to other stabilized methods.\nWe find that the vertical velocity component is more sensitive to the choice of\nGLS stabilization parameter than horizontal velocity. Additionally, the\naccuracy of the vertical velocity component is especially important since\nerrors in this component can cause ice surface instabilities and propagate into\nfuture ice volume predictions. If the element cell size is set to the minimum\nedge length and the stabilization parameter is allowed to vary non-linearly\nwith viscosity, the GLS stabilization parameter found in literature is a good\nchoice on simple domains. However, near ice margins the standard parameter\nchoice may result in significant oscillations in the vertical component of the\nsurface velocity. For these cases, other stabilization techniques, such as the\ninterior penalty method, result in better accuracy and are less sensitive to\nthe choice of the stabilization parameter. During this work we also discovered\nthat the manufactured solutions often used to evaluate errors in glaciology are\nnot reliable due to high artificial surface forces at singularities. We perform\nour numerical experiments in both FEniCS and Elmer/Ice.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Incremental Principal Component Analysis Exact implementation and continuity corrections.   This paper describes some applications of an incremental implementation of\nthe principal component analysis (PCA). The algorithm updates the\ntransformation coefficients matrix on-line for each new sample, without the\nneed to keep all the samples in memory. The algorithm is formally equivalent to\nthe usual batch version, in the sense that given a sample set the\ntransformation coefficients at the end of the process are the same. The\nimplications of applying the PCA in real time are discussed with the help of\ndata analysis examples. In particular we focus on the problem of the continuity\nof the PCs during an on-line analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On semi-supervised learning.   Semi-supervised learning deals with the problem of how, if possible, to take\nadvantage of a huge amount of unclassified data, to perform a classification in\nsituations when, typically, there is little labeled data. Even though this is\nnot always possible (it depends on how useful, for inferring the labels, it\nwould be to know the distribution of the unlabeled data), several algorithm\nhave been proposed recently. %but in general they are not proved to outperform\nA new algorithm is proposed, that under almost necessary conditions, %and it is\nproved that it attains asymptotically the performance of the best theoretical\nrule as the amount of unlabeled data tends to infinity. The set of necessary\nassumptions, although reasonable, show that semi-supervised classification only\nworks for very well conditioned problems. The focus is on understanding when\nand why semi-supervised learning works when the size of the initial training\nsample remains fixed and the asymptotic is on the size of the unlabeled data.\nThe performance of the algorithm is assessed in the well known \"Isolet\"\nreal-data of phonemes, where a strong dependence on the choice of the initial\ntraining sample is shown.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Maximum Number of Modes of Gaussian Mixtures.   Gaussian mixture models are widely used in Statistics. A fundamental aspect\nof these distributions is the study of the local maxima of the density, or\nmodes. In particular, it is not known how many modes a mixture of $k$ Gaussians\nin $d$ dimensions can have. We give a brief account of this problem's history.\nThen, we give improved lower bounds and the first upper bound on the maximum\nnumber of modes, provided it is finite.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Some properties of nested Kriging predictors.   Kriging is a widely employed technique, in particular for computer\nexperiments, in machine learning or in geostatistics. An important challenge\nfor Kriging is the computational burden when the data set is large. We focus on\na class of methods aiming at decreasing this computational cost, consisting in\naggregating Kriging predictors based on smaller data subsets. We prove that\naggregations based solely on the conditional variances provided by the\ndifferent Kriging predictors can yield an inconsistent final Kriging\nprediction. In contrasts, we study theoretically the recent proposal by\n[Rulli{è}re et al., 2017] and obtain additional attractive properties for it.\nWe prove that this predictor is consistent, we show that it can be interpreted\nas an exact conditional distribution for a modified process and we provide\nerror bounds for it.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Pricing of Barrier Options on High Volatility Assets using Subset Simulation.   Barrier options are one of the most widely traded exotic options on stock\nexchanges. In this paper, we develop a new stochastic simulation method for\npricing barrier options and estimating the corresponding execution\nprobabilities. We show that the proposed method always outperforms the standard\nMonte Carlo approach and becomes substantially more efficient when the\nunderlying asset has high volatility, while it performs better than multilevel\nMonte Carlo for special cases of barrier options and underlying assets. These\ntheoretical findings are confirmed by numerous simulation results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interplay between social influence and competitive strategical games in multiplex networks.   We present a model that takes into account the coupling between evolutionary\ngame dynamics and social influence. Importantly, social influence and game\ndynamics take place in different domains, which we model as different layers of\na multiplex network. We show that the coupling between these dynamical\nprocesses can lead to cooperation in scenarios where the pure game dynamics\npredicts defection. In addition, we show that the structure of the network\nlayers and the relation between them can further increase cooperation.\nRemarkably, if the layers are related in a certain way, the system can reach a\npolarized metastable state.These findings could explain the prevalence of\npolarization observed in many social dilemmas.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Demonstration of an efficient, photonic-based astronomical spectrograph on an 8-m telescope.   We demonstrate for the first time an efficient, photonic-based astronomical\nspectrograph on the 8-m Subaru Telescope. An extreme adaptive optics system is\ncombined with pupil apodiziation optics to efficiently inject light directly\ninto a single-mode fiber, which feeds a compact cross-dispersed spectrograph\nbased on array waveguide grating technology. The instrument currently offers a\nthroughput of 5% from sky-to-detector which we outline could easily be upgraded\nto ~13% (assuming a coupling efficiency of 50%). The isolated spectrograph\nthroughput from the single-mode fiber to detector was 42% at 1550 nm. The\ncoupling efficiency into the single-mode fiber was limited by the achievable\nStrehl ratio on a given night. A coupling efficiency of 47% has been achieved\nwith ~60% Strehl ratio on-sky to date. Improvements to the adaptive optics\nsystem will enable 90% Strehl ratio and a coupling of up to 67% eventually.\nThis work demonstrates that the unique combination of advanced technologies\nenables the realization of a compact and highly efficient spectrograph, setting\na precedent for future instrument design on very-large and extremely-large\ntelescopes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Formalization of Transform Methods using HOL Light.   Transform methods, like Laplace and Fourier, are frequently used for\nanalyzing the dynamical behaviour of engineering and physical systems, based on\ntheir transfer function, and frequency response or the solutions of their\ncorresponding differential equations. In this paper, we present an ongoing\nproject, which focuses on the higher-order logic formalization of transform\nmethods using HOL Light theorem prover. In particular, we present the\nmotivation of the formalization, which is followed by the related work. Next,\nwe present the task completed so far while highlighting some of the challenges\nfaced during the formalization. Finally, we present a roadmap to achieve our\nobjectives, the current status and the future goals for this project.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Prior-aware Dual Decomposition: Document-specific Topic Inference for Spectral Topic Models.   Spectral topic modeling algorithms operate on matrices/tensors of word\nco-occurrence statistics to learn topic-specific word distributions. This\napproach removes the dependence on the original documents and produces\nsubstantial gains in efficiency and provable topic inference, but at a cost:\nthe model can no longer provide information about the topic composition of\nindividual documents. Recently Thresholded Linear Inverse (TLI) is proposed to\nmap the observed words of each document back to its topic composition. However,\nits linear characteristics limit the inference quality without considering the\nimportant prior information over topics. In this paper, we evaluate Simple\nProbabilistic Inverse (SPI) method and novel Prior-aware Dual Decomposition\n(PADD) that is capable of learning document-specific topic compositions in\nparallel. Experiments show that PADD successfully leverages topic correlations\nas a prior, notably outperforming TLI and learning quality topic compositions\ncomparable to Gibbs sampling on various data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Procedural Content Generation via Machine Learning (PCGML).   This survey explores Procedural Content Generation via Machine Learning\n(PCGML), defined as the generation of game content using machine learning\nmodels trained on existing content. As the importance of PCG for game\ndevelopment increases, researchers explore new avenues for generating\nhigh-quality content with or without human involvement; this paper addresses\nthe relatively new paradigm of using machine learning (in contrast with\nsearch-based, solver-based, and constructive methods). We focus on what is most\noften considered functional game content such as platformer levels, game maps,\ninteractive fiction stories, and cards in collectible card games, as opposed to\ncosmetic content such as sprites and sound effects. In addition to using PCG\nfor autonomous generation, co-creativity, mixed-initiative design, and\ncompression, PCGML is suited for repair, critique, and content analysis because\nof its focus on modeling existing content. We discuss various data sources and\nrepresentations that affect the resulting generated content. Multiple PCGML\nmethods are covered, including neural networks, long short-term memory (LSTM)\nnetworks, autoencoders, and deep convolutional networks; Markov models,\n$n$-grams, and multi-dimensional Markov chains; clustering; and matrix\nfactorization. Finally, we discuss open problems in the application of PCGML,\nincluding learning from small datasets, lack of training data, multi-layered\nlearning, style-transfer, parameter tuning, and PCG as a game mechanic.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Q-Learning Algorithm for VoLTE Closed-Loop Power Control in Indoor Small Cells.   We propose a reinforcement learning (RL) based closed loop power control\nalgorithm for the downlink of the voice over LTE (VoLTE) radio bearer for an\nindoor environment served by small cells. The main contributions of our paper\nare to 1) use RL to solve performance tuning problems in an indoor cellular\nnetwork for voice bearers and 2) show that our derived lower bound loss in\neffective signal to interference plus noise ratio due to neighboring cell\nfailure is sufficient for VoLTE power control purposes in practical cellular\nnetworks. In our simulation, the proposed RL-based power control algorithm\nsignificantly improves both voice retainability and mean opinion score compared\nto current industry standards. The improvement is due to maintaining an\neffective downlink signal to interference plus noise ratio against adverse\nnetwork operational issues and faults.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Human-Centered Autonomous Vehicle Systems: Principles of Effective Shared Autonomy.   Building effective, enjoyable, and safe autonomous vehicles is a lot harder\nthan has historically been considered. The reason is that, simply put, an\nautonomous vehicle must interact with human beings. This interaction is not a\nrobotics problem nor a machine learning problem nor a psychology problem nor an\neconomics problem nor a policy problem. It is all of these problems put into\none. It challenges our assumptions about the limitations of human beings at\ntheir worst and the capabilities of artificial intelligence systems at their\nbest. This work proposes a set of principles for designing and building\nautonomous vehicles in a human-centered way that does not run away from the\ncomplexity of human nature but instead embraces it. We describe our development\nof the Human-Centered Autonomous Vehicle (HCAV) as an illustrative case study\nof implementing these principles in practice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Superlinear scaling in the urban system of England of Wales. A comparison with US cities.   According to the theory of urban scaling, urban indicators scale with city\nsize in a predictable fashion. In particular, indicators of social and economic\nproductivity are expected to have a superlinear relation. This behavior was\nverified for many urban systems, but recent findings suggest that this pattern\nmay not be valid for England and Wales (E&W), where income has a linear\nrelation with city size. This finding raises the question of whether the cities\nof E&W exhibit any superlinear relation with respect to quantities such as the\nlevel of education and occupational groups. In this paper, we evaluate the\nscaling of educational and occupational groups of E&W to see if we can detect\nsuperlinear relations in the number of educated and better-paid persons. As E&W\nmay be unique in its linear scaling of income, we complement our analysis by\ncomparing it to the urban system of the United States (US), a country for which\nsuperlinear scaling of income has already been demonstrated. To make the two\nurban systems comparable, we define the urban systems of both countries using\nthe same method and test the sensitivity of our results to changes in the\nboundaries of cities. We find that cities of E&W exhibit patterns of\nsuperlinear scaling with respect to education and certain categories of\nbetter-paid occupations. However, the tendency of such groups to have\nsuperlinear scaling seems to be more consistent in the US. We show that while\nthe educational and occupational distributions of US cities can partly explain\nthe superlinear scaling of earnings, the distribution leads to a linear scaling\nof earnings in E&W.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Online Boosting Algorithms for Multi-label Ranking.   We consider the multi-label ranking approach to multi-label learning.\nBoosting is a natural method for multi-label ranking as it aggregates weak\npredictions through majority votes, which can be directly used as scores to\nproduce a ranking of the labels. We design online boosting algorithms with\nprovable loss bounds for multi-label ranking. We show that our first algorithm\nis optimal in terms of the number of learners required to attain a desired\naccuracy, but it requires knowledge of the edge of the weak learners. We also\ndesign an adaptive algorithm that does not require this knowledge and is hence\nmore practical. Experimental results on real data sets demonstrate that our\nalgorithms are at least as good as existing batch boosting algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Posterior Asymptotic Normality for an Individual Coordinate in High-dimensional Linear Regression.   We consider the sparse high-dimensional linear regression model\n$Y=Xb+\\epsilon$ where $b$ is a sparse vector. For the Bayesian approach to this\nproblem, many authors have considered the behavior of the posterior\ndistribution when, in truth, $Y=X\\beta+\\epsilon$ for some given $\\beta$. There\nhave been numerous results about the rate at which the posterior distribution\nconcentrates around $\\beta$, but few results about the shape of that posterior\ndistribution. We propose a prior distribution for $b$ such that the marginal\nposterior distribution of an individual coordinate $b_i$ is asymptotically\nnormal centered around an asymptotically efficient estimator, under the truth.\nSuch a result gives Bayesian credible intervals that match with the confidence\nintervals obtained from an asymptotically efficient estimator for $b_i$. We\nalso discuss ways of obtaining such asymptotically efficient estimators on\nindividual coordinates. We compare the two-step procedure proposed by Zhang and\nZhang (2014) and a one-step modified penalization method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Second differentials in the Quillen spectral sequence.   For an algebraic variety $X$ we introduce generalized first Chern classes,\nwhich are defined for coherent sheaves on $X$ with support in codimension $p$\nand take values in $CH^p(X)$. We use them to provide an explicit formula for\nthe differentials ${d_2^p: E_2^{p,-p-1} \\to E_2^{p+2, -p-2} \\cong CH^{p+2}(X)}$\nin the Quillen spectral sequence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modelling and prediction of financial trading networks: An application to the NYMEX natural gas futures market.   Over the last few years there has been a growing interest in using financial\ntrading networks to understand the microstructure of financial markets. Most of\nthe methodologies developed so far for this purpose have been based on the\nstudy of descriptive summaries of the networks such as the average node degree\nand the clustering coefficient. In contrast, this paper develops novel\nstatistical methods for modeling sequences of financial trading networks. Our\napproach uses a stochastic blockmodel to describe the structure of the network\nduring each period, and then links multiple time periods using a hidden Markov\nmodel. This structure allows us to identify events that affect the structure of\nthe market and make accurate short-term prediction of future transactions. The\nmethodology is illustrated using data from the NYMEX natural gas futures market\nfrom January 2005 to December 2008.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Superconductivity in quantum wires: A symmetry analysis.   We study properties of quantim wires with spin-orbit coupling and time\nreversal symmetry breaking, in normal and superconducting states. Electronic\nband structures are classified according to quasi-one-dimensional magnetic\npoint groups, or magnetic classes. The latter belong to one of three distinct\ntypes, depending on the way the time reversal operation appears in the group\nelements. The superconducting gap functions are constructed using antiunitary\noperations and have different symmetry properties depending on the type of the\nmagnetic point group. We obtain the spectrum of the Andreev boundary modes near\nthe end of the wire in a model-independent way, using the semiclassical\napproach with the boundary conditions described by a phenomenological\nscattering matrix. Explicit expressions for the bulk topological invariants\ncontrolling the number of the boundary zero modes are presented in the general\nmultiband case for two types of the magnetic point groups, corresponding to\nDIII and BDI symmetry classes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Using English as Pivot to Extract Persian-Italian Parallel Sentences from Non-Parallel Corpora.   The effectiveness of a statistical machine translation system (SMT) is very\ndependent upon the amount of parallel corpus used in the training phase. For\nlow-resource language pairs there are not enough parallel corpora to build an\naccurate SMT. In this paper, a novel approach is presented to extract bilingual\nPersian-Italian parallel sentences from a non-parallel (comparable) corpus. In\nthis study, English is used as the pivot language to compute the matching\nscores between source and target sentences and candidate selection phase.\nAdditionally, a new monolingual sentence similarity metric, Normalized Google\nDistance (NGD) is proposed to improve the matching process. Moreover, some\nextensions of the baseline system are applied to improve the quality of\nextracted sentences measured with BLEU. Experimental results show that using\nthe new pivot based extraction can increase the quality of bilingual corpus\nsignificantly and consequently improves the performance of the Persian-Italian\nSMT system.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Link colorings and the Goeritz matrix.   We discuss the connection between colorings of a link diagram and the Goeritz\nmatrix.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improving Trajectory Optimization using a Roadmap Framework.   We present an evaluation of several representative sampling-based and\noptimization-based motion planners, and then introduce an integrated motion\nplanning system which incorporates recent advances in trajectory optimization\ninto a sparse roadmap framework. Through experiments in 4 common application\nscenarios with 5000 test cases each, we show that optimization-based or\nsampling-based planners alone are not effective for realistic problems where\nfast planning times are required. To the best of our knowledge, this is the\nfirst work that presents such a systematic and comprehensive evaluation of\nstate-of-the-art motion planners, which are based on a significant amount of\nexperiments. We then combine different stand-alone planners with trajectory\noptimization. The results show that the combination of our sparse roadmap and\ntrajectory optimization provides superior performance over other standard\nsampling-based planners combinations. By using a multi-query roadmap instead of\ngenerating completely new trajectories for each planning problem, our approach\nallows for extensions such as persistent control policy information associated\nwith a trajectory across planning problems. Also, the sub-optimality resulting\nfrom the sparsity of roadmap, as well as the unexpected disturbances from the\nenvironment, can both be overcome by the real-time trajectory optimization\nprocess.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Full-angle Negative Reflection with An Ultrathin Acoustic Gradient Metasurface: Floquet-Bloch Modes Perspective and Experimental Verification.   Metasurface with gradient phase response offers new alternative for steering\nthe propagation of waves. Conventional Snell's law has been revised by taking\nthe contribution of local phase gradient into account. However, the requirement\nof momentum matching along the metasurface sets its nontrivial beam\nmanipulation functionality within a limited-angle incidence. In this work, we\ntheoretically and experimentally demonstrate that the acoustic gradient\nmetasurface supports the negative reflection for full-angle incidence. The mode\nexpansion theory is developed to help understand how the gradient metasurface\ntailors the incident beams, and the full-angle negative reflection occurs when\nthe first negative order Floquet-Bloch mode dominates. The coiling-up space\nstructures are utilized to build desired acoustic gradient metasurface and the\nfull-angle negative reflections have been perfectly verified by experimental\nmeasurements. Our work offers the Floquet-Bloch modes perspective for\nqualitatively understanding the reflection behaviors of the acoustic gradient\nmetasurface and enables a new degree of the acoustic wave manipulating.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Transverse spinning of light with globally unique handedness.   Access to the transverse spin of light has unlocked new regimes in\ntopological photonics and optomechanics. To achieve the transverse spin of\nnonzero longitudinal fields, various platforms that derive transversely\nconfined waves based on focusing, interference, or evanescent waves have been\nsuggested. Nonetheless, because of the transverse confinement inherently\naccompanying sign reversal of the field derivative, the resulting transverse\nspin handedness experiences spatial inversion, which leads to a mismatch\nbetween the densities of the wavefunction and its spin component and hinders\nthe global observation of the transverse spin. Here, we reveal a globally pure\ntransverse spin in which the wavefunction density signifies the spin\ndistribution, by employing inverse molding of the eigenmode in the spin basis.\nStarting from the target spin profile, we analytically obtain the potential\nlandscape and then show that the elliptic-hyperbolic transition around the\nepsilon-near-zero permittivity allows for the global conservation of transverse\nspin handedness across the topological interface between anisotropic\nmetamaterials. Extending to the non-Hermitian regime, we also develop\nannihilated transverse spin modes to cover the entire Poincare sphere of the\nmeridional plane. Our results enable the complete transfer of optical energy to\ntransverse spinning motions and realize the classical analogy of 3-dimensional\nquantum spin states.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Strong coupling Bose polarons in a BEC.   We use a non-perturbative renormalization group approach to develop a unified\npicture of the Bose polaron problem, where a mobile impurity is strongly\ninteracting with a surrounding Bose-Einstein condensate (BEC). A detailed\ntheoretical analysis of the phase diagram is presented and the\npolaron-to-molecule transition is discussed. For attractive polarons we argue\nthat a description in terms of an effective Fröhlich Hamiltonian with\nrenormalized parameters is possible. Its strong coupling regime is realized\nclose to a Feshbach resonance, where we predict a sharp increase of the\neffective mass. Already for weaker interactions, before the polaron mass\ndiverges, we predict a transition to a regime where states exist below the\npolaron energy and the attractive polaron is no longer the ground state. On the\nrepulsive side of the Feshbach resonance we recover the repulsive polaron,\nwhich has a finite lifetime because it can decay into low-lying molecular\nstates. We show for the entire range of couplings that the polaron energy has\nlogarithmic corrections in comparison with predictions by the mean-field\napproach. We demonstrate that they are a consequence of the polaronic mass\nrenormalization which is due to quantum fluctuations of correlated phonons in\nthe polaron cloud.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Optimal lower exponent for the higher gradient integrability of solutions to two-phase elliptic equations in two dimensions.   We study the higher gradient integrability of distributional solutions $u$ to\nthe equation $div(\\sigma \\nabla u) = 0$ in dimension two, in the case when the\nessential range of $\\sigma$ consists of only two elliptic matrices, i.e.,\n$\\sigma\\in\\{\\sigma_1, \\sigma_2\\}$ a.e. in $\\Omega$.\nIn [4], for every pair of elliptic matrices $\\sigma_1$ and $\\sigma_2$,\nexponents $p_{\\sigma_1,\\sigma_2}\\in(2,+\\infty)$ and $q_{\\sigma_1,\\sigma_2}\\in\n(1,2)$ have been characterised so that if $u\\in\nW^{1,q_{\\sigma_1,\\sigma_2}}(\\Omega)$ is solution to the elliptic equation then\n$\\nabla u\\in L^{p_{\\sigma_1,\\sigma_2}}_{\\rm weak}(\\Omega)$ and the optimality\nof the upper exponent $p_{\\sigma_1,\\sigma_2}$ has been proved. In this paper we\ncomplement the above result by proving the optimality of the lower exponent\n$q_{\\sigma_1,\\sigma_2}$. Precisely, we show that for every arbitrarily small\n$\\delta$, one can find a particular microgeometry, i.e., an arrangement of the\nsets $\\sigma^{-1}(\\sigma_1)$ and $\\sigma^{-1}(\\sigma_2)$, for which there\nexists a solution $u$ to the corresponding elliptic equation such that $\\nabla\nu \\in L^{q_{\\sigma_1,\\sigma_2}-\\delta}$, but $\\nabla u \\notin\nL^{q_{\\sigma_1,\\sigma_2}}.$ The existence of such optimal microgeometries is\nachieved by convex integration methods, adapting to the present setting the\ngeometric constructions provided in [2] for the isotropic case.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Large odd order character sums and improvements of the Pólya-Vinogradov inequality.   For a primitive Dirichlet character $\\chi$ modulo $q$, we define\n$M(\\chi)=\\max_{t } |\\sum_{n \\leq t} \\chi(n)|$. In this paper, we study this\nquantity for characters of a fixed odd order $g\\geq 3$. Our main result\nprovides a further improvement of the classical Pólya-Vinogradov inequality\nin this case. More specifically, we show that for any such character $\\chi$ we\nhave $$M(\\chi)\\ll_{\\varepsilon} \\sqrt{q}(\\log q)^{1-\\delta_g}(\\log\\log\nq)^{-1/4+\\varepsilon},$$ where $\\delta_g := 1-\\frac{g}{\\pi}\\sin(\\pi/g)$. This\nimproves upon the works of Granville and Soundararajan and of Goldmakher.\nFurthermore, assuming the Generalized Riemann hypothesis (GRH) we prove that $$\nM(\\chi) \\ll \\sqrt{q} \\left(\\log_2 q\\right)^{1-\\delta_g} \\left(\\log_3\nq\\right)^{-\\frac{1}{4}}\\left(\\log_4 q\\right)^{O(1)}, $$ where $\\log_j$ is the\n$j$-th iterated logarithm. We also show unconditionally that this bound is best\npossible (up to a power of $\\log_4 q$). One of the key ingredients in the proof\nof the upper bounds is a new Halász-type inequality for logarithmic mean\nvalues of completely multiplicative functions, which might be of independent\ninterest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Abrupt disappearance and reemergence of the SU(2) and SU(4) Kondo effects due to population inversion.   The interplay of almost degenerate levels in quantum dots and molecular\njunctions with possibly different couplings to the reservoirs has lead to many\nobservable phenomena, such as the Fano effect, transmission phase slips and the\nSU(4) Kondo effect. Here we predict a dramatic repeated disappearance and\nreemergence of the SU(4) and anomalous SU(2) Kondo effects with increasing gate\nvoltage. This phenomenon is attributed to the level occupation switching which\nhas been previously invoked to explain the universal transmission phase slips\nin the conductance through a quantum dot. We use analytical arguments and\nnumerical renormalization group calculations to explain the observations and\ndiscuss their experimental relevance and dependence on the physical parameters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Riesz sequences and generalized arithmetic progressions.   The purpose of this note is to verify that the results attained in [6] admit\nan extension to the multidimensional setting. Namely, for subsets of the two\ndimensional torus we find the sharp growth rate of the step(s) of a generalized\narithmetic progression in terms of its size which may be found in an\nexponential systems satisfying the Riesz sequence property.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Incremental Skip-gram Model with Negative Sampling.   This paper explores an incremental training strategy for the skip-gram model\nwith negative sampling (SGNS) from both empirical and theoretical perspectives.\nExisting methods of neural word embeddings, including SGNS, are multi-pass\nalgorithms and thus cannot perform incremental model update. To address this\nproblem, we present a simple incremental extension of SGNS and provide a\nthorough theoretical analysis to demonstrate its validity. Empirical\nexperiments demonstrated the correctness of the theoretical analysis as well as\nthe practical usefulness of the incremental algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards Object Life Cycle-Based Variant Generation of Business Process Models.   Variability management of process models is a major challenge for\nProcess-Aware Information Systems. Process model variants can be attributed to\nany of the following reasons: new technologies, governmental rules,\norganizational context or adoption of new standards. Current approaches to\nmanage variants of process models address issues such as reducing the huge\neffort of modeling from scratch, preventing redundancy, and controlling\ninconsistency in process models. Although the effort to manage process model\nvariants has been exerted, there are still limitations. Furthermore, existing\napproaches do not focus on variants that come from change in organizational\nperspective of process models. Organizational-driven variant management is an\nimportant area that still needs more study that we focus on in this paper.\nObject Life Cycle (OLC) is an important aspect that may change from an\norganization to another. This paper introduces an approach inspired by real\nlife scenario to generate consistent process model variants that come from\nadaptations in the OLC.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Toric Codes, Multiplicative Structure and Decoding.   Long linear codes constructed from toric varieties over finite fields, their\nmultiplicative structure and decoding. The main theme is the inherent\nmultiplicative structure on toric codes. The multiplicative structure allows\nfor \\emph{decoding}, resembling the decoding of Reed-Solomon codes and aligns\nwith decoding by error correcting pairs. We have used the multiplicative\nstructure on toric codes to construct linear secret sharing schemes with\n\\emph{strong multiplication} via Massey's construction generalizing the Shamir\nLinear secret sharing shemes constructed from Reed-Solomon codes. We have\nconstructed quantum error correcting codes from toric surfaces by the\nCalderbank-Shor-Steane method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Computing Simple Multiple Zeros of Polynomial Systems.   Given a polynomial system f associated with a simple multiple zero x of\nmultiplicity {\\mu}, we give a computable lower bound on the minimal distance\nbetween the simple multiple zero x and other zeros of f. If x is only given\nwith limited accuracy, we propose a numerical criterion that f is certified to\nhave {\\mu} zeros (counting multiplicities) in a small ball around x.\nFurthermore, for simple double zeros and simple triple zeros whose Jacobian is\nof normalized form, we define modified Newton iterations and prove the\nquantified quadratic convergence when the starting point is close to the exact\nsimple multiple zero. For simple multiple zeros of arbitrary multiplicity whose\nJacobian matrix may not have a normalized form, we perform unitary\ntransformations and modified Newton iterations, and prove its non-quantified\nquadratic convergence and its quantified convergence for simple triple zeros.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sparse-Group Bayesian Feature Selection Using Expectation Propagation for Signal Recovery and Network Reconstruction.   We present a Bayesian method for feature selection in the presence of\ngrouping information with sparsity on the between- and within group level.\nInstead of using a stochastic algorithm for parameter inference, we employ\nexpectation propagation, which is a deterministic and fast algorithm. Available\nmethods for feature selection in the presence of grouping information have a\nnumber of short-comings: on one hand, lasso methods, while being fast,\nunderestimate the regression coefficients and do not make good use of the\ngrouping information, and on the other hand, Bayesian approaches, while\naccurate in parameter estimation, often rely on the stochastic and slow Gibbs\nsampling procedure to recover the parameters, rendering them infeasible e.g.\nfor gene network reconstruction. Our approach of a Bayesian sparse-group\nframework with expectation propagation enables us to not only recover accurate\nparameter estimates in signal recovery problems, but also makes it possible to\napply this Bayesian framework to large-scale network reconstruction problems.\nThe presented method is generic but in terms of application we focus on gene\nregulatory networks. We show on simulated and experimental data that the method\nconstitutes a good choice for network reconstruction regarding the number of\ncorrectly selected features, prediction on new data and reasonable computing\ntime.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Scalable Realistic Recommendation Datasets through Fractal Expansions.   Recommender System research suffers currently from a disconnect between the\nsize of academic data sets and the scale of industrial production systems. In\norder to bridge that gap we propose to generate more massive user/item\ninteraction data sets by expanding pre-existing public data sets. User/item\nincidence matrices record interactions between users and items on a given\nplatform as a large sparse matrix whose rows correspond to users and whose\ncolumns correspond to items. Our technique expands such matrices to larger\nnumbers of rows (users), columns (items) and non zero values (interactions)\nwhile preserving key higher order statistical properties. We adapt the\nKronecker Graph Theory to user/item incidence matrices and show that the\ncorresponding fractal expansions preserve the fat-tailed distributions of user\nengagements, item popularity and singular value spectra of user/item\ninteraction matrices. Preserving such properties is key to building large\nrealistic synthetic data sets which in turn can be employed reliably to\nbenchmark Recommender Systems and the systems employed to train them. We\nprovide algorithms to produce such expansions and apply them to the MovieLens\n20 million data set comprising 20 million ratings of 27K movies by 138K users.\nThe resulting expanded data set has 10 billion ratings, 2 million items and\n864K users in its smaller version and can be scaled up or down. A larger\nversion features 655 billion ratings, 7 million items and 17 million users.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Networks of planar Hamiltonian systems.   We introduce diffusively coupled networks where the dynamical system at each\nvertex is planar Hamiltonian. The problems we address are synchronisation and\nan analogue of diffusion-driven Turing instability for time-dependent\nhomogeneous states. As a consequence of the underlying Hamiltonian structure\nthere exist unusual behaviours compared with networks of coupled limit cycle\noscillators or activator-inhibitor systems.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Normal forms of dispersive scalar Poisson brackets with two independent variables.   We classify the dispersive Poisson brackets with one dependent variable and\ntwo independent variables, with leading order of hydrodynamic type, up to Miura\ntransformations. We show that, in contrast to the case of a single independent\nvariable for which a well known triviality result exists, the Miura equivalence\nclasses are parametrised by an infinite number of constants, which we call\nnumerical invariants of the brackets. We obtain explicit formulas for the first\nfew numerical invariants.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Optimal client recommendation for market makers in illiquid financial products.   The process of liquidity provision in financial markets can result in\nprolonged exposure to illiquid instruments for market makers. In this case,\nwhere a proprietary position is not desired, pro-actively targeting the right\nclient who is likely to be interested can be an effective means to offset this\nposition, rather than relying on commensurate interest arising through natural\ndemand. In this paper, we consider the inference of a client profile for the\npurpose of corporate bond recommendation, based on typical recorded information\navailable to the market maker. Given a historical record of corporate bond\ntransactions and bond meta-data, we use a topic-modelling analogy to develop a\nprobabilistic technique for compiling a curated list of client recommendations\nfor a particular bond that needs to be traded, ranked by probability of\ninterest. We show that a model based on Latent Dirichlet Allocation offers\npromising performance to deliver relevant recommendations for sales traders.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Use of Limited-Memory Accelerators for Linear Learning on Heterogeneous Systems.   We propose a generic algorithmic building block to accelerate training of\nmachine learning models on heterogeneous compute systems. Our scheme allows to\nefficiently employ compute accelerators such as GPUs and FPGAs for the training\nof large-scale machine learning models, when the training data exceeds their\nmemory capacity. Also, it provides adaptivity to any system's memory hierarchy\nin terms of size and processing speed. Our technique is built upon novel\ntheoretical insights regarding primal-dual coordinate methods, and uses duality\ngap information to dynamically decide which part of the data should be made\navailable for fast processing. To illustrate the power of our approach we\ndemonstrate its performance for training of generalized linear models on a\nlarge-scale dataset exceeding the memory size of a modern GPU, showing an\norder-of-magnitude speedup over existing approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Linearity of stability conditions.   We study different concepts of stability for modules over a finite\ndimensional algebra: linear stability, given by a \"central charge\", and\nnonlinear stability given by the wall-crossing sequence of a \"green path\". Two\nother concepts, finite Harder-Narasimhan stratification of the module category\nand maximal forward hom-orthogonal sequences of Schurian modules, which are\nalways equivalent to each other, are shown to be equivalent to nonlinear\nstability and to a maximal green sequence, defined using Fomin-Zelevinsky\nquiver mutation, in the case the algebra is hereditary.\nThis is the first of a series of three papers whose purpose is to determine\nall maximal green sequences of maximal length for quivers of affine type\n$\\tilde A$ and determine which are linear. The complete answer will be given in\nthe final paper [1].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Continuous CM-regularity of semihomogeneous vector bundles.   We show that if $X$ is an abelian variety of dimension $g \\geq 1$ and\n${\\mathcal E}$ is an M-regular coherent sheaf on $X$, the Castelnuovo-Mumford\nregularity of ${\\mathcal E}$ with respect to an ample and globally generated\nline bundle ${\\mathcal O}(1)$ on $X$ is at most $g$, and that equality is\nobtained when ${\\mathcal E}^{\\vee}(1)$ is continuously globally generated. As\nan application, we give a numerical characterization of ample semihomogeneous\nvector bundles for which this bound is attained.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Motion Planning for a UAV with a Straight or Kinked Tether.   This paper develops and compares two motion planning algorithms for a\ntethered UAV with and without the possibility of the tether contacting the\nconfined and cluttered environment. Tethered aerial vehicles have been studied\ndue to their advantages such as power duration, stability, and safety. However,\nthe disadvantages brought in by the extra tether have not been well\ninvestigated by the robotic locomotion community, especially when the tethered\nagent is locomoting in a non-free space occupied with obstacles. In this work,\nwe propose two motion planning frameworks that (1) reduce the reachable\nconfiguration space by taking into account the tether and (2) deliberately plan\n(and relax) the contact point(s) of the tether with the environment and enable\nan equivalent reachable configuration space as the non-tethered counterpart\nwould have. Both methods are tested on a physical robot, Fotokite Pro. With our\napproaches, tethered aerial vehicles could find their applications in confined\nand cluttered environments with obstacles as opposed to ideal free space, while\nstill maintaining the advantages from the usage of a tether. The motion\nplanning strategies are particularly suitable for marsupial heterogeneous\nrobotic teams, such as visual servoing/assisting for another mobile,\ntele-operated primary robot.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Weighted Kendall and High-order Kernels for Permutations.   We propose new positive definite kernels for permutations. First we introduce\na weighted version of the Kendall kernel, which allows to weight unequally the\ncontributions of different item pairs in the permutations depending on their\nranks. Like the Kendall kernel, we show that the weighted version is invariant\nto relabeling of items and can be computed efficiently in $O(n \\ln(n))$\noperations, where $n$ is the number of items in the permutation. Second, we\npropose a supervised approach to learn the weights by jointly optimizing them\nwith the function estimated by a kernel machine. Third, while the Kendall\nkernel considers pairwise comparison between items, we extend it by considering\nhigher-order comparisons among tuples of items and show that the supervised\napproach of learning the weights can be systematically generalized to\nhigher-order permutation kernels.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optic Disc and Cup Segmentation Methods for Glaucoma Detection with Modification of U-Net Convolutional Neural Network.   Glaucoma is the second leading cause of blindness all over the world, with\napproximately 60 million cases reported worldwide in 2010. If undiagnosed in\ntime, glaucoma causes irreversible damage to the optic nerve leading to\nblindness. The optic nerve head examination, which involves measurement of\ncup-to-disc ratio, is considered one of the most valuable methods of structural\ndiagnosis of the disease. Estimation of cup-to-disc ratio requires segmentation\nof optic disc and optic cup on eye fundus images and can be performed by modern\ncomputer vision algorithms. This work presents universal approach for automatic\noptic disc and cup segmentation, which is based on deep learning, namely,\nmodification of U-Net convolutional neural network. Our experiments include\ncomparison with the best known methods on publicly available databases\nDRIONS-DB, RIM-ONE v.3, DRISHTI-GS. For both optic disc and cup segmentation,\nour method achieves quality comparable to current state-of-the-art methods,\noutperforming them in terms of the prediction time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning Probabilistic Programs Using Backpropagation.   Probabilistic modeling enables combining domain knowledge with learning from\ndata, thereby supporting learning from fewer training instances than purely\ndata-driven methods. However, learning probabilistic models is difficult and\nhas not achieved the level of performance of methods such as deep neural\nnetworks on many tasks. In this paper, we attempt to address this issue by\npresenting a method for learning the parameters of a probabilistic program\nusing backpropagation. Our approach opens the possibility to building deep\nprobabilistic programming models that are trained in a similar way to neural\nnetworks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Fourier analytic approach to inhomogeneous Diophantine approximation.   In this paper, we study inhomogeneous Diophantine approximation with rational\nnumbers of reduced form. The central object to study is the set $W(f,\\theta)$\nas follows, \\begin{eqnarray*} \\left\\{x\\in [0,1]:\\left\n|x-\\frac{m+\\theta(n)}{n}\\right|<\\frac{f(n)}{n}\\text{ for infinitely many\ncoprime pairs of numbers } m,n\\right\\}, \\end{eqnarray*} where\n$\\{f(n)\\}_{n\\in\\mathbb{N}}$ and $\\{\\theta(n)\\}_{n\\in\\mathbb{N}}$ are sequences\nof real numbers in $[0,1/2]$. We will completely determine the Hausdorff\ndimension of $W(f,\\theta)$ in terms of $f$ and $\\theta$. As a by-product, we\nalso obtain a new sufficient condition for $W(f,\\theta)$ to have full Lebesgue\nmeasure and this result is closely related to the study of \\ds with extra\nconditions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Environmental feedback drives cooperation in spatial social dilemmas.   Exploiting others is beneficial individually but it could also be detrimental\nglobally. The reverse is also true: a higher cooperation level may change the\nenvironment in a way that is beneficial for all competitors. To explore the\npossible consequence of this feedback we consider a coevolutionary model where\nthe local cooperation level determines the payoff values of the applied\nprisoner's dilemma game. We observe that the coevolutionary rule provides a\nsignificantly higher cooperation level comparing to the traditional setup\nindependently of the topology of the applied interaction graph. Interestingly,\nthis cooperation supporting mechanism offers lonely defectors a high surviving\nchance for a long period hence the relaxation to the final cooperating state\nhappens logarithmically slow. As a consequence, the extension of the\ntraditional evolutionary game by considering interactions with the environment\nprovides a good opportunity for cooperators, but their reward may arrive with\nsome delay.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tensorizing Generative Adversarial Nets.   Generative Adversarial Network (GAN) and its variants exhibit\nstate-of-the-art performance in the class of generative models. To capture\nhigher-dimensional distributions, the common learning procedure requires high\ncomputational complexity and a large number of parameters. The problem of\nemploying such massive framework arises when deploying it on a platform with\nlimited computational power such as mobile phones. In this paper, we present a\nnew generative adversarial framework by representing each layer as a tensor\nstructure connected by multilinear operations, aiming to reduce the number of\nmodel parameters by a large factor while preserving the generative performance\nand sample quality. To learn the model, we employ an efficient algorithm which\nalternatively optimizes both discriminator and generator. Experimental outcomes\ndemonstrate that our model can achieve high compression rate for model\nparameters up to $35$ times when compared to the original GAN for MNIST\ndataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Analytical Design Optimization Method for Electric Propulsion Systems of Multicopter UAVs with Desired Hovering Endurance.   Multicopters are becoming increasingly important in both civil and military\nfields. Currently, most multicopter propulsion systems are designed by\nexperience and trial-and-error experiments, which are costly and ineffective.\nThis paper proposes a simple and practical method to help designers find the\noptimal propulsion system according to the given design requirements. First,\nthe modeling methods for four basic components of the propulsion system\nincluding propellers, motors, electric speed controls, and batteries are\nstudied respectively. Secondly, the whole optimization design problem is\nsimplified and decoupled into several sub-problems. By solving these\nsub-problems, the optimal parameters of each component can be obtained\nrespectively. Finally, based on the obtained optimal component parameters, the\noptimal product of each component can be quickly located and determined from\nthe corresponding database. Experiments and statistical analyses demonstrate\nthe effectiveness of the proposed method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Holomorphic Hermite polynomials in two variables.   Generalizations of the Hermite polynomials to many variables and/or to the\ncomplex domain have been located in mathematical and physical literature for\nsome decades. Polynomials traditionally called complex Hermite ones are mostly\nunderstood as polynomials in $z$ and $\\bar{z}$ which in fact makes them\npolynomials in two real variables with complex coefficients. The present paper\nproposes to investigate for the first time holomorphic Hermite polynomials in\ntwo variables. Their algebraic and analytic properties are developed here.\nWhile the algebraic properties do not differ too much for those considered so\nfar, their analytic features are based on a kind of non-rotational\northogonality invented by van Eijndhoven and Meyers. Inspired by their\ninvention we merely follow the idea of Bargmann's seminal paper (1961) giving\nexplicit construction of reproducing kernel Hilbert spaces based on those\npolynomials. \"Homotopic\" behavior of our new formation culminates in comparing\nit to the very classical Bargmann space of two variables on one edge and the\naforementioned Hermite polynomials in $z$ and $\\bar{z}$ on the other. Unlike in\nthe case of Bargmann's basis our Hermite polynomials are not product ones but\nfactorize to it when bonded together with the first case of limit properties\nleading both to the Bargmann basis and suitable form of the reproducing kernel.\nAlso in the second limit we recover standard results obeyed by Hermite\npolynomials in $z$ and $\\bar{z}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Conditions for the invertibility of dual energy data.   The Alvarez-Macovski method [Alvarez, R. E and Macovski, A.,\n\"Energy-selective reconstructions in X-ray computerized tomography\", Phys. Med.\nBiol. (1976), 733--44] requires the inversion of the transformation from the\nline integrals of the basis set coefficients to measurements with multiple\nx-ray spectra. Analytical formulas for invertibility of the transformation from\ntwo measurements to two line integrals are derived. It is found that\nnon-invertible systems have near zero Jacobian determinants on a nearly\nstraight line in the line integrals plane. Formulas are derived for the points\nwhere the line crosses the axes, thus determining the line. Additional formulas\nare derived for the values of the terms of the Jacobian determinant at the\nendpoints of the line of non-invertibility. The formulas are applied to a set\nof spectra including one suggested by Levine that is not invertible as well as\nsimilar spectra that are invertible and voltage switched x-ray tube spectra\nthat are also invertible. An iterative inverse transformation algorithm\nexhibits large errors with non-invertible spectra.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Controlling Multimode Optomechanical Interactions via Interference.   We demonstrate optomechanical interference in a multimode system, in which an\noptical mode couples to two mechanical modes. A phase-dependent\nexcitation-coupling approach is developed, which enables the observation of\nconstructive and destructive optomechanical interferences. The destructive\ninterference prevents the coupling of the mechanical system to the optical\nmode, suppressing optically-induced mechanical damping. These studies establish\noptomechanical interference as an essential tool for controlling the\ninteractions between light and mechanical oscillators.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Rayleigh-Brillouin light scattering spectroscopy of nitrous oxide (N$_2$O).   High signal-to-noise and high-resolution light scattering spectra are\nmeasured for nitrous oxide (N$_2$O) gas at an incident wavelength of 403.00 nm,\nat 90$^\\circ$ scattering, at room temperature and at gas pressures in the range\n$0.5-4$ bar. The resulting Rayleigh-Brillouin light scattering spectra are\ncompared to a number of models describing in an approximate manner the\ncollisional dynamics and energy transfer in this gaseous medium of this\npolyatomic molecular species. The Tenti-S6 model, based on macroscopic gas\ntransport coefficients, reproduces the scattering profiles in the entire\npressure range at less than 2\\% deviation at a similar level as does the\nalternative kinetic Grad's 6-moment model, which is based on the internal\ncollisional relaxation as a decisive parameter. A hydrodynamic model fails to\nreproduce experimental spectra for the low pressures of 0.5-1 bar, but yields\nvery good agreement ($< 1$\\%) in the pressure range $2-4$ bar. While these\nthree models have a different physical basis the internal molecular relaxation\nderived can for all three be described in terms of a bulk viscosity of $\\eta_b\n\\sim (6 \\pm 2) \\times 10^{-5}$ Pa$\\cdot$s. A 'rough-sphere' model, previously\nshown to be effective to describe light scattering in SF$_6$ gas, is not found\nto be suitable, likely in view of the non-sphericity and asymmetry of the N-N-O\nstructured linear polyatomic molecule.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Two-Layer Component-Based Allocation for Embedded Systems with GPUs.   Component-based development is a software engineering paradigm that can\nfacilitate the construction of embedded systems and tackle its complexities.\nThe modern embedded systems have more and more demanding requirements. One way\nto cope with such versatile and growing set of requirements is to employ\nheterogeneous processing power, i.e., CPU-GPU architectures. The new CPU-GPU\nembedded boards deliver an increased performance but also introduce additional\ncomplexity and challenges. In this work, we address the component-to-hardware\nallocation for CPU-GPU embedded systems. The allocation for such systems is\nmuch complex due to the increased amount of GPU-related information. For\nexample, while in traditional embedded systems the allocation mechanism may\nconsider only the CPU memory usage of components to find an appropriate\nallocation scheme, in heterogeneous systems, the GPU memory usage needs also to\nbe taken into account in the allocation process. This paper aims at decreasing\nthe component-to-hardware allocation complexity by introducing a 2-layer\ncomponent-based architecture for heterogeneous embedded systems. The detailed\nCPU-GPU information of the system is abstracted at a high-layer by compacting\nconnected components into single units that behave as regular components. The\nallocator, based on the compacted information received from the high-level\nlayer, computes, with a decreased complexity, feasible allocation schemes. In\nthe last part of the paper, the 2-layer allocation method is evaluated using an\nexisting embedded system demonstrator; namely, an underwater robot.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Relative Entropy in CFT.   By using Araki's relative entropy, Lieb's convexity and the theory of\nsingular integrals, we compute the mutual information associated with free\nfermions, and we deduce many results about entropies for chiral CFT's which are\nembedded into free fermions, and their extensions. Such relative entropies in\nCFT are here computed explicitly for the first time in a mathematical rigorous\nway. Our results agree with previous computations by physicists based on\nheuristic arguments; in addition we uncover a surprising connection with the\ntheory of subfactors, in particular by showing that a certain duality, which is\nargued to be true on physical grounds, is in fact violated if the global\ndimension of the conformal net is greater than $1.$",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "DoShiCo Challenge: Domain Shift in Control Prediction.   Training deep neural network policies end-to-end for real-world applications\nso far requires big demonstration datasets in the real world or big sets\nconsisting of a large variety of realistic and closely related 3D CAD models.\nThese real or virtual data should, moreover, have very similar characteristics\nto the conditions expected at test time. These stringent requirements and the\ntime consuming data collection processes that they entail, are currently the\nmost important impediment that keeps deep reinforcement learning from being\ndeployed in real-world applications. Therefore, in this work we advocate an\nalternative approach, where instead of avoiding any domain shift by carefully\nselecting the training data, the goal is to learn a policy that can cope with\nit. To this end, we propose the DoShiCo challenge: to train a model in very\nbasic synthetic environments, far from realistic, in a way that it can be\napplied in more realistic environments as well as take the control decisions on\nreal-world data. In particular, we focus on the task of collision avoidance for\ndrones. We created a set of simulated environments that can be used as\nbenchmark and implemented a baseline method, exploiting depth prediction as an\nauxiliary task to help overcome the domain shift. Even though the policy is\ntrained in very basic environments, it can learn to fly without collisions in a\nvery different realistic simulated environment. Of course several benchmarks\nfor reinforcement learning already exist - but they never include a large\ndomain shift. On the other hand, several benchmarks in computer vision focus on\nthe domain shift, but they take the form of a static datasets instead of\nsimulated environments. In this work we claim that it is crucial to take the\ntwo challenges together in one benchmark.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spectral Projector-Based Graph Fourier Transforms.   The paper presents the graph Fourier transform (GFT) of a signal in terms of\nits spectral decomposition over the Jordan subspaces of the graph adjacency\nmatrix $A$. This representation is unique and coordinate free, and it leads to\nunambiguous definition of the spectral components (\"harmonics\") of a graph\nsignal. This is particularly meaningful when $A$ has repeated eigenvalues, and\nit is very useful when $A$ is defective or not diagonalizable (as it may be the\ncase with directed graphs). Many real world large sparse graphs have defective\nadjacency matrices. We present properties of the GFT and show it to satisfy a\ngeneralized Parseval inequality and to admit a total variation ordering of the\nspectral components. We express the GFT in terms of spectral projectors and\npresent an illustrative example for a real world large urban traffic dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From modelling of systems with constraints to generalized geometry and back to numerics.   In this note we describe how some objects from generalized geometry appear in\nthe qualitative analysis and numerical simulation of mechanical systems. In\nparticular we discuss double vector bundles and Dirac structures. It turns out\nthat those objects can be naturally associated to systems with constraints --\nwe recall the mathematical construction in the context of so called implicit\nLagrangian systems. We explain how they can be used to produce new numerical\nmethods, that we call Dirac integrators.\nOn a test example of a simple pendulum in a gravity field we compare the\nDirac integrators with classical explicit and implicit methods, we pay special\nattention to conservation of constrains. Then, on a more advanced example of\nthe Ziegler column we show that the choice of numerical methods can indeed\naffect the conclusions of qualitative analysis of the dynamics of mechanical\nsystems. We also tell why we think that Dirac integrators are appropriate for\nthis kind of systems by explaining the relation with the notions of geometric\ndegree of non-conservativity and kinematic structural stability.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Field dependence of non-reciprocal magnons in chiral MnSi.   Spin waves in chiral magnetic materials are strongly influenced by the\nDzyaloshinskii-Moriya interaction resulting in intriguing phenomena like\nnon-reciprocal magnon propagation and magnetochiral dichroism. Here, we study\nthe non-reciprocal magnon spectrum of the archetypical chiral magnet MnSi and\nits evolution as a function of magnetic field covering the field-polarized and\nconical helix phase. Using inelastic neutron scattering, the magnon energies\nand their spectral weights are determined quantitatively after deconvolution\nwith the instrumental resolution. In the field-polarized phase the imaginary\npart of the dynamical susceptibility $\\chi''(\\varepsilon, {\\bf q})$ is shown to\nbe asymmetric with respect to wavevectors ${\\bf q}$ longitudinal to the applied\nmagnetic field ${\\bf H}$, which is a hallmark of chiral magnetism. In the\nhelimagnetic phase, $\\chi''(\\varepsilon, {\\bf q})$ becomes increasingly\nsymmetric with decreasing ${\\bf H}$ due to the formation of helimagnon bands\nand the activation of additional spinflip and non-spinflip scattering channels.\nThe neutron spectra are in excellent quantitative agreement with the low-energy\ntheory of cubic chiral magnets with a single fitting parameter being the\ndamping rate of spin waves.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Quest for Scalability and Accuracy in the Simulation of the Internet of Things: an Approach based on Multi-Level Simulation.   This paper presents a methodology for simulating the Internet of Things (IoT)\nusing multi-level simulation models. With respect to conventional simulators,\nthis approach allows us to tune the level of detail of different parts of the\nmodel without compromising the scalability of the simulation. As a use case, we\nhave developed a two-level simulator to study the deployment of smart services\nover rural territories. The higher level is base on a coarse grained,\nagent-based adaptive parallel and distributed simulator. When needed, this\nsimulator spawns OMNeT++ model instances to evaluate in more detail the issues\nconcerned with wireless communications in restricted areas of the simulated\nworld. The performance evaluation confirms the viability of multi-level\nsimulations for IoT environments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Action-conditional Sequence Modeling for Recommendation.   In many online applications interactions between a user and a web-service are\norganized in a sequential way, e.g., user browsing an e-commerce website. In\nthis setting, recommendation system acts throughout user navigation by showing\nitems. Previous works have addressed this recommendation setup through the task\nof predicting the next item user will interact with. In particular, Recurrent\nNeural Networks (RNNs) has been shown to achieve substantial improvements over\ncollaborative filtering baselines. In this paper, we consider interactions\ntriggered by the recommendations of deployed recommender system in addition to\nbrowsing behavior. Indeed, it is reported that in online services interactions\nwith recommendations represent up to 30\\% of total interactions. Moreover, in\npractice, recommender system can greatly influence user behavior by promoting\nspecific items. In this paper, we extend the RNN modeling framework by taking\ninto account user interaction with recommended items. We propose and evaluate\nRNN architectures that consist of the recommendation action module and the\nstate-action fusion module. Using real-world large-scale datasets we\ndemonstrate improved performance on the next item prediction task compared to\nthe baselines.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sleep Stage Classification Based on Multi-level Feature Learning and Recurrent Neural Networks via Wearable Device.   This paper proposes a practical approach for automatic sleep stage\nclassification based on a multi-level feature learning framework and Recurrent\nNeural Network (RNN) classifier using heart rate and wrist actigraphy derived\nfrom a wearable device. The feature learning framework is designed to extract\nlow- and mid-level features. Low-level features capture temporal and frequency\ndomain properties and mid-level features learn compositions and structural\ninformation of signals. Since sleep staging is a sequential problem with\nlong-term dependencies, we take advantage of RNNs with Bidirectional Long\nShort-Term Memory (BLSTM) architectures for sequence data learning. To simulate\nthe actual situation of daily sleep, experiments are conducted with a resting\ngroup in which sleep is recorded in resting state, and a comprehensive group in\nwhich both resting sleep and non-resting sleep are included.We evaluate the\nalgorithm based on an eight-fold cross validation to classify five sleep stages\n(W, N1, N2, N3, and REM). The proposed algorithm achieves weighted precision,\nrecall and F1 score of 58.0%, 60.3%, and 58.2% in the resting group and 58.5%,\n61.1%, and 58.5% in the comprehensive group, respectively. Various comparison\nexperiments demonstrate the effectiveness of feature learning and BLSTM. We\nfurther explore the influence of depth and width of RNNs on performance. Our\nmethod is specially proposed for wearable devices and is expected to be\napplicable for long-term sleep monitoring at home. Without using too much prior\ndomain knowledge, our method has the potential to generalize sleep disorder\ndetection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Novel Approach to Forecasting Financial Volatility with Gaussian Process Envelopes.   In this paper we use Gaussian Process (GP) regression to propose a novel\napproach for predicting volatility of financial returns by forecasting the\nenvelopes of the time series. We provide a direct comparison of their\nperformance to traditional approaches such as GARCH. We compare the forecasting\npower of three approaches: GP regression on the absolute and squared returns;\nregression on the envelope of the returns and the absolute returns; and\nregression on the envelope of the negative and positive returns separately. We\nuse a maximum a posteriori estimate with a Gaussian prior to determine our\nhyperparameters. We also test the effect of hyperparameter updating at each\nforecasting step. We use our approaches to forecast out-of-sample volatility of\nfour currency pairs over a 2 year period, at half-hourly intervals. From three\nkernels, we select the kernel giving the best performance for our data. We use\ntwo published accuracy measures and four statistical loss functions to evaluate\nthe forecasting ability of GARCH vs GPs. In mean squared error the GP's perform\n20% better than a random walk model, and 50% better than GARCH for the same\ndata.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Better than counting: Density profiles from force sampling.   Calculating one-body density profiles in equilibrium via particle-based\nsimulation methods involves counting of events of particle occurrences at\n(histogram-resolved) space points. Here we investigate an alternative method\nbased on a histogram of the local force density. Via an exact sum rule the\ndensity profile is obtained with a simple spatial integration. The method\ncircumvents the inherent ideal gas fluctuations. We have tested the method in\nMonte Carlo, Brownian Dynamics and Molecular Dynamics simulations. The results\ncarry a statistical uncertainty smaller than that of the standard, counting,\nmethod, reducing therefore the computation time.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Generic Dynamical Phase Transition in One-Dimensional Bulk-Driven Lattice Gases with Exclusion.   Dynamical phase transitions are crucial features of the fluctuations of\nstatistical systems, corresponding to boundaries between qualitatively\ndifferent mechanisms of maintaining unlikely values of dynamical observables\nover long periods of time. They manifest themselves in the form of\nnon-analyticities in the large deviation function of those observables. In this\npaper, we look at bulk-driven exclusion processes with open boundaries. It is\nknown that the standard asymmetric simple exclusion process exhibits a\ndynamical phase transition in the large deviations of the current of particles\nflowing through it. That phase transition has been described thanks to specific\ncalculation methods relying on the model being exactly solvable, but more\ngeneral methods have also been used to describe the extreme large deviations of\nthat current, far from the phase transition. We extend those methods to a large\nclass of models based on the ASEP, where we add arbitrary spatial\ninhomogeneities in the rates and short-range potentials between the particles.\nWe show that, as for the regular ASEP, the large deviation function of the\ncurrent scales differently with the size of the system if one considers very\nhigh or very low currents, pointing to the existence of a dynamical phase\ntransition between those two regimes: high current large deviations are\nextensive in the system size, and the typical states associated to them are\nCoulomb gases, which are correlated ; low current large deviations do not\ndepend on the system size, and the typical states associated to them are\nanti-shocks, consistently with a hydrodynamic behaviour. Finally, we illustrate\nour results numerically on a simple example, and we interpret the transition in\nterms of the current pushing beyond its maximal hydrodynamic value, as well as\nrelate it to the appearance of Tracy-Widom distributions in the relaxation\nstatistics of such models.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Explicit construction of RIP matrices is Ramsey-hard.   Matrices $\\Phi\\in\\R^{n\\times p}$ satisfying the Restricted Isometry Property\n(RIP) are an important ingredient of the compressive sensing methods. While it\nis known that random matrices satisfy the RIP with high probability even for\n$n=\\log^{O(1)}p$, the explicit construction of such matrices defied the\nrepeated efforts, and the most known approaches hit the so-called $\\sqrt{n}$\nsparsity bottleneck. The notable exception is the work by Bourgain et al\n\\cite{bourgain2011explicit} constructing an $n\\times p$ RIP matrix with\nsparsity $s=\\Theta(n^{{1\\over 2}+\\epsilon})$, but in the regime\n$n=\\Omega(p^{1-\\delta})$.\nIn this short note we resolve this open question in a sense by showing that\nan explicit construction of a matrix satisfying the RIP in the regime\n$n=O(\\log^2 p)$ and $s=\\Theta(n^{1\\over 2})$ implies an explicit construction\nof a three-colored Ramsey graph on $p$ nodes with clique sizes bounded by\n$O(\\log^2 p)$ -- a question in the extremal combinatorics which has been open\nfor decades.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Liveness Verification and Synthesis: New Algorithms for Recursive Programs.   We consider the problems of liveness verification and liveness synthesis for\nrecursive programs. The liveness verification problem (LVP) is to decide\nwhether a given omega-context-free language is contained in a given\nomega-regular language. The liveness synthesis problem (LSP) is to compute a\nstrategy so that a given omega-context-free game, when played along the\nstrategy, is guaranteed to derive a word in a given omega-regular language. The\nproblems are known to be EXPTIME-complete and EXPTIME-complete, respectively.\nOur contributions are new algorithms with optimal time complexity. For LVP, we\ngeneralize recent lasso-finding algorithms (also known as Ramsey-based\nalgorithms) from finite to recursive programs. For LSP, we generalize a recent\nsummary-based algorithm from finite to infinite words. Lasso finding and\nsummaries have proven to be efficient in a number of implementations for the\nfinite state and finite word setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A revision of the subtract-with-borrow random number generators.   The most popular and widely used subtract-with-borrow generator, also known\nas RANLUX, is reimplemented as a linear congruential generator using large\ninteger arithmetic with the modulus size of 576 bits. Modern computers, as well\nas the specific structure of the modulus inferred from RANLUX, allow for the\ndevelopment of a fast modular multiplication -- the core of the procedure. This\nwas previously believed to be slow and have too high cost in terms of computing\nresources. Our tests show a significant gain in generation speed which is\ncomparable with other fast, high quality random number generators. An\nadditional feature is the fast skipping of generator states leading to a\nseeding scheme which guarantees the uniqueness of random number sequences.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Wasserstein Learning of Deep Generative Point Process Models.   Point processes are becoming very popular in modeling asynchronous sequential\ndata due to their sound mathematical foundation and strength in modeling a\nvariety of real-world phenomena. Currently, they are often characterized via\nintensity function which limits model's expressiveness due to unrealistic\nassumptions on its parametric form used in practice. Furthermore, they are\nlearned via maximum likelihood approach which is prone to failure in\nmulti-modal distributions of sequences. In this paper, we propose an\nintensity-free approach for point processes modeling that transforms nuisance\nprocesses to a target one. Furthermore, we train the model using a\nlikelihood-free leveraging Wasserstein distance between point processes.\nExperiments on various synthetic and real-world data substantiate the\nsuperiority of the proposed point process model over conventional ones.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Preference Modeling by Exploiting Latent Components of Ratings.   Understanding user preference is essential to the optimization of recommender\nsystems. As a feedback of user's taste, rating scores can directly reflect the\npreference of a given user to a given product. Uncovering the latent components\nof user ratings is thus of significant importance for learning user interests.\nIn this paper, a new recommendation approach, called LCR, was proposed by\ninvestigating the latent components of user ratings. The basic idea is to\ndecompose an existing rating into several components via a cost-sensitive\nlearning strategy. Specifically, each rating is assigned to several latent\nfactor models and each model is updated according to its predictive errors.\nAfterwards, these accumulated predictive errors of models are utilized to\ndecompose a rating into several components, each of which is treated as an\nindependent part to retrain the latent factor models. Finally, all latent\nfactor models are combined linearly to estimate predictive ratings for users.\nIn contrast to existing methods, LCR provides an intuitive preference modeling\nstrategy via multiple component analysis at an individual perspective.\nMeanwhile, it is verified by the experimental results on several benchmark\ndatasets that the proposed method is superior to the state-of-art methods in\nterms of recommendation accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonvanishing of central $L$-values of Maass forms.   With the method of moments and the mollification method, we study the central\n$L$-values of GL(2) Maass forms of weight $0$ and level $1$ and establish a\npositive-proportional nonvanishing result of such values in the aspect of large\nspectral parameter in short intervals, which is qualitatively optimal in view\nof Weyl's law. As an application of this result and a formula of Katok--Sarnak,\nwe give a nonvanishing result on the first Fourier coefficients of Maass forms\nof weight $\\frac{1}{2}$ and level $4$ in the Kohnen plus space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A family of transformed copulas with singular component.   In this paper, we present a family of bivariate copulas by transforming a\ngiven copula function with two increasing functions, named as transformed\ncopula. One distinctive characteristic of the transformed copula is its\nsingular component along the main diagonal. Conditions guaranteeing the\ntransformed function to be a copula function are provided, and several classes\nof the transformed copulas are given. The singular component along the main\ndiagonal of the transformed copula is verified, and the tail dependence\ncoefficients of the transformed copulas are obtained. Finally, some properties\nof the transformed copula are discussed, such as the totally positive of order\n2 and the concordance order.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Is Life Most Likely Around Sun-like Stars?.   We consider the habitability of Earth-analogs around stars of different\nmasses, which is regulated by the stellar lifetime, stellar wind-induced\natmospheric erosion, and biologically active ultraviolet (UV) irradiance. By\nestimating the timescales associated with each of these processes, we show that\nthey collectively impose limits on the habitability of Earth-analogs. We\nconclude that planets orbiting most M-dwarfs are not likely to host life, and\nthat the highest probability of complex biospheres is for planets around K- and\nG-type stars. Our analysis suggests that the current existence of life near the\nSun is slightly unusual, but not significantly anomalous.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Rare-earth/transition-metal magnetic interactions in pristine and (Ni,Fe)-doped YCo5 and GdCo5.   We present an investigation into the intrinsic magnetic properties of the\ncompounds YCo5 and GdCo5, members of the RETM5 class of permanent magnets (RE =\nrare earth, TM = transition metal). Focusing on Y and Gd provides direct\ninsight into both the TM magnetization and RE-TM interactions without the\ncomplication of strong crystal field effects. We synthesize single crystals of\nYCo5 and GdCo5 using the optical floating zone technique and measure the\nmagnetization from liquid helium temperatures up to 800 K. These measurements\nare interpreted through calculations based on a Green's function formulation of\ndensity-functional theory, treating the thermal disorder of the local magnetic\nmoments within the coherent potential approximation. The rise in the\nmagnetization of GdCo5 with temperature is shown to arise from a faster\ndisordering of the Gd magnetic moments compared to the antiferromagnetically\naligned Co sublattice. We use the calculations to analyze the different Curie\ntemperatures of the compounds and also compare the molecular (Weiss) fields at\nthe RE site with previously published neutron scattering experiments. To gain\nfurther insight into the RE-TM interactions, we perform substitutional doping\non the TM site, studying the compounds RECo4.5Ni0.5, RECo4Ni, and RECo4.5Fe0.5.\nBoth our calculations and experiments on powdered samples find an\nincreased/decreased magnetization with Fe/Ni doping, respectively. The\ncalculations further reveal a pronounced dependence on the location of the\ndopant atoms of both the Curie temperatures and the Weiss field at the RE site.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Diversity of preferences can increase collective welfare in sequential exploration problems.   In search engines, online marketplaces and other human-computer interfaces\nlarge collectives of individuals sequentially interact with numerous\nalternatives of varying quality. In these contexts, trial and error\n(exploration) is crucial for uncovering novel high-quality items or solutions,\nbut entails a high cost for individual users. Self-interested decision makers,\nare often better off imitating the choices of individuals who have already\nincurred the costs of exploration. Although imitation makes sense at the\nindividual level, it deprives the group of additional information that could\nhave been gleaned by individual explorers. In this paper we show that in such\nproblems, preference diversity can function as a welfare enhancing mechanism.\nIt leads to a consistent increase in the quality of the consumed alternatives\nthat outweighs the increased cost of search for the users.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Differential quadrature method for space-fractional diffusion equations on 2D irregular domains.   In mathematical physics, the space-fractional diffusion equations are of\nparticular interest in the studies of physical phenomena modelled by Lévy\nprocesses, which are sometimes called super-diffusion equations. In this\narticle, we develop the differential quadrature (DQ) methods for solving the 2D\nspace-fractional diffusion equations on irregular domains. The methods in\npresence reduce the original equation into a set of ordinary differential\nequations (ODEs) by introducing valid DQ formulations to fractional directional\nderivatives based on the functional values at scattered nodal points on problem\ndomain. The required weighted coefficients are calculated by using radial basis\nfunctions (RBFs) as trial functions, and the resultant ODEs are discretized by\nthe Crank-Nicolson scheme. The main advantages of our methods lie in their\nflexibility and applicability to arbitrary domains. A series of illustrated\nexamples are finally provided to support these points.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "An Introduction to Classic DEVS.   DEVS is a popular formalism for modelling complex dynamic systems using a\ndiscrete-event abstraction. At this abstraction level, a timed sequence\nofpertinent \"events\" input to a system (or internal, in the case of timeouts)\ncause instantaneous changes to the state of the system. Between events, the\nstate does not change, resulting in a a piecewise constant state trajectory.\nMain advantages of DEVS are its rigorous formal definition, and its support for\nmodular composition.\nThis chapter introduces the Classic DEVS formalism in a bottom-up fashion,\nusing a simple traffic light example. The syntax and operational semantics of\nAtomic (i.e., non-hierarchical) models are intruced first. The semantics of\nCoupled (hierarchical) models is then given by translation into Atomic DEVS\nmodels. As this formal \"flattening\" is not efficient, a modular abstract\nsimulator which operates directly on the coupled model is also presented. This\nis the common basis for subsequent efficient implementations. We continue to\nactual applications of DEVS modelling and simulation, as seen in performance\nanalysis for queueing systems. Finally, we present some of the shortcomings in\nthe Classic DEVS formalism, and show solutions to them in the form of variants\nof the original formalism.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Fast Algorithm for Solving Henderson's Mixed Model Equation.   This article investigates a fast and stable method to solve Henderson's mixed\nmodel equation. The proposed algorithm is stable in that it avoids inverting a\nmatrix of a large dimension and hence is free from the curse of dimensionality.\nThis tactic is enabled through row operations performed on the design matrix.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning what matters - Sampling interesting patterns.   In the field of exploratory data mining, local structure in data can be\ndescribed by patterns and discovered by mining algorithms. Although many\nsolutions have been proposed to address the redundancy problems in pattern\nmining, most of them either provide succinct pattern sets or take the interests\nof the user into account-but not both. Consequently, the analyst has to invest\nsubstantial effort in identifying those patterns that are relevant to her\nspecific interests and goals. To address this problem, we propose a novel\napproach that combines pattern sampling with interactive data mining. In\nparticular, we introduce the LetSIP algorithm, which builds upon recent\nadvances in 1) weighted sampling in SAT and 2) learning to rank in interactive\npattern mining. Specifically, it exploits user feedback to directly learn the\nparameters of the sampling distribution that represents the user's interests.\nWe compare the performance of the proposed algorithm to the state-of-the-art in\ninteractive pattern mining by emulating the interests of a user. The resulting\nsystem allows efficient and interleaved learning and sampling, thus\nuser-specific anytime data exploration. Finally, LetSIP demonstrates favourable\ntrade-offs concerning both quality-diversity and exploitation-exploration when\ncompared to existing methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Arrow Categories of Monoidal Model Categories.   We prove that the arrow category of a monoidal model category, equipped with\nthe pushout product monoidal structure and the projective model structure, is a\nmonoidal model category. This answers a question posed by Mark Hovey, and has\nthe important consequence that it allows for the consideration of a monoidal\nproduct in cubical homotopy theory. As illustrations we include numerous\nexamples of non-cofibrantly generated monoidal model categories, including\nchain complexes, small categories, topological spaces, and pro-categories.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the number of integer polynomials with multiplicatively dependent roots.   In this paper, we give some counting results on integer polynomials of fixed\ndegree and bounded height whose distinct non-zero roots are multiplicatively\ndependent. These include sharp lower bounds, upper bounds and asymptotic\nformulas for various cases, although in general there is a logarithmic gap\nbetween lower and upper bounds.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tailoring Architecture Centric Design Method with Rapid Prototyping.   Many engineering processes exist in the industry, text books and\ninternational standards. However, in practice rarely any of the processes are\nfollowed consistently and literally. It is observed across industries the\nprocesses are altered based on the requirements of the projects. Two features\ncommonly lacking from many engineering processes are, 1) the formal capacity to\nrapidly develop prototypes in the rudimentary stage of the project, 2)\ntransitioning of requirements into architectural designs, when and how to\nevaluate designs and how to use the throw away prototypes throughout the system\nlifecycle. Prototypes are useful for eliciting requirements, generating\ncustomer feedback and identifying, examining or mitigating risks in a project\nwhere the product concept is at a cutting edge or not fully perceived. Apart\nfrom the work that the product is intended to do, systemic properties like\navailability, performance and modifiability matter as much as functionality.\nArchitects must even these concerns with the method they select to promote\nthese systemic properties and at the same time equip the stakeholders with the\ndesired functionality. Architectural design and prototyping is one of the key\nways to build the right product embedded with the desired systemic properties.\nOnce the product is built it can be almost impossible to retrofit the system\nwith the desired attributes. This paper customizes the architecture centric\ndevelopment method with rapid prototyping to achieve the above-mentioned goals\nand reducing the number of iterations across the stages of ACDM.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Integrated Fabry-Perot cavities as a mechanism for enhancing micro-ring resonator performance.   We propose and experimentally demonstrate the enhancement in the filtering\nquality (Q) factor of an integrated micro-ring resonator (MRR) by embedding it\nin an integrated Fabry-Perot (FP) cavity formed by cascaded Sagnac loop\nreflectors (SLRs). By utilizing coherent interference within the FP cavity to\nreshape the transmission spectrum of the MRR, both the Q factor and the\nextinction ratio (ER) can be significantly improved. The device is\ntheoretically analyzed, and practically fabricated on a silicon-on-insulator\n(SOI) wafer. Experimental results show that up to 11-times improvement in Q\nfactor, together with an 8-dB increase in ER, can be achieved via our proposed\nmethod. The impact of varying structural parameters on the device performance\nis also investigated and verified by the measured spectra of the fabricated\ndevices with different structural parameters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On architectural choices in deep learning: From network structure to gradient convergence and parameter estimation.   We study mechanisms to characterize how the asymptotic convergence of\nbackpropagation in deep architectures, in general, is related to the network\nstructure, and how it may be influenced by other design choices including\nactivation type, denoising and dropout rate. We seek to analyze whether network\narchitecture and input data statistics may guide the choices of learning\nparameters and vice versa. Given the broad applicability of deep architectures,\nthis issue is interesting both from theoretical and a practical standpoint.\nUsing properties of general nonconvex objectives (with first-order\ninformation), we first build the association between structural, distributional\nand learnability aspects of the network vis-à-vis their interaction with\nparameter convergence rates. We identify a nice relationship between feature\ndenoising and dropout, and construct families of networks that achieve the same\nlevel of convergence. We then derive a workflow that provides systematic\nguidance regarding the choice of network sizes and learning parameters often\nmediated4 by input statistics. Our technical results are corroborated by an\nextensive set of evaluations, presented in this paper as well as independent\nempirical observations reported by other groups. We also perform experiments\nshowing the practical implications of our framework for choosing the best\nfully-connected design for a given problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parameter Estimation in Finite Mixture Models by Regularized Optimal Transport: A Unified Framework for Hard and Soft Clustering.   In this short paper, we formulate parameter estimation for finite mixture\nmodels in the context of discrete optimal transportation with convex\nregularization. The proposed framework unifies hard and soft clustering methods\nfor general mixture models. It also generalizes the celebrated\n$k$\\nobreakdash-means and expectation-maximization algorithms in relation to\nassociated Bregman divergences when applied to exponential family mixture\nmodels.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using Inertial Sensors for Position and Orientation Estimation.   In recent years, MEMS inertial sensors (3D accelerometers and 3D gyroscopes)\nhave become widely available due to their small size and low cost. Inertial\nsensor measurements are obtained at high sampling rates and can be integrated\nto obtain position and orientation information. These estimates are accurate on\na short time scale, but suffer from integration drift over longer time scales.\nTo overcome this issue, inertial sensors are typically combined with additional\nsensors and models. In this tutorial we focus on the signal processing aspects\nof position and orientation estimation using inertial sensors. We discuss\ndifferent modeling choices and a selected number of important algorithms. The\nalgorithms include optimization-based smoothing and filtering as well as\ncomputationally cheaper extended Kalman filter and complementary filter\nimplementations. The quality of their estimates is illustrated using both\nexperimental and simulated data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Low-Latency Millimeter-Wave Communications: Traffic Dispersion or Network Densification?.   This paper investigates two strategies to reduce the communication delay in\nfuture wireless networks: traffic dispersion and network densification. A\nhybrid scheme that combines these two strategies is also considered. The\nprobabilistic delay and effective capacity are used to evaluate performance.\nFor probabilistic delay, the violation probability of delay, i.e., the\nprobability that the delay exceeds a given tolerance level, is characterized in\nterms of upper bounds, which are derived by applying stochastic network\ncalculus theory. In addition, to characterize the maximum affordable arrival\ntraffic for mmWave systems, the effective capacity, i.e., the service\ncapability with a given quality-of-service (QoS) requirement, is studied. The\nderived bounds on the probabilistic delay and effective capacity are validated\nthrough simulations. These numerical results show that, for a given average\nsystem gain, traffic dispersion, network densification, and the hybrid scheme\nexhibit different potentials to reduce the end-to-end communication delay. For\ninstance, traffic dispersion outperforms network densification, given high\naverage system gain and arrival rate, while it could be the worst option,\notherwise. Furthermore, it is revealed that, increasing the number of\nindependent paths and/or relay density is always beneficial, while the\nperformance gain is related to the arrival rate and average system gain,\njointly. Therefore, a proper transmission scheme should be selected to optimize\nthe delay performance, according to the given conditions on arrival traffic and\nsystem service capability.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Bohm's approach to quantum mechanics: Alternative theory or practical picture?.   Since its inception Bohmian mechanics has been generally regarded as a\nhidden-variable theory aimed at providing an objective description of quantum\nphenomena. To date, this rather narrow conception of Bohm's proposal has caused\nit more rejection than acceptance. Now, after 65 years of Bohmian mechanics,\nshould still be such an interpretational aspect the prevailing appraisal? Why\nnot favoring a more pragmatic view, as a legitimate picture of quantum\nmechanics, on equal footing in all respects with any other more conventional\nquantum picture? These questions are used here to introduce a discussion on an\nalternative way to deal with Bohmian mechanics at present, enhancing its aspect\nas an efficient and useful picture or formulation to tackle, explore, describe\nand explain quantum phenomena where phase and correlation (entanglement) are\nkey elements. This discussion is presented through two complementary blocks.\nThe first block is aimed at briefly revisiting the historical context that gave\nrise to the appearance of Bohmian mechanics, and how this approach or analogous\nones have been used in different physical contexts. This discussion is used to\nemphasize a more pragmatic view to the detriment of the more conventional\nhidden-variable (ontological) approach that has been a leitmotif within the\nquantum foundations. The second block focuses on some particular formal aspects\nof Bohmian mechanics supporting the view presented here, with special emphasis\non the physical meaning of the local phase field and the associated velocity\nfield encoded within the wave function. As an illustration, a simple model of\nYoung's two-slit experiment is considered. The simplicity of this model allows\nto understand in an easy manner how the information conveyed by the Bohmian\nformulation relates to other more conventional concepts in quantum mechanics.\nThis sort of pedagogical application is also aimed at ...",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Statistical Timing Analysis for Latch-Controlled Circuits with Reduced Iterations and Graph Transformations.   Level-sensitive latches are widely used in high- performance designs. For\nsuch circuits efficient statistical timing analysis algorithms are needed to\ntake increasing process vari- ations into account. But existing methods solving\nthis problem are still computationally expensive and can only provide the yield\nat a given clock period. In this paper we propose a method combining reduced\niterations and graph transformations. The reduced iterations extract setup time\nconstraints and identify a subgraph for the following graph transformations\nhandling the constraints from nonpositive loops. The combined algorithms are\nvery efficient, more than 10 times faster than other existing methods, and\nresult in a parametric minimum clock period, which together with the hold time\nconstraints can be used to compute the yield at any given clock period very\neasily.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Expressions of Sentiments During Code Reviews: Male vs. Female.   Background: As most of the software development organizations are\nmale-dominated, female developers encountering various negative workplace\nexperiences reported feeling like they \"do not belong\". Exposures to\ndiscriminatory expletives or negative critiques from their male colleagues may\nfurther exacerbate those feelings. Aims: The primary goal of this study is to\nidentify the differences in expressions of sentiments between male and female\ndevelopers during various software engineering tasks. Method: On this goal, we\nmined the code review repositories of six popular open source projects. We used\na semi-automated approach leveraging the name as well as multiple social\nnetworks to identify the gender of a developer. Using SentiSE, a customized and\nstate-of-the-art sentiment analysis tool for the software engineering domain,\nwe classify each communication as negative, positive, or neutral. We also\ncompute the frequencies of sentiment words, emoticons, and expletives used by\neach developer. Results: Our results suggest that the likelihood of using\nsentiment words, emoticons, and expletives during code reviews varies based on\nthe gender of a developer, as females are significantly less likely to express\nsentiments than males. Although female developers were more neutral to their\nmale colleagues than to another female, male developers from three out of the\nsix projects were not only writing more frequent negative comments but also\nwithholding positive encouragements from their female counterparts. Conclusion:\nOur results provide empirical evidence of another factor behind the negative\nwork place experiences encountered by the female developers that may be\ncontributing to the diminishing number of females in the SE industry.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spin diffusion from an inhomogeneous quench in an integrable system.   Generalised hydrodynamics predicts universal ballistic transport in\nintegrable lattice systems when prepared in generic inhomogeneous initial\nstates. However, the ballistic contribution to transport can vanish in systems\nwith additional discrete symmetries. Here we perform large scale numerical\nsimulations of spin dynamics in the anisotropic Heisenberg $XXZ$ spin $1/2$\nchain starting from an inhomogeneous mixed initial state which is symmetric\nwith respect to a combination of spin-reversal and spatial reflection. In the\nisotropic and easy-axis regimes we find non-ballistic spin transport which we\nanalyse in detail in terms of scaling exponents of the transported\nmagnetisation and scaling profiles of the spin density. While in the easy-axis\nregime we find accurate evidence of normal diffusion, the spin transport in the\nisotropic case is clearly super-diffusive, with the scaling exponent very close\nto $2/3$, but with universal scaling dynamics which obeys the diffusion\nequation in nonlinearly scaled time.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Optimal Stopping for Interval Estimation in Bernoulli Trials.   We propose an optimal sequential methodology for obtaining confidence\nintervals for a binomial proportion $\\theta$. Assuming that an i.i.d. random\nsequence of Benoulli($\\theta$) trials is observed sequentially, we are\ninterested in designing a)~a stopping time $T$ that will decide when is the\nbest time to stop sampling the process, and b)~an optimum estimator\n$\\hat{\\theta}_{T}$ that will provide the optimum center of the interval\nestimate of $\\theta$. We follow a semi-Bayesian approach, where we assume that\nthere exists a prior distribution for $\\theta$, and our goal is to minimize the\naverage number of samples while we guarantee a minimal coverage probability\nlevel. The solution is obtained by applying standard optimal stopping theory\nand computing the optimum pair $(T,\\hat{\\theta}_{T})$ numerically. Regarding\nthe optimum stopping time component $T$, we demonstrate that it enjoys certain\nvery uncommon characteristics not encountered in solutions of other classical\noptimal stopping problems. Finally, we compare our method with the optimum\nfixed-sample-size procedure but also with existing alternative sequential\nschemes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Smoothing for the fractional Schrodinger equation on the torus and the real line.   In this paper we study the cubic fractional nonlinear Schrodinger equation\n(NLS) on the torus and on the real line. Combining the normal form and the\nrestricted norm methods we prove that the nonlinear part of the solution is\nsmoother than the initial data. Our method applies to both focusing and\ndefocusing nonlinearities. In the case of full dispersion (NLS) and on the\ntorus, the gain is a full derivative, while on the real line we get a\nderivative smoothing with an $\\epsilon$ loss. Our result lowers the regularity\nrequirement of a recent theorem of Kappeler et al. on the periodic defocusing\ncubic NLS, and extends it to the focusing case and to the real line. We also\nobtain estimates on the higher order Sobolev norms of the global smooth\nsolutions in the defocusing case.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Stability and instability of the sub-extremal Reissner-Nordström black hole interior for the Einstein-Maxwell-Klein-Gordon equations in spherical symmetry.   We show non-linear stability and instability results in spherical symmetry\nfor the interior of a charged black hole -approaching a sub-extremal\nReissner-Nordström background fast enough at infinity- in presence of a\nmassive and charged scalar field, motivated by the strong cosmic censorship\nconjecture in that setting :\n1. Stability : We prove that spherically symmetric characteristic initial\ndata to the Einstein-Maxwell- Klein-Gordon equations approaching a\nReissner-Nordström background with a sufficiently decaying polynomial decay\nrate on the event horizon gives rise to a space-time possessing a Cauchy\nhorizon in a neighbourhood of time-like infinity. Moreover if the decay is even\nstronger, we prove that the spacetime metric admits a continuous extension to\nthe Cauchy horizon. This generalizes the celebrated stability result of\nDafermos for Einstein-Maxwell-real-scalar-field in spherical symmetry.\n2. Instability : We prove that for the class of space-times considered in the\nstability part, whose scalar field in addition obeys a polynomial averaged-L^2\n(consistent) lower bound on the event horizon, the scalar field obeys an\nintegrated lower bound transversally to the Cauchy horizon. As a consequence we\nprove that the non-degenerate energy is infinite on any null surface crossing\nthe Cauchy horizon and the curvature of a geodesic vector field blows up at the\nCauchy horizon near time-like infinity. This generalizes an instability result\ndue to Luk and Oh for Einstein-Maxwell-real-scalar-field in spherical symmetry.\nThis instability of the black hole interior can also be viewed as a step\ntowards the resolution of the C^2 strong cosmic censorship conjecture for\none-ended asymptotically initial data.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On the apparent permeability of porous media in rarefied gas flows.   The apparent gas permeability of the porous medium is an important parameter\nin the prediction of unconventional gas production, which was first\ninvestigated systematically by Klinkenberg in 1941 and found to increase with\nthe reciprocal mean gas pressure (or equivalently, the Knudsen number).\nAlthough the underlying rarefaction effects are well-known, the reason that the\ncorrection factor in Klinkenberg's famous equation decreases when the Knudsen\nnumber increases has not been fully understood. Most of the studies idealize\nthe porous medium as a bundle of straight cylindrical tubes, however, according\nto the gas kinetic theory, this only results in an increase of the correction\nfactor with the Knudsen number, which clearly contradicts Klinkenberg's\nexperimental observations. Here, by solving the Bhatnagar-Gross-Krook equation\nin simplified (but not simple) porous media, we identify, for the first time,\ntwo key factors that can explain Klinkenberg's experimental results: the\ntortuous flow path and the non-unitary tangential momentum accommodation\ncoefficient for the gas-surface interaction. Moreover, we find that\nKlinkenberg's results can only be observed when the ratio between the apparent\nand intrinsic permeabilities is $\\lesssim30$; at large ratios (or Knudsen\nnumbers) the correction factor increases with the Knudsen number. Our numerical\nresults could also serve as benchmarking cases to assess the accuracy of\nmacroscopic models and/or numerical schemes for the modeling/simulation of\nrarefied gas flows in complex geometries over a wide range of gas rarefaction.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "One level density of low-lying zeros of quadratic and quartic Hecke $L$-functions.   In this paper, we prove some one level density results for the low-lying\nzeros of famliies of quadratic and quartic Hecke $L$-functions of the Gaussian\nfield. As corollaries, we deduce that, respectively, at least $94.27 \\%$ and\n$5\\%$ of the members of the quadratic family and the quartic family do not\nvanish at the central point.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mapping the aberrations of a wide-field spectrograph using a photonic comb.   We demonstrate a new approach to calibrating the spectral-spatial response of\na wide-field spectrograph using a fibre etalon comb. Conventional wide-field\ninstruments employed on front-line telescopes are mapped with a grid of\ndiffraction-limited holes cut into a focal plane mask. The aberrated grid\npattern in the image plane typically reveals n-symmetric (e.g. pincushion)\ndistortion patterns over the field arising from the optical train. This\napproach is impractical in the presence of a dispersing element because the\ndiffraction-limited spots in the focal plane are imaged as an array of\noverlapping spectra. Instead we propose a compact solution that builds on\nrecent developments in fibre-based Fabry-Perot etalons. We introduce a novel\napproach to near-field illumination that exploits a 25cm commercial telescope\nand the propagation of skew rays in a multimode fibre. The mapping of the\noptical transfer function across the full field is represented accurately\n(<0.5% rms residual) by an orthonormal set of Chebyshev moments. Thus we are\nable to reconstruct the full 4Kx4K CCD image of the dispersed output from the\noptical fibres using this mapping, as we demonstrate. Our method removes one of\nthe largest sources of systematic error in multi-object spectroscopy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Conditional Model Selection in Mixed-Effects Models with cAIC4.   Model selection in mixed models based on the conditional distribution is\nappropriate for many practical applications and has been a focus of recent\nstatistical research. In this paper we introduce the R-package cAIC4 that\nallows for the computation of the conditional Akaike Information Criterion\n(cAIC). Computation of the conditional AIC needs to take into account the\nuncertainty of the random effects variance and is therefore not\nstraightforward. We introduce a fast and stable implementation for the\ncalculation of the cAIC for linear mixed models estimated with lme4 and\nadditive mixed models estimated with gamm4 . Furthermore, cAIC4 offers a\nstepwise function that allows for a fully automated stepwise selection scheme\nfor mixed models based on the conditional AIC. Examples of many possible\napplications are presented to illustrate the practical impact and easy handling\nof the package.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Throughput Optimal Beam Alignment in Millimeter Wave Networks.   Millimeter wave communications rely on narrow-beam transmissions to cope with\nthe strong signal attenuation at these frequencies, thus demanding precise beam\nalignment between transmitter and receiver. The communication overhead incurred\nto achieve beam alignment may become a severe impairment in mobile networks.\nThis paper addresses the problem of optimizing beam alignment acquisition, with\nthe goal of maximizing throughput. Specifically, the algorithm jointly\ndetermines the portion of time devoted to beam alignment acquisition, as well\nas, within this portion of time, the optimal beam search parameters, using the\nframework of Markov decision processes. It is proved that a bisection search\nalgorithm is optimal, and that it outperforms exhaustive and iterative search\nalgorithms proposed in the literature. The duration of the beam alignment phase\nis optimized so as to maximize the overall throughput. The numerical results\nshow that the throughput, optimized with respect to the duration of the beam\nalignment phase, achievable under the exhaustive algorithm is 88.3% lower than\nthat achievable under the bisection algorithm. Similarly, the throughput\nachievable by the iterative search algorithm for a division factor of 4 and 8\nis, respectively, 12.8% and 36.4% lower than that achievable by the bisection\nalgorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Functional Gradient Path Planning in Occupancy Maps.   Planning safe paths is a major building block in robot autonomy. It has been\nan active field of research for several decades, with a plethora of planning\nmethods. Planners can be generally categorised as either trajectory optimisers\nor sampling-based planners. The latter is the predominant planning paradigm for\noccupancy maps. Trajectory optimisation entails major algorithmic changes to\ntackle contextual information gaps caused by incomplete sensor coverage of the\nmap. However, the benefits are substantial, as trajectory optimisers can reason\non the trade-off between path safety and efficiency.\nIn this work, we improve our previous work on stochastic functional gradient\nplanners. We introduce a novel expressive path representation based on kernel\napproximation, that allows cost effective model updates based on stochastic\nsamples. The main drawback of the previous stochastic functional gradient\nplanner was the cubic cost, stemming from its non-parametric path\nrepresentation. Our novel approximate kernel based model, on the other hand,\nhas a fixed linear cost that depends solely on the number of features used to\nrepresent the path. We show that the stochasticity of the samples is crucial\nfor the planner and present comparisons to other state-of-the-art planning\nmethods in both simulation and with real occupancy data. The experiments\ndemonstrate the advantages of the stochastic approximate kernel method for path\nplanning in occupancy maps.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Time Hierarchy Theorem for the LOCAL Model.   The celebrated Time Hierarchy Theorem for Turing machines states, informally,\nthat more problems can be solved given more time. The extent to which a time\nhierarchy-type theorem holds in the distributed LOCAL model has been open for\nmany years. It is consistent with previous results that all natural problems in\nthe LOCAL model can be classified according to a small constant number of\ncomplexities, such as $O(1),O(\\log^* n), O(\\log n), 2^{O(\\sqrt{\\log n})}$, etc.\nIn this paper we establish the first time hierarchy theorem for the LOCAL\nmodel and prove that several gaps exist in the LOCAL time hierarchy.\n1. We define an infinite set of simple coloring problems called Hierarchical\n$2\\frac{1}{2}$-Coloring}. A correctly colored graph can be confirmed by simply\nchecking the neighborhood of each vertex, so this problem fits into the class\nof locally checkable labeling (LCL) problems. However, the complexity of the\n$k$-level Hierarchical $2\\frac{1}{2}$-Coloring problem is $\\Theta(n^{1/k})$,\nfor $k\\in\\mathbb{Z}^+$. The upper and lower bounds hold for both general graphs\nand trees, and for both randomized and deterministic algorithms.\n2. Consider any LCL problem on bounded degree trees. We prove an\nautomatic-speedup theorem that states that any randomized $n^{o(1)}$-time\nalgorithm solving the LCL can be transformed into a deterministic $O(\\log\nn)$-time algorithm. Together with a previous result, this establishes that on\ntrees, there are no natural deterministic complexities in the ranges\n$\\omega(\\log^* n)$---$o(\\log n)$ or $\\omega(\\log n)$---$n^{o(1)}$.\n3. We expose a gap in the randomized time hierarchy on general graphs. Any\nrandomized algorithm that solves an LCL problem in sublogarithmic time can be\nsped up to run in $O(T_{LLL})$ time, which is the complexity of the distributed\nLovasz local lemma problem, currently known to be $\\Omega(\\log\\log n)$ and\n$O(\\log n)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Functoriality and uniformity in Hrushovski's groupoid-cover correspondence.   The correspondence between definable connected groupoids in a theory $T$ and\ninternal generalised imaginary sorts of $T$, established by Hrushovski in\n[\"Groupoids, imaginaries and internal covers,\" Turkish Journal of Mathematics,\n2012], is here extended in two ways: First, it is shown that the correspondence\nis in fact an equivalence of categories, with respect to appropriate notions of\nmorphism. Secondly, the equivalence of categories is shown to vary uniformly in\ndefinable families, with respect to an appropriate relativisation of these\ncategories. Some elaboration on Hrushovki's original constructions are also\nincluded.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Camera Calibration by Global Constraints on the Motion of Silhouettes.   We address the problem of epipolar geometry using the motion of silhouettes.\nSuch methods match epipolar lines or frontier points across views, which are\nthen used as the set of putative correspondences. We introduce an approach that\nimproves by two orders of magnitude the performance over state-of-the-art\nmethods, by significantly reducing the number of outliers in the putative\nmatching. We model the frontier points' correspondence problem as constrained\nflow optimization, requiring small differences between their coordinates over\nconsecutive frames. Our approach is formulated as a Linear Integer Program and\nwe show that due to the nature of our problem, it can be solved efficiently in\nan iterative manner. Our method was validated on four standard datasets\nproviding accurate calibrations across very different viewpoints.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Essential Dimension of Generic Symbols in Characteristic p.   In this article the $p$-essential dimension of generic symbols over fields of\ncharacteristic $p$ is studied. In particular, the $p$-essential dimension of\nthe length $\\ell$ generic $p$-symbol of degree $n+1$ is bounded below by\n$n+\\ell$ when the base field is algebraically closed of characteristic $p$. The\nproof uses new techniques for working with residues in Milne-Kato\n$p$-cohomology and builds on work of Babic and Chernousov in the Witt group in\ncharacteristic 2. Two corollaries on $p$-symbol algebras (i.e, degree 2\nsymbols) result from this work. The generic $p$-symbol algebra of length $\\ell$\nis shown to have $p$-essential dimension equal to $\\ell+1$ as a $p$-torsion\nBrauer class. The second is a lower bound of $\\ell+1$ on the $p$-essential\ndimension of the functor $\\mathrm{Alg}_{p^\\ell,p}$. Roughly speaking this says\nthat you will need at least $\\ell+1$ independent parameters to be able to\nspecify any given algebra of degree $p^{\\ell}$ and exponent $p$ over a field of\ncharacteristic $p$ and improves on the previously established lower bound of 3.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Graph Model with Indirect Co-location Links.   Graph models are widely used to analyse diffusion processes embedded in\nsocial contacts and to develop applications. A range of graph models are\navailable to replicate the underlying social structures and dynamics\nrealistically. However, most of the current graph models can only consider\nconcurrent interactions among individuals in the co-located interaction\nnetworks. However, they do not account for indirect interactions that can\ntransmit spreading items to individuals who visit the same locations at\ndifferent times but within a certain time limit. The diffusion phenomena\noccurring through direct and indirect interactions is called same place\ndifferent time (SPDT) diffusion. This paper introduces a model to synthesize\nco-located interaction graphs capturing both direct interactions, where\nindividuals meet at a location, and indirect interactions, where individuals\nvisit the same location at different times within a set timeframe. We analyze\n60 million location updates made by 2 million users from a social networking\napplication to characterize the graph properties, including the space-time\ncorrelations and its time evolving characteristics, such as bursty or ongoing\nbehaviors. The generated synthetic graph reproduces diffusion dynamics of a\nrealistic contact graph, and reduces the prediction error by up to 82% when\ncompare to other contact graph models demonstrating its potential for\nforecasting epidemic spread.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On conditional parity as a notion of non-discrimination in machine learning.   We identify conditional parity as a general notion of non-discrimination in\nmachine learning. In fact, several recently proposed notions of\nnon-discrimination, including a few counterfactual notions, are instances of\nconditional parity. We show that conditional parity is amenable to statistical\nanalysis by studying randomization as a general mechanism for achieving\nconditional parity and a kernel-based test of conditional parity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Introduction to compact and discrete quantum groups.   These are notes from introductory lectures at the graduate school\n\"Topological Quantum Groups\" in Będlewo (June 28--July 11, 2015). The notes\npresent the passage from Hopf algebras to compact quantum groups and sketch the\nnotion of discrete quantum groups viewed as duals of compact quantum groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Cross-Correlation Redshift Calibration Without Spectroscopic Calibration Samples in DES Science Verification Data.   Galaxy cross-correlations with high-fidelity redshift samples hold the\npotential to precisely calibrate systematic photometric redshift uncertainties\narising from the unavailability of complete and representative training and\nvalidation samples of galaxies. However, application of this technique in the\nDark Energy Survey (DES) is hampered by the relatively low number density,\nsmall area, and modest redshift overlap between photometric and spectroscopic\nsamples. We propose instead using photometric catalogs with reliable\nphotometric redshifts for photo-z calibration via cross-correlations. We verify\nthe viability of our proposal using redMaPPer clusters from the Sloan Digital\nSky Survey (SDSS) to successfully recover the redshift distribution of SDSS\nspectroscopic galaxies. We demonstrate how to combine photo-z with\ncross-correlation data to calibrate photometric redshift biases while\nmarginalizing over possible clustering bias evolution in either the calibration\nor unknown photometric samples. We apply our method to DES Science Verification\n(DES SV) data in order to constrain the photometric redshift distribution of a\ngalaxy sample selected for weak lensing studies, constraining the mean of the\ntomographic redshift distributions to a statistical uncertainty of $\\Delta z\n\\sim \\pm 0.01$. We forecast that our proposal can in principle control\nphotometric redshift uncertainties in DES weak lensing experiments at a level\nnear the intrinsic statistical noise of the experiment over the range of\nredshifts where redMaPPer clusters are available. Our results provide strong\nmotivation to launch a program to fully characterize the systematic errors from\nbias evolution and photo-z shapes in our calibration procedure.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Weighted estimates for positive operators and Doob maximal operators on filtered measure spaces.   We characterize strong type and weak type inequalities with two weights for\npositive operators on filtered measure spaces. These estimates are\nprobabilistic analogues of two-weight inequalities for positive operators\nassociated to the dyadic cubes in $\\mathbb R^n$ due to Lacey, Sawyer and\nUriarte-Tuero \\cite{LaSaUr}. Several mixed bounds for the Doob maximal operator\non filtered measure spaces are also obtained. In fact, Hytönen-Pérez\ntype and Lerner-Moen type norm estimates for Doob maximal operator are\nestablished. Our approaches are mainly based on the construction of principal\nsets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stacking and stability.   Stacking is a general approach for combining multiple models toward greater\npredictive accuracy. It has found various application across different domains,\nensuing from its meta-learning nature. Our understanding, nevertheless, on how\nand why stacking works remains intuitive and lacking in theoretical insight. In\nthis paper, we use the stability of learning algorithms as an elemental\nanalysis framework suitable for addressing the issue. To this end, we analyze\nthe hypothesis stability of stacking, bag-stacking, and dag-stacking and\nestablish a connection between bag-stacking and weighted bagging. We show that\nthe hypothesis stability of stacking is a product of the hypothesis stability\nof each of the base models and the combiner. Moreover, in bag-stacking and\ndag-stacking, the hypothesis stability depends on the sampling strategy used to\ngenerate the training set replicates. Our findings suggest that 1) subsampling\nand bootstrap sampling improve the stability of stacking, and 2) stacking\nimproves the stability of both subbagging and bagging.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Clinical and Finite Elements Study of Stress Urinary Incontinence in Women Using Fluid-Structure Interactions.   Stress Urinary Incontinence (SUI) or urine leakage from urethra occurs due to\nan increase in abdominal pressure resulting from stress like a cough or jumping\nheight. SUI is more frequent among post-menopausal women. In the absence of\nbladder contraction, vesical pressure exceeds from urethral pressure leading to\nurine leakage. Despite a large number of patients diagnosed with this problem,\nfew studies have investigated its function and mechanics. The main goal of this\nstudy is to model bladder and urethra computationally under an external\npressure like sneezing. Finite Element Method and Fluid-Structure Interactions\nare utilized for simulation. Linear mechanical properties assigned to the\nbladder and urethra and pressure boundary conditions are indispensable in this\nmodel. The results show good accordance between the clinical data and predicted\nvalues of the computational models, such as the pressure at the center of the\nbladder. This indicates that numerical methods and simplified physics of\nbiological systems like inferior urinary tract are helpful to achieve the\nresults similar to clinical results, in order to investigate pathological\nconditions.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Field-induced coexistence of $s_{++}$ and $s_{\\pm}$ superconducting states in dirty multiband superconductors.   In multiband systems, such as iron-based superconductors, the superconducting\nstates with locking and anti-locking of the interband phase differences, are\nusually considered as mutually exclusive. For example, a dirty two-band system\nwith interband impurity scattering undergoes a sharp crossover between the\n$s_{\\pm}$ state (which favors phase anti locking) and the $s_{++}$ state (which\nfavors phase locking). We discuss here that the situation can be much more\ncomplex in the presence of an external field or superconducting currents. In an\nexternal applied magnetic field, dirty two-band superconductors do not feature\na sharp $s_{\\pm}\\to s_{++}$ crossover but rather a washed-out crossover to a\nfinite region in the parameter space where both $s_{\\pm}$ and $s_{++}$ states\ncan coexist for example as a lattice or a microemulsion of inclusions of\ndifferent states. The current-carrying regions such as the regions near vortex\ncores can exhibit an $s_\\pm$ state while it is the $s_{++}$ state that is\nfavored in the bulk. This coexistence of both states can even be realized in\nthe Meissner state at the domain's boundaries featuring Meissner currents. We\ndemonstrate that there is a magnetic-field-driven crossover between the pure\n$s_{\\pm}$ and the $s_{++}$ states.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Iteratively Linearized Reweighted Alternating Direction Method of Multipliers for a Class of Nonconvex Problems.   In this paper, we consider solving a class of nonconvex and nonsmooth\nproblems frequently appearing in signal processing and machine learning\nresearch. The traditional alternating direction method of multipliers\nencounters troubles in both mathematics and computations in solving the\nnonconvex and nonsmooth subproblem. In view of this, we propose a reweighted\nalternating direction method of multipliers. In this algorithm, all subproblems\nare convex and easy to solve. We also provide several guarantees for the\nconvergence and prove that the algorithm globally converges to a critical point\nof an auxiliary function with the help of the Kurdyka-{\\L}ojasiewicz property.\nSeveral numerical results are presented to demonstrate the efficiency of the\nproposed algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stability and Transparency Analysis of a Bilateral Teleoperation in Presence of Data Loss.   This paper presents a novel approach for stability and transparency analysis\nfor bilateral teleoperation in the presence of data loss in communication\nmedia. A new model for data loss is proposed based on a set of periodic\ncontinuous pulses and its finite series representation. The passivity of the\noverall system is shown using wave variable approach including the newly\ndefined model for data loss. Simulation results are presented to show the\neffectiveness of the proposed approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "From Pragmatic to Systematic Software Process Improvement: An Evaluated Approach.   Software processes improvement (SPI) is a challenging task, as many different\nstakeholders, project settings, and contexts and goals need to be considered.\nSPI projects are often operated in a complex and volatile environment and,\nthus, require a sound management that is resource-intensive requiring many\nstakeholders to contribute to the process assessment, analysis, design,\nrealisation, and deployment. Although there exist many valuable SPI approaches,\nnone address the needs of both process engineers and project managers. This\narticle presents an Artefact-based Software Process Improvement & Management\napproach (ArSPI) that closes this gap. ArSPI was developed and tested across\nseveral SPI projects in large organisations in Germany and Eastern Europe. The\napproach further encompasses a template for initiating, performing, and\nmanaging SPI projects by defining a set of 5 key artefacts and 24 support\nartefacts. We present ArSPI and discus results of its validation indicating\nArSPI to be a helpful instrument to set up and steer SPI projects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymmetry-Induced Synchronization in Oscillator Networks.   A scenario has recently been reported in which in order to stabilize complete\nsynchronization of an oscillator network---a symmetric state---the symmetry of\nthe system itself has to be broken by making the oscillators nonidentical. But\nhow often does such behavior---which we term asymmetry-induced synchronization\n(AISync)---occur in oscillator networks? Here we present the first general\nscheme for constructing AISync systems and demonstrate that this behavior is\nthe norm rather than the exception in a wide class of physical systems that can\nbe seen as multilayer networks. Since a symmetric network in complete synchrony\nis the basic building block of cluster synchronization in more general\nnetworks, AISync should be common also in facilitating cluster synchronization\nby breaking the symmetry of the cluster subnetworks.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On spectral properties of high-dimensional spatial-sign covariance matrices in elliptical distributions with applications.   Spatial-sign covariance matrix (SSCM) is an important substitute of sample\ncovariance matrix (SCM) in robust statistics. This paper investigates the SSCM\non its asymptotic spectral behaviors under high-dimensional elliptical\npopulations, where both the dimension $p$ of observations and the sample size\n$n$ tend to infinity with their ratio $p/n\\to c\\in (0, \\infty)$. The empirical\nspectral distribution of this nonparametric scatter matrix is shown to converge\nin distribution to a generalized Marčenko-Pastur law. Beyond this, a new\ncentral limit theorem (CLT) for general linear spectral statistics of the SSCM\nis also established. For polynomial spectral statistics, explicit formulae of\nthe limiting mean and covarance functions in the CLT are provided. The derived\nresults are then applied to an estimation procedure and a test procedure for\nthe spectrum of the shape component of population covariance matrices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fully Optical Spacecraft Communications: Implementing an Omnidirectional PV-Cell Receiver and 8Mb/s LED Visible Light Downlink with Deep Learning Error Correction.   Free space optical communication techniques have been the subject of numerous\ninvestigations in recent years, with multiple missions expected to fly in the\nnear future. Existing methods require high pointing accuracies, drastically\ndriving up overall system cost. Recent developments in LED-based visible light\ncommunication (VLC) and past in-orbit experiments have convinced us that the\ntechnology has reached a critical level of maturity. On these premises, we\npropose a new optical communication system utilizing a VLC downlink and a high\nthroughput, omnidirectional photovoltaic cell receiver system. By performing\nerror-correction via deep learning methods and by utilizing phase-delay\ninterference, the system is able to deliver data rates that match those of\ntraditional laser-based solutions. A prototype of the proposed system has been\nconstructed, demonstrating the scheme to be a feasible alternative to\nlaser-based methods. This creates an opportunity for the full scale development\nof optical communication techniques on small spacecraft as a backup telemetry\nbeacon or as a high throughput link.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Simply Exponential Approximation of the Permanent of Positive Semidefinite Matrices.   We design a deterministic polynomial time $c^n$ approximation algorithm for\nthe permanent of positive semidefinite matrices where $c=e^{\\gamma+1}\\simeq\n4.84$. We write a natural convex relaxation and show that its optimum solution\ngives a $c^n$ approximation of the permanent. We further show that this factor\nis asymptotically tight by constructing a family of positive semidefinite\nmatrices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "End-to-end Lung Nodule Detection in Computed Tomography.   Computer aided diagnostic (CAD) system is crucial for modern med-ical\nimaging. But almost all CAD systems operate on reconstructed images, which were\noptimized for radiologists. Computer vision can capture features that is subtle\nto human observers, so it is desirable to design a CAD system op-erating on the\nraw data. In this paper, we proposed a deep-neural-network-based detection\nsystem for lung nodule detection in computed tomography (CT). A\nprimal-dual-type deep reconstruction network was applied first to convert the\nraw data to the image space, followed by a 3-dimensional convolutional neural\nnetwork (3D-CNN) for the nodule detection. For efficient network training, the\ndeep reconstruction network and the CNN detector was trained sequentially\nfirst, then followed by one epoch of end-to-end fine tuning. The method was\nevaluated on the Lung Image Database Consortium image collection (LIDC-IDRI)\nwith simulated forward projections. With 144 multi-slice fanbeam pro-jections,\nthe proposed end-to-end detector could achieve comparable sensitivity with the\nreference detector, which was trained and applied on the fully-sampled image\ndata. It also demonstrated superior detection performance compared to detectors\ntrained on the reconstructed images. The proposed method is general and could\nbe expanded to most detection tasks in medical imaging.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On slowly rotating axisymmetric solutions of the Einstein-Euler equations.   In recent works we have constructed axisymmetric solutions to the\nEuler-Poisson equations which give mathematical models of slowly uniformly\nrotating gaseous stars. We try to extend this result to the study of solutions\nof the Einstein-Euler equations in the framework of the general theory of\nrelativity. Although many interesting studies have been done about axisymmetric\nmetric in the general theory of relativity, they are restricted to the region\nof the vacuum. Mathematically rigorous existence theorem of the axisymmetric\ninterior solutions of the stationary metric corresponding to the\nenergy-momentum tensor of the perfect fluid with non-zero pressure may be not\nyet established until now except only one found in the pioneering work by U.\nHeilig done in 1993. In this article, along a different approach to that of\nHeilig's work, axisymmetric stationary solutions of the Einstein-Euler\nequations are constructed near those of the Euler-Poisson equations when the\nspeed of light is sufficiently large in the considered system of units, or,\nwhen the gravitational field is sufficiently weak.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Alternate Estimation of a Classifier and the Class-Prior from Positive and Unlabeled Data.   We consider a problem of learning a binary classifier only from positive data\nand unlabeled data (PU learning) and estimating the class-prior in unlabeled\ndata under the case-control scenario. Most of the recent methods of PU learning\nrequire an estimate of the class-prior probability in unlabeled data, and it is\nestimated in advance with another method. However, such a two-step approach\nwhich first estimates the class prior and then trains a classifier may not be\nthe optimal approach since the estimation error of the class-prior is not taken\ninto account when a classifier is trained. In this paper, we propose a novel\nunified approach to estimating the class-prior and training a classifier\nalternately. Our proposed method is simple to implement and computationally\nefficient. Through experiments, we demonstrate the practical usefulness of the\nproposed method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sensitivity Analysis for matched pair analysis of binary data: From worst case to average case analysis.   In matched observational studies where treatment assignment is not\nrandomized, sensitivity analysis helps investigators determine how sensitive\ntheir estimated treatment effect is to some unmeasured con- founder. The\nstandard approach calibrates the sensitivity analysis according to the worst\ncase bias in a pair. This approach will result in a conservative sensitivity\nanalysis if the worst case bias does not hold in every pair. In this paper, we\nshow that for binary data, the standard approach can be calibrated in terms of\nthe average bias in a pair rather than worst case bias. When the worst case\nbias and average bias differ, the average bias interpretation results in a less\nconservative sensitivity analysis and more power. In many studies, the average\ncase calibration may also carry a more natural interpretation than the worst\ncase calibration and may also allow researchers to incorporate additional data\nto establish an empirical basis with which to calibrate a sensitivity analysis.\nWe illustrate this with a study of the effects of cellphone use on the\nincidence of automobile accidents. Finally, we extend the average case\ncalibration to the sensitivity analysis of confidence intervals for\nattributable effects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Landau-Ginzburg theory of cortex dynamics: Scale-free avalanches emerge at the edge of synchronization.   Understanding the origin, nature, and functional significance of complex\npatterns of neural activity, as recorded by diverse electrophysiological and\nneuroimaging techniques, is a central challenge in neuroscience. Such patterns\ninclude collective oscillations emerging out of neural synchronization as well\nas highly heterogeneous outbursts of activity interspersed by periods of\nquiescence, called \"neuronal avalanches.\" Much debate has been generated about\nthe possible scale invariance or criticality of such avalanches and its\nrelevance for brain function. Aimed at shedding light onto this, here we\nanalyze the large-scale collective properties of the cortex by using a\nmesoscopic approach following the principle of parsimony of Landau-Ginzburg.\nOur model is similar to that of Wilson-Cowan for neural dynamics but crucially,\nincludes stochasticity and space; synaptic plasticity and inhibition are\nconsidered as possible regulatory mechanisms. Detailed analyses uncover a phase\ndiagram including down-state, synchronous, asynchronous, and up-state phases\nand reveal that empirical findings for neuronal avalanches are consistently\nreproduced by tuning our model to the edge of synchronization. This reveals\nthat the putative criticality of cortical dynamics does not correspond to a\nquiescent-to-active phase transition as usually assumed in theoretical\napproaches but to a synchronization phase transition, at which incipient\noscillations and scale-free avalanches coexist. Furthermore, our model also\naccounts for up and down states as they occur (e.g., during deep sleep). This\napproach constitutes a framework to rationalize the possible collective phases\nand phase transitions of cortical networks in simple terms, thus helping to\nshed light on basic aspects of brain functioning from a very broad perspective.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A Polynomial Time Match Test for Large Classes of Extended Regular Expressions.   In the present paper, we study the match test for extended regular\nexpressions. We approach this NP-complete problem by introducing a novel\nvariant of two-way multihead automata, which reveals that the complexity of the\nmatch test is determined by a hidden combinatorial property of extended regular\nexpressions, and it shows that a restriction of the corresponding parameter\nleads to rich classes with a polynomial time match test. For presentational\nreasons, we use the concept of pattern languages in order to specify extended\nregular expressions. While this decision, formally, slightly narrows the scope\nof our results, an extension of our concepts and results to more general\nnotions of extended regular expressions is straightforward.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Off The Beaten Lane: AI Challenges In MOBAs Beyond Player Control.   MOBAs represent a huge segment of online gaming and are growing as both an\neSport and a casual genre. The natural starting point for AI researchers\ninterested in MOBAs is to develop an AI to play the game better than a human -\nbut MOBAs have many more challenges besides adversarial AI. In this paper we\nintroduce the reader to the wider context of MOBA culture, propose a range of\nchallenges faced by the community today, and posit concrete AI projects that\ncan be undertaken to begin solving them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum Teleportation and Super-dense Coding in Operator Algebras.   Let $\\mathcal{B}_d$ be the unital $C^*$-algebra generated by the elements\n$u_{jk}, \\, 0 \\le i, j \\le d-1$, satisfying the relations that $[u_{j,k}]$ is a\nunitary operator, and let $C^*(\\mathbb{F}_{d^2})$ be the full group\n$C^*$-algebra of free group of $d^2$ generators. Based on the idea of\nteleportation and super-dense coding in quantum information theory, we exhibit\nthe two $*$-isomorphisms $M_d(C^*(\\mathbb{F}_{d^2}))\\cong \\mathcal{B}_d\\rtimes\n\\mathbb{Z}_d\\rtimes \\mathbb{Z}_d$ and $M_d(\\mathcal{B}_d)\\cong\nC^*(\\mathbb{F}_{d^2})\\rtimes \\mathbb{Z}_d\\rtimes \\mathbb{Z}_d$, for certain\nactions of $\\mathbb{Z}_d$. As an application, we show that for any $d,m\\ge 2$\nwith $(d,m)\\neq (2,2)$, the matrix-valued generalization of the (tensor\nproduct) quantum correlation set of $d$ inputs and $m$ outputs is not closed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Correlating the nanostructure of Al-oxide with deposition conditions and dielectric contributions of two-level systems in perspective of superconducting quantum circuits.   This work is concerned with Al/Al-oxide(AlO$_{x}$)/Al-layer systems which are\nimportant for Josephson-junction-based superconducting devices such as quantum\nbits. The device performance is limited by noise, which has been to a large\ndegree assigned to the presence and properties of two-level tunneling systems\nin the amorphous AlO$_{x}$ tunnel barrier. The study is focused on the\ncorrelation of the fabrication conditions, nanostructural and nanochemical\nproperties and the occurrence of two-level tunneling systems with particular\nemphasis on the AlO$_{x}$-layer. Electron-beam evaporation with two different\nprocesses and sputter deposition were used for structure fabrication, and the\neffect of illumination by ultraviolet light during Al-oxide formation is\nelucidated. Characterization was performed by analytical transmission electron\nmicroscopy and low-temperature dielectric measurements. We show that the\nfabrication conditions have a strong impact on the nanostructural and\nnanochemical properties of the layer systems and the properties of two-level\ntunneling systems. Based on the understanding of the observed structural\ncharacteristics, routes are derived towards the fabrication of\nAl/AlO$_{x}$/Al-layers systems with improved properties.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Steady Galactic Dynamos and Observational Consequences I: Halo Magnetic Fields.   We study the global consequences in the halos of spiral galaxies of the\nsteady, axially symmetric, mean field dynamo. We use the classical theory but\nadd the possibility of using the velocity field components as parameters in\naddition to the helicity and diffusivity. The analysis is based on the simplest\nversion of the theory and uses scale-invariant solutions. The velocity field\n(subject to restrictions) is a scale invariant field in a `pattern' frame, in\nplace of a full dynamical theory. The `pattern frame' of reference may either\nbe the systemic frame or some rigidly rotating spiral pattern frame. One type\nof solution for the magnetic field yields off-axis, spirally wound, magnetic\nfield lines. These predict sign changes in the Faraday screen rotation measure\nin every quadrant of the halo of an edge-on galaxy. Such rotation measure\noscillations have been observed in the CHANG-ES survey.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Efficient Propagation of Uncertainties in Manufacturing Supply Chains: Time Buckets, L-leap and Multilevel Monte Carlo.   Uncertainty propagation of large scale discrete supply chains can be\nprohibitive when a large number of events occur during the simulated period and\ndiscrete event simulations (DES) are costly. We present a time bucket method to\napproximate and accelerate the DES of supply chains. Its stochastic version,\nwhich we call the L(logistic)-leap method, can be viewed as an extension of the\nleap methods, e.g., tau-leap, D-leap, developed in the chemical engineering\ncommunity for the acceleration of stochastic DES of chemical reactions. The\nL-leap method instantaneously updates the system state vector at discrete time\npoints and the production rates and policies of a supply chain are assumed to\nbe stationary during each time bucket. We propose to use Multilevel Monte Carlo\n(MLMC) to efficiently propagate the uncertainties in a supply chain network,\nwhere the levels are naturally defined by the sizes of the time buckets of the\nsimulations. We demonstrate the efficiency and accuracy of our methods using\nfour numerical examples derived from a real world manufacturing material flow.\nIn these examples, our multilevel L-leap approach can be faster than the\nstandard Monte Carlo (MC) method by one or two orders of magnitudes without\ncompromising the accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spatially Adaptive Colocalization Analysis in Dual-Color Fluorescence Microscopy.   Colocalization analysis aims to study complex spatial associations between\nbio-molecules via optical imaging techniques. However, existing colocalization\nanalysis workflows only assess an average degree of colocalization within a\ncertain region of interest and ignore the unique and valuable spatial\ninformation offered by microscopy. In the current work, we introduce a new\nframework for colocalization analysis that allows us to quantify colocalization\nlevels at each individual location and automatically identify pixels or regions\nwhere colocalization occurs. The framework, referred to as spatially adaptive\ncolocalization analysis (SACA), integrates a pixel-wise local kernel model for\ncolocalization quantification and a multi-scale adaptive propagation-separation\nstrategy for utilizing spatial information to detect colocalization in a\nspatially adaptive fashion. Applications to simulated and real biological\ndatasets demonstrate the practical merits of SACA in what we hope to be an\neasily applicable and robust colocalization analysis method. In addition,\ntheoretical properties of SACA are investigated to provide rigorous statistical\njustification.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A note on a new paradox in superluminal signalling.   The Tolman paradox is well known as a base for demonstrating the causality\nviolation by faster-than-light signals within special relativity. It is\nconstructed using a two-way exchange of faster-than-light signals between two\ninertial observers who are in a relative motion receding one from another.\nRecently a one-way superluminal signalling arrangement was suggested as a\npossible construction of a causal paradox. In this note we show that this\nsuggestion is not correct, and no causality principle violation can occur in\nany one-way signalling by the use of faster-than-light particles and signals.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Embedded tori with prescribed mean curvature.   We construct a sequence of compact, oriented, embedded, two-dimensional\nsurfaces of genus one into Euclidean 3-space with prescribed, almost constant,\nmean curvature of the form $H(X)=1+{A}{|X|^{-\\gamma}}$ for $|X|$ large, when\n$A<0$ and $\\gamma\\in(0,2)$. Such surfaces are close to sections of unduloids\nwith small necksize, folded along circumferences centered at the origin and\nwith larger and larger radii. The construction involves a deep study of the\ncorresponding Jacobi operators, an application of the Lyapunov-Schmidt\nreduction method and some variational argument.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Data-Augmented Contact Model for Rigid Body Simulation.   Accurately modeling contact behaviors for real-world, near-rigid materials\nremains a grand challenge for existing rigid-body physics simulators. This\npaper introduces a data-augmented contact model that incorporates analytical\nsolutions with observed data to predict the 3D contact impulse which could\nresult in rigid bodies bouncing, sliding or spinning in all directions. Our\nmethod enhances the expressiveness of the standard Coulomb contact model by\nlearning the contact behaviors from the observed data, while preserving the\nfundamental contact constraints whenever possible. For example, a classifier is\ntrained to approximate the transitions between static and dynamic frictions,\nwhile non-penetration constraint during collision is enforced analytically. Our\nmethod computes the aggregated effect of contact for the entire rigid body,\ninstead of predicting the contact force for each contact point individually,\nremoving the exponential decline in accuracy as the number of contact points\nincreases.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Numerical non-LTE 3D radiative transfer using a multigrid method.   3D non-LTE radiative transfer problems are computationally demanding, and\nthis sets limits on the size of the problems that can be solved. So far\nMultilevel Accelerated Lambda Iteration (MALI) has been to the method of choice\nto perform high-resolution computations in multidimensional problems. The\ndisadvantage of MALI is that its computing time scales as $\\mathcal{O}(n^2)$,\nwith $n$ the number of grid points. When the grid gets finer, the computational\ncost increases quadratically. We aim to develop a 3D non-LTE radiative transfer\ncode that is more efficient than MALI. We implement a non-linear multigrid,\nfast approximation storage scheme, into the existing Multi3D radiative transfer\ncode. We verify our multigrid implementation by comparing with MALI\ncomputations. We show that multigrid can be employed in realistic problems with\nsnapshots from 3D radiative-MHD simulations as input atmospheres. With\nmultigrid, we obtain a factor 3.3-4.5 speedup compared to MALI. With\nfull-multigrid the speed-up increases to a factor 6. The speedup is expected to\nincrease for input atmospheres with more grid points and finer grid spacing.\nSolving 3D non-LTE radiative transfer problems using non-linear multigrid\nmethods can be applied to realistic atmospheres with a substantial speed-up.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Hypergraph Convolution and Hypergraph Attention.   Recently, graph neural networks have attracted great attention and achieved\nprominent performance in various research fields. Most of those algorithms have\nassumed pairwise relationships of objects of interest. However, in many real\napplications, the relationships between objects are in higher-order, beyond a\npairwise formulation. To efficiently learn deep embeddings on the high-order\ngraph-structured data, we introduce two end-to-end trainable operators to the\nfamily of graph neural networks, i.e., hypergraph convolution and hypergraph\nattention. Whilst hypergraph convolution defines the basic formulation of\nperforming convolution on a hypergraph, hypergraph attention further enhances\nthe capacity of representation learning by leveraging an attention module. With\nthe two operators, a graph neural network is readily extended to a more\nflexible model and applied to diverse applications where non-pairwise\nrelationships are observed. Extensive experimental results with semi-supervised\nnode classification demonstrate the effectiveness of hypergraph convolution and\nhypergraph attention.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simultaneous dynamic characterization of charge and structural motion during ferroelectric switching.   Monitoring structural changes in ferroelectric thin films during electric\nfield-induced polarization switching is important for a full microscopic\nunderstanding of the coupled motion of charges, atoms and domain walls. We\ncombine standard ferroelectric test-cycles with time-resolved x-ray diffraction\nto investigate the response of a nanoscale ferroelectric oxide capacitor upon\ncharging, discharging and switching. Piezoelectric strain develops during the\nelectronic RC time constant and additionally during structural domain-wall\ncreep. The complex atomic motion during ferroelectric polarization reversal\nstarts with a negative piezoelectric response to the charge flow triggered by\nvoltage pulses. Incomplete screening limits the compressive strain. The\npiezoelectric modulation of the unit cell tweaks the energy barrier between the\ntwo polarization states. Domain wall motion is evidenced by a broadening of the\nin-plane components of Bragg reflections. Such simultaneous measurements on a\nworking device elucidate and visualize the complex interplay of charge flow and\nstructural motion and challenges theoretical modelling.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Reconstruction formulas for Photoacoustic Imaging in Attenuating Media.   In this paper we study the problem of photoacoustic inversion in a weakly\nattenuating medium. We present explicit reconstruction formulas in such media\nand show that the inversion based on such formulas is moderately ill--posed.\nMoreover, we present a numerical algorithm for imaging and demonstrate in\nnumerical experiments the feasibility of this approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On reductions of the discrete Kadomtsev--Petviashvili-type equations.   The reduction by restricting the spectral parameters $k$ and $k'$ on a\ngeneric algebraic curve of degree $\\mathcal{N}$ is performed for the discrete\nAKP, BKP and CKP equations, respectively. A variety of two-dimensional discrete\nintegrable systems possessing a more general solution structure arise from the\nreduction, and in each case a unified formula for generic positive integer\n$\\mathcal{N}\\geq 2$ is given to express the corresponding reduced integrable\nlattice equations. The obtained extended two-dimensional lattice models give\nrise to many important integrable partial difference equations as special\ndegenerations. Some new integrable lattice models such as the discrete\nSawada--Kotera, Kaup--Kupershmidt and Hirota--Satsuma equations in extended\nform are given as examples within the framework.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Ensemble Clustering for Graphs.   We propose an ensemble clustering algorithm for graphs (ECG), which is based\non the Louvain algorithm and the concept of consensus clustering. We validate\nour approach by replicating a recently published study comparing graph\nclustering algorithms over artificial networks, showing that ECG outperforms\nthe leading algorithms from that study. We also illustrate how the ensemble\nobtained with ECG can be used to quantify the presence of community structure\nin the graph.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Long-term Blood Pressure Prediction with Deep Recurrent Neural Networks.   Existing methods for arterial blood pressure (BP) estimation directly map the\ninput physiological signals to output BP values without explicitly modeling the\nunderlying temporal dependencies in BP dynamics. As a result, these models\nsuffer from accuracy decay over a long time and thus require frequent\ncalibration. In this work, we address this issue by formulating BP estimation\nas a sequence prediction problem in which both the input and target are\ntemporal sequences. We propose a novel deep recurrent neural network (RNN)\nconsisting of multilayered Long Short-Term Memory (LSTM) networks, which are\nincorporated with (1) a bidirectional structure to access larger-scale context\ninformation of input sequence, and (2) residual connections to allow gradients\nin deep RNN to propagate more effectively. The proposed deep RNN model was\ntested on a static BP dataset, and it achieved root mean square error (RMSE) of\n3.90 and 2.66 mmHg for systolic BP (SBP) and diastolic BP (DBP) prediction\nrespectively, surpassing the accuracy of traditional BP prediction models. On a\nmulti-day BP dataset, the deep RNN achieved RMSE of 3.84, 5.25, 5.80 and 5.81\nmmHg for the 1st day, 2nd day, 4th day and 6th month after the 1st day SBP\nprediction, and 1.80, 4.78, 5.0, 5.21 mmHg for corresponding DBP prediction,\nrespectively, which outperforms all previous models with notable improvement.\nThe experimental results suggest that modeling the temporal dependencies in BP\ndynamics significantly improves the long-term BP prediction accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Multi-armed Bandits in Constant Space.   We consider the stochastic bandit problem in the sublinear space setting,\nwhere one cannot record the win-loss record for all $K$ arms. We give an\nalgorithm using $O(1)$ words of space with regret \\[\n\\sum_{i=1}^{K}\\frac{1}{\\Delta_i}\\log \\frac{\\Delta_i}{\\Delta}\\log T \\] where\n$\\Delta_i$ is the gap between the best arm and arm $i$ and $\\Delta$ is the gap\nbetween the best and the second-best arms. If the rewards are bounded away from\n$0$ and $1$, this is within an $O(\\log 1/\\Delta)$ factor of the optimum regret\npossible without space constraints.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian hierarchical weighting adjustment and survey inference.   We combine Bayesian prediction and weighted inference as a unified approach\nto survey inference. The general principles of Bayesian analysis imply that\nmodels for survey outcomes should be conditional on all variables that affect\nthe probability of inclusion. We incorporate the weighting variables under the\nframework of multilevel regression and poststratification, as a byproduct\ngenerating model-based weights after smoothing. We investigate deep\ninteractions and introduce structured prior distributions for smoothing and\nstability of estimates. The computation is done via Stan and implemented in the\nopen source R package \"rstanarm\" ready for public use. Simulation studies\nillustrate that model-based prediction and weighting inference outperform\nclassical weighting. We apply the proposal to the New York Longitudinal Study\nof Wellbeing. The new approach generates robust weights and increases\nefficiency for finite population inference, especially for subsets of the\npopulation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Minimax Game-Theoretic Approach to Multiscale H-infinity Optimal Filtering.   Sensing in complex systems requires large-scale information exchange and\non-the-go communications over heterogeneous networks and integrated processing\nplatforms. Many networked cyber-physical systems exhibit hierarchical\ninfrastructures of information flows, which naturally leads to a multi-level\ntree-like information structure in which each level corresponds to a particular\nscale of representation. This work focuses on the multiscale fusion of data\ncollected at multiple levels of the system. We propose a multiscale state-space\nmodel to represent multi-resolution data over the hierarchical information\nsystem and formulate a multi-stage dynamic zero-sum game to design a\nmulti-scale $H_{\\infty}$ robust filter. We present numerical experiments for\none and two-dimensional signals and provide a comparative analysis of the\nminimax filter with the standard Kalman filter to show the improvement in\nsignal-to-noise ratio (SNR).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Opinion evolution in time-varying social influence networks with prejudiced agents.   Investigation of social influence dynamics requires mathematical models that\nare \"simple\" enough to admit rigorous analysis, and yet sufficiently \"rich\" to\ncapture salient features of social groups. Thus, the mechanism of iterative\nopinion pooling from (DeGroot, 1974), which can explain the generation of\nconsensus, was elaborated in (Friedkin and Johnsen, 1999) to take into account\nindividuals' ongoing attachments to their initial opinions, or prejudices. The\n\"anchorage\" of individuals to their prejudices may disable reaching consensus\nand cause disagreement in a social influence network. Further elaboration of\nthis model may be achieved by relaxing its restrictive assumption of a\ntime-invariant influence network. During opinion dynamics on an issue, arcs of\ninterpersonal influence may be added or subtracted from the network, and the\ninfluence weights assigned by an individual to his/her neighbors may alter. In\nthis paper, we establish new important properties of the (Friedkin and Johnsen,\n1999) opinion formation model, and also examine its extension to time-varying\nsocial influence networks.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "The exit time finite state projection scheme: bounding exit distributions and occupation measures of continuous-time Markov chains.   We introduce the exit time finite state projection (ETFSP) scheme, a\ntruncation-based method that yields approximations to the exit distribution and\noccupation measure associated with the time of exit from a domain (i.e., the\ntime of first passage to the complement of the domain) of time-homogeneous\ncontinuous-time Markov chains. We prove that: (i) the computed approximations\nbound the measures from below; (ii) the total variation distances between the\napproximations and the measures decrease monotonically as states are added to\nthe truncation; and (iii) the scheme converges, in the sense that, as the\ntruncation tends to the entire state space, the total variation distances tend\nto zero. Furthermore, we give a computable bound on the total variation\ndistance between the exit distribution and its approximation, and we delineate\nthe cases in which the bound is sharp. We also revisit the related finite state\nprojection scheme and give a comprehensive account of its theoretical\nproperties. We demonstrate the use of the ETFSP scheme by applying it to two\nbiological examples: the computation of the first passage time associated with\nthe expression of a gene, and the fixation times of competing species subject\nto demographic noise.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Precise Recovery of Latent Vectors from Generative Adversarial Networks.   Generative adversarial networks (GANs) transform latent vectors into visually\nplausible images. It is generally thought that the original GAN formulation\ngives no out-of-the-box method to reverse the mapping, projecting images back\ninto latent space. We introduce a simple, gradient-based technique called\nstochastic clipping. In experiments, for images generated by the GAN, we\nprecisely recover their latent vector pre-images 100% of the time. Additional\nexperiments demonstrate that this method is robust to noise. Finally, we show\nthat even for unseen images, our method appears to recover unique encodings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Stochastic Control Approach to Managed Futures Portfolios.   We study a stochastic control approach to managed futures portfolios.\nBuilding on the Schwartz 97 stochastic convenience yield model for commodity\nprices, we formulate a utility maximization problem for dynamically trading a\nsingle-maturity futures or multiple futures contracts over a finite horizon. By\nanalyzing the associated Hamilton-Jacobi-Bellman (HJB) equation, we solve the\ninvestor's utility maximization problem explicitly and derive the optimal\ndynamic trading strategies in closed form. We provide numerical examples and\nillustrate the optimal trading strategies using WTI crude oil futures data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient cold outflows driven by cosmic rays in high redshift galaxies and their global effects on the IGM.   We present semi-analytical models of galactic outflows in high redshift\ngalaxies driven by both hot thermal gas and non-thermal cosmic rays. Thermal\npressure alone may not sustain a large scale outflow in low mass galaxies (i.e\n$M\\sim 10^8$~M$_\\odot$), in the presence of supernovae (SNe) feedback with\nlarge mass loading. We show that inclusion of cosmic ray pressure allows\noutflow solutions even in these galaxies. In massive galaxies for the same\nenergy efficiency, cosmic ray driven winds can propagate to larger distances\ncompared to pure thermally driven winds. On an average gas in the cosmic ray\ndriven winds has a lower temperature which could aid detecting it through\nabsorption lines in the spectra of background sources. Using our constrained\nsemi-analytical models of galaxy formation (that explains the observed UV\nluminosity functions of galaxies) we study the influence of cosmic ray driven\nwinds on the properties of the intergalactic medium (IGM) at different\nredshifts. In particular, we study the volume filling factor, average\nmetallicity, cosmic ray and magnetic field energy densities for models invoking\natomic cooled and molecular cooled halos. We show that the cosmic rays in the\nIGM could have enough energy that can be transferred to the thermal gas in\npresence of magnetic fields to influence the thermal history of the\nintergalactic medium. The significant volume filling and resulting strength of\nIGM magnetic fields can also account for recent $\\gamma$-ray observations of\nblazars.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Secular Resonant Origin for the Loneliness of Hot Jupiters.   Despite decades of inquiry, the origin of giant planets residing within a few\ntenths of an astronomical unit from their host stars remains unclear.\nTraditionally, these objects are thought to have formed further out before\nsubsequently migrating inwards. However, the necessity of migration has been\nrecently called into question with the emergence of in-situ formation models of\nclose-in giant planets. Observational characterization of the transiting\nsub-sample of close-in giants has revealed that \"warm\" Jupiters, possessing\norbital periods longer than roughly 10 days more often possess close-in,\nco-transiting planetary companions than shorter period \"hot\" Jupiters, that are\nusually lonely. This finding has previously been interpreted as evidence that\nsmooth, early migration or in situ formation gave rise to warm Jupiter-hosting\nsystems, whereas more violent, post-disk migration pathways sculpted hot\nJupiter-hosting systems. In this work, we demonstrate that both classes of\nplanet may arise via early migration or in-situ conglomeration, but that the\nenhanced loneliness of hot Jupiters arises due to a secular resonant\ninteraction with the stellar quadrupole moment. Such an interaction tilts the\norbits of exterior, lower mass planets, removing them from transit surveys\nwhere the hot Jupiter is detected. Warm Jupiter-hosting systems, in contrast,\nretain their coplanarity due to the weaker influence of the host star's\nquadrupolar potential relative to planet-disk interactions. In this way, hot\nJupiters and warm Jupiters are placed within a unified theoretical framework\nthat may be readily validated or falsified using data from upcoming missions\nsuch as TESS.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards Robust Interpretability with Self-Explaining Neural Networks.   Most recent work on interpretability of complex machine learning models has\nfocused on estimating $\\textit{a posteriori}$ explanations for previously\ntrained models around specific predictions. $\\textit{Self-explaining}$ models\nwhere interpretability plays a key role already during learning have received\nmuch less attention. We propose three desiderata for explanations in general --\nexplicitness, faithfulness, and stability -- and show that existing methods do\nnot satisfy them. In response, we design self-explaining models in stages,\nprogressively generalizing linear classifiers to complex yet architecturally\nexplicit models. Faithfulness and stability are enforced via regularization\nspecifically tailored to such models. Experimental results across various\nbenchmark datasets show that our framework offers a promising direction for\nreconciling model complexity and interpretability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On constraining projections of future climate using observations and simulations from multiple climate models.   A new Bayesian framework is presented that can constrain projections of\nfuture climate using historical observations by exploiting robust estimates of\nemergent relationships between multiple climate models. We argue that emergent\nrelationships can be interpreted as constraints on model inadequacy, but that\nprojections may be biased if we do not account for internal variability in\nclimate model projections. We extend the previously proposed coexchangeable\nframework to account for natural variability in the Earth system and internal\nvariability simulated by climate models. A detailed theoretical comparison with\nprevious multi-model projection frameworks is provided.\nThe proposed framework is applied to projecting surface temperature in the\nArctic at the end of the 21st century. A subset of available climate models are\nselected in order to satisfy the assumptions of the framework. All available\ninitial condition runs from each model are utilized in order maximize the\nutility of the data. Projected temperatures in some regions are more than 2C\nlower when constrained by historical observations. The uncertainty about the\nclimate response is reduced by up to 30% where strong constraints exist.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Enhancing Blood Glucose Prediction with Meal Absorption and Physical Exercise Information.   Objective: Numerous glucose prediction algorithm have been proposed to\nempower type 1 diabetes (T1D) management. Most of these algorithms only account\nfor input such as glucose, insulin and carbohydrate, which limits their\nperformance. Here, we present a novel glucose prediction algorithm which, in\naddition to standard inputs, accounts for meal absorption and physical exercise\ninformation to enhance prediction accuracy. Methods: a compartmental model of\nglucose-insulin dynamics combined with a deconvolution technique for state\nestimation is employed for glucose prediction. In silico data corresponding\nfrom the 10 adult subjects of UVa-Padova simulator, and clinical data from 10\nadults with T1D were used. Finally, a comparison against a validated glucose\nprediction algorithm based on a latent variable with exogenous input (LVX)\nmodel is provided. Results: For a prediction horizon of 60 minutes, accounting\nfor meal absorption and physical exercise improved glucose forecasting\naccuracy. In particular, root mean square error (mg/dL) went from 26.68 to\n23.89, p<0.001 (in silico data); and from 37.02 to 35.96, p<0.001 (clinical\ndata - only meal information). Such improvement in accuracy was translated into\nsignificant improvements on hypoglycaemia and hyperglycaemia prediction.\nFinally, the performance of the proposed algorithm is statistically superior to\nthat of the LVX algorithm (26.68 vs. 32.80, p<0.001 (in silico data); 37.02 vs.\n49.17, p<0.01 (clinical data). Conclusion: Taking into account meal absorption\nand physical exercise information improves glucose prediction accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Graph Product Multilayer Networks: Spectral Properties and Applications.   This paper aims to establish theoretical foundations of graph product\nmultilayer networks (GPMNs), a family of multilayer networks that can be\nobtained as a graph product of two or more factor networks. Cartesian, direct\n(tensor), and strong product operators are considered, and then generalized. We\nfirst describe mathematical relationships between GPMNs and their factor\nnetworks regarding their degree/strength, adjacency, and Laplacian spectra, and\nthen show that those relationships can still hold for nonsimple and generalized\nGPMNs. Applications of GPMNs are discussed in three areas: predicting epidemic\nthresholds, modeling propagation in nontrivial space and time, and analyzing\nhigher-order properties of self-similar networks. Directions of future research\nare also discussed.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "MOEMS deformable mirror testing in cryo for future optical instrumentation.   MOEMS Deformable Mirrors (DM) are key components for next generation\ninstruments with innovative adaptive optics systems, in existing telescopes and\nin the future ELTs. These DMs must perform at room temperature as well as in\ncryogenic and vacuum environment. Ideally, the MOEMS-DMs must be designed to\noperate in such environment. We present some major rules for designing /\noperating DMs in cryo and vacuum. We chose to use interferometry for the full\ncharacterization of these devices, including surface quality measurement in\nstatic and dynamical modes, at ambient and in vacuum/cryo. Thanks to our\nprevious set-up developments, we placed a compact cryo-vacuum chamber designed\nfor reaching 10-6 mbar and 160K, in front of our custom Michelson\ninterferometer, able to measure performances of the DM at actuator/segment\nlevel as well as whole mirror level, with a lateral resolution of 2{\\mu}m and a\nsub-nanometric z-resolution. Using this interferometric bench, we tested the\nIris AO PTT111 DM: this unique and robust design uses an array of single\ncrystalline silicon hexagonal mirrors with a pitch of 606{\\mu}m, able to move\nin tip, tilt and piston with strokes from 5 to 7{\\mu}m, and tilt angle in the\nrange of +/-5mrad. They exhibit typically an open-loop flat surface figure as\ngood as <20nm rms. A specific mount including electronic and opto-mechanical\ninterfaces has been designed for fitting in the test chamber. Segment\ndeformation, mirror shaping, open-loop operation are tested at room and cryo\ntemperature and results are compared. The device could be operated successfully\nat 160K. An additional, mainly focus-like, 500 nm deformation is measured at\n160K; we were able to recover the best flat in cryo by correcting the focus and\nlocal tip-tilts on some segments. Tests on DM with different mirror thicknesses\n(25{\\mu}m and 50{\\mu}m) and different coatings (silver and gold) are currently\nunder way.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Variational Bayesian dropout: pitfalls and fixes.   Dropout, a stochastic regularisation technique for training of neural\nnetworks, has recently been reinterpreted as a specific type of approximate\ninference algorithm for Bayesian neural networks. The main contribution of the\nreinterpretation is in providing a theoretical framework useful for analysing\nand extending the algorithm. We show that the proposed framework suffers from\nseveral issues; from undefined or pathological behaviour of the true posterior\nrelated to use of improper priors, to an ill-defined variational objective due\nto singularity of the approximating distribution relative to the true\nposterior. Our analysis of the improper log uniform prior used in variational\nGaussian dropout suggests the pathologies are generally irredeemable, and that\nthe algorithm still works only because the variational formulation annuls some\nof the pathologies. To address the singularity issue, we proffer Quasi-KL (QKL)\ndivergence, a new approximate inference objective for approximation of\nhigh-dimensional distributions. We show that motivations for variational\nBernoulli dropout based on discretisation and noise have QKL as a limit.\nProperties of QKL are studied both theoretically and on a simple practical\nexample which shows that the QKL-optimal approximation of a full rank Gaussian\nwith a degenerate one naturally leads to the Principal Component Analysis\nsolution.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Virtually free finite-normal-subgroup-free groups are strongly verbally closed.   Any virtually free group $H$ containing no non-trivial finite normal subgroup\n(e.g., the infinite dihedral group) is a retract of any finitely generated\ngroup containing $H$ as a verbally closed subgroup.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multi-SpaM: a Maximum-Likelihood approach to Phylogeny reconstruction based on Multiple Spaced-Word Matches.   Motivation: Word-based or `alignment-free' methods for phylogeny\nreconstruction are much faster than traditional approaches, but they are\ngenerally less accurate. Most of these methods calculate pairwise distances for\na set of input sequences, for example from word frequencies, from so-called\nspaced-word matches or from the average length of common substrings.\nResults: In this paper, we propose the first word-based approach to tree\nreconstruction that is based on multiple sequence comparison and Maximum\nLikelihood. Our algorithm first samples small, gap-free alignments involving\nfour taxa each. For each of these alignments, it then calculates a quartet tree\nand, finally, the program Quartet MaxCut is used to infer a super tree topology\nfor the full set of input taxa from the calculated quartet trees. Experimental\nresults show that trees calculated with our approach are of high quality.\nAvailability: The source code of the program is available at\nthis https URL\nContact: thomas.dencker@stud.uni-goettingen.de",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Design of Capacity Approaching Ensembles of LDPC Codes for Correlated Sources using EXIT Charts.   This paper is concerned with the design of capacity approaching ensembles of\nLow-Densiy Parity-Check (LDPC) codes for correlated sources. We consider\ncorrelated binary sources where the data is encoded independently at each\nsource through a systematic LDPC encoder and sent over two independent\nchannels. At the receiver, a iterative joint decoder consisting of two\ncomponent LDPC decoders is considered where the encoded bits at the output of\neach component decoder are used at the other decoder as the a priori\ninformation. We first provide asymptotic performance analysis using the concept\nof extrinsic information transfer (EXIT) charts. Compared to the conventional\nEXIT charts devised to analyze LDPC codes for point to point communication, the\nproposed EXIT charts have been completely modified to able to accommodate the\nsystematic nature of the codes as well as the iterative behavior between the\ntwo component decoders. Then the developed modified EXIT charts are deployed to\ndesign ensembles for different levels of correlation. Our results show that as\nthe average degree of the designed ensembles grow, the thresholds corresponding\nto the designed ensembles approach the capacity. In particular, for ensembles\nwith average degree of around 9, the gap to capacity is reduced to about 0.2dB.\nFinite block length performance evaluation is also provided for the designed\nensembles to verify the asymptotic results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "ArchiveWeb: collaboratively extending and exploring web archive collections - How would you like to work with your collections?.   Curated web archive collections contain focused digital content which is\ncollected by archiving organizations, groups, and individuals to provide a\nrepresentative sample covering specific topics and events to preserve them for\nfuture exploration and analysis. In this paper, we discuss how to best support\ncollaborative construction and exploration of these collections through the\nArchiveWeb system. ArchiveWeb has been developed using an iterative\nevaluation-driven design-based research approach, with considerable user\nfeedback at all stages. The first part of this paper describes the important\ninsights we gained from our initial requirements engineering phase during the\nfirst year of the project and the main functionalities of the current\nArchiveWeb system for searching, constructing, exploring, and discussing web\narchive collections. The second part summarizes the feedback we received on\nthis version from archiving organizations and libraries, as well as our\ncorresponding plans for improving and extending the system for the next\nrelease.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Infinitary generalizations of Deligne's completeness theorem.   Given a regular cardinal $\\kappa$ such that $\\kappa^{<\\kappa}=\\kappa$, we\nstudy a class of toposes with enough points, the $\\kappa$-separable toposes.\nThese are equivalent to sheaf toposes over a site with $\\kappa$-small limits\nthat has at most $\\kappa$ many objects and morphisms, the (basis for the)\ntopology being generated by at most $\\kappa$ many covering families, and that\nsatisfy a further exactness property $T$. We prove that these toposes have\nenough $\\kappa$-points, that is, points whose inverse image preserve all\n$\\kappa$-small limits. This generalizes the separable toposes of Makkai and\nReyes, that are a particular case when $\\kappa=\\omega$, when property $T$ is\ntrivially satisfied. This result is essentially a completeness theorem for a\ncertain infinitary logic that we call $\\kappa$-geometric, where conjunctions of\nless than $\\kappa$ formulas and existential quantification on less than\n$\\kappa$ many variables is allowed. We prove that $\\kappa$-geometric theories\nhave a $\\kappa$-classifying topos having property $T$, the universal property\nbeing that models of the theory in a Grothendieck topos with property $T$\ncorrespond to $\\kappa$-geometric morphisms (geometric morphisms the inverse\nimage of which preserves all $\\kappa$-small limits) into that topos. Moreover,\nwe prove that $\\kappa$-separable toposes occur as the $\\kappa$-classifying\ntoposes of $\\kappa$-geometric theories of at most $\\kappa$ many axioms in\ncanonical form, and that every such $\\kappa$-classifying topos is\n$\\kappa$-separable. Finally, we consider the case when $\\kappa$ is weakly\ncompact and study the $\\kappa$-classifying topos of a $\\kappa$-coherent theory\n(with at most $\\kappa$ many axioms), that is, a theory where only disjunction\nof less than $\\kappa$ formulas are allowed, obtaining a version of Deligne's\ntheorem for $\\kappa$-coherent toposes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Endomorphism Algebras of Abelian varieties with special reference to Superelliptic Jacobians.   This is (mostly) a survey article. We use an information about Galois\nproperties of points of small order on an abelian variety in order to describe\nits endomorphism algebra over an algebraic closure of the ground field. We\ndiscuss in detail applications to jacobians of cyclic covers of the projective\nline.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Finite-Time Distributed Linear Equation Solver for Minimum $l_1$ Norm Solutions.   This paper proposes distributed algorithms for multi-agent networks to\nachieve a solution in finite time to a linear equation $Ax=b$ where $A$ has\nfull row rank, and with the minimum $l_1$-norm in the underdetermined case\n(where $A$ has more columns than rows). The underlying network is assumed to be\nundirected and fixed, and an analytical proof is provided for the proposed\nalgorithm to drive all agents' individual states to converge to a common value,\nviz a solution of $Ax=b$, which is the minimum $l_1$-norm solution in the\nunderdetermined case. Numerical simulations are also provided as validation of\nthe proposed algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the vanishing of self extensions over Cohen-Macaulay local rings.   The celebrated Auslander-Reiten Conjecture, on the vanishing of self\nextensions of a module, is one of the long-standing conjectures in ring theory.\nAlthough it is still open, there are several results in the literature that\nestablish the conjecture over Gorenstein rings under certain conditions. The\npurpose of this article is to obtain extensions of such results over\nCohen-Macaulay local rings that admit canonical modules. In particular, our\nmain result recovers theorems of Araya, and Ono and Yoshino simultaneously.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Particle-hole Asymmetry in the Cuprate Pseudogap Measured with Time-Resolved Spectroscopy.   One of the most puzzling features of high-temperature cuprate superconductors\nis the pseudogap state, which appears above the temperature at which\nsuperconductivity is destroyed. There remain fundamental questions regarding\nits nature and its relation to superconductivity. But to address these\nquestions, we must first determine whether the pseudogap and superconducting\nstates share a common property: particle-hole symmetry. We introduce a new\ntechnique to test particle-hole symmetry by using laser pulses to manipulate\nand measure the chemical potential on picosecond time scales. The results\nstrongly suggest that the asymmetry in the density of states is inverted in the\npseudogap state, implying a particle-hole asymmetric gap. Independent of\ninterpretation, these results can test theoretical predictions of the density\nof states in cuprates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "High Contrast Observations of Bright Stars with a Starshade.   Starshades are a leading technology to enable the direct detection and\nspectroscopic characterization of Earth-like exoplanets. In an effort to\nadvance starshade technology through system level demonstrations, the\nMcMath-Pierce Solar Telescope was adapted to enable the suppression of\nastronomical sources with a starshade. The long baselines achievable with the\nheliostat provide measurements of starshade performance at a flight-like\nFresnel number and resolution, aspects critical to the validation of optical\nmodels. The heliostat has provided the opportunity to perform the first\nastronomical observations with a starshade and has made science accessible in a\nunique parameter space, high contrast at moderate inner working angles. On-sky\nimages are valuable for developing the experience and tools needed to extract\nscience results from future starshade observations. We report on high contrast\nobservations of nearby stars provided by a starshade. We achieve 5.6e-7\ncontrast at 30 arcseconds inner working angle on the star Vega and provide new\nphotometric constraints on background stars near Vega.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Topologist's View of Kinematic Maps and Manipulation Complexity.   In this paper we combine a survey of the most important topological\nproperties of kinematic maps that appear in robotics, with the exposition of\nsome basic results regarding the topological complexity of a map. In\nparticular, we discuss mechanical devices that consist of rigid parts connected\nby joints and show how the geometry of the joints determines the forward\nkinematic map that relates the configuration of joints with the pose of the\nend-effector of the device. We explain how to compute the dimension of the\njoint space and describe topological obstructions for a kinematic map to be a\nfibration or to admit a continuous section. In the second part of the paper we\ndefine the complexity of a continuous map and show how the concept can be\nviewed as a measure of the difficulty to find a robust manipulation plan for a\ngiven mechanical device. We also derive some basic estimates for the complexity\nand relate it to the degree of instability of a manipulation plan.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimal Jittered Sampling for two Points in the Unit Square.   Jittered Sampling is a refinement of the classical Monte Carlo sampling\nmethod. Instead of picking $n$ points randomly from $[0,1]^2$, one partitions\nthe unit square into $n$ regions of equal measure and then chooses a point\nrandomly from each partition. Currently, no good rules for how to partition the\nspace are available. In this paper, we present a solution for the special case\nof subdividing the unit square by a decreasing function into two regions so as\nto minimize the expected squared $\\mathcal{L}_2-$discrepancy. The optimal\npartitions are given by a \\textit{highly} nonlinear integral equation for which\nwe determine an approximate solution. In particular, there is a break of\nsymmetry and the optimal partition is not into two sets of equal measure. We\nhope this stimulates further interest in the construction of good partitions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Isotope Shifts in the 7s$\\rightarrow$8s Transition of Francium: Measurements and Comparison to \\textit{ab initio} Theory.   We observe the electric-dipole forbidden $7s\\rightarrow8s$ transition in the\nfrancium isotopes $^{208-211}$Fr and $^{213}$Fr using a two-photon excitation\nscheme. We collect the atoms online from an accelerator and confine them in a\nmagneto optical trap for the measurements. In combination with previous\nmeasurements of the $7s\\rightarrow7p_{1/2}$ transition we perform a King Plot\nanalysis. We compare the thus determined ratio of the field shift constants\n(1.230 $\\pm$ 0.019) to results obtained from new ab initio calculations (1.234\n$\\pm$ 0.010) and find excellent agreement.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Motions about a fixed point by hypergeometric functions: new non-complex analytical solutions and integration of the herpolhode.   We study four problems in the dynamics of a body moving about a fixed point,\nproviding a non-complex, analytical solution for all of them. For the first\ntwo, we will work on the motion first integrals. For the symmetrical heavy\nbody, that is the Lagrange-Poisson case, we compute the second and third Euler\nangles in explicit and real forms by means of multiple hypergeometric functions\n(Lauricella, functions). Releasing the weight load but adding the complication\nof the asymmetry, by means of elliptic integrals of third kind, we provide the\nprecession angle completing some previous treatments of the Euler-Poinsot case.\nIntegrating then the relevant differential equation, we reach the finite polar\nequation of a special trajectory named the {\\it herpolhode}. In the last\nproblem we keep the symmetry of the first problem, but without the weight, and\ntake into account a viscous dissipation. The approach of first integrals is no\nlonger practicable in this situation and the Euler equations are faced directly\nleading to dumped goniometric functions obtained as particular occurrences of\nBessel functions of order $-1/2$.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "SUBIC: A Supervised Bi-Clustering Approach for Precision Medicine.   Traditional medicine typically applies one-size-fits-all treatment for the\nentire patient population whereas precision medicine develops tailored\ntreatment schemes for different patient subgroups. The fact that some factors\nmay be more significant for a specific patient subgroup motivates clinicians\nand medical researchers to develop new approaches to subgroup detection and\nanalysis, which is an effective strategy to personalize treatment. In this\nstudy, we propose a novel patient subgroup detection method, called Supervised\nBiclustring (SUBIC) using convex optimization and apply our approach to detect\npatient subgroups and prioritize risk factors for hypertension (HTN) in a\nvulnerable demographic subgroup (African-American). Our approach not only finds\npatient subgroups with guidance of a clinically relevant target variable but\nalso identifies and prioritizes risk factors by pursuing sparsity of the input\nvariables and encouraging similarity among the input variables and between the\ninput and target variables",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-singular spacetimes with a negative cosmological constant: IV. Stationary black hole solutions with matter fields.   We use an elliptic system of equations with complex coefficients for a set of\ncomplex-valued tensor fields as a tool to construct infinite-dimensional\nfamilies of non-singular stationary black holes, real-valued Lorentzian\nsolutions of the Einstein-Maxwell-dilaton-scalar\nfields-Yang-Mills-Higgs-Chern-Simons-$f(R)$ equations with a negative\ncosmological constant. The families include an infinite-dimensional family of\nsolutions with the usual AdS conformal structure at conformal infinity.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "On Bayesian Exponentially Embedded Family for Model Order Selection.   In this paper, we derive a Bayesian model order selection rule by using the\nexponentially embedded family method, termed Bayesian EEF. Unlike many other\nBayesian model selection methods, the Bayesian EEF can use vague proper priors\nand improper noninformative priors to be objective in the elicitation of\nparameter priors. Moreover, the penalty term of the rule is shown to be the sum\nof half of the parameter dimension and the estimated mutual information between\nparameter and observed data. This helps to reveal the EEF mechanism in\nselecting model orders and may provide new insights into the open problems of\nchoosing an optimal penalty term for model order selection and choosing a good\nprior from information theoretic viewpoints. The important example of linear\nmodel order selection is given to illustrate the algorithms and arguments.\nLastly, the Bayesian EEF that uses Jeffreys prior coincides with the EEF rule\nderived by frequentist strategies. This shows another interesting relationship\nbetween the frequentist and Bayesian philosophies for model selection.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs.   Generative Adversarial Networks (GANs) have shown remarkable success as a\nframework for training models to produce realistic-looking data. In this work,\nwe propose a Recurrent GAN (RGAN) and Recurrent Conditional GAN (RCGAN) to\nproduce realistic real-valued multi-dimensional time series, with an emphasis\non their application to medical data. RGANs make use of recurrent neural\nnetworks in the generator and the discriminator. In the case of RCGANs, both of\nthese RNNs are conditioned on auxiliary information. We demonstrate our models\nin a set of toy datasets, where we show visually and quantitatively (using\nsample likelihood and maximum mean discrepancy) that they can successfully\ngenerate realistic time-series. We also describe novel evaluation methods for\nGANs, where we generate a synthetic labelled training dataset, and evaluate on\na real test set the performance of a model trained on the synthetic data, and\nvice-versa. We illustrate with these metrics that RCGANs can generate\ntime-series data useful for supervised training, with only minor degradation in\nperformance on real test data. This is demonstrated on digit classification\nfrom 'serialised' MNIST and by training an early warning system on a medical\ndataset of 17,000 patients from an intensive care unit. We further discuss and\nanalyse the privacy concerns that may arise when using RCGANs to generate\nrealistic synthetic medical time series data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Darboux and Binary Darboux Transformations for Discrete Integrable Systems. II. Discrete Potential mKdV Equation.   The paper presents two results. First it is shown how the discrete potential\nmodified KdV equation and its Lax pairs in matrix form arise from the\nHirota-Miwa equation by a 2-periodic reduction. Then Darboux transformations\nand binary Darboux transformations are derived for the discrete potential\nmodified KdV equation and it is shown how these may be used to construct exact\nsolutions.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Bi-Lagrangian structures and Teichmüller theory.   This paper has two purposes: the first is to study several structures on\nmanifolds in the general setting of real and complex differential geometry; the\nsecond is to apply this study to Teichmüller theory. We primarily focus on\nbi-Lagrangian structures, which are the data of a symplectic structure and a\npair of transverse Lagrangian foliations, and are equivalent to para-Kähler\nstructures. First we carefully study real and complex bi-Lagrangian structures\nand discuss other closely related structures and their interrelationships. Next\nwe prove the existence of a canonical complex bi-Lagrangian structure in the\ncomplexification of any real-analytic Kähler manifold and showcase its\nproperties. We later use this bi-Lagrangian structure to construct a natural\nalmost hyper-Hermitian structure. We then specialize our study to moduli spaces\nof geometric structures on closed surfaces, which tend to have a rich\nsymplectic structure. We show that some of the recognized geometric features of\nthese moduli spaces are formal consequences of the general theory, while\nrevealing other new geometric features. We also gain clarity on several\nwell-known results of Teichmüller theory by deriving them from pure\ndifferential geometric machinery.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Development of a 32-channel ASIC for an X-ray APD Detector onboard the ISS.   We report on the design and performance of a mixed-signal application\nspecific integrated circuit (ASIC) dedicated to avalanche photodiodes (APDs) in\norder to detect hard X-ray emissions in a wide energy band onboard the\nInternational Space Station. To realize wide-band detection from 20 keV to 1\nMeV, we use Ce:GAGG scintillators, each coupled to an APD, with low-noise\nfront-end electronics capable of achieving a minimum energy detection threshold\nof 20 keV. The developed ASIC has the ability to read out 32-channel APD\nsignals using 0.35 $\\mu$m CMOS technology, and an analog amplifier at the input\nstage is designed to suppress the capacitive noise primarily arising from the\nlarge detector capacitance of the APDs. The ASIC achieves a performance of 2099\ne$^{-}$ + 1.5 e$^{-}$/pF at root mean square (RMS) with a wide 300 fC dynamic\nrange. Coupling a reverse-type APD with a Ce:GAGG scintillator, we obtain an\nenergy resolution of 6.7% (FWHM) at 662 keV and a minimum detectable energy of\n20 keV at room temperature (20 $^{\\circ}$C). Furthermore, we examine the\nradiation tolerance for space applications by using a 90 MeV proton beam,\nconfirming that the ASIC is free of single-event effects and can operate\nproperly without serious degradation in analog and digital processing.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "ClusterNet: Detecting Small Objects in Large Scenes by Exploiting Spatio-Temporal Information.   Object detection in wide area motion imagery (WAMI) has drawn the attention\nof the computer vision research community for a number of years. WAMI proposes\na number of unique challenges including extremely small object sizes, both\nsparse and densely-packed objects, and extremely large search spaces (large\nvideo frames). Nearly all state-of-the-art methods in WAMI object detection\nreport that appearance-based classifiers fail in this challenging data and\ninstead rely almost entirely on motion information in the form of background\nsubtraction or frame-differencing. In this work, we experimentally verify the\nfailure of appearance-based classifiers in WAMI, such as Faster R-CNN and a\nheatmap-based fully convolutional neural network (CNN), and propose a novel\ntwo-stage spatio-temporal CNN which effectively and efficiently combines both\nappearance and motion information to significantly surpass the state-of-the-art\nin WAMI object detection. To reduce the large search space, the first stage\n(ClusterNet) takes in a set of extremely large video frames, combines the\nmotion and appearance information within the convolutional architecture, and\nproposes regions of objects of interest (ROOBI). These ROOBI can contain from\none to clusters of several hundred objects due to the large video frame size\nand varying object density in WAMI. The second stage (FoveaNet) then estimates\nthe centroid location of all objects in that given ROOBI simultaneously via\nheatmap estimation. The proposed method exceeds state-of-the-art results on the\nWPAFB 2009 dataset by 5-16% for moving objects and nearly 50% for stopped\nobjects, as well as being the first proposed method in wide area motion imagery\nto detect completely stationary objects.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The discrete logarithm problem over prime fields: the safe prime case. The Smart attack, non-canonical lifts and logarithmic derivatives.   In this brief note we connect the discrete logarithm problem over prime\nfields in the safe prime case to the logarithmic derivative.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Asynchronous Parallel Approach to Sparse Recovery.   Asynchronous parallel computing and sparse recovery are two areas that have\nreceived recent interest. Asynchronous algorithms are often studied to solve\noptimization problems where the cost function takes the form $\\sum_{i=1}^M\nf_i(x)$, with a common assumption that each $f_i$ is sparse; that is, each\n$f_i$ acts only on a small number of components of $x\\in\\mathbb{R}^n$. Sparse\nrecovery problems, such as compressed sensing, can be formulated as\noptimization problems, however, the cost functions $f_i$ are dense with respect\nto the components of $x$, and instead the signal $x$ is assumed to be sparse,\nmeaning that it has only $s$ non-zeros where $s\\ll n$. Here we address how one\nmay use an asynchronous parallel architecture when the cost functions $f_i$ are\nnot sparse in $x$, but rather the signal $x$ is sparse. We propose an\nasynchronous parallel approach to sparse recovery via a stochastic greedy\nalgorithm, where multiple processors asynchronously update a vector in shared\nmemory containing information on the estimated signal support. We include\nnumerical simulations that illustrate the potential benefits of our proposed\nasynchronous method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generating Query Suggestions to Support Task-Based Search.   We address the problem of generating query suggestions to support users in\ncompleting their underlying tasks (which motivated them to search in the first\nplace). Given an initial query, these query suggestions should provide a\ncoverage of possible subtasks the user might be looking for. We propose a\nprobabilistic modeling framework that obtains keyphrases from multiple sources\nand generates query suggestions from these keyphrases. Using the test suites of\nthe TREC Tasks track, we evaluate and analyze each component of our model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hardy Spaces over Half-strip Domains.   We define Hardy spaces $H^p(\\Omega_\\pm)$ on half-strip domain~$\\Omega_+$ and\n$\\Omega_-= \\mathbb{C}\\setminus\\overline{\\Omega_+}$, where $0<p<\\infty$, and\nprove that functions in $H^p(\\Omega_\\pm)$ has non-tangential boundary limit\na.e. on $\\Gamma$, the common boundary of $\\Omega_\\pm$. We then prove that\nCauchy integral of functions in $L^p(\\Gamma)$ are in $H^p(\\Omega_\\pm)$, where\n$1<p<\\infty$, that is, Cauchy transform is bounded. Besides, if $1\\leqslant\np<\\infty$, then $H^p(\\Omega_\\pm)$ functions are the Cauchy integral of their\nnon-tangential boundary limits. We also establish an isomorphism between\n$H^p(\\Omega_\\pm)$ and $H^p(\\mathbb{C}_\\pm)$, the classical Hardy spaces over\nupper and lower half complex planes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simple And Efficient Architecture Search for Convolutional Neural Networks.   Neural networks have recently had a lot of success for many tasks. However,\nneural network architectures that perform well are still typically designed\nmanually by experts in a cumbersome trial-and-error process. We propose a new\nmethod to automatically search for well-performing CNN architectures based on a\nsimple hill climbing procedure whose operators apply network morphisms,\nfollowed by short optimization runs by cosine annealing. Surprisingly, this\nsimple method yields competitive results, despite only requiring resources in\nthe same order of magnitude as training a single network. E.g., on CIFAR-10,\nour method designs and trains networks with an error rate below 6% in only 12\nhours on a single GPU; training for one day reduces this error further, to\nalmost 5%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Status maximization as a source of fairness in a networked dictator game.   Human behavioural patterns exhibit selfish or competitive, as well as\nselfless or altruistic tendencies, both of which have demonstrable effects on\nhuman social and economic activity. In behavioural economics, such effects have\ntraditionally been illustrated experimentally via simple games like the\ndictator and ultimatum games. Experiments with these games suggest that, beyond\nrational economic thinking, human decision-making processes are influenced by\nsocial preferences, such as an inclination to fairness. In this study we\nsuggest that the apparent gap between competitive and altruistic human\ntendencies can be bridged by assuming that people are primarily maximising\ntheir status, i.e., a utility function different from simple profit\nmaximisation. To this end we analyse a simple agent-based model, where\nindividuals play the repeated dictator game in a social network they can\nmodify. As model parameters we consider the living costs and the rate at which\nagents forget infractions by others. We find that individual strategies used in\nthe game vary greatly, from selfish to selfless, and that both of the above\nparameters determine when individuals form complex and cohesive social\nnetworks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Regret Bounds for Reinforcement Learning via Markov Chain Concentration.   We give a simple optimistic algorithm for which it is easy to derive regret\nbounds of $\\tilde{O}(\\sqrt{t_{\\rm mix} SAT})$ after $T$ steps in uniformly\nergodic Markov decision processes with $S$ states, $A$ actions, and mixing time\nparameter $t_{\\rm mix}$. These bounds are the first regret bounds in the\ngeneral, non-episodic setting with an optimal dependence on all given\nparameters. They could only be improved by using an alternative mixing time\nparameter.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Model Order Selection Rules For Covariance Structure Classification.   The adaptive classification of the interference covariance matrix structure\nfor radar signal processing applications is addressed in this paper. This\nrepresents a key issue because many detection architectures are synthesized\nassuming a specific covariance structure which may not necessarily coincide\nwith the actual one due to the joint action of the system and environment\nuncertainties. The considered classification problem is cast in terms of a\nmultiple hypotheses test with some nested alternatives and the theory of Model\nOrder Selection (MOS) is exploited to devise suitable decision rules. Several\nMOS techniques, such as the Akaike, Takeuchi, and Bayesian information criteria\nare adopted and the corresponding merits and drawbacks are discussed. At the\nanalysis stage, illustrating examples for the probability of correct model\nselection are presented showing the effectiveness of the proposed rules.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Kondo destruction in a quantum paramagnet with magnetic frustration.   We report results of isothermal magnetotransport and susceptibility\nmeasurements at elevated magnetic fields B down to very low temperatures T on\nhigh-quality single crystals of the frustrated Kondo-lattice system CePdAl.\nThey reveal a B*(T) line within the paramagnetic part of the phase diagram.\nThis line denotes a thermally broadened 'small'-to-'large' Fermi surface\ncrossover which substantially narrows upon cooling. At B_0* = B*(T=0) = (4.6\n+/- 0.1) T, this B*(T) line merges with two other crossover lines, viz. Tp(B)\nbelow and T_FL(B) above B_0*. Tp characterizes a frustration-dominated\nspin-liquid state, while T_FL is the Fermi-liquid temperature associated with\nthe lattice Kondo effect. Non-Fermi-liquid phenomena which are commonly\nobserved near a 'Kondo destruction' quantum critical point cannot be resolved\nin CePdAl. Our observations reveal a rare case where Kondo coupling,\nfrustration and quantum criticality are closely intertwined.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bounds on poloidal kinetic energy in plane layer convection.   A numerical method is presented which conveniently computes upper bounds on\nheat transport and poloidal energy in plane layer convection for infinite and\nfinite Prandtl numbers. The bounds obtained for the heat transport coincide\nwith earlier results. These bounds imply upper bounds for the poloidal energy\nwhich follow directly from the definitions of dissipation and energy. The same\nconstraints used for computing upper bounds on the heat transport lead to\nimproved bounds for the poloidal energy.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A time change strategy to model reporting delay dynamics in claims reserving.   This paper considers the problem of predicting the number of claims that have\nalready incurred in past exposure years, but which have not yet been reported\nto the insurer. This is an important building block in the risk management\nstrategy of an insurer since the company should be able to fulfill its\nliabilities with respect to such claims. Our approach puts emphasis on modeling\nthe time between the occurrence and reporting of claims, the so-called\nreporting delay. Using data at a daily level we propose a micro-level model for\nthe heterogeneity in reporting delay caused by calendar day effects in the\nreporting process, such as the weekday pattern and holidays. A simulation study\nidentifies the strengths and weaknesses of our approach in several scenarios\ncompared to traditional methods to predict the number of incurred but not\nreported claims from aggregated data (i.e. the chain ladder method). We also\nillustrate our model on a European general liability insurance data set and\nconclude that the granular approach compared to the chain ladder method is more\nrobust with respect to volatility in the occurrence process. Our framework can\nbe extended to other predictive problems where interest goes to events that\nincurred in the past but which are subject to an observation delay (e.g. the\nnumber of infections during an epidemic).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The efficiency of community detection by most similar node pairs.   Community analysis is an important way to ascertain whether or not a complex\nsystem consists of sub-structures with different properties. In this paper, we\ngive a two level community structure analysis for the SSCI journal system by\nmost similar co-citation pattern. Five different strategies for the selection\nof most similar node (journal) pairs are introduced. The efficiency is checked\nby the normalized mutual information technique. Statistical properties and\ncomparisons of the community results show that both of the two level detection\ncould give instructional information for the community structure of complex\nsystems. Further comparisons of the five strategies indicates that, the most\nefficient strategy is to assign nodes with maximum similarity into the same\ncommunity whether the similarity information is complete or not, while random\nselection generates small world local community with no inside order. These\nresults give valuable indication for efficient community detection by most\nsimilar node pairs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modular representations in type A with a two-row nilpotent central character.   We study the category of representations of $\\mathfrak{sl}_{m+2n}$ in\npositive characteristic, whose p-character is a nilpotent whose Jordan type is\nthe two-row partition (m+n,n). In a previous paper with Anno, we used\nBezrukavnikov-Mirkovic-Rumynin's theory of positive characteristic localization\nand exotic t-structures to give a geometric parametrization of the simples\nusing annular crossingless matchings. Building on this, here we give\ncombinatorial dimension formulae for the simple objects, and compute the\nJordan-Holder multiplicities of the simples inside the baby Vermas (in special\ncase where n=1, i.e. that a subregular nilpotent, these were known from work of\nJantzen). We use Cautis-Kamnitzer's geometric categorification of the tangle\ncalculus to study the images of the simple objects under the [BMR] equivalence.\nThe dimension formulae may be viewed as a positive characteristic analogue of\nthe combinatorial character formulae for simple objects in parabolic category O\nfor $\\mathfrak{sl}_{m+2n}$, due to Lascoux and Schutzenberger.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sparse and Smooth Prior for Bayesian Linear Regression with Application to ETEX Data.   Sparsity of the solution of a linear regression model is a common\nrequirement, and many prior distributions have been designed for this purpose.\nA combination of the sparsity requirement with smoothness of the solution is\nalso common in application, however, with considerably fewer existing prior\nmodels. In this paper, we compare two prior structures, the Bayesian fused\nlasso (BFL) and least-squares with adaptive prior covariance matrix (LS-APC).\nSince only variational solution was published for the latter, we derive a Gibbs\nsampling algorithm for its inference and Bayesian model selection. The method\nis designed for high dimensional problems, therefore, we discuss numerical\nissues associated with evaluation of the posterior. In simulation, we show that\nthe LS-APC prior achieves results comparable to that of the Bayesian Fused\nLasso for piecewise constant parameter and outperforms the BFL for parameters\nof more general shapes. Another advantage of the LS-APC priors is revealed in\nreal application to estimation of the release profile of the European Tracer\nExperiment (ETEX). Specifically, the LS-APC model provides more conservative\nuncertainty bounds when the regressor matrix is not informative.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Preliminary Experiments using Subjective Logic for the Polyrepresentation of Information Needs.   According to the principle of polyrepresentation, retrieval accuracy may\nimprove through the combination of multiple and diverse information object\nrepresentations about e.g. the context of the user, the information sought, or\nthe retrieval system. Recently, the principle of polyrepresentation was\nmathematically expressed using subjective logic, where the potential\nsuitability of each representation for improving retrieval performance was\nformalised through degrees of belief and uncertainty. No experimental evidence\nor practical application has so far validated this model. We extend the work of\nLioma et al. (2010), by providing a practical application and analysis of the\nmodel. We show how to map the abstract notions of belief and uncertainty to\nreal-life evidence drawn from a retrieval dataset. We also show how to estimate\ntwo different types of polyrepresentation assuming either (a) independence or\n(b) dependence between the information objects that are combined. We focus on\nthe polyrepresentation of different types of context relating to user\ninformation needs (i.e. work task, user background knowledge, ideal answer) and\nshow that the subjective logic model can predict their optimal combination\nprior and independently to the retrieval process.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Malgrange Form and Fredholm Determinants.   We consider the factorization problem of matrix symbols relative to a closed\ncontour, i.e., a Riemann-Hilbert problem, where the symbol depends analytically\non parameters. We show how to define a function $\\tau$ which is locally\nanalytic on the space of deformations and that is expressed as a Fredholm\ndeterminant of an operator of \"integrable\" type in the sense of\nIts-Izergin-Korepin-Slavnov. The construction is not unique and the\nnon-uniqueness highlights the fact that the tau function is really the section\nof a line bundle.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Numerical studies of Thompson's group F and related groups.   We have developed polynomial-time algorithms to generate terms of the\ncogrowth series for groups $\\mathbb{Z}\\wr \\mathbb{Z},$ the lamplighter group,\n$(\\mathbb{Z}\\wr \\mathbb{Z})\\wr \\mathbb{Z}$ and the Navas-Brin group $B.$ We\nhave also given an improved algorithm for the coefficients of Thompson's group\n$F,$ giving 32 terms of the cogrowth series. We develop numerical techniques to\nextract the asymptotics of these various cogrowth series. We present improved\nrigorous lower bounds on the growth-rate of the cogrowth series for Thompson's\ngroup $F$ using the method from \\cite{HHR15} applied to our extended series. We\nalso generalise their method by showing that it applies to loops on any locally\nfinite graph. Unfortunately, lower bounds less than 16 do not help in\ndetermining amenability.\nAgain for Thompson's group $F$ we prove that, if the group is amenable, there\ncannot be a sub-dominant stretched exponential term in the\nasymptotics\\footnote{ }. Yet the numerical data provides compelling evidence\nfor the presence of such a term. This observation suggests a potential path to\na proof of non-amenability: If the universality class of the cogrowth sequence\ncan be determined rigorously, it will likely prove non-amenability.\nWe estimate the asymptotics of the cogrowth coefficients of $F$ to be $$ c_n\n\\sim c \\cdot \\mu^n \\cdot \\kappa^{n^\\sigma \\log^\\delta{n}} \\cdot n^g,$$ where\n$\\mu \\approx 15,$ $\\kappa \\approx 1/e,$ $\\sigma \\approx 1/2,$ $\\delta \\approx\n1/2,$ and $g \\approx -1.$ The growth constant $\\mu$ must be 16 for amenability.\nThese two approaches, plus a third based on extrapolating lower bounds, support\nthe conjecture \\cite{ERvR15, HHR15} that the group is not amenable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A three-dimensional symmetry result for a phase transition equation in the genuinely nonlocal regime.   We consider bounded solutions of the nonlocal Allen-Cahn equation $$\n(-\\Delta)^s u=u-u^3\\qquad{\\mbox{ in }}{\\mathbb{R}}^3,$$ under the monotonicity\ncondition $\\partial_{x_3}u>0$ and in the genuinely nonlocal regime in\nwhich~$s\\in\\left(0,\\frac12\\right)$. Under the limit assumptions $$\n\\lim_{x_n\\to-\\infty} u(x',x_n)=-1\\quad{\\mbox{ and }}\\quad \\lim_{x_n\\to+\\infty}\nu(x',x_n)=1,$$ it has been recently shown that~$u$ is necessarily $1$D, i.e. it\ndepends only on one Euclidean variable. The goal of this paper is to obtain a\nsimilar result without assuming such limit conditions. This type of results can\nbe seen as nonlocal counterparts of the celebrated conjecture formulated by\nEnnio De Giorgi.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Attentive Convolutional Neural Network based Speech Emotion Recognition: A Study on the Impact of Input Features, Signal Length, and Acted Speech.   Speech emotion recognition is an important and challenging task in the realm\nof human-computer interaction. Prior work proposed a variety of models and\nfeature sets for training a system. In this work, we conduct extensive\nexperiments using an attentive convolutional neural network with multi-view\nlearning objective function. We compare system performance using different\nlengths of the input signal, different types of acoustic features and different\ntypes of emotion speech (improvised/scripted). Our experimental results on the\nInteractive Emotional Motion Capture (IEMOCAP) database reveal that the\nrecognition performance strongly depends on the type of speech data independent\nof the choice of input features. Furthermore, we achieved state-of-the-art\nresults on the improvised speech data of IEMOCAP.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The role of local-geometrical-orders on the growth of dynamic-length-scales in glass-forming liquids.   The precise nature of complex structural relaxation as well as an explanation\nfor the precipitous growth of relaxation time in cooling glass-forming liquids\nare essential to the understanding of vitrification of liquids. The dramatic\nincrease of relaxation time is believed to be caused by the growth of one or\nmore correlation lengths, which has received much attention recently. Here, we\nreport a direct link between the growth of a specific local-geometrical-order\nand an increase of dynamic-length-scale as the atomic dynamics in metallic\nglass-forming liquids slow down. Although several types of local\ngeometrical-orders are present in these metallic liquids, the growth of\nicosahedral ordering is found to be directly related to the increase of the\ndynamic-length-scale. This finding suggests an intriguing scenario that the\ntransient icosahedral ordering could be the origin of the dynamic-length-scale\nin metallic glass-forming liquids.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Penalized Maximum Tangent Likelihood Estimation and Robust Variable Selection.   We introduce a new class of mean regression estimators -- penalized maximum\ntangent likelihood estimation -- for high-dimensional regression estimation and\nvariable selection. We first explain the motivations for the key ingredient,\nmaximum tangent likelihood estimation (MTE), and establish its asymptotic\nproperties. We further propose a penalized MTE for variable selection and show\nthat it is $\\sqrt{n}$-consistent, enjoys the oracle property. The proposed\nclass of estimators consists penalized $\\ell_2$ distance, penalized exponential\nsquared loss, penalized least trimmed square and penalized least square as\nspecial cases and can be regarded as a mixture of minimum Kullback-Leibler\ndistance estimation and minimum $\\ell_2$ distance estimation. Furthermore, we\nconsider the proposed class of estimators under the high-dimensional setting\nwhen the number of variables $d$ can grow exponentially with the sample size\n$n$, and show that the entire class of estimators (including the aforementioned\nspecial cases) can achieve the optimal rate of convergence in the order of\n$\\sqrt{\\ln(d)/n}$. Finally, simulation studies and real data analysis\ndemonstrate the advantages of the penalized MTE.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Utilizing artificial neural networks to predict demand for weather-sensitive products at retail stores.   One key requirement for effective supply chain management is the quality of\nits inventory management. Various inventory management methods are typically\nemployed for different types of products based on their demand patterns,\nproduct attributes, and supply network. In this paper, our goal is to develop\nrobust demand prediction methods for weather sensitive products at retail\nstores. We employ historical datasets from Walmart, whose customers and markets\nare often exposed to extreme weather events which can have a huge impact on\nsales regarding the affected stores and products. We want to accurately predict\nthe sales of 111 potentially weather-sensitive products around the time of\nmajor weather events at 45 of Walmart retails locations in the U.S.\nIntuitively, we may expect an uptick in the sales of umbrellas before a big\nthunderstorm, but it is difficult for replenishment managers to predict the\nlevel of inventory needed to avoid being out-of-stock or overstock during and\nafter that storm. While they rely on a variety of vendor tools to predict sales\naround extreme weather events, they mostly employ a time-consuming process that\nlacks a systematic measure of effectiveness. We employ all the methods critical\nto any analytics project and start with data exploration. Critical features are\nextracted from the raw historical dataset for demand forecasting accuracy and\nrobustness. In particular, we employ Artificial Neural Network for forecasting\ndemand for each product sold around the time of major weather events. Finally,\nwe evaluate our model to evaluate their accuracy and robustness.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Combinatorial Approach to the Opposite Bi-Free Partial $S$-Transform.   In this paper, we present a combinatorial approach to the opposite 2-variable\nbi-free partial $S$-transforms where the opposite multiplication is used on the\nright. In addition, extensions of this partial $S$-transforms to the\nconditional bi-free and operator-valued bi-free settings are discussed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Knowledge Engineering for Hybrid Deductive Databases.   Modern knowledge base systems frequently need to combine a collection of\ndatabases in different formats: e.g., relational databases, XML databases, rule\nbases, ontologies, etc. In the deductive database system DDBASE, we can manage\nthese different formats of knowledge and reason about them. Even the file\nsystems on different computers can be part of the knowledge base. Often, it is\nnecessary to handle different versions of a knowledge base. E.g., we might want\nto find out common parts or differences of two versions of a relational\ndatabase.\nWe will examine the use of abstractions of rule bases by predicate dependency\nand rule predicate graphs. Also the proof trees of derived atoms can help to\ncompare different versions of a rule base. Moreover, it might be possible to\nhave derivations joining rules with other formalisms of knowledge\nrepresentation.\nOntologies have shown their benefits in many applications of intelligent\nsystems, and there have been many proposals for rule languages compatible with\nthe semantic web stack, e.g., SWRL, the semantic web rule language. Recently,\nontologies are used in hybrid systems for specifying the provenance of the\ndifferent components.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interval-based Prediction Uncertainty Bound Computation in Learning with Missing Values.   The problem of machine learning with missing values is common in many areas.\nA simple approach is to first construct a dataset without missing values simply\nby discarding instances with missing entries or by imputing a fixed value for\neach missing entry, and then train a prediction model with the new dataset. A\ndrawback of this naive approach is that the uncertainty in the missing entries\nis not properly incorporated in the prediction. In order to evaluate prediction\nuncertainty, the multiple imputation (MI) approach has been studied, but the\nperformance of MI is sensitive to the choice of the probabilistic model of the\ntrue values in the missing entries, and the computational cost of MI is high\nbecause multiple models must be trained. In this paper, we propose an\nalternative approach called the Interval-based Prediction Uncertainty Bounding\n(IPUB) method. The IPUB method represents the uncertainties due to missing\nentries as intervals, and efficiently computes the lower and upper bounds of\nthe prediction results when all possible training sets constructed by imputing\narbitrary values in the intervals are considered. The IPUB method can be\napplied to a wide class of convex learning algorithms including penalized\nleast-squares regression, support vector machine (SVM), and logistic\nregression. We demonstrate the advantages of the IPUB method by comparing it\nwith an existing method in numerical experiment with benchmark datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning with Bounded Instance- and Label-dependent Label Noise.   Instance- and label-dependent label noise (ILN) is widely existed in\nreal-world datasets but has been rarely studied. In this paper, we focus on a\nparticular case of ILN where the label noise rates, representing the\nprobabilities that the true labels of examples flip into the corrupted labels,\nhave upper bounds. We propose to handle this bounded instance- and\nlabel-dependent label noise under two different conditions. First,\ntheoretically, we prove that when the marginal distributions $P(X|Y=+1)$ and\n$P(X|Y=-1)$ have non-overlapping supports, we can recover every noisy example's\ntrue label and perform supervised learning directly on the cleansed examples.\nSecond, for the overlapping situation, we propose a novel approach to learn a\nwell-performing classifier which needs only a few noisy examples to be labeled\nmanually. Experimental results demonstrate that our method works well on both\nsynthetic and real-world datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Estimation of Linear Functionals of Principal Components.   We study principal component analysis (PCA) for mean zero i.i.d. Gaussian\nobservations $X_1,\\dots, X_n$ in a separable Hilbert space $\\mathbb{H}$ with\nunknown covariance operator $\\Sigma.$ The complexity of the problem is\ncharacterized by its effective rank ${\\bf r}(\\Sigma):= \\frac{{\\rm\ntr}(\\Sigma)}{\\|\\Sigma\\|},$ where ${\\rm tr}(\\Sigma)$ denotes the trace of\n$\\Sigma$ and $\\|\\Sigma\\|$ denotes its operator norm. We develop a method of\nbias reduction in the problem of estimation of linear functionals of\neigenvectors of $\\Sigma.$ Under the assumption that ${\\bf r}(\\Sigma)=o(n),$ we\nestablish the asymptotic normality and asymptotic properties of the risk of the\nresulting estimators and prove matching minimax lower bounds, showing their\nsemi-parametric optimality.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Time-lagged autoencoders: Deep learning of slow collective variables for molecular kinetics.   Inspired by the success of deep learning techniques in the physical and\nchemical sciences, we apply a modification of an autoencoder type deep neural\nnetwork to the task of dimension reduction of molecular dynamics data. We can\nshow that our time-lagged autoencoder reliably finds low-dimensional embeddings\nfor high-dimensional feature spaces which capture the slow dynamics of the\nunderlying stochastic processes - beyond the capabilities of linear dimension\nreduction techniques.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Canonical sine and cosine Transforms For Integrable Boehmians.   In this paper we define canonical sine and cosine transform, convolution\noperations, prove convolution theorems in space of integrable functions on real\nspace. Further, obtain some results require to construct the spaces of\nintegrable Boehmians then extend this canonical sine and canonical cosine\ntransforms to space of integrable Boehmians and obtain their properties.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficiently Manifesting Asynchronous Programming Errors in Android Apps.   Android, the #1 mobile app framework, enforces the single-GUI-thread model,\nin which a single UI thread manages GUI rendering and event dispatching. Due to\nthis model, it is vital to avoid blocking the UI thread for responsiveness. One\ncommon practice is to offload long-running tasks into async threads. To achieve\nthis, Android provides various async programming constructs, and leaves\ndevelopers themselves to obey the rules implied by the model. However, as our\nstudy reveals, more than 25% apps violate these rules and introduce\nhard-to-detect, fail-stop errors, which we term as aysnc programming errors\n(APEs). To this end, this paper introduces APEChecker, a technique to\nautomatically and efficiently manifest APEs. The key idea is to characterize\nAPEs as specific fault patterns, and synergistically combine static analysis\nand dynamic UI exploration to detect and verify such errors. Among the 40\nreal-world Android apps, APEChecker unveils and processes 61 APEs, of which 51\nare confirmed (83.6% hit rate). Specifically, APEChecker detects 3X more APEs\nthan the state-of-art testing tools (Monkey, Sapienz and Stoat), and reduces\ntesting time from half an hour to a few minutes. On a specific type of APEs,\nAPEChecker confirms 5X more errors than the data race detection tool,\nEventRacer, with very few false alarms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Variational methods for degenerate Kirchhoff equations.   For a degenerate autonomous Kirchhoff equation which is set on $\\mathbb{R}^N$\nand involves the Berestycki-Lions type nonlinearity, we cope with the cases\n$N=2,3$ and $N\\geq5$ by using mountain pass and symmetric mountain pass\napproaches and by using Clark theorem respectively.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Reinforcement Learning with a Corrupted Reward Channel.   No real-world reward function is perfect. Sensory errors and software bugs\nmay result in RL agents observing higher (or lower) rewards than they should.\nFor example, a reinforcement learning agent may prefer states where a sensory\nerror gives it the maximum reward, but where the true reward is actually small.\nWe formalise this problem as a generalised Markov Decision Problem called\nCorrupt Reward MDP. Traditional RL methods fare poorly in CRMDPs, even under\nstrong simplifying assumptions and when trying to compensate for the possibly\ncorrupt rewards. Two ways around the problem are investigated. First, by giving\nthe agent richer data, such as in inverse reinforcement learning and\nsemi-supervised reinforcement learning, reward corruption stemming from\nsystematic sensory errors may sometimes be completely managed. Second, by using\nrandomisation to blunt the agent's optimisation, reward corruption can be\npartially managed under some assumptions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Crystal structure, site selectivity, and electronic structure of layered chalcogenide LaOBiPbS3.   We have investigated the crystal structure of LaOBiPbS3 using neutron\ndiffraction and synchrotron X-ray diffraction. From structural refinements, we\nfound that the two metal sites, occupied by Bi and Pb, were differently\nsurrounded by the sulfur atoms. Calculated bond valence sum suggested that one\nmetal site was nearly trivalent and the other was nearly divalent. Neutron\ndiffraction also revealed site selectivity of Bi and Pb in the LaOBiPbS3\nstructure. These results suggested that the crystal structure of LaOBiPbS3 can\nbe regarded as alternate stacks of the rock-salt-type Pb-rich sulfide layers\nand the LaOBiS2-type Bi-rich layers. From band calculations for an ideal\n(LaOBiS2)(PbS) system, we found that the S bands of the PbS layer were\nhybridized with the Bi bands of the BiS plane at around the Fermi energy, which\nresulted in the electronic characteristics different from that of LaOBiS2.\nStacking the rock-salt type sulfide (chalcogenide) layers and the BiS2-based\nlayered structure could be a new strategy to exploration of new BiS2-based\nlayered compounds, exotic two-dimensional electronic states, or novel\nfunctionality.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Second-order constrained variational problems on Lie algebroids: applications to optimal control.   The aim of this work is to study, from an intrinsic and geometric point of\nview, second-order constrained variational problems on Lie algebroids, that is,\noptimization problems defined by a cost functional which depends on\nhigher-order derivatives of admissible curves on a Lie algebroid. Extending the\nclassical Skinner and Rusk formalism for the mechanics in the context of Lie\nalgebroids, for second-order constrained mechanical systems, we derive the\ncorresponding dynamical equations. We find a symplectic Lie subalgebroid where,\nunder some mild regularity conditions, the second-order constrained variational\nproblem, seen as a presymplectic Hamiltonian system, has a unique solution. We\nstudy the relationship of this formalism with the second-order constrained\nEuler-Poincaré and Lagrange-Poincaré equations, among others. Our study is\napplied to the optimal control of mechanical systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Subset Synchronization in Monotonic Automata.   We study extremal and algorithmic questions of subset and careful\nsynchronization in monotonic automata. We show that several synchronization\nproblems that are hard in general automata can be solved in polynomial time in\nmonotonic automata, even without knowing a linear order of the states preserved\nby the transitions. We provide asymptotically tight bounds on the maximum\nlength of a shortest word synchronizing a subset of states in a monotonic\nautomaton and a shortest word carefully synchronizing a partial monotonic\nautomaton. We provide a complexity framework for dealing with problems for\nmonotonic weakly acyclic automata over a three-letter alphabet, and use it to\nprove NP-completeness and inapproximability of problems such as {\\sc Finite\nAutomata Intersection} and the problem of computing the rank of a subset of\nstates in this class. We also show that checking whether a monotonic partial\nautomaton over a four-letter alphabet is carefully synchronizing is NP-hard.\nFinally, we give a simple necessary and sufficient condition when a strongly\nconnected digraph with a selected subset of vertices can be transformed into a\ndeterministic automaton where the corresponding subset of states is\nsynchronizing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Closed almost-Kähler 4-manifolds of constant non-negative Hermitian holomorphic sectional curvature are Kähler.   We show that a closed almost Kähler 4-manifold of globally constant\nholomorphic sectional curvature $k\\geq 0$ with respect to the canonical\nHermitian connection is automatically Kähler. The same result holds for $k<0$\nif we require in addition that the Ricci curvature is J-invariant. The proofs\nare based on the observation that such manifolds are self-dual, so that\nChern-Weil theory implies useful integral formulas, which are then combined\nwith results from Seiberg--Witten theory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Trace Criterion for Kernel Bandwidth Selection for Support Vector Data Description.   Support vector data description (SVDD) is a popular anomaly detection\ntechnique. The SVDD classifier partitions the whole data space into an\n$\\textit{inlier}$ region, which consists of the region $\\textit{near}$ the\ntraining data, and an $\\textit{outlier}$ region, which consists of points\n$\\textit{away}$ from the training data. The computation of the SVDD classifier\nrequires a kernel function, for which the Gaussian kernel is a common choice.\nThe Gaussian kernel has a bandwidth parameter, and it is important to set the\nvalue of this parameter correctly for good results. A small bandwidth leads to\noverfitting such that the resulting SVDD classifier overestimates the number of\nanomalies, whereas a large bandwidth leads to underfitting and an inability to\ndetect many anomalies. In this paper, we present a new unsupervised method for\nselecting the Gaussian kernel bandwidth. Our method, which exploits the\nlow-rank representation of the kernel matrix to suggest a kernel bandwidth\nvalue, is competitive with existing bandwidth selection methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Dynamic Geometry of Interaction Machine: A Call-by-need Graph Rewriter.   Girard's Geometry of Interaction (GoI), a semantics designed for linear logic\nproofs, has been also successfully applied to programming language semantics.\nOne way is to use abstract machines that pass a token on a fixed graph along a\npath indicated by the GoI. These token-passing abstract machines are space\nefficient, because they handle duplicated computation by repeating the same\nmoves of a token on the fixed graph. Although they can be adapted to obtain\nsound models with regard to the equational theories of various evaluation\nstrategies for the lambda calculus, it can be at the expense of significant\ntime costs. In this paper we show a token-passing abstract machine that can\nimplement evaluation strategies for the lambda calculus, with certified time\nefficiency. Our abstract machine, called the Dynamic GoI Machine (DGoIM),\nrewrites the graph to avoid replicating computation, using the token to find\nthe redexes. The flexibility of interleaving token transitions and graph\nrewriting allows the DGoIM to balance the trade-off of space and time costs.\nThis paper shows that the DGoIM can implement call-by-need evaluation for the\nlambda calculus by using a strategy of interleaving token passing with as much\ngraph rewriting as possible. Our quantitative analysis confirms that the DGoIM\nwith this strategy of interleaving the two kinds of possible operations on\ngraphs can be classified as \"efficient\" following Accattoli's taxonomy of\nabstract machines.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "simode: R Package for statistical inference of ordinary differential equations using separable integral-matching.   In this paper we describe simode: Separable Integral Matching for Ordinary\nDifferential Equations. The statistical methodologies applied in the package\nfocus on several minimization procedures of an integral-matching criterion\nfunction, taking advantage of the mathematical structure of the differential\nequations like separability of parameters from equations. Application of\nintegral based methods to parameter estimation of ordinary differential\nequations was shown to yield more accurate and stable results comparing to\nderivative based ones. Linear features such as separability were shown to ease\noptimization and inference. We demonstrate the functionalities of the package\nusing various systems of ordinary differential equations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Electrode Reactions in Slowly Relaxing Media.   Standard models of reaction kinetics in condensed materials rely on the\nBoltzmann-Gibbs distribution for the population of reactants at the top of the\nfree energy barrier separating them from the products. While energy dissipation\nand quantum effects at the barrier top can potentially affect the transmission\ncoefficient entering the rate preexponential factor, much stronger dynamical\neffects on the reaction barrier are caused by the breakdown of ergodicity for\npopulating the reaction barrier (violation of the Boltzmann-Gibbs statistics).\nWhen the spectrum of medium modes coupled to the reaction coordinate includes\nfluctuations slower than the reaction rate, such nuclear motions dynamically\nfreeze on the reaction time-scale and do not contribute to the activation\nbarrier. Here we consider the consequences of this scenario for electrode\nreactions in slowly relaxing media. Changing electrode overpotential speeds\nelectrode electron transfer up, potentially cutting through the spectrum of\nnuclear modes coupled to the reaction coordinate. The reorganization energy of\nelectrochemical electron transfer becomes a function of the electrode\noverpotential, switching between the thermodynamic value at low rates to the\nnonergodic limit at higher rates. The sharpness of this transition depends of\nthe relaxation spectrum of the medium. The reorganization energy experiences a\nsudden drop with increasing overpotential for a medium with a Debye relaxation,\nbut becomes a much shallower function of the overpotential for media with\nstretched exponential dynamics. The latter scenario characterizes electron\ntransfer in ionic liquids. The analysis of electrode reactions in\nroom-temperature ionic liquids shows that the magnitude of the free energy of\nnuclear solvation is significantly below its thermodynamic limit.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Bäcklund Transformations for the Boussinesq Equation and Merging Solitons.   The Bäcklund transformation (BT) for the \"good\" Boussinesq equation and its\nsuperposition principles are presented and applied. Unlike many other standard\nintegrable equations, the Boussinesq equation does not have a strictly\nalgebraic superposition principle for 2 BTs, but it does for 3. We present\nassociated lattice systems. Applying the BT to the trivial solution generates\nstandard solitons but also what we call \"merging solitons\" --- solutions in\nwhich two solitary waves (with related speeds) merge into a single one. We use\nthe superposition principles to generate a variety of interesting solutions,\nincluding superpositions of a merging soliton with $1$ or $2$ regular solitons,\nand solutions that develop a singularity in finite time which then disappears\nat some later finite time. We prove a Wronskian formula for the solutions\nobtained by applying a general sequence of BTs on the trivial solution.\nFinally, we show how to obtain the standard conserved quantities of the\nBoussinesq equation from the BT, and how the hierarchy of local symmetries\nfollows in a simple manner from the superposition principle for 3 BTs.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Backward Monte-Carlo applied to muon transport.   We discuss a backward Monte-Carlo technique for muon transport problem, with\nemphasis on its application in muography. Backward Monte-Carlo allows exclusive\nsampling of a final state by reversing the simulation flow. In practice it can\nbe made analogous to an adjoint Monte-Carlo, though it is more versatile for\nmuon transport. A backward Monte-Carlo was implemented as a dedicated muon\ntransport library: PUMAS. It is shown for case studies relevant for muography\nimaging that the implementations of forward and backward Monte-Carlo schemes\nagree to better than 1%.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "SHINE: Signed Heterogeneous Information Network Embedding for Sentiment Link Prediction.   In online social networks people often express attitudes towards others,\nwhich forms massive sentiment links among users. Predicting the sign of\nsentiment links is a fundamental task in many areas such as personal\nadvertising and public opinion analysis. Previous works mainly focus on textual\nsentiment classification, however, text information can only disclose the \"tip\nof the iceberg\" about users' true opinions, of which the most are unobserved\nbut implied by other sources of information such as social relation and users'\nprofile. To address this problem, in this paper we investigate how to predict\npossibly existing sentiment links in the presence of heterogeneous information.\nFirst, due to the lack of explicit sentiment links in mainstream social\nnetworks, we establish a labeled heterogeneous sentiment dataset which consists\nof users' sentiment relation, social relation and profile knowledge by\nentity-level sentiment extraction method. Then we propose a novel and flexible\nend-to-end Signed Heterogeneous Information Network Embedding (SHINE) framework\nto extract users' latent representations from heterogeneous networks and\npredict the sign of unobserved sentiment links. SHINE utilizes multiple deep\nautoencoders to map each user into a low-dimension feature space while\npreserving the network structure. We demonstrate the superiority of SHINE over\nstate-of-the-art baselines on link prediction and node recommendation in two\nreal-world datasets. The experimental results also prove the efficacy of SHINE\nin cold start scenario.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning a Robust Society of Tracking Parts.   Object tracking is an essential task in computer vision that has been studied\nsince the early days of the field. Being able to follow objects that undergo\ndifferent transformations in the video sequence, including changes in scale,\nillumination, shape and occlusions, makes the problem extremely difficult. One\nof the real challenges is to keep track of the changes in objects appearance\nand not drift towards the background clutter. Different from previous\napproaches, we obtain robustness against background with a tracker model that\nis composed of many different parts. They are classifiers that respond at\ndifferent scales and locations. The tracker system functions as a society of\nparts, each having its own role and level of credibility. Reliable classifiers\ndecide the tracker's next move, while newcomers are first monitored before\ngaining the necessary level of reliability to participate in the decision\nprocess. Some parts that loose their consistency are rejected, while others\nthat show consistency for a sufficiently long time are promoted to permanent\nroles. The tracker system, as a whole, could also go through different phases,\nfrom the usual, normal functioning to states of weak agreement and even crisis.\nThe tracker system has different governing rules in each state. What truly\ndistinguishes our work from others is not necessarily the strength of\nindividual tracking parts, but the way in which they work together and build a\nstrong and robust organization. We also propose an efficient way to learn\nsimultaneously many tracking parts, with a single closed-form formulation. We\nobtain a fast and robust tracker with state of the art performance on the\nchallenging OTB50 dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Biplots for Multidimensional Scaled Projections.   Dimension reduction and visualization is a staple of data analytics. Methods\nsuch as Principal Component Analysis (PCA) and Multidimensional Scaling (MDS)\nprovide low dimensional (LD) projections of high dimensional (HD) data while\npreserving an HD relationship between observations. Traditional biplots assign\nmeaning to the LD space of a PCA projection by displaying LD axes for the\nattributes. These axes, however, are specific to the linear projection used in\nPCA. MDS projections, which allow for arbitrary stress and dissimilarity\nfunctions, require special care when labeling the LD space. We propose an\niterative scheme to plot an LD axis for each attribute based on the\nuser-specified stress and dissimilarity metrics. We discuss the details of our\ngeneral biplot methodology, its relationship with PCA-derived biplots, and\nprovide examples using real data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Channel surfaces in Lie sphere geometry.   We discuss channel surfaces in the context of Lie sphere geometry and\ncharacterise them as certain $\\Omega_{0}$-surfaces. Since $\\Omega_{0}$-surfaces\npossess a rich transformation theory, we study the behaviour of channel\nsurfaces under these transformations. Furthermore, by using certain Dupin\ncyclide congruences, we characterise Ribaucour pairs of channel surfaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling Game Avatar Synergy and Opposition through Embedding in Multiplayer Online Battle Arena Games.   Multiplayer Online Battle Arena (MOBA) games have received increasing\nworldwide popularity recently. In such games, players compete in teams against\neach other by controlling selected game avatars, each of which is designed with\ndifferent strengths and weaknesses. Intuitively, putting together game avatars\nthat complement each other (synergy) and suppress those of opponents\n(opposition) would result in a stronger team. In-depth understanding of synergy\nand opposition relationships among game avatars benefits player in making\ndecisions in game avatar drafting and gaining better prediction of match\nevents. However, due to intricate design and complex interactions between game\navatars, thorough understanding of their relationships is not a trivial task.\nIn this paper, we propose a latent variable model, namely Game Avatar\nEmbedding (GAE), to learn avatars' numerical representations which encode\nsynergy and opposition relationships between pairs of avatars. The merits of\nour model are twofold: (1) the captured synergy and opposition relationships\nare sensible to experienced human players' perception; (2) the learned\nnumerical representations of game avatars allow many important downstream\ntasks, such as similar avatar search, match outcome prediction, and avatar pick\nrecommender. To our best knowledge, no previous model is able to simultaneously\nsupport both features. Our quantitative and qualitative evaluations on real\nmatch data from three commercial MOBA games illustrate the benefits of our\nmodel.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Orientability of the moduli space of Spin(7)-instantons.   Let $(M,\\Omega)$ be a closed $8$-dimensional manifold equipped with a\ngenerically non-integrable $\\mathrm{Spin}(7)$-structure $\\Omega$. We prove that\nif $\\mathrm{Hom}(H^{3}(M,\\mathbb{Z}), \\mathbb{Z}_{2}) = 0$ then the moduli\nspace of irreducible $\\mathrm{Spin}(7)$-instantons on $(M,\\Omega)$ with gauge\ngroup $\\mathrm{SU}(r)$, $r\\geq 2$, is orientable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Secure and Reconfigurable Network Design for Critical Information Dissemination in the Internet of Battlefield Things (IoBT).   The Internet of things (IoT) is revolutionizing the management and control of\nautomated systems leading to a paradigm shift in areas such as smart homes,\nsmart cities, health care, transportation, etc. The IoT technology is also\nenvisioned to play an important role in improving the effectiveness of military\noperations in battlefields. The interconnection of combat equipment and other\nbattlefield resources for coordinated automated decisions is referred to as the\nInternet of battlefield things (IoBT). IoBT networks are significantly\ndifferent from traditional IoT networks due to the battlefield specific\nchallenges such as the absence of communication infrastructure, and the\nsusceptibility of devices to cyber and physical attacks. The combat efficiency\nand coordinated decision-making in war scenarios depends highly on real-time\ndata collection, which in turn relies on the connectivity of the network and\nthe information dissemination in the presence of adversaries. This work aims to\nbuild the theoretical foundations of designing secure and reconfigurable IoBT\nnetworks. Leveraging the theories of stochastic geometry and mathematical\nepidemiology, we develop an integrated framework to study the communication of\nmission-critical data among different types of network devices and consequently\ndesign the network in a cost effective manner.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On certain type of difference polynomials of meromorphic functions.   In this paper, we investigate zeros of difference polynomials of the form\n$f(z)^nH(z, f)-s(z)$, where $f(z)$ is a meromorphic function, $H(z, f)$ is a\ndifference polynomial of $f(z)$ and $s(z)$ is a small function. We first obtain\nsome inequalities for the relationship of the zero counting function of\n$f(z)^nH(z, f)-s(z)$ and the characteristic function and pole counting function\nof $f(z)$. Based on these inequalities, we establish some difference analogues\nof a classical result of Hayman for meromorphic functions. Some special cases\nare also investigated. These results improve previous findings.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Abundances in photoionized nebulae of the Local Group and nucleosynthesis of intermediate mass stars.   Photoionized nebulae, comprising HII regions and planetary nebulae, are\nexcellent laboratories to investigate the nucleosynthesis and chemical\nevolution of several elements in the Galaxy and other galaxies of the Local\nGroup. Our purpose in this investigation is threefold: (i) compare the\nabundances of HII regions and planetary nebulae in each system in order to\ninvestigate the differences derived from the age and origin of these objects,\n(ii) compare the chemical evolution in different systems, such as the Milky\nWay, the Magellanic Clouds, and other galaxies of the Local Group, and (iii)\ninvestigate to what extent the nucleosynthesis contributions from the\nprogenitor stars affect the observed abundances in planetary nebulae, which\nconstrains the nucleosynthesis of intermediate mass stars. We show that all\nobjects in the samples present similar trends concerning distance-independent\ncorrelations, and some constraints can be defined on the production of He and N\nby the PN progenitor stars.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On unique continuation for solutions of the Schr{ö}dinger equation on trees.   We prove that if a solution of the time-dependent Schr{ö}dinger equation on\nan homogeneous tree with bounded potential decays fast at two distinct times\nthen the solution is trivial. For the free Schr{ö}dinger operator, we use the\nspectral theory of the Laplacian and complex analysis and obtain a\ncharacterization of the initial conditions that lead to a sharp decay at any\ntime. We then use the recent spectral decomposition of the Schr{ö}dinger\noperator with compactly supported potential due to Colin de Verdi{è}rre and\nTurc to extend our results in the presence of such potentials. Finally, we use\nreal variable methods first introduced by Escauriaza, Kenig, Ponce and Vega to\nestablish a general sharp result in the case of bounded potentials.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Econometric Modeling of Regional Electricity Spot Prices in the Australian Market.   Wholesale electricity markets are increasingly integrated via high voltage\ninterconnectors, and inter-regional trade in electricity is growing. To model\nthis, we consider a spatial equilibrium model of price formation, where\nconstraints on inter-regional flows result in three distinct equilibria in\nprices. We use this to motivate an econometric model for the distribution of\nobserved electricity spot prices that captures many of their unique empirical\ncharacteristics. The econometric model features supply and inter-regional trade\ncost functions, which are estimated using Bayesian monotonic regression\nsmoothing methodology. A copula multivariate time series model is employed to\ncapture additional dependence -- both cross-sectional and serial-- in regional\nprices. The marginal distributions are nonparametric, with means given by the\nregression means. The model has the advantage of preserving the heavy\nright-hand tail in the predictive densities of price. We fit the model to\nhalf-hourly spot price data in the five interconnected regions of the\nAustralian national electricity market. The fitted model is then used to\nmeasure how both supply and price shocks in one region are transmitted to the\ndistribution of prices in all regions in subsequent periods. Finally, to\nvalidate our econometric model, we show that prices forecast using the proposed\nmodel compare favorably with those from some benchmark alternatives.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Central limit theorems for entropy-regularized optimal transport on finite spaces and statistical applications.   The notion of entropy-regularized optimal transport, also known as Sinkhorn\ndivergence, has recently gained popularity in machine learning and statistics,\nas it makes feasible the use of smoothed optimal transportation distances for\ndata analysis. The Sinkhorn divergence allows the fast computation of an\nentropically regularized Wasserstein distance between two probability\ndistributions supported on a finite metric space of (possibly) high-dimension.\nFor data sampled from one or two unknown probability distributions, we derive\nthe distributional limits of the empirical Sinkhorn divergence and its centered\nversion (Sinkhorn loss). We also propose a bootstrap procedure which allows to\nobtain new test statistics for measuring the discrepancies between multivariate\nprobability distributions. Our work is inspired by the results of Sommerfeld\nand Munk (2016) on the asymptotic distribution of empirical Wasserstein\ndistance on finite space using unregularized transportation costs. Incidentally\nwe also analyze the asymptotic distribution of entropy-regularized Wasserstein\ndistances when the regularization parameter tends to zero. Simulated and real\ndatasets are used to illustrate our approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The geometry of some generalized affine Springer fibers.   We study basic geometric properties of some group analogue of affine Springer\nfibers and compare with the classical Lie algebra affine Springer fibers. The\nmain purpose is to formulate a conjecture that relates the number of\nirreducible components of such varieties for a reductive group $G$ to certain\nweight multiplicities defined by the Langlands dual group $\\hat{G}$. We prove\nour conjecture in the case of unramified conjugacy class.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamic Rank Maximal Matchings.   We consider the problem of matching applicants to posts where applicants have\npreferences over posts. Thus the input to our problem is a bipartite graph G =\n(A U P,E), where A denotes a set of applicants, P is a set of posts, and there\nare ranks on edges which denote the preferences of applicants over posts. A\nmatching M in G is called rank-maximal if it matches the maximum number of\napplicants to their rank 1 posts, subject to this the maximum number of\napplicants to their rank 2 posts, and so on.\nWe consider this problem in a dynamic setting, where vertices and edges can\nbe added and deleted at any point. Let n and m be the number of vertices and\nedges in an instance G, and r be the maximum rank used by any rank-maximal\nmatching in G. We give a simple O(r(m+n))-time algorithm to update an existing\nrank-maximal matching under each of these changes. When r = o(n), this is\nfaster than recomputing a rank-maximal matching completely using a known\nalgorithm like that of Irving et al., which takes time O(min((r + n,\nr*sqrt(n))m).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stable components in the parameter plane of meromorphic functions of finite type.   We study the parameter planes of certain one-dimensional, dynamically-defined\nslices of holomorphic families of meromorphic transcendental maps of finite\ntype for which infinity is not an asymptotic value. Our planes are defined by\nconstraining the orbits of all but one of the asymptotic values. We study the\nstructure of the regions in the parameter plane where the dynamics have a free\nasymptotic value that is attracted to an attracting periodic orbit. The tangent\nfamily is an example that has been studied in detail, \\cite{KK}, and our goal\nis to understand in the general context of meromorphic functions to what extent\nthe structure one sees in parameter plane of the tangent family is generic.\nFor the analogous dynamically defined slices of parameter spaces for rational\nmaps, there are Mandelbrot-like components that have a unique {\\em center} that\ncan be used to give a combinatorial descripton of the components. No such\ncenter exists for our slices, no matter how carefully they are chosen. We can\nshow, however, that there is an analogous concept, a \"virtual\" center, that\nplays essentially the same role as a center would have. It lies on the boundary\nof the component and corresponds to a map for which there is a \"virtual cycle\",\nnamely, an iterate of the free asymptotic value that lands at a pole. These\nvirtual centers are dense in the bifurcation locus of our one-dimensional\nfamilies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modeling and Simulation of the Dynamics of the Quick Return Mechanism: A Bond Graph Approach.   This paper applies the multibond graph approach for rigid multibody systems\nto model the dynamics of general spatial mechanisms. The commonly used quick\nreturn mechanism which comprises of revolute as well as prismatic joints has\nbeen chosen as a representative example to demonstrate the application of this\ntechnique and its resulting advantages. In this work, the links of the quick\nreturn mechanism are modeled as rigid bodies. The rigid links are then coupled\nat the joints based on the nature of constraint. This alternative method of\nformulation of system dynamics, using Bond Graphs, offers a rich set of\nfeatures that include pictorial representation of the dynamics of translation\nand rotation for each link of the mechanism in the inertial frame,\nrepresentation and handling of constraints at the joints, depiction of\ncausality, obtaining dynamic reaction forces and moments at various locations\nin the mechanism and so on. Yet another advantage of this approach is that the\ncoding for simulation can be carried out directly from the Bond Graph in an\nalgorithmic manner, without deriving system equations. In this work, the\nprogram code for simulation is written in MATLAB. The vector and tensor\noperations are conveniently represented in MATLAB, resulting in a compact and\noptimized code. The simulation results are plotted and discussed in detail.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Comparison of forcing functions in magnetohydrodynamic turbulence.   Results are presented of direct numerical simulations of incompressible,\nhomogeneous magnetohydrodynamic turbulence without a mean magnetic field,\nsubject to different mechanical forcing functions commonly used in the\nliterature. Specifically, the forces are negative damping (which uses the\nlarge-scale velocity field as a forcing function), a nonhelical random force,\nand a nonhelical static sinusoidal force (analogous to helical ABC forcing).\nThe time evolution of the three ideal invariants (energy, magnetic helicity and\ncross helicity), the time-averaged energy spectra, the energy ratios and the\ndissipation ratios are examined. All three forcing functions produce\nqualitatively similar steady states with regards to the time evolution of the\nenergy and magnetic helicity. However, differences in the cross helicity\nevolution are observed, particularly in the case of the static sinusoidal\nmethod of energy injection. Indeed, an ensemble of sinusoidally-forced\nsimulations with identical parameters shows significant variations in the cross\nhelicity over long time periods, casting some doubt on the validity of the\nprinciple of ergodicity in systems in which the injection of helicity cannot be\ncontrolled. Cross helicity can unexpectedly enter the system through the\nforcing function and must be carefully monitored.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Warm dark matter and the ionization history of the Universe.   In warm dark matter scenarios structure formation is suppressed on small\nscales with respect to the cold dark matter case, reducing the number of\nlow-mass halos and the fraction of ionized gas at high redshifts and thus,\ndelaying reionization. This has an impact on the ionization history of the\nUniverse and measurements of the optical depth to reionization, of the\nevolution of the global fraction of ionized gas and of the thermal history of\nthe intergalactic medium, can be used to set constraints on the mass of the\ndark matter particle. However, the suppression of the fraction of ionized\nmedium in these scenarios can be partly compensated by varying other\nparameters, as the ionization efficiency or the minimum mass for which halos\ncan host star-forming galaxies. Here we use different data sets regarding the\nionization and thermal histories of the Universe and, taking into account the\ndegeneracies from several astrophysical parameters, we obtain a lower bound on\nthe mass of thermal warm dark matter candidates of $m_X > 1.3$ keV, or $m_s >\n5.5$ keV for the case of sterile neutrinos non-resonantly produced in the early\nUniverse, both at 90\\% confidence level.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Role of Skin Friction Drag during Flow-Induced Reconfiguration of a Flexible Thin Plate.   We investigate drag reduction due to the flow-induced reconfiguration of a\nflexible thin plate in presence of skin friction drag at low Reynolds Number.\nThe plate is subjected to a uniform free stream and is tethered at one end. We\nextend existing models in the literature to account for the skin friction drag.\nThe total drag on the plate with respect to a rigid upright plate decreases due\nto flow-induced reconfiguration and further reconfiguration increases the total\ndrag due to increase in skin friction drag. A critical value of Cauchy number\n($Ca$) exists at which the total drag on the plate with respect to a rigid\nupright plate is minimum at a given Reynolds number. The reconfigured shape of\nthe plate for this condition is unique, beyond which the total drag increases\non the plate even with reconfiguration. The ratio of the form drag coefficient\nfor an upright rigid plate and skin drag coefficient for a horizontal rigid\nplate ($\\lambda$) determines the critical Cauchy number ($Ca_{cr}$). We propose\nmodification in the drag scaling with free stream velocity ($F_{x}$ ${\\propto}$\n$U^{n}$) in presence of the skin friction drag. The following expressions of\n$n$ are found for $0.01 \\leq Re \\leq 1$, $n = 4/5 + {\\lambda}/5$ for 1 $\\leq$\n$Ca$ $<$ $Ca_{cr}$ and $n = 1 + {\\lambda}/5$ for $Ca_{cr} \\leq Ca \\leq 300$,\nwhere $Re$ is Reynolds number. We briefly discuss the combined effect of the\nskin friction drag and buoyancy on the drag reduction. An assessment of the\nfeasibility of experiments is presented in order to translate the present model\nto physical systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Variational Continual Learning.   This paper develops variational continual learning (VCL), a simple but\ngeneral framework for continual learning that fuses online variational\ninference (VI) and recent advances in Monte Carlo VI for neural networks. The\nframework can successfully train both deep discriminative models and deep\ngenerative models in complex continual learning settings where existing tasks\nevolve over time and entirely new tasks emerge. Experimental results show that\nVCL outperforms state-of-the-art continual learning methods on a variety of\ntasks, avoiding catastrophic forgetting in a fully automatic way.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Optimizing expected word error rate via sampling for speech recognition.   State-level minimum Bayes risk (sMBR) training has become the de facto\nstandard for sequence-level training of speech recognition acoustic models. It\nhas an elegant formulation using the expectation semiring, and gives large\nimprovements in word error rate (WER) over models trained solely using\ncross-entropy (CE) or connectionist temporal classification (CTC). sMBR\ntraining optimizes the expected number of frames at which the reference and\nhypothesized acoustic states differ. It may be preferable to optimize the\nexpected WER, but WER does not interact well with the expectation semiring, and\nprevious approaches based on computing expected WER exactly involve expanding\nthe lattices used during training. In this paper we show how to perform\noptimization of the expected WER by sampling paths from the lattices used\nduring conventional sMBR training. The gradient of the expected WER is itself\nan expectation, and so may be approximated using Monte Carlo sampling. We show\nexperimentally that optimizing WER during acoustic model training gives 5%\nrelative improvement in WER over a well-tuned sMBR baseline on a 2-channel\nquery recognition task (Google Home).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "How production networks amplify economic growth.   Technological improvement is the most important cause of long-term economic\ngrowth, but the factors that drive it are still not fully understood. In\nstandard growth models technology is treated in the aggregate, and a main goal\nhas been to understand how growth depends on factors such as knowledge\nproduction. But an economy can also be viewed as a network, in which producers\npurchase goods, convert them to new goods, and sell them to households or other\nproducers. Here we develop a simple theory that shows how the network\nproperties of an economy can amplify the effects of technological improvements\nas they propagate along chains of production. A key property of an industry is\nits output multiplier, which can be understood as the average number of\nproduction steps required to make a good. The model predicts that the output\nmultiplier of an industry predicts future changes in prices, and that the\naverage output multiplier of a country predicts future economic growth. We test\nthese predictions using data from the World Input Output Database and find\nresults in good agreement with the model. The results show how purely\nstructural properties of an economy, that have nothing to do with innovation or\nhuman creativity, can exert an important influence on long-term growth.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Bridging Static and Dynamic Program Analysis using Fuzzy Logic.   Static program analysis is used to summarize properties over all dynamic\nexecutions. In a unifying approach based on 3-valued logic properties are\neither assigned a definite value or unknown. But in summarizing a set of\nexecutions, a property is more accurately represented as being biased towards\ntrue, or towards false. Compilers use program analysis to determine benefit of\nan optimization. Since benefit (e.g., performance) is justified based on the\ncommon case understanding bias is essential in guiding the compiler.\nFurthermore, successful optimization also relies on understanding the quality\nof the information, i.e. the plausibility of the bias. If the quality of the\nstatic information is too low to form a decision we would like a mechanism that\nimproves dynamically.\nWe consider the problem of building such a reasoning framework and present\nthe fuzzy data-flow analysis. Our approach generalize previous work that use\n3-valued logic. We derive fuzzy extensions of data-flow analyses used by the\nlazy code motion optimization and unveil opportunities previous work would not\ndetect due to limited expressiveness. Furthermore we show how the results of\nour analysis can be used in an adaptive classifier that improve as the\napplication executes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effect of Meltdown and Spectre Patches on the Performance of HPC Applications.   In this work we examine how the updates addressing Meltdown and Spectre\nvulnerabilities impact the performance of HPC applications. To study this we\nuse the application kernel module of XDMoD to test the performance before and\nafter the application of the vulnerability patches. We tested the performance\ndifference for multiple application and benchmarks including: NWChem, NAMD,\nHPCC, IOR, MDTest and IMB. The results show that although some specific\nfunctions can have performance decreased by as much as 74%, the majority of\nindividual metrics indicates little to no decrease in performance. The\nreal-world applications show a 2-3% decrease in performance for single node\njobs and a 5-11% decrease for parallel multi node jobs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simulating Dirac models with ultracold atoms in optical lattices.   We present a general model allowing \"quantum simulation\" of one-dimensional\nDirac models with 2- and 4-component spinors using ultracold atoms in driven 1D\ntilted optical latices. The resulting Dirac physics is illustrated by one of\nits well-known manifestations, Zitterbewegung. This general model can be\nextended and applied with great flexibility to more complex situations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Hausdorff Measure: Lost in Translation.   In the present article we describe how one can define Hausdorff measure\nallowing empty elements in coverings, and using infinite countable coverings\nonly. In addition, we discuss how the use of different nonequivalent\ninterpretations of the notion \"countable set\", that is typical for classical\nand modern mathematics, may lead to contradictions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strong convergence rates of modified truncated EM method for stochastic differential equations.   Motivated by truncated EM method introduced by Mao (2015), a new explicit\nnumerical method named modified truncated Euler-Maruyama method is developed in\nthis paper. Strong convergence rates of the given numerical scheme to the exact\nsolutions to stochastic differential equations are investigated under given\nconditions in this paper. Compared with truncated EM method, the given\nnumerical simulation strongly converges to the exact solution at fixed time $T$\nand over a time interval $[0,T]$ under weaker sufficient conditions. Meanwhile,\nthe convergence rates are also obtained for both cases. Two examples are\nprovided to support our conclusions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Analytic Formula for Numbers of Restricted Partitions from Conformal Field Theory.   We study the correlators of irregular vertex operators in two-dimensional\nconformal field theory (CFT) in order to propose an exact analytic formula for\ncalculating numbers of partitions, that is:\n1) for given $N,k$, finding the total number $\\lambda(N|k)$ of length $k$\npartitions of $N$: $N=n_1+...+n_k;0<n_1\\leq{n_2}...\\leq{n_k}$.\n2) finding the total number $\\lambda(N)=\\sum_{k=1}^N\\lambda(N|k)$ of\npartitions of a natural number $N$\nWe propose an exact analytic expression for $\\lambda(N|k)$ by relating\ntwo-point short-distance correlation functions of irregular vertex operators in\n$c=1$ conformal field theory ( the form of the operators is established in this\npaper): with the first correlator counting the partitions in the upper\nhalf-plane and the second one obtained from the first correlator by conformal\ntransformations of the form $f(z)=h(z)e^{-{i\\over{z}}}$ where $h(z)$ is regular\nand non-vanishing at $z=0$. The final formula for $\\lambda(N|k)$ is given in\nterms of regularized ($\\epsilon$-ordered) finite series in the generalized\nhigher-derivative Schwarzians and incomplete Bell polynomials of the above\nconformal transformation at $z=i\\epsilon$ ($\\epsilon\\rightarrow{0}$)",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Continuous Measurement of an Atomic Current.   We are interested in dynamics of quantum many-body systems under continuous\nobservation, and its physical realizations involving cold atoms in lattices. In\nthe present work we focus on continuous measurement of atomic currents in\nlattice models, including the Hubbard model. We describe a Cavity QED setup,\nwhere measurement of a homodyne current provides a faithful representation of\nthe atomic current as a function of time. We employ the quantum optical\ndescription in terms of a diffusive stochastic Schrödinger equation to follow\nthe time evolution of the atomic system conditional to observing a given\nhomodyne current trajectory, thus accounting for the competition between the\nHamiltonian evolution and measurement back-action. As an illustration, we\ndiscuss minimal models of atomic dynamics and continuous current measurement on\nrings with synthetic gauge fields, involving both real space and synthetic\ndimension lattices (represented by internal atomic states). Finally, by `not\nreading' the current measurements the time evolution of the atomic system is\ngoverned by a master equation, where - depending on the microscopic details of\nour CQED setups - we effectively engineer a current coupling of our system to a\nquantum reservoir. This provides novel scenarios of dissipative dynamics\ngenerating `dark' pure quantum many-body states.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Behavior Revealed in Mobile Phone Usage Predicts Loan Repayment.   Many households in developing countries lack formal financial histories,\nmaking it difficult for banks to extend loans, and for potential borrowers to\nreceive them. However, many of these households have mobile phones, which\ngenerate rich data about behavior. This paper shows that behavioral signatures\nin mobile phone data predict loan default, using call records matched to loan\noutcomes. In a middle income South American country, individuals in the highest\nquintile of risk by our measure are 2.8 times more likely to default than those\nin the lowest quintile. On our sample of individuals with (thin) financial\nhistories, our method outperforms models using credit bureau information, both\nwithin time and when tested on a different time period. The method forms the\nbasis for new forms of lending that reach the unbanked.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Categorification of sign-skew-symmetric cluster algebras and some conjectures on g-vectors.   Using the unfolding method given in \\cite{HL}, we prove the conjectures on\nsign-coherence and a recurrence formula respectively of ${\\bf g}$-vectors for\nacyclic sign-skew-symmetric cluster algebras. As a following consequence, the\nconjecture is affirmed in the same case which states that the ${\\bf g}$-vectors\nof any cluster form a basis of $\\mathbb Z^n$. Also, the additive\ncategorification of an acyclic sign-skew-symmetric cluster algebra $\\mathcal\nA(\\Sigma)$ is given, which is realized as $(\\mathcal C^{\\widetilde Q},\\Gamma)$\nfor a Frobenius $2$-Calabi-Yau category $\\mathcal C^{\\widetilde Q}$ constructed\nfrom an unfolding $(Q,\\Gamma)$ of the acyclic exchange matrix $B$ of $\\mathcal\nA(\\Sigma)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topological thermal Hall effect due to Weyl magnons.   We present the first theoretical evidence of zero magnetic field topological\n(anomalous) thermal Hall effect due to Weyl magnons. Here, we consider Weyl\nmagnons in stacked noncoplanar frustrated kagomé antiferromagnets recently\nproposed by Owerre, [arXiv:1708.04240]. The Weyl magnons in this system result\nfrom macroscopically broken time-reversal symmetry by the scalar spin chirality\nof noncoplanar chiral spin textures. Most importantly, they come from the\nlowest excitation, therefore they can be easily observed experimentally at low\ntemperatures due to the population effect. Similar to electronic Weyl nodes\nclose to the Fermi energy, Weyl magnon nodes in the lowest excitation are the\nmost important. Indeed, we show that the topological (anomalous) thermal Hall\neffect in this system arises from nonvanishing Berry curvature due to Weyl\nmagnon nodes in the lowest excitation, and it depends on their distribution\n(distance) in momentum space. The present result paves the way to directly\nprobe low excitation Weyl magnons and macroscopically broken time-reversal\nsymmetry in three-dimensional frustrated magnets with the anomalous thermal\nHall effect.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Focusing on a Probability Element: Parameter Selection of Message Importance Measure in Big Data.   Message importance measure (MIM) is applicable to characterize the importance\nof information in the scenario of big data, similar to entropy in information\ntheory. In fact, MIM with a variable parameter can make an effect on the\ncharacterization of distribution. Furthermore, by choosing an appropriate\nparameter of MIM, it is possible to emphasize the message importance of a\ncertain probability element in a distribution. Therefore, parametric MIM can\nplay a vital role in anomaly detection of big data by focusing on probability\nof an anomalous event. In this paper, we propose a parameter selection method\nof MIM focusing on a probability element and then present its major properties.\nIn addition, we discuss the parameter selection with prior probability, and\ninvestigate the availability in a statistical processing model of big data for\nanomaly detection problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "SOI RF Switch for Wireless Sensor Network.   The objective of this research was to design a 0-5 GHz RF SOI switch, with\n0.18um power Jazz SOI technology by using Cadence software, for health care\napplications. This paper introduces the design of a RF switch implemented in\nshunt-series topology. An insertion loss of 0.906 dB and an isolation of 30.95\ndB were obtained at 5 GHz. The switch also achieved a third order distortion of\n53.05 dBm and 1 dB compression point reached 50.06dBm. The RF switch\nperformance meets the desired specification requirements.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Poisson--Gamma Dynamical Systems.   We introduce a new dynamical system for sequentially observed multivariate\ncount data. This model is based on the gamma--Poisson construction---a natural\nchoice for count data---and relies on a novel Bayesian nonparametric prior that\nties and shrinks the model parameters, thus avoiding overfitting. We present an\nefficient MCMC inference algorithm that advances recent work on augmentation\nschemes for inference in negative binomial models. Finally, we demonstrate the\nmodel's inductive bias using a variety of real-world data sets, showing that it\nexhibits superior predictive performance over other models and infers highly\ninterpretable latent structure.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Brownian forgery of statistical dependences.   The balance held by Brownian motion between temporal regularity and\nrandomness is embodied in a remarkable way by Levy's forgery of continuous\nfunctions. Here we describe how this property can be extended to forge\narbitrary dependences between two statistical systems, and then establish a new\nBrownian independence test based on fluctuating random paths. We also argue\nthat this result allows revisiting the theory of Brownian covariance from a\nphysical perspective and opens the possibility of engineering nonlinear\ncorrelation measures from more general functional integrals.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A more symmetric picture for Kasparov's KK-bifunctor.   For C*-algebras $A$ and $B$, we generalize the notion of a quasihomomorphism\nfrom $A$ to $B$, due to Cuntz, by considering quasihomomorphisms from some\nC*-algebra $C$ to $B$ such that $C$ surjects onto $A$, and the two maps forming\na quasihomomorphism agree on the kernel of this surjection. Under an additional\nassumption, the group of homotopy classes of such generalized\nquasihomomorphisms coincides with $KK(A,B)$. This makes the definition of\nKasparov's bifunctor slightly more symmetric and gives more flexibility for\nconstructing elements of $KK$-groups. These generalized quasihomomorphisms can\nbe viewed as pairs of maps directly from $A$ (instead of various $C$'s), but\nthese maps need not be $*$-homomorphisms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Semi-Supervised Generation with Cluster-aware Generative Models.   Deep generative models trained with large amounts of unlabelled data have\nproven to be powerful within the domain of unsupervised learning. Many real\nlife data sets contain a small amount of labelled data points, that are\ntypically disregarded when training generative models. We propose the\nCluster-aware Generative Model, that uses unlabelled information to infer a\nlatent representation that models the natural clustering of the data, and\nadditional labelled data points to refine this clustering. The generative\nperformances of the model significantly improve when labelled information is\nexploited, obtaining a log-likelihood of -79.38 nats on permutation invariant\nMNIST, while also achieving competitive semi-supervised classification\naccuracies. The model can also be trained fully unsupervised, and still improve\nthe log-likelihood performance with respect to related methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A trans-disciplinary review of deep learning research for water resources scientists.   Deep learning (DL), a new-generation of artificial neural network research,\nhas transformed industries, daily lives and various scientific disciplines in\nrecent years. DL represents significant progress in the ability of neural\nnetworks to automatically engineer problem-relevant features and capture highly\ncomplex data distributions. I argue that DL can help address several major new\nand old challenges facing research in water sciences such as\ninter-disciplinarity, data discoverability, hydrologic scaling, equifinality,\nand needs for parameter regionalization. This review paper is intended to\nprovide water resources scientists and hydrologists in particular with a simple\ntechnical overview, trans-disciplinary progress update, and a source of\ninspiration about the relevance of DL to water. The review reveals that various\nphysical and geoscientific disciplines have utilized DL to address data\nchallenges, improve efficiency, and gain scientific insights. DL is especially\nsuited for information extraction from image-like data and sequential data.\nTechniques and experiences presented in other disciplines are of high relevance\nto water research. Meanwhile, less noticed is that DL may also serve as a\nscientific exploratory tool. A new area termed 'AI neuroscience,' where\nscientists interpret the decision process of deep networks and derive insights,\nhas been born. This budding sub-discipline has demonstrated methods including\ncorrelation-based analysis, inversion of network-extracted features,\nreduced-order approximations by interpretable models, and attribution of\nnetwork decisions to inputs. Moreover, DL can also use data to condition\nneurons that mimic problem-specific fundamental organizing units, thus\nrevealing emergent behaviors of these units. Vast opportunities exist for DL to\npropel advances in water sciences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spin-Frustrated Pyrochlore Chains in the Volcanic Mineral Kamchatkite (KCu3OCl(SO4)2).   Search of new frustrated magnetic systems is of a significant importance for\nphysics studying the condensed matter. The platform for geometric frustration\nof magnetic systems can be provided by copper oxocentric tetrahedra (OCu4)\nforming the base of crystalline structures of copper minerals from Tolbachik\nvolcanos in Kamchatka. The present work was devoted to a new frustrated\nantiferromagnetic - kamchatkite (KCu3OCl(SO4)2). The calculation of the sign\nand strength of magnetic couplings in KCu3OCl(SO4)2 has been performed on the\nbasis of structural data by the phenomenological crystal chemistry method with\ntaking into account corrections on the Jahn-Teller orbital degeneracy of Cu2.\nIt has been established that kamchatkite (KCu3OCl(SO4)2) contains AFM\nspin-frustrated chains of the pyrochlore type composed of cone-sharing Cu4\ntetrahedra. Strong AFM intrachain and interchain couplings compete with each\nother. Frustration of magnetic couplings in tetrahedral chains is combined with\nthe presence of electric polarization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Koszul sign map.   We define a Koszul sign map encoding the Koszul sign convention. A\ncohomological interpretation is given.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Align and Copy: UZH at SIGMORPHON 2017 Shared Task for Morphological Reinflection.   This paper presents the submissions by the University of Zurich to the\nSIGMORPHON 2017 shared task on morphological reinflection. The task is to\npredict the inflected form given a lemma and a set of morpho-syntactic\nfeatures. We focus on neural network approaches that can tackle the task in a\nlimited-resource setting. As the transduction of the lemma into the inflected\nform is dominated by copying over lemma characters, we propose two recurrent\nneural network architectures with hard monotonic attention that are strong at\ncopying and, yet, substantially different in how they achieve this. The first\napproach is an encoder-decoder model with a copy mechanism. The second approach\nis a neural state-transition system over a set of explicit edit actions,\nincluding a designated COPY action. We experiment with character alignment and\nfind that naive, greedy alignment consistently produces strong results for some\nlanguages. Our best system combination is the overall winner of the SIGMORPHON\n2017 Shared Task 1 without external resources. At a setting with 100 training\nsamples, both our approaches, as ensembles of models, outperform the next best\ncompetitor.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Strain broadening of the 1042-nm zero-phonon line of the NV- center in diamond: a promising spectroscopic tool for defect tomography.   The negatively charged nitrogen-vacancy (NV-) center in diamond is a\npromising candidate for many quantum applications. Here, we examine the\nsplitting and broadening of the center's infrared (IR) zero-phonon line (ZPL).\nWe develop a model for these effects that accounts for the strain induced by\nphoto-dependent microscopic distributions of defects. We apply this model to\ninterpret observed variations of the IR ZPL shape with temperature and\nphotoexcitation conditions. We identify an anomalous temperature dependent\nbroadening mechanism and that defects other than the substitutional nitrogen\ncenter significantly contribute to strain broadening. The former conclusion\nsuggests the presence of a strong Jahn-Teller effect in the center's singlet\nlevels and the latter indicates that major sources of broadening are yet to be\nidentified. These conclusions have important implications for the understanding\nof the center and the engineering of diamond quantum devices. Finally, we\npropose that the IR ZPL can be used as a sensitive spectroscopic tool for\nprobing microscopic strain fields and performing defect tomography.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Generative Temporal Models with Memory.   We consider the general problem of modeling temporal data with long-range\ndependencies, wherein new observations are fully or partially predictable based\non temporally-distant, past observations. A sufficiently powerful temporal\nmodel should separate predictable elements of the sequence from unpredictable\nelements, express uncertainty about those unpredictable elements, and rapidly\nidentify novel elements that may help to predict the future. To create such\nmodels, we introduce Generative Temporal Models augmented with external memory\nsystems. They are developed within the variational inference framework, which\nprovides both a practical training methodology and methods to gain insight into\nthe models' operation. We show, on a range of problems with sparse, long-term\ntemporal dependencies, that these models store information from early in a\nsequence, and reuse this stored information efficiently. This allows them to\nperform substantially better than existing models based on well-known recurrent\nneural networks, like LSTMs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Optimal Algorithm for Online Unconstrained Submodular Maximization.   We consider a basic problem at the interface of two fundamental fields:\nsubmodular optimization and online learning. In the online unconstrained\nsubmodular maximization (online USM) problem, there is a universe\n$[n]=\\{1,2,...,n\\}$ and a sequence of $T$ nonnegative (not necessarily\nmonotone) submodular functions arrive over time. The goal is to design a\ncomputationally efficient online algorithm, which chooses a subset of $[n]$ at\neach time step as a function only of the past, such that the accumulated value\nof the chosen subsets is as close as possible to the maximum total value of a\nfixed subset in hindsight. Our main result is a polynomial-time no-$1/2$-regret\nalgorithm for this problem, meaning that for every sequence of nonnegative\nsubmodular functions, the algorithm's expected total value is at least $1/2$\ntimes that of the best subset in hindsight, up to an error term sublinear in\n$T$. The factor of $1/2$ cannot be improved upon by any polynomial-time online\nalgorithm when the submodular functions are presented as value oracles.\nPrevious work on the offline problem implies that picking a subset uniformly at\nrandom in each time step achieves zero $1/4$-regret.\nA byproduct of our techniques is an explicit subroutine for the two-experts\nproblem that has an unusually strong regret guarantee: the total value of its\nchoices is comparable to twice the total value of either expert on rounds it\ndid not pick that expert. This subroutine may be of independent interest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "$b$-symbol distance distribution of repeated-root cyclic codes.   Symbol-pair codes, introduced by Cassuto and Blaum [1], have been raised for\nsymbol-pair read channels. This new idea is motivated by the limitation of the\nreading process in high-density data storage technologies. Yaakobi et al. [8]\nintroduced codes for $b$-symbol read channels, where the read operation is\nperformed as a consecutive sequence of $b>2$ symbols. In this paper, we come up\nwith a method to compute the $b$-symbol-pair distance of two $n$-tuples, where\n$n$ is a positive integer. Also, we deal with the $b$-symbol-pair distances of\nsome kind of cyclic codes of length $p^e$ over $\\mathbb{F}_{p^m}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Homogeneous Kobayashi-hyperbolic manifolds with automorphism group of subcritical dimension.   We determine all connected homogeneous Kobayashi-hyperbolic manifolds of\ndimension $n\\ge 2$ whose holomorphic automorphism group has dimension $n^2-3$.\nThis result complements existing classifications for automorphism group\ndimension $n^2-2$ (which is in some sense critical) and greater.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Transforming Coroutining Logic Programs into Equivalent CHR Programs.   We extend a technique called Compiling Control. The technique transforms\ncoroutining logic programs into logic programs that, when executed under the\nstandard left-to-right selection rule (and not using any delay features) have\nthe same computational behavior as the coroutining program. In recent work, we\nrevised Compiling Control and reformulated it as an instance of Abstract\nConjunctive Partial Deduction. This work was mostly focused on the program\nanalysis performed in Compiling Control. In the current paper, we focus on the\nsynthesis of the transformed program. Instead of synthesizing a new logic\nprogram, we synthesize a CHR(Prolog) program which mimics the coroutining\nprogram. The synthesis to CHR yields programs containing only simplification\nrules, which are particularly amenable to certain static analysis techniques.\nThe programs are also more concise and readable and can be ported to CHR\nimplementations embedded in other languages than Prolog.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "MAT: A Multimodal Attentive Translator for Image Captioning.   In this work we formulate the problem of image captioning as a multimodal\ntranslation task. Analogous to machine translation, we present a\nsequence-to-sequence recurrent neural networks (RNN) model for image caption\ngeneration. Different from most existing work where the whole image is\nrepresented by convolutional neural network (CNN) feature, we propose to\nrepresent the input image as a sequence of detected objects which feeds as the\nsource sequence of the RNN model. In this way, the sequential representation of\nan image can be naturally translated to a sequence of words, as the target\nsequence of the RNN model. To represent the image in a sequential way, we\nextract the objects features in the image and arrange them in a order using\nconvolutional neural networks. To further leverage the visual information from\nthe encoded objects, a sequential attention layer is introduced to selectively\nattend to the objects that are related to generate corresponding words in the\nsentences. Extensive experiments are conducted to validate the proposed\napproach on popular benchmark dataset, i.e., MS COCO, and the proposed model\nsurpasses the state-of-the-art methods in all metrics following the dataset\nsplits of previous work. The proposed approach is also evaluated by the\nevaluation server of MS COCO captioning challenge, and achieves very\ncompetitive results, e.g., a CIDEr of 1.029 (c5) and 1.064 (c40).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discriminant analysis in small and large dimensions.   We study the distributional properties of the linear discriminant function\nunder the assumption of normality by comparing two groups with the same\ncovariance matrix but different mean vectors. A stochastic representation for\nthe discriminant function coefficients is derived which is then used to obtain\ntheir asymptotic distribution under the high-dimensional asymptotic regime. We\ninvestigate the performance of the classification analysis based on the\ndiscriminant function in both small and large dimensions. A stochastic\nrepresentation is established which allows to compute the error rate in an\nefficient way. We further compare the calculated error rate with the optimal\none obtained under the assumption that the covariance matrix and the two mean\nvectors are known. Finally, we present an analytical expression of the error\nrate calculated in the high-dimensional asymptotic regime. The finite-sample\nproperties of the derived theoretical results are assessed via an extensive\nMonte Carlo study.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Weak type operator Lipschitz and commutator estimates for commuting tuples.   Let $f: \\mathbb{R}^d \\to\\mathbb{R}$ be a Lipschitz function. If $B$ is a\nbounded self-adjoint operator and if $\\{A_k\\}_{k=1}^d$ are commuting bounded\nself-adjoint operators such that $[A_k,B]\\in L_1(H),$ then\n$$\\|[f(A_1,\\cdots,A_d),B]\\|_{1,\\infty}\\leq\nc(d)\\|\\nabla(f)\\|_{\\infty}\\max_{1\\leq k\\leq d}\\|[A_k,B]\\|_1,$$ where $c(d)$ is\na constant independent of $f$, $\\mathcal{M}$ and $A,B$ and\n$\\|\\cdot\\|_{1,\\infty}$ denotes the weak $L_1$-norm. If $\\{X_k\\}_{k=1}^d$\n(respectively, $\\{Y_k\\}_{k=1}^d$) are commuting bounded self-adjoint operators\nsuch that $X_k-Y_k\\in L_1(H),$ then\n$$\\|f(X_1,\\cdots,X_d)-f(Y_1,\\cdots,Y_d)\\|_{1,\\infty}\\leq\nc(d)\\|\\nabla(f)\\|_{\\infty}\\max_{1\\leq k\\leq d}\\|X_k-Y_k\\|_1.$$",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mechanisms for bacterial gliding motility on soft substrates.   The motility mechanism of certain rod-shaped bacteria has long been a\nmystery, since no external appendages are involved in their motion which is\nknown as gliding. However, the physical principles behind gliding motility\nstill remain poorly understood. Using myxobacteria as a canonical example of\nsuch organisms, we identify here the physical principles behind gliding\nmotility, and develop a theoretical model that predicts a two-regime behavior\nof the gliding speed as a function of the substrate stiffness. Our theory\ndescribes the elastic, viscous, and capillary interactions between the\nbacterial membrane carrying a traveling wave, the secreted slime acting as a\nlubricating film, and the substrate which we model as a soft solid. Defining\nthe myxobacterial gliding as the horizontal motion on the substrate under zero\nnet force, we find the two-regime behavior is due to two different mechanisms\nof motility thrust. On stiff substrates, the thrust arises from the bacterial\nshape deformations creating a flow of slime that exerts a pressure along the\nbacterial length. This pressure in conjunction with the bacterial shape\nprovides the necessary thrust for propulsion. However, we show that such a\nmechanism cannot lead to gliding on very soft substrates. Instead, we show that\ncapillary effects lead to the formation of a ridge at the slime-substrate-air\ninterface, which creates a thrust in the form of a localized pressure gradient\nat the tip of the bacteria. To test our theory, we perform experiments with\nisolated cells on agar substrates of varying stiffness and find the measured\ngliding speeds to be in good agreement with the predictions from our\nelasto-capillary-hydrodynamic model. The physical mechanisms reported here\nserve as an important step towards an accurate theory of friction and\nsubstrate-mediated interaction between bacteria in a swarm of cells\nproliferating in soft media.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear Modal Decoupling Based Power System Transient Stability Analysis.   Nonlinear modal decoupling (NMD) was recently proposed to nonlinearly\ntransform a multi-oscillator system into a number of decoupled oscillators\nwhich together behave the same as the original system in an extended\nneighborhood of the equilibrium. Each oscillator has just one degree of freedom\nand hence can easily be analyzed to infer the stability of the original system\nassociated with one electromechanical mode. As the first attempt of applying\nthe NMD methodology to realistic power system models, this paper proposes an\nNMD-based transient stability analysis approach. For a multi-machine power\nsystem, the approach first derives decoupled nonlinear oscillators by a\ncoordinates transformation, and then applies Lyapunov stability analysis to\noscillators to assess the stability of the original system. Nonlinear modal\ninteraction is also considered. The approach can be efficiently applied to a\nlarge-scale power grid by conducting NMD regarding only selected modes. Case\nstudies on a 3-machine 9-bus system and an NPCC 48-machine 140-bus system show\nthe potentials of the approach in transient stability analysis for\nmulti-machine systems.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Self-Calibration of Mobile Manipulator Kinematic and Sensor Extrinsic Parameters Through Contact-Based Interaction.   We present a novel approach for mobile manipulator self-calibration using\ncontact information. Our method, based on point cloud registration, is applied\nto estimate the extrinsic transform between a fixed vision sensor mounted on a\nmobile base and an end effector. Beyond sensor calibration, we demonstrate that\nthe method can be extended to include manipulator kinematic model parameters,\nwhich involves a non-rigid registration process. Our procedure uses on-board\nsensing exclusively and does not rely on any external measurement devices,\nfiducial markers, or calibration rigs. Further, it is fully automatic in the\ngeneral case. We experimentally validate the proposed method on a custom mobile\nmanipulator platform, and demonstrate centimetre-level post-calibration\naccuracy in positioning of the end effector using visual guidance only. We also\ndiscuss the stability properties of the registration algorithm, in order to\ndetermine the conditions under which calibration is possible.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Alpha-Divergences in Variational Dropout.   We investigate the use of alternative divergences to Kullback-Leibler (KL) in\nvariational inference(VI), based on the Variational Dropout \\cite{kingma2015}.\nStochastic gradient variational Bayes (SGVB) \\cite{aevb} is a general framework\nfor estimating the evidence lower bound (ELBO) in Variational Bayes. In this\nwork, we extend the SGVB estimator with using Alpha-Divergences, which are\nalternative to divergences to VI' KL objective. The Gaussian dropout can be\nseen as a local reparametrization trick of the SGVB objective. We extend the\nVariational Dropout to use alpha divergences for variational inference. Our\nresults compare $\\alpha$-divergence variational dropout with standard\nvariational dropout with correlated and uncorrelated weight noise. We show that\nthe $\\alpha$-divergence with $\\alpha \\rightarrow 1$ (or KL divergence) is still\na good measure for use in variational inference, in spite of the efficient use\nof Alpha-divergences for Dropout VI \\cite{Li17}. $\\alpha \\rightarrow 1$ can\nyield the lowest training error, and optimizes a good lower bound for the\nevidence lower bound (ELBO) among all values of the parameter $\\alpha \\in\n[0,\\infty)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Identifying Clickbait Posts on Social Media with an Ensemble of Linear Models.   The purpose of a clickbait is to make a link so appealing that people click\non it. However, the content of such articles is often not related to the title,\nshows poor quality, and at the end leaves the reader unsatisfied.\nTo help the readers, the organizers of the clickbait challenge\n(this http URL) asked the participants to build a machine\nlearning model for scoring articles with respect to their \"clickbaitness\".\nIn this paper we propose to solve the clickbait problem with an ensemble of\nLinear SVM models, and our approach was tested successfully in the challenge:\nit showed great performance of 0.036 MSE and ranked 3rd among all the solutions\nto the contest.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entanglement in topological systems.   These lecture notes on entanglement in topological systems are part of the\n48th IFF Spring School 2017 on Topological Matter: Topological Insulators,\nSkyrmions and Majoranas at the Forschungszentrum Juelich, Germany. They cover a\nshort discussion on topologically ordered phases and review the two main tools\navailable for detecting topological order - the entanglement entropy and the\nentanglement spectrum.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Operator algebraic approach to inverse and stability theorems for amenable groups.   We prove an inverse theorem for the Gowers $U^2$-norm for maps $G\\to\\mathcal\nM$ from an countable, discrete, amenable group $G$ into a von Neumann algebra\n$\\mathcal M$ equipped with an ultraweakly lower semi-continuous, unitarily\ninvariant (semi-)norm $\\Vert\\cdot\\Vert$. We use this result to prove a\nstability result for unitary-valued $\\varepsilon$-representations $G\\to\\mathcal\nU(\\mathcal M)$ with respect to $\\Vert\\cdot \\Vert$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Critical Vertices and Edges in $H$-free Graphs.   A vertex or edge in a graph is critical if its deletion reduces the chromatic\nnumber of the graph by 1. We consider the problems of deciding whether a graph\nhas a critical vertex or edge, respectively. We give a complexity dichotomy for\nboth problems restricted to $H$-free graphs, that is, graphs with no induced\nsubgraph isomorphic to $H$. Moreover, we show that an edge is critical if and\nonly if its contraction reduces the chromatic number by 1. Hence, we also\nobtain a complexity dichotomy for the problem of deciding if a graph has an\nedge whose contraction reduces the chromatic number by 1.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Depression and Self-Harm Risk Assessment in Online Forums.   Users suffering from mental health conditions often turn to online resources\nfor support, including specialized online support communities or general\ncommunities such as Twitter and Reddit. In this work, we present a neural\nframework for supporting and studying users in both types of communities. We\npropose methods for identifying posts in support communities that may indicate\na risk of self-harm, and demonstrate that our approach outperforms strong\npreviously proposed methods for identifying such posts. Self-harm is closely\nrelated to depression, which makes identifying depressed users on general\nforums a crucial related task. We introduce a large-scale general forum dataset\n(\"RSDD\") consisting of users with self-reported depression diagnoses matched\nwith control users. We show how our method can be applied to effectively\nidentify depressed users from their use of language alone. We demonstrate that\nour method outperforms strong baselines on this general forum dataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Interleaved Group Convolutions for Deep Neural Networks.   In this paper, we present a simple and modularized neural network\narchitecture, named interleaved group convolutional neural networks (IGCNets).\nThe main point lies in a novel building block, a pair of two successive\ninterleaved group convolutions: primary group convolution and secondary group\nconvolution. The two group convolutions are complementary: (i) the convolution\non each partition in primary group convolution is a spatial convolution, while\non each partition in secondary group convolution, the convolution is a\npoint-wise convolution; (ii) the channels in the same secondary partition come\nfrom different primary partitions. We discuss one representative advantage:\nWider than a regular convolution with the number of parameters and the\ncomputation complexity preserved. We also show that regular convolutions, group\nconvolution with summation fusion, and the Xception block are special cases of\ninterleaved group convolutions. Empirical results over standard benchmarks,\nCIFAR-$10$, CIFAR-$100$, SVHN and ImageNet demonstrate that our networks are\nmore efficient in using parameters and computation complexity with similar or\nhigher accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Group-Server Queues.   By analyzing energy-efficient management of data centers, this paper proposes\nand develops a class of interesting {\\it Group-Server Queues}, and establishes\ntwo representative group-server queues through loss networks and impatient\ncustomers, respectively. Furthermore, such two group-server queues are given\nmodel descriptions and necessary interpretation. Also, simple mathematical\ndiscussion is provided, and simulations are made to study the expected queue\nlengths, the expected sojourn times and the expected virtual service times. In\naddition, this paper also shows that this class of group-server queues are\noften encountered in many other practical areas including communication\nnetworks, manufacturing systems, transportation networks, financial networks\nand healthcare systems. Note that the group-server queues are always used to\ndesign effectively dynamic control mechanisms through regrouping and\nrecombining such many servers in a large-scale service system by means of, for\nexample, bilateral threshold control, and customers transfer to the buffer or\nserver groups. This leads to the large-scale service system that is divided\ninto several adaptive and self-organizing subsystems through scheduling of\nbatch customers and regrouping of service resources, which make the middle\nlayer of this service system more effectively managed and strengthened under a\ndynamic, real-time and even reward optimal framework. Based on this,\nperformance of such a large-scale service system may be improved greatly in\nterms of introducing and analyzing such group-server queues. Therefore, not\nonly analysis of group-server queues is regarded as a new interesting research\ndirection, but there also exists many theoretical challenges, basic\ndifficulties and open problems in the area of queueing networks.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entire holomorphic curves into projective spaces intersecting a generic hypersurface of high degree.   In this note, we establish the following Second Main Theorem type estimate\nfor every entire non-algebraically degenerate holomorphic curve\n$f\\colon\\mathbb{C}\\rightarrow\\mathbb{P}^n(\\mathbb{C})$, in present of a {\\sl\ngeneric} hypersuface $D\\subset\\mathbb{P}^n(\\mathbb{C})$ of sufficiently high\ndegree $d\\geq 15(5n+1)n^n$: \\[ T_f(r) \\leq \\,N_f^{[1]}(r,D) + O\\big(\\log T_f(r)\n+ \\log r \\big)\\parallel, \\] where $T_f(r)$ and $N_f^{[1]}(r,D)$ stand for the\norder function and the $1$-truncated counting function in Nevanlinna theory.\nThis inequality quantifies recent results on the logarithmic Green--Griffiths\nconjecture.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Edge Caching Scheme Considering the Tradeoff Between the Diversity and Redundancy of Cached Content.   Caching popular contents at the edge of cellular networks has been proposed\nto reduce the load, and hence the cost of backhaul links. It is significant to\ndecide which files should be cached and where to cache them. In this paper, we\npropose a distributed caching scheme considering the tradeoff between the\ndiversity and redundancy of base stations' cached contents. Whether it is\nbetter to cache the same or different contents in different base stations? To\nfind out this, we formulate an optimal redundancy caching problem. Our goal is\nto minimize the total transmission cost of the network, including cost within\nthe radio access network (RAN) and cost incurred by transmission to the core\nnetwork via backhaul links. The optimal redundancy ratio under given system\nconfiguration is obtained with adapted particle swarm optimization (PSO)\nalgorithm. We analyze the impact of important system parameters through\nMonte-Carlo simulation. Results show that the optimal redundancy ratio is\nmainly influenced by two parameters, which are the backhaul to RAN unit cost\nratio and the steepness of file popularity distribution. The total cost can be\nreduced by up to 54% at given unit cost ratio of backhaul to RAN when the\noptimal redundancy ratio is selected. Under typical file request pattern, the\nreduction amount can be up to 57%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Symplectic resolutions for Higgs moduli spaces.   In this paper, we study the algebraic symplectic geometry of the singular\nmoduli spaces of Higgs bundles of degree $0$ and rank $n$ on a compact Riemann\nsurface $X$ of genus $g$. In particular, we prove that such moduli spaces are\nsymplectic singularities, in the sense of Beauville [Bea00], and admit a\nprojective symplectic resolution if and only if $g=1$ or $(g, n)=(2,2)$. These\nresults are an application of a recent paper by Bellamy and Schedler [BS16] via\nthe so-called Isosingularity Theorem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sobolev GAN.   We propose a new Integral Probability Metric (IPM) between distributions: the\nSobolev IPM. The Sobolev IPM compares the mean discrepancy of two distributions\nfor functions (critic) restricted to a Sobolev ball defined with respect to a\ndominant measure $\\mu$. We show that the Sobolev IPM compares two distributions\nin high dimensions based on weighted conditional Cumulative Distribution\nFunctions (CDF) of each coordinate on a leave one out basis. The Dominant\nmeasure $\\mu$ plays a crucial role as it defines the support on which\nconditional CDFs are compared. Sobolev IPM can be seen as an extension of the\none dimensional Von-Mises Cramér statistics to high dimensional\ndistributions. We show how Sobolev IPM can be used to train Generative\nAdversarial Networks (GANs). We then exploit the intrinsic conditioning implied\nby Sobolev IPM in text generation. Finally we show that a variant of Sobolev\nGAN achieves competitive results in semi-supervised learning on CIFAR-10,\nthanks to the smoothness enforced on the critic by Sobolev GAN which relates to\nLaplacian regularization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Collaborative similarity analysis of multilayer developer-project bipartite network.   To understand the multiple relations between developers and projects on\nGitHub as a whole, we model them as a multilayer bipartite network and analyze\nthe degree distributions, the nearest neighbors' degree distributions and their\ncorrelations with degree, and the collaborative similarity distributions and\ntheir correlations with degree. Our results show that all degree distributions\nhave a power-law form, especially, the degree distribution of projects in\nwatching layer has double power-law form. Negative correlations between nearest\nneighbors' degree and degree for both developers and projects are observed in\nboth layers, exhibiting a disassortative mixing pattern. The collaborative\nsimilarity of both developers and projects negatively correlates with degree in\nwatching layer, while a positive correlations is observed for developers in\nforking layer and no obvious correlation is observed for projects in forking\nlayer.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Ultraslow fluctuations in the pseudogap states of HgBa$_{2}$CaCu$_{2}$O$_{6+d}$.   We report the transverse relaxation rates 1/$T_2$'s of the $^{63}$Cu nuclear\nspin-echo envelope for double-layer high-$T_c$ cuprate superconductors\nHgBa$_{2}$CaCu$_{2}$O$_{6+d}$ from underdoped to overdoped. The relaxation rate\n1/$T_{2L}$ of the exponential function (Lorentzian component) shows a peak at\n220$-$240 K in the underdoped ($T_c$ = 103 K) and the optimally doped ($T_c$ =\n127 K) samples but no peak in the overdoped ($T_c$ = 93 K) sample. The\nenhancement in 1/$T_{2L}$ suggests development of the zero frequency components\nof local field fluctuations. Ultraslow fluctuations are hidden in the pseudogap\nstates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Distributed Deep Transfer Learning by Basic Probability Assignment.   Transfer learning is a popular practice in deep neural networks, but\nfine-tuning of large number of parameters is a hard task due to the complex\nwiring of neurons between splitting layers and imbalance distributions of data\nin pretrained and transferred domains. The reconstruction of the original\nwiring for the target domain is a heavy burden due to the size of\ninterconnections across neurons. We propose a distributed scheme that tunes the\nconvolutional filters individually while backpropagates them jointly by means\nof basic probability assignment. Some of the most recent advances in evidence\ntheory show that in a vast variety of the imbalanced regimes, optimizing of\nsome proper objective functions derived from contingency matrices prevents\nbiases towards high-prior class distributions. Therefore, the original filters\nget gradually transferred based on individual contributions to overall\nperformance of the target domain. This largely reduces the expected complexity\nof transfer learning whilst highly improves precision. Our experiments on\nstandard benchmarks and scenarios confirm the consistent improvement of our\ndistributed deep transfer learning strategy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Twin-beam real-time position estimation of micro-objects in 3D.   Various optical methods for measuring positions of micro-objects in 3D have\nbeen reported in the literature. Nevertheless, majority of them are not\nsuitable for real-time operation, which is needed, for example, for feedback\nposition control. In this paper, we present a method for real-time estimation\nof the position of micro-objects in 3D; the method is based on twin-beam\nillumination and it requires only a very simple hardware setup whose essential\npart is a standard image sensor without any lens. Performance of the proposed\nmethod is tested during a micro-manipulation task in which the estimated\nposition served as a feedback for the controller. The experiments show that the\nestimate is accurate to within ~3 um in the lateral position and ~7 um in the\naxial distance with the refresh rate of 10 Hz. Although the experiments are\ndone using spherical objects, the presented method could be modified to handle\nnon-spherical objects as well.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Learning with Confident Examples: Rank Pruning for Robust Classification with Noisy Labels.   Noisy PN learning is the problem of binary classification when training\nexamples may be mislabeled (flipped) uniformly with noise rate rho1 for\npositive examples and rho0 for negative examples. We propose Rank Pruning (RP)\nto solve noisy PN learning and the open problem of estimating the noise rates,\ni.e. the fraction of wrong positive and negative labels. Unlike prior\nsolutions, RP is time-efficient and general, requiring O(T) for any\nunrestricted choice of probabilistic classifier with T fitting time. We prove\nRP has consistent noise estimation and equivalent expected risk as learning\nwith uncorrupted labels in ideal conditions, and derive closed-form solutions\nwhen conditions are non-ideal. RP achieves state-of-the-art noise estimation\nand F1, error, and AUC-PR for both MNIST and CIFAR datasets, regardless of the\namount of noise and performs similarly impressively when a large portion of\ntraining examples are noise drawn from a third distribution. To highlight, RP\nwith a CNN classifier can predict if an MNIST digit is a \"one\"or \"not\" with\nonly 0.25% error, and 0.46 error across all digits, even when 50% of positive\nexamples are mislabeled and 50% of observed positive labels are mislabeled\nnegative examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A fast algorithm for maximal propensity score matching.   We present a new algorithm which detects the maximal possible number of\nmatched disjoint pairs satisfying a given caliper when a bipartite matching is\ndone with respect to a scalar index (e.g., propensity score), and constructs a\ncorresponding matching. Variable width calipers are compatible with the\ntechnique, provided that the width of the caliper is a Lipschitz function of\nthe index. If the observations are ordered with respect to the index then the\nmatching needs $O(N)$ operations, where $N$ is the total number of subjects to\nbe matched. The case of 1-to-$n$ matching is also considered.\nWe offer also a new fast algorithm for optimal complete one-to-one matching\non a scalar index when the treatment and control groups are of the same size.\nThis allows us to improve greedy nearest neighbor matching on a scalar index.\nKeywords: propensity score matching, nearest neighbor matching, matching with\ncaliper, variable width caliper.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Graded components of Local cohomology modules II.   Let $A$ be a commutative Noetherian ring containing a field $K$ of\ncharacteristic zero and let $R= A[X_1, \\ldots, X_m]$. Consider $R$ as standard\ngraded with $°A=0$ and $°X_i=1$ for all $i$. We present a few results\nabout the behavior of the graded components of local cohomology modules\n$H_I^i(R)$ where $I$ is an arbitrary homogeneous ideal in $R$. We mostly\nrestrict our attention to the Vanishing, Tameness and Rigidity problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Network analyses of 4D genome datasets automate detection of community-scale gene structure and plasticity.   Chromosome conformation capture and Hi-C technologies provide gene-gene\nproximity datasets of stationary cells, revealing chromosome territories,\ntopologically associating domains, and chromosome topology. Imaging of tagged\nDNA sequences in live cells through the lac operator reporter system provides\ndynamic datasets of chromosomal loci. Chromosome modeling explores the\nmechanisms underlying 3D genome structure and dynamics. Here, we automate 4D\ngenome dataset analysis with network-based tools as an alternative to gene-gene\nproximity statistics and visual structure determination. Temporal network\nmodels and community detection algorithms are applied to 4D modeling of G1 in\nbudding yeast with transient crosslinking of $5 kb$ domains in the nucleolus,\nanalyzing datasets from four decades of transient binding timescales. Network\ntools detect and track transient gene communities (clusters) within the\nnucleolus, their size, number, persistence time, and frequency of gene\nexchanges. An optimal, weak binding affinity is revealed that maximizes\ncommunity-scale plasticity whereby large communities persist, frequently\nexchanging genes.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Kitting in the Wild through Online Domain Adaptation.   Technological developments call for increasing perception and action\ncapabilities of robots. Among other skills, vision systems that can adapt to\nany possible change in the working conditions are needed. Since these\nconditions are unpredictable, we need benchmarks which allow to assess the\ngeneralization and robustness capabilities of our visual recognition\nalgorithms. In this work we focus on robotic kitting in unconstrained\nscenarios. As a first contribution, we present a new visual dataset for the\nkitting task. Differently from standard object recognition datasets, we provide\nimages of the same objects acquired under various conditions where camera,\nillumination and background are changed. This novel dataset allows for testing\nthe robustness of robot visual recognition algorithms to a series of different\ndomain shifts both in isolation and unified. Our second contribution is a novel\nonline adaptation algorithm for deep models, based on batch-normalization\nlayers, which allows to continuously adapt a model to the current working\nconditions. Differently from standard domain adaptation algorithms, it does not\nrequire any image from the target domain at training time. We benchmark the\nperformance of the algorithm on the proposed dataset, showing its capability to\nfill the gap between the performances of a standard architecture and its\ncounterpart adapted offline to the given target domain.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Unifying the micro and macro properties of AGN feeding and feedback.   We unify the feeding and feedback of supermassive black holes with the global\nproperties of galaxies, groups, and clusters, by linking for the first time the\nphysical mechanical efficiency at the horizon and Mpc scale. The macro hot halo\nis tightly constrained by the absence of overheating and overcooling as probed\nby X-ray data and hydrodynamic simulations ($\\varepsilon_{\\rm BH} \\simeq$\n10$^{-3}\\, T_{\\rm x,7.4}$). The micro flow is shaped by general relativistic\neffects tracked by state-of-the-art GR-RMHD simulations ($\\varepsilon_\\bullet\n\\simeq$ 0.03). The SMBH properties are tied to the X-ray halo temperature\n$T_{\\rm x}$, or related cosmic scaling relation (as $L_{\\rm x}$). The model is\nminimally based on first principles, as conservation of energy and mass\nrecycling. The inflow occurs via chaotic cold accretion (CCA), the rain of cold\nclouds condensing out of the quenched cooling flow and recurrently funneled via\ninelastic collisions. Within 100s gravitational radii, the accretion energy is\ntransformed into ultrafast 10$^4$ km s$^{-1}$ outflows (UFOs) ejecting most of\nthe inflowing mass. At larger radii the energy-driven outflow entrains\nprogressively more mass: at roughly kpc scale, the velocities of the\nhot/warm/cold outflows are a few 10$^3$, 1000, 500 km s$^{-1}$, with median\nmass rates ~10, 100, several 100 M$_\\odot$ yr$^{-1}$, respectively. The unified\nCCA model is consistent with the observations of nuclear UFOs, and ionized,\nneutral, and molecular macro outflows. We provide step-by-step implementation\nfor subgrid simulations, (semi)analytic works, or observational interpretations\nwhich require self-regulated AGN feedback at coarse scales, avoiding the\na-posteriori fine-tuning of efficiencies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Does the Testing Level affect the Prevalence of Coincidental Correctness?.   Researchers have previously shown that Coincidental Correctness (CC) is\nprevalent; however, the benchmarks they used are considered inadequate\nnowadays. They have also recognized the negative impact of CC on the\neffectiveness of fault localization and testing. The aim of this paper is to\nstudy Coincidental Correctness, using more realistic code, mainly from the\nperspective of unit testing. This stems from the fact that the practice of unit\ntesting has grown tremendously in recent years due to the wide adoption of\nsoftware development processes, such as Test-Driven Development. We quantified\nthe presence of CC in unit testing using the Defects4J benchmark. This entailed\nmanually injecting two code checkers for each of the 395 defects in Defects4J:\n1) a weak checker that detects weak CC tests by monitoring whether the defect\nwas reached; and 2) a strong checker that detects strong CC tests by monitoring\nwhether the defect was reached and the program has transitioned into an\ninfectious state. We also conducted preliminary experiments (using Defects4J,\nNanoXML and JTidy) to assess the pervasiveness of CC at the unit testing level\nin comparison to that at the integration and system levels. Our study showed\nthat unit testing is not immune to CC, as it exhibited 7.2x more strong CC\ntests than failing tests and 8.3x more weak CC tests than failing tests.\nHowever, our preliminary results suggested that it might be less prone to CC\nthan integration testing and system testing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "O$^2$TD: (Near)-Optimal Off-Policy TD Learning.   Temporal difference learning and Residual Gradient methods are the most\nwidely used temporal difference based learning algorithms; however, it has been\nshown that none of their objective functions is optimal w.r.t approximating the\ntrue value function $V$. Two novel algorithms are proposed to approximate the\ntrue value function $V$. This paper makes the following contributions: (1) A\nbatch algorithm that can help find the approximate optimal off-policy\nprediction of the true value function $V$. (2) A linear computational cost (per\nstep) near-optimal algorithm that can learn from a collection of off-policy\nsamples. (3) A new perspective of the emphatic temporal difference learning\nwhich bridges the gap between off-policy optimality and off-policy stability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A new magnetic phase in the nickelate perovskite TlNiO$_3$.   The RNiO$_3$ perovskites are known to order antiferromagnetically below a\nmaterial-dependent Néel temperature $T_\\text{N}$. We report experimental\nevidence indicating the existence of a second magnetically-ordered phase in\nTlNiO$_3$ above $T_\\text{N} = 104$ K, obtained using nuclear magnetic resonance\nand muon spin rotation spectroscopy. The new phase, which persists up to a\ntemperature $T_\\text{N}^* = 202$ K, is suppressed by the application of an\nexternal magnetic field of approximately 1 T. It is not yet known if such a\nphase also exists in other perovskite nickelates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A wide field-of-view crossed Dragone optical system using the anamorphic aspherical surfaces.   A side-fed crossed Dragone telescope provides a wide field-of-view. This type\nof a telescope is commonly employed in the measurement of cosmic microwave\nbackground (CMB) polarization, which requires an image-space telecentric\ntelescope with a large focal plane over broadband coverage. We report the\ndesign of the wide field-of-view crossed Dragone optical system using the\nanamorphic aspherical surfaces with correction terms up to the 10th order. We\nachieved the Strehl ratio larger than 0.95 over 32 by 18 square degrees at 150\nGHz. This design is an image-space telecentric and fully diffraction-limited\nsystem below 400 GHz. We discuss the optical performance in the uniformity of\nthe axially symmetric point spread function and telecentricity over the\nfield-of-view. We also address the analysis to evaluate the polarization\nproperties, including the instrumental polarization, extinction rate, and\npolarization angle rotation. This work is a part of programs to design a\ncompact multi-color wide field-of-view telescope for LiteBIRD, which is a next\ngeneration CMB polarization satellite.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "DiVM: Model Checking with LLVM and Graph Memory.   In this paper, we introduce the concept of a virtual machine with\ngraph-organised memory as a versatile backend for both explicit-state and\nabstraction-driven verification of software. Our virtual machine uses the LLVM\nIR as its instruction set, enriched with a small set of hypercalls. We show\nthat the provided hypercalls are sufficient to implement a small operating\nsystem, which can then be linked with applications to provide a\nPOSIX-compatible verification environment. Finally, we demonstrate the\nviability of the approach through a comparison with a more\ntraditionally-designed LLVM model checker.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stellar population synthesis based modelling of the Milky Way using asteroseismology of dwarfs and subgiants from Kepler.   Early attempts to apply asteroseismology to study the Galaxy have already\nshown unexpected discrepancies for the mass distribution of stars between the\nGalactic models and the data; a result that is still unexplained. Here, we\nrevisit the analysis of the asteroseismic sample of dwarf and subgiant stars\nobserved by Kepler and investigate in detail the possible causes for the\nreported discrepancy. We investigate two models of the Milky Way based on\nstellar population synthesis, Galaxia and TRILEGAL. In agreement with previous\nresults, we find that TRILEGAL predicts more massive stars compared to Galaxia,\nand that TRILEGAL predicts too many blue stars compared to 2MASS observations.\nBoth models fail to match the distribution of the stellar sample in $(\\log\ng,T_{\\rm eff})$ space, pointing to inaccuracies in the models and/or the\nassumed selection function. When corrected for this mismatch in $(\\log g,T_{\\rm\neff})$ space, the mass distribution calculated by Galaxia is broader and the\nmean is shifted toward lower masses compared to that of the observed stars.\nThis behaviour is similar to what has been reported for the Kepler red giant\nsample. The shift between the mass distributions is equivalent to a change of\n2\\% in $\\nu_{\\rm max}$, which is within the current uncertainty in the\n$\\nu_{\\rm max}$ scaling relation. Applying corrections to the $\\Delta \\nu$\nscaling relation predicted by the stellar models makes the observed mass\ndistribution significantly narrower, but there is no change to the mean.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The fundamental factor of optical interference.   It has been widely accepted that electric field alone is the fundamental\nfactor for optical interference, since Wiener's experiments in 1890 proved that\nthe electric field plays such a dominant role. A group of experiments were\ndemonstrated against Wiener's experiments under the condition that the\ninterference fringes made by optical standing waves could have been\ndistinguished from the fringes of equal thickness between the inner surface of\nemulsion and the plane mirror used to build the optical standing waves. It was\nfound that the Bragg diffraction from the interference fringes formed by the\nstanding waves did not exist. This means optical standing waves did not blacken\nthe photographic emulsion, or the electric field did not play such a dominant\nrole. Therefore, instead of the electric-field energy density solely in\nproportion to the electric-field square, Energy Flux in Interference was\nproposed to represent the intensity of optical interference-field and approved\nin the derivation of equations for the interference. The derived equations\nindicate that both the electric-field vector and the magnetic-field vector are\nin phase and have equal amount of energy densities at the interference maxima\nof two light beams. Thus, the magnetic-field vector acts the same role as the\nelectric-field vector on light interacting with substance. The fundamental\nfactor of optical interference is electromagnetic energy flux densities rather\nthan electric-field alone, or the intensity of optical interference fringes\nshould be the energy flux density, not electric-field energy density.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Matrix divisors on Riemann surfaces and Lax operator algebras.   Matrix divisors are introduced in the work by A.Weil (1938) which is\nconsidered as a starting point of the theory of holomorphic vector bundles on\nRiemann surfaces. In this theory matrix divisors play the role similar to the\nrole of usual divisors in the theory of line bundles. Moreover, they provide\nexplicit coordinates (Tyurin parameters) in an open subset of the moduli space\nof stable vector bundles. These coordinates turned out to be helpful in\nintegration of soliton equations.\nWe would like to gain attention to one more relationship between matrix\ndivisors of vector G-bundles (where G is a complex semi-simple Lie group) and\nthe theory of integrable systems, namely to the relationship with Lax operator\nalgebras. The result we obtain can be briefly formulated as follows: the moduli\nspace of matrix divisors with certain discrete invariants and fixed support is\na homogeneous space. Its tangent space at the unit is naturally isomorphic to\nthe quotient space of M-operators by L-operators, both spaces essentially\ndefined by the same invariants (the result goes back to Krichever, 2001). We\ngive one more description of the same space in terms of root systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spitzer Secondary Eclipses of Qatar-1b.   Previous secondary eclipse observations of the hot Jupiter Qatar-1b in the Ks\nband suggest that it may have an unusually high day side temperature,\nindicative of minimal heat redistribution. There have also been indications\nthat the orbit may be slightly eccentric, possibly forced by another planet in\nthe system. We investigate the day side temperature and orbital eccentricity\nusing secondary eclipse observations with Spitzer. We observed the secondary\neclipse with Spitzer/IRAC in subarray mode, in both 3.6 and 4.5 micron\nwavelengths. We used pixel-level decorrelation to correct for Spitzer's\nintra-pixel sensitivity variations and thereby obtain accurate eclipse depths\nand central phases. Our 3.6 micron eclipse depth is 0.149 +/- 0.051% and the\n4.5 micron depth is 0.273 +/- 0.049%. Fitting a blackbody planet to our data\nand two recent Ks band eclipse depths indicates a brightness temperature of\n1506 +/- 71K. Comparison to model atmospheres for the planet indicates that its\ndegree of longitudinal heat redistribution is intermediate between fully\nuniform and day side only. The day side temperature of the planet is unlikely\nto be as high (1885K) as indicated by the ground-based eclipses in the Ks band,\nunless the planet's emergent spectrum deviates strongly from model atmosphere\npredictions. The average central phase for our Spitzer eclipses is 0.4984 +/-\n0.0017, yielding e cos(omega) = -0.0028 +/- 0.0027. Our results are consistent\nwith a circular orbit, and we constrain e cos(omega) much more strongly than\nhas been possible with previous observations.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Characterization and control of linear coupling using turn-by-turn beam position monitor data in storage rings.   We introduce a new application of measuring symplectic generators to\ncharacterize and control the linear betatron coupling in storage rings. From\nsynchronized and consecutive BPM (Beam Position Monitor) turn-by-turn (TbT)\nreadings, symplectic Lie generators describing the coupled linear dynamics are\nextracted. Four plane-crossing terms in the generators directly characterize\nthe coupling between the horizontal and the vertical planes. Coupling control\ncan be accomplished by utilizing the dependency of these plane-crossing terms\non skew quadrupoles. The method has been successfully demonstrated to reduce\nthe vertical effective emittance down to the diffraction limit in the newly\nconstructed National Synchrotron Light Source II (NSLS-II) storage ring. This\nmethod can be automatized to realize linear coupling feedback control with\nnegligible disturbance on machine operation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Data-Driven Framework for Assessing Cold Load Pick-up Demand in Service Restoration.   Cold load pick-up (CLPU) has been a critical concern to utilities.\nResearchers and industry practitioners have underlined the impact of CLPU on\ndistribution system design and service restoration. The recent large-scale\ndeployment of smart meters has provided the industry with a huge amount of data\nthat is highly granular, both temporally and spatially. In this paper, a\ndata-driven framework is proposed for assessing CLPU demand of residential\ncustomers using smart meter data. The proposed framework consists of two\ninterconnected layers: 1) At the feeder level, a nonlinear auto-regression\nmodel is applied to estimate the diversified demand during the system\nrestoration and calculate the CLPU demand ratio. 2) At the customer level,\nGaussian Mixture Models (GMM) and probabilistic reasoning are used to quantify\nthe CLPU demand increase. The proposed methodology has been verified using real\nsmart meter data and outage cases.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Thinking Fast and Slow with Deep Learning and Tree Search.   Sequential decision making problems, such as structured prediction, robotic\ncontrol, and game playing, require a combination of planning policies and\ngeneralisation of those plans. In this paper, we present Expert Iteration\n(ExIt), a novel reinforcement learning algorithm which decomposes the problem\ninto separate planning and generalisation tasks. Planning new policies is\nperformed by tree search, while a deep neural network generalises those plans.\nSubsequently, tree search is improved by using the neural network policy to\nguide search, increasing the strength of new plans. In contrast, standard deep\nReinforcement Learning algorithms rely on a neural network not only to\ngeneralise plans, but to discover them too. We show that ExIt outperforms\nREINFORCE for training a neural network to play the board game Hex, and our\nfinal tree search agent, trained tabula rasa, defeats MoHex 1.0, the most\nrecent Olympiad Champion player to be publicly released.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A General Algorithm to Calculate the Inverse Principal $p$-th Root of Symmetric Positive Definite Matrices.   We address the general mathematical problem of computing the inverse $p$-th\nroot of a given matrix in an efficient way. A new method to construct iteration\nfunctions that allow calculating arbitrary $p$-th roots and their inverses of\nsymmetric positive definite matrices is presented. We show that the order of\nconvergence is at least quadratic and that adaptively adjusting a parameter $q$\nalways leads to an even faster convergence. In this way, a better performance\nthan with previously known iteration schemes is achieved. The efficiency of the\niterative functions is demonstrated for various matrices with different\ndensities, condition numbers and spectral radii.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stability of a Volterra Integral Equation on Time Scales.   In this paper, we study Hyers-Ulam stability for integral equation of\nVolterra type in time scale setting. Moreover we study the stability of the\nconsidered equation in Hyers-Ulam-Rassias sense. Our technique depends on\nsuccessive approximation method, and we use time scale variant of induction\nprinciple to show that equation (1.1) is stable on unbounded domains in\nHyers-Ulam-Rassias sense.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Performance Analysis of MEC Approach for Haplotype Assembly.   The Minimum Error Correction (MEC) approach is used as a metric for\nreconstruction of haplotypes from NGS reads. In this paper, we show that the\nMEC may encounter with imprecise reconstructed haplotypes for some NGS devices.\nSpecifically, using mathematical derivations, we evaluate this approach for the\nSOLiD, Illumina, 454, Ion, Pacific BioSciences, Oxford Nanopore, and 10X\nGenomics devices. Our results reveal that the MEC yields inexact haplotypes for\nthe Illumina MiniSeq, 454 GS Junior+, Ion PGM 314, and Oxford Nanopore MK 1\nMinION.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Chaotic dynamics around cometary nuclei.   We apply a generalized Kepler map theory to describe the qualitative chaotic\ndynamics around cometary nuclei, based on accessible observational data for\nfive comets whose nuclei are well-documented to resemble dumb-bells. The sizes\nof chaotic zones around the nuclei and the Lyapunov times of the motion inside\nthese zones are estimated. In the case of Comet 1P/Halley, the circumnuclear\nchaotic zone seems to engulf an essential part of the Hill sphere, at least for\norbits of moderate to high eccentricity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Diversity of Abundance Patterns of Light Neutron-capture Elements in Very-metal-poor Stars.   We determine the abundances of neutron-capture elements from Sr to Eu for\nfive very-metal-poor stars (-3<[Fe/H]<-2) in the Milky Way halo to reveal the\norigin of light neutron-capture elements. Previous spectroscopic studies have\nshown evidence of at least two components in the r-process; one referred to as\nthe \"main r-process\" and the other as the \"weak r-process,\" which is mainly\nresponsible for producing heavy and light neutron-capture elements,\nrespectively. Observational studies of metal-poor stars suggest that there is a\nuniversal pattern in the main r-process, similar to the abundance pattern of\nthe r-process component of solar-system material. Still, it is uncertain\nwhether the abundance pattern of the weak r-process shows universality or\ndiversity, due to the sparseness of measured light neutron-capture elements. We\nhave detected the key elements, Mo, Ru, and Pd, in five target stars to give an\nanswer to this question. The abundance patterns of light neutron-capture\nelements from Sr to Pd suggest a diversity in the weak r-process. In\nparticular, scatter in the abundance ratio between Ru and Pd is significant\nwhen the abundance patterns are normalized at Zr. Our results are compared with\nthe elemental abundances predicted by nucleosynthesis models of supernovae with\nparameters such as electron fraction or proto-neutron-star mass, to investigate\nsources of such diversity in the abundance patterns of light neutron-capture\nelements. This paper presents that the variation in the abundances of observed\nstars can be explained with a small range of parameters, which can serve as\nconstraints on future modeling of supernova models.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multi-pass configuration for Improved Squeezed Vacuum Generation in Hot Rb Vapor.   We study a squeezed vacuum field generated in hot Rb vapor via the\npolarization self-rotation effect. Our previous experiments showed that the\namount of observed squeezing may be limited by the contamination of the\nsqueezed vacuum output with higher-order spatial modes, also generated inside\nthe cell. Here, we demonstrate that the squeezing can be improved by making the\nlight interact several times with a less dense atomic ensemble. With\noptimization of some parameters we can achieve up to -2.6 dB of squeezing in\nthe multi-pass case, which is 0.6 dB improvement compared to the single-pass\nexperimental configuration. Our results show that other than the optical depth\nof the medium, the spatial mode structure and cell configuration also affect\nthe squeezing level.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Pattern Search Multidimensional Scaling.   We present a novel view of nonlinear manifold learning using derivative-free\noptimization techniques. Specifically, we propose an extension of the classical\nmulti-dimensional scaling (MDS) method, where instead of performing gradient\ndescent, we sample and evaluate possible \"moves\" in a sphere of fixed radius\nfor each point in the embedded space. A fixed-point convergence guarantee can\nbe shown by formulating the proposed algorithm as an instance of General\nPattern Search (GPS) framework. Evaluation on both clean and noisy synthetic\ndatasets shows that pattern search MDS can accurately infer the intrinsic\ngeometry of manifolds embedded in high-dimensional spaces. Additionally,\nexperiments on real data, even under noisy conditions, demonstrate that the\nproposed pattern search MDS yields state-of-the-art results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On a method for constructing the Lax pairs for integrable models via quadratic ansatz.   A method for constructing the Lax pairs for nonlinear integrable models is\nsuggested. First we look for a nonlinear invariant manifold to the\nlinearization of the given equation. Examples show that such invariant manifold\ndoes exist and can effectively be found. Actually it is defined by a quadratic\nform. As a result we get a nonlinear Lax pair consisting of the linearized\nequation and the invariant manifold. Our second step consists of finding an\nappropriate change of the variables to linearize the found nonlinear Lax pair.\nThe desired change of the variables is again defined by a quadratic form. The\nmethod is illustrated by the well-known KdV equation and the modified Volterra\nchain. New Lax pairs are found. The formal asymptotic expansions for their\neigenfunctions are constructed around the singular values of the spectral\nparameter. By applying the method of the formal diagonalization to these Lax\npairs the infinite series of the local conservation laws are obtained for the\ncorresponding nonlinear models.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Mechanisms of near-surface structural evolution in nanocrystalline materials during sliding contact.   The wear-driven structural evolution of nanocrystalline Cu was simulated with\nmolecular dynamics under constant normal loads, followed by a quantitative\nanalysis. While the microstructure far away from the sliding contact remains\nunchanged, grain growth accompanied by partial dislocations and twin formation\nwas observed near the contact surface, with more rapid coarsening promoted by\nhigher applied normal loads. The structural evolution continues with increasing\nnumber of sliding cycles and eventually saturates to a stable distinct layer of\ncoarsened grains, separated from the finer matrix by a steep gradient in grain\nsize. The coarsening process is balanced by the rate of material removal when\nthe normal load is high enough. The observed structural evolution leads to an\nincrease in hardness and decrease in friction coefficient, which also saturate\nafter a number of sliding cycles. This work provides important mechanistic\nunderstanding of nanocrystalline wear, while also introducing a methodology for\natomistic simulations of cyclic wear damage under constant applied normal\nloads.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stochastic Gradient Descent: Going As Fast As Possible But Not Faster.   When applied to training deep neural networks, stochastic gradient descent\n(SGD) often incurs steady progression phases, interrupted by catastrophic\nepisodes in which loss and gradient norm explode. A possible mitigation of such\nevents is to slow down the learning process. This paper presents a novel\napproach to control the SGD learning rate, that uses two statistical tests. The\nfirst one, aimed at fast learning, compares the momentum of the normalized\ngradient vectors to that of random unit vectors and accordingly gracefully\nincreases or decreases the learning rate. The second one is a change point\ndetection test, aimed at the detection of catastrophic learning episodes; upon\nits triggering the learning rate is instantly halved. Both abilities of\nspeeding up and slowing down the learning rate allows the proposed approach,\ncalled SALeRA, to learn as fast as possible but not faster. Experiments on\nstandard benchmarks show that SALeRA performs well in practice, and compares\nfavorably to the state of the art.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the Azuma inequality in spaces of subgaussian of rank $p$ random variables.   For $p > 1$ let a function $\\varphi_p(x) = x^2/2$ if $|x|\\le 1$ and\n$\\varphi_p(x) = 1/p|x|^p -1/p + 1/2$ if $|x| > 1$. For a random variable $\\xi$\nlet $\\tau_{\\varphi_p}(\\xi)$ denote $\\inf\\{c\\ge 0 :\\;\n\\forall_{\\lambda\\in\\mathbb{R}}\\;\n\\ln\\mathbb{E}\\exp(\\lambda\\xi)\\le\\varphi_p(c\\lambda)\\}$; $\\tau_{\\varphi_p}$ is a\nnorm in a space $Sub_{\\varphi_p}(\\Omega) =\\{\\xi:\n\\; \\tau_{\\varphi_p}(\\xi) <\\infty\\}$ of $\\varphi_p$-subgaussian random\nvariables which we call {\\it subgaussian of rank $p$ random variables}. For $p\n= 2$ we have the classic subgaussian random variables. The Azuma inequality\ngives an estimate on the probability of the deviations of a zero-mean\nmartingale $(\\xi_n)_{n\\ge 0}$ with bounded increments from zero. In its classic\nform is assumed that $\\xi_0 = 0$. In this paper it is shown a version of the\nAzuma inequality under assumption that $\\xi_0$ is any subgaussian of rank $p$\nrandom variable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Can Neural Machine Translation be Improved with User Feedback?.   We present the first real-world application of methods for improving neural\nmachine translation (NMT) with human reinforcement, based on explicit and\nimplicit user feedback collected on the eBay e-commerce platform. Previous work\nhas been confined to simulation experiments, whereas in this paper we work with\nreal logged feedback for offline bandit learning of NMT parameters. We conduct\na thorough analysis of the available explicit user judgments---five-star\nratings of translation quality---and show that they are not reliable enough to\nyield significant improvements in bandit learning. In contrast, we successfully\nutilize implicit task-based feedback collected in a cross-lingual search task\nto improve task-specific and machine translation quality metrics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mutual Alignment Transfer Learning.   Training robots for operation in the real world is a complex, time consuming\nand potentially expensive task. Despite significant success of reinforcement\nlearning in games and simulations, research in real robot applications has not\nbeen able to match similar progress. While sample complexity can be reduced by\ntraining policies in simulation, such policies can perform sub-optimally on the\nreal platform given imperfect calibration of model dynamics. We present an\napproach -- supplemental to fine tuning on the real robot -- to further benefit\nfrom parallel access to a simulator during training and reduce sample\nrequirements on the real robot. The developed approach harnesses auxiliary\nrewards to guide the exploration for the real world agent based on the\nproficiency of the agent in simulation and vice versa. In this context, we\ndemonstrate empirically that the reciprocal alignment for both agents provides\nfurther benefit as the agent in simulation can adjust to optimize its behaviour\nfor states commonly visited by the real-world agent.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Ultraproducts of crossed product von Neumann algebras.   We study a relationship between the ultraproduct of a crossed product von\nNeumann algebra and the crossed product of an ultraproduct von Neumann algebra.\nAs an application, the continuous core of an ultraproduct von Neumann algebra\nis described.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bianchi type-II universe with wet dark fluid in General Theory of Relativity.   In this paper, dark energy models of the universe filled with wet dark fluid\nare constructed in the framework of LRS Bianchi type-II space-time in General\nTheory of Relativity. A new equation of state modeled on the equation of state\n$p$=$\\gamma(\\rho - \\rho_*)$, which can describe a liquid including water, is\nused. The exact solutions of Einstein's field equations are obtained in\nquadrature form and the models corresponding to the cases $\\gamma = 0$ and\n$\\gamma = 1$ are discussed in detail.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Wavefunction of the Collapsing Bose-Einstein Condensate.   Bose-Einstein condensates with tunable interatomic interactions have been\nstudied intensely in recent experiments. The investigation of the collapse of a\ncondensate following a sudden change in the nature of the interaction from\nrepulsive to attractive has led to the observation of a remnant condensate that\ndid not undergo further collapse. We suggest that this high-density remnant is\nin fact the absolute minimum of the energy, if the attractive atomic\ninteractions are nonlocal, and is therefore inherently stable. We show that a\nvariational trial function consisting of a superposition of two distinct\ngaussians is an accurate representation of the wavefunction of the ground state\nof the conventional local Gross-Pitaevskii field equation for an attractive\ncondensate and gives correctly the points of emergence of instability. We then\nuse such a superposition of two gaussians as a variational trial function in\norder to calculate the minima of the energy when it includes a nonlocal\ninteraction term. We use experimental data in order to study the long range of\nthe nonlocal interaction, showing that they agree very well with a\ndimensionally derived expression for this range.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "No iterated identities satisfied by all finite groups.   We show that there is no iterated identity satisfied by all finite groups.\nFor $w$ being a non-trivial word of length $l$, we show that there exists a\nfinite group $G$ of cardinality at most $\\exp(l^C)$ which does not satisfy the\niterated identity $w$. The proof uses the approach of Borisov and Sapir, who\nused dynamics of polynomial mappings for the proof of non residual finiteness\nof some groups.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sequential Neural Likelihood: Fast Likelihood-free Inference with Autoregressive Flows.   We present Sequential Neural Likelihood (SNL), a new method for Bayesian\ninference in simulator models, where the likelihood is intractable but\nsimulating data from the model is possible. SNL trains an autoregressive flow\non simulated data in order to learn a model of the likelihood in the region of\nhigh posterior density. A sequential training procedure guides simulations and\nreduces simulation cost by orders of magnitude. We show that SNL is more\nrobust, more accurate and requires less tuning than related neural-based\nmethods, and we discuss diagnostics for assessing calibration, convergence and\ngoodness-of-fit.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Randomized Composable Coresets for Matching and Vertex Cover.   A common approach for designing scalable algorithms for massive data sets is\nto distribute the computation across, say $k$, machines and process the data\nusing limited communication between them. A particularly appealing framework\nhere is the simultaneous communication model whereby each machine constructs a\nsmall representative summary of its own data and one obtains an\napproximate/exact solution from the union of the representative summaries. If\nthe representative summaries needed for a problem are small, then this results\nin a communication-efficient and round-optimal protocol. While many fundamental\ngraph problems admit efficient solutions in this model, two prominent problems\nare notably absent from the list of successes, namely, the maximum matching\nproblem and the minimum vertex cover problem. Indeed, it was shown recently\nthat for both these problems, even achieving a polylog$(n)$ approximation\nrequires essentially sending the entire input graph from each machine.\nThe main insight of our work is that the intractability of matching and\nvertex cover in the simultaneous communication model is inherently connected to\nan adversarial partitioning of the underlying graph across machines. We show\nthat when the underlying graph is randomly partitioned across machines, both\nthese problems admit randomized composable coresets of size $\\widetilde{O}(n)$\nthat yield an $\\widetilde{O}(1)$-approximate solution. This results in an\n$\\widetilde{O}(1)$-approximation simultaneous protocol for these problems with\n$\\widetilde{O}(nk)$ total communication when the input is randomly partitioned\nacross $k$ machines. We further prove the optimality of our results. Finally,\nby a standard application of composable coresets, our results also imply\nMapReduce algorithms with the same approximation guarantee in one or two rounds\nof communication",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structure of a Parabolic Partial Differential Equation on Graphs and Digital spaces. Solution of PDE on Digital Spaces: a Klein Bottle, a Projective Plane, a 4D Sphere and a Moebius Band.   This paper studies the structure of a parabolic partial differential equation\non graphs and digital n-dimensional manifolds, which are digital models of\ncontinuous n-manifolds. Conditions for the existence of solutions of equations\nare determined and investigated. Numerical solutions of the equation on a Klein\nbottle, a projective plane, a 4D sphere and a Moebius strip are presented.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Measuring the unmeasurable - a project of domestic violence risk prediction and management.   The prevention of domestic violence (DV) have aroused serious concerns in\nTaiwan because of the disparity between the increasing amount of reported DV\ncases that doubled over the past decade and the scarcity of social workers.\nAdditionally, a large amount of data was collected when social workers use the\npredominant case management approach to document case reports information.\nHowever, these data were not properly stored or organized.\nTo improve the efficiency of DV prevention and risk management, we worked\nwith Taipei City Government and utilized the 2015 data from its DV database to\nperform a spatial pattern analysis of the reports of DV cases to build a DV\nrisk map. However, during our map building process, the issue of confounding\nbias arose because we were not able to verify if reported cases truly reflected\nreal violence occurrence or were simply false reports from potential victim's\nneighbors. Therefore, we used the random forest method to build a repeat\nvictimization risk prediction model. The accuracy and F1-measure of our model\nwere 96.3% and 62.8%. This model helped social workers differentiate the risk\nlevel of new cases, which further reduced their major workload significantly.\nTo our knowledge, this is the first project that utilized machine learning in\nDV prevention. The research approach and results of this project not only can\nimprove DV prevention process, but also be applied to other social work or\ncriminal prevention areas.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Shape and Energy Consistent Pseudopotentials for Correlated Electron systems.   A method is developed for generating pseudopotentials for use in\ncorrelated-electron calculations. The paradigms of shape and energy consistency\nare combined and defined in terms of correlated-electron wave-functions. The\nresulting energy consistent correlated electron pseudopotentials (eCEPPs) are\nconstructed for H, Li--F, Sc--Fe, and Cu. Their accuracy is quantified by\ncomparing the relaxed molecular geometries and dissociation energies they\nprovide with all electron results, with all quantities evaluated using coupled\ncluster singles doubles and triples calculations. Errors inherent in the\npseudopotentials are also compared with those arising from a number of\napproximations commonly used with pseudopotentials. The eCEPPs provide a\nsignificant improvement in optimised geometries and dissociation energies for\nsmall molecules, with errors for the latter being an order-of-magnitude smaller\nthan for Hartree-Fock-based pseudopotentials available in the literature.\nGaussian basis sets are optimised for use with these pseudopotentials.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Estimation of lactate threshold with machine learning techniques in recreational runners.   Lactate threshold is considered an essential parameter when assessing\nperformance of elite and recreational runners and prescribing training\nintensities in endurance sports. However, the measurement of blood lactate\nconcentration requires expensive equipment and the extraction of blood samples,\nwhich are inconvenient for frequent monitoring. Furthermore, most recreational\nrunners do not have access to routine assessment of their physical fitness by\nthe aforementioned equipment so they are not able to calculate the lactate\nthreshold without resorting to an expensive and specialized centre. Therefore,\nthe main objective of this study is to create an intelligent system capable of\nestimating the lactate threshold of recreational athletes participating in\nendurance running sports. The solution here proposed is based on a machine\nlearning system which models the lactate evolution using recurrent neural\nnetworks and includes the proposal of standardization of the temporal axis as\nwell as a modification of the stratified sampling method. The results show that\nthe proposed system accurately estimates the lactate threshold of 89.52% of the\nathletes and its correlation with the experimentally measured lactate threshold\nis very high (R=0,89). Moreover, its behaviour with the test dataset is as good\nas with the training set, meaning that the generalization power of the model is\nhigh. Therefore, in this study a machine learning based system is proposed as\nalternative to the traditional invasive lactate threshold measurement tests for\nrecreational runners.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Throughput-Improving Control of Highways Facing Stochastic Perturbations.   In this article, we study the problem of controlling a highway segment facing\nstochastic perturbations, such as recurrent incidents and moving bottlenecks.\nTo model traffic flow under perturbations, we use the cell-transmission model\nwith Markovian capacities. The control inputs are: (i) the inflows that are\nsent to various on-ramps to the highway (for managing traffic demand), and (ii)\nthe priority levels assigned to the on-ramp traffic relative to the mainline\ntraffic (for allocating highway capacity). The objective is to maximize the\nthroughput while ensuring that on-ramp queues remain bounded in the long-run.\nWe develop a computational approach to solving this stability-constrained,\nthroughput-maximization problem. Firstly, we use the classical drift condition\nin stability analysis of Markov processes to derive a sufficient condition for\nboundedness of on-ramp queues. Secondly, we show that our control design\nproblem can be formulated as a mixed integer program with linear or bilinear\nconstraints, depending on the complexity of Lyapunov function involved in the\nstability condition. Finally, for specific types of capacity perturbations, we\nderive intuitive criteria for managing demand and/or selecting priority levels.\nThese criteria suggest that inflows and priority levels should be determined\nsimultaneously such that traffic queues are placed at locations that discharge\nqueues fast. We illustrate the performance benefits of these criteria through a\ncomputational study of a segment on Interstate 210 in California, USA.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Interference Removal for Un-coordinated Radar/Communication Co-existence.   Most existing approaches to co-existing communication/radar systems assume\nthat the radar and communication systems are coordinated, i.e., they share\ninformation, such as relative position, transmitted waveforms and channel\nstate. In this paper, we consider an un-coordinated scenario where a\ncommunication receiver is to operate in the presence of a number of radars, of\nwhich only a sub-set may be active, which poses the problem of estimating the\nactive waveforms and the relevant parameters thereof, so as to cancel them\nprior to demodulation. Two algorithms are proposed for such a joint waveform\nestimation/data demodulation problem, both exploiting sparsity of a proper\nrepresentation of the interference and of the vector containing the errors of\nthe data block, so as to implement an iterative joint interference removal/data\ndemodulation process. The former algorithm is based on classical on-grid\ncompressed sensing (CS), while the latter forces an atomic norm (AN)\nconstraint: in both cases the radar parameters and the communication\ndemodulation errors can be estimated by solving a convex problem. We also\npropose a way to improve the efficiency of the AN-based algorithm. The\nperformance of these algorithms are demonstrated through extensive simulations,\ntaking into account a variety of conditions concerning both the interferers and\nthe respective channel states.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tunable high-harmonic generation by chromatic focusing of few-cycle laser pulses.   In this work we study the impact of chromatic focusing of few-cycle laser\npulses on high-order harmonic generation (HHG) through analysis of the emitted\nextreme ultraviolet (XUV) radiation. Chromatic focusing is usually avoided in\nthe few-cycle regime, as the pulse spatio-temporal structure may be highly\ndistorted by the spatiotemporal aberrations. Here, however, we demonstrate it\nas an additional control parameter to modify the generated XUV radiation. We\npresent experiments where few-cycle pulses are focused by a singlet lens in a\nKr gas jet. The chromatic distribution of focal lengths allows us to tune HHG\nspectra by changing the relative singlet-target distance. Interestingly, we\nalso show that the degree of chromatic aberration needed to this control does\nnot degrade substantially the harmonic conversion efficiency, still allowing\nfor the generation of supercontinua with the chirped-pulse scheme, demonstrated\npreviously for achromatic focussing. We back up our experiments with\ntheoretical simulations reproducing the experimental HHG results depending on\ndiverse parameters (input pulse spectral phase, pulse duration, focus position)\nand proving that, under the considered parameters, the attosecond pulse train\nremains very similar to the achromatic case, even showing cases of isolated\nattosecond pulse generation for near single-cycle driving pulses.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Measuring the effects of Loop Quantum Cosmology in the CMB data.   In this Essay we investigate the observational signatures of Loop Quantum\nCosmology (LQC) in the CMB data. First, we concentrate on the dynamics of LQC\nand we provide the basic cosmological functions. We then obtain the power\nspectrum of scalar and tensor perturbations in order to study the performance\nof LQC against the latest CMB data. We find that LQC provides a robust\nprediction for the main slow-roll parameters, like the scalar spectral index\nand the tensor-to-scalar fluctuation ratio, which are in excellent agreement\nwithin $1\\sigma$ with the values recently measured by the Planck collaboration.\nThis result indicates that LQC can be seen as an alternative scenario with\nrespect to that of standard inflation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Model Averaging for Generalized Linear Model with Covariates that are Missing completely at Random.   In this paper, we consider the estimation of generalized linear models with\ncovariates that are missing completely at random. We propose a model averaging\nestimation method and prove that the corresponding model averaging estimator is\nasymptotically optimal under certain assumptions. Simulaiton results illustrate\nthat this method has better performance than other alternatives under most\nsituations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Exact Learning of Decision Trees from Membership Queries.   In this paper we study the adaptive learnability of decision trees of depth\nat most $d$ from membership queries. This has many applications in automated\nscientific discovery such as drugs development and software update problem.\nFeldman solves the problem in a randomized polynomial time algorithm that asks\n$\\tilde O(2^{2d})\\log n$ queries and Kushilevitz-Mansour in a deterministic\npolynomial time algorithm that asks $ 2^{18d+o(d)}\\log n$ queries. We improve\nthe query complexity of both algorithms. We give a randomized polynomial time\nalgorithm that asks $\\tilde O(2^{2d}) + 2^{d}\\log n$ queries and a\ndeterministic polynomial time algorithm that asks $2^{5.83d}+2^{2d+o(d)}\\log n$\nqueries.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Entity Linking for Queries by Searching Wikipedia Sentences.   We present a simple yet effective approach for linking entities in queries.\nThe key idea is to search sentences similar to a query from Wikipedia articles\nand directly use the human-annotated entities in the similar sentences as\ncandidate entities for the query. Then, we employ a rich set of features, such\nas link-probability, context-matching, word embeddings, and relatedness among\ncandidate entities as well as their related entities, to rank the candidates\nunder a regression based framework. The advantages of our approach lie in two\naspects, which contribute to the ranking process and final linking result.\nFirst, it can greatly reduce the number of candidate entities by filtering out\nirrelevant entities with the words in the query. Second, we can obtain the\nquery sensitive prior probability in addition to the static link-probability\nderived from all Wikipedia articles. We conduct experiments on two benchmark\ndatasets on entity linking for queries, namely the ERD14 dataset and the GERDAQ\ndataset. Experimental results show that our method outperforms state-of-the-art\nsystems and yields 75.0% in F1 on the ERD14 dataset and 56.9% on the GERDAQ\ndataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Covering Groups of Nonconnected Topological Groups and 2-Groups.   We investigate the universal cover of a topological group that is not\nnecessarily connected. Its existence as a topological group is governed by a\nTaylor cocycle, an obstruction in 3-cohomology. Alternatively, it always exists\nas a topological 2-group. The splitness of this 2-group is also governed by an\nobstruction in 3-cohomology, a Sinh cocycle. We give explicit formulas for both\nobstructions and show that they are inverse of each other.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dirac operators with $W^{1,\\infty}$-potential under codimension one collapse.   We study the behavior of the spectrum of the Dirac operator together with a\nsymmetric $W^{1, \\infty}$-potential on spin manifolds under a collapse of\ncodimension one with bounded sectional curvature and diameter. If there is an\ninduced spin structure on the limit space $N$ then there are convergent\neigenvalues which converge to the spectrum of a first order differential\noperator $D$ on $N$ together with a symmetric $W^{1,\\infty}$-potential. If $N$\nis orientable and the dimension of the limit space is even then $D$ is the\nDirac operator $D^N$ on $N$ and if the dimension of the limit space is odd,\nthen $D = D^N \\oplus -D^N$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Twitter and the Press: an Ego-Centred Analysis.   Ego networks have proved to be a valuable tool for understanding the\nrelationships that individuals establish with their peers, both in offline and\nonline social networks. Particularly interesting are the cognitive constraints\nassociated with the interactions between the ego and the members of their ego\nnetwork, whereby individuals cannot maintain meaningful interactions with more\nthan 150 people, on average. In this work, we focus on the ego networks of\njournalists on Twitter, and we investigate whether they feature the same\ncharacteristics observed for other relevant classes of Twitter users, like\npoliticians and generic users. Our findings are that journalists are generally\nmore active and interact with more people than generic users. Their ego network\nstructure is very aligned with reference models derived from the social brain\nhypothesis and observed in general human ego networks. Remarkably, the\nsimilarity is even higher than the one of politicians and generic users ego\nnetworks. This may imply a greater cognitive involvement with Twitter than with\nother social interaction means. Moreover, the ego networks of journalists are\nmuch stabler than those of politicians and generic users, and the ego-alter\nties are often information-driven.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The affine approach to homogeneous geodesics in homogeneous Finsler spaces.   In a recent paper, it was claimed that any homogeneous Finsler space of odd\ndimension admits a homogeneous geodesic through any point. For the proof, the\nalgebraic method dealing with the reductive decomposition of the Lie algebra of\nthe isometry group was used. However, the proof contains a serious gap. In the\npresent paper, homogeneous geodesics in Finsler homogeneous spaces are studied\nusing the affine method, which was developed in earlier papers by the author.\nThe mentioned statement is proved correctly and it is further proved that any\nhomogeneous Berwald space or homogeneous reversible Finsler space admits a\nhomogeneous geodesic through any point.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Indoor Frame Recovery from Refined Line Segments.   An important yet challenging problem in understanding indoor scene is\nrecovering indoor frame structure from a monocular image. It is more difficult\nwhen occlusions and illumination vary, and object boundaries are weak. To\novercome these difficulties, a new approach based on line segment refinement\nwith two constraints is proposed. First, the line segments are refined by four\nconsecutive operations, i.e., reclassifying, connecting, fitting, and voting.\nSpecifically, misclassified line segments are revised by the reclassifying\noperation, some short line segments are joined by the connecting operation, the\nundetected key line segments are recovered by the fitting operation with the\nhelp of the vanishing points, the line segments converging on the frame are\nselected by the voting operation. Second, we construct four frame models\naccording to four classes of possible shooting angles of the monocular image,\nthe natures of all frame models are introduced via enforcing the cross ratio\nand depth constraints. The indoor frame is then constructed by fitting those\nrefined line segments with related frame model under the two constraints, which\njointly advance the accuracy of the frame. Experimental results on a collection\nof over 300 indoor images indicate that our algorithm has the capability of\nrecovering the frame from complex indoor scenes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust reputation-based ranking on multipartite rating networks.   The spread of online reviews, ratings and opinions and its growing influence\non people's behavior and decisions boosted the interest to extract meaningful\ninformation from this data deluge. Hence, crowdsourced ratings of products and\nservices gained a critical role in business, governments, and others. We\npropose a new reputation-based ranking system utilizing multipartite rating\nsubnetworks, that clusters users by their similarities, using Kolmogorov\ncomplexity. Our system is novel in that it reflects a diversity of\nopinions/preferences by assigning possibly distinct rankings, for the same\nitem, for different groups of users. We prove the convergence and efficiency of\nthe system and show that it copes better with spamming/spurious users, and it\nis more robust to attacks than state-of-the-art approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Free constructions and coproducts of d-frames.   A general theory of presentations for d-frames does not yet exist. We review\nthe difficulties and give sufficient conditions for when they can be overcome.\nAs an application we prove that the category of d-frames is closed under\ncoproducts.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lions' formula for RKHSs of real harmonic functions on Lipschitz domains.   Let $ \\Omega$ be a bounded Lipschitz domain of $ \\mathbb{R}^{d}.$ The purpose\nof this paper is to establish Lions' formula for reproducing kernel Hilbert\nspaces $\\mathcal H^s(\\Omega)$ of real harmonic functions elements of the usual\nSobolev space $H^s(\\Omega)$ for $s\\geq 0.$ To this end, we provide a functional\ncharacterization of $\\mathcal H^s(\\Omega)$ via some new families of positive\nself-adjoint operators, describe their trace data and discuss the values of $s$\nfor which they are RKHSs. Also a construction of an orthonormal basis of\n$\\mathcal H^s(\\Omega)$ is established.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Poisson distribution for gaps between sums of two squares and level spacings for toral point scatterers.   We investigate the level spacing distribution for the quantum spectrum of the\nsquare billiard. Extending work of Connors--Keating, and Smilansky, we\nformulate an analog of the Hardy--Littlewood prime $k$-tuple conjecture for\nsums of two squares, and show that it implies that the spectral gaps, after\nremoving degeneracies and rescaling, are Poisson distributed. Consequently, by\nwork of Rudnick and Ueberschär, the level spacings of arithmetic toral point\nscatterers, in the weak coupling limit, are also Poisson distributed. We also\ngive numerical evidence for the conjecture and its implications.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Analytic Expressions for the Inner-Rim Structure of Passively Heated Protoplanetary Disks.   We analytically derive the expressions for the structure of the inner region\nof protoplanetary disks based on the results from the recent hydrodynamical\nsimulations. The inner part of a disk can be divided into four regions:\ndust-free region with gas temperature in the optically thin limit, optically\nthin dust halo, optically thick condensation front and the classical optically\nthick region in order from the inside. We derive the dust-to-gas mass ratio\nprofile in the dust halo using the fact that partial dust condensation\nregulates the temperature to the dust evaporation temperature. Beyond the dust\nhalo, there is an optically thick condensation front where all the available\nsilicate gas condenses out. The curvature of the condensation surface is\ndetermined by the condition that the surface temperature must be nearly equal\nto the characteristic temperature $\\sim 1200{\\,\\rm K}$. We derive the mid-plane\ntemperature in the outer two regions using the two-layer approximation with the\nadditional heating by the condensation front for the outermost region. As a\nresult, the overall temperature profile is step-like with steep gradients at\nthe borders between the outer three regions. The borders might act as planet\ntraps where the inward migration of planets due to gravitational interaction\nwith the gas disk stops. The temperature at the border between the two\noutermost regions coincides with the temperature needed to activate\nmagnetorotational instability, suggesting that the inner edge of the dead zone\nmust lie at this border. The radius of the dead-zone inner edge predicted from\nour solution is $\\sim$ 2-3 times larger than that expected from the classical\noptically thick temperature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards Gene Expression Convolutions using Gene Interaction Graphs.   We study the challenges of applying deep learning to gene expression data. We\nfind experimentally that there exists non-linear signal in the data, however is\nit not discovered automatically given the noise and low numbers of samples used\nin most research. We discuss how gene interaction graphs (same pathway,\nprotein-protein, co-expression, or research paper text association) can be used\nto impose a bias on a deep model similar to the spatial bias imposed by\nconvolutions on an image. We explore the usage of Graph Convolutional Neural\nNetworks coupled with dropout and gene embeddings to utilize the graph\ninformation. We find this approach provides an advantage for particular tasks\nin a low data regime but is very dependent on the quality of the graph used. We\nconclude that more work should be done in this direction. We design experiments\nthat show why existing methods fail to capture signal that is present in the\ndata when features are added which clearly isolates the problem that needs to\nbe addressed.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The ANTARES Collaboration: Contributions to ICRC 2017 Part II: The multi-messenger program.   Papers on the ANTARES multi-messenger program, prepared for the 35th\nInternational Cosmic Ray Conference (ICRC 2017, Busan, South Korea) by the\nANTARES Collaboration",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Low Resolution Face Recognition Using a Two-Branch Deep Convolutional Neural Network Architecture.   We propose a novel couple mappings method for low resolution face recognition\nusing deep convolutional neural networks (DCNNs). The proposed architecture\nconsists of two branches of DCNNs to map the high and low resolution face\nimages into a common space with nonlinear transformations. The branch\ncorresponding to transformation of high resolution images consists of 14 layers\nand the other branch which maps the low resolution face images to the common\nspace includes a 5-layer super-resolution network connected to a 14-layer\nnetwork. The distance between the features of corresponding high and low\nresolution images are backpropagated to train the networks. Our proposed method\nis evaluated on FERET data set and compared with state-of-the-art competing\nmethods. Our extensive experimental results show that the proposed method\nsignificantly improves the recognition performance especially for very low\nresolution probe face images (11.4% improvement in recognition accuracy).\nFurthermore, it can reconstruct a high resolution image from its corresponding\nlow resolution probe image which is comparable with state-of-the-art\nsuper-resolution methods in terms of visual quality.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Observation of Intrinsic Half-metallic Behavior of CrO$_2$ (100) Epitaxial Films by Bulk-sensitive Spin-resolved PES.   We have investigated the electronic states and spin polarization of\nhalf-metallic ferromagnet CrO$_2$ (100) epitaxial films by bulk-sensitive\nspin-resolved photoemission spectroscopy with a focus on non-quasiparticle\n(NQP) states derived from electron-magnon interactions. We found that the\naveraged values of the spin polarization are approximately 100% and 40% at 40 K\nand 300 K, respectively. This is consistent with the previously reported result\n[H. Fujiwara et al., Appl. Phys. Lett. 106, 202404 (2015).]. At 100 K, peculiar\nspin depolarization was observed at the Fermi level ($E_{F}$), which is\nsupported by theoretical calculations predicting NQP states. This suggests the\npossible appearance of NQP states in CrO$_2$. We also compare the temperature\ndependence of our spin polarizations with that of the magnetization.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A multi-layered energy consumption model for smart wireless acoustic sensor networks.   Smart sensing is expected to become a pervasive technology in smart cities\nand environments of the near future. These services are improving their\ncapabilities due to integrated devices shrinking in size while maintaining\ntheir computational power, which can run diverse Machine Learning algorithms\nand achieve high performance in various data-processing tasks. One attractive\nsensor modality to be used for smart sensing are acoustic sensors, which can\nconvey highly informative data while keeping a moderate energy consumption.\nUnfortunately, the energy budget of current wireless sensor networks is usually\nnot enough to support the requirements of standard microphones. Therefore,\nenergy efficiency needs to be increased at all layers --- sensing, signal\nprocessing and communication --- in order to bring wireless smart acoustic\nsensors into the market. To help to attain this goal, this paper introduces\nWASN-EM: an energy consumption model for wireless acoustic sensors networks\n(WASN), whose aim is to aid in the development of novel techniques to increase\nthe energy-efficient of smart wireless acoustic sensors. This model provides a\nfirst step of exploration prior to custom design of a smart wireless acoustic\nsensor, and also can be used to compare the energy consumption of different\nprotocols.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Simultaneously Learning Neighborship and Projection Matrix for Supervised Dimensionality Reduction.   Explicitly or implicitly, most of dimensionality reduction methods need to\ndetermine which samples are neighbors and the similarity between the neighbors\nin the original highdimensional space. The projection matrix is then learned on\nthe assumption that the neighborhood information (e.g., the similarity) is\nknown and fixed prior to learning. However, it is difficult to precisely\nmeasure the intrinsic similarity of samples in high-dimensional space because\nof the curse of dimensionality. Consequently, the neighbors selected according\nto such similarity might and the projection matrix obtained according to such\nsimilarity and neighbors are not optimal in the sense of classification and\ngeneralization. To overcome the drawbacks, in this paper we propose to let the\nsimilarity and neighbors be variables and model them in low-dimensional space.\nBoth the optimal similarity and projection matrix are obtained by minimizing a\nunified objective function. Nonnegative and sum-to-one constraints on the\nsimilarity are adopted. Instead of empirically setting the regularization\nparameter, we treat it as a variable to be optimized. It is interesting that\nthe optimal regularization parameter is adaptive to the neighbors in\nlow-dimensional space and has intuitive meaning. Experimental results on the\nYALE B, COIL-100, and MNIST datasets demonstrate the effectiveness of the\nproposed method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Weak Label Supervision for Monaural Source Separation Using Non-negative Denoising Variational Autoencoders.   Deep learning models are very effective in source separation when there are\nlarge amounts of labeled data available. However it is not always possible to\nhave carefully labeled datasets. In this paper, we propose a weak supervision\nmethod that only uses class information rather than source signals for learning\nto separate short utterance mixtures. We associate a variational autoencoder\n(VAE) with each class within a non-negative model. We demonstrate that deep\nconvolutional VAEs provide a prior model to identify complex signals in a sound\nmixture without having access to any source signal. We show that the separation\nresults are on par with source signal supervision.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stability of semi-wavefronts for delayed reaction-diffusion equations.   This paper deals with the asymptotic behavior of solutions to the delayed\nmonostable equation: $(*)$ $u_{t}(t,x) = u_{xx}(t,x) - u(t,x) + g(u(t-h,x)),$\n$x \\in \\mathbb{R},\\ t >0,$ where $h>0$ and the reaction term $g: \\mathbb{R}_+\n\\to \\mathbb{R}_+$ has exactly two fixed points (zero and $\\kappa >0$). Under\ncertain condition on the derivative of $g$ at $\\kappa$, the global stability of\nfast wavefronts is proved. Also, the stability of the $leading \\ edge$ of\nsemi-wavefronts for $(*)$ with $g$ satisfying $g(u)\\leq g'(0)u, u\\in\\R_+,$ is\nestablished",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantifying telescope phase discontinuities external to AO-systems by use of Phase Diversity and Focal Plane Sharpening.   We propose and apply two methods to estimate pupil plane phase\ndiscontinuities for two realistic scenarios on VLT and Keck. The methods use\nboth Phase Diversity and a form of image sharpening. For the case of VLT, we\nsimulate the `low wind effect' (LWE) which is responsible for focal plane\nerrors in the SPHERE system in low wind and good seeing conditions. We\nsuccessfully estimate the simulated LWE using both methods, and show that they\nare complimentary to one another. We also demonstrate that single image Phase\nDiversity (also known as Phase Retrieval with diversity) is also capable of\nestimating the simulated LWE when using the natural de-focus on the SPHERE/DTTS\nimager. We demonstrate that Phase Diversity can estimate the LWE to within 30\nnm RMS WFE, which is within the allowable tolerances to achieve a target SPHERE\ncontrast of 10$^{-6}$. Finally, we simulate 153 nm RMS of piston errors on the\nmirror segments of Keck and produce NIRC2 images subject to these effects. We\nshow that a single, diverse image with 1.5 waves (PV) of focus can be used to\nestimate this error to within 29 nm RMS WFE, and a perfect correction of our\nestimation would increase the Strehl ratio of a NIRC2 image by 12\\%",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards automation of data quality system for CERN CMS experiment.   Daily operation of a large-scale experiment is a challenging task,\nparticularly from perspectives of routine monitoring of quality for data being\ntaken. We describe an approach that uses Machine Learning for the automated\nsystem to monitor data quality, which is based on partial use of data qualified\nmanually by detector experts. The system automatically classifies marginal\ncases: both of good an bad data, and use human expert decision to classify\nremaining \"grey area\" cases.\nThis study uses collision data collected by the CMS experiment at LHC in\n2010. We demonstrate that proposed workflow is able to automatically process at\nleast 20\\% of samples without noticeable degradation of the result.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Character sums for elliptic curve densities.   If $E$ is an elliptic curve over $\\mathbb{Q}$, then it follows from work of\nSerre and Hooley that, under the assumption of the Generalized Riemann\nHypothesis, the density of primes $p$ such that the group of\n$\\mathbb{F}_p$-rational points of the reduced curve $\\tilde{E}(\\mathbb{F}_p)$\nis cyclic can be written as an infinite product $\\prod \\delta_\\ell$ of local\nfactors $\\delta_\\ell$ reflecting the degree of the $\\ell$-torsion fields,\nmultiplied by a factor that corrects for the entanglements between the various\ntorsion fields. We show that this correction factor can be interpreted as a\ncharacter sum, and the resulting description allows us to easily determine\nnon-vanishing criteria for it. We apply this method in a variety of other\nsettings. Among these, we consider the aforementioned problem with the\nadditional condition that the primes $p$ lie in a given arithmetic progression.\nWe also study the conjectural constants appearing in Koblitz's conjecture, a\nconjecture which relates to the density of primes $p$ for which the cardinality\nof the group of $\\mathbb{F}_p$-points of $E$ is prime.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pebble accretion at the origin of water in Europa.   Despite the fact that the observed gradient in water content among the\nGalilean satellites is globally consistent with a formation in a circum-Jovian\ndisk on both sides of the snowline, the mechanisms that led to a low water mass\nfraction in Europa ($\\sim$$8\\%$) are not yet understood. Here, we present new\nmodeling results of solids transport in the circum-Jovian disk accounting for\naerodynamic drag, turbulent diffusion, surface temperature evolution and\nsublimation of water ice. We find that the water mass fraction of pebbles\n(e.g., solids with sizes of 10$^{-2}$ -- 1 m) as they drift inward is globally\nconsistent with the current water content of the Galilean system. This opens\nthe possibility that each satellite could have formed through pebble accretion\nwithin a delimited region whose boundaries were defined by the position of the\nsnowline. This further implies that the migration of the forming satellites was\ntied to the evolution of the snowline so that Europa fully accreted from\npartially dehydrated material in the region just inside of the snowline.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Space-time domain solutions of the wave equation by a non-singular boundary integral method and Fourier transform.   The general space-time evolution of the scattering of an incident acoustic\nplane wave pulse by an arbitrary configuration of targets is treated by\nemploying a recently developed non-singular boundary integral method to solve\nthe Helmholtz equation in the frequency domain from which the fast Fourier\ntransform is used to obtain the full space-time solution of the wave equation.\nThe non-singular boundary integral solution can enforce the radiation boundary\ncondition at infinity exactly and can account for multiple scattering effects\nat all spacings between scatterers without adverse effects on the numerical\nprecision. More generally, the absence of singular kernels in the non-singular\nintegral equation confers high numerical stability and precision for smaller\nnumbers of degrees of freedom. The use of fast Fourier transform to obtain the\ntime dependence is not constrained to discrete time steps and is particularly\nefficient for studying the response to different incident pulses by the same\nconfiguration of scatterers. The precision that can be attained using a smaller\nnumber of Fourier components is also quantified.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Linearized Einstein's field equations.   From the Einstein field equations, in a weak-field approximation and for\nspeeds small compared to the speed of light in vacuum, the following system is\nobtained \\begin{align*}\n\\nabla \\times \\overrightarrow{E_g} & =\n-\\frac{1}{c} \\frac{\\partial \\overrightarrow{B_g}}{\\partial t},\n\\nabla \\cdot \\overrightarrow{E_g} \\;\\; & \\approx -4\\pi G\\rho_g,\n\\nabla \\times \\overrightarrow{B_g} & \\approx\n-\\frac{4\\pi G}{c^{2}}\\overrightarrow{J_g}+\n\\frac{1}{c}\\frac{\\partial \\overrightarrow{E_g}}{\\partial t},\n\\nabla \\cdot \\overrightarrow{B_g} \\;\\; & = 0, \\end{align*} where\n$\\overrightarrow{E_g}$ is the gravitoelectric field, $\\overrightarrow{B_g}$ is\nthe gravitomagnetic field, $\\overrightarrow{J_g}$ is the space-time-mass\ncurrent density and $\\rho_g$ is the space-time-mass density. This last\ngravitoelectromagnetic field system is similar to the Maxwell equations, thus\nshowing an analogy between the electromagnetic theory and gravitation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Surjective H-Colouring: New Hardness Results.   A homomorphism from a graph G to a graph H is a vertex mapping f from the\nvertex set of G to the vertex set of H such that there is an edge between\nvertices f(u) and f(v) of H whenever there is an edge between vertices u and v\nof G. The H-Colouring problem is to decide whether or not a graph G allows a\nhomomorphism to a fixed graph H. We continue a study on a variant of this\nproblem, namely the Surjective H-Colouring problem, which imposes the\nhomomorphism to be vertex-surjective. We build upon previous results and show\nthat this problem is NP-complete for every connected graph H that has exactly\ntwo vertices with a self-loop as long as these two vertices are not adjacent.\nAs a result, we can classify the computational complexity of Surjective\nH-Colouring for every graph H on at most four vertices.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Relevance of backtracking paths in epidemic spreading on networks.   The understanding of epidemics on networks has greatly benefited from the\nrecent application of message-passing approaches, which allow to derive exact\nresults for irreversible spreading (i.e. diseases with permanent acquired\nimmunity) in locally-tree like topologies. This success has suggested the\napplication of the same approach to reversible epidemics, for which an\nindividual can contract the epidemic and recover repeatedly. The underlying\nassumption is that backtracking paths (i.e. an individual is reinfected by a\nneighbor he/she previously infected) do not play a relevant role. In this paper\nwe show that this is not the case for reversible epidemics, since the neglect\nof backtracking paths leads to a formula for the epidemic threshold that is\nqualitatively incorrect in the large size limit. Moreover we define a modified\nreversible dynamics which explicitly forbids direct backtracking events and\nshow that this modification completely upsets the phenomenology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Free differential Lie Rota-Baxter algebras and Gröbner-Shirshov bases.   We establish the Gröbner-Shirshov bases theory for differential Lie\n$\\Omega$-algebras. As an application, we give a linear basis of a free\ndifferential Lie Rota-Baxter algebra on a set.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Studies to Understand and Optimize the Performance of Scintillation Counters for the Mu2e Cosmic Ray Veto System.   In order to optimize the performance of the CRV, reflection studies and aging\nstudies were conducted.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The maximum number of cycles in a graph with fixed number of edges.   The main topic considered is maximizing the number of cycles in a graph with\ngiven number of edges. In 2009, Király conjectured that there is constant $c$\nsuch that any graph with $m$ edges has at most $(1.4)^m$ cycles. In this paper,\nit is shown that for sufficiently large $m$, a graph with $m$ edges has at most\n$(1.443)^m$ cycles. For sufficiently large $m$, examples of a graph with $m$\nedges and $(1.37)^m$ cycles are presented. For a graph with given number of\nvertices and edges an upper bound on the maximal number of cycles is given.\nAlso, exponentially tight bounds are proved for the maximum number of cycles in\na multigraph with given number of edges, as well as in a multigraph with given\nnumber of vertices and edges.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A variational-geometric approach for the optimal control of nonholonomic systems.   Necessary conditions for existence of normal extremals in optimal control of\nsystems subject to nonholonomic constraints are derived as solutions of a\nconstrained second order variational problems. In this work, a geometric\ninterpretation of the derivation is studied from the theory of Lie algebroids.\nWe employ such a framework to describe the problem into a unifying formalism\nfor normal extremals in optimal control of nonholonomic systems and including\nsituations that have not been considered before in the literature from this\nperspective. We show that necessary conditions for existence of extremals in\nthe optimal control problem can be also determined by a Hamiltonian system on\nthe cotangent bundle of a skew-symmetric algebroid.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Machine learning quantum mechanics: solving quantum mechanics problems using radial basis function networks.   Inspired by the recent work of Carleo and Troyer[1], we apply machine\nlearning methods to quantum mechanics in this article. The radial basis\nfunction network in a discrete basis is used as the variational wavefunction\nfor the ground state of a quantum system. Variational Monte Carlo(VMC)\ncalculations are carried out for some simple Hamiltonians. The results are in\ngood agreements with theoretical values. The smallest eigenvalue of a Hermitian\nmatrix can also be acquired using VMC calculations. Our results demonstrate\nthat machine learning techniques are capable of solving quantum mechanical\nproblems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The existence and global exponential stability of almost periodic solutions for neutral type CNNs on time scales.   In this paper, a class of neutral type competitive neural networks with mixed\ntime-varying delays and leakage delays on time scales is proposed. Based on the\nexponential dichotomy of linear dynamic equations on time scales, Banach's\nfixed point theorem and the theory of calculus on time scales, some sufficient\nconditions that are independent of the backwards graininess function of the\ntime scale are obtained for the existence and global exponential stability of\nalmost periodic solutions for this class of neural networks. The obtained\nresults are completely new and indicate that both the continuous time and the\ndiscrete time cases of the networks share the same dynamical behavior. Finally,\nan examples is given to show the effectiveness of the obtained results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Elicitability and its Application in Risk Management.   Elicitability is a property of $\\mathbb{R}^k$-valued functionals defined on a\nset of distribution functions. These functionals represent statistical\nproperties of a distribution, for instance its mean, variance, or median. They\nare called elicitable if there exists a scoring function such that the expected\nscore under a distribution takes its unique minimum at the functional value of\nthis distribution. If such a scoring function exists, it is called strictly\nconsistent for the functional. Motivated by the recent findings of Fissler and\nZiegel concerning higher order elicitability, this thesis reviews the most\nimportant results, examples, and applications which are found in the relevant\nliterature. Moreover, we also contribute our own examples and findings in order\nto give the reader a well-founded overview of the topic as well as of the most\nused tools and techniques. We include necessary and sufficient conditions for\nstrictly consistent scoring functions, several elicitable as well as\nnon-elicitable functionals and the use of elicitability in forecast comparison,\nregression, and estimation. Special emphasis is placed on quantitative risk\nmanagement and the result that Value at Risk and Expected Shortfall are jointly\nelicitable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Formal Guarantees on the Robustness of a Classifier against Adversarial Manipulation.   Recent work has shown that state-of-the-art classifiers are quite brittle, in\nthe sense that a small adversarial change of an originally with high confidence\ncorrectly classified input leads to a wrong classification again with high\nconfidence. This raises concerns that such classifiers are vulnerable to\nattacks and calls into question their usage in safety-critical systems. We show\nin this paper for the first time formal guarantees on the robustness of a\nclassifier by giving instance-specific lower bounds on the norm of the input\nmanipulation required to change the classifier decision. Based on this analysis\nwe propose the Cross-Lipschitz regularization functional. We show that using\nthis form of regularization in kernel methods resp. neural networks improves\nthe robustness of the classifier without any loss in prediction performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A sparse linear algebra algorithm for fast computation of prediction variances with Gaussian Markov random fields.   Gaussian Markov random fields are used in a large number of disciplines in\nmachine vision and spatial statistics. The models take advantage of sparsity in\nmatrices introduced through the Markov assumptions, and all operations in\ninference and prediction use sparse linear algebra operations that scale well\nwith dimensionality. Yet, for very high-dimensional models, exact computation\nof predictive variances of linear combinations of variables is generally\ncomputationally prohibitive, and approximate methods (generally interpolation\nor conditional simulation) are typically used instead. A set of conditions are\nestablished under which the variances of linear combinations of random\nvariables can be computed exactly using the Takahashi recursions. The ensuing\ncomputational simplification has wide applicability and may be used to enhance\nseveral software packages where model fitting is seated in a maximum-likelihood\nframework. The resulting algorithm is ideal for use in a variety of spatial\nstatistical applications, including \\emph{LatticeKrig} modelling, statistical\ndownscaling, and fixed rank kriging. It can compute hundreds of thousands exact\npredictive variances of linear combinations on a standard desktop with ease,\neven when large spatial GMRF models are used.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multivariate Locally Stationary Wavelet Process Analysis with the mvLSW R Package.   This paper describes the R package mvLSW. The package contains a suite of\ntools for the analysis of multivariate locally stationary wavelet (LSW) time\nseries. Key elements include: (i) the simulation of multivariate LSW time\nseries for a given multivariate evolutionary wavelet spectrum (EWS); (ii)\nestimation of the time-dependent multivariate EWS for a given time series;\n(iii) estimation of the time-dependent coherence and partial coherence between\ntime series channels; and, (iv) estimation of approximate confidence intervals\nfor multivariate EWS estimates. A demonstration of the package is presented via\nboth a simulated example and a case study with EuStockMarkets from the datasets\npackage. This paper has been accepted by the Journal of Statistical Software.\nPresented code extracts demonstrating the mvLSW package is performed under\nversion 1.2.1.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Courant's Nodal Domain Theorem for Positivity Preserving Forms.   We introduce a notion of nodal domains for positivity preserving forms. This\nnotion generalizes the classical ones for Laplacians on domains and on graphs.\nWe prove the Courant nodal domain theorem in this generalized setting using\npurely analytical methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Verification of operational solar flare forecast: Case of Regional Warning Center Japan.   In this article, we discuss a verification study of an operational solar\nflare forecast in the Regional Warning Center (RWC) Japan. The RWC Japan has\nbeen issuing four-categorical deterministic solar flare forecasts for a long\ntime. In this forecast verification study, we used solar flare forecast data\naccumulated over 16 years (from 2000 to 2015). We compiled the forecast data\ntogether with solar flare data obtained with the Geostationary Operational\nEnvironmental Satellites (GOES). Using the compiled data sets, we estimated\nsome conventional scalar verification measures with 95% confidence intervals.\nWe also estimated a multi-categorical scalar verification measure. These scalar\nverification measures were compared with those obtained by the persistence\nmethod and recurrence method. As solar activity varied during the 16 years, we\nalso applied verification analyses to four subsets of forecast-observation pair\ndata with different solar activity levels. We cannot conclude definitely that\nthere are significant performance difference between the forecasts of RWC Japan\nand the persistence method, although a slightly significant difference is found\nfor some event definitions. We propose to use a scalar verification measure to\nassess the judgment skill of the operational solar flare forecast. Finally, we\npropose a verification strategy for deterministic operational solar flare\nforecasting.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Markov Chain Gradient Descent.   Stochastic gradient methods are the workhorse (algorithms) of large-scale\noptimization problems in machine learning, signal processing, and other\ncomputational sciences and engineering. This paper studies Markov chain\ngradient descent, a variant of stochastic gradient descent where the random\nsamples are taken on the trajectory of a Markov chain. Existing results of this\nmethod assume convex objectives and a reversible Markov chain and thus have\ntheir limitations. We establish new non-ergodic convergence under wider step\nsizes, for nonconvex problems, and for non-reversible finite-state Markov\nchains. Nonconvexity makes our method applicable to broader problem classes.\nNon-reversible finite-state Markov chains, on the other hand, can mix\nsubstatially faster. To obtain these results, we introduce a new technique that\nvaries the mixing levels of the Markov chains. The reported numerical results\nvalidate our contributions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Extrapolating Expected Accuracies for Large Multi-Class Problems.   The difficulty of multi-class classification generally increases with the\nnumber of classes. Using data from a subset of the classes, can we predict how\nwell a classifier will scale with an increased number of classes? Under the\nassumptions that the classes are sampled identically and independently from a\npopulation, and that the classifier is based on independently learned scoring\nfunctions, we show that the expected accuracy when the classifier is trained on\nk classes is the (k-1)st moment of a certain distribution that can be estimated\nfrom data. We present an unbiased estimation method based on the theory, and\ndemonstrate its application on a facial recognition example.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Quantum Chebyshev's Inequality and Applications.   In this paper we provide new quantum algorithms with polynomial speed-up for\na range of problems for which no such results were known, or we improve\nprevious algorithms. First, we consider the approximation of the frequency\nmoments $F_k$ of order $k \\geq 3$ in the multi-pass streaming model with\nupdates (turnstile model). We design a $P$-pass quantum streaming algorithm\nwith memory $M$ satisfying a tradeoff of $P^2 M = \\tilde{O}(n^{1-2/k})$,\nwhereas the best classical algorithm requires $P M = \\Theta(n^{1-2/k})$. Then,\nwe study the problem of estimating the number $m$ of edges and the number $t$\nof triangles given query access to an $n$-vertex graph. We describe optimal\nquantum algorithms that perform $\\tilde{O}(\\sqrt{n}/m^{1/4})$ and\n$\\tilde{O}(\\sqrt{n}/t^{1/6} + m^{3/4}/\\sqrt{t})$ queries respectively. This is\na quadratic speed-up compared to the classical complexity of these problems.\nFor this purpose we develop a new quantum paradigm that we call Quantum\nChebyshev's inequality. Namely we demonstrate that, in a certain model of\nquantum sampling, one can approximate with relative error the mean of any\nrandom variable with a number of quantum samples that is linear in the ratio of\nthe square root of the variance to the mean. Classically the dependency is\nquadratic. Our algorithm subsumes a previous result of Montanaro [Mon15]. This\nnew paradigm is based on a refinement of the Amplitude Estimation algorithm of\nBrassard et al. [BHMT02] and of previous quantum algorithms for the mean\nestimation problem. We show that this speed-up is optimal, and we identify\nanother common model of quantum sampling where it cannot be obtained. For our\napplications, we also adapt the variable-time amplitude amplification technique\nof Ambainis [Amb10] into a variable-time amplitude estimation algorithm.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Visual Detection of Structural Changes in Time-Varying Graphs Using Persistent Homology.   Topological data analysis is an emerging area in exploratory data analysis\nand data mining. Its main tool, persistent homology, has become a popular\ntechnique to study the structure of complex, high-dimensional data. In this\npaper, we propose a novel method using persistent homology to quantify\nstructural changes in time-varying graphs. Specifically, we transform each\ninstance of the time-varying graph into metric spaces, extract topological\nfeatures using persistent homology, and compare those features over time. We\nprovide a visualization that assists in time-varying graph exploration and\nhelps to identify patterns of behavior within the data. To validate our\napproach, we conduct several case studies on real world data sets and show how\nour method can find cyclic patterns, deviations from those patterns, and\none-time events in time-varying graphs. We also examine whether\npersistence-based similarity measure as a graph metric satisfies a set of\nwell-established, desirable properties for graph metrics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "NDSHA: robust and reliable seismic hazard assessment.   The Neo-Deterministic Seismic Hazard Assessment (NDSHA) method reliably and\nrealistically simulates the suite of earthquake ground motions that may impact\ncivil populations as well as their heritage buildings. The modeling technique\nis developed from comprehensive physical knowledge of the seismic source\nprocess, the propagation of earthquake waves and their combined interactions\nwith site effects. NDSHA effectively accounts for the tensor nature of\nearthquake ground motions formally described as the tensor product of the\nearthquake source functions and the Green Functions of the pathway. NDSHA uses\nall available information about the space distribution of large magnitude\nearthquake, including Maximum Credible Earthquake (MCE) and geological and\ngeophysical data. It does not rely on scalar empirical ground motion\nattenuation models, as these are often both weakly constrained by available\nobservations and unable to account for the tensor nature of earthquake ground\nmotion. Standard NDSHA provides robust and safely conservative hazard estimates\nfor engineering design and mitigation decision strategies without requiring\n(often faulty) assumptions about the probabilistic risk analysis model of\nearthquake occurrence. If specific applications may benefit from temporal\ninformation the definition of the Gutenberg-Richter (GR) relation is performed\naccording to the multi-scale seismicity model and occurrence rate is associated\nto each modeled source. Observations from recent destructive earthquakes in\nItaly and Nepal have confirmed the validity of NDSHA approach and application,\nand suggest that more widespread application of NDSHA will enhance earthquake\nsafety and resilience of civil populations in all earthquake-prone regions,\nespecially in tectonically active areas where the historic earthquake record is\ntoo short.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Fingerprints of angulon instabilities in the spectra of matrix-isolated molecules.   The formation of vortices is usually considered to be the main mechanism of\nangular momentum disposal in superfluids. Recently, it was predicted that a\nsuperfluid can acquire angular momentum via an alternative, microscopic route\n-- namely, through interaction with rotating impurities, forming so-called\n`angulon quasiparticles' [Phys. Rev. Lett. 114, 203001 (2015)]. The angulon\ninstabilities correspond to transfer of a small number of angular momentum\nquanta from the impurity to the superfluid, as opposed to vortex instabilities,\nwhere angular momentum is quantized in units of $\\hbar$ per atom. Furthermore,\nsince conventional impurities (such as molecules) represent three-dimensional\n(3D) rotors, the angular momentum transferred is intrinsically 3D as well, as\nopposed to a merely planar rotation which is inherent to vortices. Herein we\nshow that the angulon theory can explain the anomalous broadening of the\nspectroscopic lines observed for CH$_3$ and NH$_3$ molecules in superfluid\nhelium nanodroplets, thereby providing a fingerprint of the emerging angulon\ninstabilities in experiment.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Revisiting Simple Neural Networks for Learning Representations of Knowledge Graphs.   We address the problem of learning vector representations for entities and\nrelations in Knowledge Graphs (KGs) for Knowledge Base Completion (KBC). This\nproblem has received significant attention in the past few years and multiple\nmethods have been proposed. Most of the existing methods in the literature use\na predefined characteristic scoring function for evaluating the correctness of\nKG triples. These scoring functions distinguish correct triples (high score)\nfrom incorrect ones (low score). However, their performance vary across\ndifferent datasets. In this work, we demonstrate that a simple neural network\nbased score function can consistently achieve near start-of-the-art performance\non multiple datasets. We also quantitatively demonstrate biases in standard\nbenchmark datasets, and highlight the need to perform evaluation spanning\nvarious datasets.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uniqueness and stability of Ricci flow through singularities.   We verify a conjecture of Perelman, which states that there exists a\ncanonical Ricci flow through singularities starting from an arbitrary compact\nRiemannian 3-manifold. Our main result is a uniqueness theorem for such flows,\nwhich, together with an earlier existence theorem of Lott and the second named\nauthor, implies Perelman's conjecture. We also show that this flow through\nsingularities depends continuously on its initial condition and that it may be\nobtained as a limit of Ricci flows with surgery.\nOur results have applications to the study of diffeomorphism groups of three\nmanifolds --- in particular to the Generalized Smale Conjecture --- which will\nappear in a subsequent paper.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effects of Disorder on the Pressure-Induced Mott Transition in $κ$-BEDT-TTF)$_2$Cu[N(CN)$_2$]Cl.   We present a study of the influence of disorder on the Mott metal-insulator\ntransition for the organic charge-transfer salt\n$\\kappa$-(BEDT-TTF)$_2$Cu[N(CN)$_2$]Cl. To this end, disorder was introduced\ninto the system in a controlled way by exposing the single crystals to x-ray\nirradiation. The crystals were then fine-tuned across the Mott transition by\nthe application of continuously controllable He-gas pressure at low\ntemperatures. Measurements of the thermal expansion and resistance show that\nthe first-order character of the Mott transition prevails for low irradiation\ndoses achieved by irradiation times up to 100 h. For these crystals with a\nmoderate degree of disorder, we find a first-order transition line which ends\nin a second-order critical endpoint, akin to the pristine crystals. Compared to\nthe latter, however, we observe a significant reduction of both, the critical\npressure $p_c$ and the critical temperature $T_c$. This result is consistent\nwith the theoretically-predicted formation of a soft Coulomb gap in the\npresence of strong correlations and small disorder. Furthermore, we\ndemonstrate, similar to the observation for the pristine sample, that the Mott\ntransition after 50 h of irradiation is accompanied by sizable lattice effects,\nthe critical behavior of which can be well described by mean-field theory. Our\nresults demonstrate that the character of the Mott transition remains\nessentially unchanged at a low disorder level. However, after an irradiation\ntime of 150 h, no clear signatures of a discontinuous metal-insulator\ntransition could be revealed anymore. These results suggest that, above a\ncertain disorder level, the metal-insulator transition becomes a smeared\nfirst-order transition with some residual hysteresis.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A New Tracking Algorithm for Multiple Colloidal Particles Close to Contact.   In this paper, we propose a new algorithm based on radial symmetry center\nmethod to track colloidal particles close to contact, where the optical images\nof the particles start to overlap in digital video microscopy. This overlapping\neffect is important to observe the pair interaction potential in colloidal\nstudies and it appears as additional interaction in the measurement of the\ninteraction with conventional tracking analysis. The proposed algorithm in this\nwork is simple, fast and applicable for not only two particles but also three\nand more particles without any modification. The algorithm uses gradient\nvectors of the particle intensity distribution, which allows us to use a part\nof the symmetric intensity distribution in the calculation of the actual\nparticle position. In this study, simulations are performed to see the\nperformance of the proposed algorithm for two and three particles, where the\nsimulation images are generated by using fitted curve to experimental particle\nimage for different sized particles. As a result, the algorithm yields the\nmaximum error smaller than 2 nm for 5.53 {\\mu}m silica particles in contact\ncondition.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Biochemical Coupling Through Emergent Conservation Laws.   Bazhin has analyzed ATP coupling in terms of quasiequilibrium states where\nfast reactions have reached an approximate steady state while slow reactions\nhave not yet reached equilibrium. After an expository introduction to the\nrelevant aspects of reaction network theory, we review his work and explain the\nrole of emergent conserved quantities in coupling. These are quantities, left\nunchanged by fast reactions, whose conservation forces exergonic processes such\nas ATP hydrolysis to drive desired endergonic processes.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Visibility of minorities in social networks.   Homophily can put minority groups at a disadvantage by restricting their\nability to establish links with people from a majority group. This can limit\nthe overall visibility of minorities in the network. Building on a\nBarabási-Albert model variation with groups and homophily, we show how the\nvisibility of minority groups in social networks is a function of (i) their\nrelative group size and (ii) the presence or absence of homophilic behavior. We\nprovide an analytical solution for this problem and demonstrate the existence\nof asymmetric behavior. Finally, we study the visibility of minority groups in\nexamples of real-world social networks: sexual contacts, scientific\ncollaboration, and scientific citation. Our work presents a foundation for\nassessing the visibility of minority groups in social networks in which\nhomophilic or heterophilic behaviour is present.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Feature uncertainty bounding schemes for large robust nonlinear SVM classifiers.   We consider the binary classification problem when data are large and subject\nto unknown but bounded uncertainties. We address the problem by formulating the\nnonlinear support vector machine training problem with robust optimization. To\ndo so, we analyze and propose two bounding schemes for uncertainties associated\nto random approximate features in low dimensional spaces. The proposed\ntechniques are based on Random Fourier Features and the Nyström methods. The\nresulting formulations can be solved with efficient stochastic approximation\ntechniques such as stochastic (sub)-gradient, stochastic proximal gradient\ntechniques or their variants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Can Deep Reinforcement Learning Solve Erdos-Selfridge-Spencer Games?.   Deep reinforcement learning has achieved many recent successes, but our\nunderstanding of its strengths and limitations is hampered by the lack of rich\nenvironments in which we can fully characterize optimal behavior, and\ncorrespondingly diagnose individual actions against such a characterization.\nHere we consider a family of combinatorial games, arising from work of Erdos,\nSelfridge, and Spencer, and we propose their use as environments for evaluating\nand comparing different approaches to reinforcement learning. These games have\na number of appealing features: they are challenging for current learning\napproaches, but they form (i) a low-dimensional, simply parametrized\nenvironment where (ii) there is a linear closed form solution for optimal\nbehavior from any state, and (iii) the difficulty of the game can be tuned by\nchanging environment parameters in an interpretable way. We use these\nErdos-Selfridge-Spencer games not only to compare different algorithms, but\ntest for generalization, make comparisons to supervised learning, analyse\nmultiagent play, and even develop a self play algorithm. Code can be found at:\nthis https URL",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Systematic Quantum Mechanical Region Determination in QM/MM Simulation.   Hybrid quantum mechanical-molecular mechanical (QM/MM) simulations are widely\nused in enzyme simulation. Over ten convergence studies of QM/MM methods have\nrevealed over the past several years that key energetic and structural\nproperties approach asymptotic limits with only very large (ca. 500-1000 atom)\nQM regions. This slow convergence has been observed to be due in part to\nsignificant charge transfer between the core active site and surrounding\nprotein environment, which cannot be addressed by improvement of MM force\nfields or the embedding method employed within QM/MM. Given this slow\nconvergence, it becomes essential to identify strategies for the most\natom-economical determination of optimal QM regions and to gain insight into\nthe crucial interactions captured only in large QM regions. Here, we extend and\ndevelop two methods for quantitative determination of QM regions. First, in the\ncharge shift analysis (CSA) method, we probe the reorganization of electron\ndensity when core active site residues are removed completely, as determined by\nlarge-QM region QM/MM calculations. Second, we introduce the\nhighly-parallelizable Fukui shift analysis (FSA), which identifies how\ncore/substrate frontier states are altered by the presence of an additional QM\nresidue on smaller initial QM regions. We demonstrate that the FSA and CSA\napproaches are complementary and consistent on three test case enzymes:\ncatechol O-methyltransferase, cytochrome P450cam, and hen eggwhite lysozyme. We\nalso introduce validation strategies and test sensitivities of the two methods\nto geometric structure, basis set size, and electronic structure methodology.\nBoth methods represent promising approaches for the systematic, unbiased\ndetermination of quantum mechanical effects in enzymes and large systems that\nnecessitate multi-scale modeling.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Assimilated LVEF: A Bayesian technique combining human intuition with machine measurement for sharper estimates of left ventricular ejection fraction and stronger association with outcomes.   The cardiologist's main tool for measuring systolic heart failure is left\nventricular ejection fraction (LVEF). Trained cardiologist's report both a\nvisual and machine-guided measurement of LVEF, but only use this machine-guided\nmeasurement in analysis. We use a Bayesian technique to combine visual and\nmachine-guided estimates from the PARTNER-IIA Trial, a cohort of patients with\naortic stenosis at moderate risk treated with bioprosthetic aortic valves, and\nfind our combined estimate reduces measurement errors and improves the\nassociation between LVEF and a 1-year composite endpoint.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Drug response prediction by ensemble learning and drug-induced gene expression signatures.   Chemotherapeutic response of cancer cells to a given compound is one of the\nmost fundamental information one requires to design anti-cancer drugs. Recent\nadvances in producing large drug screens against cancer cell lines provided an\nopportunity to apply machine learning methods for this purpose. In addition to\ncytotoxicity databases, considerable amount of drug-induced gene expression\ndata has also become publicly available. Following this, several methods that\nexploit omics data were proposed to predict drug activity on cancer cells.\nHowever, due to the complexity of cancer drug mechanisms, none of the existing\nmethods are perfect. One possible direction, therefore, is to combine the\nstrengths of both the methods and the databases for improved performance. We\ndemonstrate that integrating a large number of predictions by the proposed\nmethod improves the performance for this task. The predictors in the ensemble\ndiffer in several aspects such as the method itself, the number of tasks method\nconsiders (multi-task vs. single-task) and the subset of data considered\n(sub-sampling). We show that all these different aspects contribute to the\nsuccess of the final ensemble. In addition, we attempt to use the drug screen\ndata together with two novel signatures produced from the drug-induced gene\nexpression profiles of cancer cell lines. Finally, we evaluate the method\npredictions by in vitro experiments in addition to the tests on data sets.The\npredictions of the methods, the signatures and the software are available from\n\\url{this http URL}.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Modified Sigma-Pi-Sigma Neural Network with Adaptive Choice of Multinomials.   Sigma-Pi-Sigma neural networks (SPSNNs) as a kind of high-order neural\nnetworks can provide more powerful mapping capability than the traditional\nfeedforward neural networks (Sigma-Sigma neural networks). In the existing\nliterature, in order to reduce the number of the Pi nodes in the Pi layer, a\nspecial multinomial P_s is used in SPSNNs. Each monomial in P_s is linear with\nrespect to each particular variable sigma_i when the other variables are taken\nas constants. Therefore, the monomials like sigma_i^n or sigma_i^n sigma_j with\nn>1 are not included. This choice may be somehow intuitive, but is not\nnecessarily the best. We propose in this paper a modified Sigma-Pi-Sigma neural\nnetwork (MSPSNN) with an adaptive approach to find a better multinomial for a\ngiven problem. To elaborate, we start from a complete multinomial with a given\norder. Then we employ a regularization technique in the learning process for\nthe given problem to reduce the number of monomials used in the multinomial,\nand end up with a new SPSNN involving the same number of monomials (= the\nnumber of nodes in the Pi-layer) as in P_s. Numerical experiments on some\nbenchmark problems show that our MSPSNN behaves better than the traditional\nSPSNN with P_s.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dimensionality reduction methods for molecular simulations.   Molecular simulations produce very high-dimensional data-sets with millions\nof data points. As analysis methods are often unable to cope with so many\ndimensions, it is common to use dimensionality reduction and clustering methods\nto reach a reduced representation of the data. Yet these methods often fail to\ncapture the most important features necessary for the construction of a Markov\nmodel. Here we demonstrate the results of various dimensionality reduction\nmethods on two simulation data-sets, one of protein folding and another of\nprotein-ligand binding. The methods tested include a k-means clustering\nvariant, a non-linear auto encoder, principal component analysis and tICA. The\ndimension-reduced data is then used to estimate the implied timescales of the\nslowest process by a Markov state model analysis to assess the quality of the\nprojection. The projected dimensions learned from the data are visualized to\ndemonstrate which conformations the various methods choose to represent the\nmolecular process.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "System calibration method for Fourier ptychographic microscopy.   Fourier ptychographic microscopy (FPM) is a recently proposed quantitative\nphase imaging technique with high resolution and wide field-of-view (FOV). In\ncurrent FPM imaging platforms, systematic error sources come from the\naberrations, LED intensity fluctuation, parameter imperfections and noise,\nwhich will severely corrupt the reconstruction results with artifacts. Although\nthese problems have been researched and some special methods have been proposed\nrespectively, there is no method to solve all of them. However, the systematic\nerror is a mixture of various sources in the real situation. It is difficult to\ndistinguish a kind of error source from another due to the similar artifacts.\nTo this end, we report a system calibration procedure, termed SC-FPM, based on\nthe simulated annealing (SA) algorithm, LED intensity correction and adaptive\nstep-size strategy, which involves the evaluation of an error matric at each\niteration step, followed by the re-estimation of accurate parameters. The great\nperformance has been achieved both in simulation and experiments. The reported\nsystem calibration scheme improves the robustness of FPM and relaxes the\nexperiment conditions, which makes the FPM more pragmatic.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "GAMER-2: a GPU-accelerated adaptive mesh refinement code -- accuracy, performance, and scalability.   We present GAMER-2, a GPU-accelerated adaptive mesh refinement (AMR) code for\nastrophysics. It provides a rich set of features, including adaptive\ntime-stepping, several hydrodynamic schemes, magnetohydrodynamics,\nself-gravity, particles, star formation, chemistry and radiative processes with\nGRACKLE, data analysis with yt, and memory pool for efficient object\nallocation. GAMER-2 is fully bitwise reproducible. For the performance\noptimization, it adopts hybrid OpenMP/MPI/GPU parallelization and utilizes\noverlapping CPU computation, GPU computation, and CPU-GPU communication. Load\nbalancing is achieved using a Hilbert space-filling curve on a level-by-level\nbasis without the need to duplicate the entire AMR hierarchy on each MPI\nprocess. To provide convincing demonstrations of the accuracy and performance\nof GAMER-2, we directly compare with Enzo on isolated disk galaxy simulations\nand with FLASH on galaxy cluster merger simulations. We show that the physical\nresults obtained by different codes are in very good agreement, and GAMER-2\noutperforms Enzo and FLASH by nearly one and two orders of magnitude,\nrespectively, on the Blue Waters supercomputers using $1-256$ nodes. More\nimportantly, GAMER-2 exhibits similar or even better parallel scalability\ncompared to the other two codes. We also demonstrate good weak and strong\nscaling using up to 4096 GPUs and 65,536 CPU cores, and achieve a uniform\nresolution as high as $10{,}240^3$ cells. Furthermore, GAMER-2 can be adopted\nas an AMR+GPUs framework and has been extensively used for the wave dark matter\n($\\psi$DM) simulations. GAMER-2 is open source (available at\nthis https URL) and new contributions are welcome.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Symmetry-enforced quantum spin Hall insulators in $π$-flux models.   We prove a Lieb-Schultz-Mattis theorem for the quantum spin Hall effect\n(QSHE) in two-dimensional $\\pi$-flux models. In the presence of time reversal,\n$U(1)$ charge conservation and magnetic translation (with $\\pi$-flux per unit\ncell) symmetries, if a generic interacting Hamiltonian has a unique gapped\nsymmetric ground state at half filling (i.e. an odd number of electrons per\nunit cell), it can only be a QSH insulator. In other words, a trivial Mott\ninsulator is forbidden by symmetries at half filling. We further show that such\na symmetry-enforced QSHE can be realized in cold atoms, by shaking an optical\nlattice and applying a time-dependent Zeeman field.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Matching neural paths: transfer from recognition to correspondence search.   Many machine learning tasks require finding per-part correspondences between\nobjects. In this work we focus on low-level correspondences - a highly\nambiguous matching problem. We propose to use a hierarchical semantic\nrepresentation of the objects, coming from a convolutional neural network, to\nsolve this ambiguity. Training it for low-level correspondence prediction\ndirectly might not be an option in some domains where the ground-truth\ncorrespondences are hard to obtain. We show how transfer from recognition can\nbe used to avoid such training. Our idea is to mark parts as \"matching\" if\ntheir features are close to each other at all the levels of convolutional\nfeature hierarchy (neural paths). Although the overall number of such paths is\nexponential in the number of layers, we propose a polynomial algorithm for\naggregating all of them in a single backward pass. The empirical validation is\ndone on the task of stereo correspondence and demonstrates that we achieve\ncompetitive results among the methods which do not use labeled target domain\ndata.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The heat trace for the drifting Laplacian and Schrödinger operators on manifolds.   We study the heat trace for both the drifting Laplacian as well as\nSchrödinger operators on compact Riemannian manifolds. In the case of a\nfinite regularity potential or weight function, we prove the existence of a\npartial (six term) asymptotic expansion of the heat trace for small times as\nwell as a suitable remainder estimate. We also demonstrate that the more\nprecise asymptotic behavior of the remainder is determined by and conversely\ndistinguishes higher (Sobolev) regularity on the potential or weight function.\nIn the case of a smooth weight function, we determine the full asymptotic\nexpansion of the heat trace for the drifting Laplacian for small times. We then\nuse the heat trace to study the asymptotics of the eigenvalue counting\nfunction. In both cases the Weyl law coincides with the Weyl law for the\nRiemannian manifold with the standard Laplace-Beltrami operator. We conclude by\ndemonstrating isospectrality results for the drifting Laplacian on compact\nmanifolds.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Overfitting Mechanism and Avoidance in Deep Neural Networks.   Assisted by the availability of data and high performance computing, deep\nlearning techniques have achieved breakthroughs and surpassed human performance\nempirically in difficult tasks, including object recognition, speech\nrecognition, and natural language processing. As they are being used in\ncritical applications, understanding underlying mechanisms for their successes\nand limitations is imperative. In this paper, we show that overfitting, one of\nthe fundamental issues in deep neural networks, is due to continuous gradient\nupdating and scale sensitiveness of cross entropy loss. By separating samples\ninto correctly and incorrectly classified ones, we show that they behave very\ndifferently, where the loss decreases in the correct ones and increases in the\nincorrect ones. Furthermore, by analyzing dynamics during training, we propose\na consensus-based classification algorithm that enables us to avoid overfitting\nand significantly improve the classification accuracy especially when the\nnumber of training samples is limited. As each trained neural network depends\non extrinsic factors such as initial values as well as training data, requiring\nconsensus among multiple models reduces extrinsic factors substantially; for\nstatistically independent models, the reduction is exponential. Compared to\nensemble algorithms, the proposed algorithm avoids overgeneralization by not\nclassifying ambiguous inputs. Systematic experimental results demonstrate the\neffectiveness of the proposed algorithm. For example, using only 1000 training\nsamples from MNIST dataset, the proposed algorithm achieves 95% accuracy,\nsignificantly higher than any of the individual models, with 90% of the test\nsamples classified.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Biomedical Event Trigger Identification Using Bidirectional Recurrent Neural Network Based Models.   Biomedical events describe complex interactions between various biomedical\nentities. Event trigger is a word or a phrase which typically signifies the\noccurrence of an event. Event trigger identification is an important first step\nin all event extraction methods. However many of the current approaches either\nrely on complex hand-crafted features or consider features only within a\nwindow. In this paper we propose a method that takes the advantage of recurrent\nneural network (RNN) to extract higher level features present across the\nsentence. Thus hidden state representation of RNN along with word and entity\ntype embedding as features avoid relying on the complex hand-crafted features\ngenerated using various NLP toolkits. Our experiments have shown to achieve\nstate-of-art F1-score on Multi Level Event Extraction (MLEE) corpus. We have\nalso performed category-wise analysis of the result and discussed the\nimportance of various features in trigger identification task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mean-Field Controllability and Decentralized Stabilization of Markov Chains, Part I: Global Controllability and Rational Feedbacks.   In this paper, we study the controllability and stabilizability properties of\nthe Kolmogorov forward equation of a continuous time Markov chain (CTMC)\nevolving on a finite state space, using the transition rates as the control\nparameters. Firstly, we prove small-time local and global controllability from\nand to strictly positive equilibrium configurations when the underlying graph\nis strongly connected. Secondly, we show that there always exists a locally\nexponentially stabilizing decentralized linear (density-)feedback law that\ntakes zero valu at equilibrium and respects the graph structure, provided that\nthe transition rates are allowed to be negative and the desired target density\nlies in the interior of the set of probability densities. For bidirected\ngraphs, that is, graphs where a directed edge in one direction implies an edge\nin the opposite direction, we show that this linear control law can be realized\nusing a decentralized rational feedback law of the form k(x) = a(x) +\nb(x)f(x)/g(x) that also respects the graph structure and control constraints\n(positivity and zero at equilibrium). This enables the possibility of using\nLinear Matrix Inequality (LMI) based tools to algorithmically construct\ndecentralized density feedback controllers for stabilization of a robotic swarm\nto a target task distribution with no task-switching at equilibrium, as we\ndemonstrate with several numerical examples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Monte Carlo Tree Search with Sampled Information Relaxation Dual Bounds.   Monte Carlo Tree Search (MCTS), most famously used in game-play artificial\nintelligence (e.g., the game of Go), is a well-known strategy for constructing\napproximate solutions to sequential decision problems. Its primary innovation\nis the use of a heuristic, known as a default policy, to obtain Monte Carlo\nestimates of downstream values for states in a decision tree. This information\nis used to iteratively expand the tree towards regions of states and actions\nthat an optimal policy might visit. However, to guarantee convergence to the\noptimal action, MCTS requires the entire tree to be expanded asymptotically. In\nthis paper, we propose a new technique called Primal-Dual MCTS that utilizes\nsampled information relaxation upper bounds on potential actions, creating the\npossibility of \"ignoring\" parts of the tree that stem from highly suboptimal\nchoices. This allows us to prove that despite converging to a partial decision\ntree in the limit, the recommended action from Primal-Dual MCTS is optimal. The\nnew approach shows significant promise when used to optimize the behavior of a\nsingle driver navigating a graph while operating on a ride-sharing platform.\nNumerical experiments on a real dataset of 7,000 trips in New Jersey suggest\nthat Primal-Dual MCTS improves upon standard MCTS by producing deeper decision\ntrees and exhibits a reduced sensitivity to the size of the action space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Game-Theoretic Choice of Curing Rates Against Networked SIS Epidemics by Human Decision-Makers.   We study networks of human decision-makers who independently decide how to\nprotect themselves against Susceptible-Infected-Susceptible (SIS) epidemics.\nMotivated by studies in behavioral economics showing that humans perceive\nprobabilities in a nonlinear fashion, we examine the impacts of such\nmisperceptions on the equilibrium protection strategies. In our setting, nodes\nchoose their curing rates to minimize the infection probability under the\ndegree-based mean-field approximation of the SIS epidemic plus the cost of\ntheir selected curing rate. We establish the existence of a degree based\nequilibrium under both true and nonlinear perceptions of infection\nprobabilities (under suitable assumptions). When the per-unit cost of curing\nrate is sufficiently high, we show that true expectation minimizers choose the\ncuring rate to be zero at the equilibrium, while curing rate is nonzero under\nnonlinear probability weighting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Observation of Skyrmions at Room Temperature in Co2FeAl Heusler Alloy Ultrathin Films.   Magnetic skyrmions are topological spin structures having immense potential\nfor energy efficient spintronic devices. However, observations of skyrmions at\nroom temperature are limited to patterned nanostructures. Here, we report the\nobservation of stable skyrmions in unpatterned Ta/Co2FeAl(CFA)/MgO thin film\nheterostructures at room temperature and in zero external magnetic field\nemploying magnetic force microscopy. The skyrmions are observed in a trilayer\nstructure comprised of heavy metal (HM)/ferromagnet (FM)/Oxide interfaces which\nresult in strong interfacial Dzyaloshinskii-Moriya interaction (i-DMI) as\nevidenced by Brillouin light scattering measurements, in agreement with the\nresults of micromagnetic simulations. We also emphasize on room temperature\nobservation of multiple skyrmions which can be stabilized for suitable choices\nof CFA layer thickness, perpendicular magnetic anisotropy, and i-DMI. These\nresults open up a new paradigm for designing room temperature spintronic\ndevices based on skyrmions in FM continuous thin films.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Interpreted Formalisms for Configurations.   Imprecise and incomplete specification of system \\textit{configurations}\nthreatens safety, security, functionality, and other critical system properties\nand uselessly enlarges the configuration spaces to be searched by configuration\nengineers and auto-tuners. To address these problems, this paper introduces\n\\textit{interpreted formalisms based on real-world types for configurations}.\nConfiguration values are lifted to values of real-world types, which we\nformalize as \\textit{subset types} in Coq. Values of these types are dependent\npairs whose components are values of underlying Coq types and proofs of\nadditional properties about them. Real-world types both extend and further\nconstrain \\textit{machine-level} configurations, enabling richer, proof-based\nchecking of their consistency with real-world constraints. Tactic-based proof\nscripts are written once to automate the construction of proofs, if proofs\nexist, for configuration fields and whole configurations. \\textit{Failures to\nprove} reveal real-world type errors. Evaluation is based on a case study of\ncombinatorial optimization of Hadoop performance by meta-heuristic search over\nHadoop configurations spaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Algorithmic Decision Making in the Presence of Unmeasured Confounding.   On a variety of complex decision-making tasks, from doctors prescribing\ntreatment to judges setting bail, machine learning algorithms have been shown\nto outperform expert human judgments. One complication, however, is that it is\noften difficult to anticipate the effects of algorithmic policies prior to\ndeployment, making the decision to adopt them risky. In particular, one\ngenerally cannot use historical data to directly observe what would have\nhappened had the actions recommended by the algorithm been taken. One standard\nstrategy is to model potential outcomes for alternative decisions assuming that\nthere are no unmeasured confounders (i.e., to assume ignorability). But if this\nignorability assumption is violated, the predicted and actual effects of an\nalgorithmic policy can diverge sharply. In this paper we present a flexible,\nBayesian approach to gauge the sensitivity of predicted policy outcomes to\nunmeasured confounders. We show that this policy evaluation problem is a\ngeneralization of estimating heterogeneous treatment effects in observational\nstudies, and so our methods can immediately be applied to that setting.\nFinally, we show, both theoretically and empirically, that under certain\nconditions it is possible to construct near-optimal algorithmic policies even\nwhen ignorability is violated. We demonstrate the efficacy of our methods on a\nlarge dataset of judicial actions, in which one must decide whether defendants\nawaiting trial should be required to pay bail or can be released without\npayment.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Friendship Maintenance and Prediction in Multiple Social Networks.   Due to the proliferation of online social networks (OSNs), users find\nthemselves participating in multiple OSNs. These users leave their activity\ntraces as they maintain friendships and interact with other users in these\nOSNs. In this work, we analyze how users maintain friendship in multiple OSNs\nby studying users who have accounts in both Twitter and Instagram.\nSpecifically, we study the similarity of a user's friendship and the evenness\nof friendship distribution in multiple OSNs. Our study shows that most users in\nTwitter and Instagram prefer to maintain different friendships in the two OSNs,\nkeeping only a small clique of common friends in across the OSNs. Based upon\nour empirical study, we conduct link prediction experiments to predict missing\nfriendship links in multiple OSNs using the neighborhood features, neighborhood\nfriendship maintenance features and cross-link features. Our link prediction\nexperiments shows that un- supervised methods can yield good accuracy in\npredicting links in one OSN using another OSN data and the link prediction\naccuracy can be further improved using supervised method with friendship\nmaintenance and others measures as features.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Optimizing wearable assistive devices with neuromuscular models and optimal control.   The coupling of human movement dynamics with the function and design of\nwearable assistive devices is vital to better understand the interaction\nbetween the two. Advanced neuromuscular models and optimal control formulations\nprovide the possibility to study and improve this interaction. In addition,\noptimal control can also be used to generate predictive simulations that\ngenerate novel movements for the human model under varying optimization\ncriterion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Markov Chain Model for the Cure Rate of Non-Performing Loans.   A Markov-chain model is developed for the purpose estimation of the cure rate\nof non-performing loans. The technique is performed collectively, on portfolios\nand it can be applicable in the process of calculation of credit impairment. It\nis efficient in terms of data manipulation costs which makes it accessible even\nto smaller financial institutions. In addition, several other applications to\nportfolio optimization are suggested.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Uniqueness and radial symmetry of minimizers for a nonlocal variational problem.   In this paper we prove the uniqueness and radial symmetry of minimizers for\nvariational problems that model several phenomena. The uniqueness is a\nconsequence of the convexity of the functional. The main technique is Fourier\ntransform of tempered distributions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Distributed Impedance Control of Latency-Prone Robotic Systems with Series Elastic Actuation.   Robotic systems are increasingly relying on distributed feedback controllers\nto tackle complex and latency-prone sensing and decision problems. These\ndemands come at the cost of a growing computational burden and, as a result,\nlarger controller latencies. To maximize robustness to mechanical disturbances\nand achieve high control performance, we emphasize the necessity for executing\ndamping feedback in close proximity to the control plant while allocating\nstiffness feedback in a latency-prone centralized control process.\nAdditionally, series elastic actuators (SEAs) are becoming prevalent in\ntorque-controlled robots during recent years to achieve compliant interactions\nwith environments and humans. However, designing optimal impedance controllers\nand characterizing impedance performance for SEAs with time delays and\nfiltering are still under-explored problems. The presented study addresses the\noptimal controller design problem by devising a critically-damped gain design\nmethod for a class of SEA cascaded control architectures, which is composed of\nouter-impedance and inner-torque feedback loops. Via the proposed controller\ndesign criterion, we adopt frequency-domain methods to thoroughly analyze the\neffects of time delays, filtering and load inertia on SEA impedance\nperformance. These results are further validated through the analysis,\nsimulation, and experimental testing on high-performance actuators and on an\nomnidirectional mobile base.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Information and estimation in Fokker-Planck channels.   We study the relationship between information- and estimation-theoretic\nquantities in time-evolving systems. We focus on the Fokker-Planck channel\ndefined by a general stochastic differential equation, and show that the time\nderivatives of entropy, KL divergence, and mutual information are characterized\nby estimation-theoretic quantities involving an appropriate generalization of\nthe Fisher information. Our results vastly extend De Bruijn's identity and the\nclassical I-MMSE relation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "MOBILITY21: Strategic Investments for Transportation Infrastructure & Technology.   America's transportation infrastructure is the backbone of our economy. A\nstrong infrastructure means a strong America - an America that competes\nglobally, supports local and regional economic development, and creates jobs.\nStrategic investments in our transportation infrastructure are vital to our\nnational security, economic growth, transportation safety and our technology\nleadership. This document outlines critical needs for our transportation\ninfrastructure, identifies new technology drivers and proposes strategic\ninvestments for safe and efficient air, ground, rail and marine mobility of\npeople and goods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parylene-C microfibrous thin films as phononic crystals.   Phononic bandgaps of Parylene-C microfibrous thin films (muFTFs) were\ncomputationally determined by treating them as phononic crystals comprising\nidentical microfibers arranged either on a square or a hexagonal lattice. The\nmicrofibers could be columnar,chevronic, or helical in shape, and the host\nmedium could be either water or air. All bandgaps were observed to lie in the\n0.01-to-162.9-MHz regime, for microfibers of realistically chosen dimensions.\nThe upper limit of the frequency of bandgaps was the highest for the columnar\nmuFTF and the lowest for the chiral muFTF. More bandgaps exist when the host\nmedium is water than air. Complete bandgaps were observed for the columnar\nmuFTF with microfibers arranged on a hexagonal lattice in air, the chevronic\nmuFTF with microfibers arranged on a square lattice in water, and the chiral\nmuFTF with microfibers arranged on a hexagonal lattice in either air or water.\nThe softness of the Parylene-C muFTFs makes them mechanically tunable, and\ntheir bandgaps can be exploited in multiband ultrasonic filters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "An Improved Training Procedure for Neural Autoregressive Data Completion.   Neural autoregressive models are explicit density estimators that achieve\nstate-of-the-art likelihoods for generative modeling. The D-dimensional data\ndistribution is factorized into an autoregressive product of one-dimensional\nconditional distributions according to the chain rule. Data completion is a\nmore involved task than data generation: the model must infer missing variables\nfor any partially observed input vector. Previous work introduced an\norder-agnostic training procedure for data completion with autoregressive\nmodels. Missing variables in any partially observed input vector can be imputed\nefficiently by choosing an ordering where observed dimensions precede\nunobserved ones and by computing the autoregressive product in this order. In\nthis paper, we provide evidence that the order-agnostic (OA) training procedure\nis suboptimal for data completion. We propose an alternative procedure (OA++)\nthat reaches better performance in fewer computations. It can handle all data\ncompletion queries while training fewer one-dimensional conditional\ndistributions than the OA procedure. In addition, these one-dimensional\nconditional distributions are trained proportionally to their expected usage at\ninference time, reducing overfitting. Finally, our OA++ procedure can exploit\nprior knowledge about the distribution of inference completion queries, as\nopposed to OA. We support these claims with quantitative experiments on\nstandard datasets used to evaluate autoregressive generative models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonlinear Unknown Input and State Estimation Algorithm in Mobile Robots.   This technical report provides the description and the derivation of a novel\nnonlinear unknown input and state estimation algorithm (NUISE) for mobile\nrobots. The algorithm is designed for real-world robots with nonlinear dynamic\nmodels and subject to stochastic noises on sensing and actuation. Leveraging\nsensor readings and planned control commands, the algorithm detects and\nquantifies anomalies on both sensors and actuators. Later, we elaborate the\ndynamic models of two distinctive mobile robots for the purpose of\ndemonstrating the application of NUISE. This report serves as a supplementary\ndocument for [1].",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Placing your Coins on a Shelf.   We consider the problem of packing a family of disks \"on a shelf\", that is,\nsuch that each disk touches the $x$-axis from above and such that no two disks\noverlap. We prove that the problem of minimizing the distance between the\nleftmost point and the rightmost point of any disk is NP-hard. On the positive\nside, we show how to approximate this problem within a factor of 4/3 in $O(n\n\\log n)$ time, and provide an $O(n \\log n)$-time exact algorithm for a special\ncase, in particular when the ratio between the largest and smallest radius is\nat most four.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Active modulation of electromagnetically induced transparency analogue in terahertz hybrid metal-graphene metamaterials.   Metamaterial analogues of electromagnetically induced transparency (EIT) have\nbeen intensively studied and widely employed for slow light and enhanced\nnonlinear effects. In particular, the active modulation of the EIT analogue and\nwell-controlled group delay in metamaterials have shown great prospects in\noptical communication networks. Previous studies have focused on the optical\ncontrol of the EIT analogue by integrating the photoactive materials into the\nunit cell, however, the response time is limited by the recovery time of the\nexcited carriers in these bulk materials. Graphene has recently emerged as an\nexceptional optoelectronic material. It shows an ultrafast relaxation time on\nthe order of picosecond and its conductivity can be tuned via manipulating the\nFermi energy. Here we integrate a monolayer graphene into metal-based terahertz\n(THz) metamaterials, and realize a complete modulation in the resonance\nstrength of the EIT analogue at the accessible Fermi energy. The physical\nmechanism lies in the active tuning the damping rate of the dark mode resonator\nthrough the recombination effect of the conductive graphene. Note that the\nmonolayer morphology in our work is easier to fabricate and manipulate than\nisolated fashion. This work presents a novel modulation strategy of the EIT\nanalogue in the hybrid metamaterials, and pave the way towards designing very\ncompact slow light devices to meet future demand of ultrafast optical signal\nprocessing.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "What drives transient behaviour in complex systems?.   We study transient behaviour in the dynamics of complex systems described by\na set of non-linear ODE's. Destabilizing nature of transient trajectories is\ndiscussed and its connection with the eigenvalue-based linearization procedure.\nThe complexity is realized as a random matrix drawn from a modified May-Wigner\nmodel. Based on the initial response of the system, we identify a novel\nstable-transient regime. We calculate exact abundances of typical and extreme\ntransient trajectories finding both Gaussian and Tracy-Widom distributions\nknown in extreme value statistics. We identify degrees of freedom driving\ntransient behaviour as connected to the eigenvectors and encoded in a\nnon-orthogonality matrix $T_0$. We accordingly extend the May-Wigner model to\ncontain a phase with typical transient trajectories present. An exact norm of\nthe trajectory is obtained in the vanishing $T_0$ limit where it describes a\nnormal matrix.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Black holes in vector-tensor theories.   We study static and spherically symmetric black hole (BH) solutions in\nsecond-order generalized Proca theories with nonminimal vector field derivative\ncouplings to the Ricci scalar, the Einstein tensor, and the double dual Riemann\ntensor. We find concrete Lagrangians which give rise to exact BH solutions by\nimposing two conditions of the two identical metric components and the constant\nnorm of the vector field. These exact solutions are described by either\nReissner-Nordström (RN), stealth Schwarzschild, or extremal RN solutions\nwith a non-trivial longitudinal mode of the vector field. We then numerically\nconstruct BH solutions without imposing these conditions. For cubic and quartic\nLagrangians with power-law couplings which encompass vector Galileons as the\nspecific cases, we show the existence of BH solutions with the difference\nbetween two non-trivial metric components. The quintic-order power-law\ncouplings do not give rise to non-trivial BH solutions regular throughout the\nhorizon exterior. The sixth-order and intrinsic vector-mode couplings can lead\nto BH solutions with a secondary hair. For all the solutions, the vector field\nis regular at least at the future or past horizon. The deviation from General\nRelativity induced by the Proca hair can be potentially tested by future\nmeasurements of gravitational waves in the nonlinear regime of gravity.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Consistency of Compressive Spectral Clustering.   Spectral clustering is one of the most popular methods for community\ndetection in graphs. A key step in spectral clustering algorithms is the eigen\ndecomposition of the $n{\\times}n$ graph Laplacian matrix to extract its $k$\nleading eigenvectors, where $k$ is the desired number of clusters among $n$\nobjects. This is prohibitively complex to implement for very large datasets.\nHowever, it has recently been shown that it is possible to bypass the eigen\ndecomposition by computing an approximate spectral embedding through graph\nfiltering of random signals. In this paper, we analyze the working of spectral\nclustering performed via graph filtering on the stochastic block model.\nSpecifically, we characterize the effects of sparsity, dimensionality and\nfilter approximation error on the consistency of the algorithm in recovering\nplanted clusters.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A stable numerical strategy for Reynolds-Rayleigh-Plesset coupling.   The coupling of Reynolds and Rayleigh-Plesset equations has been used in\nseveral works to simulate lubricated devices considering cavitation. The\nnumerical strategies proposed so far are variants of a staggered strategy where\nReynolds equation is solved considering the bubble dynamics frozen, and then\nthe Rayleigh-Plesset equation is solved to update the bubble radius with the\npressure frozen. We show that this strategy has severe stability issues and a\nstable methodology is proposed. The proposed methodology performance is\nassessed on two physical settings. The first one concerns the propagation of a\ndecompression wave along a fracture considering the presence of cavitation\nnuclei. The second one is a typical journal bearing, in which the coupled model\nis compared with the Elrod-Adams model.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Manuscripts in Time and Space: Experiments in Scriptometrics on an Old French Corpus.   Witnesses of medieval literary texts, preserved in manuscript, are layered\nobjects , being almost exclusively copies of copies. This results in multiple\nand hard to distinguish linguistic strata -- the author's scripta interacting\nwith the scriptae of the various scribes -- in a context where literary written\nlanguage is already a dialectal hybrid. Moreover, no single linguistic\nphenomenon allows to distinguish between different scriptae, and only the\ncombination of multiple characteristics is likely to be significant [9] -- but\nwhich ones? The most common approach is to search for these features in a set\nof previously selected texts, that are supposed to be representative of a given\nscripta. This can induce a circularity, in which texts are used to select\nfeatures that in turn characterise them as belonging to a linguistic area. To\ncounter this issue, this paper offers an unsupervised and corpus-based\napproach, in which clustering methods are applied to an Old French corpus to\nidentify main divisions and groups. Ultimately, scriptometric profiles are\nbuilt for each of them.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "New neutrino physics and the altered shapes of solar neutrino spectra.   Neutrinos coming from the Sun's core are now measured with a high precision,\nand fundamental neutrino oscillations parameters are determined with a good\naccuracy. In this work, we estimate the impact that a new neutrino physics\nmodel, the so-called generalized Mikheyev-Smirnov-Wolfenstein (MSW) oscillation\nmechanism, has on the shape of some of leading solar neutrino spectra, some of\nwhich will be partially tested by the next generation of solar neutrino\nexperiments. In these calculations, we use a high-precision standard solar\nmodel in good agreement with helioseismology data. We found that the neutrino\nspectra of the different solar nuclear reactions of the proton-proton chains\nand carbon-nitrogen-oxygen cycle have quite distinct sensitivities to the new\nneutrino physics. The $HeP$ and $^8B$ neutrino spectra are the ones for which\ntheir shapes are more affected when neutrinos interact with quarks in addition\nto electrons. The shape of the $^{15}O$ and $^{17}F$ neutrino spectra are also\nmodified, although in these cases the impact is much smaller. Finally, the\nimpact in the shape of the $PP$ and $^{13}N$ neutrino spectra is practically\nnegligible.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Tanaka formula for strictly stable processes.   For symmetric Lévy processes, if the local times exist, the Tanaka formula\nhas already constructed via the techniques in the potential theory by Salminen\nand Yor (2007). In this paper, we study the Tanaka formula for arbitrary\nstrictly stable processes with index $\\alpha \\in (1,2)$ including spectrally\npositive and negative cases in a framework of Itô's stochastic calculus. Our\napproach to the existence of local times for such processes is different from\nBertoin (1996).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Coupling Story to Visualization: Using Textual Analysis as a Bridge Between Data and Interpretation.   Online writers and journalism media are increasingly combining visualization\n(and other multimedia content) with narrative text to create narrative\nvisualizations. Often, however, the two elements are presented independently of\none another. We propose an approach to automatically integrate text and\nvisualization elements. We begin with a writer's narrative that presumably can\nbe supported with visual data evidence. We leverage natural language\nprocessing, quantitative narrative analysis, and information visualization to\n(1) automatically extract narrative components (who, what, when, where) from\ndata-rich stories, and (2) integrate the supporting data evidence with the text\nto develop a narrative visualization. We also employ bidirectional interaction\nfrom text to visualization and visualization to text to support reader\nexploration in both directions. We demonstrate the approach with a case study\nin the data-rich field of sports journalism.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bayesian Scale Estimation for Monocular SLAM Based on Generic Object Detection for Correcting Scale Drift.   This work proposes a new, online algorithm for estimating the local scale\ncorrection to apply to the output of a monocular SLAM system and obtain an as\nfaithful as possible metric reconstruction of the 3D map and of the camera\ntrajectory. Within a Bayesian framework, it integrates observations from a\ndeep-learning based generic object detector and a prior on the evolution of the\nscale drift. For each observation class, a predefined prior on the heights of\nthe class objects is used. This allows to define the observations likelihood.\nDue to the scale drift inherent to monocular SLAM systems, we integrate a rough\nmodel on the dynamics of scale drift. Quantitative evaluations of the system\nare presented on the KITTI dataset, and compared with different approaches. The\nresults show a superior performance of our proposal in terms of relative\ntranslational error when compared to other monocular systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Affine Rough Models.   The goal of this survey article is to explain and elucidate the affine\nstructure of recent models appearing in the rough volatility literature, and\nshow how it leads to exponential-affine transform formulas.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Network Structure of Two-Dimensional Decaying Isotropic Turbulence.   The present paper reports on our effort to characterize vortical interactions\nin complex fluid flows through the use of network analysis. In particular, we\nexamine the vortex interactions in two-dimensional decaying isotropic\nturbulence and find that the vortical interaction network can be characterized\nby a weighted scale-free network. It is found that the turbulent flow network\nretains its scale-free behavior until the characteristic value of circulation\nreaches a critical value. Furthermore, we show that the two-dimensional\nturbulence network is resilient against random perturbations but can be greatly\ninfluenced when forcing is focused towards the vortical structures that are\ncategorized as network hubs. These findings can serve as a network-analytic\nfoundation to examine complex geophysical and thin-film flows and take\nadvantage of the rapidly growing field of network theory, which complements\nongoing turbulence research based on vortex dynamics, hydrodynamic stability,\nand statistics. While additional work is essential to extend the mathematical\ntools from network analysis to extract deeper physical insights of turbulence,\nan understanding of turbulence based on the interaction-based network-theoretic\nframework presents a promising alternative in turbulence modeling and control\nefforts.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Comparing Aggregators for Relational Probabilistic Models.   Relational probabilistic models have the challenge of aggregation, where one\nvariable depends on a population of other variables. Consider the problem of\npredicting gender from movie ratings; this is challenging because the number of\nmovies per user and users per movie can vary greatly. Surprisingly, aggregation\nis not well understood. In this paper, we show that existing relational models\n(implicitly or explicitly) either use simple numerical aggregators that lose\ngreat amounts of information, or correspond to naive Bayes, logistic\nregression, or noisy-OR that suffer from overconfidence. We propose new simple\naggregators and simple modifications of existing models that empirically\noutperform the existing ones. The intuition we provide on different (existing\nor new) models and their shortcomings plus our empirical findings promise to\nform the foundation for future representations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Economic Design of Memory-Type Control Charts: The Fallacy of the Formula Proposed by Lorenzen and Vance (1986).   The memory-type control charts, such as EWMA and CUSUM, are powerful tools\nfor detecting small quality changes in univariate and multivariate processes.\nMany papers on economic design of these control charts use the formula proposed\nby Lorenzen and Vance (1986) [Lorenzen, T. J., & Vance, L. C. (1986). The\neconomic design of control charts: A unified approach. Technometrics, 28(1),\n3-10, DOI: 10.2307/1269598]. This paper shows that this formula is not correct\nfor memory-type control charts and its values can significantly deviate from\nthe original values even if the ARL values used in this formula are accurately\ncomputed. Consequently, the use of this formula can result in charts that are\nnot economically optimal. The formula is corrected for memory-type control\ncharts, but unfortunately the modified formula is not a helpful tool from a\ncomputational perspective. We show that simulation-based optimization is a\npossible alternative method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Methodological variations in lagged regression for detecting physiologic drug effects in EHR data.   We studied how lagged linear regression can be used to detect the physiologic\neffects of drugs from data in the electronic health record (EHR). We\nsystematically examined the effect of methodological variations ((i) time\nseries construction, (ii) temporal parameterization, (iii) intra-subject\nnormalization, (iv) differencing (lagged rates of change achieved by taking\ndifferences between consecutive measurements), (v) explanatory variables, and\n(vi) regression models) on performance of lagged linear methods in this\ncontext. We generated two gold standards (one knowledge-base derived, one\nexpert-curated) for expected pairwise relationships between 7 drugs and 4 labs,\nand evaluated how the 64 unique combinations of methodological perturbations\nreproduce gold standards. Our 28 cohorts included patients in Columbia\nUniversity Medical Center/NewYork-Presbyterian Hospital clinical database. The\nmost accurate methods achieved AUROC of 0.794 for knowledge-base derived gold\nstandard (95%CI [0.741, 0.847]) and 0.705 for expert-curated gold standard (95%\nCI [0.629, 0.781]). We observed a 0.633 mean AUROC (95%CI [0.610, 0.657],\nexpert-curated gold standard) across all methods that re-parameterize time\naccording to sequence and use either a joint autoregressive model with\ndifferencing or an independent lag model without differencing. The complement\nof this set of methods achieved a mean AUROC close to 0.5, indicating the\nimportance of these choices. We conclude that time- series analysis of EHR data\nwill likely rely on some of the beneficial pre-processing and modeling\nmethodologies identified, and will certainly benefit from continued careful\nanalysis of methodological perturbations. This study found that methodological\nvariations, such as pre-processing and representations, significantly affect\nresults, exposing the importance of evaluating these components when comparing\nmachine-learning methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Henri Bénard: Thermal convection and vortex shedding.   We present in this article the work of Henri Bénard (1874-1939), French\nphysicist who began the systematic experimental study of two hydrodynamic\nsystems: the thermal convection of fluids heated from below (the\nRayleigh-Bénard convection and the Bénard-Marangoni convection) and the\nperiodical vortex shedding behind a bluff body in a flow (the\nBénard-Kármán vortex street). Across his scientific biography, we review\nthe interplay between experiments and theory in these two major subjects of\nfluid mechanics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "High-temperature charge density wave correlations in La$_{1.875}$Ba$_{0.125}$CuO$_{4}$ without spin-charge locking.   Although all superconducting cuprates display charge-ordering tendencies,\ntheir low-temperature properties are distinct, impeding efforts to understand\nthe phenomena within a single conceptual framework. While some systems exhibit\nstripes of charge and spin, with a locked periodicity, others host charge\ndensity waves (CDWs) without any obviously related spin order. Here we use\nresonant inelastic x-ray scattering (RIXS) to follow the evolution of charge\ncorrelations in the canonical stripe ordered cuprate\nLa$_{1.875}$Ba$_{0.125}$CuO$_{4}$ (LBCO~$1/8$) across its ordering transition.\nWe find that high-temperature charge correlations are unlocked from the\nwavevector of the spin correlations, signaling analogies to CDW phases in\nvarious other cuprates. This indicates that stripe order at low temperatures is\nstabilized by the coupling of otherwise independent charge and spin density\nwaves, with important implications for the relation between charge and spin\ncorrelations in the cuprates.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Statistical properties of an enstrophy conserving discretisation for the stochastic quasi-geostrophic equation.   A framework of variational principles for stochastic fluid dynamics was\npresented by Holm (2015), and these stochastic equations were also derived by\nCotter et al. (2017). We present a conforming finite element discretisation for\nthe stochastic quasi-geostrophic equation that was derived from this framework.\nThe discretisation preserves the first two moments of potential vorticity, i.e.\nthe mean potential vorticity and the enstrophy. Following the work of Dubinkina\nand Frank (2007), who investigated the statistical mechanics of discretisations\nof the deterministic quasi-geostrophic equation, we investigate the statistical\nmechanics of our discretisation of the stochastic quasi-geostrophic equation.\nWe compare the statistical properties of our discretisation with the Gibbs\ndistribution under assumption of these conserved quantities, finding that there\nis agreement between the statistics under a wide range of set-ups.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Semi-supervised Conditional GANs.   We introduce a new model for building conditional generative models in a\nsemi-supervised setting to conditionally generate data given attributes by\nadapting the GAN framework. The proposed semi-supervised GAN (SS-GAN) model\nuses a pair of stacked discriminators to learn the marginal distribution of the\ndata, and the conditional distribution of the attributes given the data\nrespectively. In the semi-supervised setting, the marginal distribution (which\nis often harder to learn) is learned from the labeled + unlabeled data, and the\nconditional distribution is learned purely from the labeled data. Our\nexperimental results demonstrate that this model performs significantly better\ncompared to existing semi-supervised conditional GAN models.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Local-global principles in circle packings.   We generalize work of Bourgain-Kontorovich and Zhang, proving an almost\nlocal-to-global property for the curvatures of certain circle packings, to a\nlarge class of Kleinian groups. Specifically, we associate in a natural way an\ninfinite family of integral packings of circles to any Kleinian group $\\mathcal\nA\\leq\\textrm{PSL}_2(K)$ satisfying certain conditions, where $K$ is an\nimaginary quadratic field, and show that the curvatures of the circles in any\nsuch packing satisfy an almost local-to-global principle. A key ingredient in\nthe proof of this is that $\\mathcal A$ possesses a spectral gap property, which\nwe prove for any infinite-covolume, geometrically finite, Zariski dense\nKleinian group in $\\textrm{PSL}_2(\\mathcal{O}_K)$ containing a Zariski dense\nsubgroup of $\\textrm{PSL}_2(\\mathbb{Z})$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Robust Gaussian Stochastic Process Emulation.   We consider estimation of the parameters of a Gaussian Stochastic Process\n(GaSP), in the context of emulation (approximation) of computer models for\nwhich the outcomes are real-valued scalars. The main focus is on estimation of\nthe GaSP parameters through various generalized maximum likelihood methods,\nmostly involving finding posterior modes; this is because full Bayesian\nanalysis in computer model emulation is typically prohibitively expensive. The\nposterior modes that are studied arise from objective priors, such as the\nreference prior. These priors have been studied in the literature for the\nsituation of an isotropic covariance function or under the assumption of\nseparability in the design of inputs for model runs used in the GaSP\nconstruction. In this paper, we consider more general designs (e.g., a Latin\nHypercube Design) with a class of commonly used anisotropic correlation\nfunctions, which can be written as a product of isotropic correlation\nfunctions, each having an unknown range parameter and a fixed roughness\nparameter. We discuss properties of the objective priors and marginal\nlikelihoods for the parameters of the GaSP and establish the posterior\npropriety of the GaSP parameters, but our main focus is to demonstrate that\ncertain parameterizations result in more robust estimation of the GaSP\nparameters than others, and that some parameterizations that are in common use\nshould clearly be avoided. These results are applicable to many frequently used\ncovariance functions, e.g., power exponential, Mat{é}rn, rational quadratic\nand spherical covariance. We also generalize the results to the GaSP model with\na nugget parameter. Both theoretical and numerical evidence is presented\nconcerning the performance of the studied procedures.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Pohozaev identity for the fractional $p-$Laplacian on $\\mathbb{R}^N$.   By virtue of a suitable approximation argument, we prove a Pohozaev identity\nfor nonlinear nonlocal problems on $\\mathbb{R}^N$ involving the fractional\n$p-$Laplacian operator. Furthermore we provide an application of the identity\nto show that some relevant levels of the energy functional associated with the\nproblem coincide.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Crystal field excitations and magnons: their roles in oxyselenides Pr2O2M2OSe2 (M = Mn, Fe).   We present the results of neutron scattering experiments to study the crystal\nand magnetic structures of the Mott-insulating transition metal oxyselenides\nPr2O2M2OSe2 (M = Mn, Fe). The structural role of the non-Kramers Pr3+ ion is\ninvestigated and analysis of Pr3+ crystal field excitations performed.\nLong-range order of Pr3+ moments in Pr2O2Fe2OSe2 can be induced by an applied\nmagnetic field.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Like trainer, like bot? Inheritance of bias in algorithmic content moderation.   The internet has become a central medium through which `networked publics'\nexpress their opinions and engage in debate. Offensive comments and personal\nattacks can inhibit participation in these spaces. Automated content moderation\naims to overcome this problem using machine learning classifiers trained on\nlarge corpora of texts manually annotated for offence. While such systems could\nhelp encourage more civil debate, they must navigate inherently normatively\ncontestable boundaries, and are subject to the idiosyncratic norms of the human\nraters who provide the training data. An important objective for platforms\nimplementing such measures might be to ensure that they are not unduly biased\ntowards or against particular norms of offence. This paper provides some\nexploratory methods by which the normative biases of algorithmic content\nmoderation systems can be measured, by way of a case study using an existing\ndataset of comments labelled for offence. We train classifiers on comments\nlabelled by different demographic subsets (men and women) to understand how\ndifferences in conceptions of offence between these groups might affect the\nperformance of the resulting models on various test sets. We conclude by\ndiscussing some of the ethical choices facing the implementers of algorithmic\nmoderation systems, given various desired levels of diversity of viewpoints\namongst discussion participants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Driver Action Prediction Using Deep (Bidirectional) Recurrent Neural Network.   Advanced driver assistance systems (ADAS) can be significantly improved with\neffective driver action prediction (DAP). Predicting driver actions early and\naccurately can help mitigate the effects of potentially unsafe driving\nbehaviors and avoid possible accidents. In this paper, we formulate driver\naction prediction as a timeseries anomaly prediction problem. While the anomaly\n(driver actions of interest) detection might be trivial in this context,\nfinding patterns that consistently precede an anomaly requires searching for or\nextracting features across multi-modal sensory inputs. We present such a driver\naction prediction system, including a real-time data acquisition, processing\nand learning framework for predicting future or impending driver action. The\nproposed system incorporates camera-based knowledge of the driving environment\nand the driver themselves, in addition to traditional vehicle dynamics. It then\nuses a deep bidirectional recurrent neural network (DBRNN) to learn the\ncorrelation between sensory inputs and impending driver behavior achieving\naccurate and high horizon action prediction. The proposed system performs\nbetter than other existing systems on driver action prediction tasks and can\naccurately predict key driver actions including acceleration, braking, lane\nchange and turning at durations of 5sec before the action is executed by the\ndriver.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Modular System for Shelves and Coasts (MOSSCO v1.0) - a flexible and multi-component framework for coupled coastal ocean ecosystem modelling.   Shelf and coastal sea processes extend from the atmosphere through the water\ncolumn and into the sea bed. These processes are driven by physical, chemical,\nand biological interactions at local scales, and they are influenced by\ntransport and cross strong spatial gradients. The linkages between domains and\nmany different processes are not adequately described in current model systems.\nTheir limited integration level in part reflects lacking modularity and\nflexibility; this shortcoming hinders the exchange of data and model components\nand has historically imposed supremacy of specific physical driver models. We\nhere present the Modular System for Shelves and Coasts (MOSSCO,\nthis http URL), a novel domain and process coupling system\ntailored---but not limited--- to the coupling challenges of and applications in\nthe coastal ocean. MOSSCO builds on the existing coupling technology Earth\nSystem Modeling Framework and on the Framework for Aquatic Biogeochemical\nModels, thereby creating a unique level of modularity in both domain and\nprocess coupling; the new framework adds rich metadata, flexible scheduling,\nconfigurations that allow several tens of models to be coupled, and tested\nsetups for coastal coupled applications. That way, MOSSCO addresses the\ntechnology needs of a growing marine coastal Earth System community that\nencompasses very different disciplines, numerical tools, and research\nquestions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Phase-diagram and dynamics of Rydberg-dressed fermions in two-dimensions.   We investigate the ground-state properties and the collective modes of a\ntwo-dimensional two-component Rydberg-dressed Fermi liquid in the\ndipole-blockade regime. We find instability of the homogeneous system toward\nphase separated and density ordered phases, using the Hartree-Fock and\nrandom-phase approximations, respectively. The spectral weight of collective\ndensity oscillations in the homogenous phase also signals the emergence of\ndensity-wave instability. We examine the effect of exchange-hole on the\ndensity-wave instability and on the collective mode dispersion using the\nHubbard local-field factor.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stable Limit Theorems for Empirical Processes under Conditional Neighborhood Dependence.   This paper introduces a new concept of stochastic dependence among many\nrandom variables which we call conditional neighborhood dependence (CND).\nSuppose that there are a set of random variables and a set of sigma algebras\nwhere both sets are indexed by the same set endowed with a neighborhood system.\nWhen the set of random variables satisfies CND, any two non-adjacent sets of\nrandom variables are conditionally independent given sigma algebras having\nindices in one of the two sets' neighborhood. Random variables with CND include\nthose with conditional dependency graphs and a class of Markov random fields\nwith a global Markov property. The CND property is useful for modeling\ncross-sectional dependence governed by a complex, large network. This paper\nprovides two main results. The first result is a stable central limit theorem\nfor a sum of random variables with CND. The second result is a Donsker-type\nresult of stable convergence of empirical processes indexed by a class of\nfunctions satisfying a certain bracketing entropy condition when the random\nvariables satisfy CND.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Terrestrial effects of moderately nearby supernovae.   Recent data indicate one or more moderately nearby supernovae in the early\nPleistocene, with additional events likely in the Miocene. This has motivated\nmore detailed computations, using new information about the nature of\nsupernovae and the distances of these events to describe in more detail the\nsorts of effects that are indicated at the Earth. This short\ncommunication/review is designed to describe some of these effects so that they\nmay possibly be related to changes in the biota around these times.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The perceived assortativity of social networks: Methodological problems and solutions.   Networks describe a range of social, biological and technical phenomena. An\nimportant property of a network is its degree correlation or assortativity,\ndescribing how nodes in the network associate based on their number of\nconnections. Social networks are typically thought to be distinct from other\nnetworks in being assortative (possessing positive degree correlations);\nwell-connected individuals associate with other well-connected individuals, and\npoorly-connected individuals associate with each other. We review the evidence\nfor this in the literature and find that, while social networks are more\nassortative than non-social networks, only when they are built using\ngroup-based methods do they tend to be positively assortative. Non-social\nnetworks tend to be disassortative. We go on to show that connecting\nindividuals due to shared membership of a group, a commonly used method, biases\ntowards assortativity unless a large enough number of censuses of the network\nare taken. We present a number of solutions to overcoming this bias by drawing\non advances in sociological and biological fields. Adoption of these methods\nacross all fields can greatly enhance our understanding of social networks and\nnetworks in general.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Waveform and Spectrum Management for Unmanned Aerial Systems Beyond 2025.   The application domains of civilian unmanned aerial systems (UASs) include\nagriculture, exploration, transportation, and entertainment. The expected\ngrowth of the UAS industry brings along new challenges: Unmanned aerial vehicle\n(UAV) flight control signaling requires low throughput, but extremely high\nreliability, whereas the data rate for payload data can be significant. This\npaper develops UAV number projections and concludes that small and micro UAVs\nwill dominate the US airspace with accelerated growth between 2028 and 2032. We\nanalyze the orthogonal frequency division multiplexing (OFDM) waveform because\nit can provide the much needed flexibility, spectral efficiency, and,\npotentially, reliability and derive suitable OFDM waveform parameters as a\nfunction of UAV flight characteristics. OFDM also lends itself to agile\nspectrum access. Based on our UAV growth predictions, we conclude that dynamic\nspectrum access is needed and discuss the applicability of spectrum sharing\ntechniques for future UAS communications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Inhomogeneous Heisenberg Spin Chain and Quantum Vortex Filament as Non-Holonomically Deformed NLS Systems.   Through the Hasimoto map, various dynamical systems can be mapped to\ndifferent integrodifferential generalizations of Nonlinear Schrodinger (NLS)\nfamily of equations some of which are known to be integrable. Two such\ncontinuum limits, corresponding to the inhomogeneous XXX Heisenberg spin chain\n[Balakrishnan, J. Phys. C 15, L1305 (1982)] and that of a thin vortex filament\nmoving in a superfluid with drag [Shivamoggi, Eur. Phys. J. B 86, 275 (2013)\n86; Van Gorder, Phys. Rev. E 91, 053201 (2015)], are shown to be particular\nnon-holonomic deformations (NHDs) of the standard NLS system involving\ngeneralized parameterizations. Crucially, such NHDs of the NLS system are\nrestricted to specific spectral orders that exactly complements NHDs of the\noriginal physical systems. The specific non-holonomic constraints associated\nwith these integrodifferential generalizations additionally posses distinct\nsemi-classical signature.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Irreducible network backbones: unbiased graph filtering via maximum entropy.   Networks provide an informative, yet non-redundant description of complex\nsystems only if links represent truly dyadic relationships that cannot be\ndirectly traced back to node-specific properties such as size, importance, or\ncoordinates in some embedding space. In any real-world network, some links may\nbe reducible, and others irreducible, to such local properties. This dichotomy\npersists despite the steady increase in data availability and resolution, which\nactually determines an even stronger need for filtering techniques aimed at\ndiscerning essential links from non-essential ones. Here we introduce a\nrigorous method that, for any desired level of statistical significance,\noutputs the network backbone that is irreducible to the local properties of\nnodes, i.e. their degrees and strengths. Unlike previous approaches, our method\nemploys an exact maximum-entropy formulation guaranteeing that the filtered\nnetwork encodes only the links that cannot be inferred from local information.\nExtensive empirical analysis confirms that this approach uncovers essential\nbackbones that are otherwise hidden amidst many redundant relationships and\ninaccessible to other methods. For instance, we retrieve the hub-and-spoke\nskeleton of the US airport network and many specialised patterns of\ninternational trade. Being irreducible to local transportation and economic\nconstraints of supply and demand, these backbones single out genuinely\nhigher-order wiring principles.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "The Taipan Galaxy Survey: Scientific Goals and Observing Strategy.   Taipan is a multi-object spectroscopic galaxy survey starting in 2017 that\nwill cover 2pi steradians over the southern sky, and obtain optical spectra for\nabout two million galaxies out to z<0.4. Taipan will use the newly-refurbished\n1.2m UK Schmidt Telescope at Siding Spring Observatory with the new TAIPAN\ninstrument, which includes an innovative 'Starbugs' positioning system capable\nof rapidly and simultaneously deploying up to 150 spectroscopic fibres (and up\nto 300 with a proposed upgrade) over the 6-deg diameter focal plane, and a\npurpose-built spectrograph operating from 370 to 870nm with resolving power\nR>2000. The main scientific goals of Taipan are: (i) to measure the distance\nscale of the Universe (primarily governed by the local expansion rate, H_0) to\n1% precision, and the structure growth rate of structure to 5%; (ii) to make\nthe most extensive map yet constructed of the mass distribution and motions in\nthe local Universe, using peculiar velocities based on improved Fundamental\nPlane distances, which will enable sensitive tests of gravitational physics;\nand (iii) to deliver a legacy sample of low-redshift galaxies as a unique\nlaboratory for studying galaxy evolution as a function of mass and environment.\nThe final survey, which will be completed within 5 years, will consist of a\ncomplete magnitude-limited sample (i<17) of about 1.2x10^6 galaxies,\nsupplemented by an extension to higher redshifts and fainter magnitudes\n(i<18.1) of a luminous red galaxy sample of about 0.8x10^6 galaxies.\nObservations and data processing will be carried out remotely and in a\nfully-automated way, using a purpose-built automated 'virtual observer'\nsoftware and an automated data reduction pipeline. The Taipan survey is\ndeliberately designed to maximise its legacy value, by complementing and\nenhancing current and planned surveys of the southern sky at wavelengths from\nthe optical to the radio.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Network support of talented people.   Network support is a key success factor for talented people. As an example,\nthe Hungarian Talent Support Network involves close to 1500 Talent Points and\nmore than 200,000 people. This network started the Hungarian Templeton Program\nidentifying and helping 315 exceptional cognitive talents. This network is a\npart of the European Talent Support Network initiated by the European Council\nfor High Ability involving more than 300 organizations in over 30 countries in\nEurope and extending in other continents. These networks are giving good\nexamples that talented people often occupy a central, but highly dynamic\nposition in social networks. The involvement of such 'creative nodes' in\nnetwork-related decision making processes is vital, especially in novel\nenvironmental challenges. Such adaptive/learning responses characterize a large\nvariety of complex systems from proteins, through brains to society. It is\ncrucial for talent support programs to use these networking and learning\nprocesses to increase their efficiency further.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Obstructions to a small hyperbolicity in Helly graphs.   It is known that for every graph $G$ there exists the smallest Helly graph\n$\\cal H(G)$ into which $G$ isometrically embeds ($\\cal H(G)$ is called the\ninjective hull of $G$) such that the hyperbolicity of $\\cal H(G)$ is equal to\nthe hyperbolicity of $G$. Motivated by this, we investigate structural\nproperties of Helly graphs that govern their hyperbolicity and identify three\nisometric subgraphs of the King-grid as structural obstructions to a small\nhyperbolicity in Helly graphs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Linear Progress with Exponential Decay in Weakly Hyperbolic Groups.   A random walk $w_n$ on a separable, geodesic hyperbolic metric space $X$\nconverges to the boundary $\\partial X$ with probability one when the step\ndistribution supports two independent loxodromics. In particular, the random\nwalk makes positive linear progress. Progress is known to be linear with\nexponential decay when (1) the step distribution has exponential tail and (2)\nthe action on $X$ is acylindrical. We extend exponential decay to the\nnon-acylindrical case.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Crime Prediction by Data-Driven Green's Function method.   We develop an algorithm that forecasts cascading events, by employing a\nGreen's function scheme on the basis of the self-exciting point process model.\nThis method is applied to open data of 10 types of crimes happened in Chicago.\nIt shows a good prediction accuracy superior to or comparable to the standard\nmethods which are the expectation-maximization method and prospective hotspot\nmaps method. We find a cascade influence of the crimes that has a long-time,\nlogarithmic tail; this result is consistent with an earlier study on\nburglaries. This long-tail feature cannot be reproduced by the other standard\nmethods. In addition, a merit of the Green's function method is the low\ncomputational cost in the case of high density of events and/or large amount of\nthe training data.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Social versus Moral preferences in the Ultimatum Game: A theoretical model and an experiment.   In the Ultimatum Game (UG) one player, named \"proposer\", has to decide how to\nallocate a certain amount of money between herself and a \"responder\". If the\noffer is greater than or equal to the responder's minimum acceptable offer\n(MAO), then the money is split as proposed, otherwise, neither the proposer nor\nthe responder get anything. The UG has intrigued generations of behavioral\nscientists because people in experiments blatantly violate the equilibrium\npredictions that self-interested proposers offer the minimum available non-zero\namount, and self-interested responders accept. Why are these predictions\nviolated? Previous research has mainly focused on the role of social\npreferences. Little is known about the role of general moral preferences for\ndoing the right thing, preferences that have been shown to play a major role in\nother social interactions (e.g., Dictator Game and Prisoner's Dilemma). Here I\ndevelop a theoretical model and an experiment designed to pit social\npreferences against moral preferences. I find that, although people recognize\nthat offering half and rejecting low offers are the morally right things to do,\nmoral preferences have no causal impact on UG behavior. The experimental data\nare indeed well fit by a model according to which: (i) high UG offers are\nmotivated by inequity aversion and, to a lesser extent, self-interest; (ii)\nhigh MAOs are motivated by inequity aversion.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Focusing light through dynamical samples using fast closed-loop wavefront optimization.   We describe a fast closed-loop optimization wavefront shaping system able to\nfocus light through dynamic scattering media. A MEMS-based spatial light\nmodulator (SLM), a fast photodetector and FPGA electronics are combined to\nimplement a closed-loop optimization of a wavefront with a single mode\noptimization rate of 4.1 kHz. The system performances are demonstrated by\nfocusing light through colloidal solutions of TiO2 particles in glycerol with\ntunable temporal stability.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Cell Tracking via Proposal Generation and Selection.   Microscopy imaging plays a vital role in understanding many biological\nprocesses in development and disease. The recent advances in automation of\nmicroscopes and development of methods and markers for live cell imaging has\nled to rapid growth in the amount of image data being captured. To efficiently\nand reliably extract useful insights from these captured sequences, automated\ncell tracking is essential. This is a challenging problem due to large\nvariation in the appearance and shapes of cells depending on many factors\nincluding imaging methodology, biological characteristics of cells, cell matrix\ncomposition, labeling methodology, etc. Often cell tracking methods require a\nsequence-specific segmentation method and manual tuning of many tracking\nparameters, which limits their applicability to sequences other than those they\nare designed for. In this paper, we propose 1) a deep learning based cell\nproposal method, which proposes candidates for cells along with their scores,\nand 2) a cell tracking method, which links proposals in adjacent frames in a\ngraphical model using edges representing different cellular events and poses\njoint cell detection and tracking as the selection of a subset of cell and edge\nproposals. Our method is completely automated and given enough training data\ncan be applied to a wide variety of microscopy sequences. We evaluate our\nmethod on multiple fluorescence and phase contrast microscopy sequences\ncontaining cells of various shapes and appearances from ISBI cell tracking\nchallenge, and show that our method outperforms existing cell tracking methods.\nCode is available at: this https URL",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Maslov, Chern-Weil and Mean Curvature.   We provide an integral formula for the Maslov index of a pair $(E,F)$ over a\nsurface $\\Sigma$, where $E\\rightarrow\\Sigma$ is a complex vector bundle and\n$F\\subset E_{|\\partial\\Sigma}$ is a totally real subbundle. As in Chern-Weil\ntheory, this formula is written in terms of the curvature of $E$ plus a\nboundary contribution.\nWhen $(E,F)$ is obtained via an immersion of $(\\Sigma,\\partial\\Sigma)$ into a\npair $(M,L)$ where $M$ is Kähler and $L$ is totally real, the formula allows\nus to control the Maslov index in terms of the geometry of $(M,L)$. We exhibit\nnatural conditions on $(M,L)$ which lead to bounds and monotonicity results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Hybrid Normed Ideal Perturbations of n-tuples of Operators I.   In hybrid normed ideal perturbations of $n$-tuples of operators, the normed\nideal is allowed to vary with the component operators. We begin extending to\nthis setting the machinery we developed for normed ideal perturbations based on\nthe modulus of quasicentral approximation and an adaptation of our\nnon-commutative generalization of the Weyl--von~Neumann theorem. For commuting\n$n$-tuples of hermitian operators, the modulus of quasicentral approximation\nremains essentially the same when $\\cC_n^-$ is replaced by a hybrid $n$-tuple\n$\\cC_{p_1,\\dots}^-,\\dots,\\cC^-_{p_n}$, $p_1^{-1} + \\dots + p_n^{-1} = 1$. The\nproof involves singular integrals of mixed homogeneity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Thick Subcategories of the stable category of modules over the exterior algebra I.   We study thick subcategories defined by modules of complexity one in\n$\\underline{\\md}R$, where $R$ is the exterior algebra in $n+1$ indeterminates.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Constrained Coupled Matrix-Tensor Factorization for Learning Time-evolving and Emerging Topics.   Topic discovery has witnessed a significant growth as a field of data mining\nat large. In particular, time-evolving topic discovery, where the evolution of\na topic is taken into account has been instrumental in understanding the\nhistorical context of an emerging topic in a dynamic corpus. Traditionally,\ntime-evolving topic discovery has focused on this notion of time. However,\nespecially in settings where content is contributed by a community or a crowd,\nan orthogonal notion of time is the one that pertains to the level of expertise\nof the content creator: the more experienced the creator, the more advanced the\ntopic. In this paper, we propose a novel time-evolving topic discovery method\nwhich, in addition to the extracted topics, is able to identify the evolution\nof that topic over time, as well as the level of difficulty of that topic, as\nit is inferred by the level of expertise of its main contributors. Our method\nis based on a novel formulation of Constrained Coupled Matrix-Tensor\nFactorization, which adopts constraints well-motivated for, and, as we\ndemonstrate, are essential for high-quality topic discovery. We qualitatively\nevaluate our approach using real data from the Physics and also Programming\nStack Exchange forum, and we were able to identify topics of varying levels of\ndifficulty which can be linked to external events, such as the announcement of\ngravitational waves by the LIGO lab in Physics forum. We provide a quantitative\nevaluation of our method by conducting a user study where experts were asked to\njudge the coherence and quality of the extracted topics. Finally, our proposed\nmethod has implications for automatic curriculum design using the extracted\ntopics, where the notion of the level of difficulty is necessary for the proper\nmodeling of prerequisites and advanced concepts.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Bulk crystalline optomechanics.   Brillouin processes couple light and sound through optomechanical three-wave\ninteractions. Within bulk solids, this coupling is mediated by the intrinsic\nphoto-elastic material response yielding coherent emission of high frequency\n(GHz) acoustic phonons. This same interaction produces strong optical\nnonlinearities that overtake both Raman or Kerr nonlinearities in practically\nall solids. In this paper, we show that the strength and character of Brillouin\ninteractions are radically altered at low temperatures when the phonon\ncoherence length surpasses the system size. In this limit, the solid becomes a\ncoherent optomechanical system with macroscopic (cm-scale) phonon modes\npossessing large ($60\\ \\mu \\rm{g}$) motional masses. These phonon modes, which\nare formed by shaping the surfaces of the crystal into a confocal phononic\nresonator, yield appreciable optomechanical coupling rates (${\\sim}100$ Hz),\nproviding access to ultra-high $Q$-factor ($4.2{\\times}10^7$) phonon modes at\nhigh ($12$ GHz) carrier frequencies. The single-pass nonlinear optical\nsusceptibility is enhanced from its room temperature value by more than four\norders of magnitude. Through use of bulk properties, rather than\nnano-structural control, this comparatively simple approach is enticing for the\nability to engineer optomechanical coupling at high frequencies and with high\npower handling. In contrast to cavity optomechanics, we show that this system\nyields a unique form of dispersive symmetry breaking that enables selective\nphonon heating or cooling without an optical cavity (i.e., cavity-less\noptomechanics). Extending these results, practically any transparent\ncrystalline material can be shaped into an optomechanical system as the basis\nfor materials spectroscopy, new regimes of laser physics, precision metrology,\nquantum information processing, and for studies of macroscopic quantum\ncoherence.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Deterministic and Randomized Diffusion based Iterative Generalized Hard Thresholding (DiFIGHT) for Distributed Sparse Signal Recovery.   In this paper, we propose a distributed iterated hard thresholding algorithm\ntermed DiFIGHT over a network that is built on the diffusion mechanism and also\npropose a modification of the proposed algorithm termed MoDiFIGHT, that has low\ncomplexity in terms of communication in the network. We additionally propose\nfour different strategies termed RP, RNP, RGPr, and RGNPr that are used to\nrandomly select a subset of nodes that are subsequently activated to take part\nin the distributed algorithm, so as to reduce the mean number of communications\nduring the run of the distributed algorithm. We present theoretical estimates\nof the long run communication per unit time for these different strategies,\nwhen used by the two proposed algorithms. Also, we present an analysis of the\ntwo proposed algorithms and provide provable bounds on their recovery\nperformance with or without using the random node selection strategies.\nFinally, we use numerical studies to show that both when the random strategies\nare used as well as when they are not used, the proposed algorithms display\nperformances far superior to distributed IHT algorithm using consensus\nmechanism.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Relational Algebra for In-Database Process Mining.   The execution logs that are used for process mining in practice are often\nobtained by querying an operational database and storing the result in a flat\nfile. Consequently, the data processing power of the database system cannot be\nused anymore for this information, leading to constrained flexibility in the\ndefinition of mining patterns and limited execution performance in mining large\nlogs. Enabling process mining directly on a database - instead of via\nintermediate storage in a flat file - therefore provides additional flexibility\nand efficiency. To help facilitate this ideal of in-database process mining,\nthis paper formally defines a database operator that extracts the 'directly\nfollows' relation from an operational database. This operator can both be used\nto do in-database process mining and to flexibly evaluate process mining\nrelated queries, such as: \"which employee most frequently changes the 'amount'\nattribute of a case from one task to the next\". We define the operator using\nthe well-known relational algebra that forms the formal underpinning of\nrelational databases. We formally prove equivalence properties of the operator\nthat are useful for query optimization and present time-complexity properties\nof the operator. By doing so this paper formally defines the necessary\nrelational algebraic elements of a 'directly follows' operator, which are\nrequired for implementation of such an operator in a DBMS.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On discrimination between two close distribution tails.   The goodness-of-fit test for discrimination of two tail distribution using\nhigher order statistics is proposed. The consistency of proposed test is proved\nfor two different alternatives. We do not assume belonging the corresponding\ndistribution function to a maximum domain of attraction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sparsity constrained split feasibility for dose-volume constraints in inverse planning of intensity-modulated photon or proton therapy.   A split feasibility formulation for the inverse problem of\nintensity-modulated radiation therapy (IMRT) treatment planning with\ndose-volume constraints (DVCs) included in the planning algorithm is presented.\nIt involves a new type of sparsity constraint that enables the inclusion of a\npercentage-violation constraint in the model problem and its handling by\ncontinuous (as opposed to integer) methods. We propose an iterative algorithmic\nframework for solving such a problem by applying the feasibility-seeking\nCQ-algorithm of Byrne combined with the automatic relaxation method (ARM) that\nuses cyclic projections. Detailed implementation instructions are furnished.\nFunctionality of the algorithm was demonstrated through the creation of an\nintensity-modulated proton therapy plan for a simple 2D C-shaped geometry and\nalso for a realistic base-of-skull chordoma treatment site. Monte Carlo\nsimulations of proton pencil beams of varying energy were conducted to obtain\ndose distributions for the 2D test case. A research release of the Pinnacle3\nproton treatment planning system was used to extract pencil beam doses for a\nclinical base-of-skull chordoma case. In both cases the beamlet doses were\ncalculated to satisfy dose-volume constraints according to our new algorithm.\nExamination of the dose-volume histograms following inverse planning with our\nalgorithm demonstrated that it performed as intended. The application of our\nproposed algorithm to dose-volume constraint inverse planning was successfully\ndemonstrated. Comparison with optimized dose distributions from the research\nrelease of the Pinnacle3 treatment planning system showed the algorithm could\nachieve equivalent or superior results.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Resolving the notorious case of conical intersections for coupled cluster dynamics.   The motion of electrons and nuclei in photochemical events often involve\nconical intersections, degeneracies between electronic states. They serve as\nfunnels for nuclear relaxation - on the femtosecond scale - in processes where\nthe electrons and nuclei couple nonadiabatically. Accurate ab initio quantum\nchemical models are essential for interpreting experimental measurements of\nsuch phenomena. In this paper we resolve a long-standing problem in coupled\ncluster theory, presenting the first formulation of the theory that correctly\ndescribes conical intersections between excited electronic states of the same\nsymmetry. This new development demonstrates that the highly accurate coupled\ncluster theory can be applied to describe dynamics on excited electronic states\ninvolving conical intersections.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Closed-loop field development optimization with multipoint geostatistics and statistical assessment.   Closed-loop field development (CLFD) optimization is a comprehensive\nframework for optimal development of subsurface resources. CLFD involves three\nmajor steps: 1) optimization of full development plan based on current set of\nmodels, 2) drilling new wells and collecting new spatial and temporal\n(production) data, 3) model calibration based on all data. This process is\nrepeated until the optimal number of wells is drilled. This work introduces an\nefficient CLFD implementation for complex systems described by multipoint\ngeostatistics (MPS). Model calibration is accomplished in two steps:\nconditioning to spatial data by a geostatistical simulation method, and\nconditioning to production data by optimization-based PCA. A statistical\nprocedure is presented to assess the performance of CLFD. Methodology is\napplied to an oil reservoir example for 25 different true-model cases.\nApplication of a single-step of CLFD, improved the true NPV in 64%--80% of\ncases. The full CLFD procedure (with three steps) improved the true NPV in 96%\nof cases, with an average improvement of 37%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gravitational octree code performance evaluation on Volta GPU.   In this study, the gravitational octree code originally optimized for the\nFermi, Kepler, and Maxwell GPU architectures is adapted to the Volta\narchitecture. The Volta architecture introduces independent thread scheduling\nrequiring either the insertion of the explicit synchronizations at appropriate\nlocations or the enforcement of the same implicit synchronizations as do the\nPascal or earlier architectures by specifying \\texttt{-gencode\narch=compute\\_60,code=sm\\_70}. The performance measurements on Tesla V100, the\ncurrent flagship GPU by NVIDIA, revealed that the $N$-body simulations of the\nAndromeda galaxy model with $2^{23} = 8388608$ particles took $3.8 \\times\n10^{-2}$~s or $3.3 \\times 10^{-2}$~s per step for each case. Tesla V100\nachieves a 1.4 to 2.2-fold acceleration in comparison with Tesla P100, the\nflagship GPU in the previous generation. The observed speed-up of 2.2 is\ngreater than 1.5, which is the ratio of the theoretical peak performance of the\ntwo GPUs. The independence of the units for integer operations from those for\nfloating-point number operations enables the overlapped execution of integer\nand floating-point number operations. It hides the execution time of the\ninteger operations leading to the speed-up rate above the theoretical peak\nperformance ratio. Tesla V100 can execute $N$-body simulation with up to $25\n\\times 2^{20} = 26214400$ particles, and it took $2.0 \\times 10^{-1}$~s per\nstep. It corresponds to $3.5$~TFlop/s, which is 22\\% of the single-precision\ntheoretical peak performance.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Action Robust Reinforcement Learning and Applications in Continuous Control.   A policy is said to be robust if it maximizes the reward while considering a\nbad, or even adversarial, model. In this work we formalize two new criteria of\nrobustness to action uncertainty. Specifically, we consider two scenarios in\nwhich the agent attempts to perform an action $\\mathbf{a}$, and (i) with\nprobability $\\alpha$, an alternative adversarial action $\\bar{\\mathbf{a}}$ is\ntaken, or (ii) an adversary adds a perturbation to the selected action in the\ncase of continuous action space. We show that our criteria are related to\ncommon forms of uncertainty in robotics domains, such as the occurrence of\nabrupt forces, and suggest algorithms in the tabular case. Building on the\nsuggested algorithms, we generalize our approach to deep reinforcement learning\n(DRL) and provide extensive experiments in the various MuJoCo domains. Our\nexperiments show that not only does our approach produce robust policies, but\nit also improves the performance in the absence of perturbations. This\ngeneralization indicates that action-robustness can be thought of as implicit\nregularization in RL problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Does Your Phone Know Your Touch?.   This paper explores supervised techniques for continuous anomaly detection\nfrom biometric touch screen data. A capacitive sensor array used to mimic a\ntouch screen as used to collect touch and swipe gestures from participants. The\ngestures are recorded over fixed segments of time, with position and force\nmeasured for each gesture. Support Vector Machine, Logistic Regression, and\nGaussian mixture models were tested to learn individual touch patterns. Test\nresults showed true negative and true positive scores of over 95% accuracy for\nall gesture types, with logistic regression models far outperforming the other\nmethods. A more expansive and varied data collection over longer periods of\ntime is needed to determine pragmatic usage of these results.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emergence of Structured Behaviors from Curiosity-Based Intrinsic Motivation.   Infants are experts at playing, with an amazing ability to generate novel\nstructured behaviors in unstructured environments that lack clear extrinsic\nreward signals. We seek to replicate some of these abilities with a neural\nnetwork that implements curiosity-driven intrinsic motivation. Using a simple\nbut ecologically naturalistic simulated environment in which the agent can move\nand interact with objects it sees, the agent learns a world model predicting\nthe dynamic consequences of its actions. Simultaneously, the agent learns to\ntake actions that adversarially challenge the developing world model, pushing\nthe agent to explore novel and informative interactions with its environment.\nWe demonstrate that this policy leads to the self-supervised emergence of a\nspectrum of complex behaviors, including ego motion prediction, object\nattention, and object gathering. Moreover, the world model that the agent\nlearns supports improved performance on object dynamics prediction and\nlocalization tasks. Our results are a proof-of-principle that computational\nmodels of intrinsic motivation might account for key features of developmental\nvisuomotor learning in infants.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "App Store 2.0: From Crowd Information to Actionable Feedback in Mobile Ecosystems.   Given the increasing competition in mobile app ecosystems, improving the\nexperience of users has become a major goal for app vendors. This article\nintroduces a visionary app store, called APP STORE 2.0, which exploits\ncrowdsourced information about apps, devices and users to increase the overall\nquality of the delivered mobile apps. We sketch a blueprint architecture of the\nenvisioned app stores and discuss the different kinds of actionable feedbacks\nthat app stores can generate using crowdsourced information.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Okapi: Causally Consistent Geo-Replication Made Faster, Cheaper and More Available.   Okapi is a new causally consistent geo-replicated key- value store. Okapi\nleverages two key design choices to achieve high performance. First, it relies\non hybrid logical/physical clocks to achieve low latency even in the presence\nof clock skew. Second, Okapi achieves higher resource efficiency and better\navailability, at the expense of a slight increase in update visibility latency.\nTo this end, Okapi implements a new stabilization protocol that uses a\ncombination of vector and scalar clocks and makes a remote update visible when\nits delivery has been acknowledged by every data center. We evaluate Okapi with\ndifferent workloads on Amazon AWS, using three geographically distributed\nregions and 96 nodes. We compare Okapi with two recent approaches to causal\nconsistency, Cure and GentleRain. We show that Okapi delivers up to two orders\nof magnitude better performance than GentleRain and that Okapi achieves up to\n3.5x lower latency and a 60% reduction of the meta-data overhead with respect\nto Cure.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Network of vertically c-oriented prism shaped InN nanowalls grown on c-GaN/sapphire template by chemical vapor deposition technique.   Networks of vertically c-oriented prism shaped InN nanowalls, are grown on\nc-GaN/sapphire templates using a CVD technique, where pure indium and ammonia\nare used as metal and nitrogen precursors. A systematic study of the growth,\nstructural and electronic properties of these samples shows a preferential\ngrowth of the islands along [11-20] and [0001] directions leading to the\nformation of such a network structure, where the vertically [0001] oriented\ntapered walls are laterally align along one of the three [11-20] directions.\nInclined facets of these walls are identified as r-planes [(1-102)-planes] of\nwurtzite InN. Onset of absorption for these samples is observed to be higher\nthan the band gap of InN suggesting a high background carrier concentration in\nthis material. Study of the valence band edge through XPS indicates the\nformation of positive depletion regions below the r-plane side facets of the\nwalls. This is in contrast with the observation for c-plane InN epilayers,\nwhere electron accumulation is often reported below the top surface.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On families of fibred knots with equal Seifert forms.   For every genus $g\\geq 2$, we construct an infinite family of strongly\nquasipositive fibred knots having the same Seifert form as the torus knot\n$T(2,2g+1)$. In particular, their signatures and four-genera are maximal and\ntheir homological monodromies (hence their Alexander module structures) agree.\nOn the other hand, the geometric stretching factors are pairwise distinct and\nthe knots are pairwise not ribbon concordant.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Underapproximation of Reach-Avoid Sets for Discrete-Time Stochastic Systems via Lagrangian Methods.   We examine Lagrangian techniques for computing underapproximations of\nfinite-time horizon, stochastic reach-avoid level-sets for discrete-time,\nnonlinear systems. We use the concept of reachability of a target tube in the\ncontrol literature to define robust reach-avoid sets which are parameterized by\nthe target set, safe set, and the set in which the disturbance is drawn from.\nWe unify two existing Lagrangian approaches to compute these sets and establish\nthat there exists an optimal control policy of the robust reach-avoid sets\nwhich is a Markov policy. Based on these results, we characterize the subset of\nthe disturbance space whose corresponding robust reach-avoid set for the given\ntarget and safe set is a guaranteed underapproximation of the stochastic\nreach-avoid level-set of interest. The proposed approach dramatically improves\nthe computational efficiency for obtaining an underapproximation of stochastic\nreach-avoid level-sets when compared to the traditional approaches based on\ngridding. Our method, while conservative, does not rely on a grid, implying\nscalability as permitted by the known computational geometry constraints. We\ndemonstrate the method on two examples: a simple two-dimensional integrator,\nand a space vehicle rendezvous-docking problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Mixed penalization in convolutive nonnegative matrix factorization for blind speech dereverberation.   When a signal is recorded in an enclosed room, it typically gets affected by\nreverberation. This degradation represents a problem when dealing with audio\nsignals, particularly in the field of speech signal processing, such as\nautomatic speech recognition. Although there are some approaches to deal with\nthis issue that are quite satisfactory under certain conditions, constructing a\nmethod that works well in a general context still poses a significant\nchallenge. In this article, we propose a method based on convolutive\nnonnegative matrix factorization that mixes two penalizers in order to impose\ncertain characteristics over the time-frequency components of the restored\nsignal and the reverberant components. An algorithm for implementing the method\nis described and tested. Comparisons of the results against those obtained with\nstate of the art methods are presented, showing significant improvement.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Recursive Whitening Transformation for Speaker Recognition on Language Mismatched Condition.   Recently in speaker recognition, performance degradation due to the channel\ndomain mismatched condition has been actively addressed. However, the\nmismatches arising from language is yet to be sufficiently addressed. This\npaper proposes an approach which employs recursive whitening transformation to\nmitigate the language mismatched condition. The proposed method is based on the\nmultiple whitening transformation, which is intended to remove un-whitened\nresidual components in the dataset associated with i-vector length\nnormalization. The experiments were conducted on the Speaker Recognition\nEvaluation 2016 trials of which the task is non-English speaker recognition\nusing development dataset consist of both a large scale out-of-domain (English)\ndataset and an extremely low-quantity in-domain (non-English) dataset. For\nperformance comparison, we develop a state-of- the-art system using deep neural\nnetwork and bottleneck feature, which is based on a phonetically aware model.\nFrom the experimental results, along with other prior studies, effectiveness of\nthe proposed method on language mismatched condition is validated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Variational approach for learning Markov processes from time series data.   Inference, prediction and control of complex dynamical systems from time\nseries is important in many areas, including financial markets, power grid\nmanagement, climate and weather modeling, or molecular dynamics. The analysis\nof such highly nonlinear dynamical systems is facilitated by the fact that we\ncan often find a (generally nonlinear) transformation of the system coordinates\nto features in which the dynamics can be excellently approximated by a linear\nMarkovian model. Moreover, the large number of system variables often change\ncollectively on large time- and length-scales, facilitating a low-dimensional\nanalysis in feature space. In this paper, we introduce a variational approach\nfor Markov processes (VAMP) that allows us to find optimal feature mappings and\noptimal Markovian models of the dynamics from given time series data. The key\ninsight is that the best linear model can be obtained from the top singular\ncomponents of the Koopman operator. This leads to the definition of a family of\nscore functions called VAMP-r which can be calculated from data, and can be\nemployed to optimize a Markovian model. In addition, based on the relationship\nbetween the variational scores and approximation errors of Koopman operators,\nwe propose a new VAMP-E score, which can be applied to cross-validation for\nhyper-parameter optimization and model selection in VAMP. VAMP is valid for\nboth reversible and nonreversible processes and for stationary and\nnon-stationary processes or realizations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "JADE: Joint Autoencoders for Dis-Entanglement.   The problem of feature disentanglement has been explored in the literature,\nfor the purpose of image and video processing and text analysis.\nState-of-the-art methods for disentangling feature representations rely on the\npresence of many labeled samples. In this work, we present a novel method for\ndisentangling factors of variation in data-scarce regimes. Specifically, we\nexplore the application of feature disentangling for the problem of supervised\nclassification in a setting where few labeled samples exist, and there are no\nunlabeled samples for use in unsupervised training. Instead, a similar datasets\nexists which shares at least one direction of variation with the\nsample-constrained datasets. We train our model end-to-end using the framework\nof variational autoencoders and are able to experimentally demonstrate that\nusing an auxiliary dataset with similar variation factors contribute positively\nto classification performance, yielding competitive results with the\nstate-of-the-art in unsupervised learning.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Excitable behaviors.   This chapter revisits the concept of excitability, a basic system property of\nneurons. The focus is on excitable systems regarded as behaviors rather than\ndynamical systems. By this we mean open systems modulated by specific\ninterconnection properties rather than closed systems classified by their\nparameter ranges. Modeling, analysis, and synthesis questions can be formulated\nin the classical language of circuit theory. The input-output characterization\nof excitability is in terms of the local sensitivity of the current-voltage\nrelationship. It suggests the formulation of novel questions for non-linear\nsystem theory, inspired by questions from experimental neurophysiology.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "LandmarkBoost: Efficient Visual Context Classifiers for Robust Localization.   The growing popularity of autonomous systems creates a need for reliable and\nefficient metric pose retrieval algorithms. Currently used approaches tend to\nrely on nearest neighbor search of binary descriptors to perform the 2D-3D\nmatching and guarantee realtime capabilities on mobile platforms. These methods\nstruggle, however, with the growing size of the map, changes in viewpoint or\nappearance, and visual aliasing present in the environment. The rigidly defined\ndescriptor patterns only capture a limited neighborhood of the keypoint and\ncompletely ignore the overall visual context.\nWe propose LandmarkBoost - an approach that, in contrast to the conventional\n2D-3D matching methods, casts the search problem as a landmark classification\ntask. We use a boosted classifier to classify landmark observations and\ndirectly obtain correspondences as classifier scores. We also introduce a\nformulation of visual context that is flexible, efficient to compute, and can\ncapture relationships in the entire image plane. The original binary\ndescriptors are augmented with contextual information and informative features\nare selected by the boosting framework. Through detailed experiments, we\nevaluate the retrieval quality and performance of LandmarkBoost, demonstrating\nthat it outperforms common state-of-the-art descriptor matching methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improving Network Robustness against Adversarial Attacks with Compact Convolution.   Though Convolutional Neural Networks (CNNs) have surpassed human-level\nperformance on tasks such as object classification and face verification, they\ncan easily be fooled by adversarial attacks. These attacks add a small\nperturbation to the input image that causes the network to misclassify the\nsample. In this paper, we focus on neutralizing adversarial attacks by compact\nfeature learning. In particular, we show that learning features in a closed and\nbounded space improves the robustness of the network. We explore the effect of\nL2-Softmax Loss, that enforces compactness in the learned features, thus\nresulting in enhanced robustness to adversarial perturbations. Additionally, we\npropose compact convolution, a novel method of convolution that when\nincorporated in conventional CNNs improves their robustness. Compact\nconvolution ensures feature compactness at every layer such that they are\nbounded and close to each other. Extensive experiments show that Compact\nConvolutional Networks (CCNs) neutralize multiple types of attacks, and perform\nbetter than existing methods in defending adversarial attacks, without\nincurring any additional training overhead compared to CNNs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Effect algebras as presheaves on finite Boolean algebras.   For an effect algebra $A$, we examine the category of all morphisms from\nfinite Boolean algebras into $A$. This category can be described as a category\nof elements of a presheaf $R(A)$ on the category of finite Boolean algebras. We\nprove that some properties (being an orthoalgebra, the Riesz decomposition\nproperty, being a Boolean algebra) of an effect algebra $A$ can be\ncharacterized by properties of the category of elements of the presheaf $R(A)$.\nWe prove that the tensor product of of effect algebras arises as a left Kan\nextension of the free product of finite Boolean algebras along the inclusion\nfunctor. As a consequence, the tensor product of effect algebras can be\nexpressed by means of the Day convolution of presheaves on finite Boolean\nalgebras.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A note on Weyl groups and crystallographic root lattices.   We follow the dual approach to Coxeter systems and show for Weyl groups a\ncriterium which decides whether a set of reflections is generating the group\ndepending on the root and the coroot lattice. Further we study special\ngenerating sets involving a parabolic subgroup and show that they are very\ntame.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Multitarget search on complex networks: A logarithmic growth of global mean random cover time.   We investigate multitarget search on complex networks and derive an exact\nexpression for the mean random cover time that quantifies the expected time a\nwalker needs to visit multiple targets. Based on this, we recover and extend\nsome interesting results of multitarget search on networks. Specifically, we\nobserve the logarithmic increase of the global mean random cover time with the\ntarget number for a broad range of random search processes, including generic\nrandom walks, biased random walks, and maximal entropy random walks. We show\nthat the logarithmic growth pattern is a universal feature of multi-target\nsearch on networks by using the annealed network approach and the\nSherman-Morrison formula. Moreover, we find that for biased random walks, the\nglobal mean random cover time can be minimized, and that the corresponding\noptimal parameter also minimizes the global mean first passage time, pointing\ntowards its robustness. Our findings further confirm that the logarithmic\ngrowth pattern is a universal law governing multitarget search in confined\nmedia.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Convolutional Neural Networks for Page Segmentation of Historical Document Images.   This paper presents a Convolutional Neural Network (CNN) based page\nsegmentation method for handwritten historical document images. We consider\npage segmentation as a pixel labeling problem, i.e., each pixel is classified\nas one of the predefined classes. Traditional methods in this area rely on\ncarefully hand-crafted features or large amounts of prior knowledge. In\ncontrast, we propose to learn features from raw image pixels using a CNN. While\nmany researchers focus on developing deep CNN architectures to solve different\nproblems, we train a simple CNN with only one convolution layer. We show that\nthe simple architecture achieves competitive results against other deep\narchitectures on different public datasets. Experiments also demonstrate the\neffectiveness and superiority of the proposed method compared to previous\nmethods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evidential Deep Learning to Quantify Classification Uncertainty.   Deterministic neural nets have been shown to learn effective predictors on a\nwide range of machine learning problems. However, as the standard approach is\nto train the network to minimize a prediction loss, the resultant model remains\nignorant to its prediction confidence. Orthogonally to Bayesian neural nets\nthat indirectly infer prediction uncertainty through weight uncertainties, we\npropose explicit modeling of the same using the theory of subjective logic. By\nplacing a Dirichlet distribution on the class probabilities, we treat\npredictions of a neural net as subjective opinions and learn the function that\ncollects the evidence leading to these opinions by a deterministic neural net\nfrom data. The resultant predictor for a multi-class classification problem is\nanother Dirichlet distribution whose parameters are set by the continuous\noutput of a neural net. We provide a preliminary analysis on how the\npeculiarities of our new loss function drive improved uncertainty estimation.\nWe observe that our method achieves unprecedented success on detection of\nout-of-distribution queries and endurance against adversarial perturbations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An enthalpy-based multiple-relaxation-time lattice Boltzmann method for solid-liquid phase change heat transfer in metal foams.   In this paper, an enthalpy-based multiple-relaxation-time (MRT) lattice\nBoltzmann (LB) method is developed for solid-liquid phase change heat transfer\nin metal foams under local thermal non-equilibrium (LTNE) condition. The\nenthalpy-based MRT-LB method consists of three different MRT-LB models: one for\nflow field based on the generalized non-Darcy model, and the other two for\nphase change material (PCM) and metal foam temperature fields described by the\nLTNE model. The moving solid-liquid phase interface is implicitly tracked\nthrough the liquid fraction, which is simultaneously obtained when the energy\nequations of PCM and metal foam are solved. The present method has several\ndistinctive features. First, as compared with previous studies, the present\nmethod avoids the iteration procedure, thus it retains the inherent merits of\nthe standard LB method and is superior over the iteration method in terms of\naccuracy and computational efficiency. Second, a volumetric LB scheme instead\nof the bounce-back scheme is employed to realize the no-slip velocity condition\nin the interface and solid phase regions, which is consistent with the actual\nsituation. Last but not least, the MRT collision model is employed, and with\nadditional degrees of freedom, it has the ability to reduce the numerical\ndiffusion across phase interface induced by solid-liquid phase change.\nNumerical tests demonstrate that the present method can be served as an\naccurate and efficient numerical tool for studying metal foam enhanced\nsolid-liquid phase change heat transfer in latent heat storage. Finally,\ncomparisons and discussions are made to offer useful information for practical\napplications of the present method.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Cohomology of the flag variety under PBW degenerations.   PBW degenerations are a particularly nice family of flat degenerations of\ntype A flag varieties. We show that the cohomology of any PBW degeneration of\nthe flag variety surjects onto the cohomology of the original flag variety, and\nthat this holds in an equivariant setting too. We also prove that the same is\ntrue in the symplectic setting when considering Feigin's linear degeneration of\nthe symplectic flag variety.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Bag-of-Paths Node Criticality Measure.   This work compares several node (and network) criticality measures\nquantifying to which extend each node is critical with respect to the\ncommunication flow between nodes of the network, and introduces a new measure\nbased on the Bag-of-Paths (BoP) framework. Network disconnection simulation\nexperiments show that the new BoP measure outperforms all the other measures on\na sample of Erdos-Renyi and Albert-Barabasi graphs. Furthermore, a faster\n(still O(n^3)), approximate, BoP criticality relying on the Sherman-Morrison\nrank-one update of a matrix is introduced for tackling larger networks. This\napproximate measure shows similar performances as the original, exact, one.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "DeepSketch2Face: A Deep Learning Based Sketching System for 3D Face and Caricature Modeling.   Face modeling has been paid much attention in the field of visual computing.\nThere exist many scenarios, including cartoon characters, avatars for social\nmedia, 3D face caricatures as well as face-related art and design, where\nlow-cost interactive face modeling is a popular approach especially among\namateur users. In this paper, we propose a deep learning based sketching system\nfor 3D face and caricature modeling. This system has a labor-efficient\nsketching interface, that allows the user to draw freehand imprecise yet\nexpressive 2D lines representing the contours of facial features. A novel CNN\nbased deep regression network is designed for inferring 3D face models from 2D\nsketches. Our network fuses both CNN and shape based features of the input\nsketch, and has two independent branches of fully connected layers generating\nindependent subsets of coefficients for a bilinear face representation. Our\nsystem also supports gesture based interactions for users to further manipulate\ninitial face models. Both user studies and numerical results indicate that our\nsketching system can help users create face models quickly and effectively. A\nsignificantly expanded face database with diverse identities, expressions and\nlevels of exaggeration is constructed to promote further research and\nevaluation of face modeling techniques.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Colouring perfect graphs with bounded clique number.   A graph is perfect if the chromatic number of every induced subgraph equals\nthe size of its largest clique, and an algorithm of Grötschel, Lovász, and\nSchrijver from 1988 finds an optimal colouring of a perfect graph in polynomial\ntime. But this algorithm uses the ellipsoid method, and it is a well-known open\nquestion to construct a \"combinatorial\" polynomial-time algorithm that yields\nan optimal colouring of a perfect graph.\nA skew partition in $G$ is a partition $(A,B)$ of $V(G)$ such that $G[A]$ is\nnot connected and $\\bar{G}[B]$ is not connected, where $\\bar{G}$ denotes the\ncomplement graph ; and it is balanced if an additional parity condition of\npaths in $G$ and $\\bar{G}$ is satisfied.\nIn this paper we first give a polynomial-time algorithm that, with input a\nperfect graph, outputs a balanced skew partition if there is one. Then we use\nthis to obtain a combinatorial algorithm that finds an optimal colouring of a\nperfect graph with clique number $k$, in time that is polynomial for fixed $k$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Measuring bot and human behavioral dynamics.   Bots, social media accounts controlled by software rather than by humans,\nhave recently been under the spotlight for their association with various forms\nof online manipulation. To date, much work has focused on social bot detection,\nbut little attention has been devoted to the characterization and measurement\nof the behavior and activity of bots, as opposed to humans'. Over the course of\nthe years, bots have become more sophisticated, and capable to reflect some\nshort-term behavior, emulating that of human users. The goal of this paper is\nto study the behavioral dynamics that bots exhibit over the course of one\nactivity session, and highlight if and how these differ from human activity\nsignatures. By using a large Twitter dataset associated with recent political\nevents, we first separate bots and humans, then isolate their activity\nsessions. We compile a list of quantities to be measured, like the propensity\nof users to engage in social interactions or to produce content. Our analysis\nhighlights the presence of short-term behavioral trends in humans, which can be\nassociated with a cognitive origin, that are absent in bots, intuitively due to\ntheir automated activity. These findings are finally codified to create and\nevaluate a machine learning algorithm to detect activity sessions produced by\nbots and humans, to allow for more nuanced bot detection strategies.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A spin-gapped Mott insulator with the dimeric arrangement of twisted molecules Zn(tmdt)$_{2}$.   $^{13}$C nuclear magnetic resonance measurements were performed for a\nsingle-component molecular material Zn(tmdt)$_{2}$, in which tmdt's form an\narrangement similar to the so-called ${\\kappa}$-type molecular packing in\nquasi-two-dimensional Mott insulators and superconductors. Detailed analysis of\nthe powder spectra uncovered local spin susceptibility in the tmdt ${\\pi}$\norbitals. The obtained shift and relaxation rate revealed the singlet-triplet\nexcitations of the ${\\pi}$ spins, indicating that Zn(tmdt)$_{2}$ is a\nspin-gapped Mott insulator with exceptionally large electron correlations\ncompared to conventional molecular Mott systems.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A temperate exo-Earth around a quiet M dwarf at 3.4 parsecs.   The combination of high-contrast imaging and high-dispersion spectroscopy,\nwhich has successfully been used to detect the atmosphere of a giant planet, is\none of the most promising potential probes of the atmosphere of Earth-size\nworlds. The forthcoming generation of extremely large telescopes (ELTs) may\nobtain sufficient contrast with this technique to detect O$_2$ in the\natmosphere of those worlds that orbit low-mass M dwarfs. This is strong\nmotivation to carry out a census of planets around cool stars for which\nhabitable zones can be resolved by ELTs, i.e. for M dwarfs within $\\sim$5\nparsecs. Our HARPS survey has been a major contributor to that sample of nearby\nplanets. Here we report on our radial velocity observations of Ross 128\n(Proxima Virginis, GJ447, HIP 57548), an M4 dwarf just 3.4 parsec away from our\nSun. This source hosts an exo-Earth with a projected mass $m \\sin i = 1.35\nM_\\oplus$ and an orbital period of 9.9 days. Ross 128 b receives $\\sim$1.38\ntimes as much flux as Earth from the Sun and its equilibrium ranges in\ntemperature between 269 K for an Earth-like albedo and 213 K for a Venus-like\nalbedo. Recent studies place it close to the inner edge of the conventional\nhabitable zone. An 80-day long light curve from K2 campaign C01 demonstrates\nthat Ross~128~b does not transit. Together with the All Sky Automated Survey\n(ASAS) photometry and spectroscopic activity indices, the K2 photometry shows\nthat Ross 128 rotates slowly and has weak magnetic activity. In a habitability\ncontext, this makes survival of its atmosphere against erosion more likely.\nRoss 128 b is the second closest known exo-Earth, after Proxima Centauri b (1.3\nparsec), and the closest temperate planet known around a quiet star. The 15 mas\nplanet-star angular separation at maximum elongation will be resolved by ELTs\n($>$ 3$\\lambda/D$) in the optical bands of O$_2$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "GlobeNet: Convolutional Neural Networks for Typhoon Eye Tracking from Remote Sensing Imagery.   Advances in remote sensing technologies have made it possible to use\nhigh-resolution visual data for weather observation and forecasting tasks. We\npropose the use of multi-layer neural networks for understanding complex\natmospheric dynamics based on multichannel satellite images. The capability of\nour model was evaluated by using a linear regression task for single typhoon\ncoordinates prediction. A specific combination of models and different\nactivation policies enabled us to obtain an interesting prediction result in\nthe northeastern hemisphere (ENH).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Enhancing Stratified Graph Sampling Algorithms based on Approximate Degree Distribution.   Sampling technique has become one of the recent research focuses in the\ngraph-related fields. Most of the existing graph sampling algorithms tend to\nsample the high degree or low degree nodes in the complex networks because of\nthe characteristic of scale-free. Scale-free means that degrees of different\nnodes are subject to a power law distribution. So, there is a significant\ndifference in the degrees between the overall sampling nodes. In this paper, we\npropose an idea of approximate degree distribution and devise a stratified\nstrategy using it in the complex networks. We also develop two graph sampling\nalgorithms combining the node selection method with the stratified strategy.\nThe experimental results show that our sampling algorithms preserve several\nproperties of different graphs and behave more accurately than other\nalgorithms. Further, we prove the proposed algorithms are superior to the\noff-the-shelf algorithms in terms of the unbiasedness of the degrees and more\nefficient than state-of-the-art FFS and ES-i algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Description of the evolution of inhomogeneities on a Dark Matter halo with the Vlasov equation.   We use a direct numerical integration of the Vlasov equation in spherical\nsymmetry with a background gravitational potential to determine the evolution\nof a collection of particles in different models of a galactic halo. Such a\ncollection is assumed to represent a dark matter inhomogeneity which reaches a\nstationary state determined by the virialization of the system. We describe\nsome features of the stationary states and, by using several halo models,\nobtain distinctive signatures for the evolution of the inhomogeneities in each\nof the models.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Adaptive Estimation for Nonlinear Systems using Reproducing Kernel Hilbert Spaces.   This paper extends a conventional, general framework for online adaptive\nestimation problems for systems governed by unknown nonlinear ordinary\ndifferential equations. The central feature of the theory introduced in this\npaper represents the unknown function as a member of a reproducing kernel\nHilbert space (RKHS) and defines a distributed parameter system (DPS) that\ngoverns state estimates and estimates of the unknown function. This paper 1)\nderives sufficient conditions for the existence and stability of the infinite\ndimensional online estimation problem, 2) derives existence and stability of\nfinite dimensional approximations of the infinite dimensional approximations,\nand 3) determines sufficient conditions for the convergence of finite\ndimensional approximations to the infinite dimensional online estimates. A new\ncondition for persistency of excitation in a RKHS in terms of its evaluation\nfunctionals is introduced in the paper that enables proof of convergence of the\nfinite dimensional approximations of the unknown function in the RKHS. This\npaper studies two particular choices of the RKHS, those that are generated by\nexponential functions and those that are generated by multiscale kernels\ndefined from a multiresolution analysis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "COREclust: a new package for a robust and scalable analysis of complex data.   In this paper, we present a new R package COREclust dedicated to the\ndetection of representative variables in high dimensional spaces with a\npotentially limited number of observations. Variable sets detection is based on\nan original graph clustering strategy denoted CORE-clustering algorithm that\ndetects CORE-clusters, i.e. variable sets having a user defined size range and\nin which each variable is very similar to at least another variable.\nRepresentative variables are then robustely estimate as the CORE-cluster\ncenters. This strategy is entirely coded in C++ and wrapped by R using the Rcpp\npackage. A particular effort has been dedicated to keep its algorithmic cost\nreasonable so that it can be used on large datasets. After motivating our work,\nwe will explain the CORE-clustering algorithm as well as a greedy extension of\nthis algorithm. We will then present how to use it and results obtained on\nsynthetic and real data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Complete Cyclic Proof Systems for Inductive Entailments.   In this paper we develop cyclic proof systems for the problem of inclusion\nbetween the least sets of models of mutually recursive predicates, when the\nground constraints in the inductive definitions belong to the quantifier-free\nfragments of (i) First Order Logic with the canonical Herbrand interpretation\nand (ii) Separation Logic, respectively. Inspired by classical\nautomata-theoretic techniques of proving language inclusion between tree\nautomata, we give a small set of inference rules, that are proved to be sound\nand complete, under certain semantic restrictions, involving the set of\nconstraints in the inductive system. Moreover, we investigate the decidability\nand computational complexity of these restrictions for all the logical\nfragments considered and provide a proof search semi-algorithm that becomes a\ndecision procedure for the entailment problem, for those systems that fulfill\nthe restrictions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nearly Instance Optimal Sample Complexity Bounds for Top-k Arm Selection.   In the Best-$k$-Arm problem, we are given $n$ stochastic bandit arms, each\nassociated with an unknown reward distribution. We are required to identify the\n$k$ arms with the largest means by taking as few samples as possible. In this\npaper, we make progress towards a complete characterization of the\ninstance-wise sample complexity bounds for the Best-$k$-Arm problem. On the\nlower bound side, we obtain a novel complexity term to measure the sample\ncomplexity that every Best-$k$-Arm instance requires. This is derived by an\ninteresting and nontrivial reduction from the Best-$1$-Arm problem. We also\nprovide an elimination-based algorithm that matches the instance-wise lower\nbound within doubly-logarithmic factors. The sample complexity of our algorithm\nstrictly dominates the state-of-the-art for Best-$k$-Arm (module constant\nfactors).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Towards a Deep Reinforcement Learning Approach for Tower Line Wars.   There have been numerous breakthroughs with reinforcement learning in the\nrecent years, perhaps most notably on Deep Reinforcement Learning successfully\nplaying and winning relatively advanced computer games. There is undoubtedly an\nanticipation that Deep Reinforcement Learning will play a major role when the\nfirst AI masters the complicated game plays needed to beat a professional\nReal-Time Strategy game player. For this to be possible, there needs to be a\ngame environment that targets and fosters AI research, and specifically Deep\nReinforcement Learning. Some game environments already exist, however, these\nare either overly simplistic such as Atari 2600 or complex such as Starcraft II\nfrom Blizzard Entertainment. We propose a game environment in between Atari\n2600 and Starcraft II, particularly targeting Deep Reinforcement Learning\nalgorithm research. The environment is a variant of Tower Line Wars from\nWarcraft III, Blizzard Entertainment. Further, as a proof of concept that the\nenvironment can harbor Deep Reinforcement algorithms, we propose and apply a\nDeep Q-Reinforcement architecture. The architecture simplifies the state space\nso that it is applicable to Q-learning, and in turn improves performance\ncompared to current state-of-the-art methods. Our experiments show that the\nproposed architecture can learn to play the environment well, and score 33%\nbetter than standard Deep Q-learning which in turn proves the usefulness of the\ngame environment.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The unreasonable effectiveness of the forget gate.   Given the success of the gated recurrent unit, a natural question is whether\nall the gates of the long short-term memory (LSTM) network are necessary.\nPrevious research has shown that the forget gate is one of the most important\ngates in the LSTM. Here we show that a forget-gate-only version of the LSTM\nwith chrono-initialized biases, not only provides computational savings but\noutperforms the standard LSTM on multiple benchmark datasets and competes with\nsome of the best contemporary models. Our proposed network, the JANET, achieves\naccuracies of 99% and 92.5% on the MNIST and pMNIST datasets, outperforming the\nstandard LSTM which yields accuracies of 98.5% and 91%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "One-step and Two-step Classification for Abusive Language Detection on Twitter.   Automatic abusive language detection is a difficult but important task for\nonline social media. Our research explores a two-step approach of performing\nclassification on abusive language and then classifying into specific types and\ncompares it with one-step approach of doing one multi-class classification for\ndetecting sexist and racist languages. With a public English Twitter corpus of\n20 thousand tweets in the type of sexism and racism, our approach shows a\npromising performance of 0.827 F-measure by using HybridCNN in one-step and\n0.824 F-measure by using logistic regression in two-steps.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "VEGAS: A VST Early-type GAlaxy Survey. II. Photometric study of giant ellipticals and their stellar halos.   Observations of diffuse starlight in the outskirts of galaxies are thought to\nbe a fundamental source of constraints on the cosmological context of galaxy\nassembly in the $\\Lambda$CDM model. Such observations are not trivial because\nof the extreme faintness of such regions. In this work, we investigate the\nphotometric properties of six massive early type galaxies (ETGs) in the VEGAS\nsample (NGC 1399, NGC 3923, NGC 4365, NGC 4472, NGC 5044, and NGC 5846) out to\nextremely low surface brightness levels, with the goal of characterizing the\nglobal structure of their light profiles for comparison to state-of-the-art\ngalaxy formation models. We carry out deep and detailed photometric mapping of\nour ETG sample taking advantage of deep imaging with VST/OmegaCAM in the g and\ni bands. By fitting the light profiles, and comparing the results to\nsimulations of elliptical galaxy assembly, we identify signatures of a\ntransition between \"relaxed\" and \"unrelaxed\" accreted components and can\nconstrain the balance between in situ and accreted stars. The very good\nagreement of our results with predictions from theoretical simulations\ndemonstrates that the full VEGAS sample of $\\sim 100$ ETGs will allow us to use\nthe distribution of diffuse light as a robust statistical probe of the\nhierarchical assembly of massive galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Emission line galaxies behind the planetary nebula IC 5148: Potential for a serendipity survey with archival data.   During the start of a survey program using FORS2 long slit spectroscopy on\nplanetary nebulae (PN) and their haloes, we serendipitously discovered six\nbackground emission line galaxies (ELG) with redshifts of z = 0.2057, 0.3137,\n0.37281, 0.4939, 0.7424 and 0.8668. Thus they clearly do not belong to a common\ncluster structure. We derived the major physical properties of the targets.\nSince the used long slit covers a sky area of only 570 arcsec^2, we discuss\nfurther potential of serendipitous discoveries in archival data, beside the\ndeep systematic work of the ongoing and upcoming big surveys. We conclude that\narchival data provide a decent potential for extending the overall data on ELGs\nwithout any selection bias.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Community Aware Random Walk for Network Embedding.   Social network analysis provides meaningful information about behavior of\nnetwork members that can be used for diverse applications such as\nclassification, link prediction. However, network analysis is computationally\nexpensive because of feature learning for different applications. In recent\nyears, many researches have focused on feature learning methods in social\nnetworks. Network embedding represents the network in a lower dimensional\nrepresentation space with the same properties which presents a compressed\nrepresentation of the network. In this paper, we introduce a novel algorithm\nnamed \"CARE\" for network embedding that can be used for different types of\nnetworks including weighted, directed and complex. Current methods try to\npreserve local neighborhood information of nodes, whereas the proposed method\nutilizes local neighborhood and community information of network nodes to cover\nboth local and global structure of social networks. CARE builds customized\npaths, which are consisted of local and global structure of network nodes, as a\nbasis for network embedding and uses the Skip-gram model to learn\nrepresentation vector of nodes. Subsequently, stochastic gradient descent is\napplied to optimize our objective function and learn the final representation\nof nodes. Our method can be scalable when new nodes are appended to network\nwithout information loss. Parallelize generation of customized random walks is\nalso used for speeding up CARE. We evaluate the performance of CARE on multi\nlabel classification and link prediction tasks. Experimental results on various\nnetworks indicate that the proposed method outperforms others in both Micro and\nMacro-f1 measures for different size of training data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "New zirconium hydrides predicted by structure search method based on first principles calculations.   The formation of precipitated zirconium (Zr) hydrides is closely related to\nthe hydrogen embrittlement problem for the cladding materials of pressured\nwater reactors (PWR). In this work, we systematically investigated the crystal\nstructures of zirconium hydride (ZrHx) with different hydrogen concentrations\n(x = 0~2, atomic ratio) by combining the basin hopping algorithm with first\nprinciples calculations. We conclude that the P3m1 {\\zeta}-ZrH0.5 is\ndynamically unstable, while a novel dynamically stable P3m1 ZrH0.5 structure\nwas discovered in the structure search. The stability of bistable P42/nnm\nZrH1.5 structures and I4/mmm ZrH2 structures are also revisited. We find that\nthe P42/nnm (c/a > 1) ZrH1.5 is dynamically unstable, while the I4/mmm (c/a =\n1.57) ZrH2 is dynamically stable.The P42/nnm (c/a < 1) ZrH1.5 might be a key\nintermediate phase for the transition of {\\gamma}->{\\delta}->{\\epsilon} phases.\nAdditionally, by using the thermal dynamic simulations, we find that\n{\\delta}-ZrH1.5 is the most stable structure at high temperature while ZrH2 is\nthe most stable hydride at low temperature. Slow cooling process will promote\nthe formation of {\\delta}-ZrH1.5, and fast cooling process will promote the\nformation of {\\gamma}-ZrH. These results may help to understand the phase\ntransitions of zirconium hydrides.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards Classification of Web ontologies using the Horizontal and Vertical Segmentation.   The new era of the Web is known as the semantic Web or the Web of data. The\nsemantic Web depends on ontologies that are seen as one of its pillars. The\nbigger these ontologies, the greater their exploitation. However, when these\nontologies become too big other problems may appear, such as the complexity to\ncharge big files in memory, the time it needs to download such files and\nespecially the time it needs to make reasoning on them. We discuss in this\npaper approaches for segmenting such big Web ontologies as well as its\nusefulness. The segmentation method extracts from an existing ontology a\nsegment that represents a layer or a generation in the existing ontology; i.e.\na horizontally extraction. The extracted segment should be itself an ontology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Automated Text Categorization Framework based on Hyperparameter Optimization.   A great variety of text tasks such as topic or spam identification, user\nprofiling, and sentiment analysis can be posed as a supervised learning problem\nand tackle using a text classifier. A text classifier consists of several\nsubprocesses, some of them are general enough to be applied to any supervised\nlearning problem, whereas others are specifically designed to tackle a\nparticular task, using complex and computational expensive processes such as\nlemmatization, syntactic analysis, etc. Contrary to traditional approaches, we\npropose a minimalistic and wide system able to tackle text classification tasks\nindependent of domain and language, namely microTC. It is composed by some easy\nto implement text transformations, text representations, and a supervised\nlearning algorithm. These pieces produce a competitive classifier even in the\ndomain of informally written text. We provide a detailed description of microTC\nalong with an extensive experimental comparison with relevant state-of-the-art\nmethods. mircoTC was compared on 30 different datasets. Regarding accuracy,\nmicroTC obtained the best performance in 20 datasets while achieves competitive\nresults in the remaining 10. The compared datasets include several problems\nlike topic and polarity classification, spam detection, user profiling and\nauthorship attribution. Furthermore, it is important to state that our approach\nallows the usage of the technology even without knowledge of machine learning\nand natural language processing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Do altmetrics correlate with the quality of papers? A large-scale empirical study based on F1000Prime data.   In this study, we address the question whether (and to what extent,\nrespectively) altmetrics are related to the scientific quality of papers (as\nmeasured by peer assessments). Only a few studies have previously investigated\nthe relationship between altmetrics and assessments by peers. In the first\nstep, we analyse the underlying dimensions of measurement for traditional\nmetrics (citation counts) and altmetrics - by using principal component\nanalysis (PCA) and factor analysis (FA). In the second step, we test the\nrelationship between the dimensions and quality of papers (as measured by the\npost-publication peer-review system of F1000Prime assessments) - using\nregression analysis. The results of the PCA and FA show that altmetrics operate\nalong different dimensions, whereas Mendeley counts are related to citation\ncounts, and tweets form a separate dimension. The results of the regression\nanalysis indicate that citation-based metrics and readership counts are\nsignificantly more related to quality, than tweets. This result on the one hand\nquestions the use of Twitter counts for research evaluation purposes and on the\nother hand indicates potential use of Mendeley reader counts.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "When Streams of Optofluidics Meet the Sea of Life.   Luke P. Lee is a Tan Chin Tuan Centennial Professor at the National\nUniversity of Singapore. In this contribution he describes the power of\noptofluidics as a research tool and reviews new insights within the areas of\nsingle cell analysis, microphysiological analysis, and integrated systems.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "An Approximate Bayesian Long Short-Term Memory Algorithm for Outlier Detection.   Long Short-Term Memory networks trained with gradient descent and\nback-propagation have received great success in various applications. However,\npoint estimation of the weights of the networks is prone to over-fitting\nproblems and lacks important uncertainty information associated with the\nestimation. However, exact Bayesian neural network methods are intractable and\nnon-applicable for real-world applications. In this study, we propose an\napproximate estimation of the weights uncertainty using Ensemble Kalman Filter,\nwhich is easily scalable to a large number of weights. Furthermore, we optimize\nthe covariance of the noise distribution in the ensemble update step using\nmaximum likelihood estimation. To assess the proposed algorithm, we apply it to\noutlier detection in five real-world events retrieved from the Twitter\nplatform.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Compile-Time Symbolic Differentiation Using C++ Expression Templates.   Template metaprogramming is a popular technique for implementing compile time\nmechanisms for numerical computing. We demonstrate how expression templates can\nbe used for compile time symbolic differentiation of algebraic expressions in\nC++ computer programs. Given a positive integer $N$ and an algebraic function\nof multiple variables, the compiler generates executable code for the $N$th\npartial derivatives of the function. Compile-time simplification of the\nderivative expressions is achieved using recursive templates. A detailed\nanalysis indicates that current C++ compiler technology is already sufficient\nfor practical use of our results, and highlights a number of issues where\nfurther improvements may be desirable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Automatic White-Box Testing of First-Order Logic Ontologies.   Formal ontologies are axiomatizations in a logic-based formalism. The\ndevelopment of formal ontologies, and their important role in the Semantic Web\narea, is generating considerable research on the use of automated reasoning\ntechniques and tools that help in ontology engineering. One of the main aims is\nto refine and to improve axiomatizations for enabling automated reasoning tools\nto efficiently infer reliable information. Defects in the axiomatization can\nnot only cause wrong inferences, but can also hinder the inference of expected\ninformation, either by increasing the computational cost of, or even\npreventing, the inference. In this paper, we introduce a novel, fully automatic\nwhite-box testing framework for first-order logic ontologies. Our methodology\nis based on the detection of inference-based redundancies in the given\naxiomatization. The application of the proposed testing method is fully\nautomatic since a) the automated generation of tests is guided only by the\nsyntax of axioms and b) the evaluation of tests is performed by automated\ntheorem provers. Our proposal enables the detection of defects and serves to\ncertify the grade of suitability --for reasoning purposes-- of every axiom. We\nformally define the set of tests that are generated from any axiom and prove\nthat every test is logically related to redundancies in the axiom from which\nthe test has been generated. We have implemented our method and used this\nimplementation to automatically detect several non-trivial defects that were\nhidden in various first-order logic ontologies. Throughout the paper we provide\nillustrative examples of these defects, explain how they were found, and how\neach proof --given by an automated theorem-prover-- provides useful hints on\nthe nature of each defect. Additionally, by correcting all the detected\ndefects, we have obtained an improved version of one of the tested ontologies:\nAdimen-SUMO.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Multilevel maximum likelihood estimation with application to covariance matrices.   The asymptotic variance of the maximum likelihood estimate is proved to\ndecrease when the maximization is restricted to a subspace that contains the\ntrue parameter value. Maximum likelihood estimation allows a systematic fitting\nof covariance models to the sample, which is important in data assimilation.\nThe hierarchical maximum likelihood approach is applied to the spectral\ndiagonal covariance model with different parameterizations of eigenvalue decay,\nand to the sparse inverse covariance model with specified parameter values on\ndifferent sets of nonzero entries. It is shown computationally that using\nsmaller sets of parameters can decrease the sampling noise in high dimension\nsubstantially.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sitatapatra: Blocking the Transfer of Adversarial Samples.   Convolutional Neural Networks (CNNs) are widely used to solve classification\ntasks in computer vision. However, they can be tricked into misclassifying\nspecially crafted `adversarial' samples -- and samples built to trick one model\noften work alarmingly well against other models trained on the same task. In\nthis paper we introduce Sitatapatra, a system designed to block the transfer of\nadversarial samples. It diversifies neural networks using a key, as in\ncryptography, and provides a mechanism for detecting attacks. What's more, when\nadversarial samples are detected they can typically be traced back to the\nindividual device that was used to develop them. The run-time overheads are\nminimal permitting the use of Sitatapatra on constrained systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Wasserstein Soft Label Propagation on Hypergraphs: Algorithm and Generalization Error Bounds.   Inspired by recent interests of developing machine learning and data mining\nalgorithms on hypergraphs, we investigate in this paper the semi-supervised\nlearning algorithm of propagating \"soft labels\" (e.g. probability\ndistributions, class membership scores) over hypergraphs, by means of optimal\ntransportation. Borrowing insights from Wasserstein propagation on graphs\n[Solomon et al. 2014], we re-formulate the label propagation procedure as a\nmessage-passing algorithm, which renders itself naturally to a generalization\napplicable to hypergraphs through Wasserstein barycenters. Furthermore, in a\nPAC learning framework, we provide generalization error bounds for propagating\none-dimensional distributions on graphs and hypergraphs using 2-Wasserstein\ndistance, by establishing the \\textit{algorithmic stability} of the proposed\nsemi-supervised learning algorithm. These theoretical results also shed new\nlights upon deeper understandings of the Wasserstein propagation on graphs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "LocalNysation: A bottom up approach to efficient localized kernel regression.   We consider a localized approach in the well-established setting of\nreproducing kernel learning under random design. The input space $X$ is\npartitioned into local disjoint subsets $X_j$ ($j=1,...,m$) equipped with a\nlocal reproducing kernel $K_j$. It is then straightforward to define local KRR\nestimates. Our first main contribution is in showing that minimax optimal rates\nof convergence are preserved if the number $m$ of partitions grows sufficiently\nslowly with the sample size, under locally different degrees on smoothness\nassumptions on the regression function. As a byproduct, we show that low\nsmoothness on exceptional sets of small probability does not contribute,\nleading to a faster rate of convergence. Our second contribution lies in\nshowing that the partitioning approach for KRR can be efficiently combined with\nlocal Nyström subsampling, improving computational cost twofold. If the\nnumber of locally subsampled inputs grows sufficiently fast with the sample\nsize, minimax optimal rates of convergence are maintained.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Supersymmetric field theories and geometric Langlands: The other side of the coin.   This note announces results on the relations between the approach of\nBeilinson and Drinfeld to the geometric Langlands correspondence based on\nconformal field theory, the approach of Kapustin and Witten based on $N=4$ SYM,\nand the AGT-correspondence. The geometric Langlands correspondence is described\nas the Nekrasov-Shatashvili limit of a generalisation of the AGT-correspondence\nin the presence of surface operators. Following the approaches of Kapustin -\nWitten and Nekrasov - Witten we interpret some aspects of the resulting picture\nusing an effective description in terms of two-dimensional sigma models having\nHitchin's moduli spaces as target-manifold.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Penrose type inequaltiy for graphs over Reissner-Nordström-anti-deSitter manifold.   In this paper, we use the inverse mean curvature flow to establish an optimal\nMinkowski type inquality, weighted Alexandrov-Fenchel inequality for the mean\nconvex star shaped hypersurfaces in Reissner-Nordström-anti-deSitter manifold\nand Penrose type inequality for asymptotically locally hyperbolic manifolds in\nwhich can be realized as graphs over Reissner-Nordström-anti-deSitter\nmanifold.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Existence of Noise Induced Order, a Computer Aided Proof.   We prove, by a computer aided proof, the existence of noise induced order in\nthe model of chaotic chemical reactions where it was first discovered\nnumerically by Matsumoto and Tsuda in 1983. We prove that in this random\ndynamical system the increase in amplitude of the noise causes the Lyapunov\nexponent to decrease from positive to negative, stabilizing the system. The\nmethod used is based on a certified approximation of the stationary measure in\nthe $L^{1}$ norm. This is done by an efficient algorithm which is general\nenough to be adapted to any piecewise differentiable dynamical system on the\ninterval with additive noise. We also prove that the stationary measure of the\nsystem and its Lyapunov exponent have a Lipschitz stability under several kinds\nof perturbation of the noise and of the system itself. The Lipschitz constants\nof this stability result are also estimated explicitly.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "A Survey of Runtime Monitoring Instrumentation Techniques.   Runtime Monitoring is a lightweight and dynamic verification technique that\ninvolves observing the internal operations of a software system and/or its\ninteractions with other external entities, with the aim of determining whether\nthe system satisfies or violates a correctness specification. Compilation\ntechniques employed in Runtime Monitoring tools allow monitors to be\nautomatically derived from high-level correctness specifications (aka.\nproperties). This allows the same property to be converted into different types\nof monitors, which may apply different instrumentation techniques for checking\nwhether the property was satisfied or not. In this paper we compare and\ncontrast the various types of monitoring methodologies found in the current\nliterature, and classify them into a spectrum of monitoring instrumentation\ntechniques, ranging from completely asynchronous monitoring on the one end and\ncompletely synchronous monitoring on the other.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Stochastic Feedback Control of Systems with Unknown Nonlinear Dynamics.   This paper studies the stochastic optimal control problem for systems with\nunknown dynamics. First, an open-loop deterministic trajectory optimization\nproblem is solved without knowing the explicit form of the dynamical system.\nNext, a Linear Quadratic Gaussian (LQG) controller is designed for the nominal\ntrajectory-dependent linearized system, such that under a small noise\nassumption, the actual states remain close to the optimal trajectory. The\ntrajectory-dependent linearized system is identified using input-output\nexperimental data consisting of the impulse responses of the nominal system. A\ncomputational example is given to illustrate the performance of the proposed\napproach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonsequential double ionization of helium in IR+XUV two-color laser fields II: Collision-excitation ionization process.   The collision-ionization mechanism of nonsequential double ionization (NSDI)\nprocess in IR+XUV two-color laser fields [\\PRA \\textbf{93}, 043417 (2016)] has\nbeen investigated by us recently. Here we extend this work to study the\ncollision-excitation-ionization (CEI) mechanism of NSDI processes in the\ntwo-color laser fields with different laser conditions. It is found that the\nCEI mechanism makes a dominant contribution to the NSDI as the XUV photon\nenergy is smaller than the ionization threshold of the He$^+$ ion, and the\nmomentum spectrum shows complex interference patterns and symmetrical\nstructures. By channel analysis, we find that, as the energy carried by the\nrecollision electron is not enough to excite the bound electron, the bound\nelectron will absorb XUV photons during their collision, as a result, both\nforward and backward collisions make a comparable contributions to the NSDI\nprocesses. However, it is found that, as the energy carried by the recollision\nelectron is large enough to excite the bound electron, the bound electron does\nnot absorb any XUV photon and it is excited only by sharing the energy carried\nby the recollsion electron, hence the forward collision plays a dominant role\non the NSDI processes. Moreover, we find that the interference patterns of the\nNSDI spectra can be reconstructed by the spectra of two above-threshold\nionization (ATI) processes, which may be used to analyze the structure of the\ntwo separate ATI spectra by NSDI processes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multiplicities of Character Values of Binary Sidel'nikov-Lempel-Cohn-Eastman Sequences.   Binary Sidel'nikov-Lempel-Cohn-Eastman sequences (or SLCE sequences) over F 2\nhave even period and almost perfect autocorrelation. However, the evaluation of\nthe linear complexity of these sequences is really difficult. In this paper, we\ncontinue the study of [1]. We first express the multiple roots of character\npolynomials of SLCE sequences into certain kinds of Jacobi sums. Then by making\nuse of Gauss sums and Jacobi sums in the \"semiprimitive\" case, we derive new\ndivisibility results for SLCE sequences.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A note on the bijectivity of antipode of a Hopf algebra and its applications.   Certain sufficient homological and ring-theoretical conditions are given for\na Hopf algebra to have bijective antipode with applications to noetherian Hopf\nalgebras regarding their homological behaviors.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Shannon entropy: a study of confined hydrogenic-like atoms.   The Shannon entropy in the atomic, molecular and chemical physics context is\npresented by using as test cases the hydrogenic-like atoms $H_c$, ${He_c}^+$\nand ${Li_c}^{2+}$ confined by an impenetrable spherical box. Novel expressions\nfor entropic uncertainty relation and Shannon entropies $S_r$ and $S_p$ are\nproposed to ensure their physical dimensionless characteristic. The electronic\nground state energy and the quantities $S_r$, $S_p$ and $S_t$ are calculated\nfor the hydrogenic-like atoms to different confinement radii by using a\nvariational method. The global behavior of these quantities and different\nconjectures are analyzed. The results are compared, when available, with those\npreviously published.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Inconsistency of Template Estimation with the Fr{é}chet mean in Quotient Space.   We tackle the problem of template estimation when data have been randomly\ntransformed under an isometric group action in the presence of noise. In order\nto estimate the template, one often minimizes the variance when the influence\nof the transformations have been removed (computation of the Fr{é}chet mean\nin quotient space). The consistency bias is defined as the distance (possibly\nzero) between the orbit of the template and the orbit of one element which\nminimizes the variance. In this article we establish an asymptotic behavior of\nthe consistency bias with respect to the noise level. This behavior is linear\nwith respect to the noise level. As a result the inconsistency is unavoidable\nas soon as the noise is large enough. In practice, the template estimation with\na finite sample is often done with an algorithm called max-max. We show the\nconvergence of this algorithm to an empirical Karcher mean. Finally, our\nnumerical experiments show that the bias observed in practice cannot be\nattributed to the small sample size or to a convergence problem but is indeed\ndue to the previously studied inconsistency.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An Optimal Control Problem for the Steady Nonhomogeneous Asymmetric Fluids.   We study an optimal boundary control problem for the two-dimensional\nstationary micropolar fluids system with variable density. We control the\nsystem by considering boundary controls, for the velocity vector and angular\nvelocity of rotation of particles, on parts of the boundary of the flow domain.\nOn the remaining part of the boundary, we consider mixed boundary conditions\nfor the vector velocity (Dirichlet and Navier conditions) and Dirichlet\nboundary conditions for the angular velocity. We analyze the existence of a\nweak solution obtaining the fluid density as a scalar function of the stream\nfunction. We prove the existence of an optimal solution and, by using the\nLagrange multipliers theorem, we state first-order optimality conditions. We\nalso derive, through a penalty method, some optimality conditions satisfied by\nthe optimal controls.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Human Eye Visual Hyperacuity: A New Paradigm for Sensing?.   The human eye appears to be using a low number of sensors for image\ncapturing. Furthermore, regarding the physical dimensions of\ncones-photoreceptors responsible for the sharp central vision-, we may realize\nthat these sensors are of a relatively small size and area. Nonetheless, the\neye is capable to obtain high resolution images due to visual hyperacuity and\npresents an impressive sensitivity and dynamic range when set against\nconventional digital cameras of similar characteristics. This article is based\non the hypothesis that the human eye may be benefiting from diffraction to\nimprove both image resolution and acquisition process. The developed method\nintends to explain and simulate using MATLAB software the visual hyperacuity:\nthe introduction of a controlled diffraction pattern at an initial stage,\nenables the use of a reduced number of sensors for capturing the image and\nmakes possible a subsequent processing to improve the final image resolution.\nThe results have been compared with the outcome of an equivalent system but in\nabsence of diffraction, achieving promising results. The main conclusion of\nthis work is that diffraction could be helpful for capturing images or signals\nwhen a small number of sensors available, which is far from being a\nresolution-limiting factor.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Grayscale Image Authentication using Neural Hashing.   Many different approaches for neural network based hash functions have been\nproposed. Statistical analysis must correlate security of them. This paper\nproposes novel neural hashing approach for gray scale image authentication. The\nsuggested system is rapid, robust, useful and secure. Proposed hash function\ngenerates hash values using neural network one-way property and non-linear\ntechniques. As a result security and performance analysis are performed and\nsatisfying results are achieved. These features are dominant reasons for\npreferring against traditional ones.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Deep Network Model for Paraphrase Detection in Short Text Messages.   This paper is concerned with paraphrase detection. The ability to detect\nsimilar sentences written in natural language is crucial for several\napplications, such as text mining, text summarization, plagiarism detection,\nauthorship authentication and question answering. Given two sentences, the\nobjective is to detect whether they are semantically identical. An important\ninsight from this work is that existing paraphrase systems perform well when\napplied on clean texts, but they do not necessarily deliver good performance\nagainst noisy texts. Challenges with paraphrase detection on user generated\nshort texts, such as Twitter, include language irregularity and noise. To cope\nwith these challenges, we propose a novel deep neural network-based approach\nthat relies on coarse-grained sentence modeling using a convolutional neural\nnetwork and a long short-term memory model, combined with a specific\nfine-grained word-level similarity matching model. Our experimental results\nshow that the proposed approach outperforms existing state-of-the-art\napproaches on user-generated noisy social media data, such as Twitter texts,\nand achieves highly competitive performance on a cleaner corpus.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Motion Planning Networks.   Fast and efficient motion planning algorithms are crucial for many\nstate-of-the-art robotics applications such as self-driving cars. Existing\nmotion planning methods such as RRT*, A*, and D*, become ineffective as their\ncomputational complexity increases exponentially with the dimensionality of the\nmotion planning problem. To address this issue, we present a neural\nnetwork-based novel planning algorithm which generates end-to-end\ncollision-free paths irrespective of the obstacles' geometry. The proposed\nmethod, called MPNet (Motion Planning Network), comprises of a Contractive\nAutoencoder which encodes the given workspaces directly from a point cloud\nmeasurement, and a deep feedforward neural network which takes the workspace\nencoding, start and goal configuration, and generates end-to-end feasible\nmotion trajectories for the robot to follow. We evaluate MPNet on multiple\nplanning problems such as planning of a point-mass robot, rigid-body, and 7 DOF\nBaxter robot manipulators in various 2D and 3D environments. The results show\nthat MPNet is not only consistently computationally efficient in all 2D and 3D\nenvironments but also show remarkable generalization to completely unseen\nenvironments. The results also show that computation time of MPNet consistently\nremains less than 1 second which is significantly lower than existing\nstate-of-the-art motion planning algorithms. Furthermore, through transfer\nlearning, the MPNet trained in one scenario (e.g., indoor living places) can\nalso quickly adapt to new scenarios (e.g., factory floors) with a little amount\nof data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning General Latent-Variable Graphical Models with Predictive Belief Propagation and Hilbert Space Embeddings.   In this paper, we propose a new algorithm for learning general\nlatent-variable probabilistic graphical models using the techniques of\npredictive state representation, instrumental variable regression, and\nreproducing-kernel Hilbert space embeddings of distributions. Under this new\nlearning framework, we first convert latent-variable graphical models into\ncorresponding latent-variable junction trees, and then reduce the hard\nparameter learning problem into a pipeline of supervised learning problems,\nwhose results will then be used to perform predictive belief propagation over\nthe latent junction tree during the actual inference procedure. We then give\nproofs of our algorithm's correctness, and demonstrate its good performance in\nexperiments on one synthetic dataset and two real-world tasks from\ncomputational biology and computer vision - classifying DNA splice junctions\nand recognizing human actions in videos.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Structure theorems for star-commuting power partial isometries.   We give a new formulation and proof of a theorem of Halmos and Wallen on the\nstructure of power partial isometries on Hilbert space. We then use this\ntheorem to give a structure theorem for a finite set of partial isometries\nwhich star-commute: each operator commutes with the others and with their\nadjoints.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Nonparametric inference for continuous-time event counting and link-based dynamic network models.   A flexible approach for modeling both dynamic event counting and dynamic\nlink-based networks based on counting processes is proposed, and estimation in\nthese models is studied. We consider nonparametric likelihood based estimation\nof parameter functions via kernel smoothing. The asymptotic behavior of these\nestimators is rigorously analyzed by allowing the number of nodes to tend to\ninfinity. The finite sample performance of the estimators is illustrated\nthrough an empirical analysis of bike share data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Phonon-assisted oscillatory exciton dynamics in monolayer MoSe2.   In monolayer semiconductor transition metal dichalcogenides, the\nexciton-phonon interaction is expected to strongly affect the photocarrier\ndynamics. Here, we report on an unusual oscillatory enhancement of the neutral\nexciton photoluminescence with the excitation laser frequency in monolayer\nMoSe2. The frequency of oscillation matches that of the M-point longitudinal\nacoustic phonon, LA(M). Oscillatory behavior is also observed in the\nsteady-state emission linewidth and in timeresolved photoluminescence\nexcitation data, which reveals variation with excitation energy in the exciton\nlifetime. These results clearly expose the key role played by phonons in the\nexciton formation and relaxation dynamics of two-dimensional van der Waals\nsemiconductors.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Scalable Cryogenic Read-out Circuit for a Superconducting Nanowire Single-Photon Detector System.   The superconducting nanowire single photon detector (SNSPD) is a leading\ntechnology for quantum information science applications using photons, and they\nare finding increasing uses in photon-starved classical imaging applications.\nCritical detector characteristics, such as timing resolution (jitter), reset\ntime and maximum count rate, are heavily influenced by the readout electronics\nthat sense and amplify the photon detection signal. We describe a readout\ncircuit for SNSPDs using commercial off-the-shelf amplifiers operating at\ncryogenic temperatures. Our design demonstrates a 35 ps timing resolution and a\nmaximum count rate of over 2x10^7 counts per second while maintaining <3 mW\npower consumption per channel, making it suitable for a multichannel readout.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Rigorous statistical analysis of HTTPS reachability.   The use of secure connections using HTTPS as the default means, or even the\nonly means, to connect to web servers is increasing. It is being pushed from\nboth sides: from the bottom up by client distributions and plugins, and from\nthe top down by organisations such as Google. However, there are potential\ntechnical hurdles that might lock some clients out of the modern web. This\npaper seeks to measure and precisely quantify those hurdles in the wild. More\nthan three million measurements provide statistically significant evidence of\ndegradation. We show this through a variety of statistical techniques. Various\nfactors are shown to influence the problem, ranging from the client's browser,\nto the locale from which they connect.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Asymptotic Exponentiality of the First Exit Time of the Shiryaev-Roberts Diffusion with Constant Positive Drift.   We consider the first exit time of a Shiryaev-Roberts diffusion with constant\npositive drift from the interval $[0,A]$ where $A>0$. We show that the moment\ngenerating function (Laplace transform) of a suitably standardized version of\nthe first exit time converges to that of the unit-mean exponential distribution\nas $A\\to+\\infty$. The proof is explicit in that the moment generating function\nof the first exit time is first expressed analytically and in a closed form,\nand then the desired limit as $A\\to+\\infty$ is evaluated directly. The result\nis of importance in the area of quickest change-point detection, and its\ndiscrete-time counterpart has been previously established - although in a\ndifferent manner - by Pollak and Tartakovsky (2009).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Singular Riemannian flows and characteristic numbers.   Let $M$ be an even-dimensional, oriented closed manifold. We show that the\nrestriction of a singular Riemannian flow on $M$ to a small tubular\nneighborhood of each connected component of its singular stratum is\nfoliated-diffeomorphic to an isometric flow on the same neighborhood. We then\nprove a formula that computes characteristic numbers of $M$ as the sum of\nresidues associated to the infinitesimal foliation at the components of the\nsingular stratum of the flow.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "$\\texttt{PyTranSpot}$ - A tool for multiband light curve modeling of planetary transits and stellar spots.   Several studies have shown that stellar activity features, such as occulted\nand non-occulted starspots, can affect the measurement of transit parameters\nbiasing studies of transit timing variations and transmission spectra. We\npresent $\\texttt{PyTranSpot}$, which we designed to model multiband transit\nlight curves showing starspot anomalies, inferring both transit and spot\nparameters. The code follows a pixellation approach to model the star with its\ncorresponding limb darkening, spots, and transiting planet on a two dimensional\nCartesian coordinate grid. We combine $\\texttt{PyTranSpot}$ with an MCMC\nframework to study and derive exoplanet transmission spectra, which provides\nstatistically robust values for the physical properties and uncertainties of a\ntransiting star-planet system. We validate $\\texttt{PyTranSpot}$'s performance\nby analyzing eleven synthetic light curves of four different star-planet\nsystems and 20 transit light curves of the well-studied WASP-41b system. We\nalso investigate the impact of starspots on transit parameters and derive\nwavelength dependent transit depth values for WASP-41b covering a range of\n6200-9200 $\\AA$, indicating a flat transmission spectrum.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Periods and factors of weak model sets.   There is a renewed interest in weak model sets due to their connection to\n$\\mathcal B$-free systems, which emerged from Sarnak's program on the Möbius\ndisjointness conjecture. Here we continue our recent investigation\n[arXiv:1511.06137] of the extended hull ${\\mathcal M}^{\\scriptscriptstyle\nG}_{\\scriptscriptstyle W}$, a dynamical system naturally associated to a weak\nmodel set in an abelian group $G$ with relatively compact window $W$. For\nwindows having a nowhere dense boundary (this includes compact windows), we\nidentify the maximal equicontinuous factor of ${\\mathcal M}^{\\scriptscriptstyle\nG}_{\\scriptscriptstyle W}$ and give a sufficient condition when ${\\mathcal\nM}^{\\scriptscriptstyle G}_{\\scriptscriptstyle W}$ is an almost 1:1 extension of\nits maximal equicontinuous factor. If the window is measurable with positive\nHaar measure and is almost compact, then the system ${\\mathcal\nM}^{\\scriptscriptstyle G}_{\\scriptscriptstyle W}$ equipped with its Mirsky\nmeasure is isomorphic to its Kronecker factor. For general nontrivial ergodic\nprobability measures on ${\\mathcal M}^{\\scriptscriptstyle\nG}_{\\scriptscriptstyle W}$, we provide a kind of lower bound for the Kronecker\nfactor. All relevant factor systems are natural $G$-actions on quotient\nsubgroups of the torus underlying the weak model set. These are obtained by\nfactoring out suitable window periods. Our results are specialised to the usual\nhull of the weak model set, and they are also interpreted for ${\\mathcal\nB}$-free systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Non-convex Conditional Gradient Sliding.   We investigate a projection free method, namely conditional gradient sliding\non batched, stochastic and finite-sum non-convex problem. CGS is a smart\ncombination of Nesterov's accelerated gradient method and Frank-Wolfe (FW)\nmethod, and outperforms FW in the convex setting by saving gradient\ncomputations. However, the study of CGS in the non-convex setting is limited.\nIn this paper, we propose the non-convex conditional gradient sliding (NCGS)\nwhich surpasses the non-convex Frank-Wolfe method in batched, stochastic and\nfinite-sum setting.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Comprehensive evaluation of statistical speech waveform synthesis.   Statistical TTS systems that directly predict the speech waveform have\nrecently reported improvements in synthesis quality. This investigation\nevaluates Amazon's statistical speech waveform synthesis (SSWS) system. An\nin-depth evaluation of SSWS is conducted across a number of domains to better\nunderstand the consistency in quality. The results of this evaluation are\nvalidated by repeating the procedure on a separate group of testers. Finally,\nan analysis of the nature of speech errors of SSWS compared to hybrid unit\nselection synthesis is conducted to identify the strengths and weaknesses of\nSSWS. Having a deeper insight into SSWS allows us to better define the focus of\nfuture work to improve this new technology.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Is the kinetic equation for turbulent gas-particle flows ill-posed?.   This paper is about well-posedness and realizability of the kinetic equation\nfor gas-particle flows and its relationship to the Generalized Langevin Model\n(GLM) PDF equation. Previous analyses claim that this kinetic equation is\nill-posed, that in particular it has the properties of a backward heat equation\nand as a consequence, its solutions will in the course of time exhibit\nfinite-time singularities. We show that the analysis leading to this conclusion\nis fundamentally incorrect because it ignores the coupling between the phase\nspace variables in the kinetic equation and the time and particle inertia\ndependence of the phase space diffusion tensor. This contributes an extra $+ve$\ndiffusion that always outweighs the contribution from the$-ve$ diffusion\nassociated with the dispersion along one of the principal axes of the phase\nspace diffusion tensor. This is confirmed by a numerical evaluation of analytic\nsolutions of these $+ve$ and $-ve$ contributions to the particle diffusion\ncoefficient along this principal axis. We also examine other erroneous claims\nand assumptions made in previous studies that demonstrate the apparent\nsuperiority of the GLM PDF approach over the kinetic approach. In so doing we\nhave drawn attention to the limitations of the GLM approach which these studies\nhave ignored or not properly considered, to give a more balanced appraisal of\nthe benefits of both PDF approaches.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Calibrating the Planck Cluster Mass Scale with Cluster Velocity Dispersions.   We measure the Planck cluster mass bias using dynamical mass measurements\nbased on velocity dispersions of a subsample of 17 Planck-detected clusters.\nThe velocity dispersions were calculated using redshifts determined from\nspectra obtained at Gemini observatory with the GMOS multi-object spectrograph.\nWe correct our estimates for effects due to finite aperture, Eddington bias and\ncorrelated scatter between velocity dispersion and the Planck mass proxy. The\nresult for the mass bias parameter, $(1-b)$, depends on the value of the galaxy\nvelocity bias $b_v$ adopted from simulations: $(1-b)=(0.51\\pm0.09) b_v^3$.\nUsing a velocity bias of $b_v=1.08$ from Munari et al., we obtain\n$(1-b)=0.64\\pm 0.11$, i.e, an error of 17% on the mass bias measurement with 17\nclusters. This mass bias value is consistent with most previous weak lensing\ndeterminations. It lies within $1\\sigma$ of the value needed to reconcile the\nPlanck cluster counts with the Planck primary CMB constraints. We emphasize\nthat uncertainty in the velocity bias severely hampers precision measurements\nof the mass bias using velocity dispersions. On the other hand, when we fix the\nPlanck mass bias using the constraints from Penna-Lima et al., based on weak\nlensing measurements, we obtain a positive velocity bias $b_v \\gtrsim 0.9$ at\n$3\\sigma$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Data-Driven MHD Model of the Global Solar Corona within Multi-Scale Fluid-Kinetic Simulation Suite (MS-FLUKSS).   We have developed a data-driven magnetohydrodynamic (MHD) model of the global\nsolar corona which uses characteristically-consistent boundary conditions (BCs)\nat the inner boundary. Our global solar corona model can be driven by different\nobservational data including Solar Dynamics Observatory/Helioseismic and\nMagnetic Imager (SDO/HMI) synoptic vector magnetograms together with the\nhorizontal velocity data in the photosphere obtained by the time-distance\nhelioseismology method, and the line-of-sight (LOS) magnetogram data obtained\nby HMI, Solar and Heliospheric Observatory/Michelson Doppler Imager (SOHO/MDI),\nNational Solar Observatory/Global Oscillation Network Group (NSO/GONG) and\nWilcox Solar Observatory (WSO). We implemented our model in the Multi-Scale\nFluid-Kinetic Simulation Suite (MS-FLUKSS) - a suite of adaptive mesh\nrefinement (AMR) codes built upon the Chombo AMR framework developed at the\nLawrence Berkeley National Laboratory. We present an overview of our model,\ncharacteristic BCs, and two results we obtained using our model: A benchmark\ntest of relaxation of a dipole field using characteristic BCs, and relaxation\nof an initial PFSS field driven by HMI LOS magnetogram data, and horizontal\nvelocity data obtained by the time-distance helioseismology method using a set\nof non-characteristic BCs.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Stellar Absorption Line Analysis of Local Star-Forming Galaxies: The Relation Between Stellar Mass, Metallicity, Dust Attenuation and Star Formation Rate.   We analyze the optical continuum of star-forming galaxies in SDSS by fitting\nstacked spectra with stellar population synthesis models to investigate the\nrelation between stellar mass, stellar metallicity, dust attenuation and star\nformation rate. We fit models calculated with star formation and chemical\nevolution histories that are derived empirically from multi-epoch observations\nof the stellar mass---star formation rate and the stellar mass---gas-phase\nmetallicity relations, respectively. We also fit linear combinations of single\nburst models with a range of metallicities and ages. Star formation and\nchemical evolution histories are unconstrained for these models. The stellar\nmass---stellar metallicity relations obtained from the two methods agree with\nthe relation measured from individual supergiant stars in nearby galaxies.\nThese relations are also consistent with the relation obtained from emission\nline analysis of gas-phase metallicity after accounting for systematic offsets\nin the gas-phase-metallicity. We measure dust attenuation of the stellar\ncontinuum and show that its dependence on stellar mass and star formation rate\nis consistent with previously reported results derived from nebular emission\nlines. However, stellar continuum attenuation is smaller than nebular emission\nline attenuation. The continuum-to-nebular attenuation ratio depends on stellar\nmass and is smaller in more massive galaxies. Our consistent analysis of\nstellar continuum and nebular emission lines paves the way for a comprehensive\ninvestigation of stellar metallicities of star-forming and quiescent galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Conjoined constraints on modified gravity from the expansion history and cosmic growth.   In this paper we present conjoined constraints on several cosmological models\nfrom the expansion history $H(z)$ and cosmic growth $f\\sigma_8(z)$. The models\nwe study include the CPL $w_0w_a$ parametrization, the Holographic Dark Energy\n(HDE) model, the Time varying vacuum ($\\Lambda_t$CDM) model, the Dvali,\nGabadadze and Porrati (DGP) and Finsler-Randers (FRDE) models, a power law\n$f(T)$ model and finally the Hu-Sawicki $f(R)$ model. In all cases we perform a\nsimultaneous fit to the SnIa, CMB, BAO, $H(z)$ and growth data, while also\nfollowing the conjoined visualization of $H(z)$ and $f\\sigma_8(z)$ as in Linder\n(2017). Furthermore, we introduce the Figure of Merit (FoM) in the\n$H(z)-f\\sigma_8(z)$ parameter space as a way to constrain models that jointly\nfit both probes well. We use both the latest $H(z)$ and $f\\sigma_8(z)$ data,\nbut also LSST-like mocks with $1\\%$ measurements and we find that the conjoined\nmethod of constraining the expansion history and cosmic growth simultaneously\nis able not only to place stringent constraints on these parameters but also to\nprovide an easy visual way to discriminate cosmological models. Finally, we\nconfirm the existence of a tension between the growth rate and Planck CMB data\nand we find that the FoM in the conjoined parameter space of\n$H(z)-f\\sigma_8(z)$ can be used to discriminate between the $\\Lambda$CDM model\nand certain classes of modified gravity models, namely the DGP and $f(T)$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Facial Keypoints Detection.   Detect facial keypoints is a critical element in face recognition. However,\nthere is difficulty to catch keypoints on the face due to complex influences\nfrom original images, and there is no guidance to suitable algorithms. In this\npaper, we study different algorithms that can be applied to locate keyponits.\nSpecifically: our framework (1)prepare the data for further investigation\n(2)Using PCA and LBP to process the data (3) Apply different algorithms to\nanalysis data, including linear regression models, tree based model, neural\nnetwork and convolutional neural network, etc. Finally we will give our\nconclusion and further research topic. A comprehensive set of experiments on\ndataset demonstrates the effectiveness of our framework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Beam-induced Back-streaming Electron Suppression Analysis for Accelerator Type Neutron Generators.   A facility based on a next-generation, high-flux D-D neutron generator has\nbeen commissioned and it is now operational at the University of California,\nBerkeley. The current generator design produces near monoenergetic 2.45 MeV\nneutrons at outputs of 10^8 n/s. Calculations provided show that future\nconditioning at higher currents and voltages will allow for a production rate\nover 10^10 n/s. A significant problem encountered was beam-induced electron\nbackstreaming, that needed to be resolved to achieve meaningful beam currents.\nTwo methods of suppressing secondary electrons resulting from the deuterium\nbeam striking the target were tested: the application of static electric and\nmagnetic fields. Computational simulations of both techniques were done using a\nfinite element analysis in COMSOL Multiphysics. Experimental tests verified\nthese simulation results. The most reliable suppression was achieved via the\nimplementation of an electrostatic shroud with a voltage offset of -800 V\nrelative to the target.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Factors in Recommending Contrarian Content on Social Media.   Polarization is a troubling phenomenon that can lead to societal divisions\nand hurt the democratic process. It is therefore important to develop methods\nto reduce it.\nWe propose an algorithmic solution to the problem of reducing polarization.\nThe core idea is to expose users to content that challenges their point of\nview, with the hope broadening their perspective, and thus reduce their\npolarity. Our method takes into account several aspects of the problem, such as\nthe estimated polarity of the user, the probability of accepting the\nrecommendation, the polarity of the content, and popularity of the content\nbeing recommended.\nWe evaluate our recommendations via a large-scale user study on Twitter users\nthat were actively involved in the discussion of the US elections results.\nResults shows that, in most cases, the factors taken into account in the\nrecommendation affect the users as expected, and thus capture the essential\nfeatures of the problem.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Membrane Trafficking in the Yeast Saccharomyces cerevisiae Model.   The yeast Saccharomyces cerevisiae is one of the best characterized\neukaryotic models. The secretory pathway was the first trafficking pathway\nclearly understood mainly thanks to the work done in the laboratory of Randy\nSchekman in the 1980s. They have isolated yeast sec mutants unable to secrete\nan extracellular enzyme and these SEC genes were identified as encoding key\neffectors of the secretory machinery. For this work, the 2013 Nobel Prize in\nPhysiology and Medicine has been awarded to Randy Schekman; the prize is shared\nwith James Rothman and Thomas S{ü}dhof. Here, we present the different\ntrafficking pathways of yeast S. cerevisiae. At the Golgi apparatus newly\nsynthesized proteins are sorted between those transported to the plasma\nmembrane (PM), or the external medium, via the exocytosis or secretory pathway\n(SEC), and those targeted to the vacuole either through endosomes (vacuolar\nprotein sorting or VPS pathway) or directly (alkaline phosphatase or ALP\npathway). Plasma membrane proteins can be internalized by endocytosis (END) and\ntransported to endosomes where they are sorted between those targeted for\nvacuolar degradation and those redirected to the Golgi (recycling or RCY\npathway). Studies in yeast S. cerevisiae allowed the identification of most of\nthe known effectors, protein complexes, and trafficking pathways in eukaryotic\ncells, and most of them are conserved among eukaryotes.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Dynamical characteristics of electromagnetic field under conditions of total reflection.   The dynamical characteristics of electromagnetic fields include energy,\nmomentum, angular momentum (spin) and helicity. We analyze their spatial\ndistributions near the planar interface between two transparent and\nnon-dispersive media, when the incident monochromatic plane wave with arbitrary\npolarization is totally reflected, and an evanescent wave is formed in the\nmedium with lower optical density. Based on the recent arguments in favor of\nthe Minkowski definition of the electromagnetic momentum in a material medium\n[Phys. Rev. A 83, 013823 (2011); 86, 055802 (2012); Phys. Rev. Lett. 119,\n073901 (2017)], we derive the explicit expressions for the dynamical\ncharacteristics in both media, with special attention to their behavior at the\ninterface. Especially, the \"extraordinary\" spin and momentum components\northogonal to the plane of incidence are described, and the canonical (spin -\norbital) momentum decomposition is performed that contains no singular terms.\nThe field energy, helicity, the spin momentum and orbital momentum components\nare everywhere regular but experience discontinuities at the interface; the\nspin components parallel to the interface appear to be continuous, which\ntestifies for the consistency of the adopted Minkowski picture. The results\nsupply a meaningful example of the electromagnetic momentum decomposition, with\nseparation of spatial and polarization degrees of freedom, in inhomogeneous\nmedia, and can be used in engineering the structured fields designed for\noptical sorting, dispatching and micromanipulation.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "From Distance Correlation to Multiscale Graph Correlation.   Understanding and developing a correlation measure that can detect general\ndependencies is not only imperative to statistics and machine learning, but\nalso crucial to general scientific discovery in the big data age. In this\npaper, we establish a new framework that generalizes distance correlation --- a\ncorrelation measure that was recently proposed and shown to be universally\nconsistent for dependence testing against all joint distributions of finite\nmoments --- to the Multiscale Graph Correlation (MGC). By utilizing the\ncharacteristic functions and incorporating the nearest neighbor machinery, we\nformalize the population version of local distance correlations, define the\noptimal scale in a given dependency, and name the optimal local correlation as\nMGC. The new theoretical framework motivates a theoretically sound Sample MGC\nand allows a number of desirable properties to be proved, including the\nuniversal consistency, convergence and almost unbiasedness of the sample\nversion. The advantages of MGC are illustrated via a comprehensive set of\nsimulations with linear, nonlinear, univariate, multivariate, and noisy\ndependencies, where it loses almost no power in monotone dependencies while\nachieving better performance in general dependencies, compared to distance\ncorrelation and other popular methods.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Applying the Delta method in metric analytics: A practical guide with novel ideas.   During the last decade, the information technology industry has adopted a\ndata-driven culture, relying on online metrics to measure and monitor business\nperformance. Under the setting of big data, the majority of such metrics\napproximately follow normal distributions, opening up potential opportunities\nto model them directly without extra model assumptions and solve big data\nproblems via closed-form formulas using distributed algorithms at a fraction of\nthe cost of simulation-based procedures like bootstrap. However, certain\nattributes of the metrics, such as their corresponding data generating\nprocesses and aggregation levels, pose numerous challenges for constructing\ntrustworthy estimation and inference procedures. Motivated by four real-life\nexamples in metric development and analytics for large-scale A/B testing, we\nprovide a practical guide to applying the Delta method, one of the most\nimportant tools from the classic statistics literature, to address the\naforementioned challenges. We emphasize the central role of the Delta method in\nmetric analytics by highlighting both its classic and novel applications.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adversarial Attacks on Neural Networks for Graph Data.   Deep learning models for graphs have achieved strong performance for the task\nof node classification. Despite their proliferation, currently there is no\nstudy of their robustness to adversarial attacks. Yet, in domains where they\nare likely to be used, e.g. the web, adversaries are common. Can deep learning\nmodels for graphs be easily fooled? In this work, we introduce the first study\nof adversarial attacks on attributed graphs, specifically focusing on models\nexploiting ideas of graph convolutions. In addition to attacks at test time, we\ntackle the more challenging class of poisoning/causative attacks, which focus\non the training phase of a machine learning model. We generate adversarial\nperturbations targeting the node's features and the graph structure, thus,\ntaking the dependencies between instances in account. Moreover, we ensure that\nthe perturbations remain unnoticeable by preserving important data\ncharacteristics. To cope with the underlying discrete domain we propose an\nefficient algorithm Nettack exploiting incremental computations. Our\nexperimental study shows that accuracy of node classification significantly\ndrops even when performing only few perturbations. Even more, our attacks are\ntransferable: the learned attacks generalize to other state-of-the-art node\nclassification models and unsupervised approaches, and likewise are successful\neven when only limited knowledge about the graph is given.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Invitation to Alexandrov geometry: CAT[0] spaces.   The idea is to demonstrate the beauty and power of Alexandrov geometry by\nreaching interesting applications with a minimum of preparation.\nThe topics include\n1. Estimates on the number of collisions in billiards.\n2. Construction of exotic aspherical manifolds.\n3. The geometry of two-convex sets in Euclidean space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Advantages of versatile neural-network decoding for topological codes.   Finding optimal correction of errors in generic stabilizer codes is a\ncomputationally hard problem, even for simple noise models. While this task can\nbe simplified for codes with some structure, such as topological stabilizer\ncodes, developing good and efficient decoders still remains a challenge. In our\nwork, we systematically study a very versatile class of decoders based on\nfeedforward neural networks. To demonstrate adaptability, we apply neural\ndecoders to the triangular color and toric codes under various noise models\nwith realistic features, such as spatially-correlated errors. We report that\nneural decoders provide significant improvement over leading efficient decoders\nin terms of the error-correction threshold. Using neural networks simplifies\nthe process of designing well-performing decoders, and does not require prior\nknowledge of the underlying noise model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Evaluating openEHR for storing computable representations of electronic health record phenotyping algorithms.   Electronic Health Records (EHR) are data generated during routine clinical\ncare. EHR offer researchers unprecedented phenotypic breadth and depth and have\nthe potential to accelerate the pace of precision medicine at scale. A main EHR\nuse-case is creating phenotyping algorithms to define disease status, onset and\nseverity. Currently, no common machine-readable standard exists for defining\nphenotyping algorithms which often are stored in human-readable formats. As a\nresult, the translation of algorithms to implementation code is challenging and\nsharing across the scientific community is problematic. In this paper, we\nevaluate openEHR, a formal EHR data specification, for computable\nrepresentations of EHR phenotyping algorithms.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Non-Gaussian, Nonparametric Structure for Gene-Gene and Gene-Environment Interactions in Case-Control Studies Based on Hierarchies of Dirichlet Processes.   It is becoming increasingly clear that complex interactions among genes and\nenvironmental factors play crucial roles in triggering complex diseases. Thus,\nunderstanding such interactions is vital, which is possible only through\nstatistical models that adequately account for such intricate, albeit unknown,\ndependence structures. Bhattacharya & Bhattacharya (2016b) attempt such\nmodeling, relating finite mixtures composed of Dirichlet processes that\nrepresent unknown number of genetic sub-populations through a hierarchical\nmatrix-normal structure that incorporates gene-gene interactions, and possible\nmutations, induced by environmental variables. However, the product dependence\nstructure implied by their matrix-normal model seems to be too simple to be\nappropriate for general complex, realistic situations. In this article, we\npropose and develop a novel nonparametric Bayesian model for case-control\ngenotype data using hierarchies of Dirichlet processes that offers a more\nrealistic and nonparametric dependence structure between the genes, induced by\nthe environmental variables. In this regard, we propose a novel and highly\nparallelisable MCMC algorithm that is rendered quite efficient by the\ncombination of modern parallel computing technology, effective Gibbs sampling\nsteps, retrospective sampling and Transformation based Markov Chain Monte Carlo\n(TMCMC). We use appropriate Bayesian hypothesis testing procedures to detect\nthe roles of genes and environment in case-control studies. We apply our ideas\nto 5 biologically realistic case-control genotype datasets simulated under\ndistinct set-ups, and obtain encouraging results in each case. We finally apply\nour ideas to a real, myocardial infarction dataset, and obtain interesting\nresults on gene-gene and gene-environment interaction, while broadly agreeing\nwith the results reported in the literature.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Discrete Gradient Line Fields on Surfaces.   A line field on a manifold is a smooth map which assigns a tangent line to\nall but a finite number of points of the manifold. As such, it can be seen as a\ngeneralization of vector fields. They model a number of geometric and physical\nproperties, e.g. the principal curvature directions dynamics on surfaces or the\nstress flux in elasticity.\nWe propose a discretization of a Morse-Smale line field on surfaces,\nextending Forman's construction for discrete vector fields. More general\ncritical elements and their indices are defined from local matchings, for which\nEuler theorem and the characterization of homotopy type in terms of critical\ncells still hold.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Minors of two-connected graphs of large path-width.   Let $P$ be a graph with a vertex $v$ such that $P\\backslash v$ is a forest,\nand let $Q$ be an outerplanar graph. We prove that there exists a number\n$p=p(P,Q)$ such that every 2-connected graph of path-width at least $p$ has a\nminor isomorphic to $P$ or $Q$. This result answers a question of Seymour and\nimplies a conjecture of Marshall and Wood. The proof is based on a new property\nof tree-decompositions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the character degrees of a Sylow $p$-subgroup of a finite Chevalley group $G(p^f)$ over a bad prime.   Let $q$ be a power of a prime $p$ and let $U(q)$ be a Sylow $p$-subgroup of a\nfinite Chevalley group $G(q)$ defined over the field with $q$ elements. We\nfirst give a parametrization of the set $\\text{Irr}(U(q))$ of irreducible\ncharacters of $U(q)$ when $G(q)$ is of type $\\mathrm{G}_2$. This is uniform for\nprimes $p \\ge 5$, while the bad primes $p=2$ and $p=3$ have to be considered\nseparately. We then use this result and the contribution of several authors to\nshow a general result, namely that if $G(q)$ is any finite Chevalley group with\n$p$ a bad prime, then there exists a character $\\chi \\in \\text{Irr}(U(q))$ such\nthat $\\chi(1)=q^n/p$ for some $n \\in \\mathbb{Z}_{\\ge_0}$. In particular, for\neach $G(q)$ and every bad prime $p$, we construct a family of characters of\nsuch degree as inflation followed by an induction of linear characters of an\nabelian subquotient $V(q)$ of $U(q)$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Disentangling and Assessing Uncertainties in Multiperiod Corporate Default Risk Predictions.   Measuring the corporate default risk is broadly important in economics and\nfinance. Quantitative methods have been developed to predictively assess future\ncorporate default probabilities. However, as a more difficult yet crucial\nproblem, evaluating the uncertainties associated with the default predictions\nremains little explored. In this paper, we attempt to fill this blank by\ndeveloping a procedure for quantifying the level of associated uncertainties\nupon carefully disentangling multiple contributing sources. Our framework\neffectively incorporates broad information from historical default data,\ncorporates' financial records, and macroeconomic conditions by a)\ncharacterizing the default mechanism, and b) capturing the future dynamics of\nvarious features contributing to the default mechanism. Our procedure overcomes\nthe major challenges in this large scale statistical inference problem and\nmakes it practically feasible by using parsimonious models, innovative methods,\nand modern computational facilities. By predicting the marketwide total number\nof defaults and assessing the associated uncertainties, our method can also be\napplied for evaluating the aggregated market credit risk level. Upon analyzing\na US market data set, we demonstrate that the level of uncertainties associated\nwith default risk assessments is indeed substantial. More informatively, we\nalso find that the level of uncertainties associated with the default risk\npredictions is correlated with the level of default risks, indicating potential\nfor new scopes in practical applications including improving the accuracy of\ndefault risk assessments.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Joint Routing, Scheduling and Power Control Providing Hard Deadline in Wireless Multihop Networks.   We consider optimal/efficient power allocation policies in a single/multihop\nwireless network in the presence of hard end-to-end deadline delay constraints\non the transmitted packets. Such constraints can be useful for real time voice\nand video. Power is consumed in only transmission of the data. We consider the\ncase when the power used in transmission is a convex function of the data\ntransmitted. We develop a computationally efficient online algorithm, which\nminimizes the average power for the single hop. We model this problem as\ndynamic program (DP) and obtain the optimal solution. Next, we generalize it to\nthe multiuser, multihop scenario when there are multiple real time streams with\ndifferent hard deadline constraints.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tunnelling in Dante's Inferno.   We study quantum tunnelling in Dante's Inferno model of large field\ninflation. Such a tunnelling process, which will terminate inflation, becomes\nproblematic if the tunnelling rate is rapid compared to the Hubble time scale\nat the time of inflation. Consequently, we constrain the parameter space of\nDante's Inferno model by demanding a suppressed tunnelling rate during\ninflation. The constraints are derived and explicit numerical bounds are\nprovided for representative examples. Our considerations are at the level of an\neffective field theory; hence, the presented constraints have to hold\nregardless of any UV completion.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Room-temperature spin transport in n-Ge probed by four-terminal nonlocal measurements.   We demonsrtate electrical spin injection and detection in $n$-type Ge\n($n$-Ge) at room temperature using four-terminal nonlocal spin-valve and\nHanle-effect measurements in lateral spin-valve (LSV) devices with\nHeusler-alloy Schottky tunnel contacts. The spin diffusion length\n($\\lambda$$_{\\rm Ge}$) of the Ge layer used ($n \\sim$ 1 $\\times$ 10$^{19}$\ncm$^{-3}$) at 296 K is estimated to be $\\sim$ 0.44 $\\pm$ 0.02 $\\mu$m.\nRoom-temperature spin signals can be observed reproducibly at the low bias\nvoltage range ($\\le$ 0.7 V) for LSVs with relatively low resistance-area\nproduct ($RA$) values ($\\le$ 1 k$\\Omega$$\\mu$m$^{2}$). This means that the\nSchottky tunnel contacts used here are more suitable than ferromagnet/MgO\ntunnel contacts ($RA \\ge$ 100 k$\\Omega$$\\mu$m$^{2}$) for developing Ge\nspintronic applications.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Fast and Robust Shortest Paths on Manifolds Learned from Data.   We propose a fast, simple and robust algorithm for computing shortest paths\nand distances on Riemannian manifolds learned from data. This amounts to\nsolving a system of ordinary differential equations (ODEs) subject to boundary\nconditions. Here standard solvers perform poorly because they require\nwell-behaved Jacobians of the ODE, and usually, manifolds learned from data\nimply unstable and ill-conditioned Jacobians. Instead, we propose a fixed-point\niteration scheme for solving the ODE that avoids Jacobians. This enhances the\nstability of the solver, while reduces the computational cost. In experiments\ninvolving both Riemannian metric learning and deep generative models we\ndemonstrate significant improvements in speed and stability over both\ngeneral-purpose state-of-the-art solvers as well as over specialized solvers.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "mGPfusion: Predicting protein stability changes with Gaussian process kernel learning and data fusion.   Proteins are commonly used by biochemical industry for numerous processes.\nRefining these proteins' properties via mutations causes stability effects as\nwell. Accurate computational method to predict how mutations affect protein\nstability are necessary to facilitate efficient protein design. However,\naccuracy of predictive models is ultimately constrained by the limited\navailability of experimental data. We have developed mGPfusion, a novel\nGaussian process (GP) method for predicting protein's stability changes upon\nsingle and multiple mutations. This method complements the limited experimental\ndata with large amounts of molecular simulation data. We introduce a Bayesian\ndata fusion model that re-calibrates the experimental and in silico data\nsources and then learns a predictive GP model from the combined data. Our\nprotein-specific model requires experimental data only regarding the protein of\ninterest and performs well even with few experimental measurements. The\nmGPfusion models proteins by contact maps and infers the stability effects\ncaused by mutations with a mixture of graph kernels. Our results show that\nmGPfusion outperforms state-of-the-art methods in predicting protein stability\non a dataset of 15 different proteins and that incorporating molecular\nsimulation data improves the model learning and prediction accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Spatial structure of shock formation.   The formation of a singularity in a compressible gas, as described by the\nEuler equation, is characterized by the steepening, and eventual overturning of\na wave. Using a self-similar description in two space dimensions, we show that\nthe spatial structure of this process, which starts at a point, is equivalent\nto the formation of a caustic, i.e. to a cusp catastrophe. The lines along\nwhich the profile has infinite slope correspond to the caustic lines, from\nwhich we construct the position of the shock. By solving the similarity\nequation, we obtain a complete local description of wave steepening and of the\nspreading of the shock from a point.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Survey on Content-Aware Video Analysis for Sports.   Sports data analysis is becoming increasingly large-scale, diversified, and\nshared, but difficulty persists in rapidly accessing the most crucial\ninformation. Previous surveys have focused on the methodologies of sports video\nanalysis from the spatiotemporal viewpoint instead of a content-based\nviewpoint, and few of these studies have considered semantics. This study\ndevelops a deeper interpretation of content-aware sports video analysis by\nexamining the insight offered by research into the structure of content under\ndifferent scenarios. On the basis of this insight, we provide an overview of\nthe themes particularly relevant to the research on content-aware systems for\nbroadcast sports. Specifically, we focus on the video content analysis\ntechniques applied in sportscasts over the past decade from the perspectives of\nfundamentals and general review, a content hierarchical model, and trends and\nchallenges. Content-aware analysis methods are discussed with respect to\nobject-, event-, and context-oriented groups. In each group, the gap between\nsensation and content excitement must be bridged using proper strategies. In\nthis regard, a content-aware approach is required to determine user demands.\nFinally, the paper summarizes the future trends and challenges for sports video\nanalysis. We believe that our findings can advance the field of research on\ncontent-aware video analysis for broadcast sports.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Synergistic Team Composition.   Effective teams are crucial for organisations, especially in environments\nthat require teams to be constantly created and dismantled, such as software\ndevelopment, scientific experiments, crowd-sourcing, or the classroom. Key\nfactors influencing team performance are competences and personality of team\nmembers. Hence, we present a computational model to compose proficient and\ncongenial teams based on individuals' personalities and their competences to\nperform tasks of different nature. With this purpose, we extend Wilde's\npost-Jungian method for team composition, which solely employs individuals'\npersonalities. The aim of this study is to create a model to partition agents\ninto teams that are balanced in competences, personality and gender. Finally,\nwe present some preliminary empirical results that we obtained when analysing\nstudent performance. Results show the benefits of a more informed team\ncomposition that exploits individuals' competences besides information about\ntheir personalities.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On analyzing and evaluating privacy measures for social networks under active attack.   Widespread usage of complex interconnected social networks such as Facebook,\nTwitter and LinkedIn in modern internet era has also unfortunately opened the\ndoor for privacy violation of users of such networks by malicious entities. In\nthis article we investigate, both theoretically and empirically, privacy\nviolation measures of large networks under active attacks that was recently\nintroduced in (Information Sciences, 328, 403-417, 2016). Our theoretical\nresult indicates that the network manager responsible for prevention of privacy\nviolation must be very careful in designing the network if its topology does\nnot contain a cycle. Our empirical results shed light on privacy violation\nproperties of eight real social networks as well as a large number of synthetic\nnetworks generated by both the classical Erdos-Renyi model and the scale-free\nrandom networks generated by the Barabasi-Albert preferential-attachment model.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Theory is Predictive, but is it Complete? An Application to Human Perception of Randomness.   When we test a theory using data, it is common to focus on correctness: do\nthe predictions of the theory match what we see in the data? But we also care\nabout completeness: how much of the predictable variation in the data is\ncaptured by the theory? This question is difficult to answer, because in\ngeneral we do not know how much \"predictable variation\" there is in the\nproblem. In this paper, we consider approaches motivated by machine learning\nalgorithms as a means of constructing a benchmark for the best attainable level\nof prediction.\nWe illustrate our methods on the task of predicting human-generated random\nsequences. Relative to an atheoretical machine learning algorithm benchmark, we\nfind that existing behavioral models explain roughly 15 percent of the\npredictable variation in this problem. This fraction is robust across several\nvariations on the problem. We also consider a version of this approach for\nanalyzing field data from domains in which human perception and generation of\nrandomness has been used as a conceptual framework; these include sequential\ndecision-making and repeated zero-sum games. In these domains, our framework\nfor testing the completeness of theories provides a way of assessing their\neffectiveness over different contexts; we find that despite some differences,\nthe existing theories are fairly stable across our field domains in their\nperformance relative to the benchmark. Overall, our results indicate that (i)\nthere is a significant amount of structure in this problem that existing models\nhave yet to capture and (ii) there are rich domains in which machine learning\nmay provide a viable approach to testing completeness.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Fréchet Bounds for Cell Entries in Multidimensional Contingency Tables.   We consider the lattice, $\\mathcal{L}$, of all subsets of a multidimensional\ncontingency table and establish the properties of monotonicity and\nsupermodularity for the marginalization function, $n(\\cdot)$, on $\\mathcal{L}$.\nWe derive from the supermodularity of $n(\\cdot)$ some generalized Fréchet\ninequalities complementing and extending inequalities of Dobra and Fienberg.\nFurther, we construct new monotonic and supermodular functions from $n(\\cdot)$,\nand we remark on the connection between supermodularity and some correlation\ninequalities for probability distributions on lattices. We also apply an\ninequality of Ky Fan to derive a new approach to Fréchet inequalities for\nmultidimensional contingency tables.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "An application of the Hylleraas-B-splines basis set: High accuracy calculations of the static dipole polarizabilities of helium.   The Hylleraas-B-splines basis set is introduced in this paper, which can be\nused to obtain the eigenvalues and eigenstates of helium-like system's\nHamiltonian. Comparing with traditional B-splines basis, the rate of\nconvergence of our results has been significantly improved. Through combine\nthis method and pseudo-states sum over scheme, we obtained the high precision\nvalues of static dipole porlarizabilities of the $1{}^1S-5{}^1S$,\n$2{}^3S-6{}^3S$ states of helium in length and velocity gauges respectively,\nand the results get good agreements. The final extrapolate results of\nporlarizabilities in different quantum states arrived eight significant digits\nat least, which fully illustrates the advantage and convenience of this method\nin the problems involving continuous states.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the Evaluation of Silicon Photomultipliers for Use as Photosensors in Liquid Xenon Detectors.   Silicon photomultipliers (SiPMs) are potential solid-state alternatives to\ntraditional photomultiplier tubes (PMTs) for single-photon detection. In this\npaper, we report on evaluating SensL MicroFC-10035-SMT SiPMs for their\nsuitability as PMT replacements. The devices were successfully operated in a\nliquid-xenon detector, which demonstrates that SiPMs can be used in noble\nelement time projection chambers as photosensors. The devices were also cooled\ndown to 170 K to observe dark count dependence on temperature. No dependencies\non the direction of an applied 3.2 kV/cm electric field were observed with\nrespect to dark-count rate, gain, or photon detection efficiency.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the bottom of spectra under coverings.   For a Riemannian covering $M_1\\to M_0$ of complete Riemannian manifolds with\nboundary (possibly empty) and respective fundamental groups\n$\\Gamma_1\\subseteq\\Gamma_0$, we show that the bottoms of the spectra of $M_0$\nand $M_1$ coincide if the right action of $\\Gamma_0$ on\n$\\Gamma_1\\backslash\\Gamma_0$ is amenable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "New Directions In Cellular Automata.   We Propose A Novel Automaton Model which uses Arithmetic Operations as the\nEvolving Rules, each cell has the states of the Natural Numbers k = (N), a\nradius of r = 1/2 and operates on an arbitrary input size. The Automaton reads\nan Arithmetic Expression as an input and outputs another Arithmetic Expression.\nIn Addition, we simulate a variety of One Dimensional Cellular Automata\nStructures with different Dynamics including Elementary Cellular Automata.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "A Coherent vorticity preserving eddy viscosity correction for Large-Eddy Simulation.   This paper introduces a new approach to Large-Eddy Simulation (LES) where\nsubgrid-scale (SGS) dissipation is applied proportionally to the degree of\nlocal spectral broadening, hence mitigated or deactivated in regions dominated\nby large-scale and/or laminar vortical motion. The proposed Coherent vorticity\npreserving (CvP) LES methodology is based on the evaluation of the ratio of the\ntest-filtered to resolved (or grid-filtered) enstrophy $\\sigma$. Values of\n$\\sigma$ close to 1 indicate low sub-test-filter turbulent activity, justifying\nlocal deactivation of the SGS dissipation. The intensity of the SGS dissipation\nis progressively increased for $\\sigma < 1$ which corresponds to a small-scale\nspectral broadening. The SGS dissipation is then fully activated in developed\nturbulence characterized by $\\sigma \\le \\sigma_{eq}$, where the value\n$\\sigma_{eq}$ is derived assuming a Kolmogorov spectrum. The proposed approach\ncan be applied to any eddy-viscosity model, is algorithmically simple and\ncomputationally inexpensive. LES of Taylor-Green vortex breakdown demonstrates\nthat the CvP methodology improves the performance of traditional, non-dynamic\ndissipative SGS models, capturing the peak of total turbulent kinetic energy\ndissipation during transition. Similar accuracy is obtained by adopting\nGermano's dynamic procedure albeit at more than twice the computational\noverhead. A CvP-LES of a pair of unstable periodic helical vortices is shown to\npredict accurately the experimentally observed growth rate using coarse\nresolutions. The ability of the CvP methodology to dynamically sort the\ncoherent, large-scale motion from the smaller, broadband scales during\ntransition is demonstrated via flow visualizations. LES of compressible channel\nare carried out and show a good match with a reference DNS.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Magnetic properties of nanoparticles compacts with controlled broadening of the particle size distribution.   Binary random compacts with different proportions of small (volume V) and\nlarge (volume 2V) bare maghemite nanoparticles (NPs) are used to investigate\nthe effect of controllably broadening the particle size distribution on the\nmagnetic properties of magnetic NP assemblies with strong dipolar interaction.\nA series of eight random mixtures of highly uniform 9.0 and 11.5 nm diameter\nmaghemite particles prepared by thermal decomposition are studied. In spite of\nseverely broadened size distributions in the mixed samples, well defined\nsuperspin glass transition temperatures are observed across the series, their\nvalues increasing linearly with the weight fraction of large particles.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Projection Theorems Using Effective Dimension.   In this paper we use the theory of computing to study fractal dimensions of\nprojections in Euclidean spaces. A fundamental result in fractal geometry is\nMarstrand's projection theorem, which shows that for every analytic set E, for\nalmost every line L, the Hausdorff dimension of the orthogonal projection of E\nonto L is maximal. We use Kolmogorov complexity to give two new results on the\nHausdorff and packing dimensions of orthogonal projections onto lines. The\nfirst shows that the conclusion of Marstrand's theorem holds whenever the\nHausdorff and packing dimensions agree on the set E, even if E is not analytic.\nOur second result gives a lower bound on the packing dimension of projections\nof arbitrary sets. Finally, we give a new proof of Marstrand's theorem using\nthe theory of computing.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "General Bayesian Updating and the Loss-Likelihood Bootstrap.   In this paper we revisit the weighted likelihood bootstrap, a method that\ngenerates samples from an approximate Bayesian posterior of a parametric model.\nWe show that the same method can be derived, without approximation, under a\nBayesian nonparametric model with the parameter of interest defined as\nminimising an expected negative log-likelihood under an unknown sampling\ndistribution. This interpretation enables us to extend the weighted likelihood\nbootstrap to posterior sampling for parameters minimizing an expected loss. We\ncall this method the loss-likelihood bootstrap. We make a connection between\nthis and general Bayesian updating, which is a way of updating prior belief\ndistributions without needing to construct a global probability model, yet\nrequires the calibration of two forms of loss function. The loss-likelihood\nbootstrap is used to calibrate the general Bayesian posterior by matching\nasymptotic Fisher information. We demonstrate the methodology on a number of\nexamples.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep learning for universal linear embeddings of nonlinear dynamics.   Identifying coordinate transformations that make strongly nonlinear dynamics\napproximately linear is a central challenge in modern dynamical systems. These\ntransformations have the potential to enable prediction, estimation, and\ncontrol of nonlinear systems using standard linear theory. The Koopman operator\nhas emerged as a leading data-driven embedding, as eigenfunctions of this\noperator provide intrinsic coordinates that globally linearize the dynamics.\nHowever, identifying and representing these eigenfunctions has proven to be\nmathematically and computationally challenging. This work leverages the power\nof deep learning to discover representations of Koopman eigenfunctions from\ntrajectory data of dynamical systems. Our network is parsimonious and\ninterpretable by construction, embedding the dynamics on a low-dimensional\nmanifold that is of the intrinsic rank of the dynamics and parameterized by the\nKoopman eigenfunctions. In particular, we identify nonlinear coordinates on\nwhich the dynamics are globally linear using a modified auto-encoder. We also\ngeneralize Koopman representations to include a ubiquitous class of systems\nthat exhibit continuous spectra, ranging from the simple pendulum to nonlinear\noptics and broadband turbulence. Our framework parametrizes the continuous\nfrequency using an auxiliary network, enabling a compact and efficient\nembedding at the intrinsic rank, while connecting our models to half a century\nof asymptotics. In this way, we benefit from the power and generality of deep\nlearning, while retaining the physical interpretability of Koopman embeddings.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "Random matrices and the New York City subway system.   We analyze subway arrival times in the New York City subway system. We find\nregimes where the gaps between trains exhibit both (unitarily invariant) random\nmatrix statistics and Poisson statistics. The departure from random matrix\nstatistics is captured by the value of the Coulomb potential along the subway\nroute. This departure becomes more pronounced as trains make more stops.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Effective perturbation theory for linear operators.   We propose a new approach to the spectral theory of perturbed linear\noperators , in the case of a simple isolated eigenvalue. We obtain two kind of\nresults: \"radius bounds\" which ensure perturbation theory applies for\nperturbations up to an explicit size, and \"regularity bounds\" which control the\nvariations of eigendata to any order. Our method is based on the Implicit\nFunction Theorem and proceeds by establishing differential inequalities on two\nnatural quantities: the norm of the projection to the eigendirection, and the\nnorm of the reduced resolvent. We obtain completely explicit results without\nany assumption on the underlying Banach space. In companion articles, on the\none hand we apply the regularity bounds to Markov chains, obtaining\nnon-asymptotic concentration and Berry-Ess{é}en inequalities with explicit\nconstants, and on the other hand we apply the radius bounds to transfer\noperator of intermittent maps, obtaining explicit high-temperature regimes\nwhere a spectral gap occurs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The toric Frobenius morphism and a conjecture of Orlov.   We combine the Bondal-Uehara method for producing exceptional collections on\ntoric varieties with a result of the first author and Favero to expand the set\nof varieties satisfying Orlov's Conjecture on derived dimension.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Fast counting of medium-sized rooted subgraphs.   We prove that counting copies of any graph $F$ in another graph $G$ can be\nachieved using basic matrix operations on the adjacency matrix of $G$.\nMoreover, the resulting algorithm is competitive for medium-sized $F$: our\nalgorithm recovers the best known complexity for rooted 6-clique counting and\nimproves on the best known for 9-cycle counting. Underpinning our proofs is the\nnew result that, for a general class of graph operators, matrix operations are\nhomomorphisms for operations on rooted graphs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamic analysis and control PID path of a model type gantry crane.   This paper presents an alternate form for the dynamic modelling of a\nmechanical system that simulates in real life a gantry crane type, using\nEuler's classical mechanics and Lagrange formalism, which allows find the\nequations of motion that our model describe. Moreover, it has a basic model\ndesign system using the SolidWorks software, based on the material and\ndimensions of the model provides some physical variables necessary for\nmodelling. In order to verify the theoretical results obtained, a contrast was\nmade between solutions obtained by simulation in SimMechanics-Matlab and\nEuler-Lagrange equations system, has been solved through Matlab libraries for\nsolving equation's systems of the type and order obtained. The force is\ndetermined, but not as exerted by the spring, as this will be the control\nvariable. The objective to bring the mass of the pendulum from one point to\nanother with a specified distance without the oscillation from it, so that, the\nanswer is overdamped. This article includes an analysis of PID control in which\nthe equations of motion of Euler-Lagrange are rewritten in the state space,\nonce there, they were implemented in Simulink to get the natural response of\nthe system to a step input in F and then draw the desired trajectories.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On Quaternionic Tori and their Moduli Spaces.   Quaternionic tori are defined as quotients of the skew field $\\mathbb{H}$ of\nquaternions by rank-4 lattices. Using slice regular functions, these tori are\nendowed with natural structures of quaternionic manifolds (in fact quaternionic\ncurves), and a fundamental region in a $12$-dimensional real subspace is then\nconstructed to classify them up to biregular diffeomorphisms. The points of the\nmoduli space correspond to suitable \\emph{special} bases of rank-4 lattices,\nwhich are studied with respect to the action of the group $GL(4, \\mathbb{Z})$,\nand up to biregular diffeomeorphisms. All tori with a non trivial group of\nbiregular automorphisms - and all possible groups of their biregular\nautomorphisms - are then identified, and recognized to correspond to five\ndifferent subsets of boundary points of the moduli space.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamically reconfigurable metal-semiconductor Yagi-Uda nanoantenna.   We propose a novel type of tunable Yagi-Uda nanoantenna composed of\nmetal-dielectric (Ag-Ge) core-shell nanoparticles. We show that, due to the\ncombination of two types of resonances in each nanoparticle, such hybrid\nYagi-Uda nanoantenna can operate in two different regimes. Besides the\nconventional nonresonant operation regime at low frequencies, characterized by\nhighly directive emission in the forward direction, there is another one at\nhigher frequencies caused by hybrid magneto-electric response of the core-shell\nnanoparticles. This regime is based on the excitation of the van Hove\nsingularity, and emission in this regime is accompanied by high values of\ndirectivity and Purcell factor within the same narrow frequency range. Our\nanalysis reveals the possibility of flexible dynamical tuning of the hybrid\nnanoantenna emission pattern via electron-hole plasma excitation by 100\nfemtosecond pump pulse with relatively low peak intensities $\\sim$200\nMW/cm$^2$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Note on Property Testing Sum of Squares and Multivariate Polynomial Interpolation.   In this paper, we investigate property testing whether or not a degree d\nmultivariate poly- nomial is a sum of squares or is far from a sum of squares.\nWe show that if we require that the property tester always accepts YES\ninstances and uses random samples, $n^{\\Omega(d)}$ samples are required, which\nis not much fewer than it would take to completely determine the polynomial. To\nprove this lower bound, we show that with high probability, multivariate\npolynomial in- terpolation matches arbitrary values on random points and the\nresulting polynomial has small norm. We then consider a particular polynomial\nwhich is non-negative yet not a sum of squares and use pseudo-expectation\nvalues to prove it is far from being a sum of squares.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Origin of layer dependence in band structures of two-dimensional materials.   We study the origin of layer dependence in band structures of two-dimensional\nmaterials. We find that the layer dependence, at the density functional theory\n(DFT) level, is a result of quantum confinement and the non-linearity of the\nexchange-correlation functional. We use this to develop an efficient scheme for\nperforming DFT and GW calculations of multilayer systems. We show that the DFT\nand quasiparticle band structures of a multilayer system can be derived from a\nsingle calculation on a monolayer of the material. We test this scheme on\nmultilayers of MoS$_2$, graphene and phosphorene. This new scheme yields\nresults in excellent agreement with the standard methods at a fraction of the\ncomputation cost. This helps overcome the challenge of performing fully\nconverged GW calculations on multilayers of 2D materials, particularly in the\ncase of transition metal dichalcogenides which involve very stringent\nconvergence parameters.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Opportunistic Downlink Interference Alignment for Multi-Cell MIMO Networks.   In this paper, we propose an opportunistic downlink interference alignment\n(ODIA) for interference-limited cellular downlink, which intelligently combines\nuser scheduling and downlink IA techniques. The proposed ODIA not only\nefficiently reduces the effect of inter-cell interference from other-cell base\nstations (BSs) but also eliminates intra-cell interference among spatial\nstreams in the same cell. We show that the minimum number of users required to\nachieve a target degrees-of-freedom (DoF) can be fundamentally reduced, i.e.,\nthe fundamental user scaling law can be improved by using the ODIA, compared\nwith the existing downlink IA schemes. In addition, we adopt a limited feedback\nstrategy in the ODIA framework, and then analyze the number of feedback bits\nrequired for the system with limited feedback to achieve the same user scaling\nlaw of the ODIA as the system with perfect CSI. We also modify the original\nODIA in order to further improve sum-rate, which achieves the optimal multiuser\ndiversity gain, i.e., $\\log\\log N$, per spatial stream even in the presence of\ndownlink inter-cell interference, where $N$ denotes the number of users in a\ncell. Simulation results show that the ODIA significantly outperforms existing\ninterference management techniques in terms of sum-rate in realistic cellular\nenvironments. Note that the ODIA operates in a non-collaborative and decoupled\nmanner, i.e., it requires no information exchange among BSs and no iterative\nbeamformer optimization between BSs and users, thus leading to an easier\nimplementation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Photometric Redshifts for Hyper Suprime-Cam Subaru Strategic Program Data Release 1.   Photometric redshifts are a key component of many science objectives in the\nHyper Suprime-Cam Subaru Strategic Program (HSC-SSP). In this paper, we\ndescribe and compare the codes used to compute photometric redshifts for\nHSC-SSP, how we calibrate them, and the typical accuracy we achieve with the\nHSC five-band photometry (grizy). We introduce a new point estimator based on\nan improved loss function and demonstrate that it works better than other\ncommonly used estimators. We find that our photo-z's are most accurate at\n0.2<~zphot<~1.5, where we can straddle the 4000A break. We achieve\nsigma(d_zphot/(1+zphot))~0.05 and an outlier rate of about 15% for galaxies\ndown to i=25 within this redshift range. If we limit to a brighter sample of\ni<24, we achieve sigma~0.04 and ~8% outliers. Our photo-z's should thus enable\nmany science cases for HSC-SSP. We also characterize the accuracy of our\nredshift probability distribution function (PDF) and discover that some codes\nover/under-estimate the redshift uncertainties, which have implications for\nN(z) reconstruction. Our photo-z products for the entire area in the Public\nData Release 1 are publicly available, and both our catalog products (such as\npoint estimates) and full PDFs can be retrieved from the data release site,\nthis https URL.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Spatio-Temporal Multivariate Shared Component Model with an Application in Iran Cancer Data.   Among the proposals for joint disease mapping, the shared component model has\nbecome more popular. Another recent advance to strengthen inference of disease\ndata has been the extension of purely spatial models to include time and\nspace-time interaction. Such analyses have additional benefits over purely\nspatial models. However, only a few proposed spatio-temporal models could\naddress analysing multiple diseases jointly.\nIn the proposed model, each component is shared by different subsets of\ndiseases, spatial and temporal trends are considered for each component, and\nthe relative weight of these trends for each component for each relevant\ndisease can be estimated. We present an application of the proposed method on\nincidence rates of seven prevalent cancers in Iran. The effect of the shared\ncomponents on the individual cancer types can be identified. Regional and\ntemporal variation in relative risks is shown. We present a model which\ncombines the benefits of shared-components with spatio-temporal techniques for\nmultivariate data. We show, how the model allows to analyse geographical and\ntemporal variation among diseases beyond previous approaches.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lattice Boltzmann study of chemically-driven self-propelled droplets.   We numerically study the behavior of self-propelled liquid droplets whose\nmotion is triggered by a Marangoni-like flow. This latter is generated by\nvariations of surfactant concentration which affect the droplet surface tension\npromoting its motion. In the present paper a model for droplets with a third\namphiphilic component is adopted. The dynamics is described by Navier-Stokes\nand convection-diffusion equations, solved by lattice Boltzmann method coupled\nwith finite-difference schemes. We focus on two cases. First the study of\nself-propulsion of an isolated droplet is carried on and, then, the interaction\nof two self-propelled droplets is investigated. In both cases, when the\nsurfactant migrates towards the interface, a quadrupolar vortex of the velocity\nfield forms inside the droplet and causes the motion. A weaker dipolar field\nemerges instead when the surfactant is mainly diluted in the bulk. The dynamics\nof two interacting droplets is more complex and strongly depends on their\nreciprocal distance. If, in a head-on collision, droplets are close enough, the\nvelocity field initially attracts them until a motionless steady state is\nachieved. If the droplets are vertically shifted, the hydrodynamic field leads\nto an initial reciprocal attraction followed by a scattering along opposite\ndirections. This hydrodynamic interaction acts on a separation of some droplet\nradii otherwise it becomes negligible and droplets motion is only driven by\nMarangoni effect. Finally, if one of the droplets is passive, this latter is\ngenerally advected by the fluid flow generated by the active one.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Wavelength Does Not Equal Pressure: Vertical Contribution Functions and their Implications for Mapping Hot Jupiters.   Multi-band phase variations in principle allow us to infer the longitudinal\ntemperature distributions of planets as a function of height in their\natmospheres. For example, 3.6 micron emission originates from deeper layers of\nthe atmosphere than 4.5 micron due to greater water vapor absorption at the\nlonger wavelength. Since heat transport efficiency increases with pressure, we\nexpect thermal phase curves at 3.6 micron to exhibit smaller amplitudes and\ngreater phase offsets than at 4.5 micron; this trend is not observed. Of the\nseven hot Jupiters with full-orbit phase curves at 3.6 and 4.5 micron, all have\ngreater phase amplitude at 3.6 micron than at 4.5 micron, while four of seven\nexhibit a greater phase offset at 3.6 micron. We use a 3D\nradiative-hydrodynamic model to calculate theoretical phase curves of HD\n189733b, assuming thermo-chemical equilibrium. The model exhibits temperature,\npressure, and wavelength dependent opacity, primarily driven by carbon\nchemistry: CO is energetically favored on the dayside, while CH4 is favored on\nthe cooler nightside. Infrared opacity therefore changes by orders of magnitude\nbetween day and night, producing dramatic vertical shifts in the\nwavelength-specific photospheres, which would complicate eclipse or phase\nmapping with spectral data. The model predicts greater relative phase amplitude\nand greater phase offset at 3.6 micron than at 4.5 micron, in agreement with\nthe data. Our model qualitatively explains the observed phase curves, but is in\ntension with current thermo-chemical kinetics models that predict zonally\nuniform atmospheric composition due to transport of CO from the hot regions of\nthe atmosphere.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Temporal Graph Offset Reconstruction: Towards Temporally Robust Graph Representation Learning.   Graphs are a commonly used construct for representing relationships between\nelements in complex high dimensional datasets. Many real-world phenomenon are\ndynamic in nature, meaning that any graph used to represent them is inherently\ntemporal. However, many of the machine learning models designed to capture\nknowledge about the structure of these graphs ignore this rich temporal\ninformation when creating representations of the graph. This results in models\nwhich do not perform well when used to make predictions about the future state\nof the graph -- especially when the delta between time stamps is not small. In\nthis work, we explore a novel training procedure and an associated unsupervised\nmodel which creates graph representations optimised to predict the future state\nof the graph. We make use of graph convolutional neural networks to encode the\ngraph into a latent representation, which we then use to train our temporal\noffset reconstruction method, inspired by auto-encoders, to predict a later\ntime point -- multiple time steps into the future. Using our method, we\ndemonstrate superior performance for the task of future link prediction\ncompared with none-temporal state-of-the-art baselines. We show our approach to\nbe capable of outperforming non-temporal baselines by 38% on a real world\ndataset.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using Human Brain Activity to Guide Machine Learning.   Machine learning is a field of computer science that builds algorithms that\nlearn. In many cases, machine learning algorithms are used to recreate a human\nability like adding a caption to a photo, driving a car, or playing a game.\nWhile the human brain has long served as a source of inspiration for machine\nlearning, little effort has been made to directly use data collected from\nworking brains as a guide for machine learning algorithms. Here we demonstrate\na new paradigm of \"neurally-weighted\" machine learning, which takes fMRI\nmeasurements of human brain activity from subjects viewing images, and infuses\nthese data into the training process of an object recognition learning\nalgorithm to make it more consistent with the human brain. After training,\nthese neurally-weighted classifiers are able to classify images without\nrequiring any additional neural data. We show that our neural-weighting\napproach can lead to large performance gains when used with traditional machine\nvision features, as well as to significant improvements with already\nhigh-performing convolutional neural network features. The effectiveness of\nthis approach points to a path forward for a new class of hybrid machine\nlearning algorithms which take both inspiration and direct constraints from\nneuronal data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "DepthSynth: Real-Time Realistic Synthetic Data Generation from CAD Models for 2.5D Recognition.   Recent progress in computer vision has been dominated by deep neural networks\ntrained over large amounts of labeled data. Collecting such datasets is however\na tedious, often impossible task; hence a surge in approaches relying solely on\nsynthetic data for their training. For depth images however, discrepancies with\nreal scans still noticeably affect the end performance. We thus propose an\nend-to-end framework which simulates the whole mechanism of these devices,\ngenerating realistic depth data from 3D models by comprehensively modeling\nvital factors e.g. sensor noise, material reflectance, surface geometry. Not\nonly does our solution cover a wider range of sensors and achieve more\nrealistic results than previous methods, assessed through extended evaluation,\nbut we go further by measuring the impact on the training of neural networks\nfor various recognition tasks; demonstrating how our pipeline seamlessly\nintegrates such architectures and consistently enhances their performance.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Topic supervised non-negative matrix factorization.   Topic models have been extensively used to organize and interpret the\ncontents of large, unstructured corpora of text documents. Although topic\nmodels often perform well on traditional training vs. test set evaluations, it\nis often the case that the results of a topic model do not align with human\ninterpretation. This interpretability fallacy is largely due to the\nunsupervised nature of topic models, which prohibits any user guidance on the\nresults of a model. In this paper, we introduce a semi-supervised method called\ntopic supervised non-negative matrix factorization (TS-NMF) that enables the\nuser to provide labeled example documents to promote the discovery of more\nmeaningful semantic structure of a corpus. In this way, the results of TS-NMF\nbetter match the intuition and desired labeling of the user. The core of TS-NMF\nrelies on solving a non-convex optimization problem for which we derive an\niterative algorithm that is shown to be monotonic and convergent to a local\noptimum. We demonstrate the practical utility of TS-NMF on the Reuters and\nPubMed corpora, and find that TS-NMF is especially useful for conceptual or\nbroad topics, where topic key terms are not well understood. Although\nidentifying an optimal latent structure for the data is not a primary objective\nof the proposed approach, we find that TS-NMF achieves higher weighted Jaccard\nsimilarity scores than the contemporary methods, (unsupervised) NMF and latent\nDirichlet allocation, at supervision rates as low as 10% to 20%.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Dynamic Advisor-Based Ensemble (dynABE): Case Study in Stock Trend Prediction of Critical Metal Companies.   The demand for metals by modern technology has been shifting from common base\nmetals to a variety of minor metals, such as cobalt or indium. The industrial\nimportance and limited geological availability of some minor metals have led to\nthem being considered more \"critical,\" and there is a growing investment\ninterest in such critical metals and their producing companies. In this\nresearch, we create a novel framework, Dynamic Advisor-Based Ensemble (dynABE),\nfor stock prediction and use critical metal companies as case study. dynABE\nuses domain knowledge to diversify the feature set by dividing them into\ndifferent \"advisors.\" creates high-level ensembles with complex base models for\neach advisor, and combines the advisors together dynamically during validation\nwith a novel and effective online update strategy. We test dynABE on three\ncobalt-related companies, and it achieves the best-case misclassification error\nof 31.12% and excess return of 477% compared to the stock itself in a year and\na half. In addition to presenting an effective stock prediction model with\ndecent profitabilities, this research further analyzes dynABE to visualize how\nit works in practice, which also yields discoveries of its interesting\nbehaviors when processing time-series data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Lower bounds for several online variants of bin packing.   We consider several previously studied online variants of bin packing and\nprove new and improved lower bounds on the asymptotic competitive ratios for\nthem. For that, we use a method of fully adaptive constructions. In particular,\nwe improve the lower bound for the asymptotic competitive ratio of online\nsquare packing significantly, raising it from roughly 1.68 to above 1.75.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Monte Carlo study of the Coincidence Resolving Time of a liquid xenon PET scanner, using Cherenkov radiation.   In this paper we use detailed Monte Carlo simulations to demonstrate that\nliquid xenon (LXe) can be used to build a Cherenkov-based TOF-PET, with an\nintrinsic coincidence resolving time (CRT) in the vicinity of 10 ps. This\nextraordinary performance is due to three facts: a) the abundant emission of\nCherenkov photons by liquid xenon; b) the fact that LXe is transparent to\nCherenkov light; and c) the fact that the fastest photons in LXe have\nwavelengths higher than 300 nm, therefore making it possible to separate the\ndetection of scintillation and Cherenkov light. The CRT in a Cherenkov LXe\nTOF-PET detector is, therefore, dominated by the resolution (time jitter)\nintroduced by the photosensors and the electronics. However, we show that for\nsufficiently fast photosensors (e.g, an overall 40 ps jitter, which can be\nachieved by current micro-channel plate photomultipliers) the overall CRT\nvaries between 30 and 55 ps, depending of the detection efficiency. This is\nstill one order of magnitude better than commercial CRT devices and improves by\na factor 3 the best CRT obtained with small laboratory prototypes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A study on text-score disagreement in online reviews.   In this paper, we focus on online reviews and employ artificial intelligence\ntools, taken from the cognitive computing field, to help understanding the\nrelationships between the textual part of the review and the assigned numerical\nscore. We move from the intuitions that 1) a set of textual reviews expressing\ndifferent sentiments may feature the same score (and vice-versa); and 2)\ndetecting and analyzing the mismatches between the review content and the\nactual score may benefit both service providers and consumers, by highlighting\nspecific factors of satisfaction (and dissatisfaction) in texts.\nTo prove the intuitions, we adopt sentiment analysis techniques and we\nconcentrate on hotel reviews, to find polarity mismatches therein. In\nparticular, we first train a text classifier with a set of annotated hotel\nreviews, taken from the Booking website. Then, we analyze a large dataset, with\naround 160k hotel reviews collected from Tripadvisor, with the aim of detecting\na polarity mismatch, indicating if the textual content of the review is in\nline, or not, with the associated score.\nUsing well established artificial intelligence techniques and analyzing in\ndepth the reviews featuring a mismatch between the text polarity and the score,\nwe find that -on a scale of five stars- those reviews ranked with middle scores\ninclude a mixture of positive and negative aspects.\nThe approach proposed here, beside acting as a polarity detector, provides an\neffective selection of reviews -on an initial very large dataset- that may\nallow both consumers and providers to focus directly on the review subset\nfeaturing a text/score disagreement, which conveniently convey to the user a\nsummary of positive and negative features of the review target.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Perfect spike detection via time reversal.   Spiking neuronal networks are usually simulated with three main simulation\nschemes: the classical time-driven and event-driven schemes, and the more\nrecent hybrid scheme. All three schemes evolve the state of a neuron through a\nseries of checkpoints: equally spaced in the first scheme and determined\nneuron-wise by spike events in the latter two. The time-driven and the hybrid\nscheme determine whether the membrane potential of a neuron crosses a threshold\nat the end of of the time interval between consecutive checkpoints. Threshold\ncrossing can, however, occur within the interval even if this test is negative.\nSpikes can therefore be missed. The present work derives, implements, and\nbenchmarks a method for perfect retrospective spike detection. This method can\nbe applied to neuron models with affine or linear subthreshold dynamics. The\nidea behind the method is to propagate the threshold with a time-inverted\ndynamics, testing whether the threshold crosses the neuron state to be evolved,\nrather than vice versa. Algebraically this translates into a set of\ninequalities necessary and sufficient for threshold crossing. This test is\nslower than the imperfect one, but faster than an alternative perfect tests\nbased on bisection or root-finding methods. Comparison confirms earlier results\nthat the imperfect test rarely misses spikes (less than a fraction $1/10^8$ of\nmissed spikes) in biologically relevant settings. This study offers an\nalternative geometric point of view on neuronal dynamics.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Estimating the reproductive number, total outbreak size, and reporting rates for Zika epidemics in South and Central America.   As South and Central American countries prepare for increased birth defects\nfrom Zika virus outbreaks and plan for mitigation strategies to minimize\nongoing and future outbreaks, understanding important characteristics of Zika\noutbreaks and how they vary across regions is a challenging and important\nproblem. We developed a mathematical model for the 2015 Zika virus outbreak\ndynamics in Colombia, El Salvador, and Suriname. We fit the model to publicly\navailable data provided by the Pan American Health Organization, using\nApproximate Bayesian Computation to estimate parameter distributions and\nprovide uncertainty quantification. An important model input is the at-risk\nsusceptible population, which can vary with a number of factors including\nclimate, elevation, population density, and socio-economic status. We informed\nthis initial condition using the highest historically reported dengue incidence\nmodified by the probable dengue reporting rates in the chosen countries. The\nmodel indicated that a country-level analysis was not appropriate for Colombia.\nWe then estimated the basic reproduction number, or the expected number of new\nhuman infections arising from a single infected human, to range between 4 and 6\nfor El Salvador and Suriname with a median of 4.3 and 5.3, respectively. We\nestimated the reporting rate to be around 16% in El Salvador and 18% in\nSuriname with estimated total outbreak sizes of 73,395 and 21,647 people,\nrespectively. The uncertainty in parameter estimates highlights a need for\nresearch and data collection that will better constrain parameter ranges.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Generalized Moran sets Generated by Step-wise Adjustable Iterated Function Systems.   In this article we provide a systematic way of creating generalized Moran\nsets using an analogous iterated function system (IFS) procedure. We use a\nstep-wise adjustable IFS to introduce some variance (such as\nnon-self-similarity) in the fractal limit sets. The process retains the\ncomputational simplicity of a standard IFS procedure. In our construction of\nthe generalized Moran sets, we also weaken the fourth Moran Structure Condition\nthat requires the same pattern of diameter ratios be used across a generation.\nMoreover, we provide upper and lower bounds for the Hausdorff dimension of the\nfractals created from this generalized process. Specific examples (Cantor-like\nsets, Sierpinski-like Triangles, etc) with the calculations of their\ncorresponding dimensions are studied.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "End-to-end Networks for Supervised Single-channel Speech Separation.   The performance of single channel source separation algorithms has improved\ngreatly in recent times with the development and deployment of neural networks.\nHowever, many such networks continue to operate on the magnitude spectrogram of\na mixture, and produce an estimate of source magnitude spectrograms, to perform\nsource separation. In this paper, we interpret these steps as additional neural\nnetwork layers and propose an end-to-end source separation network that allows\nus to estimate the separated speech waveform by operating directly on the raw\nwaveform of the mixture. Furthermore, we also propose the use of masking based\nend-to-end separation networks that jointly optimize the mask and the latent\nrepresentations of the mixture waveforms. These networks show a significant\nimprovement in separation performance compared to existing architectures in our\nexperiments. To train these end-to-end models, we investigate the use of\ncomposite cost functions that are derived from objective evaluation metrics as\nmeasured on waveforms. We present subjective listening test results that\ndemonstrate the improvement attained by using masking based end-to-end networks\nand also reveal insights into the performance of these cost functions for\nend-to-end source separation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Faster Boosting with Smaller Memory.   The two state-of-the-art implementations of boosted trees: XGBoost and\nLightGBM, can process large training sets extremely fast. However, this\nperformance requires that memory size is sufficient to hold a 2-3 multiple of\nthe training set size. This paper presents an alternative approach to\nimplementing boosted trees. which achieves a significant speedup over XGBoost\nand LightGBM, especially when memory size is small. This is achieved using a\ncombination of two techniques: early stopping and stratified sampling, which\nare explained and analyzed in the paper. We describe our implementation and\npresent experimental results to support our claims.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Probing Spatial Locality in Ionic Liquids with the Grand Canonical Adaptive Resolution Molecular Dynamics Technique.   We employ the Grand Canonical Adaptive Resolution Molecular Dynamics\nTechnique (GC-AdResS) to test the spatial locality of the 1-ethyl 3-methyl\nimidazolium chloride liquid. In GC-AdResS atomistic details are kept only in an\nopen sub-region of the system while the environment is treated at\ncoarse-grained level, thus if spatial quantities calculated in such a\nsub-region agree with the equivalent quantities calculated in a full atomistic\nsimulation then the atomistic degrees of freedom outside the sub-region play a\nnegligible role. The size of the sub-region fixes the degree of spatial\nlocality of a certain quantity. We show that even for sub-regions whose radius\ncorresponds to the size of a few molecules, spatial properties are reasonably\n{reproduced} thus suggesting a higher degree of spatial locality, a hypothesis\nput forward also by other {researchers} and that seems to play an important\nrole for the characterization of fundamental properties of a large class of\nionic liquids.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Algebraic entropy of (integrable) lattice equations and their reductions.   We study the growth of degrees in many autonomous and non-autonomous lattice\nequations defined by quad rules with corner boundary values, some of which are\nknown to be integrable by other characterisations. Subject to an enabling\nconjecture, we prove polynomial growth for a large class of equations which\nincludes the Adler-Bobenko-Suris equations and Viallet's $Q_V$ and its\nnon-autonomous generalization. Our technique is to determine the ambient degree\ngrowth of the projective version of the lattice equations and to conjecture the\ngrowth of their common factors at each lattice vertex, allowing the true degree\ngrowth to be found. The resulting degrees satisfy a linear partial difference\nequation which is universal, i.e. the same for all the integrable lattice\nequations considered. When we take periodic reductions of these equations,\nwhich includes staircase initial conditions, we obtain from this linear partial\ndifference equation an ordinary difference equation for degrees that implies\nquadratic or linear degree growth. We also study growth of degree of several\nnon-integrable lattice equations. Exponential growth of degrees of these\nequations, and their mapping reductions, is also proved subject to a\nconjecture.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Weakly supervised training of deep convolutional neural networks for overhead pedestrian localization in depth fields.   Overhead depth map measurements capture sufficient amount of information to\nenable human experts to track pedestrians accurately. However, fully automating\nthis process using image analysis algorithms can be challenging. Even though\nhand-crafted image analysis algorithms are successful in many common cases,\nthey fail frequently when there are complex interactions of multiple objects in\nthe image. Many of the assumptions underpinning the hand-crafted solutions do\nnot hold in these cases and the multitude of exceptions are hard to model\nprecisely. Deep Learning (DL) algorithms, on the other hand, do not require\nhand crafted solutions and are the current state-of-the-art in object\nlocalization in images. However, they require exceeding amount of annotations\nto produce successful models. In the case of object localization these\nannotations are difficult and time consuming to produce. In this work we\npresent an approach for developing pedestrian localization models using DL\nalgorithms with efficient weak supervision from an expert. We circumvent the\nneed for annotation of large corpus of data by annotating only small amount of\npatches and relying on synthetic data augmentation as a vehicle for injecting\nexpert knowledge in the model training. This approach of weak supervision\nthrough expert selection of representative patches, suitable transformations\nand synthetic data augmentations enables us to successfully develop DL models\nfor pedestrian localization efficiently.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Using Minimum Path Cover to Boost Dynamic Programming on DAGs: Co-Linear Chaining Extended.   Aligning sequencing reads on graph representations of genomes is an important\ningredient of pan-genomics. Such approaches typically find a set of local\nanchors that indicate plausible matches between substrings of a read to\nsubpaths of the graph. These anchor matches are then combined to form a\n(semi-local) alignment of the complete read on a subpath. Co-linear chaining is\nan algorithmically rigorous approach to combine the anchors. It is a well-known\napproach for the case of two sequences as inputs. Here we extend the approach\nso that one of the inputs can be a directed acyclic graph (DAGs), e.g. a\nsplicing graph in transcriptomics or a variant graph in pan-genomics.\nThis extension to DAGs turns out to have a tight connection to the minimum\npath cover problem, asking for a minimum-cardinality set of paths that cover\nall the nodes of a DAG. We study the case when the size $k$ of a minimum path\ncover is small, which is often the case in practice. First, we propose an\nalgorithm for finding a minimum path cover of a DAG $(V,E)$ in $O(k|E|\\log|V|)$\ntime, improving all known time-bounds when $k$ is small and the DAG is not too\ndense. Second, we introduce a general technique for extending dynamic\nprogramming (DP) algorithms from sequences to DAGs. This is enabled by our\nminimum path cover algorithm, and works by mimicking the DP algorithm for\nsequences on each path of the minimum path cover. This technique generally\nproduces algorithms that are slower than their counterparts on sequences only\nby a factor $k$. Our technique can be applied, for example, to the classical\nlongest increasing subsequence and longest common subsequence problems,\nextended to labeled DAGs. Finally, we apply this technique to the co-linear\nchaining problem. We also implemented the new co-linear chaining approach.\nExperiments on splicing graphs show that the new method is efficient also in\npractice.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The Diverse Club: The Integrative Core of Complex Networks.   A complex system can be represented and analyzed as a network, where nodes\nrepresent the units of the network and edges represent connections between\nthose units. For example, a brain network represents neurons as nodes and axons\nbetween neurons as edges. In many networks, some nodes have a\ndisproportionately high number of edges. These nodes also have many edges\nbetween each other, and are referred to as the rich club. In many different\nnetworks, the nodes of this club are assumed to support global network\nintegration. However, another set of nodes potentially exhibits a connectivity\nstructure that is more advantageous to global network integration. Here, in a\nmyriad of different biological and man-made networks, we discover the diverse\nclub--a set of nodes that have edges diversely distributed across the network.\nThe diverse club exhibits, to a greater extent than the rich club, properties\nconsistent with an integrative network function--these nodes are more highly\ninterconnected and their edges are more critical for efficient global\nintegration. Moreover, we present a generative evolutionary network model that\nproduces networks with a diverse club but not a rich club, thus demonstrating\nthat these two clubs potentially evolved via distinct selection pressures.\nGiven the variety of different networks that we analyzed--the c. elegans, the\nmacaque brain, the human brain, the United States power grid, and global air\ntraffic--the diverse club appears to be ubiquitous in complex networks. These\nresults warrant the distinction and analysis of two critical clubs of nodes in\nall complex systems.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "A Reassessment of Absolute Energies of the X-ray L Lines of Lanthanide Metals.   We introduce a new technique for determining x-ray fluorescence line energies\nand widths, and we present measurements made with this technique of 22 x-ray L\nlines from lanthanide-series elements. The technique uses arrays of\ntransition-edge sensors, microcalorimeters with high energy-resolving power\nthat simultaneously observe both calibrated x-ray standards and the x-ray\nemission lines under study. The uncertainty in absolute line energies is\ngenerally less than 0.4 eV in the energy range of 4.5 keV to 7.5 keV. Of the\nseventeen line energies of neodymium, samarium, and holmium, thirteen are found\nto be consistent with the available x-ray reference data measured after 1990;\nonly two of the four lines for which reference data predate 1980, however, are\nconsistent with our results. Five lines of terbium are measured with\nuncertainties that improve on those of existing data by factors of two or more.\nThese results eliminate a significant discrepancy between measured and\ncalculated x-ray line energies for the terbium Ll line (5.551 keV). The line\nwidths are also measured, with uncertainties of 0.6 eV or less on the\nfull-width at half-maximum in most cases. These measurements were made with an\narray of approximately one hundred superconducting x- ray microcalorimeters,\neach sensitive to an energy band from 1 keV to 8 keV. No energy-dispersive\nspectrometer has previously been used for absolute-energy estimation at this\nlevel of accuracy. Future spectrometers, with superior linearity and energy\nresolution, will allow us to improve on these results and expand the\nmeasurements to more elements and a wider range of line energies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Critical Points of Neural Networks: Analytical Forms and Landscape Properties.   Due to the success of deep learning to solving a variety of challenging\nmachine learning tasks, there is a rising interest in understanding loss\nfunctions for training neural networks from a theoretical aspect. Particularly,\nthe properties of critical points and the landscape around them are of\nimportance to determine the convergence performance of optimization algorithms.\nIn this paper, we provide full (necessary and sufficient) characterization of\nthe analytical forms for the critical points (as well as global minimizers) of\nthe square loss functions for various neural networks. We show that the\nanalytical forms of the critical points characterize the values of the\ncorresponding loss functions as well as the necessary and sufficient conditions\nto achieve global minimum. Furthermore, we exploit the analytical forms of the\ncritical points to characterize the landscape properties for the loss functions\nof these neural networks. One particular conclusion is that: The loss function\nof linear networks has no spurious local minimum, while the loss function of\none-hidden-layer nonlinear networks with ReLU activation function does have\nlocal minimum that is not global minimum.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Calderón-type inequalities for affine frames.   We prove sharp upper and lower bounds for generalized Calderón's sums\nassociated to frames on LCA groups generated by affine actions of cocompact\nsubgroup translations and general measurable families of automorphisms. The\nproof makes use of techniques of analysis on metric spaces, and relies on a\ncounting estimate of lattice points inside metric balls. We will deduce as\nspecial cases Calderón-type inequalities for families of expanding\nautomorphisms as well as for LCA-Gabor systems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Deep Learning: A Critical Appraisal.   Although deep learning has historical roots going back decades, neither the\nterm \"deep learning\" nor the approach was popular just over five years ago,\nwhen the field was reignited by papers such as Krizhevsky, Sutskever and\nHinton's now classic (2012) deep network model of Imagenet. What has the field\ndiscovered in the five subsequent years? Against a background of considerable\nprogress in areas such as speech recognition, image recognition, and game\nplaying, and considerable enthusiasm in the popular press, I present ten\nconcerns for deep learning, and suggest that deep learning must be supplemented\nby other techniques if we are to reach artificial general intelligence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On winning strategies for Banach-Mazur games.   We give topological and game theoretic definitions and theorems nec- essary\nfor defining a Banach-Mazur game, and apply these definitions to formalize the\ngame. We then state and prove two theorems which give necessary conditions for\nexistence of winning strategies for players in a Banach-Mazur game.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The role of the background in past and future X-ray missions.   Background has played an important role in X-ray missions, limiting the\nexploitation of science data in several and sometimes unexpected ways. In this\npresentation I review past X-ray missions focusing on some important lessons we\ncan learn from them. I then go on discussing prospects for overcoming\nbackground related limitations in future ones.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "A Cloud-based Service for Real-Time Performance Evaluation of NoSQL Databases.   We have created a cloud-based service that allows the end users to run tests\non multiple different databases to find which databases are most suitable for\ntheir project. From our research, we could not find another application that\nenables the user to test several databases to gauge the difference between\nthem. This application allows the user to choose which type of test to perform\nand which databases to target. The application also displays the results of\ndifferent tests that were run by other users previously. There is also a map to\nshow the location where all the tests are run to give the user an estimate of\nthe location. Unlike the orthodox static tests and reports conducted to\nevaluate NoSQL databases, we have created a web application to run and analyze\nthese tests in real time. This web application evaluates the performance of\nseveral NoSQL databases. The databases covered are MongoDB, DynamoDB, CouchDB,\nand Firebase. The web service is accessible from: nosqldb.nextproject.ca.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Efficient Kinematic Planning for Mobile Manipulators with Non-holonomic Constraints Using Optimal Control.   This work addresses the problem of kinematic trajectory planning for mobile\nmanipulators with non-holonomic constraints, and holonomic operational-space\ntracking constraints. We obtain whole-body trajectories and time-varying\nkinematic feedback controllers by solving a Constrained Sequential Linear\nQuadratic Optimal Control problem. The employed algorithm features high\nefficiency through a continuous-time formulation that benefits from adaptive\nstep-size integrators and through linear complexity in the number of\nintegration steps. In a first application example, we solve kinematic\ntrajectory planning problems for a 26 DoF wheeled robot. In a second example,\nwe apply Constrained SLQ to a real-world mobile manipulator in a\nreceding-horizon optimal control fashion, where we obtain optimal controllers\nand plans at rates up to 100 Hz.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "The placement of the head that maximizes predictability. An information theoretic approach.   The minimization of the length of syntactic dependencies is a\nwell-established principle of word order and the basis of a mathematical theory\nof word order. Here we complete that theory from the perspective of information\ntheory, adding a competing word order principle: the maximization of\npredictability of a target element. These two principles are in conflict: to\nmaximize the predictability of the head, the head should appear last, which\nmaximizes the costs with respect to dependency length minimization. The\nimplications of such a broad theoretical framework to understand the\noptimality, diversity and evolution of the six possible orderings of subject,\nobject and verb are reviewed.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "On the Importance of Correlations in Rational Choice: A Case for Non-Nashian Game Theory.   The Nash equilibrium paradigm, and Rational Choice Theory in general, rely on\nagents acting independently from each other. This note shows how this\nassumption is crucial in the definition of Rational Choice Theory. It explains\nhow a consistent Alternate Rational Choice Theory, as suggested by Jean-Pierre\nDupuy, can be built on the exact opposite assumption, and how it provides a\nviable account for alternate, actually observed behavior of rational agents\nthat is based on correlations between their decisions.\nThe end goal of this note is three-fold: (i) to motivate that the Perfect\nPrediction Equilibrium, implementing Dupuy's notion of projected time and\npreviously called \"projected equilibrium\", is a reasonable approach in certain\nreal situations and a meaningful complement to the Nash paradigm, (ii) to\nsummarize common misconceptions about this equilibrium, and (iii) to give a\nconcise motivation for future research on non-Nashian game theory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "PorePy: An Open-Source Simulation Tool for Flow and Transport in Deformable Fractured Rocks.   Fractures are ubiquitous in the subsurface and strongly affect flow and\ndeformation. The physical shape of the fractures, they are long and thin\nobjects, puts strong limitations on how the effect of this dynamics can be\nincorporated into standard reservoir simulation tools. This paper reports the\ndevelopment of an open-source software framework, termed PorePy, which is aimed\nat simulation of flow and transport in three-dimensional fractured reservoirs,\nas well as deformation of the reservoir due to shearing along fracture and\nfault planes. Starting from a description of fractures as polygons embedded in\na 3D domain, PorePy provides semi-automatic gridding to construct a\ndiscrete-fracture-matrix model, which forms the basis for subsequent\nsimulations. PorePy allows for flow and transport in all lower-dimensional\nobjects, including planes (2D) representing fractures, and lines (1D) and\npoints (0D), representing fracture intersections. Interaction between processes\nin neighboring domains of different dimension is implemented as a sequence of\ncouplings of objects one dimension apart. This readily allows for handling of\ncomplex fracture geometries compared to capabilities of existing software. In\naddition to flow and transport, PorePy provides models for rock mechanics,\nporo-elasticity and coupling with fracture deformation models. The software is\nfully open, and can serve as a framework for transparency and reproducibility\nof simulations. We describe the design principles of PorePy from a user\nperspective, with focus on possibilities within gridding, covered physical\nprocesses and available discretizations. The power of the framework is\nillustrated with two sets of simulations; involving respectively coupled flow\nand transport in a fractured porous medium, and low-pressure stimulation of a\ngeothermal reservoir.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Multifractal Analysis of Pulsar Timing Residuals: Assessment of Gravitational Wave Detection.   We introduce a pipeline including multifractal detrended cross-correlation\nanalysis (MF-DXA) modified by either singular value decomposition or the\nadaptive method to examine the statistical properties of the pulsar timing\nresidual ($PTR$) induced by a gravitational wave (GW) signal. We propose a new\nalgorithm, the so-called irregular-MF-DXA, to deal with irregular data\nsampling. Inspired by the quadrupolar nature of the spatial cross-correlation\nfunction of a gravitational wave background, a new cross-correlation function,\n$\\bar{\\sigma}_{\\times}$, derived from irregular-MF-DXA will be introduced. We\nshow that, this measure reveals the quadrupolar signature in the $PTRs$ induced\nby stochastic GWB. We propose four strategies based on the $y$-intercept of\nfluctuation functions, the generalized Hurst exponent, and the width of the\nsingularity spectrum to determine the dimensionless amplitude and power-law\nexponent of the characteristic strain spectrum as\n$\\mathcal{H}_c(f)\\sim\\mathcal{A}_{yr}(f/f_{yr})^{\\zeta}$ for stochastic GWB.\nUsing the value of Hurst exponent, one can clarify the type of GWs. We apply\nour pipeline to explore 20 millisecond pulsars observed by Parkes Pulsar Timing\nArray. The computed scaling exponents confirm that all data are classified into\na nonstationary class implying the universality feature. The value of the Hurst\nexponent is in the range $H\\in [0.56,0.87]$. The $q$-dependency of the\ngeneralized Hurst exponent demonstrates that the observed $PTRs$ have\nmultifractal behavior, and the source of this multifractality is mainly\nattributed to the correlation of data which is another universality of the\nobserved datasets. Multifractal analysis of available $PTRs$ datasets reveals\nan upper bound on the dimensionless amplitude of the GWB, $\\mathcal{A}_{yr}<\n2.0\\times 10^{-15}$.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Interesting Paths in the Mapper.   The Mapper produces a compact summary of high dimensional data as a\nsimplicial complex. We study the problem of quantifying the interestingness of\nsubpopulations in a Mapper, which appear as long paths, flares, or loops.\nFirst, we create a weighted directed graph G using the 1-skeleton of the\nMapper. We use the average values at the vertices of a target function to\ndirect edges (from low to high). The difference between the average values at\nvertices (high-low) is set as the edge's weight. Covariation of the remaining h\nfunctions (independent variables) is captured by a h-bit binary signature\nassigned to the edge. An interesting path in G is a directed path whose edges\nall have the same signature. We define the interestingness score of such a path\nas a sum of its edge weights multiplied by a nonlinear function of their ranks\nin the path.\nSecond, we study three optimization problems on this graph G. In the problem\nMax-IP, we seek an interesting path in G with the maximum interestingness\nscore. We show that Max-IP is NP-complete. For the special case when G is a\ndirected acyclic graph (DAG), we show that Max-IP can be solved in polynomial\ntime - in O(mnd_i) where d_i is the maximum indegree of a vertex in G.\nIn the more general problem IP, the goal is to find a collection of\nedge-disjoint interesting paths such that the overall sum of their\ninterestingness scores is maximized. We also study a variant of IP termed k-IP,\nwhere the goal is to identify a collection of edge-disjoint interesting paths\neach with k edges, and their total interestingness score is maximized. While\nk-IP can be solved in polynomial time for k <= 2, we show k-IP is NP-complete\nfor k >= 3 even when G is a DAG. We develop polynomial time heuristics for IP\nand k-IP on DAGs.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Random taste heterogeneity in discrete choice models: Flexible nonparametric finite mixture distributions.   This study proposes a mixed logit model with multivariate nonparametric\nfinite mixture distributions. The support of the distribution is specified as a\nhigh-dimensional grid over the coefficient space, with equal or unequal\nintervals between successive points along the same dimension; the location of\neach point on the grid and the probability mass at that point are model\nparameters that need to be estimated. The framework does not require the\nanalyst to specify the shape of the distribution prior to model estimation, but\ncan approximate any multivariate probability distribution function to any\narbitrary degree of accuracy. The grid with unequal intervals, in particular,\noffers greater flexibility than existing multivariate nonparametric\nspecifications, while requiring the estimation of a small number of additional\nparameters. An expectation maximization algorithm is developed for the\nestimation of these models. Multiple synthetic datasets and a case study on\ntravel mode choice behavior are used to demonstrate the value of the model\nframework and estimation algorithm. Compared to extant models that incorporate\nrandom taste heterogeneity through continuous mixture distributions, the\nproposed model provides better out-of-sample predictive ability. Findings\nreveal significant differences in willingness to pay measures between the\nproposed model and extant specifications. The case study further demonstrates\nthe ability of the proposed model to endogenously recover patterns of attribute\nnon-attendance and choice set formation.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Particular type of gap in the spectrum of multiband superconductors.   We show, that in contrast to the free electron model (standard BCS model), a\nparticular gap in the spectrum of multiband superconductors opens at some\ndistance from the Fermi energy, if conduction band is composed of hybridized\natomic orbitals of different symmetries. This gap has composite\nsuperconducting-hybridization origin, because it exists only if both the\nsuperconductivity and the hybridization between different kinds of orbitals are\npresent. So for many classes of superconductors with multiorbital structure\nsuch spectrum changes should take place. These particular changes in the\nspectrum at some distance from the Fermi level result in slow convergence of\nthe spectral weight of the optical conductivity even in quite conventional\nsuperconductors with isotropic s-wave pairing mechanism.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Characterising exo-ringsystems around fast-rotating stars using the Rossiter-McLaughlin effect.   Planetary rings produce a distinct shape distortion in transit lightcurves.\nHowever, to accurately model such lightcurves the observations need to cover\nthe entire transit, especially ingress and egress, as well as an out-of-transit\nbaseline. Such observations can be challenging for long period planets, where\nthe transits may last for over a day. Planetary rings will also impact the\nshape of absorption lines in the stellar spectrum, as the planet and rings\ncover different parts of the rotating star (the Rossiter-McLaughlin effect).\nThese line-profile distortions depend on the size, structure, opacity,\nobliquity and sky projected angle of the ring system. For slow rotating stars,\nthis mainly impacts the amplitude of the induced velocity shift, however, for\nfast rotating stars the large velocity gradient across the star allows the line\ndistortion to be resolved, enabling direct determination of the ring\nparameters. We demonstrate that by modeling these distortions we can recover\nring system parameters (sky-projected angle, obliquity and size) using only a\nsmall part of the transit. Substructure in the rings, e.g. gaps, can be\nrecovered if the width of the features ($\\delta W$) relative to the size of the\nstar is similar to the intrinsic velocity resolution (set by the width of the\nlocal stellar profile, $\\gamma$) relative to the stellar rotation velocity ($v$\nsin$i$, i.e. $\\delta W / R_* \\gtrsim v$sin$i$/$\\gamma$). This opens up a new\nway to study the ring systems around planets with long orbital periods, where\nobservations of the full transit, covering the ingress and egress, are not\nalways feasible.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "On the semigroup rank of a group.   For an arbitrary group $G$, it is shown that either the semigroup rank $G{\\rm\nrk}S$ equals the group rank $G{\\rm rk}G$, or $G{\\rm rk}S = G{\\rm rk}G+1$. This\nis the starting point for the rest of the article, where the semigroup rank for\ndiverse kinds of groups is analysed. The semigroup rank of relatively free\ngroups, for any variety of groups, is computed. For a finitely generated\nabelian group~$G$, it is proven that $G{\\rm rk}S = G{\\rm rk}G+1$ if and only if\n$G$ is torsion-free. In general, this is not true. Partial results are obtained\nin the nilpotent case. It is also proven that if $M$ is a connected closed\nsurface, then $(\\pi_1(M)){\\rm rk}S = (\\pi_1(M)){\\rm rk}G+1$ if and only if $M$\nis orientable.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A General Sequential Delay-Doppler Estimation Scheme for Sub-Nyquist Pulse-Doppler Radar.   Sequential estimation of the delay and Doppler parameters for sub-Nyquist\nradars by analog-to-information conversion (AIC) systems has received wide\nattention recently. However, the estimation methods reported are AIC-dependent\nand have poor performance for off-grid targets. This paper develops a general\nestimation scheme in the sense that it is applicable to all AICs regardless\nwhether the targets are on or off the grids. The proposed scheme estimates the\ndelay and Doppler parameters sequentially, in which the delay estimation is\nformulated into a beamspace direction-of- arrival problem and the Doppler\nestimation is translated into a line spectrum estimation problem. Then the\nwell-known spatial and temporal spectrum estimation techniques are used to\nprovide efficient and high-resolution estimates of the delay and Doppler\nparameters. In addition, sufficient conditions on the AIC to guarantee the\nsuccessful estimation of off-grid targets are provided, while the existing\nconditions are mostly related to the on-grid targets. Theoretical analyses and\nnumerical experiments show the effectiveness and the correctness of the\nproposed scheme.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Accelerating Prototype-Based Drug Discovery using Conditional Diversity Networks.   Designing a new drug is a lengthy and expensive process. As the space of\npotential molecules is very large (10^23-10^60), a common technique during drug\ndiscovery is to start from a molecule which already has some of the desired\nproperties. An interdisciplinary team of scientists generates hypothesis about\nthe required changes to the prototype. In this work, we develop an algorithmic\nunsupervised-approach that automatically generates potential drug molecules\ngiven a prototype drug. We show that the molecules generated by the system are\nvalid molecules and significantly different from the prototype drug. Out of the\ncompounds generated by the system, we identified 35 FDA-approved drugs. As an\nexample, our system generated Isoniazid - one of the main drugs for\nTuberculosis. The system is currently being deployed for use in collaboration\nwith pharmaceutical companies to further analyze the additional generated\nmolecules.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "A Sparse Completely Positive Relaxation of the Modularity Maximization for Community Detection.   In this paper, we consider the community detection problem under either the\nstochastic block model (SBM) assumption or the degree-correlated stochastic\nblock model (DCSBM) assumption. The modularity maximization formulation for the\ncommunity detection problem is NP-hard in general. In this paper, we propose a\nsparse and low-rank completely positive relaxation for the modularity\nmaximization problem, we then develop an efficient row-by-row (RBR) type block\ncoordinate descent (BCD) algorithm to solve the relaxation and prove an\n$\\mathcal{O}(1/\\sqrt{N})$ convergence rate to a stationary point where $N$ is\nthe number of iterations. A fast rounding scheme is constructed to retrieve the\ncommunity structure from the solution. Non-asymptotic high probability bounds\non the misclassification rate are established to justify our approach. We\nfurther develop an asynchronous parallel RBR algorithm to speed up the\nconvergence. Extensive numerical experiments on both synthetic and real world\nnetworks show that the proposed approach enjoys advantages in both clustering\naccuracy and numerical efficiency. Our numerical results indicate that the\nnewly proposed method is a quite competitive alternative for community\ndetection on sparse networks with over 50 million nodes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Statistical Analysis on Bangla Newspaper Data to Extract Trending Topic and Visualize Its Change Over Time.   Trending topic of newspapers is an indicator to understand the situation of a\ncountry and also a way to evaluate the particular newspaper. This paper\nrepresents a model describing few techniques to select trending topics from\nBangla Newspaper. Topics that are discussed more frequently than other in\nBangla newspaper will be marked and how a very famous topic loses its\nimportance with the change of time and another topic takes its place will be\ndemonstrated. Data from two popular Bangla Newspaper with date and time were\ncollected. Statistical analysis was performed after on these data after\npreprocessing. Popular and most used keywords were extracted from the stream of\nBangla keyword with this analysis. This model can also cluster category wise\nnews trend or a list of news trend in daily or weekly basis with enough data. A\npattern can be found on their news trend too. Comparison among past news trend\nof Bangla newspapers will give a visualization of the situation of Bangladesh.\nThis visualization will be helpful to predict future trending topics of Bangla\nNewspaper.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Replay spoofing detection system for automatic speaker verification using multi-task learning of noise classes.   In this paper, we propose a replay attack spoofing detection system for\nautomatic speaker verification using multitask learning of noise classes. We\ndefine the noise that is caused by the replay attack as replay noise. We\nexplore the effectiveness of training a deep neural network simultaneously for\nreplay attack spoofing detection and replay noise classification. The\nmulti-task learning includes classifying the noise of playback devices,\nrecording environments, and recording devices as well as the spoofing\ndetection. Each of the three types of the noise classes also includes a genuine\nclass. The experiment results on the ASVspoof2017 datasets demonstrate that the\nperformance of our proposed system is improved by 30% relatively on the\nevaluation set.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "PHAST: Protein-like heteropolymer analysis by statistical thermodynamics.   PHAST is a software package written in standard Fortran, with MPI and CUDA\nextensions, able to efficiently perform parallel multicanonical Monte Carlo\nsimulations of single or multiple heteropolymeric chains, as coarse-grained\nmodels for proteins. The outcome data can be straightforwardly analyzed within\nits microcanonical Statistical Thermodynamics module, which allows for\ncomputing the entropy, caloric curve, specific heat and free energies. As a\ncase study, we investigate the aggregation of heteropolymers bioinspired on\n$A\\beta_{25-33}$ fragments and their cross-seeding with $IAPP_{20-29}$\nisoforms. Excellent parallel scaling is observed, even under numerically\ndifficult first-order like phase transitions, which are properly described by\nthe built-in fully reconfigurable force fields. Still, the package is free and\nopen source, this shall motivate users to readily adapt it to specific\npurposes.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Recent implementations, applications, and extensions of the Locally Optimal Block Preconditioned Conjugate Gradient method (LOBPCG).   Since introduction [A. Knyazev, Toward the optimal preconditioned\neigensolver: Locally optimal block preconditioned conjugate gradient method,\nSISC (2001) DOI:10.1137/S1064827500366124] and efficient parallel\nimplementation [A. Knyazev et al., Block locally optimal preconditioned\neigenvalue xolvers (BLOPEX) in HYPRE and PETSc, SISC (2007)\nDOI:10.1137/060661624], LOBPCG has been used is a wide range of applications in\nmechanics, material sciences, and data sciences. We review its recent\nimplementations and applications, as well as extensions of the local optimality\nidea beyond standard eigenvalue problems.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Computing Nonvacuous Generalization Bounds for Deep (Stochastic) Neural Networks with Many More Parameters than Training Data.   One of the defining properties of deep learning is that models are chosen to\nhave many more parameters than available training data. In light of this\ncapacity for overfitting, it is remarkable that simple algorithms like SGD\nreliably return solutions with low test error. One roadblock to explaining\nthese phenomena in terms of implicit regularization, structural properties of\nthe solution, and/or easiness of the data is that many learning bounds are\nquantitatively vacuous when applied to networks learned by SGD in this \"deep\nlearning\" regime. Logically, in order to explain generalization, we need\nnonvacuous bounds. We return to an idea by Langford and Caruana (2001), who\nused PAC-Bayes bounds to compute nonvacuous numerical bounds on generalization\nerror for stochastic two-layer two-hidden-unit neural networks via a\nsensitivity analysis. By optimizing the PAC-Bayes bound directly, we are able\nto extend their approach and obtain nonvacuous generalization bounds for deep\nstochastic neural network classifiers with millions of parameters trained on\nonly tens of thousands of examples. We connect our findings to recent and old\nwork on flat minima and MDL-based explanations of generalization.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Transition rates and radiative lifetimes of Ca I.   We tabulate spontaneous emission rates for all possible 811\nelectric-dipole-allowed transitions between the 75 lowest-energy states of Ca\nI. These involve the $4sns$ ($n=4-8$), $4snp$ ($n=4-7$), $4snd$ ($n=3-6$),\n$4snf$ ($n=4-6$), $4p^2$, and $3d4p$ electronic configurations. We compile the\ntransition rates by carrying out ab initio relativistic calculations using the\ncombined method of configuration interaction and many-body perturbation theory.\nThe results are compared to the available literature values. The tabulated\nrates can be useful in various applications, such as optimizing laser cooling\nin magneto-optical traps, estimating various systematic effects in optical\nclocks and evaluating static or dynamic polarizabilities and long-range\natom-atom interaction coefficients and related atomic properties.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Convergence of Stochastic Approximation Monte Carlo and modified Wang-Landau algorithms: Tests for the Ising model.   We investigate the behavior of the deviation of the estimator for the density\nof states (DOS) with respect to the exact solution in the course of Wang-Landau\nand Stochastic Approximation Monte Carlo (SAMC) simulations of the\ntwo-dimensional Ising model. We find that the deviation saturates in the\nWang-Landau case. This can be cured by adjusting the refinement scheme. To this\nend, the 1/t-modification of the Wang-Landau algorithm has been suggested. A\nsimilar choice of refinement scheme is employed in the SAMC algorithm. The\nconvergence behavior of all three algorithms is examined. It turns out that the\nconvergence of the SAMC algorithm is very sensitive to the onset of the\nrefinement. Finally, the internal energy and specific heat of the Ising model\nare calculated from the SAMC DOS and compared to exact values.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Nonlinear dynamics of polar regions in paraelectric phase of (Ba1-x,Srx)TiO3 ceramics.   The dynamic dielectric nonlinearity of barium strontium titanate\n(Ba1-x,Srx)TiO3 ceramics is investigated in their paraelectric phase. With the\ngoal to contribute to the identification of the mechanisms that govern the\ndielectric nonlinearity in this family, we analyze the amplitude and the phase\nangles of the first and the third harmonics of polarization. Our study shows\nthat an interpretation of the field-dependent polarization in paraelectric\n(Ba1-x,Srx)TiO3 ceramics in terms of the Rayleigh-type dynamics is inadequate\nfor our samples and that their nonlinear response rather resembles that\nobserved in canonical relaxor Pb(Mg1/3Nb2/3)O3.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Investigating early-type galaxy evolution with a multiwavelength approach. II. The UV structure of 11 galaxies with Swift-UVOT.   GALEX detected a significant fraction of early-type galaxies showing Far-UV\nbright structures. These features suggest the occurrence of recent star\nformation episodes. We aim at understanding their evolutionary path[s] and the\nmechanisms at the origin of their UV-bright structures. We investigate with a\nmulti-lambda approach 11 early-types selected because of their nearly passive\nstage of evolution in the nuclear region. The paper, second of a series,\nfocuses on the comparison between UV features detected by Swift-UVOT, tracing\nrecent star formation, and the galaxy optical structure mapping older stellar\npopulations. We performed their UV surface photometry and used BVRI photometry\nfrom other sources. Our integrated magnitudes have been analyzed and compared\nwith corresponding values in the literature. We characterize the overall galaxy\nstructure best fitting the UV and optical luminosity profiles using a single\nSersic law. NGC 1366, NGC 1426, NGC 3818, NGC 3962 and NGC 7192 show\nfeatureless luminosity profiles. Excluding NGC 1366 which has a clear edge-on\ndisk , n~1-2, and NGC 3818, the remaining three have Sersic's indices n~3-4 in\noptical and a lower index in the UV. Bright ring/arm-like structures are\nrevealed by UV images and luminosity profiles of NGC 1415, NGC 1533, NGC 1543,\nNGC 2685, NGC 2974 and IC 2006. The ring/arm-like structures are different from\ngalaxy to galaxy. Sersic indices of UV profiles for those galaxies are in the\nrange n=1.5-3 both in S0s and in Es. In our sample optical Sersic indices are\nusually larger than the UV ones. (M2-V) color profiles are bluer in\nring/arm-like structures with respect to the galaxy body. The lower values of\nSersic's indices in the UV bands with respect to optical ones, suggesting the\npresence of a disk, point out that the role of the dissipation cannot be\nneglected in recent evolutionary phases of these early-type galaxies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Phenotypes of Fluctuating Flow: Development of Distribution Networks in Biology and the Trade-off between Efficiency, Cost, and Resilience.   Complex distribution networks are pervasive in biology. Examples include\nnutrient transport in the slime mold $Physarum$ $polycephalum$ as well as\nmammalian and plant venation. Adaptive rules are believed to guide development\nof these networks and lead to a reticulate, hierarchically nested topology that\nis both efficient and resilient against perturbations. However, as of yet no\nmechanism is known that can generate such networks on all scales. We show how\nhierarchically organized reticulation can be generated and maintained through\nspatially collective load fluctuations on a particular length scale. We\ndemonstrate that the resulting network topologies represent a trade-off between\noptimizing power dissipation, construction cost, and damage robustness and\nidentify the Pareto-efficient front that evolution is expected to favor and\nselect for. We show that the typical fluctuation length scale controls the\nposition of the networks on the Pareto front and thus on the spectrum of\nvenation phenotypes. We compare the Pareto archetypes predicted by our model\nwith examples of real leaf networks.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Non-linear motor control by local learning in spiking neural networks.   Learning weights in a spiking neural network with hidden neurons, using\nlocal, stable and online rules, to control non-linear body dynamics is an open\nproblem. Here, we employ a supervised scheme, Feedback-based Online Local\nLearning Of Weights (FOLLOW), to train a network of heterogeneous spiking\nneurons with hidden layers, to control a two-link arm so as to reproduce a\ndesired state trajectory. The network first learns an inverse model of the\nnon-linear dynamics, i.e. from state trajectory as input to the network, it\nlearns to infer the continuous-time command that produced the trajectory.\nConnection weights are adjusted via a local plasticity rule that involves\npre-synaptic firing and post-synaptic feedback of the error in the inferred\ncommand. We choose a network architecture, termed differential feedforward,\nthat gives the lowest test error from different feedforward and recurrent\narchitectures. The learned inverse model is then used to generate a\ncontinuous-time motor command to control the arm, given a desired trajectory.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Emotion Intensities in Tweets.   This paper examines the task of detecting intensity of emotion from text. We\ncreate the first datasets of tweets annotated for anger, fear, joy, and sadness\nintensities. We use a technique called best--worst scaling (BWS) that improves\nannotation consistency and obtains reliable fine-grained scores. We show that\nemotion-word hashtags often impact emotion intensity, usually conveying a more\nintense emotion. Finally, we create a benchmark regression system and conduct\nexperiments to determine: which features are useful for detecting emotion\nintensity, and, the extent to which two emotions are similar in terms of how\nthey manifest in language.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Sample, computation vs storage tradeoffs for classification using tensor subspace models.   In this paper, we exhibit the tradeoffs between the (training) sample,\ncomputation and storage complexity for the problem of supervised classification\nusing signal subspace estimation. Our main tool is the use of tensor subspaces,\ni.e. subspaces with a Kronecker structure, for embedding the data into lower\ndimensions. Among the subspaces with a Kronecker structure, we show that using\nsubspaces with a hierarchical structure for representing data leads to improved\ntradeoffs. One of the main reasons for the improvement is that embedding data\ninto these hierarchical Kronecker structured subspaces prevents overfitting at\nhigher latent dimensions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "RoboJam: A Musical Mixture Density Network for Collaborative Touchscreen Interaction.   RoboJam is a machine-learning system for generating music that assists users\nof a touchscreen music app by performing responses to their short\nimprovisations. This system uses a recurrent artificial neural network to\ngenerate sequences of touchscreen interactions and absolute timings, rather\nthan high-level musical notes. To accomplish this, RoboJam's network uses a\nmixture density layer to predict appropriate touch interaction locations in\nspace and time. In this paper, we describe the design and implementation of\nRoboJam's network and how it has been integrated into a touchscreen music app.\nA preliminary evaluation analyses the system in terms of training, musical\ngeneration and user interaction.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "In silico optimization of critical currents in superconductors.   For many technological applications of superconductors the performance of a\nmaterial is determined by the highest current it can carry losslessly - the\ncritical current. In turn, the critical current can be controlled by adding\nnon-superconducting defects in the superconductor matrix. Here we report on\nsystematic comparison of different local and global optimization strategies to\npredict optimal structures of pinning centers leading to the highest possible\ncritical currents. We demonstrate performance of these methods for a\nsuperconductor with randomly placed spherical, elliptical, and columnar\ndefects.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "System of unbiased representatives for a collection of bicolorings.   Let $\\mathcal{B}$ denote a set of bicolorings of $[n]$, where each bicoloring\nis a mapping of the points in $[n]$ to $\\{-1,+1\\}$.\nFor each $B \\in \\mathcal{B}$, let $Y_B=(B(1),\\ldots,B(n))$.\nFor each $A \\subseteq [n]$, let $X_A \\in \\{0,1\\}^n$ denote the incidence\nvector of $A$.\nA non-empty set $A$ is said to be an `unbiased representative' for a\nbicoloring $B \\in \\mathcal{B}$ if $\\left\\langle X_A,Y_B\\right\\rangle =0$.\nGiven a set $\\mathcal{B}$ of bicolorings, we study the minimum cardinality of\na family $\\mathcal{A}$ consisting of subsets of $[n]$ such that every\nbicoloring in $\\mathcal{B}$ has an unbiased representative in $\\mathcal{A}$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Tangent: Automatic Differentiation Using Source Code Transformation in Python.   Automatic differentiation (AD) is an essential primitive for machine learning\nprogramming systems. Tangent is a new library that performs AD using source\ncode transformation (SCT) in Python. It takes numeric functions written in a\nsyntactic subset of Python and NumPy as input, and generates new Python\nfunctions which calculate a derivative. This approach to automatic\ndifferentiation is different from existing packages popular in machine\nlearning, such as TensorFlow and Autograd. Advantages are that Tangent\ngenerates gradient code in Python which is readable by the user, easy to\nunderstand and debug, and has no runtime overhead. Tangent also introduces\nabstractions for easily injecting logic into the generated gradient code,\nfurther improving usability.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Why Abeta42 Is Much More Toxic Than Abeta40.   Amyloid precursor with 770 amino acids dimerizes and aggregates, as do its c\nterminal 99 amino acids and amyloid 40,42 amino acids fragments. The titled\nquestion has been discussed extensively, and here it is addressed further using\nthermodynamic scaling theory to analyze mutational trends in structural factors\nand kinetics. Special attention is given to Family Alzheimer's Disease\nmutations outside amyloid 42. The scaling analysis is connected to extensive\ndocking simulations which included membranes, thereby confirming their results\nand extending them to Amyloid precursor.",
        "labels": 0,
        "Physics": 1,
        "is_Physics": 0
    },
    {
        "text": "ACVAE-VC: Non-parallel many-to-many voice conversion with auxiliary classifier variational autoencoder.   This paper proposes a non-parallel many-to-many voice conversion (VC) method\nusing a variant of the conditional variational autoencoder (VAE) called an\nauxiliary classifier VAE (ACVAE). The proposed method has three key features.\nFirst, it adopts fully convolutional architectures to construct the encoder and\ndecoder networks so that the networks can learn conversion rules that capture\ntime dependencies in the acoustic feature sequences of source and target\nspeech. Second, it uses an information-theoretic regularization for the model\ntraining to ensure that the information in the attribute class label will not\nbe lost in the conversion process. With regular CVAEs, the encoder and decoder\nare free to ignore the attribute class label input. This can be problematic\nsince in such a situation, the attribute class label will have little effect on\ncontrolling the voice characteristics of input speech at test time. Such\nsituations can be avoided by introducing an auxiliary classifier and training\nthe encoder and decoder so that the attribute classes of the decoder outputs\nare correctly predicted by the classifier. Third, it avoids producing\nbuzzy-sounding speech at test time by simply transplanting the spectral details\nof the input speech into its converted version. Subjective evaluation\nexperiments revealed that this simple method worked reasonably well in a\nnon-parallel many-to-many speaker identity conversion task.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Predicting Demographics of High-Resolution Geographies with Geotagged Tweets.   In this paper, we consider the problem of predicting demographics of\ngeographic units given geotagged Tweets that are composed within these units.\nTraditional survey methods that offer demographics estimates are usually\nlimited in terms of geographic resolution, geographic boundaries, and time\nintervals. Thus, it would be highly useful to develop computational methods\nthat can complement traditional survey methods by offering demographics\nestimates at finer geographic resolutions, with flexible geographic boundaries\n(i.e. not confined to administrative boundaries), and at different time\nintervals. While prior work has focused on predicting demographics and health\nstatistics at relatively coarse geographic resolutions such as the county-level\nor state-level, we introduce an approach to predict demographics at finer\ngeographic resolutions such as the blockgroup-level. For the task of predicting\ngender and race/ethnicity counts at the blockgroup-level, an approach adapted\nfrom prior work to our problem achieves an average correlation of 0.389\n(gender) and 0.569 (race) on a held-out test dataset. Our approach outperforms\nthis prior approach with an average correlation of 0.671 (gender) and 0.692\n(race).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Basin stability for chimera states.   Chimera states, namely complex spatiotemporal patterns that consist of\ncoexisting domains of spatially coherent and incoherent dynamics, are\ninvestigated in a network of coupled identical oscillators. These intriguing\nspatiotemporal patterns were first reported in nonlocally coupled phase\noscillators, and it was shown that such mixed type behavior occurs only for\nspecific initial conditions in nonlocally and globally coupled networks. The\ninfluence of initial conditions on chimera states has remained a fundamental\nproblem since their discovery. In this report, we investigate the robustness of\nchimera states together with incoherent and coherent states in dependence on\nthe initial conditions. For this, we use the basin stability method which is\nrelated to the volume of the basin of attraction, and we consider nonlocally\nand globally coupled time-delayed Mackey-Glass oscillators as example.\nPreviously, it was shown that the existence of chimera states can be\ncharacterized by mean phase velocity and a statistical measure, such as the\nstrength of incoherence, by using well prepared initial conditions. Here we\nshow further how the coexistence of different dynamical states can be\nidentified and quantified by means of the basin stability measure over a wide\nrange of the parameter space.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Sparse geometries handling in lattice-Boltzmann method implementation for graphic processors.   We describe a high-performance implementation of the lattice-Boltzmann method\n(LBM) for sparse geometries on graphic processors. In our implementation we\ncover the whole geometry with a uniform mesh of small tiles and carry out\ncalculations for each tile independently with a proper data synchronization at\ntile edges. For this method we provide both the theoretical analysis of\ncomplexity and the results for real implementations for 2D and 3D geometries.\nBased on the theoretical model, we show that tiles offer significantly smaller\nbandwidth overhead than solutions based on indirect addressing. For\n2-dimensional lattice arrangements a reduction of memory usage is also\npossible, though at the cost of diminished performance. We reached the\nperformance of 682 MLUPS on GTX Titan (72\\% of peak theoretical memory\nbandwidth) for D3Q19 lattice arrangement and double precision data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Improving Massive MIMO Belief Propagation Detector with Deep Neural Network.   In this paper, deep neural network (DNN) is utilized to improve the belief\npropagation (BP) detection for massive multiple-input multiple-output (MIMO)\nsystems. A neural network architecture suitable for detection task is firstly\nintroduced by unfolding BP algorithms. DNN MIMO detectors are then proposed\nbased on two modified BP detectors, damped BP and max-sum BP. The correction\nfactors in these algorithms are optimized through deep learning techniques,\naiming at improved detection performance. Numerical results are presented to\ndemonstrate the performance of the DNN detectors in comparison with various BP\nmodifications. The neural network is trained once and can be used for multiple\nonline detections. The results show that, compared to other state-of-the-art\ndetectors, the DNN detectors can achieve lower bit error rate (BER) with\nimproved robustness against various antenna configurations and channel\nconditions at the same level of complexity.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Thresholds for hanger slackening and cable shortening in the Melan equation for suspension bridges.   The Melan equation for suspension bridges is derived by assuming small\ndisplacements of the deck and inextensible hangers. We determine the thresholds\nfor the validity of the Melan equation when the hangers slacken, thereby\nviolating the inextensibility assumption. To this end, we preliminarily study\nthe possible shortening of the cables: it turns out that there is a striking\ndifference between even and odd vibrating modes since the former never shorten\nthe cables. These problems are studied both on beams and plates.",
        "labels": 1,
        "Physics": 0,
        "is_Physics": 1
    },
    {
        "text": "Poisson brackets with prescribed family of functions in involution.   It is well known that functions in involution with respect to Poisson\nbrackets have a privileged role in the theory of completely integrable systems.\nFinding functionally independent functions in involution with a given function\n$h$ on a Poisson manifold is a fundamental problem of this theory and is very\nuseful for the explicit integration of the equations of motion defined by $h$.\nIn this paper, we present our results on the study of the inverse, so to speak,\nproblem. By developing a technique analogous to that presented in P. Damianou\nand F. Petalidou, Poisson brackets with prescribed Casimirs, Canad. J. Math.,\n2012, vol. 64, 991-1018, for the establishment of Poisson brackets with\nprescribed Casimir invariants, we construct an algorithm which yields Poisson\nbrackets having a given family of functions in involution. Our approach allows\nus to deal with bi-Hamiltonian structures constructively and therefore allows\nus to also deal with the completely integrable systems that arise in such a\nframework.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Independence in generic incidence structures.   We study the theory $T_{m,n}$ of existentially closed incidence structures\nomitting the complete incidence structure $K_{m,n}$, which can also be viewed\nas existentially closed $K_{m,n}$-free bipartite graphs. In the case $m = n =\n2$, this is the theory of existentially closed projective planes. We give an\n$\\forall\\exists$-axiomatization of $T_{m,n}$, show that $T_{m,n}$ does not have\na countable saturated model when $m,n\\geq 2$, and show that the existence of a\nprime model for $T_{2,2}$ is equivalent to a longstanding open question about\nfinite projective planes. Finally, we analyze model theoretic notions of\ncomplexity for $T_{m,n}$. We show that $T_{m,n}$ is NSOP$_1$, but not simple\nwhen $m,n\\geq 2$, and we show that $T_{m,n}$ has weak elimination of\nimaginaries but not full elimination of imaginaries. These results rely on\ncombinatorial characterizations of various notions of independence, including\nalgebraic independence, Kim independence, and forking independence.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Using MRI Cell Tracking to Monitor Immune Cell Recruitment in Response to a Peptide-Based Cancer Vaccine.   Purpose: MRI cell tracking can be used to monitor immune cells involved in\nthe immunotherapy response, providing insight into the mechanism of action,\ntemporal progression of tumour growth and individual potency of therapies. To\nevaluate whether MRI could be used to track immune cell populations in response\nto immunotherapy, CD8+ cytotoxic T cells (CTLs), CD4+CD25+FoxP3+ regulatory T\ncells (Tregs) and myeloid derived suppressor cells (MDSCs) were labelled with\nsuperparamagnetic iron oxide (SPIO) particles.\nMethods: SPIO-labelled cells were injected into mice (one cell type/mouse)\nimplanted with an HPV-based cervical cancer model. Half of these mice were also\nvaccinated with DepoVaxTM, a lipid-based vaccine platform that was developed to\nenhance the potency of peptide-based vaccines.\nResults: MRI visualization of CTLs, Tregs and MDSCs was apparent 24 hours\npost-injection, with hypointensities due to iron labelled cells clearing\napproximately 72 hours post-injection. Vaccination resulted in increased\nrecruitment of CTLs and decreased recruitment of MDSCs and Tregs to the tumour.\nWe also found that MDSC and Treg recruitment was positively correlated with\nfinal tumour volume.\nConclusion: This type of analysis can be used to non-invasively study changes\nin immune cell recruitment in individual mice over time, potentially allowing\nimproved application and combination of immunotherapies.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Towards Detection of Exoplanetary Rings Via Transit Photometry: Methodology and a Possible Candidate.   Detection of a planetary ring of exoplanets remains as one of the most\nattractive but challenging goals in the field. We present a methodology of a\nsystematic search for exoplanetary rings via transit photometry of long-period\nplanets. The methodology relies on a precise integration scheme we develop to\ncompute a transit light curve of a ringed planet. We apply the methodology to\n89 long-period planet candidates from the Kepler data so as to estimate, and/or\nset upper limits on, the parameters of possible rings. While a majority of our\nsamples do not have a sufficiently good signal-to-noise ratio for meaningful\nconstraints on ring parameters, we find that six systems with a higher\nsignal-to-noise ratio are inconsistent with the presence of a ring larger than\n1.5 times the planetary radius assuming a grazing orbit and a tilted ring.\nFurthermore, we identify five preliminary candidate systems whose light curves\nexhibit ring-like features. After removing four false positives due to the\ncontamination from nearby stars, we identify KIC 10403228 as a reasonable\ncandidate for a ringed planet. A systematic parameter fit of its light curve\nwith a ringed planet model indicates two possible solutions corresponding to a\nSaturn-like planet with a tilted ring. There also remain other two possible\nscenarios accounting for the data; a circumstellar disk and a hierarchical\ntriple. Due to large uncertain factors, we cannot choose one specific model\namong the three.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Thermoregulation in mice, rats and humans: An insight into the evolution of human hairlessness.   The thermoregulation system in animals removes body heat in hot temperatures\nand retains body heat in cold temperatures. The better the animal removes heat,\nthe worse the animal retains heat and visa versa. It is the balance between\nthese two conflicting goals that determines the mammal's size, heart rate and\namount of hair. The rat's loss of tail hair and human's loss of its body hair\nare responses to these conflicting thermoregulation needs as these animals\nevolved to larger size over time.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Gamma-Ray Emission from Arp 220: Indications of an Active Galactic Nucleus.   Extragalactic cosmic ray populations are important diagnostic tools for\ntracking the distribution of energy in nuclei and for distinguishing between\nactivity powered by star formation versus active galactic nuclei (AGNs). Here,\nwe compare different diagnostics of the cosmic ray populations of the nuclei of\nArp 220 based on radio synchrotron observations and the recent gamma-ray\ndetection. We find the gamma-ray and radio emission to be incompatible; a joint\nsolution requires at minimum a factor of 4 - 8 times more energy coming from\nsupernovae and a factor of 40 - 70 more mass in molecular gas than is observed.\nWe conclude that this excess of gamma-ray flux in comparison to all other\ndiagnostics of star-forming activity indicates that there is an AGN present\nthat is providing the extra cosmic rays, likely in the western nucleus.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Results from the first cryogenic NaI detector for the COSINUS project.   Recently there is a flourishing and notable interest in the crystalline\nscintillator material sodium iodide (NaI) as target for direct dark matter\nsearches. This is mainly driven by the long-reigning contradicting situation in\nthe dark matter sector: the positive evidence for the detection of a dark\nmatter modulation signal claimed by the DAMA/LIBRA collaboration is (under\nso-called standard assumptions) inconsistent with the null-results reported by\nmost of the other direct dark matter experiments. We present the results of a\nfirst prototype detector using a new experimental approach in comparison to\n\\textit{conventional} single-channel NaI scintillation light detectors: a NaI\ncrystal operated as a scintillating calorimeter at milli-Kelvin temperatures\nsimultaneously providing a phonon (heat) plus scintillation light signal and\nparticle discrimination on an event-by-event basis. We evaluate energy\nresolution, energy threshold and further performance parameters of this\nprototype detector developed within the COSINUS R&D project.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Asymptotic Analysis of Plausible Tree Hash Modes for SHA-3.   Discussions about the choice of a tree hash mode of operation for a\nstandardization have recently been undertaken. It appears that a single tree\nmode cannot address adequately all possible uses and specifications of a\nsystem. In this paper, we review the tree modes which have been proposed, we\ndiscuss their problems and propose remedies. We make the reasonable assumption\nthat communicating systems have different specifications and that software\napplications are of different types (securing stored content or live-streamed\ncontent). Finally, we propose new modes of operation that address the resource\nusage problem for the three most representative categories of devices and we\nanalyse their asymptotic behavior.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Exact lowest-Landau-level solutions for vortex precession in Bose-Einstein condensates.   The Lowest Landau Level (LLL) equation emerges as an accurate approximation\nfor a class of dynamical regimes of Bose-Einstein Condensates (BEC) in\ntwo-dimensional isotropic harmonic traps in the limit of weak interactions.\nBuilding on recent developments in the field of spatially confined extended\nHamiltonian systems, we find a fully nonlinear solution of this equation\nrepresenting periodically modulated precession of a single vortex. Motions of\nthis type have been previously seen in numerical simulations and experiments at\nmoderately weak coupling. Our work provides the first controlled analytic\nprediction for trajectories of a single vortex, suggests new targets for\nexperiments, and opens up the prospect of finding analytic multi-vortex\nsolutions.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Measure-geometric Laplacians for discrete distributions.   In 2002 Freiberg and Zähle introduced and developed a harmonic calculus for\nmeasure-geometric Laplacians associated to continuous distributions. We show\ntheir theory can be extended to encompass distributions with finite support and\ngive a matrix representation for the resulting operators. In the case of a\nuniform discrete distribution we make use of this matrix representation to\nexplicitly determine the eigenvalues and the eigenfunctions of the associated\nLaplacian.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Production of 82Se enriched Zinc Selenide (ZnSe) crystals for the study of neutrinoless double beta decay.   High purity Zinc Selenide (ZnSe) crystals are produced starting from\nelemental Zn and Se to be used for the search of the neutrinoless double beta\ndecay (0{\\nu}DBD) of 82Se. In order to increase the number of emitting\nnuclides, enriched 82Se is used. Dedicated production lines for the synthesis\nand conditioning of the Zn82Se powder in order to make it suitable for crystal\ngrowth were assembled compliant with radio-purity constraints specific to rare\nevent physics experiments. Besides routine check of impurities concentration,\nhigh sensitivity measurements are made for radio-isotope concentrations in raw\nmaterials, reactants, consumables, ancillaries and intermediary products used\nfor ZnSe crystals production. Indications are given on the crystals perfection\nand how it is achieved. Since very expensive isotopically enriched material\n(82Se) is used, a special attention is given for acquiring the maximum yield in\nthe mass balance of all production stages. Production and certification\nprotocols are presented and resulting ready-to-use Zn82Se crystals are\ndescribed.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Differential Forms, Linked Fields and the $u$-Invariant.   We associate an Albert form to any pair of cyclic algebras of prime degree\n$p$ over a field $F$ with $\\operatorname{char}(F)=p$ which coincides with the\nclassical Albert form when $p=2$. We prove that if every Albert form is\nisotropic then $H^4(F)=0$. As a result, we obtain that if $F$ is a linked field\nwith $\\operatorname{char}(F)=2$ then its $u$-invariant is either $0,2,4$ or\n$8$.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Infrared Flares from M Dwarfs: a Hinderance to Future Transiting Exoplanet Studies.   Many current and future exoplanet missions are pushing to infrared (IR)\nwavelengths where the flux contrast between the planet and star is more\nfavorable (Deming et al. 2009), and the impact of stellar magnetic activity is\ndecreased. Indeed, a recent analysis of starspots and faculae found these forms\nof stellar activity do not substantially impact the transit signatures or\nscience potential for FGKM stars with JWST (Zellem et al. 2017). However, this\nis not true in the case of flares, which I demonstrate can be a hinderance to\ntransit studies in this note.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Self-organization and the Maximum Empower Principle in the Framework of max-plus Algebra.   Self-organization is a process where order of a whole system arises out of\nlocal interactions between small components of a system.\nEmergy, defined as the amount of (solar) energy used to make a product or a\nservice, is becoming an important ecological indicator. To explain observed\nself-organization of systems by emergy the Maximum Empower Principle (MEP) was\nproposed initially without a mathematical formulation.\nEmergy analysis is based on four rules called emergy algebra. Most of emergy\ncomputations in steady state are in fact approximate results, which rely on\nlinear algebra. In such a context, a mathematical formulation of the MEP has\nbeen proposed by Giannantoni (2002).\nIn 2012 Le Corre and the second author of this paper have proposed a rigorous\nmathematical framework for emergy analysis. They established that the exact\ncomputation of emergy is based on the so-called max-plus algebra and seven\ncoherent axioms that replace the emergy algebra. In this paper the MEP in\nsteady state is formalized in the context of the max-plus algebra and graph\ntheory. The main concepts of the paper are (a) a particular graph called\n'emergy graph', (b) the notion of compatible paths of the emergy graph, and (c)\nsets of compatible paths, which are called 'emergy states'. The main results of\nthe paper are as follows:\n(1) Emergy is mathematically expressed as a maximum over all possible emergy\nstates. (2) The maximum is always reached by an emergy state. (3) Only prevail\nemergy states for which the maximum is reached.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Adaptive Inferential Method for Monotone Graph Invariants.   We consider the problem of undirected graphical model inference. In many\napplications, instead of perfectly recovering the unknown graph structure, a\nmore realistic goal is to infer some graph invariants (e.g., the maximum\ndegree, the number of connected subgraphs, the number of isolated nodes). In\nthis paper, we propose a new inferential framework for testing nested multiple\nhypotheses and constructing confidence intervals of the unknown graph\ninvariants under undirected graphical models. Compared to perfect graph\nrecovery, our methods require significantly weaker conditions. This paper makes\ntwo major contributions: (i) Methodologically, for testing nested multiple\nhypotheses, we propose a skip-down algorithm on the whole family of monotone\ngraph invariants (The invariants which are non-decreasing under addition of\nedges). We further show that the same skip-down algorithm also provides valid\nconfidence intervals for the targeted graph invariants. (ii) Theoretically, we\nprove that the length of the obtained confidence intervals are optimal and\nadaptive to the unknown signal strength. We also prove generic lower bounds for\nthe confidence interval length for various invariants. Numerical results on\nboth synthetic simulations and a brain imaging dataset are provided to\nillustrate the usefulness of the proposed method.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Parameter Estimation in Mean Reversion Processes with Periodic Functional Tendency.   This paper describes the procedure to estimate the parameters in mean\nreversion processes with functional tendency defined by a periodic continuous\ndeterministic function, expressed as a series of truncated Fourier. Two phases\nof estimation are defined, in the first phase through Gaussian techniques using\nthe Euler-Maruyama discretization, we obtain the maximum likelihood function,\nthat will allow us to find estimators of the external parameters and an\nestimation of the expected value of the process. In the second phase, a\nreestimate of the periodic functional tendency with it's parameters of phase\nand amplitude is carried out, this will allow, improve the initial estimation.\nSome experimental result using simulated data sets are graphically illustrated.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Statistical Analysis of Precipitation Events.   In the present paper we demonstrate the results of a statistical analysis of\nsome characteristics of precipitation events and propose a kind of a\ntheoretical explanation of the proposed models in terms of mixed Poisson and\nmixed exponential distributions based on the information-theoretical entropy\nreasoning. The proposed models can be also treated as the result of following\nthe popular Bayesian approach.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Some Repeated-Root Constacyclic Codes over Galois Rings.   Codes over Galois rings have been studied extensively during the last three\ndecades. Negacyclic codes over $GR(2^a,m)$ of length $2^s$ have been\ncharacterized: the ring $\\mathcal{R}_2(a,m,-1)= \\frac{GR(2^a,m)[x]}{\\langle\nx^{2^s}+1\\rangle}$ is a chain ring. Furthermore, these results have been\ngeneralized to $\\lambda$-constacyclic codes for any unit $\\lambda$ of the form\n$4z-1$, $z\\in GR(2^a, m)$. In this paper, we study more general cases and\ninvestigate all cases where $\\mathcal{R}_p(a,m,\\gamma)=\n\\frac{GR(p^a,m)[x]}{\\langle x^{p^s}-\\gamma \\rangle}$ is a chain ring. In\nparticular, necessary and sufficient conditions for the ring\n$\\mathcal{R}_p(a,m,\\gamma)$ to be a chain ring are obtained. In addition, by\nusing this structure we investigate all $\\gamma$-constacyclic codes over\n$GR(p^a,m)$ when $\\mathcal{R}_p(a,m,\\gamma)$ is a chain ring. Necessary and\nsufficient conditions for the existence of self-orthogonal and self-dual\n$\\gamma$-constacyclic codes are also provided. Among others, for any prime $p$,\nthe structure of $\\mathcal{R}_p(a,m,\\gamma)=\\frac{GR(p^a,m)[x]}{\\langle\nx^{p^s}-\\gamma\\rangle}$ is used to establish the Hamming and homogeneous\ndistances of $\\gamma$-constacyclic codes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Prediction of half-metallic properties in TlCrS2 and TlCrSe2 based on density functional theory.   Half-metallic properties of TlCrS2, TlCrSe2 and hypothetical TlCrSSe have\nbeen investigated by first-principles all-electron full-potential linearized\naugmented plane wave plus local orbital (FP-LAPW+lo) method based on density\nfunctional theory (DFT). The results of calculations show that TlCrS2 and\nTlCrSSe are half-metals with energy gap (Eg ) ~0.12 ev for spin-down channel.\nStrong hybridization of p-state of chalchogen and d-state of Cr leads to\nbonding and antibonding states and subsequently to the appearance of a gap in\nspin-down channel of TlCrS2 and TlCrSSe. In the case of TlCrSe2, there is a\npartial hybridization and p-state is partially present in the DOS at Fermi\nlevel making this compound nearly half- metallic. The present calculations\nrevealed that total magnetic moment keeps its integer value on a relatively\nwide range of changes in volume (-10% 10%) for TlCrS2 and TlCrSSe, while total\nmagnetic moment of TlCrSe2 decreases with increasing volume approaching to\ninteger value 3{\\mu}B.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "The Informativeness of $k$-Means and Dimensionality Reduction for Learning Mixture Models.   The learning of mixture models can be viewed as a clustering problem. Indeed,\ngiven data samples independently generated from a mixture of distributions, we\noften would like to find the correct target clustering of the samples according\nto which component distribution they were generated from. For a clustering\nproblem, practitioners often choose to use the simple k-means algorithm.\nk-means attempts to find an optimal clustering which minimizes the\nsum-of-squared distance between each point and its cluster center. In this\npaper, we provide sufficient conditions for the closeness of any optimal\nclustering and the correct target clustering assuming that the data samples are\ngenerated from a mixture of log-concave distributions. Moreover, we show that\nunder similar or even weaker conditions on the mixture model, any optimal\nclustering for the samples with reduced dimensionality is also close to the\ncorrect target clustering. These results provide intuition for the\ninformativeness of k-means (with and without dimensionality reduction) as an\nalgorithm for learning mixture models. We verify the correctness of our\ntheorems using numerical experiments and demonstrate using datasets with\nreduced dimensionality significant speed ups for the time required to perform\nclustering.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Minimal surfaces and Schwarz lemma.   We prove a sharp Schwarz type inequality for the Weierstrass-Enneper\nrepresentation of the minimal surfaces.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Odd holes in bull-free graphs.   The complexity of testing whether a graph contains an induced odd cycle of\nlength at least five is currently unknown. In this paper we show that this can\nbe done in polynomial time if the input graph has no induced subgraph\nisomorphic to the bull (a triangle with two disjoint pendant edges).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Isomonodromy aspects of the tt* equations of Cecotti and Vafa III. Iwasawa factorization and asymptotics.   This paper, the third in a series, completes our description of all (radial)\nsolutions on C* of the tt*-Toda equations, using a combination of methods from\np.d.e., isomonodromic deformations (Riemann-Hilbert method), and loop groups.\nWe place these global solutions into the broader context of solutions which are\nsmooth near 0. For such solutions, we compute explicitly the Stokes data and\nconnection matrix of the associated meromorphic system, in the resonant cases\nas well as the non-resonant case. This allows us to give a complete picture of\nthe monodromy data of the global solutions.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Segmentation of Instances by Hashing.   We propose a novel approach to address the Simultaneous Detection and\nSegmentation problem. Using hierarchical structures we use an efficient and\naccurate procedure that exploits the hierarchy feature information using\nLocality Sensitive Hashing. We build on recent work that utilizes convolutional\nneural networks to detect bounding boxes in an image and then use the top\nsimilar hierarchical region that best fits each bounding box after hashing, we\ncall this approach CZ Segmentation. We then refine our final segmentation\nresults by automatic hierarchy pruning. CZ Segmentation introduces a train-free\nalternative to Hypercolumns. We conduct extensive experiments on PASCAL VOC\n2012 segmentation dataset, showing that CZ gives competitive state-of-the-art\nobject segmentations.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Learning to Acquire Information.   We consider the problem of diagnosis where a set of simple observations are\nused to infer a potentially complex hidden hypothesis. Finding the optimal\nsubset of observations is intractable in general, thus we focus on the problem\nof active diagnosis, where the agent selects the next most-informative\nobservation based on the results of previous observations. We show that under\nthe assumption of uniform observation entropy, one can build an implication\nmodel which directly predicts the outcome of the potential next observation\nconditioned on the results of past observations, and selects the observation\nwith the maximum entropy. This approach enjoys reduced computation complexity\nby bypassing the complicated hypothesis space, and can be trained on\nobservation data alone, learning how to query without knowledge of the hidden\nhypothesis.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Adaptive Quantization for Deep Neural Network.   In recent years Deep Neural Networks (DNNs) have been rapidly developed in\nvarious applications, together with increasingly complex architectures. The\nperformance gain of these DNNs generally comes with high computational costs\nand large memory consumption, which may not be affordable for mobile platforms.\nDeep model quantization can be used for reducing the computation and memory\ncosts of DNNs, and deploying complex DNNs on mobile equipment. In this work, we\npropose an optimization framework for deep model quantization. First, we\npropose a measurement to estimate the effect of parameter quantization errors\nin individual layers on the overall model prediction accuracy. Then, we propose\nan optimization process based on this measurement for finding optimal\nquantization bit-width for each layer. This is the first work that\ntheoretically analyse the relationship between parameter quantization errors of\nindividual layers and model accuracy. Our new quantization algorithm\noutperforms previous quantization optimization methods, and achieves 20-40%\nhigher compression rate compared to equal bit-width quantization at the same\nmodel prediction accuracy.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "On the isoperimetric quotient over scalar-flat conformal classes.   Let $(M,g)$ be a smooth compact Riemannian manifold of dimension $n$ with\nsmooth boundary $\\partial M$. Suppose that $(M,g)$ admits a scalar-flat\nconformal metric. We prove that the supremum of the isoperimetric quotient over\nthe scalar-flat conformal class is strictly larger than the best constant of\nthe isoperimetric inequality in the Euclidean space, and consequently is\nachieved, if either (i) $n\\ge 12$ and $\\partial M$ has a nonumbilic point; or\n(ii) $n\\ge 10$, $\\partial M$ is umbilic and the Weyl tensor does not vanish at\nsome boundary point.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "25 Tweets to Know You: A New Model to Predict Personality with Social Media.   Predicting personality is essential for social applications supporting\nhuman-centered activities, yet prior modeling methods with users written text\nrequire too much input data to be realistically used in the context of social\nmedia. In this work, we aim to drastically reduce the data requirement for\npersonality modeling and develop a model that is applicable to most users on\nTwitter. Our model integrates Word Embedding features with Gaussian Processes\nregression. Based on the evaluation of over 1.3K users on Twitter, we find that\nour model achieves comparable or better accuracy than state of the art\ntechniques with 8 times fewer data.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Wright-Fisher diffusions for evolutionary games with death-birth updating.   We investigate spatial evolutionary games with death-birth updating in large\nfinite populations. Within growing spatial structures subject to appropriate\nconditions, the density processes of a fixed type are proven to converge to the\nWright-Fisher diffusions with drift. In addition, convergence in the\nWasserstein distance of the laws of their occupation measures holds. The proofs\nof these results develop along an equivalence between the laws of the\nevolutionary games and certain voter models and rely on the analogous results\nof voter models on large finite sets by convergences of the Radon-Nikodym\nderivative processes. As another application of this equivalence of laws, we\nshow that in a general, large population of size $N$, for which the stationary\nprobabilities of the corresponding voting kernel are comparable to uniform\nprobabilities, a first-derivative test among the major methods for these\nevolutionary games is applicable at least up to weak selection strengths in the\nusual biological sense (that is, selection strengths of the order $\\mathcal\nO(1/N)$).",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Prediction of Sea Surface Temperature using Long Short-Term Memory.   This letter adopts long short-term memory(LSTM) to predict sea surface\ntemperature(SST), which is the first attempt, to our knowledge, to use\nrecurrent neural network to solve the problem of SST prediction, and to make\none week and one month daily prediction. We formulate the SST prediction\nproblem as a time series regression problem. LSTM is a special kind of\nrecurrent neural network, which introduces gate mechanism into vanilla RNN to\nprevent the vanished or exploding gradient problem. It has strong ability to\nmodel the temporal relationship of time series data and can handle the\nlong-term dependency problem well. The proposed network architecture is\ncomposed of two kinds of layers: LSTM layer and full-connected dense layer.\nLSTM layer is utilized to model the time series relationship. Full-connected\nlayer is utilized to map the output of LSTM layer to a final prediction. We\nexplore the optimal setting of this architecture by experiments and report the\naccuracy of coastal seas of China to confirm the effectiveness of the proposed\nmethod. In addition, we also show its online updated characteristics.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Open problems in mathematical physics.   We present a list of open questions in mathematical physics. After a\nhistorical introduction, a number of problems in a variety of different fields\nare discussed, with the intention of giving an overall impression of the\ncurrent status of mathematical physics, particularly in the topical fields of\nclassical general relativity, cosmology and the quantum realm. This list is\nmotivated by the recent article proposing 42 fundamental questions (in physics)\nwhich must be answered on the road to full enlightenment. But paraphrasing a\nfamous quote by the British football manager Bill Shankly, in response to the\nquestion of whether mathematics can answer the Ultimate Question of Life, the\nUniverse, and Everything, mathematics is, of course, much more important than\nthat.",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Univalent Foundations and the UniMath Library.   We give a concise presentation of the Univalent Foundations of mathematics\noutlining the main ideas, followed by a discussion of the UniMath library of\nformalized mathematics implementing the ideas of the Univalent Foundations\n(section 1), and the challenges one faces in attempting to design a large-scale\nlibrary of formalized mathematics (section 2). This leads us to a general\ndiscussion about the links between architecture and mathematics where a meeting\nof minds is revealed between architects and mathematicians (section 3). On the\nway our odyssey from the foundations to the \"horizon\" of mathematics will lead\nus to meet the mathematicians David Hilbert and Nicolas Bourbaki as well as the\narchitect Christopher Alexander.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Radar, without tears.   A brief introduction to radar: principles, Doppler effect, antennas,\nwaveforms, power budget - and future radars. [13 pages]",
        "labels": 1,
        "Physics": 1,
        "is_Physics": 1
    },
    {
        "text": "Second-Order Optimization for Non-Convex Machine Learning: An Empirical Study.   While first-order optimization methods such as stochastic gradient descent\n(SGD) are popular in machine learning (ML), they come with well-known\ndeficiencies, including relatively-slow convergence, sensitivity to the\nsettings of hyper-parameters such as learning rate, stagnation at high training\nerrors, and difficulty in escaping flat regions and saddle points. These issues\nare particularly acute in highly non-convex settings such as those arising in\nneural networks. Motivated by this, there has been recent interest in\nsecond-order methods that aim to alleviate these shortcomings by capturing\ncurvature information. In this paper, we report detailed empirical evaluations\nof a class of Newton-type methods, namely sub-sampled variants of trust region\n(TR) and adaptive regularization with cubics (ARC) algorithms, for non-convex\nML problems. In doing so, we demonstrate that these methods not only can be\ncomputationally competitive with hand-tuned SGD with momentum, obtaining\ncomparable or better generalization performance, but also they are highly\nrobust to hyper-parameter settings. Further, in contrast to SGD with momentum,\nwe show that the manner in which these Newton-type methods employ curvature\ninformation allows them to seamlessly escape flat regions and saddle points.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    },
    {
        "text": "Proactive Edge Computing in Latency-Constrained Fog Networks.   In this paper, the fundamental problem of distribution and proactive caching\nof computing tasks in fog networks is studied under latency and reliability\nconstraints. In the proposed scenario, computing can be executed either locally\nat the user device or offloaded to an edge cloudlet. Moreover, cloudlets\nexploit both their computing and storage capabilities by proactively caching\npopular task computation results to minimize computing latency. To this end, a\nclustering method to group spatially proximate user devices with mutual task\npopularity interests and their serving cloudlets is proposed. Then, cloudlets\ncan proactively cache the popular tasks' computations of their cluster members\nto minimize computing latency. Additionally, the problem of distributing tasks\nto cloudlets is formulated as a matching game in which a cost function of\ncomputing delay is minimized under latency and reliability constraints.\nSimulation results show that the proposed scheme guarantees reliable\ncomputations with bounded latency and achieves up to 91% decrease in computing\nlatency as compared to baseline schemes.",
        "labels": 0,
        "Physics": 0,
        "is_Physics": 0
    }
]